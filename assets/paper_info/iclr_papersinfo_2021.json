[
    {
        "order": 0,
        "title": "$i$-Mix: A Domain-Agnostic Strategy for Contrastive Representation Learning",
        "html": "https://iclr.cc//virtual/2021/poster/290911111",
        "abstract": "Contrastive representation learning has shown to be effective to learn representations from unlabeled data. However, much progress has been made in vision domains relying on data augmentations carefully designed using domain knowledge. In this work, we propose i-Mix, a simple yet effective domain-agnostic regularization strategy for improving contrastive representation learning. We cast contrastive learning as training a non-parametric classifier by assigning a unique virtual class to each data in a batch. Then, data instances are mixed in both the input and virtual label spaces, providing more augmented data during training. In experiments, we demonstrate that i-Mix consistently improves the quality of learned representations across domains, including image, speech, and tabular data. Furthermore, we confirm its regularization effect via extensive ablation studies across model and dataset sizes. The code is available at https://github.com/kibok90/imix.",
        "conference": "ICLR",
        "中文标题": "i-Mix：一种领域无关的对比表示学习策略",
        "摘要翻译": "对比表示学习已被证明能有效从无标签数据中学习表示。然而，许多进展依赖于利用领域知识精心设计的数据增强，在视觉领域取得了显著成果。在这项工作中，我们提出了i-Mix，一种简单而有效的领域无关的正则化策略，用于改进对比表示学习。我们将对比学习视为通过为批次中的每个数据分配一个唯一的虚拟类来训练一个非参数分类器。然后，数据实例在输入和虚拟标签空间中进行混合，从而在训练过程中提供更多增强数据。在实验中，我们证明了i-Mix能够持续提高跨领域（包括图像、语音和表格数据）学习表示的质量。此外，我们通过跨模型和数据集大小的广泛消融研究确认了其正则化效果。代码可在https://github.com/kibok90/imix获取。",
        "领域": "对比学习、多模态学习、数据增强",
        "问题": "如何在缺乏领域特定数据增强的情况下，提高对比表示学习的效果",
        "动机": "现有的对比表示学习大多依赖于特定领域的数据增强方法，限制了其在更广泛领域的应用。本研究旨在开发一种不依赖领域知识的通用策略，以提升对比学习的效果。",
        "方法": "提出i-Mix策略，通过在输入和虚拟标签空间混合数据实例，为对比学习提供更多样化的训练数据，从而提升模型的学习能力和泛化性。",
        "关键词": [
            "对比学习",
            "领域无关",
            "数据增强",
            "正则化",
            "多模态学习"
        ],
        "涉及的技术概念": {
            "对比表示学习": "一种通过比较数据实例间的相似性和差异性来学习数据表示的无监督学习方法。",
            "非参数分类器": "一种不依赖于固定参数形式的分类器，能够灵活适应数据分布的变化。",
            "虚拟标签空间": "在对比学习中，为每个数据实例分配一个唯一的虚拟类别，用于构建分类任务以促进表示学习。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 1,
        "title": "A Better Alternative to Error Feedback for Communication-Efficient Distributed Learning",
        "html": "https://iclr.cc//virtual/2021/poster/3119",
        "abstract": "Modern large-scale machine learning applications require stochastic optimization algorithms to be implemented on distributed computing systems. A key bottleneck of such systems is the communication overhead for exchanging information across the workers, such as stochastic gradients. Among the many techniques proposed to remedy this issue, one of the most successful is the framework of compressed communication with error feedback (EF). EF remains the only known technique that can deal with the error induced by contractive compressors which are not unbiased, such as Top-$K$ or PowerSGD.  In this paper, we propose a new and theoretically and practically better alternative to EF for dealing with contractive compressors. In particular, we propose a construction which can transform any contractive compressor into an induced unbiased compressor. Following this transformation, existing methods able to work with unbiased compressors can be applied. We show that our approach leads to vast improvements over EF, including reduced memory requirements, better communication complexity guarantees and fewer assumptions. We further extend our results to federated learning with partial participation following an arbitrary distribution over the nodes and demonstrate the benefits thereof. We perform several numerical experiments which validate our theoretical findings.",
        "conference": "ICLR",
        "中文标题": "一种更优的替代方案：用于通信高效分布式学习的误差反馈",
        "摘要翻译": "现代大规模机器学习应用需要在分布式计算系统上实现随机优化算法。这类系统的一个关键瓶颈是跨工作者交换信息（如随机梯度）的通信开销。在众多提出的解决此问题的技术中，最成功的一种是带有误差反馈（EF）的压缩通信框架。EF仍然是唯一已知的能够处理由非无偏的压缩器（如Top-K或PowerSGD）引入的误差的技术。在本文中，我们提出了一种新的、在理论和实践上都优于EF的替代方案，用于处理压缩器。特别是，我们提出了一种构造，可以将任何压缩器转换为诱导无偏压缩器。通过这种转换，可以应用能够处理无偏压缩器的现有方法。我们展示了我们的方法在多个方面优于EF，包括减少内存需求、更好的通信复杂度保证和更少的假设。我们进一步将我们的结果扩展到具有任意节点分布的部分参与的联邦学习，并展示了其好处。我们进行了多项数值实验，验证了我们的理论发现。",
        "领域": "分布式学习优化、联邦学习、通信效率优化",
        "问题": "解决分布式学习中通信开销大的问题，特别是处理非无偏压缩器引入的误差",
        "动机": "现有的误差反馈（EF）技术虽然有效，但在处理非无偏压缩器时存在局限性，需要一种更优的替代方案以提高通信效率和减少资源消耗",
        "方法": "提出一种新方法，通过构造将任何压缩器转换为诱导无偏压缩器，从而允许使用现有方法处理无偏压缩器，优化通信效率和资源使用",
        "关键词": [
            "分布式学习",
            "通信效率",
            "误差反馈",
            "压缩通信",
            "联邦学习"
        ],
        "涉及的技术概念": {
            "误差反馈（EF）": "一种用于处理压缩通信中误差的技术，能够处理非无偏压缩器引入的误差",
            "诱导无偏压缩器": "通过特定构造将压缩器转换为无偏形式，使得现有方法能够应用",
            "联邦学习": "一种分布式机器学习方法，允许多个设备或服务器共同训练模型，同时保护数据隐私"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 2,
        "title": "A Block Minifloat Representation for Training Deep Neural Networks",
        "html": "https://iclr.cc//virtual/2021/poster/2795",
        "abstract": "Training Deep Neural Networks (DNN) with high efficiency can be difficult to achieve with native floating-point representations and commercially available hardware. Specialized arithmetic with custom acceleration offers perhaps the most promising alternative. Ongoing research is trending towards narrow floating-point representations, called minifloats, that pack more operations for a given silicon area and consume less power. In this paper, we introduce Block Minifloat (BM), a new spectrum of minifloat formats capable of training DNNs end-to-end with only 4-8 bit weight, activation and gradient tensors. While standard floating-point representations have two degrees of freedom, via the exponent and mantissa, BM exposes the exponent bias as an additional field for optimization. Crucially, this enables training with fewer exponent bits, yielding dense integer-like hardware for fused multiply-add (FMA) operations. For ResNet trained on ImageNet, 6-bit BM achieves almost no degradation in floating-point accuracy with FMA units that are $4.1\\times(23.9\\times)$ smaller and consume $2.3\\times(16.1\\times)$ less energy than FP8 (FP32). Furthermore, our 8-bit BM format matches floating-point accuracy while delivering a higher computational density and faster expected training times.",
        "conference": "ICLR",
        "中文标题": "用于训练深度神经网络的块迷你浮点数表示法",
        "摘要翻译": "使用原生浮点数表示和商用硬件高效训练深度神经网络（DNN）可能难以实现。带有定制加速的专用算术或许提供了最有希望的替代方案。当前的研究趋势倾向于使用称为迷你浮点数的窄浮点数表示法，这种方法在给定的硅面积内打包更多操作并消耗更少的功率。在本文中，我们介绍了块迷你浮点数（BM），这是一种新的迷你浮点数格式谱系，能够仅使用4-8位的权重、激活和梯度张量端到端地训练DNN。虽然标准浮点数表示法通过指数和尾数有两个自由度，但BM将指数偏置作为一个额外的优化字段暴露出来。关键的是，这使得可以用更少的指数位进行训练，为融合乘加（FMA）操作产生密集的类似整数的硬件。对于在ImageNet上训练的ResNet，6位BM在FMA单元上几乎没有任何浮点精度的下降，这些单元比FP8（FP32）小4.1倍（23.9倍），消耗的能量少2.3倍（16.1倍）。此外，我们的8位BM格式在提供更高的计算密度和更快的预期训练时间的同时，匹配了浮点精度。",
        "领域": "深度学习硬件加速, 神经网络训练优化, 低精度计算",
        "问题": "如何在保持训练精度的同时，减少深度神经网络训练的计算资源和能源消耗",
        "动机": "探索更高效的浮点数表示法以减少深度神经网络训练的计算复杂度和能源消耗",
        "方法": "提出块迷你浮点数（BM）格式，通过优化指数偏置字段，减少所需的指数位数，从而实现更高效的硬件利用和能源消耗",
        "关键词": [
            "块迷你浮点数",
            "低精度训练",
            "硬件加速",
            "能源效率",
            "深度神经网络"
        ],
        "涉及的技术概念": {
            "块迷你浮点数（BM）": "一种新的浮点数表示法，通过优化指数偏置字段减少所需的指数位数，提高硬件利用率和能源效率",
            "融合乘加（FMA）操作": "一种高效的数学运算，结合乘法和加法操作，减少计算步骤和能源消耗",
            "低精度训练": "使用少于标准位数的浮点数表示法进行神经网络训练，以减少计算资源和能源消耗"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 3,
        "title": "Accelerating Convergence of Replica Exchange Stochastic Gradient MCMC via Variance Reduction",
        "html": "https://iclr.cc//virtual/2021/poster/2654",
        "abstract": "Replica exchange stochastic gradient Langevin dynamics (reSGLD) has shown promise in accelerating the convergence in non-convex learning; however, an excessively large correction for avoiding biases from noisy energy estimators has limited the potential of the acceleration. To address this issue, we study the variance reduction for noisy energy estimators, which promotes much more effective swaps. Theoretically, we provide a non-asymptotic analysis on the exponential convergence for the underlying continuous-time Markov jump process; moreover, we consider a generalized Girsanov theorem which includes the change of Poisson measure to overcome the crude discretization based on the Gr\\'{o}wall's inequality and yields a much tighter error in the 2-Wasserstein ($\\mathcal{W}_2$) distance. Numerically, we conduct extensive experiments and obtain state-of-the-art results in optimization and uncertainty estimates for synthetic experiments and image data.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "通过方差缩减加速副本交换随机梯度MCMC的收敛",
        "摘要翻译": "副本交换随机梯度朗之万动力学 (reSGLD) 在加速非凸学习中的收敛方面展现了潜力；然而，为了避免噪声能量估计器带来的偏差而进行过大的校正限制了加速的潜力。为了解决这个问题，我们研究了噪声能量估计器的方差缩减，这促进了更有效的交换。在理论上，我们对底层连续时间马尔可夫跳跃过程的指数收敛进行了非渐近分析；此外，我们考虑了一个广义的吉尔萨诺夫定理，其中包括泊松测度的变化，以克服基于格伦沃尔不等式的粗略离散化，并在2-Wasserstein (W2) 距离中产生更严格的误差。在数值上，我们进行了广泛的实验，并在合成实验和图像数据的优化和不确定性估计中获得了最先进的结果。",
        "领域": "贝叶斯优化、MCMC、随机优化",
        "问题": "如何提高副本交换随机梯度朗之万动力学(reSGLD)在非凸学习中的收敛速度，并克服因噪声能量估计器引起的偏差问题。",
        "动机": "现有的reSGLD方法为了避免噪声能量估计器带来的偏差，需要进行过大的校正，这限制了其加速收敛的潜力。因此，研究如何更有效地减少噪声能量估计器的方差，从而促进更有效的副本交换，成为一个重要的研究方向。",
        "方法": "该论文研究了噪声能量估计器的方差缩减方法，并提出了一个广义的吉尔萨诺夫定理，其中包括泊松测度的变化，以克服粗略离散化带来的误差。在理论上，对连续时间马尔可夫跳跃过程的指数收敛进行了非渐近分析。并通过实验验证了该方法在合成数据和图像数据上的优化和不确定性估计方面的有效性。",
        "关键词": [
            "副本交换随机梯度朗之万动力学",
            "方差缩减",
            "非凸学习",
            "马尔可夫跳跃过程",
            "吉尔萨诺夫定理"
        ],
        "涉及的技术概念": {
            "副本交换随机梯度朗之万动力学 (reSGLD)": "一种用于加速非凸学习中收敛速度的算法，通过多个副本在不同温度下采样，并定期交换副本状态，从而提高采样效率。",
            "方差缩减": "一种降低随机梯度估计方差的技术，通过减少梯度估计的噪声，提高优化算法的收敛速度和稳定性。",
            "吉尔萨诺夫定理": "用于描述随机过程测度变换的定理，在本文中被推广，用于分析离散化误差并提供更严格的误差界限。"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 4,
        "title": "Accurate Learning of Graph Representations with Graph Multiset Pooling",
        "html": "https://iclr.cc//virtual/2021/poster/3311",
        "abstract": "Graph neural networks have been widely used on modeling graph data, achieving impressive results on node classification and link prediction tasks. Yet, obtaining an accurate representation for a graph further requires a pooling function that maps a set of node representations into a compact form. A simple sum or average over all node representations considers all node features equally without consideration of their task relevance, and any structural dependencies among them. Recently proposed hierarchical graph pooling methods, on the other hand, may yield the same representation for two different graphs that are distinguished by the Weisfeiler-Lehman test, as they suboptimally preserve information from the node features. To tackle these limitations of existing graph pooling methods, we first formulate the graph pooling problem as a multiset encoding problem with auxiliary information about the graph structure, and propose a Graph Multiset Transformer (GMT) which is a multi-head attention based global pooling layer that captures the interaction between nodes according to their structural dependencies. We show that GMT satisfies both injectiveness and permutation invariance, such that it is at most as powerful as the Weisfeiler-Lehman graph isomorphism test. Moreover, our methods can be easily extended to the previous node clustering approaches for hierarchical graph pooling. Our experimental results show that GMT significantly outperforms state-of-the-art graph pooling methods on graph classification benchmarks with high memory and time efficiency, and obtains even larger performance gain on graph reconstruction and generation tasks.",
        "conference": "ICLR",
        "中文标题": "图多集池化的精确图表示学习",
        "摘要翻译": "图神经网络已被广泛应用于图数据的建模，在节点分类和链接预测任务上取得了令人印象深刻的成果。然而，为了获得图的精确表示，还需要一个池化函数，将一组节点表示映射为紧凑的形式。对所有节点表示进行简单的求和或平均操作，不考虑节点特征的任务相关性以及它们之间的结构依赖性。另一方面，最近提出的层次图池化方法可能会为两个通过Weisfeiler-Lehman测试区分的不同图产生相同的表示，因为它们次优地保留了节点特征的信息。为了解决现有图池化方法的这些限制，我们首先将图池化问题表述为一个带有图结构辅助信息的多集编码问题，并提出了一种基于多头注意力的全局池化层——图多集变换器（GMT），它根据节点的结构依赖性捕获节点之间的交互。我们证明了GMT满足单射性和排列不变性，因此它最多与Weisfeiler-Lehman图同构测试一样强大。此外，我们的方法可以轻松扩展到之前的节点聚类方法，用于层次图池化。我们的实验结果表明，GMT在图分类基准测试中显著优于最先进的图池化方法，具有高内存和时间效率，并在图重建和生成任务上获得了更大的性能提升。",
        "领域": "图神经网络、图分类、图生成",
        "问题": "解决现有图池化方法在保留节点特征信息和结构依赖性方面的不足",
        "动机": "提高图表示学习的精确度，通过更有效的池化方法捕捉图的结构依赖性",
        "方法": "提出图多集变换器（GMT），一种基于多头注意力的全局池化层，用于精确捕捉节点间的结构依赖性",
        "关键词": [
            "图神经网络",
            "图池化",
            "多头注意力",
            "图分类",
            "图生成"
        ],
        "涉及的技术概念": {
            "图多集变换器（GMT）": "一种基于多头注意力的全局池化层，用于精确捕捉节点间的结构依赖性",
            "Weisfeiler-Lehman测试": "用于区分图结构的测试，GMT的性能最多与此测试一样强大",
            "单射性和排列不变性": "GMT满足的性质，确保其能够为不同的图生成唯一的表示"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 5,
        "title": "Achieving Linear Speedup with Partial Worker Participation in Non-IID Federated Learning",
        "html": "https://iclr.cc//virtual/2021/poster/2729",
        "abstract": "Federated learning (FL) is a distributed machine learning architecture that leverages a large number of workers to jointly learn a model with decentralized data. FL has received increasing attention in recent years thanks to its data privacy protection, communication efficiency and a linear speedup for convergence in training (i.e., convergence performance increases linearly with respect to the number of workers). However, existing studies on linear speedup for convergence are only limited to the assumptions of i.i.d. datasets across workers and/or full worker participation, both of which rarely hold in practice. So far, it remains an open question whether or not the linear speedup for convergence is achievable under non-i.i.d. datasets with partial worker participation in FL.  In this paper, we show that the answer is affirmative. Specifically, we show that the federated averaging (FedAvg) algorithm (with two-sided learning rates) on non-i.i.d. datasets in non-convex settings achieves a convergence rate $\\mathcal{O}(\\frac{1}{\\sqrt{mKT}} + \\frac{1}{T})$ for full worker participation and a convergence rate $\\mathcal{O}(\\frac{1}{\\sqrt{nKT}} + \\frac{1}{T})$ for partial worker participation, where $K$ is the number of local steps, $T$ is the number of total communication rounds, $m$ is the total worker number and $n$ is the worker number in one communication round if for partial worker participation. Our results also reveal that the local steps in FL could help the convergence and show that the maximum number of local steps can be improved to $T/m$. We conduct extensive experiments on MNIST and CIFAR-10 to verify our theoretical results.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "在非独立同分布联邦学习中通过部分工作节点参与实现线性加速",
        "摘要翻译": "联邦学习(FL)是一种分布式机器学习架构，它利用大量工作节点，以去中心化的数据联合学习模型。近年来，联邦学习因其数据隐私保护、通信效率和训练中收敛的线性加速(即，收敛性能随着工作节点数量线性增长)而受到越来越多的关注。然而，现有关于收敛线性加速的研究仅限于工作节点间独立同分布(i.i.d.)数据集和/或完全工作节点参与的假设，而这两种情况在实践中很少成立。到目前为止，在非独立同分布数据集和部分工作节点参与的联邦学习中，收敛的线性加速是否可以实现仍然是一个悬而未决的问题。在本文中，我们证明答案是肯定的。具体来说，我们证明了联邦平均(FedAvg)算法(具有双边学习率)在非凸设置下的非独立同分布数据集上，对于完全工作节点参与，实现了$\\mathcal{O}(\\frac{1}{\\sqrt{mKT}} + \\frac{1}{T})$的收敛速度，对于部分工作节点参与，实现了$\\mathcal{O}(\\frac{1}{\\sqrt{nKT}} + \\frac{1}{T})$的收敛速度，其中$K$是局部步骤的数量，$T$是总通信轮数，$m$是总工作节点数，如果为部分工作节点参与，则$n$是一轮通信中的工作节点数。我们的结果还表明，联邦学习中的局部步骤有助于收敛，并表明局部步骤的最大数量可以提高到$T/m$。我们在MNIST和CIFAR-10上进行了广泛的实验，以验证我们的理论结果。",
        "领域": "联邦学习、非独立同分布数据、分布式优化",
        "问题": "在非独立同分布的数据集和部分工作节点参与的情况下，联邦学习是否还能实现线性加速收敛。",
        "动机": "现有的联邦学习线性加速收敛研究通常假设数据是独立同分布的，并且所有工作节点都参与训练，但这些假设在实际应用中往往不成立。因此，研究在更现实的非独立同分布数据和部分节点参与情况下，联邦学习的收敛速度至关重要。",
        "方法": "通过理论分析，证明了在非独立同分布数据集上，使用联邦平均算法(FedAvg)结合双边学习率，即使在部分工作节点参与的情况下，也能实现线性加速收敛。并通过MNIST和CIFAR-10数据集上的实验验证了理论结果。",
        "关键词": [
            "联邦学习",
            "非独立同分布",
            "线性加速",
            "联邦平均算法",
            "部分节点参与"
        ],
        "涉及的技术概念": {
            "联邦学习": "一种分布式机器学习范式，允许多个客户端在不共享原始数据的情况下协同训练模型，保护数据隐私。",
            "非独立同分布数据": "指各个客户端拥有的数据分布不一致，这是实际联邦学习场景中常见的情况，会影响模型训练的收敛性。"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 6,
        "title": "A Critique of Self-Expressive Deep Subspace Clustering",
        "html": "https://iclr.cc//virtual/2021/poster/2688",
        "abstract": "Subspace clustering is an unsupervised clustering technique designed to cluster data that is supported on a union of linear subspaces, with each subspace defining a cluster with dimension lower than the ambient space. Many existing formulations for this problem are based on exploiting the self-expressive property of linear subspaces, where any point within a subspace can be represented as linear combination of other points within the subspace. To extend this approach to data supported on a union of non-linear manifolds, numerous studies have proposed learning an embedding of the original data using  a neural network which is regularized by a self-expressive loss function on the data in the embedded space to encourage a union of linear subspaces prior on the data in the embedded space. Here we show that there are a number of potential flaws with this approach which have not been adequately addressed in prior work. In particular, we show the model formulation is often ill-posed in that it can lead to a degenerate embedding of the data, which need not correspond to a union of subspaces at all and is poorly suited for clustering. We validate our theoretical results experimentally and also repeat prior experiments reported in the literature, where we conclude that a significant portion of the previously claimed performance benefits can be attributed to an ad-hoc post processing step rather than the deep subspace clustering model.",
        "conference": "ICLR",
        "中文标题": "自表达深度子空间聚类的批判",
        "摘要翻译": "子空间聚类是一种无监督聚类技术，旨在对支撑在一组线性子空间并集上的数据进行聚类，每个子空间定义一个维度低于环境空间的聚类。许多现有的问题表述基于利用线性子空间的自表达特性，即子空间内的任何点可以表示为子空间内其他点的线性组合。为了将这种方法扩展到支撑在非线性流形并集上的数据，许多研究提出使用神经网络学习原始数据的嵌入，通过在嵌入空间中的数据上施加自表达损失函数来正则化，以鼓励嵌入空间中的数据具有线性子空间并集的先验。在这里，我们展示了这种方法存在一些潜在缺陷，这些缺陷在先前的工作中未得到充分解决。特别是，我们展示了模型表述常常是不适定的，因为它可能导致数据的退化嵌入，这种嵌入根本不需要对应于子空间的并集，并且不适合聚类。我们通过实验验证了我们的理论结果，并重复了文献中报道的先前实验，我们得出结论，先前声称的性能优势的很大一部分可以归因于一个临时后处理步骤，而不是深度子空间聚类模型。",
        "领域": "子空间聚类",
        "问题": "探讨自表达深度子空间聚类方法的潜在缺陷及其对聚类效果的影响",
        "动机": "揭示现有自表达深度子空间聚类方法在理论和实践中存在的问题，特别是模型不适定性和退化嵌入问题",
        "方法": "通过理论分析和实验验证，评估自表达深度子空间聚类方法的有效性，并重复前人实验以验证性能优势的真实来源",
        "关键词": [
            "子空间聚类",
            "自表达特性",
            "深度聚类",
            "非线性流形",
            "模型不适定性"
        ],
        "涉及的技术概念": {
            "自表达特性": "线性子空间内点可以表示为其他点的线性组合的特性，用于子空间聚类",
            "深度子空间聚类": "利用神经网络学习数据嵌入，并通过自表达损失函数正则化以促进线性子空间先验的聚类方法",
            "模型不适定性": "指模型表述可能导致不唯一或无意义的解，如退化嵌入，影响聚类效果"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 7,
        "title": "Acting in Delayed Environments with Non-Stationary Markov Policies",
        "html": "https://iclr.cc//virtual/2021/poster/3370",
        "abstract": "The standard Markov Decision Process (MDP) formulation hinges on the assumption that an action is executed immediately after it was chosen. However, assuming it is often unrealistic and can lead to catastrophic failures in applications such as robotic manipulation, cloud computing, and finance. We introduce a framework for learning and planning in MDPs where the decision-maker commits actions that are executed with a delay of $m$ steps. The brute-force state augmentation baseline where the state is concatenated to the last $m$ committed actions suffers from an exponential complexity in $m$, as we show for policy iteration. We then prove that with execution delay, deterministic Markov policies in the original state-space are sufficient for attaining maximal reward, but need to be non-stationary. As for stationary Markov policies, we show they are sub-optimal in general. Consequently, we devise a non-stationary Q-learning style model-based algorithm that solves delayed execution tasks without resorting to state-augmentation. Experiments on tabular, physical, and Atari domains reveal that it converges quickly to high performance even for substantial delays, while standard approaches that either ignore the delay or rely on state-augmentation struggle or fail due to divergence. The code is available at \\url{https://github.com/galdl/rl_delay_basic.git}.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "在具有非平稳马尔可夫策略的延迟环境中行动",
        "摘要翻译": "标准的马尔可夫决策过程（MDP）公式基于一个假设，即一个动作在被选择后会立即执行。然而，这一假设往往不切实际，并可能导致在机器人操作、云计算和金融等应用中的灾难性失败。我们引入了一个在MDP中学习和规划框架，其中决策者承诺的动作将在$m$步延迟后执行。我们展示了对于策略迭代，将状态与最后$m$个承诺动作连接的暴力状态增强基线方法在$m$上具有指数复杂度。然后我们证明，在执行延迟的情况下，原始状态空间中的确定性马尔可夫策略足以获得最大奖励，但需要是非平稳的。至于平稳马尔可夫策略，我们证明它们在一般情况下是次优的。因此，我们设计了一种非平稳Q学习风格的基于模型的算法，该算法解决了延迟执行任务，而无需依赖于状态增强。在表格、物理和Atari领域的实验表明，即使对于显著的延迟，它也能快速收敛到高性能，而忽略延迟或依赖于状态增强的标准方法要么挣扎要么由于发散而失败。代码可在https://github.com/galdl/rl_delay_basic.git获取。",
        "领域": "强化学习",
        "问题": "解决在动作执行延迟的环境中学习和规划的问题",
        "动机": "标准的马尔可夫决策过程假设动作立即执行，这在许多实际应用中不切实际，可能导致失败",
        "方法": "引入了一种非平稳Q学习风格的基于模型的算法，无需状态增强即可处理延迟执行",
        "关键词": [
            "延迟执行",
            "非平稳马尔可夫策略",
            "强化学习",
            "模型基于算法",
            "状态增强"
        ],
        "涉及的技术概念": {
            "非平稳马尔可夫策略": "在原始状态空间中使用，以适应动作执行的延迟，确保策略的有效性",
            "Q学习": "一种强化学习算法，用于在延迟执行环境中学习和规划",
            "状态增强": "一种通过增加状态信息来处理延迟的方法，但可能导致计算复杂度指数增长"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 8,
        "title": "Activation-level uncertainty in deep neural networks",
        "html": "https://iclr.cc//virtual/2021/poster/3038",
        "abstract": "Current approaches for uncertainty estimation in deep learning often produce too confident results. Bayesian Neural Networks (BNNs) model uncertainty in the space of weights, which is usually high-dimensional and limits the quality of variational approximations. The more recent functional BNNs (fBNNs) address this only partially because, although the prior is specified in the space of functions, the posterior approximation is still defined in terms of stochastic weights. In this work we propose to move uncertainty from the weights (which are deterministic) to the activation function. Specifically, the activations are modelled with simple 1D Gaussian Processes (GP), for which a triangular kernel inspired by the ReLu non-linearity is explored. Our experiments show that activation-level stochasticity provides more reliable uncertainty estimates than BNN and fBNN, whereas it performs competitively in standard prediction tasks. We also study the connection with deep GPs, both theoretically and empirically. More precisely, we show that activation-level uncertainty requires fewer inducing points and is better suited for deep architectures.",
        "conference": "ICLR",
        "中文标题": "深度神经网络中的激活级别不确定性",
        "摘要翻译": "当前深度学习中不确定性估计的方法往往产生过于自信的结果。贝叶斯神经网络（BNNs）在权重空间中建模不确定性，这通常是高维的，限制了变分近似的质量。较新的功能性贝叶斯神经网络（fBNNs）仅部分解决了这个问题，因为尽管先验是在函数空间中指定的，后验近似仍然是根据随机权重定义的。在这项工作中，我们提出将不确定性从权重（它们是确定性的）转移到激活函数。具体来说，激活被建模为简单的一维高斯过程（GP），其中探索了一个受ReLu非线性启发的三角核。我们的实验表明，激活级别的随机性比BNN和fBNN提供了更可靠的不确定性估计，而在标准预测任务中表现竞争性。我们还从理论和实证上研究了与深度GPs的联系。更准确地说，我们展示了激活级别不确定性需要更少的诱导点，并且更适合深度架构。",
        "领域": "深度学习不确定性估计、贝叶斯神经网络、高斯过程",
        "问题": "解决深度学习中不确定性估计方法产生过于自信结果的问题",
        "动机": "提高深度神经网络中不确定性估计的可靠性和准确性",
        "方法": "将不确定性从权重转移到激活函数，使用一维高斯过程建模激活，并探索受ReLu启发的三角核",
        "关键词": [
            "不确定性估计",
            "贝叶斯神经网络",
            "高斯过程",
            "激活函数",
            "深度架构"
        ],
        "涉及的技术概念": {
            "贝叶斯神经网络（BNNs）": "在权重空间中建模不确定性，但由于高维性限制了变分近似的质量",
            "功能性贝叶斯神经网络（fBNNs）": "尝试在先验函数空间中指定不确定性，但后验近似仍基于随机权重",
            "高斯过程（GP）": "用于建模激活函数的不确定性，探索受ReLu启发的三角核以提高估计的可靠性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 9,
        "title": "Active Contrastive Learning of Audio-Visual Video Representations",
        "html": "https://iclr.cc//virtual/2021/poster/2900",
        "abstract": "Contrastive learning has been shown to produce generalizable representations of audio and visual data by maximizing the lower bound on the mutual information (MI) between different views of an instance. However, obtaining a tight lower bound requires a sample size exponential in MI and thus a large set of negative samples. We can incorporate more samples by building a large queue-based dictionary, but there are theoretical limits to performance improvements even with a large number of negative samples. We hypothesize that random negative sampling leads to a highly redundant dictionary that results in suboptimal representations for downstream tasks. In this paper, we propose an active contrastive learning approach that builds an actively sampled dictionary with diverse and informative items, which improves the quality of negative samples and improves performances on tasks where there is high mutual information in the data, e.g., video classification. Our model achieves state-of-the-art performance on challenging audio and visual downstream benchmarks including UCF101, HMDB51 and ESC50. ",
        "conference": "ICLR",
        "中文标题": "音频-视觉视频表征的主动对比学习",
        "摘要翻译": "对比学习通过最大化实例不同视图间互信息（MI）的下界，已被证明能够产生音频和视觉数据的通用表征。然而，获得一个紧致的下界需要样本量随MI指数级增长，因此需要大量负样本。我们可以通过构建一个基于队列的大型字典来纳入更多样本，但即使有大量负样本，性能提升也存在理论限制。我们假设随机负采样会导致字典高度冗余，从而为下游任务产生次优表征。在本文中，我们提出了一种主动对比学习方法，该方法构建了一个主动采样的字典，包含多样化和信息丰富的项，这提高了负样本的质量，并在数据中存在高互信息的任务（如视频分类）中提高了性能。我们的模型在包括UCF101、HMDB51和ESC50在内的具有挑战性的音频和视觉下游基准测试中实现了最先进的性能。",
        "领域": "视频分类",
        "问题": "如何提高对比学习中负样本的质量以优化表征学习",
        "动机": "随机负采样导致的字典冗余限制了表征学习的性能，特别是在高互信息数据任务中",
        "方法": "提出主动对比学习方法，通过构建包含多样化和信息丰富项的主动采样字典，提高负样本质量",
        "关键词": [
            "对比学习",
            "音频-视觉表征",
            "视频分类",
            "主动采样",
            "互信息"
        ],
        "涉及的技术概念": {
            "对比学习": "一种通过最大化实例不同视图间互信息下界来学习数据表征的方法",
            "互信息（MI）": "衡量两个变量间相互依赖性的指标，用于评估表征学习的效果",
            "主动采样": "一种选择性地采集样本以优化学习过程的技术，用于提高负样本的质量和多样性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 10,
        "title": "AdaFuse: Adaptive Temporal Fusion Network for Efficient Action Recognition",
        "html": "https://iclr.cc//virtual/2021/poster/3252",
        "abstract": "Temporal modelling is the key for efficient video action recognition. While understanding temporal information can improve recognition accuracy for dynamic actions, removing temporal redundancy and reusing past features can significantly save computation leading to efficient action recognition. In this paper, we introduce an adaptive temporal fusion network, called AdaFuse, that dynamically fuses channels from current and past feature maps for strong temporal modelling. Specifically, the necessary information from the historical convolution feature maps is fused with current pruned feature maps with the goal of improving both recognition accuracy and efficiency. In addition, we use a skipping operation to further reduce the computation cost of action recognition. Extensive experiments on SomethingV1 & V2, Jester and Mini-Kinetics show that our approach can achieve about 40% computation savings with comparable accuracy to state-of-the-art methods. The project page can be found at https://mengyuest.github.io/AdaFuse/",
        "conference": "ICLR",
        "中文标题": "AdaFuse: 自适应时间融合网络用于高效动作识别",
        "摘要翻译": "时间建模是高效视频动作识别的关键。理解时间信息可以提高动态动作的识别准确率，而消除时间冗余和重用过去特征可以显著节省计算量，从而实现高效的动作识别。本文介绍了一种自适应时间融合网络，称为AdaFuse，它动态融合当前和过去特征图的通道，以实现强大的时间建模。具体来说，从历史卷积特征图中提取的必要信息与当前剪枝后的特征图融合，旨在提高识别准确率和效率。此外，我们使用跳过操作进一步降低动作识别的计算成本。在SomethingV1 & V2、Jester和Mini-Kinetics上的大量实验表明，我们的方法可以节省约40%的计算量，同时保持与最先进方法相当的准确率。项目页面可在https://mengyuest.github.io/AdaFuse/找到。",
        "领域": "动作识别",
        "问题": "如何在动作识别中高效地利用时间信息，同时减少计算冗余",
        "动机": "通过动态融合历史与当前特征，提高动作识别的准确率和效率，减少不必要的计算开销",
        "方法": "提出AdaFuse网络，动态融合当前和历史特征图的通道，采用跳过操作减少计算量",
        "关键词": [
            "自适应时间融合",
            "动作识别",
            "计算效率",
            "特征重用",
            "跳过操作"
        ],
        "涉及的技术概念": {
            "自适应时间融合": "动态融合当前和历史特征图的通道，优化时间建模",
            "跳过操作": "用于进一步减少动作识别的计算成本",
            "特征剪枝": "减少当前特征图的冗余信息，提高处理效率"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 11,
        "title": "AdaGCN: Adaboosting Graph Convolutional Networks into Deep Models",
        "html": "https://iclr.cc//virtual/2021/poster/2536",
        "abstract": "The design of deep graph models still remains to be investigated and the crucial part is how to explore and exploit the knowledge from different hops of neighbors in an efficient way. In this paper, we propose a novel RNN-like deep graph neural network architecture by incorporating AdaBoost into the computation of network; and the proposed graph convolutional network called AdaGCN~(Adaboosting Graph Convolutional Network) has the ability to efficiently extract knowledge from high-order neighbors of current nodes and then integrates knowledge from different hops of neighbors into the network in an Adaboost way. Different from other graph neural networks that directly stack many graph convolution layers, AdaGCN shares the same base neural network architecture among all ``layers'' and is recursively optimized, which is similar to an RNN. Besides, We also theoretically established the connection between AdaGCN and existing graph convolutional methods, presenting the benefits of our proposal. Finally, extensive experiments demonstrate the consistent state-of-the-art prediction performance on graphs across different label rates and the computational advantage of our approach AdaGCN~\\footnote{Code is available at \\url{https://github.com/datake/AdaGCN}.}.",
        "conference": "ICLR",
        "中文标题": "AdaGCN：将图卷积网络通过AdaBoost方法深化为深度模型",
        "摘要翻译": "深度图模型的设计仍有待探索，其关键部分在于如何高效地探索和利用来自不同跳数邻居的知识。本文提出了一种新颖的、类似于RNN的深度图神经网络架构，通过将AdaBoost融入网络计算中；所提出的图卷积网络称为AdaGCN（Adaboosting Graph Convolutional Network），能够有效地从当前节点的高阶邻居中提取知识，然后以AdaBoost的方式将来自不同跳数邻居的知识整合到网络中。与其他直接堆叠多个图卷积层的图神经网络不同，AdaGCN在所有“层”之间共享相同的基础神经网络架构，并以类似于RNN的方式进行递归优化。此外，我们还从理论上建立了AdaGCN与现有图卷积方法之间的联系，展示了我们提案的优势。最后，大量实验证明了我们的方法AdaGCN在不同标签率下的图预测性能上的一致性和计算优势。",
        "领域": "图神经网络、深度学习优化、图表示学习",
        "问题": "如何高效地探索和利用来自不同跳数邻居的知识以设计深度图模型",
        "动机": "探索和利用来自不同跳数邻居的知识，以提高图模型的预测性能和计算效率",
        "方法": "提出了一种新颖的、类似于RNN的深度图神经网络架构，通过将AdaBoost融入网络计算中，有效地从高阶邻居中提取知识并以AdaBoost方式整合",
        "关键词": [
            "AdaGCN",
            "图卷积网络",
            "AdaBoost",
            "深度图模型",
            "图表示学习"
        ],
        "涉及的技术概念": {
            "AdaBoost": "用于整合来自不同跳数邻居的知识，提升模型的预测性能",
            "图卷积网络": "用于从图中提取特征和知识的网络架构",
            "递归优化": "类似于RNN的优化方式，共享基础网络架构，提高计算效率"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 12,
        "title": "AdamP: Slowing Down the Slowdown for Momentum Optimizers on Scale-invariant Weights",
        "html": "https://iclr.cc//virtual/2021/poster/2880",
        "abstract": "Normalization techniques, such as batch normalization (BN), are a boon for modern deep learning. They let weights converge more quickly with often better generalization performances. It has been argued that the normalization-induced scale invariance among the weights provides an advantageous ground for gradient descent (GD) optimizers: the effective step sizes are automatically reduced over time, stabilizing the overall training procedure. It is often overlooked, however, that the additional introduction of momentum in GD optimizers results in a far more rapid reduction in effective step sizes for scale-invariant weights, a phenomenon that has not yet been studied and may have caused unwanted side effects in the current practice. This is a crucial issue because arguably the vast majority of modern deep neural networks consist of (1) momentum-based GD (e.g. SGD or Adam) and (2) scale-invariant parameters (e.g. more than 90% of the weights in ResNet are scale-invariant due to BN). In this paper, we verify that the widely-adopted combination of the two ingredients lead to the premature decay of effective step sizes and sub-optimal model performances. We propose a simple and effective remedy, SGDP and AdamP: get rid of the radial component, or the norm-increasing direction, at each optimizer step. Because of the scale invariance, this modification only alters the effective step sizes without changing the effective update directions, thus enjoying the original convergence properties of GD optimizers. Given the ubiquity of momentum GD and scale invariance in machine learning, we have evaluated our methods against the baselines on 13 benchmarks. They range from vision tasks like classification (e.g. ImageNet), retrieval (e.g. CUB and SOP), and detection (e.g. COCO) to language modelling (e.g. WikiText) and audio classification (e.g. DCASE) tasks. We verify that our solution brings about uniform gains in performances in those benchmarks. Source code is available at https://github.com/clovaai/adamp",
        "conference": "ICLR",
        "中文标题": "AdamP：为动量优化器在尺度不变权重上减缓减速",
        "摘要翻译": "批归一化（BN）等归一化技术对现代深度学习大有裨益。它们让权重更快收敛，且通常具有更好的泛化性能。有人认为，归一化引起的权重尺度不变性为梯度下降（GD）优化器提供了有利条件：有效步长随时间自动减小，从而稳定了整个训练过程。然而，人们往往忽视了在GD优化器中额外引入动量会导致尺度不变权重的有效步长更迅速地减小，这一现象尚未被研究，并可能在当前实践中引起不必要的副作用。这是一个关键问题，因为可以说绝大多数现代深度神经网络由（1）基于动量的GD（如SGD或Adam）和（2）尺度不变参数（如由于BN，ResNet中超过90%的权重是尺度不变的）组成。在本文中，我们验证了这两种成分的广泛采用导致了有效步长的过早衰减和次优模型性能。我们提出了一个简单有效的补救措施，SGDP和AdamP：在每个优化器步骤中去除径向分量或增加范数的方向。由于尺度不变性，这种修改仅改变有效步长而不改变有效更新方向，因此享有GD优化器的原始收敛特性。鉴于动量GD和尺度不变性在机器学习中的普遍性，我们已在13个基准测试中评估了我们的方法与基线。这些基准测试范围从视觉任务如分类（如ImageNet）、检索（如CUB和SOP）和检测（如COCO）到语言建模（如WikiText）和音频分类（如DCASE）任务。我们验证了我们的解决方案在这些基准测试中带来了性能上的统一提升。源代码可在https://github.com/clovaai/adamp获取。",
        "领域": "深度学习优化方法、计算机视觉、自然语言处理",
        "问题": "动量优化器在尺度不变权重上导致有效步长过快减小的问题",
        "动机": "研究动量优化器在尺度不变权重上的行为，解决由此引起的有效步长过快减小和模型性能下降的问题",
        "方法": "提出SGDP和AdamP优化器，通过去除每个优化步骤中的径向分量来调整有效步长，而不改变更新方向",
        "关键词": [
            "动量优化器",
            "尺度不变性",
            "批归一化",
            "深度学习优化",
            "有效步长"
        ],
        "涉及的技术概念": {
            "动量优化器": "在梯度下降中引入动量项以加速收敛和减少震荡的优化器",
            "尺度不变性": "权重经过归一化处理后，其尺度变化不影响模型输出的性质",
            "批归一化": "一种通过规范化层输入以加速深度网络训练的技术"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 13,
        "title": "Adapting to Reward Progressivity via Spectral Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2021/poster/3323",
        "abstract": "In this paper we consider reinforcement learning tasks with progressive rewards; that is, tasks where the rewards tend to increase in magnitude over time. We hypothesise that this property may be problematic for value-based deep reinforcement learning agents, particularly if the agent must first succeed in relatively unrewarding regions of the task in order to reach more rewarding regions. To address this issue, we propose Spectral DQN, which decomposes the reward into frequencies such that the high frequencies only activate when large rewards are found. This allows the training loss to be balanced so that it gives more even weighting across small and large reward regions. In two domains with extreme reward progressivity, where standard value-based methods struggle significantly, Spectral DQN is able to make much farther progress. Moreover, when evaluated on a set of six standard Atari games that do not overtly favour the approach, Spectral DQN remains more than competitive: While it underperforms one of the benchmarks in a single game, it comfortably surpasses the benchmarks in three games. These results demonstrate that the approach is not overfit to its target problem, and suggest that Spectral DQN may have advantages beyond addressing reward progressivity.",
        "conference": "ICLR",
        "中文标题": "通过谱强化学习适应奖励渐进性",
        "摘要翻译": "在本文中，我们考虑了具有渐进奖励的强化学习任务；即，奖励随时间推移而增加的幅度的任务。我们假设这一特性可能对基于价值的深度强化学习代理构成问题，特别是如果代理必须首先在任务中相对无奖励的区域取得成功才能到达更有奖励的区域。为了解决这个问题，我们提出了谱DQN，它将奖励分解为频率，使得高频仅在发现大奖励时激活。这使得训练损失能够平衡，从而在小和大奖励区域之间给予更均匀的权重。在两个具有极端奖励渐进性的领域中，标准的基于价值的方法显著挣扎，谱DQN能够取得更远的进展。此外，当在一组六种标准Atari游戏上评估时，这些游戏并不明显偏爱该方法，谱DQN仍然具有竞争力：虽然它在单个游戏中表现不如一个基准，但在三个游戏中轻松超越基准。这些结果表明，该方法并未过度适应其目标问题，并暗示谱DQN可能具有超越解决奖励渐进性的优势。",
        "领域": "深度强化学习、奖励设计、游戏AI",
        "问题": "解决在奖励渐进性任务中，基于价值的深度强化学习代理可能因奖励分布不均而表现不佳的问题。",
        "动机": "研究动机在于探索奖励渐进性对强化学习代理性能的影响，并提出一种方法来平衡训练过程中的奖励分布，以提升代理在极端奖励渐进性任务中的表现。",
        "方法": "提出谱DQN方法，通过将奖励分解为不同频率，使得高频奖励仅在发现大奖励时激活，从而平衡训练损失，给予小和大奖励区域更均匀的权重。",
        "关键词": [
            "谱DQN",
            "奖励渐进性",
            "深度强化学习",
            "奖励分解",
            "Atari游戏"
        ],
        "涉及的技术概念": {
            "谱DQN": "一种将奖励分解为频率的深度强化学习方法，旨在平衡训练过程中的奖励分布。",
            "奖励渐进性": "任务中奖励随时间推移而增加的幅度特性，可能影响强化学习代理的性能。",
            "奖励分解": "将奖励信号分解为不同频率成分的技术，用于调整训练过程中对不同大小奖励的关注度。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 14,
        "title": "Adaptive and Generative Zero-Shot Learning",
        "html": "https://iclr.cc//virtual/2021/poster/3297",
        "abstract": "We address the problem of generalized zero-shot learning (GZSL) where the task is to predict the class label of a target image whether its label belongs to the seen or unseen category. Similar to ZSL, the learning setting assumes that all class-level semantic features are given, while only the images of seen classes are available for training. By exploring the correlation between image features and the corresponding semantic features, the main idea of the proposed approach is to enrich the semantic-to-visual (S2V) embeddings via a seamless fusion of adaptive and generative learning. To this end, we extend the semantic features of each class by supplementing image-adaptive attention so that the learned S2V embedding can account for not only inter-class but also intra-class variations. In addition, to break the limit of training with images only from seen classes, we design a generative scheme to simultaneously generate virtual class labels and their visual features by sampling and interpolating over seen counterparts. In inference, a testing image will give rise to two different S2V embeddings, seen and virtual. The former is used to decide whether the underlying label is of the unseen category or otherwise a specific seen class; the latter is to predict an unseen class label. To demonstrate the effectiveness of our method, we report state-of-the-art results on four standard GZSL datasets, including an ablation study of the proposed modules. ",
        "conference": "ICLR",
        "中文标题": "自适应与生成式零样本学习",
        "摘要翻译": "我们解决了广义零样本学习（GZSL）的问题，其任务是预测目标图像的类别标签，无论其标签属于已见类别还是未见类别。与ZSL类似，学习设置假设所有类级别的语义特征都已给出，而只有已见类别的图像可用于训练。通过探索图像特征与相应语义特征之间的相关性，所提出方法的主要思想是通过自适应和生成学习的无缝融合来丰富语义到视觉（S2V）的嵌入。为此，我们通过补充图像自适应注意力来扩展每个类别的语义特征，使得学习到的S2V嵌入不仅能够考虑类别间的变化，还能考虑类别内的变化。此外，为了打破仅使用已见类别图像进行训练的限制，我们设计了一个生成方案，通过采样和插值已见类别的对应物，同时生成虚拟类别标签及其视觉特征。在推理过程中，测试图像将产生两种不同的S2V嵌入，已见和虚拟。前者用于决定底层标签是未见类别还是特定的已见类别；后者用于预测未见类别标签。为了证明我们方法的有效性，我们在四个标准的GZSL数据集上报告了最先进的结果，包括对所提出模块的消融研究。",
        "领域": "零样本学习",
        "问题": "解决广义零样本学习中的类别预测问题，包括已见和未见类别的识别。",
        "动机": "探索图像特征与语义特征之间的相关性，通过自适应和生成学习的方法提升零样本学习的性能。",
        "方法": "通过图像自适应注意力扩展语义特征，设计生成方案生成虚拟类别标签和视觉特征，结合已见和虚拟S2V嵌入进行类别预测。",
        "关键词": [
            "广义零样本学习",
            "语义到视觉嵌入",
            "图像自适应注意力",
            "虚拟类别生成",
            "类别预测"
        ],
        "涉及的技术概念": {
            "语义到视觉（S2V）嵌入": "用于将语义特征映射到视觉空间，以便于类别预测。",
            "图像自适应注意力": "用于扩展语义特征，考虑类别内和类别间的变化。",
            "虚拟类别生成": "通过采样和插值已见类别的对应物，生成未见类别的虚拟标签和视觉特征。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 15,
        "title": "Adaptive Extra-Gradient Methods for Min-Max Optimization and Games",
        "html": "https://iclr.cc//virtual/2021/poster/2773",
        "abstract": "We present a new family of min-max optimization algorithms that automatically exploit the geometry of the gradient data observed at earlier iterations to perform more informative extra-gradient steps in later ones.\nThanks to this adaptation mechanism, the proposed method automatically detects whether the problem is smooth or not, without requiring any prior tuning by the optimizer.\nAs a result, the algorithm simultaneously achieves order-optimal convergence rates, \\ie it  converges to an $\\varepsilon$-optimal solution within $\\mathcal{O}(1/\\varepsilon)$ iterations in smooth problems, and within $\\mathcal{O}(1/\\varepsilon^2)$ iterations in non-smooth ones. Importantly, these guarantees do not require any of the standard boundedness or Lipschitz continuity conditions that are typically assumed in the literature; in particular, they apply even to problems with singularities (such as resource allocation problems and the like). This adaptation is achieved through the use of a geometric apparatus based on Finsler metrics and a suitably chosen mirror-prox template that allows us to derive sharp convergence rates for the methods at hand.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "用于Min-Max优化和博弈的自适应额外梯度方法",
        "摘要翻译": "我们提出了一种新的min-max优化算法族，该算法能够自动利用先前迭代中观察到的梯度数据的几何信息，以便在后续迭代中执行更具信息的额外梯度步骤。 借助这种自适应机制，所提出的方法可以自动检测问题是否平滑，而无需优化器进行任何预先调整。 因此，该算法同时实现了阶数最优的收敛速度，即在平滑问题中，它在O(1/ε)次迭代内收敛到ε-最优解，在非平滑问题中，它在O(1/ε^2)次迭代内收敛。重要的是，这些保证不需要文献中通常假设的任何标准有界性或Lipschitz连续性条件； 特别是，它们甚至适用于具有奇点的问题（例如资源分配问题等）。 这种自适应是通过使用基于Finsler度量的几何装置和适当选择的镜像近端模板来实现的，这使我们能够推导出手头方法的清晰收敛速度。",
        "领域": "对抗学习, 优化算法, 强化学习",
        "问题": "解决Min-Max优化问题中算法对问题平滑性的敏感性和收敛速度的限制，尤其是在具有奇点或不满足传统有界性/Lipschitz连续性条件的问题中。",
        "动机": "现有的Min-Max优化算法通常需要预先调整参数以适应问题的平滑性，并且在处理具有奇点或不满足标准假设的问题时，收敛速度会受到影响。因此，研究者希望设计一种自适应的算法，能够在不同平滑性的问题上实现最优的收敛速度，并适用于更广泛的问题类型。",
        "方法": "提出了一种基于Finsler度量的几何框架和镜像近端模板的自适应额外梯度算法。该方法通过利用梯度数据的几何信息自动检测问题的平滑性，并在后续迭代中执行更具信息的额外梯度步骤，从而实现对不同平滑性问题的自适应优化。",
        "关键词": [
            "Min-Max优化",
            "额外梯度方法",
            "自适应算法",
            "Finsler度量",
            "镜像近端"
        ],
        "涉及的技术概念": {
            "Min-Max优化": "一种优化问题，目标是找到一个点，使得一个函数在该点对一个变量最大化，对另一个变量最小化。在对抗学习中常见。",
            "额外梯度方法": "一种优化算法，通过在当前梯度方向上迈出一步，然后再计算新的梯度，来提高收敛速度和稳定性。 本文的算法是额外梯度算法的改进和自适应。"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 16,
        "title": "Adaptive Federated Optimization",
        "html": "https://iclr.cc//virtual/2021/poster/2691",
        "abstract": "Federated learning is a distributed machine learning paradigm in which a large number of clients coordinate with a central server to learn a model without sharing their own training data. Standard federated optimization methods such as Federated Averaging (FedAvg) are often difficult to tune and exhibit unfavorable convergence behavior. In non-federated settings, adaptive optimization methods have had notable success in combating such issues. In this work, we propose federated versions of adaptive optimizers, including Adagrad, Adam, and  Yogi, and analyze their convergence in the presence of heterogeneous data for general non-convex settings. Our results highlight the interplay between client heterogeneity and communication efficiency. We also perform extensive experiments on these methods and show that the use of adaptive optimizers can significantly improve the performance of federated learning.",
        "conference": "ICLR",
        "中文标题": "自适应联邦优化",
        "摘要翻译": "联邦学习是一种分布式机器学习范式，其中大量客户端与中央服务器协调学习模型，而无需共享自己的训练数据。标准的联邦优化方法，如联邦平均（FedAvg），通常难以调整，并表现出不利的收敛行为。在非联邦设置中，自适应优化方法在解决此类问题方面取得了显著成功。在这项工作中，我们提出了包括Adagrad、Adam和Yogi在内的自适应优化器的联邦版本，并分析了它们在存在异构数据的一般非凸设置中的收敛性。我们的结果突出了客户端异构性与通信效率之间的相互作用。我们还对这些方法进行了广泛的实验，并表明使用自适应优化器可以显著提高联邦学习的性能。",
        "领域": "联邦学习、分布式机器学习、自适应优化",
        "问题": "解决联邦学习中标准优化方法难以调整和收敛行为不佳的问题",
        "动机": "探索自适应优化方法在联邦学习中的应用，以提高模型性能和收敛效率",
        "方法": "提出了联邦版本的自适应优化器（Adagrad、Adam、Yogi），并分析其在异构数据下的收敛性",
        "关键词": [
            "联邦学习",
            "自适应优化",
            "分布式机器学习",
            "收敛性分析",
            "异构数据"
        ],
        "涉及的技术概念": {
            "联邦学习": "一种分布式机器学习范式，允许多个客户端协作学习模型而不共享数据",
            "自适应优化器": "如Adagrad、Adam和Yogi，用于调整学习率以改善模型训练过程",
            "异构数据": "指不同客户端上的数据分布不同，影响联邦学习的模型性能和收敛行为"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 17,
        "title": "Adaptive Procedural Task Generation for Hard-Exploration Problems",
        "html": "https://iclr.cc//virtual/2021/poster/3094",
        "abstract": "We introduce Adaptive Procedural Task Generation (APT-Gen), an approach to progressively generate a sequence of tasks as curricula to facilitate reinforcement learning in hard-exploration problems. At the heart of our approach, a task generator learns to create tasks from a parameterized task space via a black-box procedural generation module. To enable curriculum learning in the absence of a direct indicator of learning progress, we propose to train the task generator by balancing the agent's performance in the generated tasks and the similarity to the target tasks. Through adversarial training, the task similarity is adaptively estimated by a task discriminator defined on the agent's experiences, allowing the generated tasks to approximate target tasks of unknown parameterization or outside of the predefined task space. Our experiments on the grid world and robotic manipulation task domains show that APT-Gen achieves substantially better performance than various existing baselines by generating suitable tasks of rich variations.",
        "conference": "ICLR",
        "中文标题": "自适应程序化任务生成用于难探索问题",
        "摘要翻译": "我们介绍了自适应程序化任务生成（APT-Gen），这是一种逐步生成一系列任务作为课程的方法，以促进在难探索问题中的强化学习。我们方法的核心是一个任务生成器，它通过一个黑盒程序化生成模块学习从参数化任务空间中创建任务。为了在缺乏学习进度直接指标的情况下实现课程学习，我们提出通过平衡智能体在生成任务中的表现和与目标任务的相似性来训练任务生成器。通过对抗训练，任务相似性由定义在智能体经验上的任务鉴别器自适应估计，允许生成的任务近似未知参数化或预定义任务空间之外的目标任务。我们在网格世界和机器人操作任务领域的实验表明，APT-Gen通过生成具有丰富变化的合适任务，实现了比各种现有基线显著更好的性能。",
        "领域": "强化学习、机器人操作、课程学习",
        "问题": "在缺乏直接学习进度指标的情况下，如何有效地生成适合当前学习阶段的任务序列以促进强化学习在难探索问题中的应用。",
        "动机": "为了解决在难探索问题中强化学习效率低下的问题，通过自适应生成任务序列来促进学习。",
        "方法": "提出APT-Gen方法，通过对抗训练平衡智能体表现和任务相似性，自适应生成任务序列。",
        "关键词": [
            "自适应任务生成",
            "强化学习",
            "课程学习",
            "对抗训练",
            "机器人操作"
        ],
        "涉及的技术概念": {
            "自适应程序化任务生成（APT-Gen）": "一种逐步生成任务序列的方法，用于促进强化学习在难探索问题中的应用。",
            "对抗训练": "用于自适应估计任务相似性，使生成的任务能更好地近似目标任务。",
            "任务鉴别器": "基于智能体的经验定义，用于评估生成任务与目标任务的相似性。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 18,
        "title": "Adaptive Universal Generalized PageRank Graph Neural Network",
        "html": "https://iclr.cc//virtual/2021/poster/2940",
        "abstract": "In many important graph data processing applications the acquired information includes both node features and observations of the graph topology. Graph neural networks (GNNs) are designed to exploit both sources of evidence but they do not optimally trade-off their utility and integrate them in a manner that is also universal. Here, universality refers to independence on homophily or heterophily graph assumptions. We address these issues by introducing a new Generalized PageRank (GPR) GNN architecture that adaptively learns the GPR weights so as to jointly optimize node feature and topological information extraction, regardless of the extent to which the node labels are homophilic or heterophilic. Learned GPR weights automatically adjust to the node label pattern, irrelevant on the type of initialization, and thereby guarantee excellent learning performance for label patterns that are usually hard to handle. Furthermore, they allow one to avoid feature over-smoothing, a process which renders feature information nondiscriminative, without requiring the network to be shallow. Our accompanying theoretical analysis of the GPR-GNN method is facilitated by novel synthetic benchmark datasets generated by the so-called contextual stochastic block model. We also compare the performance of our GNN architecture with that of several state-of-the-art GNNs on the problem of node-classification, using well-known benchmark homophilic and heterophilic datasets. The results demonstrate that GPR-GNN offers significant performance improvement compared to existing techniques on both synthetic and benchmark data.",
        "conference": "ICLR",
        "中文标题": "自适应通用广义PageRank图神经网络",
        "摘要翻译": "在许多重要的图数据处理应用中，获取的信息包括节点特征和图拓扑结构的观察。图神经网络（GNNs）旨在利用这两种证据来源，但它们并未最优地权衡其效用并以一种也是通用的方式整合它们。这里，通用性指的是不依赖于同质性或异质性图的假设。我们通过引入一种新的广义PageRank（GPR）GNN架构来解决这些问题，该架构自适应地学习GPR权重，以便联合优化节点特征和拓扑信息提取，无论节点标签是同质的还是异质的。学习到的GPR权重自动调整以适应节点标签模式，与初始化类型无关，从而保证对于通常难以处理的标签模式也有出色的学习性能。此外，它们允许避免特征过度平滑，这一过程会使特征信息变得无区别性，而不需要网络是浅层的。我们通过所谓的上下文随机块模型生成的新合成基准数据集，促进了GPR-GNN方法的理论分析。我们还在节点分类问题上，使用著名的同质性和异质性基准数据集，比较了我们的GNN架构与几种最先进的GNN的性能。结果表明，与现有技术相比，GPR-GNN在合成数据和基准数据上都提供了显著的性能改进。",
        "领域": "图神经网络、节点分类、图数据挖掘",
        "问题": "如何在图神经网络中更有效地整合节点特征和图拓扑信息，同时不依赖于图的同质性或异质性假设。",
        "动机": "现有的图神经网络未能最优地权衡和整合节点特征与图拓扑信息，且依赖于图的同质性或异质性假设，限制了其通用性和应用范围。",
        "方法": "提出了一种新的广义PageRank（GPR）GNN架构，通过自适应学习GPR权重来联合优化节点特征和拓扑信息提取，适用于任何节点标签模式。",
        "关键词": [
            "广义PageRank",
            "图神经网络",
            "自适应学习",
            "节点分类",
            "图数据挖掘"
        ],
        "涉及的技术概念": {
            "广义PageRank（GPR）": "用于在图神经网络中自适应地学习权重，以优化节点特征和拓扑信息的提取。",
            "同质性和异质性图": "指图中节点标签的模式，同质性图中相似节点倾向于连接，异质性图中不同节点倾向于连接。GPR-GNN不依赖于这些假设。",
            "特征过度平滑": "在图神经网络中，随着网络层数的增加，节点特征可能会变得过于相似，失去区分性。GPR-GNN通过自适应权重避免这一问题。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 19,
        "title": "AdaSpeech: Adaptive Text to Speech for Custom Voice",
        "html": "https://iclr.cc//virtual/2021/poster/3164",
        "abstract": "Custom voice, a specific text to speech (TTS) service in commercial speech platforms, aims to adapt a source TTS model to synthesize personal voice for a target speaker using few speech from her/him. Custom voice presents two unique challenges for TTS adaptation: 1) to support diverse customers, the adaptation model needs to handle diverse acoustic conditions which could be very different from source speech data, and 2) to support a large number of customers, the adaptation parameters need to be small enough for each target speaker to reduce memory usage while maintaining high voice quality. In this work, we propose AdaSpeech, an adaptive TTS system for high-quality and efficient customization of new voices. We design several techniques in AdaSpeech to address the two challenges in custom voice: 1) To handle different acoustic conditions, we model the acoustic information in both utterance and phoneme level. Specifically, we use one acoustic encoder to extract an utterance-level vector and another one to extract a sequence of phoneme-level vectors from the target speech during pre-training and fine-tuning; in inference, we extract the utterance-level vector from a reference speech and use an acoustic predictor to predict the phoneme-level vectors. 2) To better trade off the adaptation parameters and voice quality, we introduce conditional layer normalization in the mel-spectrogram decoder of AdaSpeech, and fine-tune this part in addition to speaker embedding for adaptation. We pre-train the source TTS model on LibriTTS datasets and fine-tune it on VCTK and LJSpeech datasets (with different acoustic conditions from LibriTTS) with few adaptation data, e.g., 20 sentences, about 1 minute speech. Experiment results show that AdaSpeech achieves much better adaptation quality than baseline methods, with only about 5K specific parameters for each speaker, which demonstrates its effectiveness for custom voice. The audio samples are available at https://speechresearch.github.io/adaspeech/.",
        "conference": "ICLR",
        "中文标题": "AdaSpeech：面向定制语音的自适应文本转语音技术",
        "摘要翻译": "定制语音作为商业语音平台中的一项特定文本转语音（TTS）服务，旨在通过少量目标说话者的语音数据，使源TTS模型适应以合成个人语音。定制语音为TTS适应提出了两个独特挑战：1）为了支持多样化的客户，适应模型需要处理与源语音数据可能非常不同的多样化声学条件；2）为了支持大量客户，适应参数需要足够小以减少每位目标说话者的内存使用，同时保持高语音质量。在本工作中，我们提出了AdaSpeech，一个用于高质量且高效定制新语音的自适应TTS系统。我们在AdaSpeech中设计了几种技术以应对定制语音中的这两个挑战：1）为了处理不同的声学条件，我们在话语和音素级别建模声学信息。具体来说，我们使用一个声学编码器在预训练和微调期间从目标语音中提取话语级向量，另一个编码器提取一系列音素级向量；在推理时，我们从参考语音中提取话语级向量，并使用声学预测器预测音素级向量。2）为了更好地权衡适应参数和语音质量，我们在AdaSpeech的梅尔频谱解码器中引入了条件层归一化，并在适应过程中除了说话者嵌入外还微调这一部分。我们在LibriTTS数据集上预训练源TTS模型，并在VCTK和LJSpeech数据集（与LibriTTS具有不同声学条件）上用少量适应数据（如20句话，约1分钟语音）进行微调。实验结果表明，AdaSpeech在适应质量上显著优于基线方法，每位说话者仅需约5K特定参数，这证明了其在定制语音中的有效性。音频样本可在https://speechresearch.github.io/adaspeech/获取。",
        "领域": "语音合成、自适应学习、声学建模",
        "问题": "如何在少量目标说话者语音数据的情况下，高效且高质量地定制个性化语音",
        "动机": "解决定制语音服务中面临的多样化声学条件处理和适应参数优化问题",
        "方法": "设计AdaSpeech系统，通过话语和音素级别的声学信息建模及条件层归一化技术，实现高效且高质量的语音定制",
        "关键词": [
            "定制语音",
            "自适应TTS",
            "声学建模",
            "条件层归一化",
            "高效适应"
        ],
        "涉及的技术概念": {
            "声学编码器": "用于从目标语音中提取话语级和音素级声学信息的关键组件",
            "条件层归一化": "在梅尔频谱解码器中引入，以优化适应参数和语音质量之间的权衡",
            "声学预测器": "在推理阶段预测音素级声学向量，以处理不同的声学条件"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 20,
        "title": "A Design Space Study for LISTA and Beyond",
        "html": "https://iclr.cc//virtual/2021/poster/2808",
        "abstract": "In recent years, great success has been witnessed in building problem-specific deep networks from unrolling iterative algorithms, for solving inverse problems and beyond. Unrolling is believed to incorporate the model-based prior with the learning capacity of deep learning. This paper revisits \\textit{the role of unrolling as a design approach for deep networks}: to what extent its resulting special architecture is superior, and can we find better? Using LISTA for sparse recovery as a representative example, we conduct the first thorough \\textit{design space study} for the unrolled models.  Among all possible variations, we focus on extensively varying the connectivity patterns and neuron types, leading to a gigantic design space arising from LISTA. To efficiently explore this space and identify top performers, we leverage the emerging tool of neural architecture search (NAS). We carefully examine the searched top architectures in a number of settings, and are able to discover networks that consistently better than LISTA. We further present more visualization and analysis to ``open the black box', and find that the searched top architectures demonstrate highly consistent and potentially transferable patterns. We hope our study to spark more reflections and explorations on how to better mingle model-based optimization prior and data-driven learning.",
        "conference": "ICLR",
        "中文标题": "LISTA及其超越的设计空间研究",
        "摘要翻译": "近年来，在通过展开迭代算法构建针对特定问题的深度网络方面取得了巨大成功，用于解决逆问题及其他问题。展开被认为将基于模型的先验与深度学习的学习能力结合起来。本文重新审视了展开作为深度网络设计方法的作用：其产生的特殊架构在多大程度上更优越，以及我们是否能找到更好的方法？以LISTA用于稀疏恢复为代表例子，我们对展开模型进行了首次彻底的设计空间研究。在所有可能的变体中，我们专注于广泛变化连接模式和神经元类型，从而产生了一个由LISTA引发的巨大设计空间。为了有效探索这一空间并识别顶级表现者，我们利用了神经架构搜索（NAS）这一新兴工具。我们在多种设置下仔细检查了搜索到的顶级架构，并能够发现始终优于LISTA的网络。我们进一步提供了更多的可视化和分析来“打开黑匣子”，并发现搜索到的顶级架构展示了高度一致且可能可转移的模式。我们希望我们的研究能够激发更多关于如何更好地结合基于模型的优化先验和数据驱动学习的反思和探索。",
        "领域": "稀疏恢复、神经架构搜索、深度学习优化",
        "问题": "探索展开迭代算法作为深度网络设计方法的有效性及其设计空间的优化潜力",
        "动机": "研究展开方法在深度网络设计中的优势，探索是否能通过设计空间研究找到更优的网络架构",
        "方法": "通过神经架构搜索（NAS）工具，在LISTA的基础上广泛变化连接模式和神经元类型，探索和识别顶级网络架构",
        "关键词": [
            "LISTA",
            "神经架构搜索",
            "稀疏恢复",
            "深度学习",
            "设计空间研究"
        ],
        "涉及的技术概念": {
            "展开迭代算法": "将迭代算法展开为深度网络结构，结合模型先验和学习能力",
            "神经架构搜索（NAS）": "用于自动探索和优化网络架构的工具，帮助识别顶级表现者",
            "稀疏恢复": "通过算法从少量观测中恢复原始信号的技术，LISTA是其中的代表方法"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 21,
        "title": "A Diffusion Theory For Deep Learning Dynamics: Stochastic Gradient Descent Exponentially Favors Flat Minima",
        "html": "https://iclr.cc//virtual/2021/poster/2620",
        "abstract": "Stochastic Gradient Descent (SGD) and its variants are mainstream methods for training deep networks in practice. SGD is known to find a flat minimum that often generalizes well. However, it is mathematically unclear how deep learning can select a flat minimum among so many minima. To answer the question quantitatively, we develop a density diffusion theory to reveal how minima selection quantitatively depends on the minima sharpness and the hyperparameters. To the best of our knowledge, we are the first to theoretically and empirically prove that, benefited from the Hessian-dependent covariance of stochastic gradient noise, SGD favors flat minima exponentially more than sharp minima, while Gradient Descent (GD) with injected white noise favors flat minima only polynomially more than sharp minima. We also reveal that either a small learning rate or large-batch training requires exponentially many iterations to escape from minima in terms of the ratio of the batch size and learning rate. Thus, large-batch training cannot search flat minima efficiently in a realistic computational time.",
        "conference": "ICLR",
        "中文标题": "深度学习动力学的扩散理论：随机梯度下降指数级偏好平坦最小值",
        "摘要翻译": "随机梯度下降（SGD）及其变体在实践中是训练深度网络的主流方法。已知SGD能够找到一个通常泛化能力良好的平坦最小值。然而，数学上尚不清楚深度学习如何在众多最小值中选择一个平坦最小值。为了定量回答这个问题，我们开发了一个密度扩散理论，以揭示最小值的选择如何定量依赖于最小值的锐度和超参数。据我们所知，我们是第一个从理论上和经验上证明，得益于随机梯度噪声的Hessian依赖协方差，SGD指数级地偏好平坦最小值而非锐利最小值，而注入白噪声的梯度下降（GD）仅多项式级地偏好平坦最小值。我们还揭示，无论是小学习率还是大批量训练，都需要在批量大小和学习率的比例方面指数级多的迭代次数才能逃离最小值。因此，大批量训练在现实的计算时间内无法高效搜索平坦最小值。",
        "领域": "优化算法、深度学习理论、泛化能力研究",
        "问题": "深度学习如何在众多最小值中选择一个平坦最小值",
        "动机": "揭示SGD为何以及如何偏好平坦最小值，从而解释其良好的泛化能力",
        "方法": "开发密度扩散理论，分析最小值选择与最小值锐度及超参数的定量关系",
        "关键词": [
            "随机梯度下降",
            "平坦最小值",
            "密度扩散理论",
            "泛化能力",
            "深度学习优化"
        ],
        "涉及的技术概念": {
            "随机梯度下降（SGD）": "用于训练深度网络的主流优化方法，通过随机采样数据点计算梯度",
            "平坦最小值": "指损失函数中梯度变化平缓的区域，通常与良好的泛化能力相关",
            "密度扩散理论": "用于定量分析SGD如何在不同最小值之间进行选择的理论框架"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 22,
        "title": "A Discriminative Gaussian Mixture Model with Sparsity",
        "html": "https://iclr.cc//virtual/2021/poster/3362",
        "abstract": "In probabilistic classification, a discriminative model based on the softmax function has a potential limitation in that it assumes unimodality for each class in the feature space. The mixture model can address this issue, although it leads to an increase in the number of parameters. We propose a sparse classifier based on a discriminative GMM, referred to as a sparse discriminative Gaussian mixture (SDGM). In the SDGM, a GMM-based discriminative model is trained via sparse Bayesian learning. Using this sparse learning framework, we can simultaneously remove redundant Gaussian components and reduce the number of parameters used in the remaining components during learning; this learning method reduces the model complexity, thereby improving the generalization capability. Furthermore, the SDGM can be embedded into neural networks (NNs), such as convolutional NNs, and can be trained in an end-to-end manner. Experimental results demonstrated that the proposed method outperformed the existing softmax-based discriminative models.",
        "conference": "ICLR",
        "中文标题": "一种具有稀疏性的判别性高斯混合模型",
        "摘要翻译": "在概率分类中，基于softmax函数的判别模型存在一个潜在限制，即它假设特征空间中每个类别的单峰性。混合模型可以解决这一问题，尽管这会导致参数数量的增加。我们提出了一种基于判别性高斯混合模型（GMM）的稀疏分类器，称为稀疏判别性高斯混合（SDGM）。在SDGM中，基于GMM的判别模型通过稀疏贝叶斯学习进行训练。利用这一稀疏学习框架，我们可以在学习过程中同时去除冗余的高斯分量并减少剩余分量中使用的参数数量；这种学习方法降低了模型的复杂性，从而提高了泛化能力。此外，SDGM可以嵌入到神经网络（NNs）中，如卷积NNs，并且可以以端到端的方式进行训练。实验结果表明，所提出的方法优于现有的基于softmax的判别模型。",
        "领域": "概率分类、稀疏学习、神经网络嵌入",
        "问题": "解决基于softmax的判别模型在特征空间中假设每个类别单峰性的限制，以及混合模型参数增加的问题",
        "动机": "提高概率分类模型的泛化能力，同时减少模型复杂度",
        "方法": "提出一种基于判别性高斯混合模型的稀疏分类器（SDGM），通过稀疏贝叶斯学习训练，去除冗余高斯分量并减少参数数量，可嵌入神经网络中以端到端方式训练",
        "关键词": [
            "稀疏判别性高斯混合",
            "稀疏贝叶斯学习",
            "概率分类",
            "神经网络嵌入",
            "模型简化"
        ],
        "涉及的技术概念": {
            "稀疏判别性高斯混合（SDGM）": "一种基于判别性高斯混合模型的稀疏分类器，通过稀疏学习减少模型复杂度和提高泛化能力",
            "稀疏贝叶斯学习": "用于训练SDGM的学习框架，能够去除冗余分量并减少参数数量",
            "端到端训练": "SDGM可以嵌入到神经网络中，如卷积神经网络，实现从输入到输出的完整训练流程"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 23,
        "title": "A Distributional Approach to Controlled Text Generation",
        "html": "https://iclr.cc//virtual/2021/poster/2796",
        "abstract": "We propose a  Distributional  Approach for addressing  Controlled  Text  Generation from pre-trained Language Models (LM). This approach permits to specify, in a single formal framework, both “pointwise’” and “distributional” constraints over the target LM — to our knowledge, the first model with such generality —while minimizing KL divergence from the initial LM distribution.  The optimal target distribution is then uniquely determined as an explicit EBM (Energy-BasedModel) representation. From that optimal representation, we then train a target controlled Autoregressive LM through an adaptive distributional variant of PolicyGradient.  We conduct a first set of experiments over pointwise constraints showing the advantages of our approach over a set of baselines, in terms of obtaining a controlled LM balancing constraint satisfaction with divergence from the pretrained LM.  We then perform experiments over distributional constraints, a unique feature of our approach, demonstrating its potential as a remedy to the problem of Bias in Language Models.  Through an ablation study, we show the effectiveness of our adaptive technique for obtaining faster convergence.\nCode available at https://github.com/naver/gdc",
        "conference": "ICLR",
        "中文标题": "一种面向受控文本生成的分布方法",
        "摘要翻译": "我们提出了一种分布方法，用于解决基于预训练语言模型（LM）的受控文本生成问题。该方法允许在单一的形式框架内指定对目标语言模型的‘点式’和‘分布’约束——据我们所知，这是第一个具有如此通用性的模型——同时最小化与初始语言模型分布的KL散度。最优目标分布随后被唯一地确定为一个明确的基于能量的模型（EBM）表示。从这一最优表示出发，我们通过策略梯度的自适应分布变体训练了一个目标受控自回归语言模型。我们进行了第一组针对点式约束的实验，展示了我们的方法在一系列基线之上的优势，即在获得一个受控语言模型的同时平衡约束满足与预训练语言模型的散度。随后，我们进行了针对分布约束的实验，这是我们方法的一个独特特点，展示了其作为解决语言模型中偏见问题潜在补救措施的潜力。通过消融研究，我们展示了我们自适应技术在获得更快收敛方面的有效性。代码可在https://github.com/naver/gdc获取。",
        "领域": "自然语言处理与视觉结合、文本生成、语言模型优化",
        "问题": "如何在预训练语言模型中实现受控文本生成，同时满足点式和分布约束，并最小化与初始模型分布的差异。",
        "动机": "为了解决预训练语言模型在生成文本时难以精确控制输出内容和分布的问题，以及减少模型偏见。",
        "方法": "提出一种分布方法，通过单一形式框架指定约束，最小化KL散度，利用基于能量的模型表示最优分布，并通过自适应策略梯度训练受控自回归语言模型。",
        "关键词": [
            "受控文本生成",
            "分布约束",
            "KL散度",
            "基于能量的模型",
            "策略梯度"
        ],
        "涉及的技术概念": {
            "KL散度": "用于衡量初始语言模型分布与目标分布之间的差异，最小化KL散度以保持生成文本的多样性和质量。",
            "基于能量的模型（EBM）": "用于表示最优目标分布，提供了一种灵活的方式来整合点式和分布约束。",
            "策略梯度": "一种强化学习方法，用于训练受控自回归语言模型，通过自适应分布变体优化模型以满足约束条件。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 24,
        "title": "Adversarially Guided Actor-Critic",
        "html": "https://iclr.cc//virtual/2021/poster/2640",
        "abstract": "Despite definite success in deep reinforcement learning problems, actor-critic algorithms are still confronted with sample inefficiency in complex environments, particularly in tasks where efficient exploration is a bottleneck. These methods consider a policy (the actor) and a value function (the critic) whose respective losses are built using different motivations and approaches. This paper introduces a third protagonist: the adversary. While the adversary mimics the actor by minimizing the KL-divergence between their respective action distributions, the actor, in addition to learning to solve the task, tries to differentiate itself from the adversary predictions. This novel objective stimulates the actor to follow strategies that could not have been correctly predicted from previous trajectories, making its behavior innovative in tasks where the reward is extremely rare. Our experimental analysis shows that the resulting Adversarially Guided Actor-Critic (AGAC) algorithm leads to more exhaustive exploration. Notably, AGAC outperforms current state-of-the-art methods on a set of various hard-exploration and procedurally-generated tasks.",
        "conference": "ICLR",
        "中文标题": "对抗性引导的演员-评论家算法",
        "摘要翻译": "尽管在深度强化学习问题中取得了一定的成功，演员-评论家算法在复杂环境中仍然面临样本效率低下的问题，特别是在那些高效探索成为瓶颈的任务中。这些方法考虑了一个策略（演员）和一个价值函数（评论家），它们各自的损失函数基于不同的动机和方法构建。本文引入了第三个主角：对抗者。对抗者通过最小化其各自动作分布之间的KL散度来模仿演员，而演员除了学习解决任务外，还试图使自己与对抗者的预测区分开来。这一新颖的目标激励演员遵循那些无法从先前轨迹中正确预测的策略，使其在奖励极为稀少的任务中表现出创新行为。我们的实验分析表明，由此产生的对抗性引导的演员-评论家（AGAC）算法导致了更彻底的探索。值得注意的是，AGAC在一系列各种难以探索和程序生成的任务上优于当前最先进的方法。",
        "领域": "深度强化学习、探索策略优化、程序生成任务",
        "问题": "解决演员-评论家算法在复杂环境中样本效率低下和探索不足的问题",
        "动机": "通过引入对抗者来激励演员采取无法从历史数据中预测的新策略，以提高在奖励稀少环境中的探索效率",
        "方法": "在传统的演员-评论家框架中引入对抗者，通过最小化KL散度模仿演员，同时演员学习区分对抗者的预测，以促进创新行为",
        "关键词": [
            "对抗性学习",
            "演员-评论家算法",
            "探索策略",
            "KL散度",
            "程序生成任务"
        ],
        "涉及的技术概念": {
            "KL散度": "用于衡量对抗者与演员动作分布之间的差异，促使演员采取新颖策略",
            "演员-评论家算法": "结合策略梯度方法和价值函数学习的强化学习框架，用于同时优化策略和评估状态价值",
            "对抗性学习": "通过引入对抗者来挑战演员，促使其探索未被充分探索的策略空间"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 25,
        "title": "Adversarially-Trained Deep Nets Transfer Better: Illustration on Image Classification",
        "html": "https://iclr.cc//virtual/2021/poster/2975",
        "abstract": "Transfer learning has emerged as a powerful methodology for adapting pre-trained deep neural networks on image recognition tasks to new domains. This process consists of taking a neural network pre-trained on a large feature-rich source dataset, freezing the early layers that encode essential generic image properties, and then fine-tuning the last few layers in order to capture specific information related to the target situation. This approach is particularly useful when only limited or weakly labeled data are available for the new task. In this work, we demonstrate that adversarially-trained models transfer better than non-adversarially-trained models, especially if only limited data are available for the new domain task. Further, we observe that adversarial training biases the learnt representations to retaining shapes, as opposed to textures, which impacts the transferability of the source models. Finally, through the lens of influence functions, we discover that transferred adversarially-trained models contain more human-identifiable semantic information, which explains -- at least partly -- why adversarially-trained models transfer better.",
        "conference": "ICLR",
        "中文标题": "对抗训练深度网络迁移效果更佳：以图像分类为例",
        "摘要翻译": "迁移学习已成为一种强大的方法，用于将预训练的深度神经网络适应于新的图像识别任务。这一过程包括采用在大型特征丰富的源数据集上预训练的神经网络，冻结编码基本通用图像属性的早期层，然后微调最后几层以捕获与目标情况相关的特定信息。这种方法在只有有限或弱标记数据可用于新任务时特别有用。在这项工作中，我们证明了对抗训练的模型比非对抗训练的模型迁移效果更好，尤其是在新领域任务只有有限数据可用时。此外，我们观察到对抗训练使学习到的表示偏向于保留形状而非纹理，这影响了源模型的可迁移性。最后，通过影响函数的视角，我们发现迁移的对抗训练模型包含更多人类可识别的语义信息，这至少部分解释了为什么对抗训练的模型迁移效果更好。",
        "领域": "图像分类、迁移学习、对抗训练",
        "问题": "如何提高深度神经网络在新领域任务中的迁移效果",
        "动机": "探索对抗训练对深度神经网络迁移学习效果的影响，特别是在数据有限的情况下",
        "方法": "采用对抗训练的深度神经网络，并通过影响函数分析模型中的语义信息",
        "关键词": [
            "对抗训练",
            "迁移学习",
            "图像分类",
            "影响函数",
            "语义信息"
        ],
        "涉及的技术概念": {
            "对抗训练": "一种训练深度神经网络的方法，通过在训练过程中引入对抗样本来提高模型的鲁棒性和泛化能力",
            "迁移学习": "将在一个任务上学到的知识应用到另一个相关任务上的机器学习方法",
            "影响函数": "用于分析模型预测对训练数据点敏感度的工具，帮助理解模型行为和决策过程"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 26,
        "title": "Adversarial score matching and improved sampling for image generation",
        "html": "https://iclr.cc//virtual/2021/poster/3155",
        "abstract": "Denoising Score Matching with Annealed Langevin Sampling (DSM-ALS) has recently found success in generative modeling. The approach works by first training a neural network to estimate the score of a distribution, and then using Langevin dynamics to sample from the data distribution assumed by the score network. Despite the convincing visual quality of samples, this method appears to perform worse than Generative Adversarial Networks (GANs) under the Fréchet Inception Distance, a standard metric for generative models. We show that this apparent gap vanishes when denoising the final Langevin samples using the score network.\nIn addition, we propose two improvements to DSM-ALS:  1) Consistent Annealed Sampling as a more stable alternative to Annealed Langevin Sampling, and 2) a hybrid training formulation, composed of both Denoising Score Matching and adversarial objectives. By combining these two techniques and exploring different network architectures, we elevate score matching methods and obtain results competitive with state-of-the-art image generation on CIFAR-10.",
        "conference": "ICLR",
        "中文标题": "对抗性分数匹配与改进的图像生成采样方法",
        "摘要翻译": "退火朗之万采样下的去噪分数匹配（DSM-ALS）最近在生成建模中取得了成功。该方法首先训练一个神经网络来估计分布的分数，然后使用朗之万动力学从分数网络假定的数据分布中采样。尽管样本的视觉质量令人信服，但这种方法在Fréchet Inception Distance（生成模型的标准度量）下似乎比生成对抗网络（GANs）表现更差。我们表明，当使用分数网络对最终的朗之万样本进行去噪时，这种明显的差距消失了。此外，我们提出了对DSM-ALS的两项改进：1）一致退火采样作为退火朗之万采样的更稳定替代方案，以及2）一种混合训练公式，由去噪分数匹配和对抗性目标组成。通过结合这两种技术并探索不同的网络架构，我们提升了分数匹配方法，并在CIFAR-10上获得了与最先进图像生成竞争的结果。",
        "领域": "图像生成、生成对抗网络、分数匹配",
        "问题": "提高基于分数匹配的图像生成方法在标准度量下的表现，使其与生成对抗网络竞争",
        "动机": "尽管DSM-ALS在生成图像的视觉质量上表现良好，但在Fréchet Inception Distance等标准度量下不如GANs，研究旨在缩小这一差距",
        "方法": "提出一致退火采样和混合训练公式（结合去噪分数匹配和对抗性目标），并探索不同网络架构",
        "关键词": [
            "分数匹配",
            "朗之万采样",
            "图像生成",
            "对抗性训练",
            "CIFAR-10"
        ],
        "涉及的技术概念": {
            "分数匹配": "用于估计数据分布的梯度，是生成模型中的关键技术",
            "朗之万动力学": "一种采样方法，用于从估计的分布中生成样本",
            "对抗性训练": "通过引入对抗性目标，提高生成模型的表现和稳定性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 27,
        "title": "A Geometric Analysis of Deep Generative Image Models and Its Applications",
        "html": "https://iclr.cc//virtual/2021/poster/3366",
        "abstract": "Generative adversarial networks (GANs) have emerged as a powerful unsupervised method to model the statistical patterns of real-world data sets, such as natural images. These networks are trained to map random inputs in their latent space to new samples representative of the learned data. However, the structure of the latent space is hard to intuit due to its high dimensionality and the non-linearity of the generator, which limits the usefulness of the models. Understanding the latent space requires a way to identify input codes for existing real-world images (inversion), and a way to identify directions with known image transformations (interpretability). Here, we use a geometric framework to address both issues simultaneously. We develop an architecture-agnostic method to compute the Riemannian metric of the image manifold created by GANs. The eigen-decomposition of the metric isolates axes that account for different levels of image variability. An empirical analysis of several pretrained GANs shows that image variation around each position is concentrated along surprisingly few major axes (the space is highly anisotropic) and the directions that create this large variation are similar at different positions in the space (the space is homogeneous). We show that many of the top eigenvectors correspond to interpretable transforms in the image space, with a substantial part of eigenspace corresponding to minor transforms which could be compressed out. This geometric understanding unifies key previous results related to GAN interpretability. We show that the use of this metric allows for more efficient optimization in the latent space (e.g. GAN inversion) and facilitates unsupervised discovery of interpretable axes. Our results illustrate that defining the geometry of the GAN image manifold can serve as a general framework for understanding GANs. ",
        "conference": "ICLR",
        "中文标题": "深度生成图像模型的几何分析及其应用",
        "摘要翻译": "生成对抗网络（GANs）已成为一种强大的无监督方法，用于建模真实世界数据集（如自然图像）的统计模式。这些网络被训练来将其潜在空间中的随机输入映射到代表学习数据的新样本。然而，由于潜在空间的高维性和生成器的非线性，其结构难以直观理解，这限制了模型的实用性。理解潜在空间需要一种方法来识别现有真实世界图像的输入代码（反转），以及一种方法来识别具有已知图像变换的方向（可解释性）。在这里，我们使用几何框架同时解决这两个问题。我们开发了一种与架构无关的方法来计算由GANs创建的图像流形的黎曼度量。度量的特征分解隔离了考虑不同级别图像变异性的轴。对几个预训练GANs的实证分析表明，每个位置周围的图像变异集中在令人惊讶的少数主要轴上（空间是高度各向异性的），并且产生这种大变异的方向在空间的不同位置是相似的（空间是均匀的）。我们展示了许多顶级特征向量对应于图像空间中的可解释变换，特征空间的很大一部分对应于可以压缩掉的次要变换。这种几何理解统一了与GAN可解释性相关的关键先前结果。我们展示了使用这种度量允许在潜在空间中进行更有效的优化（例如GAN反转），并促进了可解释轴的无监督发现。我们的结果表明，定义GAN图像流形的几何可以作为理解GANs的一般框架。",
        "领域": "生成对抗网络、图像生成、计算机视觉",
        "问题": "理解生成对抗网络（GANs）潜在空间的结构及其在图像生成中的应用",
        "动机": "由于GANs潜在空间的高维性和非线性，其结构难以直观理解，限制了模型的实用性和可解释性。",
        "方法": "采用几何框架和黎曼度量计算方法，分析GANs创建的图像流形，通过特征分解识别可解释的图像变换方向。",
        "关键词": [
            "生成对抗网络",
            "几何分析",
            "黎曼度量",
            "潜在空间",
            "图像流形"
        ],
        "涉及的技术概念": {
            "生成对抗网络（GANs）": "用于建模真实世界数据集的统计模式，通过潜在空间生成新样本。",
            "黎曼度量": "用于计算图像流形的几何特性，帮助理解GANs潜在空间的结构。",
            "特征分解": "通过分解黎曼度量，识别图像流形中的主要变异方向，提高GANs的可解释性。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 28,
        "title": "A Good Image Generator Is What You Need for High-Resolution Video Synthesis",
        "html": "https://iclr.cc//virtual/2021/poster/2810",
        "abstract": "Image and video synthesis are closely related areas aiming at generating content from noise. While rapid progress has been demonstrated in improving image-based models to handle large resolutions, high-quality renderings, and wide variations in image content, achieving comparable video generation results remains problematic. We present a framework that leverages contemporary image generators to render high-resolution videos. We frame the video synthesis problem as discovering a trajectory in the latent space of a pre-trained and fixed image generator. Not only does such a framework render high-resolution videos, but it also is an order of magnitude more computationally efficient. We introduce a motion generator that discovers the desired trajectory, in which content and motion are disentangled. With such a representation, our framework allows for a broad range of applications, including content and motion manipulation. Furthermore, we introduce a new task, which we call cross-domain video synthesis, in which the image and motion generators are trained on disjoint datasets belonging to different domains. This allows for generating moving objects for which the desired video data is not available. Extensive experiments on various datasets demonstrate the advantages of our methods over existing video generation techniques. Code will be released at https://github.com/snap-research/MoCoGAN-HD.",
        "conference": "ICLR",
        "中文标题": "高质量视频合成所需的是一个好的图像生成器",
        "摘要翻译": "图像和视频合成是紧密相关的领域，旨在从噪声中生成内容。虽然在改进基于图像的模型以处理大分辨率、高质量渲染和图像内容的广泛变化方面已经展示了快速的进展，但实现可比的视频生成结果仍然存在问题。我们提出了一个框架，利用当代图像生成器来渲染高分辨率视频。我们将视频合成问题定义为在预训练且固定的图像生成器的潜在空间中发现轨迹。这样的框架不仅能够渲染高分辨率视频，而且在计算效率上高出一个数量级。我们引入了一个运动生成器，用于发现期望的轨迹，其中内容和运动是解耦的。有了这样的表示，我们的框架允许广泛的应用，包括内容和运动操作。此外，我们引入了一个新任务，称为跨域视频合成，其中图像和运动生成器在不同域的不相交数据集上进行训练。这允许生成所需视频数据不可用的移动对象。在各种数据集上的大量实验证明了我们的方法相对于现有视频生成技术的优势。代码将在https://github.com/snap-research/MoCoGAN-HD发布。",
        "领域": "视频生成、图像合成、跨域学习",
        "问题": "如何利用现有的高质量图像生成器来实现高分辨率视频的合成",
        "动机": "解决现有视频生成技术在分辨率、质量和计算效率上的不足",
        "方法": "利用预训练的图像生成器的潜在空间轨迹来合成视频，引入运动生成器解耦内容和运动",
        "关键词": [
            "高分辨率视频合成",
            "潜在空间轨迹",
            "运动生成器",
            "跨域视频合成",
            "计算效率"
        ],
        "涉及的技术概念": {
            "潜在空间轨迹": "在预训练图像生成器的潜在空间中定义的轨迹，用于指导视频的生成",
            "运动生成器": "用于发现和解码潜在空间中的运动信息，实现视频中内容和运动的解耦",
            "跨域视频合成": "在不同域的数据集上训练图像和运动生成器，以生成缺乏视频数据的移动对象"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 29,
        "title": "A Gradient Flow Framework For Analyzing Network Pruning",
        "html": "https://iclr.cc//virtual/2021/poster/3215",
        "abstract": "Recent network pruning methods focus on pruning models early-on in training. To estimate the impact of removing a parameter, these methods use importance measures that were originally designed to prune trained models. Despite lacking justification for their use early-on in training, such measures result in surprisingly low accuracy loss. To better explain this behavior, we develop a general framework that uses gradient flow to unify state-of-the-art importance measures through the norm of model parameters. We use this framework to determine the relationship between pruning measures and evolution of model parameters, establishing several results related to pruning models early-on in training: (i) magnitude-based pruning removes parameters that contribute least to reduction in loss, resulting in models that converge faster than magnitude-agnostic methods; (ii) loss-preservation based pruning preserves first-order model evolution dynamics and its use is therefore justified for pruning minimally trained models; and (iii) gradient-norm based pruning affects second-order model evolution dynamics, such that increasing gradient norm via pruning can produce poorly performing models. We validate our claims on several VGG-13, MobileNet-V1, and ResNet-56 models trained on CIFAR-10/CIFAR-100.",
        "conference": "ICLR",
        "中文标题": "用于分析网络剪枝的梯度流框架",
        "摘要翻译": "近期的网络剪枝方法主要关注于训练初期的模型剪枝。为了评估移除参数的影响，这些方法采用了原本设计用于剪枝已训练模型的重要性度量。尽管这些度量在训练初期的使用缺乏合理性，但它们却意外地导致了较低的准确率损失。为了更好地解释这一现象，我们开发了一个通用框架，该框架利用梯度流通过模型参数的范数统一了最先进的重要性度量。我们使用这一框架来确定剪枝度量与模型参数演化之间的关系，并建立了几个与训练初期模型剪枝相关的结果：(i) 基于幅度的剪枝移除了对损失减少贡献最小的参数，使得模型比不区分幅度的方法收敛得更快；(ii) 基于损失保留的剪枝保留了模型的一阶演化动态，因此其用于剪枝最小训练模型是合理的；(iii) 基于梯度范数的剪枝影响了模型的二阶演化动态，因此通过剪枝增加梯度范数可能导致模型性能不佳。我们在CIFAR-10/CIFAR-100上训练的多个VGG-13、MobileNet-V1和ResNet-56模型上验证了我们的主张。",
        "领域": "模型压缩",
        "问题": "如何解释和优化训练初期网络剪枝方法的有效性",
        "动机": "探索和解释训练初期网络剪枝方法有效性的理论基础",
        "方法": "开发了一个基于梯度流的通用框架，用于分析和统一不同的剪枝重要性度量",
        "关键词": [
            "网络剪枝",
            "梯度流",
            "模型压缩"
        ],
        "涉及的技术概念": {
            "梯度流": "用于分析和统一不同剪枝重要性度量的数学框架",
            "模型参数范数": "在剪枝过程中评估参数重要性的关键指标",
            "损失保留": "一种剪枝策略，旨在保持模型的一阶演化动态，适用于训练初期的剪枝"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 30,
        "title": "A Hypergradient Approach to Robust Regression without Correspondence",
        "html": "https://iclr.cc//virtual/2021/poster/3186",
        "abstract": "We consider a regression problem, where the correspondence between the input and output data is not available. Such shuffled data are commonly observed in many real world problems. Take flow cytometry as an example: the measuring instruments are unable to preserve the correspondence between the samples and the measurements. Due to the combinatorial nature of the problem, most of the existing methods are only applicable when the sample size is small, and are limited to linear regression models. To overcome such bottlenecks, we propose a new computational framework --- ROBOT --- for the shuffled regression problem, which is applicable to large data and complex models. Specifically, we propose to formulate regression without correspondence as a continuous optimization problem. Then by exploiting the interaction between the regression model and the data correspondence, we propose to develop a hypergradient approach based on differentiable programming techniques. Such a hypergradient approach essentially views the data correspondence as an operator of the regression model, and therefore it allows us to find a better descent direction for the model parameters by differentiating through the data correspondence. ROBOT is quite general, and can be further extended to an inexact correspondence setting, where the input and output data are not necessarily exactly aligned. Thorough numerical experiments show that ROBOT achieves better performance than existing methods in both linear and nonlinear regression tasks, including real-world applications such as flow cytometry and multi-object tracking.  ",
        "conference": "ICLR",
        "中文标题": "一种无需对应关系的鲁棒回归的超梯度方法",
        "摘要翻译": "我们考虑一个回归问题，其中输入和输出数据之间的对应关系不可用。这种打乱的数据在许多现实世界问题中常见。以流式细胞术为例：测量仪器无法保留样本与测量之间的对应关系。由于问题的组合性质，大多数现有方法仅适用于样本量小的情况，并且仅限于线性回归模型。为了克服这些瓶颈，我们提出了一个新的计算框架——ROBOT——用于打乱回归问题，该框架适用于大数据和复杂模型。具体来说，我们提出将无对应回归表述为一个连续优化问题。然后，通过利用回归模型与数据对应之间的相互作用，我们提出基于可微分编程技术开发一种超梯度方法。这种超梯度方法本质上将数据对应视为回归模型的一个操作符，因此它允许我们通过区分数据对应来为模型参数找到更好的下降方向。ROBOT非常通用，可以进一步扩展到不精确对应设置，其中输入和输出数据不一定完全对齐。彻底的数值实验表明，ROBOT在线性和非线性回归任务中，包括流式细胞术和多目标跟踪等实际应用中，比现有方法实现了更好的性能。",
        "领域": "回归分析",
        "问题": "解决在输入和输出数据对应关系不可用情况下的回归问题",
        "动机": "针对现有方法仅适用于小样本量和线性模型的限制，提出适用于大数据和复杂模型的解决方案",
        "方法": "提出ROBOT框架，将无对应回归问题表述为连续优化问题，并开发基于可微分编程技术的超梯度方法",
        "关键词": [
            "鲁棒回归",
            "超梯度方法",
            "可微分编程",
            "流式细胞术",
            "多目标跟踪"
        ],
        "涉及的技术概念": {
            "超梯度方法": "通过区分数据对应来优化模型参数的技术",
            "可微分编程": "支持自动微分和梯度下降优化的编程范式",
            "不精确对应设置": "处理输入和输出数据不完全对齐的情况"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 31,
        "title": "A Learning Theoretic Perspective on Local Explainability",
        "html": "https://iclr.cc//virtual/2021/poster/2706",
        "abstract": "In this paper, we explore connections between interpretable machine learning and learning theory through the lens of local approximation explanations. First, we tackle the traditional problem of performance generalization and bound the test-time predictive accuracy of a model using a notion of how locally explainable it is.  Second, we explore the novel problem of explanation generalization which is an important concern for a growing class of finite sample-based local approximation explanations. Finally, we validate our theoretical results empirically and show that they reflect what can be seen in practice.",
        "conference": "ICLR",
        "中文标题": "从学习理论视角看局部可解释性",
        "摘要翻译": "在本文中，我们通过局部近似解释的视角，探讨了可解释机器学习与学习理论之间的联系。首先，我们解决了性能泛化这一传统问题，并通过模型局部可解释性的概念，界定了模型在测试时的预测准确性。其次，我们探讨了解释泛化这一新问题，这对于日益增长的基于有限样本的局部近似解释类别来说是一个重要关切。最后，我们通过实证验证了我们的理论结果，并表明这些结果反映了实践中可以观察到的现象。",
        "领域": "可解释人工智能、机器学习理论、模型解释性",
        "问题": "探讨机器学习模型的局部可解释性与学习理论之间的联系，解决性能泛化和解释泛化问题。",
        "动机": "随着机器学习模型在各个领域的广泛应用，模型的解释性变得越来越重要。本研究旨在从理论角度理解局部可解释性，并解决由此产生的泛化问题。",
        "方法": "通过局部近似解释的视角，结合学习理论，对模型的性能泛化和解释泛化进行理论分析，并通过实证研究验证理论结果。",
        "关键词": [
            "局部可解释性",
            "学习理论",
            "性能泛化",
            "解释泛化",
            "机器学习"
        ],
        "涉及的技术概念": {
            "局部近似解释": "用于解释机器学习模型在特定输入附近的决策行为，通过近似模型在局部区域的行为来提高模型的可解释性。",
            "性能泛化": "指机器学习模型在训练数据之外的测试数据上的表现能力，本研究通过局部可解释性来界定这一能力。",
            "解释泛化": "指局部解释方法在未见数据上的适用性和稳定性，是本研究探讨的新问题。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 32,
        "title": "ALFWorld: Aligning Text and Embodied Environments for Interactive Learning",
        "html": "https://iclr.cc//virtual/2021/poster/2973",
        "abstract": "Given a simple request like Put a washed apple in the kitchen fridge, humans can reason in purely abstract terms by imagining action sequences and scoring their likelihood of success, prototypicality, and efficiency, all without moving a muscle. Once we see the kitchen in question, we can update our abstract plans to fit the scene. Embodied agents require the same abilities, but existing work does not yet provide the infrastructure necessary for both reasoning abstractly and executing concretely. We address this limitation by introducing ALFWorld, a simulator that enables agents to learn abstract, text-based policies in TextWorld (Côté et al., 2018) and then execute goals from the ALFRED benchmark (Shridhar et al., 2020) in a rich visual environment. ALFWorld enables the creation of a new BUTLER agent whose abstract knowledge, learned in TextWorld, corresponds directly to concrete, visually grounded actions. In turn, as we demonstrate empirically, this fosters better agent generalization than training only in the visually grounded environment. BUTLER’s simple, modular design factors the problem to allow researchers to focus on models for improving every piece of the pipeline (language understanding, planning, navigation, and visual scene understanding).",
        "conference": "ICLR",
        "中文标题": "ALFWorld：对齐文本与具身环境以进行交互式学习",
        "摘要翻译": "给定一个简单的请求，比如'把一个洗过的苹果放进厨房的冰箱'，人类可以通过想象动作序列并评估其成功的可能性、典型性和效率来进行纯粹的抽象推理，而无需移动肌肉。一旦我们看到相关的厨房，我们就可以更新我们的抽象计划以适应场景。具身代理需要同样的能力，但现有的工作尚未提供既能够进行抽象推理又能够具体执行所需的基础设施。我们通过引入ALFWorld来解决这一限制，这是一个模拟器，使代理能够在TextWorld（Côté等人，2018）中学习基于文本的抽象策略，然后在丰富的视觉环境中执行来自ALFRED基准（Shridhar等人，2020）的目标。ALFWorld使得能够创建一个新的BUTLER代理，其在TextWorld中学到的抽象知识直接对应于具体的、视觉基础的动作。反过来，正如我们通过实证展示的那样，这比仅在视觉基础环境中训练更能促进代理的泛化。BUTLER的简单、模块化设计将问题分解，使研究人员能够专注于改进管道中每个部分的模型（语言理解、规划、导航和视觉场景理解）。",
        "领域": "自然语言处理与视觉结合、具身智能、交互式学习",
        "问题": "如何使具身代理既能进行抽象推理又能具体执行任务",
        "动机": "解决现有具身代理在抽象推理和具体执行任务能力上的不足",
        "方法": "引入ALFWorld模拟器，结合TextWorld的抽象策略学习和ALFRED基准的视觉环境执行",
        "关键词": [
            "具身智能",
            "交互式学习",
            "抽象推理",
            "视觉执行",
            "ALFWorld"
        ],
        "涉及的技术概念": {
            "TextWorld": "一个基于文本的环境，用于学习抽象策略",
            "ALFRED基准": "一个视觉丰富的环境，用于执行具体任务",
            "BUTLER代理": "一个模块化设计的代理，能够将抽象知识应用于具体动作"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 33,
        "title": "Aligning AI With Shared Human Values",
        "html": "https://iclr.cc//virtual/2021/poster/2960",
        "abstract": "We show how to assess a language model's knowledge of basic concepts of morality. We introduce the ETHICS dataset, a new benchmark that spans concepts in justice, well-being, duties, virtues, and commonsense morality. Models predict widespread moral judgments about diverse text scenarios. This requires connecting physical and social world knowledge to value judgements, a capability that may enable us to steer chatbot outputs or eventually regularize open-ended reinforcement learning agents. With the ETHICS dataset, we find that current language models have a promising but incomplete ability to predict basic human ethical judgements. Our work shows that progress can be made on machine ethics today, and it provides a steppingstone toward AI that is aligned with human values.",
        "conference": "ICLR",
        "中文标题": "将人工智能与共享人类价值观对齐",
        "摘要翻译": "我们展示了如何评估语言模型对基本道德概念的认知。我们引入了ETHICS数据集，这是一个新的基准，涵盖了正义、福祉、责任、美德和常识道德等概念。模型预测关于多样化文本场景的广泛道德判断。这需要将物理和社会世界知识与价值判断联系起来，这种能力可能使我们能够引导聊天机器人输出或最终规范开放式强化学习代理。通过ETHICS数据集，我们发现当前的语言模型在预测基本人类伦理判断方面具有有前景但不完整的能力。我们的工作表明，今天可以在机器伦理方面取得进展，并为与人类价值观对齐的人工智能提供了一个垫脚石。",
        "领域": "自然语言处理与伦理结合、人工智能伦理、语言模型评估",
        "问题": "评估语言模型对基本道德概念的认知能力",
        "动机": "为了开发能够理解和预测人类伦理判断的人工智能系统，确保AI行为与人类价值观对齐",
        "方法": "引入ETHICS数据集作为评估基准，利用语言模型预测多样化文本场景的道德判断",
        "关键词": [
            "人工智能伦理",
            "语言模型评估",
            "ETHICS数据集",
            "道德判断",
            "价值观对齐"
        ],
        "涉及的技术概念": {
            "ETHICS数据集": "一个涵盖正义、福祉、责任、美德和常识道德等概念的基准数据集，用于评估语言模型的道德判断能力",
            "语言模型": "用于预测和理解人类语言的技术，本文中用于评估其对道德概念的认知",
            "价值观对齐": "确保人工智能系统的行为和决策与人类共享的价值观一致的技术目标"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 34,
        "title": "A Mathematical Exploration of Why Language Models Help Solve Downstream Tasks",
        "html": "https://iclr.cc//virtual/2021/poster/2824",
        "abstract": "Autoregressive language models, pretrained using large text corpora to do well on next word prediction, have been successful at solving many downstream tasks, even with zero-shot usage. However, there is little theoretical understanding of this success. This paper initiates a mathematical study of this phenomenon for the downstream task of text classification by considering the following questions: (1) What is the intuitive connection between the pretraining task of next word prediction and text classification? (2) How can we mathematically formalize this connection and quantify the benefit of language modeling? For (1), we hypothesize, and verify empirically, that classification tasks of interest can be reformulated as sentence completion tasks, thus making language modeling a meaningful pretraining task. With a mathematical formalization of this hypothesis, we make progress towards (2) and show that language models that are $\\epsilon$-optimal in cross-entropy (log-perplexity) learn features that can linearly solve such classification tasks with $\\mathcal{O}(\\sqrt{\\epsilon})$ error, thus demonstrating that doing well on language modeling can be beneficial for downstream tasks. We experimentally verify various assumptions and theoretical findings, and also use insights from the analysis to design a new objective function that performs well on some classification tasks.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "语言模型为何有助于解决下游任务的数学探索",
        "摘要翻译": "自回归语言模型通过使用大型文本语料库进行预训练，在下一个词预测方面表现出色，并且已经成功地解决了许多下游任务，即使是零样本使用也是如此。然而，对于这种成功，几乎没有理论上的理解。本文通过考虑以下问题，启动了对这种现象的数学研究，针对文本分类的下游任务：（1）下一个词预测的预训练任务和文本分类之间有什么直观的联系？（2）我们如何以数学方式形式化这种联系并量化语言建模的好处？对于（1），我们假设并通过经验验证，感兴趣的分类任务可以被重新定义为句子补全任务，从而使语言建模成为一个有意义的预训练任务。通过对该假设进行数学形式化，我们在（2）方面取得了进展，并表明在交叉熵（对数困惑度）方面达到最优的语言模型学习到的特征可以通过误差来线性解决此类分类任务，从而证明了在语言建模方面表现良好可能对下游任务有益。我们通过实验验证了各种假设和理论发现，并且还利用分析中的见解来设计一种新的目标函数，该函数在某些分类任务上表现良好。",
        "领域": "自然语言处理、文本分类、预训练模型",
        "问题": "本文旨在从理论上解释为什么在下一个词预测任务上预训练的语言模型，能够成功解决文本分类等下游任务，并量化语言建模对下游任务的益处。",
        "动机": "尽管预训练语言模型在解决下游任务中取得了显著成功，但缺乏对其成功背后的理论理解。本文旨在填补这一空白，通过数学分析来揭示语言模型在下游任务中有效的原因。",
        "方法": "本文首先假设文本分类任务可以被重新定义为句子补全任务，并用实验验证该假设。然后，通过数学形式化，证明了在交叉熵方面达到最优的语言模型学习到的特征可以通过误差来线性解决文本分类任务。最后，通过实验验证了各种假设和理论发现，并基于分析结果设计了一种新的目标函数。",
        "关键词": [
            "语言模型",
            "预训练",
            "文本分类",
            "数学建模",
            "句子补全"
        ],
        "涉及的技术概念": {
            "自回归语言模型": "一种基于前文预测下一个词的语言模型，是预训练的基础。",
            "交叉熵损失": "用于衡量语言模型预测结果与真实标签之间差异的损失函数，优化目标是最小化交叉熵。"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 35,
        "title": "Analyzing the Expressive Power of Graph Neural Networks in a Spectral Perspective",
        "html": "https://iclr.cc//virtual/2021/poster/3158",
        "abstract": "In the recent literature of Graph Neural Networks (GNN), the expressive power of models has been studied through their capability to distinguish if two given graphs are isomorphic or not. Since the graph isomorphism problem is NP-intermediate, and Weisfeiler-Lehman (WL) test can give sufficient but not enough evidence in polynomial time, the theoretical power of GNNs is usually evaluated by the equivalence of WL-test order, followed by an empirical analysis of the models on some reference inductive and transductive datasets. However, such analysis does not account the signal processing pipeline, whose capability is generally evaluated in the spectral domain. In this paper, we argue that a spectral analysis of GNNs behavior can provide a complementary point of view to go one step further in the understanding of GNNs. By bridging the gap between the spectral and spatial design of graph convolutions, we theoretically demonstrate some equivalence of the graph convolution process regardless it is designed in the spatial or the spectral domain. Using this connection, we managed to re-formulate most of the state-of-the-art graph neural networks into one common framework. This general framework allows to lead a spectral analysis of the most popular GNNs, explaining their performance and showing their limits according to spectral point of view. Our theoretical spectral analysis is confirmed by experiments on various graph databases. Furthermore, we demonstrate the necessity of high and/or band-pass filters on a graph dataset, while the majority of GNN is limited to only low-pass and inevitably it fails.",
        "conference": "ICLR",
        "中文标题": "从谱视角分析图神经网络的表达能力",
        "摘要翻译": "在图神经网络（GNN）的近期文献中，模型的表现能力通过其区分两个给定图是否同构的能力来研究。由于图同构问题是NP-中间问题，而Weisfeiler-Lehman（WL）测试可以在多项式时间内提供充分但不足够的证据，GNN的理论能力通常通过WL测试阶数的等价性来评估，随后在一些参考的归纳和转导数据集上对模型进行实证分析。然而，这种分析没有考虑信号处理流程，其能力通常在谱域中评估。在本文中，我们认为对GNN行为的谱分析可以提供一种互补的视角，以进一步理解GNN。通过弥合图卷积的谱设计和空间设计之间的差距，我们从理论上证明了图卷积过程的一些等价性，无论它是在空间域还是谱域设计的。利用这种联系，我们成功地将大多数最先进的图神经网络重新表述为一个共同的框架。这个通用框架允许对最流行的GNN进行谱分析，解释它们的性能并根据谱观点展示它们的限制。我们的理论谱分析通过在各种图数据库上的实验得到了证实。此外，我们证明了在图数据集上高和/或带通滤波器的必要性，而大多数GNN仅限于低通滤波器，这不可避免地导致失败。",
        "领域": "图神经网络、图信号处理、图同构测试",
        "问题": "如何从谱视角评估和提升图神经网络的表达能力",
        "动机": "现有研究主要基于WL测试评估GNN的表达能力，忽视了谱分析的重要性，本研究旨在填补这一空白",
        "方法": "通过理论分析和实验验证，将多种GNN统一到一个框架下进行谱分析",
        "关键词": [
            "图神经网络",
            "谱分析",
            "图同构",
            "图卷积",
            "滤波器设计"
        ],
        "涉及的技术概念": {
            "Weisfeiler-Lehman测试": "用于评估图神经网络表达能力的经典方法，通过图的颜色细化过程判断图同构",
            "谱域分析": "从图的拉普拉斯矩阵特征分解角度分析图信号处理能力",
            "图卷积": "图神经网络中的核心操作，本研究证明了其在空间域和谱域的等价性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 36,
        "title": "Anatomy of Catastrophic Forgetting: Hidden Representations and Task Semantics",
        "html": "https://iclr.cc//virtual/2021/poster/2907",
        "abstract": "Catastrophic forgetting is a recurring challenge to developing versatile deep learning models. Despite its ubiquity, there is limited understanding of its connections to neural network (hidden) representations and task semantics. In this paper, we address this important knowledge gap. Through quantitative analysis of neural representations, we find that deeper layers are disproportionately responsible for forgetting, with sequential training resulting in an erasure of earlier task representational subspaces. Methods to mitigate forgetting stabilize these deeper layers, but show diversity on precise effects, with some increasing feature reuse while others store task representations orthogonally, preventing interference. These insights also enable the development of an analytic argument and empirical picture relating forgetting to task semantic similarity, where we find that maximal forgetting occurs for task sequences with intermediate similarity.",
        "conference": "ICLR",
        "中文标题": "灾难性遗忘的剖析：隐藏表示与任务语义",
        "摘要翻译": "灾难性遗忘是开发多功能深度学习模型时反复出现的挑战。尽管它普遍存在，但对其与神经网络（隐藏）表示和任务语义之间联系的理解有限。在本文中，我们解决了这一重要的知识空白。通过对神经表示的定量分析，我们发现更深层次主要负责遗忘，顺序训练导致早期任务表示子空间的擦除。减轻遗忘的方法稳定了这些更深层次，但在精确效果上显示出多样性，一些增加了特征重用，而其他则正交存储任务表示，防止干扰。这些见解还使我们能够发展一个分析论点和实证图景，将遗忘与任务语义相似性联系起来，我们发现最大遗忘发生在具有中等相似性的任务序列中。",
        "领域": "深度学习理论、神经网络优化、持续学习",
        "问题": "理解灾难性遗忘与神经网络隐藏表示及任务语义之间的关系",
        "动机": "填补关于灾难性遗忘如何与神经网络的隐藏表示和任务语义相互作用的知识空白",
        "方法": "通过定量分析神经表示，研究灾难性遗忘的机制，并探索减轻遗忘的方法",
        "关键词": [
            "灾难性遗忘",
            "神经网络表示",
            "任务语义",
            "持续学习",
            "特征重用"
        ],
        "涉及的技术概念": {
            "灾难性遗忘": "指神经网络在学习新任务时忘记之前学到的知识的现象",
            "隐藏表示": "神经网络在处理输入数据时内部形成的表示，对理解网络如何处理信息至关重要",
            "任务语义相似性": "不同任务之间在语义上的相似程度，影响灾难性遗忘的严重程度"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 37,
        "title": "Anchor & Transform: Learning Sparse Embeddings for Large Vocabularies",
        "html": "https://iclr.cc//virtual/2021/poster/3100",
        "abstract": "Learning continuous representations of discrete objects such as text, users, movies, and URLs lies at the heart of many applications including language and user modeling. When using discrete objects as input to neural networks, we often ignore the underlying structures (e.g., natural groupings and similarities) and embed the objects independently into individual vectors. As a result, existing methods do not scale to large vocabulary sizes. In this paper, we design a simple and efficient embedding algorithm that learns a small set of anchor embeddings and a sparse transformation matrix. We call our method Anchor & Transform (ANT) as the embeddings of discrete objects are a sparse linear combination of the anchors, weighted according to the transformation matrix. ANT is scalable, flexible, and end-to-end trainable. We further provide a statistical interpretation of our algorithm as a Bayesian nonparametric prior for embeddings that encourages sparsity and leverages natural groupings among objects. By deriving an approximate inference algorithm based on Small Variance Asymptotics, we obtain a natural extension that automatically learns the optimal number of anchors instead of having to tune it as a hyperparameter. On text classification, language modeling, and movie recommendation benchmarks, we show that ANT is particularly suitable for large vocabulary sizes and demonstrates stronger performance with fewer parameters (up to 40x compression) as compared to existing compression baselines.",
        "conference": "ICLR",
        "中文标题": "锚点与变换：学习大词汇量的稀疏嵌入",
        "摘要翻译": "学习离散对象（如文本、用户、电影和URL）的连续表示是许多应用的核心，包括语言和用户建模。当将离散对象作为神经网络的输入时，我们常常忽略了底层结构（例如自然分组和相似性），并将对象独立地嵌入到单个向量中。因此，现有方法无法扩展到大的词汇量。在本文中，我们设计了一种简单高效的嵌入算法，该算法学习一小部分锚点嵌入和一个稀疏变换矩阵。我们称我们的方法为锚点与变换（ANT），因为离散对象的嵌入是锚点的稀疏线性组合，根据变换矩阵加权。ANT是可扩展的、灵活的，并且可以端到端训练。我们进一步提供了我们算法的统计解释，作为一种鼓励稀疏性并利用对象间自然分组的嵌入的贝叶斯非参数先验。通过推导基于小方差渐近的近似推理算法，我们获得了一个自然扩展，该扩展自动学习最优锚点数量，而不是将其作为超参数进行调整。在文本分类、语言建模和电影推荐基准测试中，我们表明ANT特别适合大词汇量，并且与现有的压缩基线相比，用更少的参数（高达40倍的压缩）展示了更强的性能。",
        "领域": "自然语言处理与视觉结合",
        "问题": "如何有效地学习大词汇量的稀疏嵌入表示",
        "动机": "现有方法在处理大词汇量时无法有效利用离散对象的底层结构，导致扩展性差",
        "方法": "设计了一种学习锚点嵌入和稀疏变换矩阵的算法（ANT），通过稀疏线性组合和贝叶斯非参数先验来提高嵌入的效率和效果",
        "关键词": [
            "稀疏嵌入",
            "大词汇量",
            "锚点与变换",
            "贝叶斯非参数",
            "端到端训练"
        ],
        "涉及的技术概念": {
            "稀疏嵌入": "一种表示方法，通过稀疏线性组合锚点嵌入来表示离散对象，以提高效率和可扩展性",
            "贝叶斯非参数先验": "用于嵌入学习的一种统计方法，鼓励稀疏性并利用对象间的自然分组",
            "小方差渐近": "一种近似推理算法，用于自动学习最优锚点数量，减少超参数调整的需求"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 38,
        "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale",
        "html": "https://iclr.cc//virtual/2021/poster/3013",
        "abstract": "While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on CNNs is not necessary and a pure transformer applied directly to sequences of image patches can perform very well on image classification tasks. When pre-trained on large amounts of data and transferred to multiple mid-sized or small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT) attains excellent results compared to state-of-the-art convolutional networks while requiring substantially fewer computational resources to train.",
        "conference": "ICLR",
        "中文标题": "一张图片相当于16x16个词：大规模图像识别的Transformer应用",
        "摘要翻译": "尽管Transformer架构已成为自然语言处理任务的事实标准，但其在计算机视觉中的应用仍然有限。在视觉领域，注意力机制要么与卷积网络结合使用，要么用于替换卷积网络的某些组件，同时保持其整体结构不变。我们证明，这种对卷积网络的依赖并非必要，直接应用于图像补丁序列的纯Transformer在图像分类任务上可以表现得非常好。当在大规模数据上进行预训练并迁移到多个中型或小型图像识别基准（如ImageNet、CIFAR-100、VTAB等）时，视觉Transformer（ViT）与最先进的卷积网络相比取得了优异的结果，同时训练所需的计算资源大大减少。",
        "领域": "图像分类、视觉Transformer、大规模预训练",
        "问题": "探索Transformer架构在计算机视觉领域的应用，特别是在不依赖卷积网络的情况下进行图像分类。",
        "动机": "减少对卷积网络的依赖，探索纯Transformer架构在图像识别任务中的潜力，以提高计算效率和性能。",
        "方法": "提出视觉Transformer（ViT），直接将纯Transformer应用于图像补丁序列，通过大规模数据预训练和迁移学习，在多个图像识别基准上进行评估。",
        "关键词": [
            "视觉Transformer",
            "图像分类",
            "大规模预训练",
            "迁移学习",
            "计算效率"
        ],
        "涉及的技术概念": {
            "视觉Transformer（ViT）": "一种将纯Transformer架构直接应用于图像补丁序列的方法，用于图像分类任务。",
            "大规模预训练": "在大规模数据集上预先训练模型，以提高其在特定任务上的性能。",
            "迁移学习": "将在一个任务上学到的知识迁移到另一个相关任务上，以提升模型在新任务上的表现。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 39,
        "title": "ANOCE: Analysis of Causal Effects with Multiple Mediators via Constrained Structural Learning",
        "html": "https://iclr.cc//virtual/2021/poster/3019",
        "abstract": "In the era of causal revolution, identifying the causal effect of an exposure on the outcome of interest is an important problem in many areas, such as epidemics, medicine, genetics, and economics. Under a general causal graph, the exposure may have a direct effect on the outcome and also an indirect effect regulated by a set of mediators. An analysis of causal effects that interprets the causal mechanism contributed through mediators is hence challenging but on demand. To the best of our knowledge, there are no feasible algorithms that give an exact decomposition of the indirect effect on the level of individual mediators, due to common interaction among mediators in the complex graph. In this paper, we establish a new statistical framework to comprehensively characterize causal effects with multiple mediators, namely, ANalysis Of Causal Effects (ANOCE), with a newly introduced definition of the mediator effect, under the linear structure equation model. We further propose a constrained causal structure learning method by incorporating a novel identification constraint that specifies the temporal causal relationship of variables. The proposed algorithm is applied to investigate the causal effects of 2020 Hubei lockdowns on reducing the spread of the coronavirus in Chinese major cities out of Hubei. ",
        "conference": "ICLR",
        "中文标题": "ANOCE：通过约束结构学习分析多重中介的因果效应",
        "摘要翻译": "在因果革命的时代，识别暴露对感兴趣结果的因果效应是流行病学、医学、遗传学和经济学等许多领域的重要问题。在一个一般的因果图中，暴露可能对结果有直接影响，也可能通过一组中介变量调节的间接影响。因此，解释通过中介变量贡献的因果机制的因果效应分析既具有挑战性又有需求。据我们所知，由于复杂图中中介变量之间的常见交互作用，目前没有可行的算法可以在个体中介水平上对间接效应进行精确分解。在本文中，我们建立了一个新的统计框架，全面表征多重中介的因果效应，即因果效应分析（ANOCE），在线性结构方程模型下引入了中介效应的新定义。我们进一步提出了一种约束因果结构学习方法，通过纳入一个新的识别约束，指定变量的时间因果关系。所提出的算法被应用于研究2020年湖北封锁对中国湖北以外主要城市减少冠状病毒传播的因果效应。",
        "领域": "因果推断、结构方程模型、流行病学",
        "问题": "在存在多重中介变量的复杂因果图中，如何精确分解和解释暴露对结果的间接效应。",
        "动机": "解决现有方法无法在个体中介水平上精确分解间接效应的问题，特别是在中介变量之间存在交互作用的复杂因果图中。",
        "方法": "提出一个新的统计框架ANOCE，引入中介效应的新定义，并开发一种约束因果结构学习方法，通过识别约束指定变量的时间因果关系。",
        "关键词": [
            "因果效应分析",
            "多重中介",
            "约束结构学习",
            "线性结构方程模型",
            "冠状病毒传播"
        ],
        "涉及的技术概念": {
            "因果效应分析（ANOCE）": "本文提出的新统计框架，用于全面表征多重中介的因果效应。",
            "线性结构方程模型": "用于建模和分析变量间因果关系的统计框架，本文中用于定义和分解中介效应。",
            "约束因果结构学习": "本文提出的方法，通过引入识别约束来学习因果结构，特别是在存在多重中介变量的复杂图中。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 40,
        "title": "Answering Complex Open-Domain Questions with Multi-Hop Dense Retrieval",
        "html": "https://iclr.cc//virtual/2021/poster/2806",
        "abstract": "We propose a simple and efficient multi-hop dense retrieval approach for answering complex open-domain questions, which achieves state-of-the-art performance on two multi-hop datasets, HotpotQA and multi-evidence FEVER. Contrary to previous work, our method does not require access to any corpus-specific information, such as inter-document hyperlinks or human-annotated entity markers, and can be applied to any unstructured text corpus. Our system also yields a much better efficiency-accuracy trade-off, matching the best published accuracy on HotpotQA while being 10 times faster at inference time.",
        "conference": "ICLR",
        "中文标题": "使用多跳密集检索回答复杂开放领域问题",
        "摘要翻译": "我们提出了一种简单高效的多跳密集检索方法，用于回答复杂的开放领域问题，该方法在两个多跳数据集HotpotQA和多证据FEVER上实现了最先进的性能。与之前的工作不同，我们的方法不需要访问任何特定语料库的信息，如文档间超链接或人工标注的实体标记，并且可以应用于任何非结构化文本语料库。我们的系统在效率和准确性之间取得了更好的平衡，在HotpotQA上达到了已发布的最佳准确性，同时在推理时间上快了10倍。",
        "领域": "开放领域问答、多跳推理、信息检索",
        "问题": "如何在不需要特定语料库信息的情况下，高效准确地回答复杂的开放领域问题。",
        "动机": "解决现有方法在处理复杂开放领域问题时对特定语料库信息的依赖，以及效率和准确性之间的不平衡问题。",
        "方法": "提出了一种不依赖特定语料库信息的多跳密集检索方法，优化了效率和准确性之间的平衡。",
        "关键词": [
            "多跳密集检索",
            "开放领域问答",
            "效率-准确性平衡",
            "非结构化文本处理",
            "HotpotQA"
        ],
        "涉及的技术概念": {
            "多跳密集检索": "一种检索方法，通过多步（多跳）检索来回答需要综合多个信息源的复杂问题。",
            "开放领域问答": "指在没有特定领域限制的情况下，回答用户提出的任何问题。",
            "效率-准确性平衡": "在保持高准确性的同时，提高系统的处理速度，实现更好的性能表现。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 41,
        "title": "An Unsupervised Deep Learning Approach for Real-World Image Denoising",
        "html": "https://iclr.cc//virtual/2021/poster/2927",
        "abstract": "Designing an unsupervised image denoising approach in practical applications is a challenging task due to the complicated data acquisition process. In the real-world case, the noise distribution is so complex that the simplified additive white Gaussian (AWGN) assumption rarely holds, which significantly deteriorates the Gaussian denoisers' performance. To address this problem, we apply a deep neural network that maps the noisy image into a latent space in which the AWGN assumption holds, and thus any existing Gaussian denoiser is applicable. More specifically, the proposed neural network consists of the encoder-decoder structure and approximates the likelihood term in the Bayesian framework. Together with a Gaussian denoiser, the neural network can be trained with the input image itself and does not require any pre-training in other datasets. Extensive experiments on real-world noisy image datasets have shown that the combination of neural networks and Gaussian denoisers improves the performance of the original Gaussian denoisers by a large margin. In particular, the neural network+BM3D method significantly outperforms other unsupervised denoising approaches and is competitive with supervised networks such as DnCNN, FFDNet, and CBDNet.",
        "conference": "ICLR",
        "中文标题": "一种无监督深度学习方法用于真实世界图像去噪",
        "摘要翻译": "在实际应用中设计一种无监督图像去噪方法是一项具有挑战性的任务，这主要是由于复杂的数据获取过程。在真实世界的情况下，噪声分布非常复杂，以至于简化的加性白高斯噪声（AWGN）假设很少成立，这显著降低了高斯去噪器的性能。为了解决这个问题，我们应用了一个深度神经网络，将噪声图像映射到一个AWGN假设成立的潜在空间，从而使得任何现有的高斯去噪器都适用。更具体地说，提出的神经网络由编码器-解码器结构组成，并在贝叶斯框架中近似似然项。与高斯去噪器一起，神经网络可以仅使用输入图像本身进行训练，而不需要在其他数据集上进行预训练。在真实世界噪声图像数据集上的大量实验表明，神经网络和高斯去噪器的组合大幅提高了原始高斯去噪器的性能。特别是，神经网络+BM3D方法显著优于其他无监督去噪方法，并且与DnCNN、FFDNet和CBDNet等有监督网络相竞争。",
        "领域": "图像去噪、无监督学习、深度学习应用",
        "问题": "解决在复杂噪声分布下，传统高斯去噪器性能显著下降的问题",
        "动机": "由于真实世界图像噪声分布的复杂性，传统的基于AWGN假设的去噪方法效果不佳，需要一种无需预训练数据即可有效去噪的方法",
        "方法": "应用深度神经网络将噪声图像映射到AWGN假设成立的潜在空间，结合高斯去噪器进行无监督训练",
        "关键词": [
            "无监督学习",
            "图像去噪",
            "深度神经网络",
            "高斯去噪器",
            "BM3D"
        ],
        "涉及的技术概念": {
            "编码器-解码器结构": "用于将噪声图像映射到潜在空间，并在贝叶斯框架中近似似然项",
            "贝叶斯框架": "提供理论基础，使得神经网络能够近似噪声图像的似然项",
            "高斯去噪器": "在潜在空间中应用，利用AWGN假设进行图像去噪"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 42,
        "title": "Anytime Sampling for Autoregressive Models via Ordered Autoencoding",
        "html": "https://iclr.cc//virtual/2021/poster/3304",
        "abstract": "Autoregressive models are widely used for tasks such as image and audio generation. The sampling process of these models, however, does not allow interruptions and cannot adapt to real-time computational resources. This challenge impedes the deployment of powerful autoregressive models, which involve a slow sampling process that is sequential in nature and typically scales linearly with respect to the data dimension.  To address this difficulty, we propose a new family of autoregressive models that enables anytime sampling. Inspired by Principal Component Analysis, we learn a structured representation space where dimensions are ordered based on their importance with respect to reconstruction. Using an autoregressive model in this latent space, we trade off sample quality for computational efficiency by truncating the generation process before decoding into the original data space. Experimentally, we demonstrate in several image and audio generation tasks that sample quality degrades gracefully as we reduce the computational budget for sampling. The approach suffers almost no loss in sample quality (measured by FID) using only 60\\% to 80\\% of all latent dimensions for image data. Code is available at https://github.com/Newbeeer/Anytime-Auto-Regressive-Model.",
        "conference": "ICLR",
        "中文标题": "通过有序自编码实现自回归模型的任意时间采样",
        "摘要翻译": "自回归模型广泛应用于图像和音频生成等任务。然而，这些模型的采样过程不允许中断，也无法适应实时计算资源。这一挑战阻碍了强大自回归模型的部署，这些模型涉及一个本质上顺序且通常随数据维度线性扩展的缓慢采样过程。为了解决这一难题，我们提出了一种新的自回归模型家族，实现了任意时间采样。受主成分分析的启发，我们学习了一个结构化表示空间，其中维度根据其对于重建的重要性进行排序。在这个潜在空间中使用自回归模型，我们通过在解码到原始数据空间之前截断生成过程，以计算效率换取样本质量。实验上，我们在几个图像和音频生成任务中证明，随着我们减少采样的计算预算，样本质量优雅地下降。该方法在仅使用所有潜在维度的60%到80%时，样本质量（通过FID测量）几乎没有损失。代码可在https://github.com/Newbeeer/Anytime-Auto-Regressive-Model获取。",
        "领域": "图像生成, 音频生成, 自回归模型",
        "问题": "自回归模型采样过程不允许中断且无法适应实时计算资源的问题",
        "动机": "解决自回归模型采样过程缓慢且无法适应实时计算资源的挑战，以促进其更广泛的应用",
        "方法": "提出一种新的自回归模型家族，通过有序自编码在潜在空间中实现任意时间采样，以计算效率换取样本质量",
        "关键词": [
            "自回归模型",
            "任意时间采样",
            "有序自编码",
            "图像生成",
            "音频生成"
        ],
        "涉及的技术概念": {
            "自回归模型": "一种广泛应用于序列数据生成的模型，通过给定序列的前面部分预测下一个元素",
            "有序自编码": "一种学习结构化表示空间的技术，其中维度根据其对于重建的重要性进行排序",
            "FID": "Frechet Inception Distance，用于衡量生成图像质量的指标，值越小表示生成图像与真实图像的分布越接近"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 43,
        "title": "A PAC-Bayesian Approach to Generalization Bounds for Graph Neural Networks",
        "html": "https://iclr.cc//virtual/2021/poster/2789",
        "abstract": "In this paper, we derive generalization bounds for two primary classes of graph neural networks (GNNs), namely graph convolutional networks (GCNs) and message passing GNNs (MPGNNs), via a PAC-Bayesian approach. Our result reveals that the maximum node degree and the spectral norm of the weights govern the generalization bounds of both models. We also show that our bound for GCNs is a natural generalization of the results developed in \\citep{neyshabur2017pac} for fully-connected and convolutional neural networks. For MPGNNs, our PAC-Bayes bound improves over the Rademacher complexity based bound \\citep{garg2020generalization}, showing a tighter dependency on the maximum node degree and the maximum hidden dimension. The key ingredients of our proofs are a perturbation analysis of GNNs and the generalization of PAC-Bayes analysis to non-homogeneous GNNs. We perform an empirical study on several synthetic and real-world graph datasets and verify that our PAC-Bayes bound is tighter than others. ",
        "conference": "ICLR",
        "success": true,
        "中文标题": "图神经网络泛化界限的PAC-贝叶斯方法",
        "摘要翻译": "本文通过PAC-贝叶斯方法推导了两类主要图神经网络（GNN）的泛化界限，分别是图卷积网络（GCN）和消息传递GNN（MPGNN）。我们的结果表明，最大节点度和权重的谱范数控制着这两种模型的泛化界限。我们还表明，我们对GCN的界限是对\\citep{neyshabur2017pac}中开发的用于全连接和卷积神经网络的结果的自然推广。对于MPGNN，我们的PAC-Bayes界限优于基于Rademacher复杂度的界限\\citep{garg2020generalization}，显示出对最大节点度和最大隐藏维度的更严格的依赖性。我们证明的关键要素是对GNN的扰动分析以及PAC-Bayes分析对非同构GNN的推广。我们在几个合成的和真实世界的图数据集上进行了实证研究，并验证了我们的PAC-Bayes界限比其他界限更严格。",
        "领域": "图神经网络, 泛化理论, 图卷积网络",
        "问题": "如何为图神经网络（GNNs）提供有效的泛化界限，特别是对于图卷积网络（GCNs）和消息传递GNNs（MPGNNs）?",
        "动机": "现有的GNN泛化界限不够精确，需要更严格的依赖关系来控制模型复杂度和提高泛化性能。",
        "方法": "采用PAC-Bayes方法，通过扰动分析和非同构GNN的推广，推导了GCN和MPGNN的泛化界限，并进行了实证研究验证。",
        "关键词": [
            "PAC-Bayes",
            "图神经网络",
            "泛化界限",
            "图卷积网络",
            "消息传递"
        ],
        "涉及的技术概念": {
            "PAC-Bayes": "一种用于推导模型泛化误差上界的理论框架，它通过考虑模型参数的先验分布和后验分布来控制模型的复杂度。",
            "图卷积网络（GCN）": "一种直接在图结构数据上进行卷积操作的神经网络，用于提取节点和图的特征。"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 44,
        "title": "A Panda? No, It's a Sloth: Slowdown Attacks on Adaptive Multi-Exit Neural Network Inference",
        "html": "https://iclr.cc//virtual/2021/poster/3283",
        "abstract": "Recent increases in the computational demands of deep neural networks (DNNs), combined with the observation that most input samples require only simple models, have sparked interest in input-adaptive multi-exit architectures, such as MSDNets or Shallow-Deep Networks. These architectures enable faster inferences and could bring DNNs to low-power devices, e.g., in the Internet of Things (IoT). However, it is unknown if the computational savings provided by this approach are robust against adversarial pressure. In particular, an adversary may aim to slowdown adaptive DNNs by increasing their average inference time—a threat analogous to the denial-of-service attacks from the Internet. In this paper, we conduct a systematic evaluation of this threat by experimenting with three generic multi-exit DNNs (based on VGG16, MobileNet, and ResNet56) and a custom multi-exit architecture, on two popular image classification benchmarks (CIFAR-10 and Tiny ImageNet). To this end, we show that adversarial example-crafting techniques can be modified to cause slowdown, and we propose a metric for comparing their impact on different architectures. We show that a slowdown attack reduces the efficacy of multi-exit DNNs by 90–100%, and it amplifies the latency by 1.5–5× in a typical IoT deployment. We also show that it is possible to craft universal, reusable perturbations and that the attack can be effective in realistic black-box scenarios, where the attacker has limited knowledge about the victim. Finally, we show that adversarial training provides limited protection against slowdowns. These results suggest that further research is needed for defending multi-exit architectures against this emerging threat. Our code is available at https://github.com/sanghyun-hong/deepsloth. ",
        "conference": "ICLR",
        "中文标题": "熊猫？不，是树懒：对自适应多出口神经网络推理的减速攻击",
        "摘要翻译": "近年来，深度神经网络（DNNs）计算需求的增加，加上大多数输入样本仅需简单模型的观察，激发了人们对输入自适应的多出口架构的兴趣，如MSDNets或浅深网络。这些架构能够实现更快的推理，并可能将DNNs带到低功耗设备，例如物联网（IoT）中。然而，尚不清楚这种方法提供的计算节省是否能抵抗对抗性压力。特别是，攻击者可能旨在通过增加其平均推理时间来减慢自适应DNNs——这种威胁类似于互联网中的拒绝服务攻击。在本文中，我们通过对三种通用的多出口DNNs（基于VGG16、MobileNet和ResNet56）和一种定制的多出口架构在两个流行的图像分类基准（CIFAR-10和Tiny ImageNet）上的实验，对这一威胁进行了系统评估。为此，我们展示了可以修改对抗性示例制作技术以引起减速，并提出了一个用于比较它们对不同架构影响的指标。我们表明，减速攻击将多出口DNNs的效能降低了90-100%，并在典型的IoT部署中将延迟放大了1.5-5倍。我们还表明，可以制作通用的、可重复使用的扰动，并且攻击在现实的黑色场景中可能有效，其中攻击者对受害者的了解有限。最后，我们表明对抗训练对减速提供的保护有限。这些结果表明，需要进一步研究以防御多出口架构免受这一新兴威胁。我们的代码可在https://github.com/sanghyun-hong/deepsloth获取。",
        "领域": "对抗性攻击、神经网络加速、物联网安全",
        "问题": "自适应多出口神经网络在面对对抗性攻击时的计算效率下降问题",
        "动机": "研究自适应多出口神经网络在对抗性攻击下的脆弱性，以揭示其在实际应用中的潜在风险",
        "方法": "通过实验评估三种通用多出口DNNs和一种定制架构在对抗性攻击下的表现，提出减速攻击的指标和方法",
        "关键词": [
            "对抗性攻击",
            "多出口神经网络",
            "减速攻击",
            "物联网安全",
            "对抗训练"
        ],
        "涉及的技术概念": {
            "对抗性示例": "修改输入样本以欺骗神经网络，导致错误分类或性能下降的技术",
            "多出口架构": "允许神经网络在不同深度提前退出的架构，旨在提高计算效率",
            "对抗训练": "通过在训练过程中引入对抗性样本来提高模型鲁棒性的方法"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 45,
        "title": "Approximate Nearest Neighbor Negative Contrastive Learning for Dense Text Retrieval",
        "html": "https://iclr.cc//virtual/2021/poster/2673",
        "abstract": "Conducting text retrieval in a learned dense representation space has many intriguing advantages. Yet dense retrieval (DR) often underperforms word-based sparse retrieval. In this paper, we first theoretically show the bottleneck of dense retrieval is the domination of uninformative negatives sampled in mini-batch training, which yield diminishing gradient norms, large gradient variances, and slow convergence. We then propose Approximate nearest neighbor Negative Contrastive Learning (ANCE), which selects hard training negatives globally from the entire corpus. Our experiments demonstrate the effectiveness of ANCE on web search, question answering, and in a commercial search engine, showing ANCE dot-product retrieval nearly matches the accuracy of BERT-based cascade IR pipeline. We also empirically validate our theory that negative sampling with ANCE better approximates the oracle importance sampling procedure and improves learning convergence.",
        "conference": "ICLR",
        "中文标题": "密集文本检索中的近似最近邻负对比学习",
        "摘要翻译": "在学习的密集表示空间中进行文本检索具有许多引人入胜的优势。然而，密集检索（DR）的表现往往不如基于单词的稀疏检索。在本文中，我们首先从理论上展示了密集检索的瓶颈在于小批量训练中采样的无信息负样本的主导地位，这些负样本导致梯度范数减小、梯度方差增大以及收敛速度减慢。接着，我们提出了近似最近邻负对比学习（ANCE），该方法从整个语料库中全局选择难以训练的负样本。我们的实验证明了ANCE在网络搜索、问答系统以及商业搜索引擎中的有效性，显示ANCE的点积检索几乎与基于BERT的级联IR管道的准确性相匹配。我们还通过实验验证了我们的理论，即使用ANCE进行负采样能更好地近似于oracle重要性采样过程，并提高学习收敛性。",
        "领域": "文本检索、问答系统、搜索引擎优化",
        "问题": "密集检索在小批量训练中因无信息负样本的主导而表现不佳的问题",
        "动机": "解决密集检索因负样本选择不当导致的性能瓶颈，提升检索效率和准确性",
        "方法": "提出近似最近邻负对比学习（ANCE），通过全局选择难以训练的负样本来优化密集检索",
        "关键词": [
            "密集文本检索",
            "负对比学习",
            "近似最近邻",
            "BERT",
            "搜索引擎"
        ],
        "涉及的技术概念": {
            "密集检索（DR）": "一种在学习的密集表示空间中进行文本检索的方法，旨在提高检索效率和准确性",
            "近似最近邻负对比学习（ANCE）": "一种通过全局选择难以训练的负样本来优化密集检索性能的技术",
            "BERT-based cascade IR pipeline": "基于BERT的级联信息检索流程，用于提高检索的准确性和效率"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 46,
        "title": "Are Neural Nets Modular? Inspecting Functional Modularity Through Differentiable Weight Masks",
        "html": "https://iclr.cc//virtual/2021/poster/3200",
        "abstract": "Neural networks (NNs) whose subnetworks implement reusable functions are expected to offer numerous advantages, including compositionality through efficient recombination of functional building blocks, interpretability, preventing catastrophic interference, etc. Understanding if and how NNs are modular could provide insights into how to improve them. Current inspection methods, however, fail to link modules to their functionality. In this paper, we present a novel method based on learning binary weight masks to identify individual weights and subnets responsible for specific functions. Using this powerful tool, we contribute an extensive study of emerging modularity in NNs that covers several standard architectures and datasets. We demonstrate how common NNs fail to reuse submodules and offer new insights into the related issue of systematic generalization on language tasks.",
        "conference": "ICLR",
        "中文标题": "神经网络是否模块化？通过可微分权重掩码检验功能模块性",
        "摘要翻译": "神经网络（NNs）的子网络若能实现可重用功能，预计将带来诸多优势，包括通过高效重组功能构建块实现组合性、可解释性、防止灾难性干扰等。理解神经网络是否以及如何模块化，可以为如何改进它们提供洞见。然而，当前的检验方法未能将模块与其功能联系起来。在本文中，我们提出了一种基于学习二进制权重掩码的新方法，以识别负责特定功能的单个权重和子网。利用这一强大工具，我们对神经网络中出现的模块性进行了广泛研究，涵盖了几种标准架构和数据集。我们展示了常见神经网络如何未能重用子模块，并对语言任务上的系统性泛化相关问题提供了新的见解。",
        "领域": "神经网络架构设计、模块化学习、系统性泛化",
        "问题": "神经网络是否具有功能模块性，以及如何识别和利用这种模块性",
        "动机": "探索神经网络的模块化特性，以提高其组合性、可解释性和防止灾难性干扰",
        "方法": "提出了一种基于学习二进制权重掩码的新方法，用于识别负责特定功能的权重和子网",
        "关键词": [
            "模块化学习",
            "权重掩码",
            "系统性泛化",
            "神经网络架构",
            "功能识别"
        ],
        "涉及的技术概念": {
            "二进制权重掩码": "用于识别神经网络中负责特定功能的权重和子网的技术",
            "功能模块性": "神经网络子网络实现可重用功能的特性",
            "系统性泛化": "神经网络在未见过的任务或数据上表现良好的能力"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 47,
        "title": "Are Neural Rankers still Outperformed by Gradient Boosted Decision Trees?",
        "html": "https://iclr.cc//virtual/2021/poster/2911",
        "abstract": "Despite the success of neural models on many major machine learning problems, their effectiveness on traditional Learning-to-Rank (LTR) problems is still not widely acknowledged. We first validate this concern by showing that most recent neural LTR models are, by a large margin, inferior to the best publicly available Gradient Boosted Decision Trees (GBDT) in terms of their reported ranking accuracy on benchmark datasets. This unfortunately was somehow overlooked in recent neural LTR papers. We then investigate why existing neural LTR models under-perform and identify several of their weaknesses. Furthermore, we propose a unified framework comprising of counter strategies to ameliorate the existing weaknesses of neural models. Our models are the first to be able to perform equally well, comparing with the best tree-based baseline, while outperforming recently published neural LTR models by a large margin. Our results can also serve as a benchmark to facilitate future improvement of neural LTR models.",
        "conference": "ICLR",
        "中文标题": "神经排序模型是否仍被梯度提升决策树超越？",
        "摘要翻译": "尽管神经模型在许多主要的机器学习问题上取得了成功，但它们在传统的学习排序（LTR）问题上的有效性仍未得到广泛认可。我们首先通过展示大多数最近的神经LTR模型在基准数据集上报告的排序准确性远不及公开可用的最佳梯度提升决策树（GBDT）来验证这一担忧。不幸的是，这一点在最近的神经LTR论文中被某种程度上忽视了。然后，我们调查了为什么现有的神经LTR模型表现不佳，并识别出了它们的几个弱点。此外，我们提出了一个包含对抗策略的统一框架，以改善神经模型的现有弱点。我们的模型是第一个能够与基于树的最佳基线表现相当，同时大幅超越最近发布的神经LTR模型的模型。我们的结果也可以作为促进神经LTR模型未来改进的基准。",
        "领域": "学习排序（LTR）、梯度提升决策树（GBDT）、神经模型",
        "问题": "神经模型在传统学习排序问题上的表现不及梯度提升决策树",
        "动机": "验证神经模型在学习排序问题上的有效性，并探索其表现不佳的原因",
        "方法": "提出一个包含对抗策略的统一框架，以改善神经模型的弱点",
        "关键词": [
            "学习排序",
            "梯度提升决策树",
            "神经模型",
            "排序准确性",
            "基准测试"
        ],
        "涉及的技术概念": {
            "学习排序（LTR）": "一种机器学习任务，旨在根据查询的相关性对文档进行排序",
            "梯度提升决策树（GBDT）": "一种集成学习方法，通过迭代地添加决策树来改进模型的预测性能",
            "神经模型": "基于神经网络构建的模型，用于处理复杂的机器学习任务"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 48,
        "title": "Are wider nets better given the same number of parameters?",
        "html": "https://iclr.cc//virtual/2021/poster/2643",
        "abstract": "Empirical studies demonstrate that the performance of neural networks improves with increasing number of parameters. In most of these studies, the number of parameters is increased by increasing the network width. This begs the question: Is the observed improvement due to the larger number of parameters, or is it due to the larger width itself? We compare different ways of increasing model width while keeping the number of parameters constant. We show that for models initialized with a random, static sparsity pattern in the weight tensors, network width is the determining factor for good performance, while the number of weights is secondary, as long as the model achieves high training accuarcy. As a step towards understanding this effect, we analyze these models in the framework of Gaussian Process kernels. We find that the distance between the sparse finite-width model kernel and the infinite-width kernel at initialization is indicative of model performance.",
        "conference": "ICLR",
        "中文标题": "在参数数量相同的情况下，更宽的网络更好吗？",
        "摘要翻译": "实证研究表明，神经网络的性能随着参数数量的增加而提高。在大多数这些研究中，参数数量的增加是通过增加网络宽度来实现的。这就引出了一个问题：观察到的性能提升是由于参数数量的增加，还是由于网络宽度本身的增加？我们比较了在保持参数数量不变的情况下增加模型宽度的不同方法。我们发现，对于在权重张量中初始化有随机、静态稀疏模式的模型，网络宽度是决定性能好坏的关键因素，而权重数量是次要的，只要模型能够达到较高的训练准确率。为了理解这一效应，我们在高斯过程核的框架下分析了这些模型。我们发现，在初始化时，稀疏有限宽度模型核与无限宽度核之间的距离可以预示模型的性能。",
        "领域": "神经网络架构设计, 深度学习理论, 高斯过程",
        "问题": "探讨在参数数量相同的情况下，网络宽度对神经网络性能的影响",
        "动机": "理解神经网络性能提升是由于参数数量的增加还是网络宽度本身的增加",
        "方法": "比较不同增加模型宽度的方法，分析稀疏有限宽度模型与无限宽度模型在高斯过程核框架下的性能差异",
        "关键词": [
            "网络宽度",
            "参数数量",
            "高斯过程核",
            "稀疏模型",
            "模型性能"
        ],
        "涉及的技术概念": {
            "网络宽度": "指神经网络中每一层的神经元数量，研究显示它是影响模型性能的关键因素",
            "高斯过程核": "用于分析模型在初始化时的性能表现，通过比较稀疏有限宽度模型核与无限宽度核之间的距离来预测模型性能",
            "稀疏模型": "指在权重张量中采用随机、静态稀疏模式初始化的模型，研究表明在保持参数数量不变的情况下，稀疏模型的性能与网络宽度密切相关"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 49,
        "title": "ARMOURED: Adversarially Robust MOdels using Unlabeled data by REgularizing Diversity",
        "html": "https://iclr.cc//virtual/2021/poster/3369",
        "abstract": "Adversarial attacks pose a major challenge for modern deep neural networks. Recent advancements show that adversarially robust generalization requires a large amount of labeled data for training. If annotation becomes a burden, can unlabeled data help bridge the gap? In this paper, we propose ARMOURED, an adversarially robust training method based on semi-supervised learning that consists of two components. The first component applies multi-view learning to simultaneously optimize multiple independent networks and utilizes unlabeled data to enforce labeling consistency. The second component reduces adversarial transferability among the networks via diversity regularizers inspired by determinantal point processes and entropy maximization. Experimental results show that under small perturbation budgets, ARMOURED is robust against strong adaptive adversaries. Notably, ARMOURED does not rely on generating adversarial samples during training. When used in combination with adversarial training, ARMOURED yields competitive performance with the state-of-the-art adversarially-robust benchmarks on SVHN and outperforms them on CIFAR-10, while offering higher clean accuracy.",
        "conference": "ICLR",
        "中文标题": "ARMOURED：通过多样性正则化利用未标记数据构建对抗性鲁棒模型",
        "摘要翻译": "对抗性攻击对现代深度神经网络构成了重大挑战。最近的进展表明，对抗性鲁棒的泛化需要大量标记数据进行训练。如果标注成为负担，未标记数据能否帮助弥合这一差距？在本文中，我们提出了ARMOURED，一种基于半监督学习的对抗性鲁棒训练方法，该方法包含两个组成部分。第一个组成部分应用多视图学习同时优化多个独立网络，并利用未标记数据来强制执行标签一致性。第二个组成部分通过受确定性点过程和熵最大化启发的多样性正则化器减少网络间的对抗性可转移性。实验结果表明，在小扰动预算下，ARMOURED对强适应性对手具有鲁棒性。值得注意的是，ARMOURED在训练过程中不依赖于生成对抗样本。当与对抗训练结合使用时，ARMOURED在SVHN上与最先进的对抗性鲁棒基准相比具有竞争力，在CIFAR-10上表现更优，同时提供更高的干净准确率。",
        "领域": "对抗性机器学习、半监督学习、深度神经网络鲁棒性",
        "问题": "如何在标注数据有限的情况下，利用未标记数据提高深度神经网络对抗对抗性攻击的鲁棒性。",
        "动机": "对抗性攻击对深度神经网络的威胁日益增加，而对抗性鲁棒的泛化需要大量标记数据。研究旨在探索未标记数据在提高模型对抗性鲁棒性方面的潜力。",
        "方法": "提出ARMOURED方法，结合多视图学习优化多个独立网络并利用未标记数据强制执行标签一致性，以及通过多样性正则化器减少网络间的对抗性可转移性。",
        "关键词": [
            "对抗性鲁棒性",
            "半监督学习",
            "多视图学习",
            "多样性正则化",
            "对抗性攻击防御"
        ],
        "涉及的技术概念": {
            "多视图学习": "在ARMOURED中用于同时优化多个独立网络，利用未标记数据强制执行标签一致性，以提高模型的对抗性鲁棒性。",
            "多样性正则化器": "受确定性点过程和熵最大化启发，用于减少网络间的对抗性可转移性，增强模型对抗不同攻击的能力。",
            "对抗性训练": "虽然ARMOURED不依赖于生成对抗样本，但与对抗训练结合使用时，能进一步提高模型的对抗性鲁棒性和干净准确率。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 50,
        "title": "Ask Your Humans: Using Human Instructions to Improve Generalization in Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2021/poster/2677",
        "abstract": "Complex, multi-task problems have proven to be difficult to solve efficiently in a sparse-reward reinforcement learning setting. In order to be sample efficient, multi-task learning requires reuse and sharing of low-level policies. To facilitate the automatic decomposition of hierarchical tasks, we propose the use of step-by-step human demonstrations in the form of natural language instructions and action trajectories. We introduce a dataset of such demonstrations in a crafting-based grid world. Our model consists of a high-level language generator and low-level policy, conditioned on language. We find that human demonstrations help solve the most complex tasks. We also find that incorporating natural language allows the model to generalize to unseen tasks in a zero-shot setting and to learn quickly from a few demonstrations. Generalization is not only reflected in the actions of the agent, but also in the generated natural language instructions in unseen tasks. Our approach also gives our trained agent interpretable behaviors because it is able to generate a sequence of high-level descriptions of its actions.",
        "conference": "ICLR",
        "中文标题": "询问人类：利用人类指令提升强化学习的泛化能力",
        "摘要翻译": "复杂、多任务问题在稀疏奖励的强化学习环境中难以高效解决。为了提高样本效率，多任务学习需要重用和共享低级策略。为了促进分层任务的自动分解，我们提出了使用自然语言指令和动作轨迹形式的分步人类示范。我们引入了一个基于制作类网格世界中的此类示范数据集。我们的模型包括一个高级语言生成器和基于语言条件的低级策略。我们发现人类示范有助于解决最复杂的任务。我们还发现，融入自然语言使模型能够在零样本设置下泛化到未见过的任务，并能从少量示范中快速学习。泛化不仅体现在代理的行为上，也体现在未见任务中生成的自然语言指令上。我们的方法还使训练后的代理具有可解释的行为，因为它能够生成一系列高级行为描述。",
        "领域": "强化学习、自然语言处理与视觉结合、多任务学习",
        "问题": "在稀疏奖励的强化学习环境中高效解决复杂、多任务问题",
        "动机": "通过人类示范和自然语言指令提高强化学习模型的样本效率和泛化能力",
        "方法": "使用自然语言指令和动作轨迹的人类示范，构建包含高级语言生成器和低级策略的模型",
        "关键词": [
            "强化学习",
            "自然语言指令",
            "多任务学习",
            "样本效率",
            "泛化能力"
        ],
        "涉及的技术概念": {
            "自然语言指令": "用于提供分步人类示范，指导模型解决复杂任务",
            "高级语言生成器": "生成描述代理行为的高级自然语言指令",
            "低级策略": "基于语言条件执行具体任务，实现任务分解和策略共享"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 51,
        "title": "A statistical theory of cold posteriors in deep neural networks",
        "html": "https://iclr.cc//virtual/2021/poster/2890",
        "abstract": "To get Bayesian neural networks to perform comparably to standard neural networks it is usually necessary to artificially reduce uncertainty using a tempered or cold posterior. This is extremely concerning: if the prior is accurate, Bayes inference/decision theory is optimal, and any artificial changes to the posterior should harm performance. While this suggests that the prior may be at fault, here we argue that in fact, BNNs for image classification use the wrong likelihood. In particular, standard image benchmark datasets such as CIFAR-10 are carefully curated. We develop a generative model describing curation which gives a principled Bayesian account of cold posteriors, because the likelihood under this new generative model closely matches the tempered likelihoods used in past work.",
        "conference": "ICLR",
        "中文标题": "深度神经网络中冷后验的统计理论",
        "摘要翻译": "为了使贝叶斯神经网络的表现与标准神经网络相当，通常需要通过使用温和或冷后验来人为地减少不确定性。这非常令人担忧：如果先验是准确的，贝叶斯推理/决策理论是最优的，任何对后验的人为改变都应该损害性能。虽然这表明先验可能有问题，但我们在这里认为，实际上，用于图像分类的贝叶斯神经网络使用了错误的似然。特别是，标准的图像基准数据集如CIFAR-10是经过精心策划的。我们开发了一个描述策划过程的生成模型，为冷后验提供了一个原则性的贝叶斯解释，因为在这个新的生成模型下的似然与过去工作中使用的温和似然非常匹配。",
        "领域": "贝叶斯深度学习、图像分类、生成模型",
        "问题": "贝叶斯神经网络在图像分类任务中表现不佳的问题",
        "动机": "探讨贝叶斯神经网络在标准图像分类任务中表现不佳的原因，并提出新的理论解释",
        "方法": "开发了一个描述数据集策划过程的生成模型，以解释冷后验现象",
        "关键词": [
            "贝叶斯神经网络",
            "冷后验",
            "图像分类",
            "生成模型",
            "似然函数"
        ],
        "涉及的技术概念": {
            "贝叶斯神经网络": "一种结合了贝叶斯统计和深度学习的神经网络，用于处理不确定性",
            "冷后验": "在贝叶斯推理中，通过调整温度参数来减少后验分布的不确定性",
            "生成模型": "用于描述数据生成过程的统计模型，这里用于解释数据集策划对似然的影响"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 52,
        "title": "Async-RED: A Provably Convergent Asynchronous Block Parallel Stochastic Method using Deep Denoising Priors",
        "html": "https://iclr.cc//virtual/2021/poster/3077",
        "abstract": "Regularization by denoising (RED) is a recently developed framework for solving inverse problems by integrating advanced denoisers as image priors. Recent work has shown its state-of-the-art performance when combined with pre-trained deep denoisers. However, current RED algorithms are inadequate for parallel processing on multicore systems. We address this issue by proposing a new{asynchronous RED (Async-RED) algorithm that enables asynchronous parallel processing of data, making it significantly faster than its serial counterparts for large-scale inverse problems. The computational complexity of Async-RED is further reduced by using a random subset of measurements at every iteration. We present a complete theoretical analysis of the algorithm by establishing its convergence under explicit assumptions on the data-fidelity and the denoiser. We validate Async-RED on image recovery using pre-trained deep denoisers as priors.",
        "conference": "ICLR",
        "中文标题": "Async-RED：一种利用深度去噪先验的可证明收敛的异步块并行随机方法",
        "摘要翻译": "去噪正则化（RED）是最近开发的一个框架，通过将先进的去噪器作为图像先验来解决逆问题。最近的研究表明，当与预训练的深度去噪器结合使用时，它能够达到最先进的性能。然而，当前的RED算法在多核系统上的并行处理能力不足。我们通过提出一种新的异步RED（Async-RED）算法来解决这个问题，该算法能够实现数据的异步并行处理，使其在大规模逆问题上的处理速度显著快于串行版本。通过每次迭代使用随机测量子集，Async-RED的计算复杂度进一步降低。我们通过对算法在数据保真度和去噪器上的明确假设下建立其收敛性，提出了完整的理论分析。我们使用预训练的深度去噪器作为先验，在图像恢复上验证了Async-RED的有效性。",
        "领域": "图像恢复、并行计算、深度学习应用",
        "问题": "当前RED算法在多核系统上的并行处理能力不足，无法高效处理大规模逆问题。",
        "动机": "提高RED算法在多核系统上的并行处理能力，以加速大规模逆问题的解决。",
        "方法": "提出Async-RED算法，支持异步并行处理数据，并通过每次迭代使用随机测量子集降低计算复杂度。",
        "关键词": [
            "异步并行处理",
            "去噪正则化",
            "深度去噪器",
            "图像恢复",
            "大规模逆问题"
        ],
        "涉及的技术概念": {
            "去噪正则化（RED）": "一个通过将先进的去噪器作为图像先验来解决逆问题的框架。",
            "异步并行处理": "Async-RED算法的核心，允许算法在多核系统上高效并行处理数据。",
            "随机测量子集": "用于每次迭代，以降低Async-RED算法的计算复杂度。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 53,
        "title": "A teacher-student framework to distill future trajectories",
        "html": "https://iclr.cc//virtual/2021/poster/3008",
        "abstract": "By learning to predict trajectories of dynamical systems, model-based methods can make extensive use of all observations from past experience. However, due to partial observability, stochasticity, compounding errors, and irrelevant dynamics, training to predict observations explicitly often results in poor models. Model-free techniques try to side-step the problem by learning to predict values directly. While breaking the explicit dependency on future observations can result in strong performance, this usually comes at the cost of low sample efficiency, as the abundant information about the dynamics contained in future observations goes unused. Here we take a step back from both approaches: Instead of hand-designing how trajectories should be incorporated, a teacher network learns to interpret the trajectories and to provide target activations which guide a student model that can only observe the present. The teacher is trained with meta-gradients to maximize the student's performance on a validation set. We show that our approach performs well on tasks that are difficult for model-free and model-based methods, and we study the role of every component through ablation studies.",
        "conference": "ICLR",
        "中文标题": "一个师生框架用于提炼未来轨迹",
        "摘要翻译": "通过学习预测动态系统的轨迹，基于模型的方法可以充分利用过去经验中的所有观察结果。然而，由于部分可观测性、随机性、误差累积以及无关动态，训练以显式预测观察结果往往会导致模型性能不佳。无模型技术试图通过直接学习预测值来规避这个问题。虽然打破对未来观察的显式依赖可以获得强大的性能，但这通常以样本效率低下为代价，因为未来观察中包含的关于动态的丰富信息未被利用。在这里，我们从这两种方法中退一步：不是手工设计如何整合轨迹，而是一个教师网络学习解释轨迹并提供目标激活，这些激活指导一个只能观察当前的学生模型。教师通过元梯度训练，以最大化学生在验证集上的表现。我们展示了我们的方法在对于无模型和基于模型方法都难以处理的任务上表现良好，并通过消融研究研究了每个组件的作用。",
        "领域": "强化学习",
        "问题": "如何在部分可观测性和随机性等挑战下，有效利用未来观察信息提高模型性能",
        "动机": "解决基于模型和无模型方法在利用未来观察信息和样本效率上的局限性",
        "方法": "采用师生框架，教师网络学习解释轨迹并提供目标激活，指导学生模型；教师通过元梯度训练优化学生表现",
        "关键词": [
            "师生框架",
            "轨迹预测",
            "元梯度训练"
        ],
        "涉及的技术概念": {
            "师生框架": "一种教师网络指导学生网络学习的结构，用于有效传递和利用未来观察信息",
            "轨迹预测": "预测动态系统未来状态的技术，用于基于模型的方法中",
            "元梯度训练": "一种训练方法，通过优化教师网络以最大化学生网络在验证集上的表现"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 54,
        "title": "A Temporal Kernel Approach for Deep Learning with Continuous-time Information",
        "html": "https://iclr.cc//virtual/2021/poster/2602",
        "abstract": "Sequential deep learning models such as RNN, causal CNN and attention mechanism do not readily consume continuous-time information. Discretizing the temporal data, as we show, causes inconsistency even for simple continuous-time processes. Current approaches often handle time in a heuristic manner to be consistent with the existing deep learning architectures and implementations. In this paper, we provide a principled way to characterize continuous-time systems using deep learning tools. Notably, the proposed approach applies to all the major deep learning architectures and requires little modifications to the implementation. The critical insight is to represent the continuous-time system by composing neural networks with a temporal kernel, where we gain our intuition from the recent advancements in understanding deep learning with Gaussian process and neural tangent kernel. To represent the temporal kernel, we introduce the random feature approach and convert the kernel learning problem to spectral density estimation under reparameterization. We further prove the convergence and consistency results even when the temporal kernel is non-stationary, and the spectral density is misspecified. The simulations and real-data experiments demonstrate the empirical effectiveness of our temporal kernel approach in a broad range of settings.",
        "conference": "ICLR",
        "中文标题": "一种用于深度学习与连续时间信息处理的时间核方法",
        "摘要翻译": "诸如RNN、因果CNN和注意力机制等序列深度学习模型不易直接处理连续时间信息。如我们所示，对时间数据进行离散化处理，即便是对于简单的连续时间过程，也会导致不一致性。当前的方法往往以启发式的方式处理时间，以与现有的深度学习架构和实现保持一致。在本文中，我们提供了一种原则性的方法，利用深度学习工具来表征连续时间系统。值得注意的是，所提出的方法适用于所有主要的深度学习架构，且对实现所需的修改极少。关键见解是通过将神经网络与时间核组合来表示连续时间系统，我们从最近在理解深度学习与高斯过程和神经切线核方面的进展中获得直觉。为了表示时间核，我们引入了随机特征方法，并将核学习问题转化为重新参数化下的谱密度估计。我们进一步证明了即使时间核是非平稳的，且谱密度被错误指定，收敛性和一致性结果仍然成立。模拟和真实数据实验证明了我们的时间核方法在广泛设置中的实证有效性。",
        "领域": "时间序列分析、深度学习理论、高斯过程",
        "问题": "如何有效地在深度学习中处理和利用连续时间信息",
        "动机": "现有的序列深度学习模型难以直接处理连续时间信息，离散化处理会导致不一致性，需要一种更原则性的方法来表征连续时间系统",
        "方法": "通过将神经网络与时间核组合来表示连续时间系统，引入随机特征方法将核学习问题转化为谱密度估计，并证明了方法的收敛性和一致性",
        "关键词": [
            "时间核方法",
            "连续时间信息",
            "深度学习理论",
            "高斯过程",
            "谱密度估计"
        ],
        "涉及的技术概念": {
            "时间核": "用于在深度学习中表征连续时间系统的核方法，通过组合神经网络与时间核来处理连续时间信息",
            "随机特征方法": "一种将核学习问题转化为谱密度估计的技术，用于表示时间核",
            "谱密度估计": "在重新参数化下估计谱密度的过程，用于解决时间核学习问题"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 55,
        "title": "A Trainable Optimal Transport Embedding for Feature Aggregation and its Relationship to Attention",
        "html": "https://iclr.cc//virtual/2021/poster/2853",
        "abstract": "We address the problem of learning on sets of features, motivated by the need of performing pooling operations in long biological sequences of varying sizes, with long-range dependencies, and possibly few labeled data. To address this challenging task, we introduce a parametrized representation of fixed size, which  embeds and then aggregates elements from a given input set according to the optimal transport plan between the set and a trainable reference. Our approach scales to large datasets and allows end-to-end training of the reference, while also providing a simple unsupervised learning mechanism with small computational cost. Our aggregation technique admits two useful interpretations: it may be seen as a mechanism related to attention layers in neural networks, or it may be seen as a scalable surrogate of a classical optimal transport-based kernel. We experimentally demonstrate the effectiveness of our approach on biological sequences, achieving state-of-the-art results for protein fold recognition and detection of chromatin profiles tasks, and, as a proof of concept, we show promising results for processing natural language sequences. We provide an open-source implementation of our embedding that can be used alone or as a module in larger learning models at https://github.com/claying/OTK.",
        "conference": "ICLR",
        "中文标题": "一种可训练的最优运输嵌入用于特征聚合及其与注意力的关系",
        "摘要翻译": "我们解决了在特征集合上学习的问题，这一问题的动机来自于需要在具有长程依赖性和可能少量标记数据的、长度不等的生物序列中执行池化操作。为了应对这一挑战性任务，我们引入了一种固定大小的参数化表示，该表示根据给定输入集合与可训练参考之间的最优运输计划，嵌入并聚合集合中的元素。我们的方法能够扩展到大型数据集，并允许对参考进行端到端训练，同时提供了一种计算成本低的简单无监督学习机制。我们的聚合技术有两种有用的解释：它可以被视为与神经网络中的注意力层相关的机制，也可以被视为经典基于最优运输的核的可扩展替代。我们在生物序列上实验证明了我们方法的有效性，在蛋白质折叠识别和染色质轮廓检测任务上取得了最先进的结果，并且作为概念验证，我们展示了处理自然语言序列的有希望的结果。我们在https://github.com/claying/OTK上提供了我们嵌入的开源实现，可以单独使用或作为更大学习模型中的模块。",
        "领域": "生物信息学、自然语言处理、深度学习",
        "问题": "在具有长程依赖性和可能少量标记数据的、长度不等的生物序列中执行池化操作的问题",
        "动机": "开发一种能够在大型数据集上扩展，允许端到端训练，并提供简单无监督学习机制的特征聚合方法",
        "方法": "引入一种固定大小的参数化表示，根据输入集合与可训练参考之间的最优运输计划嵌入并聚合集合中的元素",
        "关键词": [
            "最优运输",
            "特征聚合",
            "注意力机制",
            "生物序列",
            "无监督学习"
        ],
        "涉及的技术概念": {
            "最优运输": "用于嵌入和聚合输入集合中的元素，根据集合与可训练参考之间的运输计划",
            "特征聚合": "通过最优运输计划将集合中的元素聚合成固定大小的表示",
            "注意力机制": "与神经网络中的注意力层相关，提供了一种解释聚合技术的视角"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 56,
        "title": "Attentional Constellation Nets for Few-Shot Learning",
        "html": "https://iclr.cc//virtual/2021/poster/3322",
        "abstract": "The success of deep convolutional neural networks builds on top of the learning of effective convolution operations, capturing a hierarchy of structured features via filtering, activation, and pooling. However, the explicit structured features, e.g. object parts, are not expressive in the existing CNN frameworks. In this paper, we tackle the few-shot learning problem and make an effort to enhance structured features by expanding CNNs with a constellation model, which performs cell feature clustering and encoding with a dense part representation; the relationships among the cell features are further modeled by an attention mechanism. With the additional constellation branch to increase the awareness of object parts, our method is able to attain the advantages of the CNNs while making the overall internal representations more robust in the few-shot learning setting. Our approach attains a significant improvement over the existing methods in few-shot learning on the CIFAR-FS, FC100, and mini-ImageNet benchmarks.",
        "conference": "ICLR",
        "中文标题": "注意力星座网络用于少样本学习",
        "摘要翻译": "深度卷积神经网络的成功建立在学习有效卷积操作的基础上，通过滤波、激活和池化捕捉结构化特征的层次。然而，现有的CNN框架中，显式的结构化特征（如物体部分）并不具有表现力。在本文中，我们解决了少样本学习问题，并努力通过用星座模型扩展CNN来增强结构化特征，该模型通过密集部分表示进行细胞特征聚类和编码；细胞特征之间的关系进一步通过注意力机制建模。通过增加星座分支以提高对物体部分的意识，我们的方法能够在少样本学习设置中获得CNN的优势，同时使整体内部表示更加稳健。我们的方法在CIFAR-FS、FC100和mini-ImageNet基准测试中，相对于现有方法取得了显著改进。",
        "领域": "少样本学习",
        "问题": "增强CNN框架中显式结构化特征的表现力，以解决少样本学习问题",
        "动机": "现有的CNN框架在处理少样本学习问题时，显式的结构化特征表现不足，限制了模型的学习能力和泛化性能",
        "方法": "通过引入星座模型和注意力机制，增强CNN对物体部分的识别和表示能力，从而提升少样本学习的效果",
        "关键词": [
            "少样本学习",
            "星座模型",
            "注意力机制",
            "卷积神经网络",
            "结构化特征"
        ],
        "涉及的技术概念": {
            "星座模型": "用于细胞特征聚类和编码，增强模型对物体部分的识别能力",
            "注意力机制": "建模细胞特征之间的关系，提升模型对重要特征的关注",
            "少样本学习": "在数据稀缺的情况下，通过学习少量样本实现有效的模型训练和泛化"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 57,
        "title": "Auction Learning as a Two-Player Game",
        "html": "https://iclr.cc//virtual/2021/poster/2623",
        "abstract": "Designing an incentive compatible auction that maximizes expected revenue is a central problem in Auction Design. While theoretical approaches to the problem have hit some limits, a recent research direction initiated by Duetting et al. (2019) consists in building neural network architectures to find optimal auctions.  We propose two conceptual deviations from their approach which result in enhanced performance. First, we use recent results in theoretical auction design to introduce a time-independent Lagrangian.  This not only circumvents the need for an expensive hyper-parameter search (as in prior work), but also provides a single metric to compare the performance of two auctions (absent from prior work). Second, the optimization procedure in previous work uses an inner maximization loop to compute optimal misreports. We amortize this process through the introduction of an additional neural network. We demonstrate the effectiveness of our approach by learning competitive or strictly improved auctions compared to prior work. Both results together further imply a novel formulation of Auction Design as a two-player game with stationary utility functions.",
        "conference": "ICLR",
        "中文标题": "拍卖学习作为一种双人博弈",
        "摘要翻译": "设计一个激励兼容且能最大化预期收益的拍卖是拍卖设计中的一个核心问题。虽然该问题的理论方法已经遇到了一些限制，但Duetting等人（2019年）发起的一个最新研究方向是构建神经网络架构以寻找最优拍卖。我们提出了两个与他们方法不同的概念性偏差，从而实现了性能的提升。首先，我们利用理论拍卖设计的最新成果引入了一个时间无关的拉格朗日量。这不仅绕过了进行昂贵超参数搜索的需要（如先前工作所示），而且还提供了一个单一的指标来比较两个拍卖的性能（先前工作中缺失的）。其次，先前工作中的优化过程使用了一个内部最大化循环来计算最优的不实报告。我们通过引入一个额外的神经网络来分摊这一过程。我们通过学习到与先前工作相比具有竞争力或严格改进的拍卖，证明了我们方法的有效性。这两个结果共同进一步暗示了拍卖设计作为一种具有静态效用函数的双人博弈的新颖表述。",
        "领域": "拍卖设计、深度学习应用、博弈论",
        "问题": "设计一个激励兼容且能最大化预期收益的拍卖",
        "动机": "克服理论方法在拍卖设计中的限制，通过神经网络架构寻找最优拍卖",
        "方法": "引入时间无关的拉格朗日量和额外的神经网络来优化拍卖设计过程",
        "关键词": [
            "拍卖设计",
            "神经网络",
            "拉格朗日量",
            "双人博弈",
            "激励兼容"
        ],
        "涉及的技术概念": {
            "拉格朗日量": "用于绕过昂贵超参数搜索，提供一个单一指标比较拍卖性能",
            "神经网络": "用于分摊计算最优不实报告的过程，提升拍卖设计的效率",
            "双人博弈": "将拍卖设计表述为具有静态效用函数的双人博弈，提供新颖的研究视角"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 58,
        "title": "Augmenting Physical Models with Deep Networks for Complex Dynamics Forecasting",
        "html": "https://iclr.cc//virtual/2021/poster/3126",
        "abstract": "Forecasting complex dynamical phenomena in settings where only partial knowledge of their dynamics is available is a prevalent problem across various scientific fields. While purely data-driven approaches are arguably insufficient in this context, standard physical modeling based approaches tend to be over-simplistic, inducing non-negligible errors. In this work, we introduce the APHYNITY framework, a principled approach for augmenting incomplete physical dynamics described by differential equations with deep data-driven models. It consists in decomposing the dynamics into two components: a physical component accounting for the dynamics for which we have some prior knowledge, and a data-driven component accounting for errors of the physical model. The learning problem is carefully formulated such that the physical model explains as much of the data as possible, while the data-driven component only describes information that cannot be captured by the physical model, no more, no less. This not only provides the existence and uniqueness for this decomposition, but also ensures interpretability and benefits generalization. Experiments made on three important use cases, each representative of a different family of phenomena, i.e. reaction-diffusion equations, wave equations and the non-linear damped pendulum, show that APHYNITY can efficiently leverage approximate physical models to accurately forecast the evolution of the system and correctly identify relevant physical parameters.",
        "conference": "ICLR",
        "中文标题": "利用深度网络增强物理模型以预测复杂动力学",
        "摘要翻译": "在仅对动力学有部分了解的背景下预测复杂动态现象是多个科学领域中普遍存在的问题。虽然纯数据驱动的方法在这种情况下被认为是不够的，但基于标准物理建模的方法往往过于简化，导致不可忽视的误差。在这项工作中，我们介绍了APHYNITY框架，这是一种原则性的方法，用于通过深度数据驱动模型增强由微分方程描述的不完整物理动力学。它将动力学分解为两个部分：一个物理部分，解释我们有一定先验知识的动力学；以及一个数据驱动部分，解释物理模型的误差。学习问题被精心设计，使得物理模型尽可能多地解释数据，而数据驱动部分仅描述物理模型无法捕获的信息，不多也不少。这不仅为此分解提供了存在性和唯一性，还确保了可解释性并有利于泛化。在三个重要用例上进行的实验，每个用例代表不同类别的现象，即反应-扩散方程、波动方程和非线性阻尼摆，表明APHYNITY可以有效地利用近似物理模型准确预测系统的演化并正确识别相关物理参数。",
        "领域": "复杂系统预测、物理信息神经网络、动力学建模",
        "问题": "在仅部分了解动力学的情况下，如何准确预测复杂动态现象",
        "动机": "解决纯数据驱动方法和标准物理建模方法在预测复杂动态现象时的不足",
        "方法": "提出APHYNITY框架，将动力学分解为物理部分和数据驱动部分，通过深度学习增强不完整的物理模型",
        "关键词": [
            "APHYNITY框架",
            "动力学分解",
            "物理信息神经网络",
            "复杂系统预测",
            "微分方程"
        ],
        "涉及的技术概念": {
            "APHYNITY框架": "一种将物理模型与深度学习相结合的方法，用于增强不完整的物理动力学描述",
            "动力学分解": "将系统动力学分解为物理部分和数据驱动部分，以优化模型性能",
            "物理信息神经网络": "利用物理定律约束神经网络，提高模型的泛化能力和解释性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 59,
        "title": "A Unified Approach to Interpreting and Boosting Adversarial Transferability",
        "html": "https://iclr.cc//virtual/2021/poster/2888",
        "abstract": "In this paper, we use the interaction inside adversarial perturbations to explain and boost the adversarial transferability. We discover and prove the negative correlation between the adversarial transferability and the interaction inside adversarial perturbations. The negative correlation is further verified through different DNNs with various inputs. Moreover, this negative correlation can be regarded as a unified perspective to understand current transferability-boosting methods. To this end, we prove that some classic methods of enhancing the transferability essentially decease interactions inside adversarial perturbations. Based on this, we propose to directly penalize interactions during the attacking process, which significantly improves the adversarial transferability. We will release the code when the paper is accepted.",
        "conference": "ICLR",
        "中文标题": "解释和提升对抗性可转移性的统一方法",
        "摘要翻译": "在本文中，我们利用对抗性扰动内部的相互作用来解释和提升对抗性可转移性。我们发现并证明了对抗性可转移性与对抗性扰动内部相互作用之间的负相关关系。这种负相关关系通过不同深度神经网络和各种输入进一步验证。此外，这种负相关关系可以被视为理解当前提升可转移性方法的统一视角。为此，我们证明了一些经典提升可转移性的方法本质上减少了对抗性扰动内部的相互作用。基于此，我们提出在攻击过程中直接惩罚相互作用，从而显著提高了对抗性可转移性。论文被接受后，我们将发布代码。",
        "领域": "对抗性攻击、深度学习安全、图像识别",
        "问题": "如何解释和提升对抗性样本在不同模型间的可转移性",
        "动机": "探索对抗性扰动内部相互作用与对抗性可转移性之间的关系，以提升对抗性攻击的效果",
        "方法": "通过分析和减少对抗性扰动内部的相互作用来提升对抗性可转移性",
        "关键词": [
            "对抗性可转移性",
            "对抗性扰动",
            "深度神经网络",
            "相互作用惩罚",
            "攻击方法"
        ],
        "涉及的技术概念": {
            "对抗性可转移性": "指对抗性样本在不同模型间保持其欺骗性的能力，是评估对抗性攻击效果的重要指标",
            "对抗性扰动": "添加到原始输入上的微小扰动，旨在使模型产生错误的输出",
            "相互作用惩罚": "在生成对抗性样本的过程中，直接减少扰动内部相互作用的技术，以提高对抗性可转移性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 60,
        "title": "A unifying view on implicit bias in training linear neural networks",
        "html": "https://iclr.cc//virtual/2021/poster/2826",
        "abstract": "We study the implicit bias of gradient flow (i.e., gradient descent with infinitesimal step size) on linear neural network training. We propose a tensor formulation of neural networks that includes fully-connected, diagonal, and convolutional networks as special cases, and investigate the linear version of the formulation called linear tensor networks. With this formulation, we can characterize the convergence direction of the network parameters as singular vectors of a tensor defined by the network. For $L$-layer linear tensor networks that are orthogonally decomposable, we show that gradient flow on separable classification finds a stationary point of the $\\ell_{2/L}$ max-margin problem in a 'transformed' input space defined by the network. For underdetermined regression, we prove that gradient flow finds a global minimum which minimizes a norm-like function that interpolates between weighted $\\ell_1$ and $\\ell_2$ norms in the transformed input space. Our theorems subsume existing results in the literature while removing standard convergence assumptions. We also provide experiments that corroborate our analysis.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "线性神经网络训练中隐式偏差的统一视角",
        "摘要翻译": "我们研究了梯度流（即，步长无限小的梯度下降）在线性神经网络训练中的隐式偏差。我们提出了一种神经网络的张量公式，它包括全连接、对角和卷积网络作为特殊情况，并研究了该公式的线性版本，称为线性张量网络。通过这种公式，我们可以将网络参数的收敛方向描述为由网络定义的张量的奇异向量。对于正交可分解的L层线性张量网络，我们表明，在由网络定义的“转换”输入空间中，可分离分类的梯度流找到了l_{2/L}最大边距问题的驻点。对于欠定回归，我们证明了梯度流找到了一个全局最小值，该最小值最小化了一个范数类函数，该函数在转换后的输入空间中在加权l_1和l_2范数之间进行插值。我们的定理涵盖了文献中现有的结果，同时消除了标准收敛假设。我们还提供了实验来证实我们的分析。",
        "领域": "神经网络优化, 线性模型, 理论分析",
        "问题": "研究线性神经网络训练中梯度流的隐式偏差，并找到其收敛方向和解。",
        "动机": "理解梯度下降在线性神经网络训练中的行为，并为其收敛特性提供理论保证，从而克服现有研究中存在的收敛性假设。",
        "方法": "提出了一种统一的线性张量网络公式，将不同类型的线性网络统一表示，并通过分析该公式下的梯度流，推导出其收敛方向和解的性质。使用奇异值分解和范数分析等数学工具。",
        "关键词": [
            "隐式偏差",
            "线性神经网络",
            "梯度流",
            "张量网络",
            "最大边距"
        ],
        "涉及的技术概念": {
            "隐式偏差": "指在优化过程中，即使有多个解都能达到最优，优化算法（如梯度下降）会倾向于选择具有特定性质的解。论文研究了梯度流在线性神经网络训练中倾向于选择何种解。",
            "梯度流": "指的是步长无限小的梯度下降，是一种连续的优化方法，便于进行理论分析。论文利用梯度流来分析线性神经网络的收敛行为。"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 61,
        "title": "A Universal Representation Transformer Layer for Few-Shot Image Classification",
        "html": "https://iclr.cc//virtual/2021/poster/2568",
        "abstract": "Few-shot classification aims to recognize unseen classes when presented with only a small number of samples. We consider the problem of multi-domain few-shot image classification, where unseen classes and examples come from diverse data sources. This problem has seen growing interest and has inspired the development of benchmarks such as Meta-Dataset. A key challenge in this multi-domain setting is to effectively integrate the feature representations from the diverse set of training domains. Here, we propose a Universal Representation Transformer (URT) layer, that meta-learns to leverage universal features for few-shot classification by dynamically re-weighting and composing the most appropriate domain-specific representations. In experiments, we show that URT sets a new state-of-the-art result on Meta-Dataset. Specifically, it achieves top-performance on the highest number of data sources compared to competing methods. We analyze variants of URT and present a visualization of the attention score heatmaps that sheds light on how the model performs cross-domain generalization.",
        "conference": "ICLR",
        "中文标题": "用于少样本图像分类的通用表示变换器层",
        "摘要翻译": "少样本分类旨在仅提供少量样本时识别未见过的类别。我们考虑多领域少样本图像分类问题，其中未见过的类别和样本来自多样化的数据源。这一问题引起了越来越多的兴趣，并激发了如Meta-Dataset等基准的开发。在这一多领域设置中，一个关键挑战是如何有效地整合来自多样化训练领域的特征表示。在此，我们提出了一种通用表示变换器（URT）层，它通过动态重新加权和组合最合适的领域特定表示，元学习利用通用特征进行少样本分类。在实验中，我们展示了URT在Meta-Dataset上设定了新的最先进结果。具体来说，与竞争方法相比，它在最多数量的数据源上实现了最佳性能。我们分析了URT的变体，并展示了注意力分数热图的可视化，揭示了模型如何进行跨领域泛化。",
        "领域": "少样本学习, 多领域学习, 图像分类",
        "问题": "解决多领域少样本图像分类中如何有效整合多样化训练领域的特征表示的问题",
        "动机": "为了在多领域少样本图像分类中实现更好的跨领域泛化能力",
        "方法": "提出通用表示变换器（URT）层，通过动态重新加权和组合最合适的领域特定表示，元学习利用通用特征进行少样本分类",
        "关键词": [
            "少样本学习",
            "多领域学习",
            "通用表示变换器",
            "元学习",
            "跨领域泛化"
        ],
        "涉及的技术概念": {
            "通用表示变换器（URT）层": "通过动态重新加权和组合最合适的领域特定表示，元学习利用通用特征进行少样本分类的技术",
            "元学习": "使模型能够快速适应新任务的学习方法，在本研究中用于优化URT层的训练",
            "注意力分数热图": "用于可视化模型在进行跨领域泛化时的注意力分布，帮助理解模型的工作原理"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 62,
        "title": "AutoLRS: Automatic Learning-Rate Schedule by Bayesian Optimization on the Fly",
        "html": "https://iclr.cc//virtual/2021/poster/3054",
        "abstract": "The learning rate (LR) schedule is one of the most important hyper-parameters needing careful tuning in training DNNs. However, it is also one of the least automated parts of machine learning systems and usually costs significant manual effort and computing. Though there are pre-defined LR schedules and optimizers with adaptive LR, they introduce new hyperparameters that need to be tuned separately for different tasks/datasets. In this paper, we consider the question: Can we automatically tune the LR over the course of training without human involvement? We propose an efficient method, AutoLRS, which automatically optimizes the LR for each training stage by modeling training dynamics. AutoLRS aims to find an LR that minimizes the validation loss, every $\\tau$ steps. We formulate it as black-box optimization and solve it by Bayesian optimization (BO). However, collecting training instances for BO requires a system to evaluate each LR queried by BO's acquisition function for $\\tau$ steps, which is prohibitively expensive in practice. Instead, we apply each candidate LR for only $\\tau'\\ll\\tau$ steps and train an exponential model to predict the validation loss after $\\tau$ steps. This mutual-training process between BO and the exponential model allows us to bound the number of training steps invested in the BO search. We demonstrate the advantages and the generality of AutoLRS through extensive experiments of training DNNs from diverse domains and using different optimizers. The LR schedules auto-generated by AutoLRS leads to a speedup of $1.22\\times$, $1.43\\times$, and $1.5\\times$ when training ResNet-50, Transformer, and BERT, respectively, compared to the LR schedules in their original papers, and an average speedup of $1.31\\times$ over state-of-the-art highly tuned LR schedules.",
        "conference": "ICLR",
        "中文标题": "AutoLRS：通过动态贝叶斯优化自动学习率调度",
        "摘要翻译": "学习率（LR）调度是训练深度神经网络（DNNs）时需要仔细调整的最重要超参数之一。然而，它也是机器学习系统中最不自动化的部分之一，通常需要大量手动努力和计算。尽管有预定义的学习率调度和具有自适应学习率的优化器，但它们引入了新的超参数，需要针对不同的任务/数据集单独调整。在本文中，我们考虑一个问题：我们能否在训练过程中无需人工干预自动调整学习率？我们提出了一种高效的方法，AutoLRS，它通过建模训练动态自动优化每个训练阶段的学习率。AutoLRS旨在找到一个最小化验证损失的学习率，每τ步。我们将其表述为黑盒优化问题，并通过贝叶斯优化（BO）来解决。然而，为BO收集训练实例需要一个系统来评估BO的获取函数查询的每个学习率τ步，这在实际中是极其昂贵的。相反，我们仅对每个候选学习率应用τ'≪τ步，并训练一个指数模型来预测τ步后的验证损失。BO和指数模型之间的这种相互训练过程使我们能够限制在BO搜索中投入的训练步骤数量。我们通过对来自不同领域和使用不同优化器的DNNs进行广泛实验，展示了AutoLRS的优势和通用性。与原始论文中的学习率调度相比，AutoLRS自动生成的学习率调度在训练ResNet-50、Transformer和BERT时分别实现了1.22倍、1.43倍和1.5倍的加速，并且与最先进的高度调整的学习率调度相比，平均加速1.31倍。",
        "领域": "深度学习优化、自动机器学习、超参数优化",
        "问题": "自动调整深度神经网络训练过程中的学习率，减少人工干预和计算成本",
        "动机": "减少深度神经网络训练中学习率调度的手动调整需求，提高训练效率和自动化水平",
        "方法": "提出AutoLRS方法，通过贝叶斯优化和指数模型预测自动优化每个训练阶段的学习率",
        "关键词": [
            "自动学习率调度",
            "贝叶斯优化",
            "深度神经网络训练",
            "超参数优化",
            "训练动态建模"
        ],
        "涉及的技术概念": {
            "贝叶斯优化": "用于自动调整学习率的黑盒优化方法，通过建模训练动态寻找最优学习率",
            "指数模型": "用于预测τ步后验证损失的模型，减少贝叶斯优化过程中的计算成本",
            "学习率调度": "深度神经网络训练中调整学习率的策略，影响模型训练的效率和最终性能"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 63,
        "title": "Autoregressive Dynamics Models for Offline Policy Evaluation and Optimization",
        "html": "https://iclr.cc//virtual/2021/poster/2845",
        "abstract": "Standard dynamics models for continuous control make use of feedforward computation to predict the conditional distribution of next state and reward given current state and action using a multivariate Gaussian with a diagonal covariance structure. This modeling choice assumes that different dimensions of the next state and reward are conditionally independent given the current state and action and may be driven by the fact that fully observable physics-based simulation environments entail deterministic transition dynamics. In this paper, we challenge this conditional independence assumption and propose a family of expressive autoregressive dynamics models that generate different dimensions of the next state and reward sequentially conditioned on previous dimensions. We demonstrate that autoregressive dynamics models indeed outperform standard feedforward models in log-likelihood on heldout transitions. Furthermore, we compare different model-based and model-free off-policy evaluation (OPE) methods on RL Unplugged, a suite of offline MuJoCo datasets, and find that autoregressive dynamics models consistently outperform all baselines, achieving a new state-of-the-art. Finally, we show that autoregressive dynamics models are useful for offline policy optimization by serving as a way to enrich the replay buffer through data augmentation and improving performance using model-based planning.\n",
        "conference": "ICLR",
        "中文标题": "自回归动态模型在离线策略评估与优化中的应用",
        "摘要翻译": "标准的连续控制动态模型利用前馈计算，通过具有对角协方差结构的多变量高斯分布，预测给定当前状态和动作的下一个状态和奖励的条件分布。这种建模选择假设下一个状态和奖励的不同维度在给定当前状态和动作的条件下是独立的，可能是由于完全可观察的基于物理的仿真环境涉及确定性转移动态。在本文中，我们挑战了这一条件独立性假设，并提出了一系列表达性强的自回归动态模型，这些模型在先前维度的条件下顺序生成下一个状态和奖励的不同维度。我们证明，在保留转换的对数似然上，自回归动态模型确实优于标准的前馈模型。此外，我们在RL Unplugged——一套离线MuJoCo数据集上比较了不同的基于模型和无模型的离线策略评估（OPE）方法，发现自回归动态模型始终优于所有基线，达到了新的最先进水平。最后，我们展示了自回归动态模型通过数据增强丰富回放缓冲区和利用基于模型的规划提高性能，对离线策略优化是有用的。",
        "领域": "强化学习、连续控制、离线策略评估",
        "问题": "解决标准动态模型在预测下一个状态和奖励时假设条件独立性的问题",
        "动机": "挑战现有动态模型的条件独立性假设，提高模型在离线策略评估和优化中的表现",
        "方法": "提出并评估一系列表达性强的自回归动态模型，用于顺序生成下一个状态和奖励的不同维度",
        "关键词": [
            "自回归动态模型",
            "离线策略评估",
            "连续控制",
            "数据增强",
            "模型规划"
        ],
        "涉及的技术概念": {
            "自回归动态模型": "一种顺序生成下一个状态和奖励不同维度的模型，用于挑战条件独立性假设",
            "离线策略评估（OPE）": "评估策略在离线数据集上的表现，无需在线交互",
            "数据增强": "通过自回归动态模型生成新数据，丰富回放缓冲区，提高策略优化效果"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 64,
        "title": "Autoregressive Entity Retrieval",
        "html": "https://iclr.cc//virtual/2021/poster/2642",
        "abstract": "Entities are at the center of how we represent and aggregate knowledge. For instance, Encyclopedias such as Wikipedia are structured by entities (e.g., one per Wikipedia article). The ability to retrieve such entities given a query is fundamental for knowledge-intensive tasks such as entity linking and open-domain question answering. One way to understand current approaches is as classifiers among atomic labels, one for each entity. Their weight vectors are dense entity representations produced by encoding entity meta information such as their descriptions. This approach leads to several shortcomings: (i) context and entity affinity is mainly captured through a vector dot product, potentially missing fine-grained interactions between the two; (ii) a large memory footprint is needed to store dense representations when considering large entity sets; (iii) an appropriately hard set of negative data has to be subsampled at training time. In this work, we propose GENRE, the first system that retrieves entities by generating their unique names, left to right, token-by-token in an autoregressive fashion and conditioned on the context. This enables us to mitigate the aforementioned technical issues since: (i) the autoregressive formulation allows us to directly capture relations between context and entity name, effectively cross encoding both; (ii) the memory footprint is greatly reduced because the parameters of our encoder-decoder architecture scale with vocabulary size, not entity count; (iii) the exact softmax loss can be efficiently computed without the need to subsample negative data. We show the efficacy of the approach, experimenting with more than 20 datasets on entity disambiguation, end-to-end entity linking and document retrieval tasks, achieving new state-of-the-art or very competitive results while using a tiny fraction of the memory footprint of competing systems. Finally, we demonstrate that new entities can be added by simply specifying their unambiguous name. Code and pre-trained models at https://github.com/facebookresearch/GENRE.",
        "conference": "ICLR",
        "中文标题": "自回归实体检索",
        "摘要翻译": "实体是我们表示和聚合知识的核心。例如，像维基百科这样的百科全书就是由实体（如每个维基百科文章一个实体）构成的。给定查询检索这些实体的能力对于知识密集型任务（如实体链接和开放领域问答）至关重要。理解当前方法的一种方式是将其视为原子标签之间的分类器，每个实体一个标签。它们的权重向量是通过编码实体元信息（如它们的描述）产生的密集实体表示。这种方法导致了几个缺点：（i）上下文和实体亲和性主要通过向量点积捕获，可能错过两者之间的细粒度交互；（ii）在考虑大型实体集时，需要大量内存来存储密集表示；（iii）在训练时需要适当硬负数据的子样本。在这项工作中，我们提出了GENRE，第一个通过以自回归方式从左到右逐个令牌生成它们的唯一名称来检索实体的系统，并基于上下文进行条件化。这使我们能够缓解上述技术问题，因为：（i）自回归公式允许我们直接捕获上下文和实体名称之间的关系，有效地交叉编码两者；（ii）内存占用大大减少，因为我们的编码器-解码器架构的参数与词汇量大小成比例，而不是实体数量；（iii）可以高效计算精确的softmax损失，无需子样本负数据。我们展示了该方法的有效性，在实体消歧、端到端实体链接和文档检索任务上实验了超过20个数据集，实现了新的最先进或非常有竞争力的结果，同时仅使用竞争系统内存占用的一小部分。最后，我们证明了可以通过简单地指定它们的明确名称来添加新实体。代码和预训练模型可在https://github.com/facebookresearch/GENRE获取。",
        "领域": "实体链接, 开放领域问答, 文档检索",
        "问题": "当前实体检索方法在捕获上下文与实体间的细粒度交互、内存占用大以及需要硬负数据子样本方面存在不足",
        "动机": "提出一种新的实体检索方法，以解决现有技术在交互捕获、内存占用和训练效率方面的限制",
        "方法": "采用自回归生成实体唯一名称的方法，通过编码器-解码器架构减少内存占用并提高交互捕获能力",
        "关键词": [
            "自回归",
            "实体检索",
            "GENRE",
            "编码器-解码器",
            "softmax损失"
        ],
        "涉及的技术概念": {
            "自回归": "在实体检索中，通过逐个令牌生成实体名称来捕获上下文与实体间的细粒度交互",
            "编码器-解码器架构": "用于减少模型的内存占用，参数规模与词汇量而非实体数量相关",
            "softmax损失": "在训练过程中高效计算，无需子样本负数据，提高训练效率"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 65,
        "title": "Auto Seg-Loss: Searching Metric Surrogates for Semantic Segmentation",
        "html": "https://iclr.cc//virtual/2021/poster/2992",
        "abstract": "Designing proper loss functions is essential in training deep networks. Especially in the field of semantic segmentation, various evaluation metrics have been proposed for diverse scenarios. Despite the success of the widely adopted cross-entropy loss and its variants, the mis-alignment between the loss functions and evaluation metrics degrades the network performance. Meanwhile, manually designing loss functions for each specific metric requires expertise and significant manpower. In this paper, we propose to automate the design of metric-specific loss functions by searching differentiable surrogate losses for each metric. We substitute the non-differentiable operations in the metrics with parameterized functions, and conduct parameter search to optimize the shape of loss surfaces. Two constraints are introduced to regularize the search space and make the search efficient. Extensive experiments on PASCAL VOC and Cityscapes demonstrate that the searched surrogate losses outperform the manually designed loss functions consistently. The searched losses can generalize well to other datasets and networks. Code shall be released at https://github.com/fundamentalvision/Auto-Seg-Loss.",
        "conference": "ICLR",
        "中文标题": "自动分割损失：为语义分割搜索度量替代品",
        "摘要翻译": "设计合适的损失函数对于训练深度网络至关重要。特别是在语义分割领域，针对不同场景提出了各种评估指标。尽管广泛采用的交叉熵损失及其变体取得了成功，但损失函数与评估指标之间的不对齐降低了网络性能。同时，为每个特定指标手动设计损失函数需要专业知识和大量人力。在本文中，我们提出通过为每个指标搜索可微分的替代损失来自动设计特定于指标的损失函数。我们用参数化函数替换了指标中的不可微分操作，并进行参数搜索以优化损失表面的形状。引入了两个约束来正则化搜索空间并使搜索高效。在PASCAL VOC和Cityscapes上的大量实验表明，搜索到的替代损失一致优于手动设计的损失函数。搜索到的损失能够很好地泛化到其他数据集和网络。代码将在https://github.com/fundamentalvision/Auto-Seg-Loss发布。",
        "领域": "语义分割、深度学习优化、自动机器学习",
        "问题": "解决语义分割中损失函数与评估指标不对齐的问题，以及手动设计损失函数的高成本问题。",
        "动机": "自动化设计特定于评估指标的损失函数，以提高语义分割模型的性能并减少人工设计的需求。",
        "方法": "通过搜索可微分的替代损失函数来自动设计特定于指标的损失函数，使用参数化函数替换不可微分操作，并引入约束优化搜索过程。",
        "关键词": [
            "语义分割",
            "损失函数自动设计",
            "度量替代",
            "深度学习优化",
            "参数搜索"
        ],
        "涉及的技术概念": {
            "可微分替代损失": "用于替换评估指标中的不可微分操作，使得损失函数可以直接优化评估指标。",
            "参数化函数": "在搜索过程中用于替代不可微分操作的函数，其形状通过参数搜索优化。",
            "搜索空间正则化": "通过引入约束来限制搜索空间，提高搜索效率并确保找到的损失函数具有良好的泛化能力。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 66,
        "title": "Auxiliary Learning by Implicit Differentiation",
        "html": "https://iclr.cc//virtual/2021/poster/2638",
        "abstract": "Training neural networks with auxiliary tasks is a common practice for improving the performance on a main task of interest.\nTwo main challenges arise in this multi-task learning setting: (i) designing useful auxiliary tasks; and (ii) combining auxiliary tasks into a single coherent loss. Here, we propose a novel framework, AuxiLearn, that targets both challenges based on implicit differentiation. First, when useful auxiliaries are known, we propose learning a network that combines all losses into a single coherent objective function. This network can learn non-linear interactions between tasks. Second, when no useful auxiliary task is known, we describe how to learn a network that generates a meaningful, novel auxiliary task. We evaluate AuxiLearn in a series of tasks and domains, including image segmentation and learning with attributes in the low data regime, and find that it consistently outperforms competing methods.",
        "conference": "ICLR",
        "中文标题": "通过隐式微分进行辅助学习",
        "摘要翻译": "通过辅助任务训练神经网络是提高主要任务性能的常见做法。在这种多任务学习设置中，出现了两个主要挑战：（i）设计有用的辅助任务；（ii）将辅助任务组合成一个连贯的损失函数。在此，我们提出了一个基于隐式微分的新框架AuxiLearn，旨在解决这两个挑战。首先，当已知有用的辅助任务时，我们提出学习一个将所有损失组合成单一连贯目标函数的网络。该网络可以学习任务之间的非线性交互。其次，当没有已知的有用辅助任务时，我们描述了如何学习一个生成有意义、新颖辅助任务的网络。我们在包括图像分割和低数据量下的属性学习等一系列任务和领域中评估了AuxiLearn，发现它始终优于竞争方法。",
        "领域": "图像分割, 多任务学习, 低数据量学习",
        "问题": "如何设计有用的辅助任务并将它们有效地组合到多任务学习中以提高主要任务的性能",
        "动机": "解决多任务学习中设计有用辅助任务和将它们组合成连贯损失函数的挑战",
        "方法": "提出基于隐式微分的新框架AuxiLearn，学习组合所有损失的目标函数网络或生成新颖辅助任务的网络",
        "关键词": [
            "隐式微分",
            "多任务学习",
            "辅助任务",
            "图像分割",
            "低数据量学习"
        ],
        "涉及的技术概念": {
            "隐式微分": "用于学习组合所有损失的目标函数网络或生成新颖辅助任务的网络的技术",
            "多任务学习": "同时学习多个相关任务以提高主要任务性能的学习范式",
            "辅助任务": "为提高主要任务性能而设计的额外学习任务"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 67,
        "title": "Auxiliary Task Update Decomposition: The Good, the Bad and the Neutral",
        "html": "https://iclr.cc//virtual/2021/poster/2674",
        "abstract": "While deep learning has been very beneficial in data-rich settings, tasks with smaller training set\noften resort to pre-training or multitask learning to leverage data from other tasks. In this case,\ncareful consideration is needed to select tasks and model parameterizations such that updates from\nthe auxiliary tasks actually help the primary task. We seek to alleviate this burden by formulating a model-agnostic framework that performs fine-grained manipulation of the auxiliary task gradients. We propose to decompose auxiliary updates into directions which help, damage or leave the primary task loss unchanged. This allows weighting the update directions \ndifferently depending on their impact on the problem of interest. We present a novel and efficient algorithm for that\npurpose and show its advantage in practice. Our method leverages efficient automatic differentiation \nprocedures and randomized singular value decomposition for scalability. We show that our framework is \ngeneric and encompasses some prior work as particular cases. Our approach consistently outperforms strong and widely used baselines when leveraging out-of-distribution data for Text and Image classification tasks.",
        "conference": "ICLR",
        "中文标题": "辅助任务更新分解：有益、有害与中性",
        "摘要翻译": "尽管深度学习在数据丰富的环境中非常有益，但在训练集较小的任务中，常常需要借助预训练或多任务学习来利用其他任务的数据。在这种情况下，需要仔细考虑任务选择和模型参数化，以确保来自辅助任务的更新实际上有助于主要任务。我们旨在通过制定一个模型无关的框架来减轻这一负担，该框架对辅助任务的梯度进行细粒度操作。我们提出将辅助更新分解为有助于、损害或对主要任务损失无影响的方向。这允许根据更新方向对感兴趣问题的影响不同而进行不同的加权。我们为此提出了一种新颖且高效的算法，并在实践中展示了其优势。我们的方法利用了高效的自动微分程序和随机奇异值分解以实现可扩展性。我们展示了我们的框架是通用的，并将一些先前的工作作为特例包含在内。在利用分布外数据进行文本和图像分类任务时，我们的方法始终优于强大且广泛使用的基线。",
        "领域": "多任务学习, 文本分类, 图像分类",
        "问题": "如何在多任务学习中有效利用辅助任务的梯度更新来帮助主要任务",
        "动机": "减轻在多任务学习中选择辅助任务和模型参数化的负担，提高主要任务的性能",
        "方法": "提出一个模型无关的框架，通过分解辅助任务的梯度更新方向，并根据其对主要任务的影响进行不同加权",
        "关键词": [
            "多任务学习",
            "梯度分解",
            "自动微分",
            "随机奇异值分解",
            "分布外数据"
        ],
        "涉及的技术概念": {
            "梯度分解": "将辅助任务的梯度更新分解为对主要任务有益、有害或中性的方向",
            "自动微分": "用于高效计算梯度的技术，支持框架的可扩展性",
            "随机奇异值分解": "用于处理大规模数据，提高算法的效率和可扩展性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 68,
        "title": "Average-case Acceleration for Bilinear Games and Normal Matrices",
        "html": "https://iclr.cc//virtual/2021/poster/3051",
        "abstract": "Advances in generative modeling and adversarial learning have given rise to renewed interest in smooth games. However, the absence of symmetry in the matrix of second derivatives poses challenges that are not present in the classical minimization framework. While a rich theory of average-case analysis has been developed for minimization problems, little is known in the context of smooth games. In this work we take a first step towards closing this gap by developing average-case optimal first-order methods for a subset of smooth games. \nWe make the following three main contributions. First, we show that for zero-sum bilinear games the average-case optimal method is the optimal method for the minimization of the Hamiltonian. Second, we provide an explicit expression for the optimal method corresponding to normal matrices, potentially non-symmetric. Finally, we specialize it to matrices with eigenvalues located in a disk and show a provable speed-up compared to worst-case optimal algorithms. We illustrate our findings through benchmarks with a varying degree of mismatch with our assumptions.",
        "conference": "ICLR",
        "中文标题": "双线性游戏与正规矩阵的平均情况加速",
        "摘要翻译": "生成模型和对抗学习的进展重新激发了人们对平滑游戏的兴趣。然而，二阶导数矩阵中对称性的缺失带来了经典最小化框架中不存在的挑战。尽管针对最小化问题已经发展出了一套丰富的平均情况分析理论，但在平滑游戏的背景下知之甚少。在这项工作中，我们通过为一部分平滑游戏开发平均情况最优的一阶方法，迈出了填补这一空白的第一步。我们做出了以下三个主要贡献。首先，我们证明了对于零和双线性游戏，平均情况最优方法是最小化哈密顿量的最优方法。其次，我们为对应于正规矩阵（可能非对称）的最优方法提供了一个明确的表达式。最后，我们将其特化为特征值位于圆盘内的矩阵，并展示了与最坏情况最优算法相比的可证明加速。我们通过与假设不同程度不匹配的基准测试来阐明我们的发现。",
        "领域": "生成对抗网络、优化算法、博弈论",
        "问题": "解决平滑游戏中由于二阶导数矩阵不对称性带来的挑战，以及缺乏平均情况分析理论的问题。",
        "动机": "填补平滑游戏领域平均情况分析理论的空白，开发针对特定平滑游戏的平均情况最优一阶方法。",
        "方法": "开发针对零和双线性游戏的平均情况最优方法，为正规矩阵提供最优方法的明确表达式，并将其特化为特征值位于圆盘内的矩阵。",
        "关键词": [
            "平滑游戏",
            "平均情况分析",
            "双线性游戏",
            "正规矩阵",
            "优化算法"
        ],
        "涉及的技术概念": {
            "平滑游戏": "研究中的主要对象，指的是在生成模型和对抗学习中出现的优化问题。",
            "平均情况分析": "用于评估算法在平均输入情况下的性能，与最坏情况分析相对。",
            "正规矩阵": "研究中处理的一类可能非对称的矩阵，其最优方法的表达式被明确给出。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 69,
        "title": "A Wigner-Eckart Theorem for Group Equivariant Convolution Kernels",
        "html": "https://iclr.cc//virtual/2021/poster/2543",
        "abstract": "Group equivariant convolutional networks (GCNNs) endow classical convolutional networks with additional symmetry priors, which can lead to a considerably improved performance. Recent advances in the theoretical description of GCNNs revealed that such models can generally be understood as performing convolutions with $G$-steerable kernels, that is, kernels that satisfy an equivariance constraint themselves. While the $G$-steerability constraint has been derived, it has to date only been solved for specific use cases - a general characterization of $G$-steerable kernel spaces is still missing. This work provides such a characterization for the practically relevant case of $G$ being any compact group. Our investigation is motivated by a striking analogy between the constraints underlying steerable kernels on the one hand and spherical tensor operators from quantum mechanics on the other hand. By generalizing the famous Wigner-Eckart theorem for spherical tensor operators, we prove that steerable kernel spaces are fully understood and parameterized in terms of 1) generalized reduced matrix elements, 2) Clebsch-Gordan coefficients, and 3) harmonic basis functions on homogeneous spaces.",
        "conference": "ICLR",
        "中文标题": "群等变卷积核的Wigner-Eckart定理",
        "摘要翻译": "群等变卷积网络（GCNNs）为经典卷积网络赋予了额外的对称性先验，这可以显著提高性能。GCNNs理论描述的最新进展表明，这类模型通常可以理解为使用$G$-可操纵核进行卷积，即核本身满足等变性约束。虽然$G$-可操纵性约束已被推导出来，但迄今为止仅针对特定用例进行了求解——$G$-可操纵核空间的一般特征仍然缺失。这项工作为$G$为任何紧群的实际情况提供了这样的特征。我们的研究动机来自于可操纵核的约束与量子力学中的球张量算子之间惊人的类比。通过推广著名的球张量算子的Wigner-Eckart定理，我们证明了可操纵核空间可以通过以下三个方面完全理解和参数化：1)广义约化矩阵元素，2)Clebsch-Gordan系数，以及3)齐次空间上的调和基函数。",
        "领域": "群等变神经网络、对称性学习、量子机器学习",
        "问题": "如何一般性地描述和参数化群等变卷积网络中的$G$-可操纵核空间",
        "动机": "通过类比量子力学中的球张量算子，解决群等变卷积网络中$G$-可操纵核空间的一般特征缺失问题",
        "方法": "推广Wigner-Eckart定理，利用广义约化矩阵元素、Clebsch-Gordan系数和调和基函数来理解和参数化可操纵核空间",
        "关键词": [
            "群等变卷积网络",
            "Wigner-Eckart定理",
            "可操纵核",
            "对称性学习",
            "量子机器学习"
        ],
        "涉及的技术概念": {
            "群等变卷积网络": "一种赋予经典卷积网络额外对称性先验的模型，以提高性能",
            "Wigner-Eckart定理": "量子力学中描述球张量算子矩阵元素的定理，本文中推广用于理解和参数化可操纵核空间",
            "可操纵核": "满足特定等变性约束的核，用于群等变卷积网络中"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 70,
        "title": "Bag of Tricks for Adversarial Training",
        "html": "https://iclr.cc//virtual/2021/poster/2754",
        "abstract": "Adversarial training (AT) is one of the most effective strategies for promoting model robustness. However, recent benchmarks show that most of the proposed improvements on AT are less effective than simply early stopping the training procedure. This counter-intuitive fact motivates us to investigate the implementation details of tens of AT methods. Surprisingly, we find that the basic settings (e.g., weight decay, training schedule, etc.) used in these methods are highly inconsistent. In this work, we provide comprehensive evaluations on CIFAR-10, focusing on the effects of mostly overlooked training tricks and hyperparameters for adversarially trained models. Our empirical observations suggest that adversarial robustness is much more sensitive to some basic training settings than we thought. For example, a slightly different value of weight decay can reduce the model robust accuracy by more than $7\\%$, which is probable to override the potential promotion induced by the proposed methods. We conclude a baseline training setting and re-implement previous defenses to achieve new state-of-the-art results. These facts also appeal to more concerns on the overlooked confounders when benchmarking defenses.",
        "conference": "ICLR",
        "中文标题": "对抗训练的实用技巧集",
        "摘要翻译": "对抗训练（AT）是提升模型鲁棒性最有效的策略之一。然而，最近的基准测试表明，大多数针对AT提出的改进方法效果不如简单地提前终止训练过程。这一反直觉的事实促使我们调查了数十种AT方法的实现细节。令人惊讶的是，我们发现这些方法中使用的基本设置（如权重衰减、训练计划等）高度不一致。在这项工作中，我们在CIFAR-10上进行了全面评估，重点关注了对抗训练模型中大多被忽视的训练技巧和超参数的影响。我们的实证观察表明，对抗鲁棒性对一些基本训练设置的敏感度远超我们的想象。例如，权重衰减值的轻微不同可以使模型的鲁棒准确率下降超过7%，这很可能会覆盖由所提出方法带来的潜在提升。我们总结了一个基线训练设置，并重新实现了之前的防御方法，以达到新的最先进结果。这些事实也呼吁在基准测试防御方法时，对忽视的混杂因素给予更多关注。",
        "领域": "对抗样本防御、模型鲁棒性优化、深度学习训练技巧",
        "问题": "对抗训练中基本训练设置的不一致性和被忽视的训练技巧对模型鲁棒性的影响",
        "动机": "调查和解决对抗训练中基本设置不一致的问题，以及探索被忽视的训练技巧对提升模型鲁棒性的潜力",
        "方法": "通过全面评估CIFAR-10数据集，分析不同训练技巧和超参数对对抗训练模型鲁棒性的影响，并总结出一个基线训练设置",
        "关键词": [
            "对抗训练",
            "模型鲁棒性",
            "训练技巧",
            "超参数优化",
            "CIFAR-10"
        ],
        "涉及的技术概念": {
            "对抗训练（AT）": "一种通过引入对抗样本来训练模型，以提高其对抗攻击下的鲁棒性的技术",
            "权重衰减": "一种正则化技术，用于防止模型过拟合，通过惩罚大的权重值来控制模型的复杂度",
            "鲁棒准确率": "模型在对抗攻击下的准确率，衡量模型对抗样本的抵抗能力"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 71,
        "title": "Balancing Constraints and Rewards with Meta-Gradient D4PG",
        "html": "https://iclr.cc//virtual/2021/poster/2639",
        "abstract": "Deploying Reinforcement Learning (RL) agents to solve real-world applications often requires satisfying complex system constraints. Often the constraint thresholds are incorrectly set due to the complex nature of a system or the inability to verify the thresholds offline (e.g, no simulator or reasonable offline evaluation procedure exists). This results in solutions where a task cannot be solved without violating the constraints. However, in many real-world cases, constraint violations are undesirable yet they are not catastrophic, motivating the need for soft-constrained RL approaches. We present two soft-constrained RL approaches that utilize meta-gradients to find a good trade-off between expected return and minimizing constraint violations. We demonstrate the effectiveness of these approaches by showing that they consistently outperform the baselines across four different Mujoco domains.",
        "conference": "ICLR",
        "中文标题": "利用元梯度D4PG平衡约束与奖励",
        "摘要翻译": "部署强化学习（RL）代理以解决现实世界应用时，常常需要满足复杂的系统约束。由于系统的复杂性或无法离线验证约束阈值（例如，没有模拟器或合理的离线评估程序存在），约束阈值经常被错误设置。这导致在不违反约束的情况下无法解决任务。然而，在许多现实世界的情况下，违反约束是不希望的，但它们并非灾难性的，这促使了对软约束RL方法的需求。我们提出了两种利用元梯度的软约束RL方法，以在预期回报和最小化约束违反之间找到良好的平衡。通过展示这些方法在四个不同的Mujoco领域中始终优于基线，我们证明了这些方法的有效性。",
        "领域": "强化学习、机器人控制、自动决策",
        "问题": "在强化学习中平衡预期回报与约束违反的问题",
        "动机": "现实世界应用中，硬约束可能导致任务无法解决，而软约束方法可以在不满足所有约束的情况下找到可行的解决方案",
        "方法": "提出了两种利用元梯度的软约束强化学习方法，以优化预期回报和约束违反之间的权衡",
        "关键词": [
            "元梯度",
            "软约束强化学习",
            "D4PG",
            "Mujoco",
            "约束优化"
        ],
        "涉及的技术概念": {
            "元梯度": "用于调整学习算法本身的参数，以优化在预期回报和约束违反之间的权衡",
            "软约束强化学习": "允许在某种程度上违反约束，以找到在不完全满足所有约束情况下的可行解决方案",
            "D4PG": "分布式深度确定性策略梯度，一种用于连续动作空间的强化学习算法"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 72,
        "title": "Batch Reinforcement Learning Through Continuation Method",
        "html": "https://iclr.cc//virtual/2021/poster/3290",
        "abstract": "Many real-world applications of reinforcement learning (RL) require the agent to learn from a fixed set of trajectories, without collecting new interactions.  Policy optimization under this setting is extremely challenging as: 1) the geometry of the objective function is hard to optimize efficiently; 2) the shift of data distributions causes high noise in the value estimation. In this work, we propose a simple yet effective policy iteration approach to batch RL using global optimization techniques known as continuation.  By constraining the difference between the learned policy and the behavior policy that generates the fixed trajectories, and continuously relaxing the constraint, our method 1) helps the agent escape local optima; 2) reduces the error in policy evaluation in the optimization procedure.   We present results on a variety of control tasks, game environments, and a recommendation task to empirically demonstrate the efficacy of our proposed method.",
        "conference": "ICLR",
        "中文标题": "通过延续方法进行批量强化学习",
        "摘要翻译": "强化学习（RL）的许多实际应用要求智能体从一组固定的轨迹中学习，而无需收集新的交互。在这种设置下进行策略优化极具挑战性，原因在于：1）目标函数的几何形状难以高效优化；2）数据分布的变化导致价值估计中存在高噪声。在这项工作中，我们提出了一种简单而有效的策略迭代方法，用于批量RL，采用称为延续的全局优化技术。通过限制学习策略与生成固定轨迹的行为策略之间的差异，并持续放松这一限制，我们的方法1）帮助智能体逃离局部最优；2）减少了优化过程中策略评估的误差。我们在多种控制任务、游戏环境和推荐任务上展示了结果，以实证证明我们提出方法的有效性。",
        "领域": "强化学习、策略优化、推荐系统",
        "问题": "在固定轨迹集上进行策略优化时面临的几何优化困难和数据分布变化导致的价值估计噪声问题。",
        "动机": "解决在固定数据集上进行强化学习时遇到的策略优化难题，包括逃离局部最优和减少策略评估误差。",
        "方法": "提出了一种基于延续方法的策略迭代方法，通过限制学习策略与行为策略的差异并逐步放松这一限制来优化策略。",
        "关键词": [
            "批量强化学习",
            "策略优化",
            "延续方法",
            "全局优化",
            "推荐系统"
        ],
        "涉及的技术概念": {
            "延续方法": "一种全局优化技术，用于帮助策略优化逃离局部最优解。",
            "策略迭代": "通过迭代更新策略来优化性能的方法。",
            "行为策略": "生成固定轨迹的策略，用于限制学习策略的更新以避免过大的分布偏移。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 73,
        "title": "Bayesian Context Aggregation for Neural Processes",
        "html": "https://iclr.cc//virtual/2021/poster/3148",
        "abstract": "Formulating scalable probabilistic regression models with reliable uncertainty estimates has been a long-standing challenge in machine learning research.  Recently, casting probabilistic regression as a multi-task learning problem in terms of conditional latent variable (CLV) models such as the Neural Process (NP) has shown promising results. In this paper, we focus on context aggregation, a central component of such architectures, which fuses information from multiple context data points. So far, this aggregation operation has been treated separately from the inference of a latent representation of the target function in CLV models. Our key contribution is to combine these steps into one holistic mechanism by phrasing context aggregation as a Bayesian inference problem. The resulting Bayesian Aggregation (BA) mechanism enables principled handling of task ambiguity, which is key for efficiently processing context information. We demonstrate on a range of challenging experiments that BA consistently improves upon the performance of traditional mean aggregation while remaining computationally efficient and fully compatible with existing NP-based models.",
        "conference": "ICLR",
        "中文标题": "神经过程的贝叶斯上下文聚合",
        "摘要翻译": "构建具有可靠不确定性估计的可扩展概率回归模型一直是机器学习研究中的一个长期挑战。最近，将概率回归视为条件潜变量（CLV）模型（如神经过程（NP））中的多任务学习问题，已显示出有希望的结果。在本文中，我们专注于上下文聚合，这是此类架构的一个核心组件，它融合了来自多个上下文数据点的信息。到目前为止，这种聚合操作在CLV模型中被视为与目标函数的潜在表示推断分开处理。我们的关键贡献是通过将上下文聚合表述为一个贝叶斯推断问题，将这些步骤结合成一个整体机制。由此产生的贝叶斯聚合（BA）机制能够原则性地处理任务模糊性，这是高效处理上下文信息的关键。我们在一系列具有挑战性的实验中证明，BA在保持计算效率且完全兼容现有基于NP的模型的同时，持续优于传统的均值聚合性能。",
        "领域": "概率回归模型, 多任务学习, 贝叶斯推断",
        "问题": "如何在概率回归模型中有效地进行上下文信息聚合，并处理任务模糊性。",
        "动机": "为了解决概率回归模型中上下文聚合与潜在表示推断分离处理的问题，提高模型处理上下文信息的效率和准确性。",
        "方法": "通过将上下文聚合表述为贝叶斯推断问题，提出贝叶斯聚合（BA）机制，实现上下文聚合与潜在表示推断的结合。",
        "关键词": [
            "贝叶斯聚合",
            "神经过程",
            "概率回归",
            "多任务学习",
            "上下文信息处理"
        ],
        "涉及的技术概念": {
            "贝叶斯聚合（BA）": "将上下文聚合表述为贝叶斯推断问题，实现上下文信息的高效处理和任务模糊性的原则性处理。",
            "神经过程（NP）": "一种条件潜变量模型，用于概率回归，通过多任务学习框架处理不确定性估计。",
            "条件潜变量（CLV）模型": "用于概率回归和多任务学习的模型框架，通过潜在变量表示目标函数的不确定性。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 74,
        "title": "Bayesian Few-Shot Classification with One-vs-Each Pólya-Gamma Augmented Gaussian Processes",
        "html": "https://iclr.cc//virtual/2021/poster/3334",
        "abstract": "Few-shot classification (FSC), the task of adapting a classifier to unseen classes given a small labeled dataset, is an important step on the path toward human-like machine learning. Bayesian methods are well-suited to tackling the fundamental issue of overfitting in the few-shot scenario because they allow practitioners to specify prior beliefs and update those beliefs in light of observed data. Contemporary approaches to Bayesian few-shot classification maintain a posterior distribution over model parameters, which is slow and requires storage that scales with model size. Instead, we propose a Gaussian process classifier based on a novel combination of Pólya-Gamma augmentation and the one-vs-each softmax approximation that allows us to efficiently marginalize over functions rather than model parameters. We demonstrate improved accuracy and uncertainty quantification on both standard few-shot classification benchmarks and few-shot domain transfer tasks.",
        "conference": "ICLR",
        "中文标题": "基于一对一每种Pólya-Gamma增强高斯过程的贝叶斯少样本分类",
        "摘要翻译": "少样本分类（FSC）是在给定少量标记数据集的情况下，将分类器适应于未见过的类别的任务，这是实现类人机器学习的重要一步。贝叶斯方法非常适合解决少样本场景中的过拟合这一基本问题，因为它们允许实践者指定先验信念并根据观察到的数据更新这些信念。当代的贝叶斯少样本分类方法维持了对模型参数的后验分布，这既缓慢又需要与模型大小成比例的存储空间。相反，我们提出了一种基于Pólya-Gamma增强和一对一每种softmax近似的新颖组合的高斯过程分类器，这使我们能够有效地对函数而非模型参数进行边缘化。我们在标准的少样本分类基准和少样本领域转移任务上展示了改进的准确性和不确定性量化。",
        "领域": "少样本学习, 高斯过程, 贝叶斯方法",
        "问题": "解决少样本分类中的过拟合问题，并提高分类准确性和不确定性量化。",
        "动机": "为了克服当代贝叶斯少样本分类方法在计算效率和存储需求上的限制，提出一种更高效的方法。",
        "方法": "提出了一种基于Pólya-Gamma增强和一对一每种softmax近似的高斯过程分类器，以实现对函数的高效边缘化。",
        "关键词": [
            "少样本分类",
            "高斯过程",
            "贝叶斯方法",
            "Pólya-Gamma增强",
            "一对一每种softmax近似"
        ],
        "涉及的技术概念": {
            "Pólya-Gamma增强": "用于高效边缘化处理的技术，通过引入辅助变量来简化计算。",
            "一对一每种softmax近似": "一种softmax函数的近似方法，用于多类分类问题，减少计算复杂度。",
            "高斯过程分类器": "一种基于高斯过程的分类方法，能够提供预测的不确定性量化。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 75,
        "title": "Behavioral Cloning from Noisy Demonstrations",
        "html": "https://iclr.cc//virtual/2021/poster/3110",
        "abstract": "We consider the problem of learning an optimal expert behavior policy given noisy demonstrations that contain observations from both optimal and non-optimal expert behaviors. Popular imitation learning algorithms, such as generative adversarial imitation learning, assume that (clear) demonstrations are given from optimal expert policies but not the non-optimal ones, and thus often fail to imitate the optimal expert behaviors given the noisy demonstrations. Prior works that address the problem require (1) learning policies through environment interactions in the same fashion as reinforcement learning, and (2) annotating each demonstration with confidence scores or rankings. However, such environment interactions and annotations in real-world settings take impractically long training time and a significant human effort. In this paper, we propose an imitation learning algorithm to address the problem without any environment interactions and annotations associated with the non-optimal demonstrations. The proposed algorithm learns ensemble policies with a generalized behavioral cloning (BC) objective function where we exploit another policy already learned by BC. Experimental results show that the proposed algorithm can learn behavior policies that are much closer to the optimal policies than ones learned by BC.",
        "conference": "ICLR",
        "中文标题": "从噪声演示中进行行为克隆",
        "摘要翻译": "我们考虑在包含最优和非最优专家行为观察的噪声演示中学习最优专家行为策略的问题。流行的模仿学习算法，如生成对抗模仿学习，假设（清晰的）演示来自最优专家策略而非非最优策略，因此在给定噪声演示时往往无法模仿最优专家行为。先前解决该问题的工作需要（1）以与强化学习相同的方式通过环境交互学习策略，以及（2）为每个演示标注置信度分数或排名。然而，在现实世界设置中，这样的环境交互和标注需要不切实际的长时间训练和大量人力。在本文中，我们提出了一种模仿学习算法，无需任何与非最优演示相关的环境交互和标注即可解决该问题。所提出的算法通过学习集成策略与广义行为克隆（BC）目标函数，其中我们利用已通过BC学习的另一个策略。实验结果表明，所提出的算法可以学习到比通过BC学习的策略更接近最优策略的行为策略。",
        "领域": "模仿学习、行为克隆、强化学习",
        "问题": "在包含最优和非最优专家行为的噪声演示中学习最优专家行为策略",
        "动机": "解决现有模仿学习算法在噪声演示中无法有效模仿最优专家行为的问题，同时避免不切实际的环境交互和人力标注需求",
        "方法": "提出一种无需环境交互和标注的模仿学习算法，通过学习集成策略与广义行为克隆目标函数，利用已通过BC学习的策略",
        "关键词": [
            "行为克隆",
            "模仿学习",
            "噪声演示",
            "集成策略",
            "广义目标函数"
        ],
        "涉及的技术概念": {
            "行为克隆": "一种通过观察专家行为来学习策略的技术，本文中用于从噪声演示中提取最优行为策略",
            "模仿学习": "通过模仿专家行为来学习策略的机器学习方法，本文中用于解决噪声演示中的最优行为学习问题",
            "集成策略": "结合多个策略以提高性能的方法，本文中用于通过学习多个策略来逼近最优专家行为"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 76,
        "title": "Benchmarks for Deep Off-Policy Evaluation",
        "html": "https://iclr.cc//virtual/2021/poster/3066",
        "abstract": "Off-policy evaluation (OPE) holds the promise of being able to leverage large, offline datasets for both evaluating and selecting complex policies for decision making. The ability to learn offline is particularly important in many real-world domains, such as in healthcare, recommender systems, or robotics, where online data collection is an expensive and potentially dangerous process. Being able to accurately evaluate and select high-performing policies without requiring online interaction could yield significant benefits in safety, time, and cost for these applications. While many OPE methods have been proposed in recent years, comparing results between papers is difficult because currently there is a lack of a comprehensive and unified benchmark, and measuring algorithmic progress has been challenging due to the lack of difficult evaluation tasks. In order to address this gap, we present a collection of policies that in conjunction with existing offline datasets can be used for benchmarking off-policy evaluation. Our tasks include a range of challenging high-dimensional continuous control problems, with wide selections of datasets and policies for performing policy selection. The goal of our benchmark is to provide a standardized measure of progress that is motivated from a set of principles designed to challenge and test the limits of existing OPE methods. We perform an evaluation of state-of-the-art algorithms and provide open-source access to our data and code to foster future research in this area.    ",
        "conference": "ICLR",
        "中文标题": "深度离策略评估的基准",
        "摘要翻译": "离策略评估（OPE）有望利用大型离线数据集来评估和选择用于决策制定的复杂策略。在许多现实世界领域，如医疗保健、推荐系统或机器人技术中，离线学习的能力尤为重要，因为在线数据收集是一个昂贵且可能危险的过程。能够在不需在线交互的情况下准确评估和选择高性能策略，可以为这些应用带来安全、时间和成本上的显著好处。尽管近年来提出了许多OPE方法，但由于目前缺乏全面统一的基准，比较不同论文之间的结果变得困难，并且由于缺乏困难的评估任务，衡量算法进展一直具有挑战性。为了填补这一空白，我们提出了一系列策略，这些策略与现有的离线数据集结合可用于基准测试离策略评估。我们的任务包括一系列具有挑战性的高维连续控制问题，以及广泛的数据集和策略选择。我们的基准测试的目标是提供一个标准化的进展衡量标准，这一标准源自一组旨在挑战和测试现有OPE方法极限的原则。我们对最先进的算法进行了评估，并提供了我们的数据和代码的开源访问，以促进该领域的未来研究。",
        "领域": "强化学习、医疗保健决策支持、机器人控制",
        "问题": "缺乏全面统一的基准来比较不同离策略评估方法的效果",
        "动机": "为了在不需要在线交互的情况下准确评估和选择高性能策略，提高安全性和效率",
        "方法": "提出了一系列策略与现有离线数据集结合用于基准测试，包括高维连续控制问题和广泛的数据集和策略选择",
        "关键词": [
            "离策略评估",
            "基准测试",
            "连续控制",
            "策略选择",
            "开源数据"
        ],
        "涉及的技术概念": {
            "离策略评估（OPE）": "利用离线数据集评估和选择决策策略的技术",
            "高维连续控制问题": "涉及高维状态和动作空间的复杂控制任务",
            "策略选择": "从多个候选策略中选择最优策略的过程"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 77,
        "title": "Benefit of deep learning with non-convex noisy gradient descent: Provable excess risk bound and superiority to kernel methods",
        "html": "https://iclr.cc//virtual/2021/poster/2725",
        "abstract": "Establishing a theoretical analysis that explains why deep learning can outperform shallow learning such as kernel methods is one of the biggest issues in the deep learning literature. Towards answering this question, we evaluate excess risk of a deep learning estimator trained by a noisy gradient descent with ridge regularization on a mildly overparameterized neural network, \nand discuss its superiority to a class of linear estimators that includes neural tangent kernel approach, random feature model, other kernel methods, $k$-NN estimator and so on. We consider a teacher-student regression model, and eventually show that {\\it any} linear estimator can be outperformed by deep learning in a sense of the minimax optimal rate especially for a high dimension setting. The obtained excess bounds are so-called fast learning rate which is faster than $O(1/\\sqrt{n})$ that is obtained by usual Rademacher complexity analysis. This discrepancy is induced by the non-convex geometry of the model and the noisy gradient descent used for neural network training provably reaches a near global optimal solution even though the loss landscape is highly non-convex. Although the noisy gradient descent does not employ any explicit or implicit sparsity inducing regularization, it shows a preferable generalization performance that dominates linear estimators.",
        "conference": "ICLR",
        "中文标题": "深度学习与非凸噪声梯度下降的优势：可证明的过剩风险界限及对核方法的优越性",
        "摘要翻译": "建立一个理论分析来解释为什么深度学习可以超越浅层学习（如核方法）是深度学习文献中最大的问题之一。为了回答这个问题，我们评估了在轻度过参数化神经网络上通过带有岭正则化的噪声梯度下降训练的深度学习估计器的过剩风险，并讨论了其对一类线性估计器（包括神经切线核方法、随机特征模型、其他核方法、k-近邻估计器等）的优越性。我们考虑了一个教师-学生回归模型，并最终表明，在高维设置下，深度学习可以在极小极大最优速率的意义上超越任何线性估计器。获得的过剩界限是所谓的快速学习率，比通常通过Rademacher复杂性分析获得的O(1/√n)更快。这种差异是由模型的非凸几何形状引起的，并且用于神经网络训练的噪声梯度下降可证明地达到了接近全局最优解，即使损失景观高度非凸。尽管噪声梯度下降没有采用任何显式或隐式的稀疏性诱导正则化，但它显示出优于线性估计器的泛化性能。",
        "领域": "深度学习理论分析、神经网络优化、核方法比较",
        "问题": "解释深度学习为何能超越浅层学习（如核方法）的理论基础",
        "动机": "为了填补深度学习理论分析的空白，特别是在解释其相对于浅层学习方法（如核方法）优越性方面的理论依据",
        "方法": "在轻度过参数化神经网络上应用带有岭正则化的噪声梯度下降，评估其过剩风险并与线性估计器进行比较",
        "关键词": [
            "深度学习理论",
            "过剩风险",
            "噪声梯度下降",
            "非凸优化",
            "核方法"
        ],
        "涉及的技术概念": {
            "过剩风险": "评估估计器性能的指标，表示估计器风险与最优可能风险之间的差异",
            "噪声梯度下降": "一种优化算法，通过在梯度下降过程中引入噪声来帮助逃离局部最优，特别适用于非凸优化问题",
            "非凸优化": "指优化问题的目标函数具有多个局部最优解，这使得寻找全局最优解变得复杂，但在深度学习中，噪声梯度下降等方法能够有效处理"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 78,
        "title": "BERTology Meets Biology: Interpreting Attention in Protein Language Models",
        "html": "https://iclr.cc//virtual/2021/poster/3057",
        "abstract": "Transformer architectures have proven to learn useful representations for protein classification and generation tasks. However, these representations present challenges in interpretability. In this work, we demonstrate a set of methods for analyzing protein Transformer models through the lens of attention. We show that attention: (1) captures the folding structure of proteins, connecting amino acids that are far apart in the underlying sequence, but spatially close in the three-dimensional structure, (2) targets binding sites, a key functional component of proteins, and (3) focuses on progressively more complex biophysical properties with increasing layer depth. We find this behavior to be consistent across three Transformer architectures (BERT, ALBERT, XLNet) and two distinct protein datasets. We also present a three-dimensional visualization of the interaction between attention and protein structure. Code for visualization and analysis is available at https://github.com/salesforce/provis.",
        "conference": "ICLR",
        "中文标题": "BERTology遇见生物学：解读蛋白质语言模型中的注意力机制",
        "摘要翻译": "Transformer架构已被证明能够学习对蛋白质分类和生成任务有用的表示。然而，这些表示在可解释性方面存在挑战。在这项工作中，我们展示了一套通过注意力视角分析蛋白质Transformer模型的方法。我们表明，注意力：（1）捕捉蛋白质的折叠结构，连接在基础序列中相距较远但在三维结构中空间上接近的氨基酸，（2）靶向结合位点，这是蛋白质的关键功能组成部分，以及（3）随着层深的增加，关注逐渐更复杂的生物物理特性。我们发现这种行为在三种Transformer架构（BERT、ALBERT、XLNet）和两个不同的蛋白质数据集中是一致的。我们还展示了注意力与蛋白质结构之间相互作用的三维可视化。可视化和分析的代码可在https://github.com/salesforce/provis获取。",
        "领域": "蛋白质结构预测, 生物信息学, 深度学习与生物学结合",
        "问题": "提高蛋白质Transformer模型的可解释性",
        "动机": "探索和解释Transformer模型在蛋白质序列分析中的注意力机制如何捕捉蛋白质的结构和功能特性",
        "方法": "通过分析注意力机制在蛋白质Transformer模型中的应用，揭示其如何捕捉蛋白质的折叠结构、靶向结合位点以及关注复杂的生物物理特性",
        "关键词": [
            "蛋白质语言模型",
            "注意力机制",
            "Transformer架构",
            "生物信息学",
            "三维可视化"
        ],
        "涉及的技术概念": {
            "注意力机制": "用于分析模型如何关注蛋白质序列中的特定部分，揭示结构和功能关系",
            "Transformer架构": "提供了一种强大的框架，用于学习蛋白质序列的复杂表示",
            "三维可视化": "帮助直观展示注意力机制与蛋白质三维结构之间的相互作用"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 79,
        "title": "Better Fine-Tuning by Reducing Representational Collapse",
        "html": "https://iclr.cc//virtual/2021/poster/3061",
        "abstract": "Although widely adopted, existing approaches for fine-tuning pre-trained language models have been shown to be unstable across hyper-parameter settings, motivating recent work on trust region methods. In this paper, we present a simplified and efficient method rooted in trust region theory that replaces previously used adversarial objectives with parametric noise (sampling from either a normal or uniform distribution), thereby discouraging representation change during fine-tuning when possible without hurting performance. We also introduce a new analysis to motivate the use of trust region methods more generally, by studying representational collapse; the degradation of generalizable representations from pre-trained models as they are fine-tuned for a specific end task. Extensive experiments show that our fine-tuning method matches or exceeds the performance of previous trust region methods on a range of understanding and generation tasks (including DailyMail/CNN, Gigaword, Reddit TIFU, and the GLUE benchmark), while also being much faster. We also show that it is less prone to representation collapse; the pre-trained models maintain more generalizable representations every time they are fine-tuned.",
        "conference": "ICLR",
        "中文标题": "通过减少表征崩溃实现更好的微调",
        "摘要翻译": "尽管现有方法广泛应用于预训练语言模型的微调，但它们在超参数设置上表现出不稳定性，这促使了最近关于信任区域方法的研究。在本文中，我们提出了一种基于信任区域理论的简化高效方法，该方法用参数化噪声（从正态或均匀分布中采样）替代了之前使用的对抗性目标，从而在不损害性能的情况下尽可能减少微调过程中的表征变化。我们还引入了一种新的分析来更广泛地激励信任区域方法的使用，通过研究表征崩溃；即预训练模型在为特定终端任务微调时，其可泛化表征的退化。大量实验表明，我们的微调方法在一系列理解和生成任务（包括DailyMail/CNN、Gigaword、Reddit TIFU和GLUE基准测试）上的表现与之前的信任区域方法相当或更优，同时速度更快。我们还表明，它更不容易出现表征崩溃；预训练模型在每次微调时都能保持更多的可泛化表征。",
        "领域": "自然语言处理与视觉结合, 语言模型微调, 表征学习",
        "问题": "解决预训练语言模型在微调过程中的不稳定性和表征崩溃问题",
        "动机": "提高预训练语言模型微调的稳定性和效率，同时减少表征崩溃，保持模型的可泛化性",
        "方法": "基于信任区域理论，使用参数化噪声替代对抗性目标，减少微调过程中的表征变化",
        "关键词": [
            "语言模型微调",
            "信任区域方法",
            "表征崩溃",
            "参数化噪声",
            "可泛化表征"
        ],
        "涉及的技术概念": {
            "信任区域理论": "用于指导微调过程，确保模型更新不会导致性能下降的理论基础",
            "参数化噪声": "替代对抗性目标，用于在微调过程中引入随机性，减少表征变化的技术手段",
            "表征崩溃": "预训练模型在微调过程中可泛化表征退化的现象，影响模型性能"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 80,
        "title": "Beyond Categorical Label Representations for Image Classification",
        "html": "https://iclr.cc//virtual/2021/poster/3226",
        "abstract": "We find that the way we choose to represent data labels can have a profound effect on the quality of trained models. For example, training an image classifier to regress audio labels rather than traditional categorical probabilities produces a more reliable classification. This result is surprising, considering that audio labels are more complex than simpler numerical probabilities or text. We hypothesize that high dimensional, high entropy label representations are generally more useful because they provide a stronger error signal. We support this hypothesis with evidence from various label representations including constant matrices, spectrograms, shuffled spectrograms, Gaussian mixtures, and uniform random matrices of various dimensionalities. Our experiments reveal that high dimensional, high entropy labels achieve comparable accuracy to text (categorical) labels on standard image classification tasks, but features learned through our label representations exhibit more robustness under various adversarial attacks and better effectiveness with a limited amount of training data. These results suggest that label representation may play a more important role than previously thought.",
        "conference": "ICLR",
        "中文标题": "超越分类标签表示的图像分类",
        "摘要翻译": "我们发现选择表示数据标签的方式对训练模型的质量有深远影响。例如，训练一个图像分类器回归音频标签而非传统的分类概率，能产生更可靠的分类结果。这一结果令人惊讶，考虑到音频标签比简单的数值概率或文本更为复杂。我们假设高维度、高熵值的标签表示通常更有用，因为它们提供了更强的错误信号。我们通过包括常数矩阵、频谱图、打乱的频谱图、高斯混合以及各种维度的均匀随机矩阵在内的多种标签表示的证据来支持这一假设。我们的实验表明，在标准的图像分类任务上，高维度、高熵值的标签能达到与文本（分类）标签相当的准确度，但通过我们的标签表示学习到的特征在各种对抗攻击下表现出更强的鲁棒性，并且在有限的训练数据下更有效。这些结果表明，标签表示的作用可能比之前认为的更为重要。",
        "领域": "图像分类、对抗性攻击防御、小样本学习",
        "问题": "探索不同标签表示对图像分类模型性能的影响",
        "动机": "研究高维度、高熵值标签表示是否能提供更强的错误信号，从而提升模型的鲁棒性和在小样本情况下的有效性",
        "方法": "通过实验比较不同标签表示（包括音频标签、常数矩阵、频谱图等）在图像分类任务中的表现，分析其对模型性能的影响",
        "关键词": [
            "标签表示",
            "高熵值",
            "对抗鲁棒性",
            "小样本学习",
            "图像分类"
        ],
        "涉及的技术概念": {
            "高熵值标签表示": "用于提供更强的错误信号，帮助模型学习更鲁棒的特征",
            "对抗攻击": "测试模型在不同标签表示下对对抗样本的鲁棒性",
            "小样本学习": "研究在有限训练数据下，不同标签表示对模型性能的影响"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 81,
        "title": "Beyond Fully-Connected Layers with Quaternions: Parameterization of Hypercomplex Multiplications with $1/n$ Parameters",
        "html": "https://iclr.cc//virtual/2021/poster/3068",
        "abstract": "Recent works have demonstrated reasonable success of representation learning in hypercomplex space. Specifically, “fully-connected layers with quaternions” (quaternions are 4D hypercomplex numbers), which replace real-valued matrix multiplications in fully-connected layers with Hamilton products of quaternions, both enjoy parameter savings with only 1/4 learnable parameters and achieve comparable performance in various applications. However, one key caveat is that hypercomplex space only exists at very few predefined dimensions (4D, 8D, and 16D). This restricts the flexibility of models that leverage hypercomplex multiplications. To this end, we propose parameterizing hypercomplex multiplications, allowing models to learn multiplication rules from data regardless of whether such rules are predefined. As a result, our method not only subsumes the Hamilton product, but also learns to operate on any arbitrary $n$D hypercomplex space, providing more architectural flexibility using arbitrarily $1/n$ learnable parameters compared with the fully-connected layer counterpart. Experiments of applications to the LSTM and transformer models on natural language inference, machine translation, text style transfer, and subject verb agreement demonstrate architectural flexibility and effectiveness of the proposed approach.",
        "conference": "ICLR",
        "中文标题": "超越四元数全连接层：用1/n参数参数化超复数乘法",
        "摘要翻译": "最近的研究表明，在超复数空间中进行表示学习取得了一定的成功。具体来说，“四元数全连接层”（四元数是4维超复数），用四元数的汉密尔顿乘积替代全连接层中的实值矩阵乘法，不仅节省了参数，仅需1/4的可学习参数，而且在各种应用中实现了可比的性能。然而，一个关键的注意事项是，超复数空间仅存在于少数预定义的维度（4维、8维和16维）。这限制了利用超复数乘法的模型的灵活性。为此，我们提出了参数化超复数乘法的方法，允许模型从数据中学习乘法规则，无论这些规则是否预定义。因此，我们的方法不仅包含了汉密尔顿乘积，还能学习在任何任意n维超复数空间上操作，与全连接层相比，使用任意1/n的可学习参数提供了更多的架构灵活性。在自然语言推理、机器翻译、文本风格转换和主谓一致等应用中对LSTM和Transformer模型的实验证明了所提出方法的架构灵活性和有效性。",
        "领域": "自然语言处理与视觉结合, 深度学习模型优化, 超复数表示学习",
        "问题": "超复数空间仅存在于少数预定义的维度，限制了模型的灵活性。",
        "动机": "提高模型在超复数空间中的灵活性，允许学习任意维度的超复数乘法规则。",
        "方法": "提出参数化超复数乘法的方法，使模型能够从数据中学习乘法规则，适用于任意维度的超复数空间。",
        "关键词": [
            "超复数乘法",
            "参数化",
            "深度学习模型",
            "架构灵活性",
            "表示学习"
        ],
        "涉及的技术概念": {
            "超复数空间": "扩展了复数概念的高维空间，用于表示学习。",
            "汉密尔顿乘积": "四元数乘法的一种形式，用于替代传统全连接层中的矩阵乘法。",
            "参数化超复数乘法": "提出的新方法，允许模型学习任意维度的超复数乘法规则，提高模型灵活性。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 82,
        "title": "Bidirectional Variational Inference for Non-Autoregressive Text-to-Speech",
        "html": "https://iclr.cc//virtual/2021/poster/3115",
        "abstract": "Although early text-to-speech (TTS) models such as Tacotron 2 have succeeded in generating human-like speech, their autoregressive architectures have several limitations: (1) They require a lot of time to generate a mel-spectrogram consisting of hundreds of steps. (2) The autoregressive speech generation shows a lack of robustness due to its error propagation property. In this paper, we propose a novel non-autoregressive TTS model called BVAE-TTS, which eliminates the architectural limitations and generates a mel-spectrogram in parallel. BVAE-TTS adopts a bidirectional-inference variational autoencoder (BVAE) that learns hierarchical latent representations using both bottom-up and top-down paths to increase its expressiveness. To apply BVAE to TTS, we design our model to utilize text information via an attention mechanism. By using attention maps that BVAE-TTS generates, we train a duration predictor so that the model uses the predicted duration of each phoneme at inference. In experiments conducted on LJSpeech dataset, we show that our model generates a mel-spectrogram 27 times faster than Tacotron 2 with similar speech quality. Furthermore, our BVAE-TTS outperforms Glow-TTS, which is one of the state-of-the-art non-autoregressive TTS models, in terms of both speech quality and inference speed while having 58% fewer parameters.",
        "conference": "ICLR",
        "中文标题": "双向变分推理用于非自回归文本到语音转换",
        "摘要翻译": "尽管早期的文本到语音（TTS）模型如Tacotron 2在生成类人语音方面取得了成功，但其自回归架构存在几个限制：（1）生成包含数百步的梅尔频谱图需要大量时间。（2）自回归语音生成由于其错误传播特性显示出鲁棒性不足。在本文中，我们提出了一种名为BVAE-TTS的新型非自回归TTS模型，该模型消除了架构限制并并行生成梅尔频谱图。BVAE-TTS采用了一种双向推理变分自编码器（BVAE），该编码器通过自下而上和自上而下的路径学习层次潜在表示以增加其表达能力。为了将BVAE应用于TTS，我们设计了我们的模型以通过注意力机制利用文本信息。通过使用BVAE-TTS生成的注意力图，我们训练了一个持续时间预测器，以便模型在推理时使用每个音素的预测持续时间。在LJSpeech数据集上进行的实验中，我们展示了我们的模型生成梅尔频谱图的速度比Tacotron 2快27倍，同时保持相似的语音质量。此外，我们的BVAE-TTS在语音质量和推理速度方面均优于最先进的非自回归TTS模型之一Glow-TTS，同时参数减少了58%。",
        "领域": "语音合成, 变分自编码器, 非自回归模型",
        "问题": "解决自回归TTS模型在生成速度和鲁棒性方面的限制",
        "动机": "提高文本到语音转换的效率和鲁棒性，消除自回归架构的限制",
        "方法": "采用双向推理变分自编码器（BVAE）和注意力机制，设计非自回归模型并行生成梅尔频谱图",
        "关键词": [
            "非自回归模型",
            "变分自编码器",
            "文本到语音",
            "注意力机制",
            "持续时间预测"
        ],
        "涉及的技术概念": {
            "双向推理变分自编码器（BVAE）": "通过自下而上和自上而下的路径学习层次潜在表示，增加模型的表达能力",
            "注意力机制": "用于模型利用文本信息，生成注意力图以训练持续时间预测器",
            "非自回归模型": "并行生成梅尔频谱图，显著提高生成速度"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 83,
        "title": "BiPointNet: Binary Neural Network for Point Clouds",
        "html": "https://iclr.cc//virtual/2021/poster/3065",
        "abstract": "To alleviate the resource constraint for real-time point cloud applications that run on edge devices, in this paper we present BiPointNet, the first model binarization approach for efficient deep learning on point clouds. We discover that the immense performance drop of binarized models for point clouds mainly stems from two challenges: aggregation-induced feature homogenization that leads to a degradation of information entropy, and scale distortion that hinders optimization and invalidates scale-sensitive structures. With theoretical justifications and in-depth analysis, our BiPointNet introduces Entropy-Maximizing Aggregation (EMA) to modulate the distribution before aggregation for the maximum information entropy, and Layer-wise Scale Recovery (LSR) to efficiently restore feature representation capacity. Extensive experiments show that BiPointNet outperforms existing binarization methods by convincing margins, at the level even comparable with the full precision counterpart. We highlight that our techniques are generic, guaranteeing significant improvements on various fundamental tasks and mainstream backbones. Moreover, BiPointNet gives an impressive 14.7× speedup and 18.9× storage saving on real-world resource-constrained devices.",
        "conference": "ICLR",
        "中文标题": "BiPointNet：面向点云的二进制神经网络",
        "摘要翻译": "为了缓解在边缘设备上运行的实时点云应用的资源限制，本文提出了BiPointNet，这是首个用于点云高效深度学习的模型二值化方法。我们发现，点云二值化模型性能大幅下降的主要原因来自两个挑战：导致信息熵下降的聚合引起的特征同质化，以及阻碍优化并使尺度敏感结构无效的尺度失真。通过理论证明和深入分析，我们的BiPointNet引入了熵最大化聚合（EMA）来在聚合前调整分布以实现最大信息熵，以及层间尺度恢复（LSR）来有效恢复特征表示能力。大量实验表明，BiPointNet以令人信服的差距优于现有的二值化方法，甚至达到了与全精度模型相当的水平。我们强调，我们的技术是通用的，保证了在各种基本任务和主流骨干网络上的显著改进。此外，BiPointNet在现实世界资源受限的设备上实现了令人印象深刻的14.7倍加速和18.9倍的存储节省。",
        "领域": "点云处理、模型压缩、边缘计算",
        "问题": "解决在资源受限的边缘设备上实时处理点云数据时，二值化模型性能大幅下降的问题",
        "动机": "为了在边缘设备上实现高效的点云深度学习应用，减少资源消耗同时保持模型性能",
        "方法": "引入熵最大化聚合（EMA）和层间尺度恢复（LSR）技术，优化二值化模型的信息熵和特征表示能力",
        "关键词": [
            "点云处理",
            "模型二值化",
            "边缘计算",
            "信息熵",
            "特征表示"
        ],
        "涉及的技术概念": {
            "熵最大化聚合（EMA）": "在聚合前调整特征分布，以最大化信息熵，解决特征同质化问题",
            "层间尺度恢复（LSR）": "有效恢复二值化模型的特征表示能力，解决尺度失真问题",
            "模型二值化": "将模型权重和激活值二值化，以减少模型大小和加速计算，适用于资源受限的设备"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 84,
        "title": "Blending MPC & Value Function Approximation for Efficient Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2021/poster/2872",
        "abstract": "Model-Predictive Control (MPC) is a powerful tool for controlling complex, real-world systems that uses a model to make predictions about future behavior. For each state encountered, MPC solves an online optimization problem to choose a control action that will minimize future cost. This is a surprisingly effective strategy, but real-time performance requirements warrant the use of simple models. If the model is not sufficiently accurate, then the resulting controller can be biased, limiting performance. We present a framework for improving on MPC with model-free reinforcement learning (RL). The key insight is to view MPC as constructing a series of local Q-function approximations. We show that by using a parameter $\\lambda$, similar to the trace decay parameter in TD($\\lambda$), we can systematically trade-off learned value estimates against the local Q-function approximations. We present a theoretical analysis that shows how error from inaccurate models in MPC and value function estimation in RL can be balanced. We further propose an algorithm that changes $\\lambda$ over time to reduce the dependence on MPC as our estimates of the value function improve, and test the efficacy our approach on challenging high-dimensional manipulation tasks with biased models in simulation. We demonstrate that our approach can obtain performance comparable with MPC with access to true dynamics even under severe model bias and is more sample efficient as compared to model-free RL.",
        "conference": "ICLR",
        "中文标题": "混合模型预测控制与价值函数逼近以实现高效强化学习",
        "摘要翻译": "模型预测控制（MPC）是一种控制复杂现实系统的强大工具，它使用模型来预测未来行为。对于遇到的每个状态，MPC通过解决一个在线优化问题来选择能够最小化未来成本的控制动作。这是一个出奇有效的策略，但实时性能要求需要使用简单模型。如果模型不够准确，那么由此产生的控制器可能会有偏差，限制性能。我们提出了一个框架，通过无模型强化学习（RL）来改进MPC。关键见解是将MPC视为构建一系列局部Q函数逼近。我们展示了通过使用类似于TD(λ)中的迹衰减参数λ，可以系统地权衡学习到的价值估计与局部Q函数逼近。我们提出了一个理论分析，展示了如何平衡MPC中不准确模型的误差和RL中的价值函数估计误差。我们进一步提出了一种算法，随着我们对价值函数估计的改进，随时间改变λ以减少对MPC的依赖，并在模拟中测试了我们的方法在具有偏差模型的高维操作任务上的效果。我们证明了即使在严重的模型偏差下，我们的方法也能获得与使用真实动态的MPC相媲美的性能，并且与无模型RL相比，样本效率更高。",
        "领域": "强化学习、模型预测控制、机器人操作",
        "问题": "如何在模型预测控制中平衡模型准确性与实时性能要求，以及如何通过强化学习提高控制性能。",
        "动机": "解决模型预测控制中因模型不准确导致的控制器偏差问题，以及提高强化学习在复杂控制任务中的样本效率。",
        "方法": "提出一个结合模型预测控制和强化学习的框架，通过动态调整参数λ来平衡模型预测和价值函数估计，逐步减少对模型预测控制的依赖。",
        "关键词": [
            "模型预测控制",
            "强化学习",
            "价值函数逼近",
            "样本效率",
            "高维操作"
        ],
        "涉及的技术概念": {
            "模型预测控制（MPC）": "一种使用模型预测未来行为并在线优化控制动作的方法，用于控制复杂系统。",
            "强化学习（RL）": "一种通过与环境交互学习最优策略的机器学习方法，用于改进控制性能。",
            "价值函数逼近": "在强化学习中，用于估计状态或状态-动作对的价值，以指导策略改进的技术。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 85,
        "title": "BOIL: Towards Representation Change for Few-shot Learning",
        "html": "https://iclr.cc//virtual/2021/poster/3347",
        "abstract": "Model Agnostic Meta-Learning (MAML) is one of the most representative of gradient-based meta-learning algorithms. MAML learns new tasks with a few data samples using inner updates from a meta-initialization point and learns the meta-initialization parameters with outer updates. It has recently been hypothesized that representation reuse, which makes little change in efficient representations, is the dominant factor in the performance of the meta-initialized model through MAML in contrast to representation change, which causes a significant change in representations. In this study, we investigate the necessity of representation change for the ultimate goal of few-shot learning, which is solving domain-agnostic tasks. To this aim, we propose a novel meta-learning algorithm, called BOIL (Body Only update in Inner Loop), which updates only the body (extractor) of the model and freezes the head (classifier) during inner loop updates. BOIL leverages representation change rather than representation reuse. A frozen head cannot achieve better results than even a random guessing classifier at the initial point of new tasks, and feature vectors (representations) have to move quickly to their corresponding frozen head vectors. We visualize this property using cosine similarity, CKA, and empirical results without the head. Although the inner loop updates purely hinge on representation change, BOIL empirically shows significant performance improvement over MAML, particularly on cross-domain tasks. The results imply that representation change in gradient-based meta-learning approaches is a critical component.",
        "conference": "ICLR",
        "中文标题": "BOIL：面向少样本学习的表示变化",
        "摘要翻译": "模型无关元学习（MAML）是基于梯度的元学习算法中最具代表性的之一。MAML通过从元初始化点进行内部更新，利用少量数据样本学习新任务，并通过外部更新学习元初始化参数。最近有假设认为，与表示变化（导致表示显著变化）相比，表示重用（在高效表示中变化不大）是通过MAML在元初始化模型性能中的主导因素。在本研究中，我们探讨了表示变化对于少样本学习的最终目标——解决领域无关任务的必要性。为此，我们提出了一种新的元学习算法，称为BOIL（内环中仅更新体部），该算法在内环更新期间仅更新模型的体部（提取器）并冻结头部（分类器）。BOIL利用表示变化而非表示重用。冻结的头部在新任务的初始点无法获得比随机猜测分类器更好的结果，特征向量（表示）必须快速移动到它们对应的冻结头部向量。我们使用余弦相似度、CKA和无头部的实证结果可视化这一特性。尽管内环更新完全依赖于表示变化，BOIL在实证上显示出比MAML显著的性能提升，特别是在跨域任务上。结果表明，在基于梯度的元学习方法中，表示变化是一个关键组成部分。",
        "领域": "元学习",
        "问题": "探讨表示变化在少样本学习中的必要性",
        "动机": "研究表示变化而非表示重用对于解决领域无关任务的重要性",
        "方法": "提出BOIL算法，仅更新模型的体部并冻结头部，利用表示变化",
        "关键词": [
            "元学习",
            "少样本学习",
            "表示变化",
            "BOIL",
            "跨域任务"
        ],
        "涉及的技术概念": {
            "表示重用": "在高效表示中变化不大，被认为是元初始化模型性能的主导因素",
            "表示变化": "导致表示显著变化，BOIL算法利用此特性提升性能",
            "BOIL算法": "内环中仅更新模型的体部并冻结头部，专注于表示变化"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 86,
        "title": "Boost then Convolve: Gradient Boosting Meets Graph Neural Networks",
        "html": "https://iclr.cc//virtual/2021/poster/2989",
        "abstract": "Graph neural networks (GNNs) are powerful models that have been successful in various graph representation learning tasks. Whereas gradient boosted decision trees (GBDT) often outperform other machine learning methods when faced with heterogeneous tabular data. But what approach should be used for graphs with tabular node features? Previous GNN models have mostly focused on networks with homogeneous sparse features and, as we show, are suboptimal in the heterogeneous setting. In this work, we propose a novel architecture that trains GBDT and GNN jointly to get the best of both worlds: the GBDT model deals with heterogeneous features, while GNN accounts for the graph structure. Our model benefits from end-to-end optimization by allowing new trees to fit the gradient updates of GNN. With an extensive experimental comparison to the leading GBDT and GNN models, we demonstrate a significant increase in performance on a variety of graphs with tabular features. The code is available: https://github.com/nd7141/bgnn.",
        "conference": "ICLR",
        "中文标题": "提升然后卷积：梯度提升与图神经网络的结合",
        "摘要翻译": "图神经网络（GNNs）是强大的模型，在各种图表示学习任务中取得了成功。而梯度提升决策树（GBDT）在面对异构表格数据时，往往优于其他机器学习方法。但对于具有表格节点特征的图，应该采用什么方法呢？以往的GNN模型主要关注于具有同构稀疏特征的网络，并且如我们所示，在异构设置下表现不佳。在这项工作中，我们提出了一种新颖的架构，联合训练GBDT和GNN，以获得两者的最佳效果：GBDT模型处理异构特征，而GNN则考虑图结构。我们的模型通过允许新树适应GNN的梯度更新，从而受益于端到端的优化。通过与领先的GBDT和GNN模型进行广泛的实验比较，我们证明了在具有表格特征的各种图上性能的显著提升。代码可在此获取：https://github.com/nd7141/bgnn。",
        "领域": "图表示学习、梯度提升决策树、图神经网络",
        "问题": "如何有效结合梯度提升决策树和图神经网络以处理具有异构表格节点特征的图数据",
        "动机": "现有的图神经网络在处理具有异构表格节点特征的图数据时表现不佳，而梯度提升决策树在处理异构表格数据时表现出色，因此需要一种方法结合两者的优势。",
        "方法": "提出了一种新颖的架构，联合训练梯度提升决策树和图神经网络，使梯度提升决策树处理异构特征，图神经网络处理图结构，并通过端到端优化提升性能。",
        "关键词": [
            "图神经网络",
            "梯度提升决策树",
            "异构特征",
            "图表示学习",
            "端到端优化"
        ],
        "涉及的技术概念": {
            "图神经网络": "用于处理图结构数据，捕捉节点间的关系和结构信息。",
            "梯度提升决策树": "用于处理异构表格数据，通过逐步添加决策树来优化模型性能。",
            "端到端优化": "允许模型在训练过程中自动调整参数，以最小化损失函数，提高模型性能。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 87,
        "title": "Bowtie Networks: Generative Modeling for Joint Few-Shot Recognition and Novel-View Synthesis",
        "html": "https://iclr.cc//virtual/2021/poster/3357",
        "abstract": "We propose a novel task of joint few-shot recognition and novel-view synthesis: given only one or few images of a novel object from arbitrary views with only category annotation, we aim to simultaneously learn an object classifier and generate images of that type of object from new viewpoints. While existing work copes with two or more tasks mainly by multi-task learning of shareable feature representations, we take a different perspective. We focus on the interaction and cooperation between a generative model and a discriminative model, in a way that facilitates knowledge to flow across tasks in complementary directions. To this end, we propose bowtie networks that jointly learn 3D geometric and semantic representations with a feedback loop. Experimental evaluation on challenging fine-grained recognition datasets demonstrates that our synthesized images are realistic from multiple viewpoints and significantly improve recognition performance as ways of data augmentation, especially in the low-data regime. ",
        "conference": "ICLR",
        "中文标题": "Bowtie网络：用于联合少样本识别和新视角合成的生成建模",
        "摘要翻译": "我们提出了一项新的联合少样本识别和新视角合成的任务：给定仅来自任意视角的一个或少数几个带有类别标注的新物体图像，我们的目标是同时学习一个物体分类器并生成该类型物体从新视角的图像。虽然现有工作主要通过多任务学习共享特征表示来处理两个或更多任务，但我们采取了不同的视角。我们专注于生成模型和判别模型之间的互动与合作，以促进知识在互补方向上跨任务流动。为此，我们提出了Bowtie网络，它通过反馈循环联合学习3D几何和语义表示。在具有挑战性的细粒度识别数据集上的实验评估表明，我们合成的图像从多个视角看都是逼真的，并且作为数据增强的方式显著提高了识别性能，尤其是在数据量较少的情况下。",
        "领域": "生成对抗网络、少样本学习、3D视觉",
        "问题": "如何在仅有一个或少数几个带有类别标注的物体图像的情况下，同时实现物体的少样本识别和新视角的图像生成。",
        "动机": "探索生成模型和判别模型之间的互动与合作，以促进知识在互补方向上跨任务流动，从而在少样本条件下同时提高识别性能和生成新视角图像的能力。",
        "方法": "提出Bowtie网络，通过反馈循环联合学习3D几何和语义表示，实现生成模型和判别模型之间的互动与合作。",
        "关键词": [
            "Bowtie网络",
            "少样本学习",
            "新视角合成",
            "生成对抗网络",
            "3D视觉"
        ],
        "涉及的技术概念": {
            "Bowtie网络": "一种联合学习3D几何和语义表示的架构，通过反馈循环促进生成模型和判别模型之间的知识流动。",
            "少样本学习": "在仅有少量标注样本的情况下学习有效的模型，本研究中用于识别任务。",
            "新视角合成": "生成物体从新视角的图像，本研究中通过生成模型实现，以增强识别性能。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 88,
        "title": "BRECQ: Pushing the Limit of Post-Training Quantization by Block Reconstruction",
        "html": "https://iclr.cc//virtual/2021/poster/2596",
        "abstract": "We study the challenging task of neural network quantization without end-to-end retraining, called Post-training Quantization (PTQ). PTQ usually requires a small subset of training data but produces less powerful quantized models than Quantization-Aware Training (QAT). In this work, we propose a novel PTQ framework, dubbed BRECQ, which pushes the limits of bitwidth in PTQ down to INT2 for the first time. BRECQ leverages the basic building blocks in neural networks and reconstructs them one-by-one. In a comprehensive theoretical study of the second-order error, we show that BRECQ achieves a good balance between cross-layer dependency and generalization error. To further employ the power of quantization, the mixed precision technique is incorporated in our framework by approximating the inter-layer and intra-layer sensitivity. Extensive experiments on various handcrafted and searched neural architectures are conducted for both image classification and object detection tasks. And for the first time we prove that, without bells and whistles, PTQ can attain 4-bit ResNet and MobileNetV2 comparable with QAT and enjoy 240 times faster production of quantized models.  Codes are available at https://github.com/yhhhli/BRECQ.",
        "conference": "ICLR",
        "中文标题": "BRECQ：通过块重建推动训练后量化的极限",
        "摘要翻译": "我们研究了无需端到端重新训练的神经网络量化这一挑战性任务，称为训练后量化（PTQ）。PTQ通常需要一小部分训练数据，但产生的量化模型性能不如量化感知训练（QAT）。在这项工作中，我们提出了一种新颖的PTQ框架，名为BRECQ，首次将PTQ的位宽限制推至INT2。BRECQ利用神经网络中的基本构建块，并逐一重建它们。在对二阶误差的全面理论研究中，我们展示了BRECQ在跨层依赖性和泛化误差之间实现了良好的平衡。为了进一步发挥量化的力量，我们的框架中引入了混合精度技术，通过近似层间和层内敏感性来实现。我们对各种手工设计和搜索的神经架构进行了广泛的实验，包括图像分类和目标检测任务。并且我们首次证明，无需任何花哨的技巧，PTQ可以达到与QAT相当的4位ResNet和MobileNetV2，并且量化模型的生产速度快240倍。代码可在https://github.com/yhhhli/BRECQ获取。",
        "领域": "模型量化、图像分类、目标检测",
        "问题": "如何在无需端到端重新训练的情况下，有效减少神经网络模型的位宽，同时保持或提升模型性能。",
        "动机": "解决训练后量化（PTQ）在减少模型位宽时性能下降的问题，推动PTQ技术的极限。",
        "方法": "提出BRECQ框架，通过块重建技术逐一处理神经网络中的基本构建块，结合二阶误差分析和混合精度技术，优化量化过程。",
        "关键词": [
            "训练后量化",
            "块重建",
            "混合精度",
            "INT2量化",
            "模型加速"
        ],
        "涉及的技术概念": {
            "训练后量化（PTQ）": "一种无需端到端重新训练的神经网络量化方法，旨在减少模型大小和加速推理过程。",
            "块重建": "BRECQ框架中的核心技术，通过逐一重建神经网络中的基本构建块来优化量化效果。",
            "混合精度技术": "在量化过程中，根据不同层的敏感性动态调整位宽，以平衡模型性能和计算效率。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 89,
        "title": "BREEDS: Benchmarks for Subpopulation Shift",
        "html": "https://iclr.cc//virtual/2021/poster/3265",
        "abstract": "We develop a methodology for assessing the robustness of models to subpopulation shift---specifically, their ability to generalize to novel data subpopulations that were not observed during training. Our approach leverages the class structure underlying existing datasets to control the data subpopulations that comprise the training and test distributions. This enables us to synthesize realistic distribution shifts whose sources can be precisely controlled and characterized, within existing\nlarge-scale datasets. Applying this methodology to the ImageNet dataset, we create a suite of subpopulation shift benchmarks of varying granularity. We then validate that the corresponding shifts are tractable by obtaining human baselines. Finally, we utilize these benchmarks to measure the sensitivity of standard model architectures as well as the effectiveness of existing train-time robustness interventions. ",
        "conference": "ICLR",
        "中文标题": "BREEDS：子群偏移的基准测试",
        "摘要翻译": "我们开发了一种方法来评估模型对子群偏移的鲁棒性——特别是它们泛化到训练期间未观察到的新数据子群的能力。我们的方法利用现有数据集的基础类结构来控制构成训练和测试分布的数据子群。这使我们能够在现有的大规模数据集中合成现实分布偏移，其来源可以被精确控制和表征。将这种方法应用于ImageNet数据集，我们创建了一套不同粒度的子群偏移基准测试。然后，我们通过获取人类基线来验证相应的偏移是可处理的。最后，我们利用这些基准测试来衡量标准模型架构的敏感性以及现有训练时鲁棒性干预措施的有效性。",
        "领域": "模型鲁棒性评估、子群偏移分析、大规模数据集处理",
        "问题": "评估模型对未在训练中观察到的新数据子群的泛化能力",
        "动机": "为了解决模型在面对数据子群偏移时的泛化能力问题，提供一种可控制和可表征的评估方法",
        "方法": "利用现有数据集的类结构控制训练和测试分布的子群，合成现实分布偏移，创建基准测试并验证其可处理性",
        "关键词": [
            "子群偏移",
            "模型鲁棒性",
            "基准测试",
            "泛化能力",
            "ImageNet"
        ],
        "涉及的技术概念": {
            "子群偏移": "指数据分布中不同子群之间的变化，论文中用于评估模型对新数据子群的泛化能力",
            "模型鲁棒性": "模型在面对数据分布变化时的性能稳定性，论文中通过基准测试评估",
            "基准测试": "一套标准化的测试方法，用于衡量模型在特定条件下的性能，论文中用于评估模型对子群偏移的敏感性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 90,
        "title": "BSQ: Exploring Bit-Level Sparsity for Mixed-Precision Neural Network Quantization",
        "html": "https://iclr.cc//virtual/2021/poster/3053",
        "abstract": "Mixed-precision quantization can potentially achieve the optimal tradeoff between performance and compression rate of deep neural networks, and thus, have been widely investigated. However, it lacks a systematic method to determine the exact quantization scheme. Previous methods either examine only a small manually-designed search space or utilize a cumbersome neural architecture search to explore the vast search space. These approaches cannot lead to an optimal quantization scheme efficiently. This work proposes bit-level sparsity quantization (BSQ) to tackle the mixed-precision quantization from a new angle of inducing bit-level sparsity. We consider each bit of quantized weights as an independent trainable variable and introduce a differentiable bit-sparsity regularizer. BSQ can induce all-zero bits across a group of weight elements and realize the dynamic precision reduction, leading to a mixed-precision quantization scheme of the original model. Our method enables the exploration of the full mixed-precision space with a single gradient-based optimization process, with only one hyperparameter to tradeoff the performance and compression. BSQ achieves both higher accuracy and higher bit reduction on various model architectures on the CIFAR-10 and ImageNet datasets comparing to previous methods.",
        "conference": "ICLR",
        "中文标题": "BSQ：探索比特级稀疏性以实现混合精度神经网络量化",
        "摘要翻译": "混合精度量化有可能在深度神经网络的性能和压缩率之间达到最佳平衡，因此已被广泛研究。然而，目前缺乏一种系统的方法来确定确切的量化方案。先前的方法要么仅检查一个小的手动设计的搜索空间，要么利用繁琐的神经架构搜索来探索广阔的搜索空间。这些方法无法高效地得出最优量化方案。本研究提出比特级稀疏量化（BSQ），从诱导比特级稀疏性的新角度来解决混合精度量化问题。我们将量化权重的每一位视为独立的可训练变量，并引入可微分的比特稀疏正则化器。BSQ可以在权重元素组中诱导全零比特，实现动态精度降低，从而得到原始模型的混合精度量化方案。我们的方法能够通过单一的基于梯度的优化过程探索完整的混合精度空间，仅需一个超参数来权衡性能和压缩。与之前的方法相比，BSQ在CIFAR-10和ImageNet数据集上的各种模型架构上实现了更高的准确率和更高的比特减少。",
        "领域": "神经网络量化、模型压缩、深度学习优化",
        "问题": "如何高效地确定混合精度神经网络的最优量化方案",
        "动机": "现有方法无法高效探索广阔的混合精度量化空间，导致难以找到最优量化方案",
        "方法": "提出比特级稀疏量化（BSQ），通过引入可微分的比特稀疏正则化器，将量化权重的每一位视为独立可训练变量，实现动态精度降低",
        "关键词": [
            "混合精度量化",
            "比特级稀疏性",
            "模型压缩",
            "神经网络优化",
            "梯度优化"
        ],
        "涉及的技术概念": {
            "比特级稀疏量化（BSQ）": "一种新的混合精度量化方法，通过诱导比特级稀疏性实现动态精度降低",
            "可微分比特稀疏正则化器": "用于在量化过程中引入稀疏性，使得某些比特位可以被置零，从而实现动态精度调整",
            "梯度优化": "用于探索混合精度量化空间的优化方法，通过单一优化过程实现性能和压缩的权衡"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 91,
        "title": "BUSTLE: Bottom-Up Program Synthesis Through Learning-Guided Exploration",
        "html": "https://iclr.cc//virtual/2021/poster/2812",
        "abstract": "Program synthesis is challenging largely because of the difficulty of search in a large space of programs. Human programmers routinely tackle the task of writing complex programs by writing sub-programs and then analyzing their intermediate results to compose them in appropriate ways. Motivated by this intuition, we present a new synthesis approach that leverages learning to guide a bottom-up search over programs. In particular, we train a model to prioritize compositions of intermediate values during search conditioned on a given set of input-output examples. This is a powerful combination because of several emergent properties. First, in bottom-up search, intermediate programs can be executed, providing semantic information to the neural network. Second, given the concrete values from those executions, we can exploit rich features based on recent work on property signatures. Finally, bottom-up search allows the system substantial flexibility in what order to generate the solution, allowing the synthesizer to build up a program from multiple smaller sub-programs. Overall, our empirical evaluation finds that the combination of learning and bottom-up search is remarkably effective, even with simple supervised learning approaches. We demonstrate the effectiveness of our technique on two datasets, one from the SyGuS competition and one of our own creation.",
        "conference": "ICLR",
        "中文标题": "BUSTLE：通过学习引导的探索自底向上程序合成",
        "摘要翻译": "程序合成的主要挑战在于在大规模程序空间中进行搜索的困难。人类程序员通常通过编写子程序然后分析其中间结果以适当方式组合它们来应对编写复杂程序的任务。受这一直觉启发，我们提出了一种新的合成方法，该方法利用学习来引导对程序的自底向上搜索。特别是，我们训练一个模型，在给定一组输入输出示例的条件下，优先考虑搜索过程中中间值的组合。这是一个强大的组合，因为它具有几个突现属性。首先，在自底向上搜索中，可以执行中间程序，为神经网络提供语义信息。其次，给定这些执行的具体值，我们可以利用基于最近关于属性签名工作的丰富特征。最后，自底向上搜索允许系统在生成解决方案的顺序上具有很大的灵活性，使得合成器可以从多个较小的子程序构建程序。总体而言，我们的实证评估发现，即使使用简单的监督学习方法，学习和自底向上搜索的组合也非常有效。我们在两个数据集上证明了我们技术的有效性，一个来自SyGuS竞赛，另一个是我们自己创建的。",
        "领域": "程序合成、机器学习、自动编程",
        "问题": "解决在大规模程序空间中进行有效搜索的困难，以提高程序合成的效率和准确性。",
        "动机": "受人类程序员编写复杂程序的方式启发，通过分析子程序的中间结果来组合它们，以提高程序合成的效率。",
        "方法": "提出了一种结合学习和自底向上搜索的新方法，训练模型在给定输入输出示例的条件下优先考虑中间值的组合，利用程序执行的语义信息和属性签名的丰富特征。",
        "关键词": [
            "程序合成",
            "自底向上搜索",
            "学习引导",
            "属性签名",
            "监督学习"
        ],
        "涉及的技术概念": {
            "自底向上搜索": "一种从基础构建块开始，逐步组合成更大程序的搜索策略，允许灵活地构建解决方案。",
            "属性签名": "基于程序执行的具体值提取的特征，用于丰富学习模型的输入信息。",
            "监督学习": "利用标记数据训练模型，以预测或决策，这里用于指导搜索过程中中间值的组合。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 92,
        "title": "Bypassing the Ambient Dimension: Private SGD with Gradient Subspace Identification",
        "html": "https://iclr.cc//virtual/2021/poster/3266",
        "abstract": "Differentially private SGD (DP-SGD) is one of the most popular methods for solving differentially private empirical risk minimization (ERM). Due to its noisy perturbation on each gradient update, the error rate of DP-SGD scales with the ambient dimension $p$, the number of parameters in the model. Such dependence can be problematic for over-parameterized models where $p \\gg n$, the number of training samples. Existing lower bounds on private ERM show that such dependence on $p$ is inevitable in the worst case. In this paper, we circumvent the dependence on the ambient dimension by leveraging a low-dimensional structure of gradient space in deep networks---that is, the stochastic gradients for deep nets usually stay in a low dimensional subspace in the training process. We propose Projected DP-SGD that performs noise reduction by projecting the noisy gradients to a low-dimensional subspace, which is given by the top gradient eigenspace on a small public dataset. We provide a general sample complexity analysis on the public dataset for the gradient subspace identification problem and demonstrate that under certain low-dimensional assumptions the public sample complexity only grows logarithmically in $p$. Finally, we provide a theoretical analysis and empirical evaluations to show that our method can substantially improve the accuracy of DP-SGD in the high privacy regime (corresponding to low privacy loss $\\epsilon$).\n\n",
        "conference": "ICLR",
        "success": true,
        "中文标题": "绕过环境维度：基于梯度子空间识别的私有SGD",
        "摘要翻译": "差分隐私随机梯度下降（DP-SGD）是解决差分隐私经验风险最小化（ERM）的最流行方法之一。由于其对每次梯度更新的噪声扰动，DP-SGD的误差率与环境维度p（模型中的参数数量）成比例。对于过度参数化的模型，其中p远大于n（训练样本的数量），这种依赖性可能会出现问题。现有的关于私有ERM的下界表明，在最坏的情况下，这种对p的依赖性是不可避免的。在本文中，我们通过利用深度网络中梯度空间的低维结构来规避对环境维度的依赖性——也就是说，深度网络的随机梯度通常在训练过程中停留在低维子空间中。我们提出了投影DP-SGD，它通过将带噪声的梯度投影到低维子空间来执行噪声降低，该子空间由小型公共数据集上的顶部梯度特征空间给出。我们提供了关于公共数据集上梯度子空间识别问题的一般样本复杂度分析，并证明在某些低维假设下，公共样本复杂度仅以p的对数形式增长。最后，我们提供了理论分析和经验评估，以表明我们的方法可以显著提高高隐私机制（对应于低隐私损失ε）中DP-SGD的准确性。",
        "领域": "差分隐私, 随机梯度下降, 深度学习",
        "问题": "在差分隐私随机梯度下降(DP-SGD)中，误差率受模型参数数量（环境维度）的影响，尤其是在过度参数化模型中，这限制了DP-SGD在高隐私性要求下的应用。",
        "动机": "为了解决DP-SGD对环境维度的依赖性问题，提升在高隐私性要求下的模型准确性，通过利用深度网络中梯度空间通常存在的低维结构，降低噪声的影响。",
        "方法": "提出了一种名为投影DP-SGD的方法，该方法通过将带噪声的梯度投影到通过公共数据集获得的低维子空间中，从而降低噪声，并分析了公共数据集的样本复杂度。",
        "关键词": [
            "差分隐私",
            "随机梯度下降",
            "梯度子空间识别",
            "降维",
            "高隐私性"
        ],
        "涉及的技术概念": {
            "差分隐私 (Differential Privacy)": "一种保护数据隐私的技术，通过在数据处理过程中添加噪声来防止个人信息泄露，DP-SGD通过对梯度添加噪声来实现差分隐私。",
            "随机梯度下降 (SGD)": "一种优化算法，用于训练机器学习模型，通过迭代更新模型参数来最小化损失函数，DP-SGD在SGD的基础上加入了差分隐私保护机制。"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 93,
        "title": "Byzantine-Resilient Non-Convex Stochastic Gradient Descent",
        "html": "https://iclr.cc//virtual/2021/poster/3312",
        "abstract": "We study adversary-resilient stochastic distributed optimization, in which $m$ machines can independently compute stochastic gradients, and cooperate to jointly optimize over their local objective functions. However, an $\\alpha$-fraction of the machines are Byzantine, in that they may behave in arbitrary, adversarial ways. We consider a variant of this procedure in the challenging non-convex case. Our main result is a new algorithm SafeguardSGD, which can provably escape saddle points and find approximate local minima of the non-convex objective. The algorithm is based on a new concentration filtering technique, and its sample and time complexity bounds match the best known theoretical bounds in the stochastic, distributed setting when no Byzantine machines are present. \n\nOur algorithm is very practical: it improves upon the performance of all prior methods when training deep neural networks, it is relatively lightweight, and it is the first method to withstand two recently-proposed Byzantine attacks. ",
        "conference": "ICLR",
        "中文标题": "拜占庭容错的非凸随机梯度下降",
        "摘要翻译": "我们研究了对抗性弹性的随机分布式优化问题，其中m台机器可以独立计算随机梯度，并合作共同优化它们的局部目标函数。然而，其中α比例的机器是拜占庭式的，它们可能以任意、对抗性的方式行为。我们考虑了在具有挑战性的非凸情况下的这一过程的变体。我们的主要成果是一个新算法SafeguardSGD，它能够证明逃离鞍点并找到非凸目标的近似局部最小值。该算法基于一种新的浓度过滤技术，其样本和时间复杂度界限在没有拜占庭机器存在时，与随机分布式设置中已知的最佳理论界限相匹配。我们的算法非常实用：它在训练深度神经网络时优于所有先前方法的性能，相对轻量级，并且是第一个能够抵御最近提出的两种拜占庭攻击的方法。",
        "领域": "分布式机器学习、对抗性机器学习、深度学习优化",
        "问题": "在存在拜占庭节点的情况下，如何在非凸优化问题中实现有效的随机梯度下降",
        "动机": "研究动机是为了解决在分布式机器学习环境中，部分节点可能表现出对抗性行为时，如何保证优化算法的鲁棒性和有效性。",
        "方法": "提出了一种名为SafeguardSGD的新算法，该算法基于浓度过滤技术，能够在非凸优化中逃离鞍点并找到近似局部最小值。",
        "关键词": [
            "拜占庭容错",
            "非凸优化",
            "随机梯度下降",
            "分布式机器学习",
            "对抗性机器学习"
        ],
        "涉及的技术概念": {
            "拜占庭节点": "指在分布式系统中可能以任意、对抗性方式行为的节点，影响系统的正常运行和优化过程。",
            "非凸优化": "指目标函数具有多个局部最优解的优化问题，增加了找到全局最优解的难度。",
            "浓度过滤技术": "一种用于识别和处理异常或对抗性输入的技术，确保算法的鲁棒性和有效性。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 94,
        "title": "Calibration of Neural Networks using Splines",
        "html": "https://iclr.cc//virtual/2021/poster/2978",
        "abstract": "Calibrating neural networks is of utmost importance when employing them in safety-critical applications where the downstream decision making depends on the predicted probabilities. Measuring calibration error amounts to comparing two empirical distributions. In this work, we introduce a binning-free calibration measure inspired by the classical Kolmogorov-Smirnov (KS) statistical test in which the main idea is to compare the respective cumulative probability distributions. From this, by approximating the empirical cumulative distribution using a differentiable function via splines, we obtain a recalibration function, which maps the network outputs to actual (calibrated) class assignment probabilities. The spline-fitting is performed using a held-out calibration set and the obtained recalibration function is evaluated on an unseen test set. We tested our method against existing calibration approaches on various image classification datasets and our spline-based recalibration approach consistently outperforms existing methods on KS error as well as other commonly used calibration measures. Code is available online at https://github.com/kartikgupta-at-anu/spline-calibration.",
        "conference": "ICLR",
        "中文标题": "使用样条校准神经网络",
        "摘要翻译": "在校准神经网络时，在安全关键应用中尤为重要，因为下游决策依赖于预测概率。测量校准误差相当于比较两个经验分布。在这项工作中，我们引入了一种受经典Kolmogorov-Smirnov（KS）统计测试启发的无分箱校准测量方法，其主要思想是比较各自的累积概率分布。由此，通过使用样条通过可微分函数近似经验累积分布，我们获得了一个重新校准函数，该函数将网络输出映射到实际的（校准的）类别分配概率。样条拟合是使用保留的校准集进行的，并且获得的重新校准函数在未见过的测试集上进行了评估。我们在各种图像分类数据集上测试了我们的方法与其他现有校准方法，我们的基于样条的重新校准方法在KS误差以及其他常用校准测量上始终优于现有方法。代码可在https://github.com/kartikgupta-at-anu/spline-calibration在线获取。",
        "领域": "图像分类、神经网络校准、安全关键应用",
        "问题": "解决神经网络在安全关键应用中预测概率校准不准确的问题",
        "动机": "提高神经网络在安全关键应用中的预测概率准确性，以支持更可靠的决策制定",
        "方法": "引入一种基于Kolmogorov-Smirnov统计测试的无分箱校准测量方法，通过样条拟合近似经验累积分布，获得重新校准函数",
        "关键词": [
            "神经网络校准",
            "样条拟合",
            "Kolmogorov-Smirnov测试",
            "图像分类",
            "安全关键应用"
        ],
        "涉及的技术概念": {
            "Kolmogorov-Smirnov（KS）统计测试": "用于比较两个累积概率分布，作为校准误差的测量基础",
            "样条拟合": "用于近似经验累积分布的可微分函数，生成重新校准函数",
            "重新校准函数": "将神经网络的输出映射到校准后的类别分配概率，提高预测准确性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 95,
        "title": "Calibration tests beyond classification",
        "html": "https://iclr.cc//virtual/2021/poster/2682",
        "abstract": "Most supervised machine learning tasks are subject to irreducible prediction errors. Probabilistic predictive models address this limitation by providing probability distributions that represent a belief over plausible targets, rather than point estimates. Such models can be a valuable tool in decision-making under uncertainty, provided that the model output is meaningful and interpretable. Calibrated models guarantee that the probabilistic predictions are neither over- nor under-confident. In the machine learning literature, different measures and statistical tests have been proposed and studied for evaluating the calibration of classification models. For regression problems, however, research has been focused on a weaker condition of calibration based on predicted quantiles for real-valued targets. In this paper, we propose the first framework that unifies calibration evaluation and tests for general probabilistic predictive models. It applies to any such model, including classification and regression models of arbitrary dimension. Furthermore, the framework generalizes existing measures and provides a more intuitive reformulation of a recently proposed framework for calibration in multi-class classification. In particular, we reformulate and generalize the kernel calibration error, its estimators, and hypothesis tests using scalar-valued kernels, and evaluate the calibration of real-valued regression\nproblems.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "超越分类的校准测试",
        "摘要翻译": "大多数监督机器学习任务都存在不可减少的预测误差。概率预测模型通过提供代表对可能目标的信念的概率分布，而不是点估计，来解决这一限制。只要模型输出是有意义且可解释的，这样的模型就可以成为在不确定性下决策的宝贵工具。校准模型保证概率预测既不过度自信也不欠自信。在机器学习文献中，已经提出并研究了不同的度量和统计测试，用于评估分类模型的校准。然而，对于回归问题，研究主要集中在基于实值目标的预测分位数的较弱校准条件上。在本文中，我们提出了第一个统一校准评估和测试的框架，适用于一般概率预测模型。它适用于任何此类模型，包括任意维度的分类和回归模型。此外，该框架概括了现有的度量，并为最近提出的多类分类校准框架提供了更直观的重新表述。特别是，我们使用标量值核重新表述并概括了核校准误差、其估计量以及假设测试，并评估了实值回归问题的校准。",
        "领域": "概率预测模型校准",
        "问题": "如何评估和测试一般概率预测模型的校准性",
        "动机": "为了解决现有研究在回归问题校准评估上的不足，并提供一个统一的框架来评估和测试各种概率预测模型的校准性",
        "方法": "提出了一个统一的框架，适用于任何概率预测模型，包括分类和回归模型，使用标量值核重新表述并概括了核校准误差及其估计量和假设测试",
        "关键词": [
            "概率预测模型",
            "校准测试",
            "核校准误差",
            "回归问题",
            "多类分类"
        ],
        "涉及的技术概念": {
            "概率预测模型": "提供概率分布而非点估计的模型，用于表示对可能目标的信念",
            "核校准误差": "用于评估模型校准性的度量，通过标量值核重新表述和概括",
            "标量值核": "在重新表述核校准误差及其估计量和假设测试中使用的技术，用于更直观地评估模型校准性"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 96,
        "title": "Can a Fruit Fly Learn Word Embeddings?",
        "html": "https://iclr.cc//virtual/2021/poster/3085",
        "abstract": "The mushroom body of the fruit fly brain is one of the best studied systems in neuroscience. At its core it consists of a population of Kenyon cells, which receive inputs from multiple sensory modalities. These cells are inhibited by the anterior paired lateral neuron, thus creating a sparse high dimensional representation of the inputs. In this work we study a mathematical formalization of this network motif and apply it to learning the correlational structure between words and their context in a corpus of unstructured text, a common natural language processing (NLP) task. We show that this network can learn semantic representations of words and can generate both static and context-dependent word embeddings. Unlike conventional methods (e.g., BERT, GloVe) that use dense representations for word embedding, our algorithm encodes semantic meaning of words and their context in the form of sparse binary hash codes. The quality of the learned representations is evaluated on word similarity analysis, word-sense disambiguation, and document classification. It is shown that not only can the fruit fly network motif achieve performance comparable to existing methods in NLP, but, additionally, it uses only a fraction of the computational resources (shorter training time and smaller memory footprint). ",
        "conference": "ICLR",
        "中文标题": "果蝇能学习词嵌入吗？",
        "摘要翻译": "果蝇大脑的蘑菇体是神经科学中研究最为深入的系统之一。其核心由一组肯扬细胞组成，这些细胞接收来自多种感官模态的输入。这些细胞受到前配对侧神经元的抑制，从而创建了一个稀疏的高维输入表示。在这项工作中，我们研究了这一网络模式的数学形式化，并将其应用于学习非结构化文本语料库中单词及其上下文之间的相关性结构，这是一项常见的自然语言处理（NLP）任务。我们展示了该网络可以学习单词的语义表示，并可以生成静态和上下文相关的词嵌入。与使用密集表示进行词嵌入的传统方法（例如BERT、GloVe）不同，我们的算法以稀疏二进制哈希码的形式编码单词及其上下文的语义。通过学习表示的质量在单词相似性分析、词义消歧和文档分类上进行评估。结果表明，果蝇网络模式不仅可以在NLP中实现与现有方法相当的性能，而且，它仅使用了一小部分计算资源（更短的训练时间和更小的内存占用）。",
        "领域": "自然语言处理与视觉结合、词嵌入技术、神经网络模型",
        "问题": "如何利用果蝇大脑的网络模式学习有效的词嵌入表示",
        "动机": "探索生物神经网络模式在自然语言处理任务中的应用潜力，特别是在资源受限的情况下",
        "方法": "研究并数学形式化果蝇大脑蘑菇体的网络模式，应用于学习单词及其上下文的语义表示，生成稀疏二进制哈希码的词嵌入",
        "关键词": [
            "果蝇大脑网络模式",
            "稀疏二进制哈希码",
            "词嵌入学习"
        ],
        "涉及的技术概念": {
            "肯扬细胞": "果蝇大脑蘑菇体中的细胞，负责接收多种感官模态的输入，创建稀疏高维表示",
            "前配对侧神经元": "抑制肯扬细胞活动的神经元，有助于形成稀疏的输入表示",
            "稀疏二进制哈希码": "用于编码单词及其上下文语义的表示形式，相比传统密集表示更节省资源"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 97,
        "title": "CaPC Learning: Confidential and Private Collaborative Learning",
        "html": "https://iclr.cc//virtual/2021/poster/2786",
        "abstract": "Machine learning benefits from large training datasets, which may not always be possible to collect by any single entity, especially when using privacy-sensitive data. In many contexts, such as healthcare and finance, separate parties may wish to collaborate and learn from each other's data but are prevented from doing so due to privacy regulations. Some regulations prevent explicit sharing of data between parties by joining datasets in a central location (confidentiality). Others also limit implicit sharing of data, e.g., through model predictions (privacy). There is currently no method that enables machine learning in such a setting, where both confidentiality and privacy need to be preserved, to prevent both explicit and implicit sharing of data. Federated learning only provides confidentiality, not privacy, since gradients shared still contain private information. Differentially private learning assumes unreasonably large datasets. Furthermore, both of these learning paradigms produce a central model whose architecture was previously agreed upon by all parties rather than enabling collaborative learning where each party learns and improves their own local model. We introduce Confidential and Private Collaborative (CaPC) learning, the first method provably achieving both confidentiality and privacy in a collaborative setting. We leverage secure multi-party computation (MPC), homomorphic encryption (HE), and other techniques in combination with privately aggregated teacher models. We demonstrate how CaPC allows participants to collaborate without having to explicitly join their training sets or train a central model. Each party is able to improve the accuracy and fairness of their model, even in settings where each party has a model that performs well on their own dataset or when datasets are not IID and model architectures are heterogeneous across parties. ",
        "conference": "ICLR",
        "中文标题": "CaPC学习：保密与隐私的协作学习",
        "摘要翻译": "机器学习受益于大型训练数据集，但任何单一实体可能并不总是能够收集到这样的数据集，尤其是在使用隐私敏感数据时。在许多情况下，如医疗保健和金融领域，不同的方可能希望协作并从彼此的数据中学习，但由于隐私法规的限制而无法这样做。一些法规通过禁止在中央位置合并数据集来防止各方之间明确共享数据（保密性）。其他法规还限制数据的隐式共享，例如通过模型预测（隐私性）。目前，没有方法能够在需要同时保持保密性和隐私性的环境中实现机器学习，以防止数据的显式和隐式共享。联邦学习仅提供保密性，而不提供隐私性，因为共享的梯度仍然包含私人信息。差分隐私学习假设数据集不合理地大。此外，这两种学习范式都产生一个中央模型，其架构是所有方事先商定的，而不是实现协作学习，其中每一方都能学习和改进自己的本地模型。我们介绍了保密与隐私协作（CaPC）学习，这是第一种在协作环境中可证明实现保密性和隐私性的方法。我们利用安全多方计算（MPC）、同态加密（HE）以及其他技术与私有聚合教师模型相结合。我们展示了CaPC如何使参与者能够协作，而无需明确合并他们的训练集或训练中央模型。每一方都能提高其模型的准确性和公平性，即使在每一方拥有在其自己的数据集上表现良好的模型或数据集不是独立同分布且模型架构在各方之间异构的情况下。",
        "领域": "隐私保护机器学习, 联邦学习, 安全多方计算",
        "问题": "在需要同时保持数据保密性和隐私性的环境中实现协作学习",
        "动机": "解决在隐私敏感领域（如医疗保健和金融）中，不同方因隐私法规限制而无法协作学习的问题",
        "方法": "结合安全多方计算（MPC）、同态加密（HE）和私有聚合教师模型，实现保密与隐私协作（CaPC）学习",
        "关键词": [
            "隐私保护",
            "协作学习",
            "安全多方计算",
            "同态加密",
            "联邦学习"
        ],
        "涉及的技术概念": {
            "安全多方计算（MPC）": "用于在不泄露各自私有数据的情况下，多方协作计算一个函数的技术",
            "同态加密（HE）": "允许在加密数据上直接进行特定计算的加密技术，保护数据隐私",
            "私有聚合教师模型": "通过聚合各方的模型预测而非原始数据，来保护数据隐私和保密性的方法"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 98,
        "title": "Capturing Label Characteristics in VAEs",
        "html": "https://iclr.cc//virtual/2021/poster/3121",
        "abstract": "We present a principled approach to incorporating labels in variational autoencoders (VAEs) that captures the rich characteristic information associated with those labels. While prior work has typically conflated these by learning latent variables that directly correspond to label values, we argue this is contrary to the intended effect of supervision in VAEs—capturing rich label characteristics with the latents. For example, we may want to capture the characteristics of a face that make it look young, rather than just the age of the person. To this end, we develop a novel VAE model, the characteristic capturing VAE (CCVAE), which “reparameterizes” supervision through auxiliary variables and a concomitant variational objective. Through judicious structuring of mappings between latent and auxiliary variables, we show that the CCVAE can effectively learn meaningful representations of the characteristics of interest across a variety of supervision schemes. In particular, we show that the CCVAE allows for more effective and more general interventions to be performed, such as smooth traversals within the characteristics for a given label, diverse conditional generation, and transferring characteristics across datapoints.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "在变分自编码器中捕捉标签特征",
        "摘要翻译": "我们提出了一种将标签信息融入变分自编码器（VAEs）的原则性方法，该方法能够捕捉与这些标签相关的丰富特征信息。以往的工作通常通过学习直接对应于标签值的潜在变量来混淆这些信息，我们认为这与监督在VAEs中的预期效果——用潜在变量捕捉丰富的标签特征——是相悖的。例如，我们可能希望捕捉使面部看起来年轻的那些特征，而不仅仅是人的年龄。为此，我们开发了一种新颖的VAE模型，即特征捕捉VAE（CCVAE），它通过辅助变量和相应的变分目标“重新参数化”监督。通过对潜在变量和辅助变量之间映射的明智构建，我们展示了CCVAE能够有效地学习各种监督方案下感兴趣特征的有意义表示。特别是，我们展示了CCVAE允许进行更有效和更一般的干预，如在给定标签的特征内进行平滑遍历、多样化的条件生成以及跨数据点的特征转移。",
        "领域": "生成模型",
        "问题": "如何在变分自编码器中有效地捕捉和利用标签的丰富特征信息",
        "动机": "解决现有方法在学习潜在变量时直接对应于标签值，而未能充分捕捉标签的丰富特征信息的问题",
        "方法": "开发了一种名为特征捕捉VAE（CCVAE）的新模型，通过辅助变量和相应的变分目标重新参数化监督，以捕捉标签的丰富特征",
        "关键词": [
            "变分自编码器",
            "标签特征",
            "监督学习",
            "条件生成",
            "特征转移"
        ],
        "涉及的技术概念": {
            "变分自编码器（VAEs）": "一种生成模型，用于学习数据的潜在表示，并通过潜在变量生成新数据",
            "辅助变量": "在CCVAE中用于重新参数化监督的变量，帮助模型捕捉标签的丰富特征",
            "变分目标": "CCVAE中用于优化模型训练的损失函数，确保模型能够有效地学习标签的特征信息"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 99,
        "title": "Categorical Normalizing Flows via Continuous Transformations",
        "html": "https://iclr.cc//virtual/2021/poster/2730",
        "abstract": "Despite their popularity, to date, the application of normalizing flows on categorical data stays limited. The current practice of using dequantization to map discrete data to a continuous space is inapplicable as categorical data has no intrinsic order. Instead, categorical data have complex and latent relations that must be inferred, like the synonymy between words. In this paper, we investigate Categorical Normalizing Flows, that is normalizing flows for categorical data. By casting the encoding of categorical data in continuous space as a variational inference problem, we jointly optimize the continuous representation and the model likelihood. Using a factorized decoder, we introduce an inductive bias to model any interactions in the normalizing flow. As a consequence, we do not only simplify the optimization compared to having a joint decoder, but also make it possible to scale up to a large number of categories that is currently impossible with discrete normalizing flows. Based on Categorical Normalizing Flows, we propose GraphCNF a permutation-invariant generative model on graphs. GraphCNF implements a three step approach modeling the nodes, edges, and adjacency matrix stepwise to increase efficiency. On molecule generation, GraphCNF outperforms both one-shot and autoregressive flow-based state-of-the-art.\n",
        "conference": "ICLR",
        "中文标题": "通过连续变换的类别归一化流",
        "摘要翻译": "尽管归一化流（normalizing flows）非常流行，但迄今为止，其在类别数据上的应用仍然有限。当前使用去量化（dequantization）将离散数据映射到连续空间的做法不适用于类别数据，因为类别数据没有内在的顺序。相反，类别数据具有复杂且潜在的关系，如同义词之间的关系，这些关系必须被推断出来。在本文中，我们研究了类别归一化流，即用于类别数据的归一化流。通过将类别数据在连续空间中的编码视为一个变分推断问题，我们联合优化了连续表示和模型似然。使用因子化解码器，我们引入了一个归纳偏置来建模归一化流中的任何交互作用。因此，我们不仅简化了与联合解码器相比的优化过程，而且还使得扩展到大量类别成为可能，这在离散归一化流中目前是不可能的。基于类别归一化流，我们提出了GraphCNF，一个在图上的排列不变生成模型。GraphCNF实现了一个三步方法，逐步建模节点、边和邻接矩阵以提高效率。在分子生成方面，GraphCNF优于基于流的一次性和自回归的最先进方法。",
        "领域": "生成模型、图神经网络、分子生成",
        "问题": "如何在类别数据上有效应用归一化流技术",
        "动机": "类别数据缺乏内在顺序，传统去量化方法不适用，需要新的方法来建模类别数据之间的复杂关系",
        "方法": "通过变分推断联合优化连续表示和模型似然，使用因子化解码器引入归纳偏置，提出GraphCNF模型逐步建模图的节点、边和邻接矩阵",
        "关键词": [
            "类别归一化流",
            "变分推断",
            "图生成",
            "分子生成",
            "因子化解码器"
        ],
        "涉及的技术概念": {
            "归一化流": "一种生成模型技术，通过一系列可逆变换将简单分布转换为复杂分布",
            "变分推断": "用于近似复杂概率分布的技术，本文中用于优化类别数据的连续表示",
            "因子化解码器": "一种解码器设计，通过分解潜在变量的交互作用来简化模型优化和扩展"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 100,
        "title": "CausalWorld: A Robotic Manipulation Benchmark for Causal Structure and Transfer Learning",
        "html": "https://iclr.cc//virtual/2021/poster/2579",
        "abstract": "Despite recent successes of reinforcement learning (RL), it remains a challenge for agents to transfer learned skills to related environments. To facilitate research addressing this problem, we proposeCausalWorld, a benchmark for causal structure and transfer learning in a robotic manipulation environment. The environment is a simulation of an open-source robotic platform, hence offering the possibility of sim-to-real transfer. Tasks consist of constructing 3D shapes from a set of blocks - inspired by how children learn to build complex structures. The key strength of CausalWorld is that it provides a combinatorial family of such tasks with common causal structure and underlying factors (including, e.g., robot and object masses, colors, sizes). The user (or the agent) may intervene on all causal variables, which allows  for  fine-grained  control  over  how  similar  different  tasks  (or  task  distributions) are. One can thus easily define training and evaluation distributions of a desired difficulty level,  targeting a specific form of generalization (e.g.,  only changes in appearance or object mass). Further, this common parametrization facilitates defining curricula by interpolating between an initial and a target task. While users may define their own task distributions, we present eight meaningful distributions as concrete benchmarks, ranging from simple to very challenging, all of which require long-horizon planning as well as precise low-level motor control. Finally, we provide baseline results for a subset of these tasks on distinct training curricula and corresponding evaluation protocols, verifying the feasibility of the tasks in this benchmark.",
        "conference": "ICLR",
        "中文标题": "因果世界：面向因果结构与迁移学习的机器人操作基准",
        "摘要翻译": "尽管强化学习（RL）近期取得了成功，但智能体将学到的技能迁移到相关环境仍然是一个挑战。为了促进针对这一问题的研究，我们提出了CausalWorld，一个在机器人操作环境中用于因果结构和迁移学习的基准。该环境是一个开源机器人平台的模拟，因此提供了从模拟到现实迁移的可能性。任务包括从一组积木构建3D形状——灵感来源于儿童学习构建复杂结构的方式。CausalWorld的关键优势在于它提供了这样一系列具有共同因果结构和潜在因素（包括，例如，机器人和物体的质量、颜色、大小）的任务组合。用户（或智能体）可以干预所有因果变量，这允许对不同任务（或任务分布）之间的相似性进行细粒度控制。因此，可以轻松定义所需难度级别的训练和评估分布，针对特定形式的泛化（例如，仅外观或物体质量的变化）。此外，这种共同的参数化便于通过在初始任务和目标任务之间插值来定义课程。虽然用户可以定义自己的任务分布，但我们提出了八个有意义的分布作为具体基准，从简单到非常具有挑战性，所有这些都需要长期规划以及精确的低级运动控制。最后，我们为这些任务的一个子集提供了在不同训练课程和相应评估协议上的基线结果，验证了该基准中任务的可行性。",
        "领域": "机器人操作、迁移学习、因果推理",
        "问题": "智能体在强化学习中难以将学到的技能迁移到相关环境的问题",
        "动机": "为了提供一个能够促进研究智能体技能迁移问题的基准环境，特别是在机器人操作领域",
        "方法": "提出了CausalWorld基准，通过模拟开源机器人平台，提供具有共同因果结构和潜在因素的任务组合，允许用户干预因果变量，定义不同难度的任务分布",
        "关键词": [
            "机器人操作",
            "迁移学习",
            "因果推理",
            "强化学习",
            "模拟到现实迁移"
        ],
        "涉及的技术概念": {
            "因果结构": "在CausalWorld中，任务设计基于共同的因果结构，允许研究因果推理在技能迁移中的作用",
            "迁移学习": "基准旨在促进研究如何将在一个环境中学到的技能迁移到另一个相关环境",
            "模拟到现实迁移": "通过模拟开源机器人平台，研究结果可以更容易地迁移到现实世界的机器人操作中"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 101,
        "title": "CcGAN: Continuous Conditional Generative Adversarial Networks for Image Generation",
        "html": "https://iclr.cc//virtual/2021/poster/3022",
        "abstract": "This work proposes the continuous conditional generative adversarial network (CcGAN), the first generative model for image generation conditional on continuous, scalar conditions (termed regression labels). Existing conditional GANs (cGANs) are mainly designed for categorical conditions (e.g., class labels); conditioning on a continuous label is mathematically distinct and raises two fundamental problems: (P1) Since there may be very few (even zero) real images for some regression labels, minimizing existing empirical versions of cGAN losses (a.k.a. empirical cGAN losses) often fails in practice; (P2) Since regression labels are scalar and infinitely many, conventional label input methods (e.g., combining a hidden map of the generator/discriminator with a one-hot encoded label) are not applicable. The proposed CcGAN solves the above problems, respectively, by (S1) reformulating existing empirical cGAN losses to be appropriate for the continuous scenario; and (S2) proposing a novel method to incorporate regression labels into the generator and the discriminator. The reformulation in (S1) leads to two novel empirical discriminator losses, termed the hard vicinal discriminator loss (HVDL) and the soft vicinal discriminator loss (SVDL) respectively, and a novel empirical generator loss. The error bounds of a discriminator trained with HVDL and SVDL are derived under mild assumptions in this work. A new benchmark dataset, RC-49, is also proposed for generative image modeling conditional on regression labels. Our experiments on the Circular 2-D Gaussians, RC-49, and UTKFace datasets show that CcGAN is able to generate diverse, high-quality samples from the image distribution conditional on a given regression label. Moreover, in these experiments, CcGAN substantially outperforms cGAN both visually and quantitatively.",
        "conference": "ICLR",
        "中文标题": "CcGAN: 用于图像生成的连续条件生成对抗网络",
        "摘要翻译": "本研究提出了连续条件生成对抗网络（CcGAN），这是第一个基于连续标量条件（称为回归标签）进行图像生成的生成模型。现有的条件生成对抗网络（cGANs）主要设计用于分类条件（例如，类别标签）；基于连续标签的条件在数学上是不同的，并引发了两个基本问题：（P1）由于某些回归标签可能只有很少（甚至没有）真实图像，最小化现有的cGAN损失的经验版本（也称为经验cGAN损失）在实践中常常失败；（P2）由于回归标签是标量且无限多，传统的标签输入方法（例如，将生成器/判别器的隐藏图与独热编码标签结合）不适用。提出的CcGAN分别通过（S1）重新制定现有的经验cGAN损失以适应连续场景；和（S2）提出一种新方法将回归标签纳入生成器和判别器，解决了上述问题。（S1）中的重新制定导致了两种新颖的经验判别器损失，分别称为硬邻近判别器损失（HVDL）和软邻近判别器损失（SVDL），以及一种新颖的经验生成器损失。在本研究中，基于温和假设，推导了使用HVDL和SVDL训练的判别器的误差界限。还提出了一个新的基准数据集RC-49，用于基于回归标签的生成图像建模。我们在Circular 2-D Gaussians、RC-49和UTKFace数据集上的实验表明，CcGAN能够基于给定的回归标签从图像分布中生成多样化的高质量样本。此外，在这些实验中，CcGAN在视觉上和数量上都大大优于cGAN。",
        "领域": "生成对抗网络、图像生成、条件生成模型",
        "问题": "解决在连续标量条件下生成高质量图像的问题，克服现有条件生成对抗网络在连续标签条件下的不足。",
        "动机": "现有的条件生成对抗网络主要针对分类条件设计，无法有效处理连续标量条件下的图像生成问题，这限制了其在更广泛场景下的应用。",
        "方法": "通过重新制定经验cGAN损失以适应连续场景，并提出一种新方法将回归标签纳入生成器和判别器，解决了在连续标签条件下生成图像的问题。",
        "关键词": [
            "连续条件生成对抗网络",
            "图像生成",
            "回归标签",
            "硬邻近判别器损失",
            "软邻近判别器损失"
        ],
        "涉及的技术概念": {
            "连续条件生成对抗网络": "一种新型的生成对抗网络，能够在连续标量条件下生成图像。",
            "硬邻近判别器损失": "一种新颖的经验判别器损失，用于在连续条件下优化判别器。",
            "软邻近判别器损失": "另一种新颖的经验判别器损失，与HVDL相比，提供了不同的优化策略。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 102,
        "title": "Certify or Predict: Boosting Certified Robustness with Compositional Architectures",
        "html": "https://iclr.cc//virtual/2021/poster/3359",
        "abstract": "A core challenge with existing certified defense mechanisms is that while they improve certified robustness, they also tend to drastically decrease natural accuracy, making it difficult to use these methods in practice. In this work, we propose a new architecture which addresses this challenge and enables one to boost the certified robustness of any state-of-the-art deep network, while controlling the overall accuracy loss, without requiring retraining. The key idea is to combine this model with a (smaller) certified network where at inference time, an adaptive selection mechanism decides on the network to process the input sample. The approach is compositional: one can combine any pair of state-of-the-art (e.g., EfficientNet or ResNet) and certified networks, without restriction. The resulting architecture enables much higher natural accuracy than previously possible with certified defenses alone, while substantially boosting the certified robustness of deep networks. We demonstrate the effectiveness of this adaptive approach on a variety of datasets and architectures.  For instance, on CIFAR-10 with an $\\ell_\\infty$ perturbation of 2/255, we are the first to obtain a high natural accuracy (90.1%) with non-trivial certified robustness (27.5%). Notably, prior state-of-the-art methods incur a substantial drop in accuracy for a similar certified robustness.",
        "conference": "ICLR",
        "中文标题": "认证或预测：通过组合架构提升认证鲁棒性",
        "摘要翻译": "现有认证防御机制的一个核心挑战是，虽然它们提高了认证鲁棒性，但也往往大幅降低自然准确率，这使得这些方法在实际应用中难以使用。在这项工作中，我们提出了一种新的架构，旨在解决这一挑战，并能够在不需要重新训练的情况下，提升任何最先进深度网络的认证鲁棒性，同时控制总体准确率损失。关键思想是将该模型与一个（较小的）认证网络结合，在推理时，一个自适应选择机制决定处理输入样本的网络。这种方法具有组合性：可以不受限制地结合任何一对最先进的（例如，EfficientNet或ResNet）和认证网络。由此产生的架构能够实现比单独使用认证防御更高的自然准确率，同时显著提升深度网络的认证鲁棒性。我们在多种数据集和架构上证明了这种自适应方法的有效性。例如，在CIFAR-10上，对于2/255的ℓ∞扰动，我们首次实现了高自然准确率（90.1%）与非平凡认证鲁棒性（27.5%）的结合。值得注意的是，先前的最先进方法在类似认证鲁棒性下会导致准确率大幅下降。",
        "领域": "深度学习安全、对抗性防御、模型鲁棒性",
        "问题": "如何在提升深度网络认证鲁棒性的同时，避免自然准确率的大幅下降。",
        "动机": "解决现有认证防御机制在提高认证鲁棒性时导致自然准确率显著下降的问题，使得认证防御方法更适用于实际应用。",
        "方法": "提出一种组合架构，将最先进的深度网络与小型认证网络结合，通过自适应选择机制在推理时决定处理输入样本的网络，从而在不需重新训练的情况下提升认证鲁棒性并控制准确率损失。",
        "关键词": [
            "认证鲁棒性",
            "组合架构",
            "自适应选择",
            "深度网络",
            "对抗性防御"
        ],
        "涉及的技术概念": {
            "认证鲁棒性": "指模型在对抗性攻击下保持性能的能力，通过数学证明确保模型在特定扰动范围内的输出不变。",
            "组合架构": "将不同类型的网络结构（如最先进的深度网络和认证网络）结合使用，以发挥各自优势的架构设计。",
            "自适应选择机制": "在推理过程中根据输入样本动态选择最合适的网络进行处理，以平衡认证鲁棒性和自然准确率。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 103,
        "title": "Chaos of Learning Beyond Zero-sum and Coordination via Game Decompositions",
        "html": "https://iclr.cc//virtual/2021/poster/3191",
        "abstract": "It is of primary interest for ML to understand how agents learn and interact dynamically in competitive environments and games (e.g. GANs). But this has been a difficult task, as irregular behaviors are commonly observed in such systems. This can be explained theoretically, for instance, by the works of Cheung and Piliouras (COLT 2019; NeurIPS 2020), which showed that in two-person zero-sum games, if agents employ one of the most well-known learning algorithms, Multiplicative Weights Update (MWU), then Lyapunov chaos occurs everywhere in the payoff space. In this paper, we study how persistent chaos can occur in the more general normal game settings, where the agents might have the motivation to coordinate (which is not true for zero-sum games) and the number of agents can be arbitrary.\n\nWe characterize bimatrix games where MWU, its optimistic variant (OMWU) or Follow-the-Regularized-Leader (FTRL) algorithms are Lyapunov chaotic almost everywhere in the payoff space. Technically, our characterization is derived by extending the volume-expansion argument of Cheung and Piliouras via the canonical game decomposition into zero-sum and coordination components. Interestingly, the two components induce opposite volume-changing behaviors, so the overall behavior can be analyzed by comparing the strengths of the components against each other. The comparison is done via our new notion of 'matrix domination' or via a linear program. For multi-player games, we present a local equivalence of volume change between general games and graphical games, which is used to perform volume and chaos analyses of MWU and OMWU in potential games.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "通过博弈分解学习超越零和与协调的混沌",
        "摘要翻译": "机器学习（ML）的一个主要兴趣点在于理解代理在竞争环境和游戏（如生成对抗网络GANs）中如何动态学习和互动。然而，这一直是一项艰巨的任务，因为在这些系统中经常观察到不规则行为。理论上可以对此进行解释，例如Cheung和Piliouras（COLT 2019; NeurIPS 2020）的工作表明，在两人零和博弈中，如果代理采用最著名的学习算法之一——乘性权重更新（MWU），则在支付空间中处处出现Lyapunov混沌。在本文中，我们研究了在更一般的正常博弈设置中，如何出现持续的混沌，其中代理可能有协调的动机（这在零和博弈中是不成立的），并且代理的数量可以是任意的。我们描述了在支付空间中几乎处处Lyapunov混沌的双矩阵博弈，其中使用了MWU、其乐观变体（OMWU）或跟随正则化领导者（FTRL）算法。技术上，我们的描述是通过将Cheung和Piliouras的体积扩展论证扩展到将博弈规范分解为零和与协调组件而得到的。有趣的是，这两个组件诱导了相反的体积变化行为，因此可以通过比较组件之间的强度来分析整体行为。这种比较是通过我们的新概念‘矩阵支配’或线性程序来完成的。对于多玩家博弈，我们提出了通用博弈和图形博弈之间体积变化的局部等价性，用于在潜在博弈中对MWU和OMWU进行体积和混沌分析。",
        "领域": "博弈论与机器学习结合、多智能体系统、生成对抗网络",
        "问题": "理解在竞争环境和游戏中代理如何动态学习和互动，以及不规则行为的出现机制",
        "动机": "探索在更一般的博弈设置中持续混沌的出现机制，特别是在代理可能有协调动机且数量任意的情境下",
        "方法": "通过扩展体积扩展论证，将博弈分解为零和与协调组件，并比较这些组件的强度来分析整体行为",
        "关键词": [
            "博弈分解",
            "Lyapunov混沌",
            "乘性权重更新",
            "多智能体系统",
            "潜在博弈"
        ],
        "涉及的技术概念": {
            "乘性权重更新（MWU）": "一种在博弈论中广泛使用的学习算法，用于调整代理的策略权重",
            "Lyapunov混沌": "描述在动态系统中，初始条件的微小变化导致系统行为巨大差异的现象",
            "博弈分解": "将复杂博弈分解为零和与协调组件，以便于分析和理解代理行为的技术"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 104,
        "title": "Characterizing signal propagation to close the performance gap in unnormalized ResNets",
        "html": "https://iclr.cc//virtual/2021/poster/3029",
        "abstract": "Batch Normalization is a key component in almost all state-of-the-art image classifiers, but it also introduces practical challenges: it breaks the independence between training examples within a batch, can incur compute and memory overhead, and often results in unexpected bugs. Building on recent theoretical analyses of deep ResNets at initialization, we propose a simple set of analysis tools to characterize signal propagation on the forward pass, and leverage these tools to design highly performant ResNets without activation normalization layers.  Crucial to our success is an adapted version of the recently proposed Weight Standardization.  Our analysis tools show how this technique preserves the signal in ReLU networks by ensuring that the per-channel activation means do not grow with depth. Across a range of FLOP budgets, our networks attain performance competitive with state-of-the-art EfficientNets on ImageNet.",
        "conference": "ICLR",
        "中文标题": "表征信号传播以缩小未归一化ResNets的性能差距",
        "摘要翻译": "批量归一化是几乎所有最先进图像分类器的关键组成部分，但它也带来了实际挑战：它破坏了批次内训练样本之间的独立性，可能导致计算和内存开销，并经常引发意外错误。基于最近对初始化时深度ResNets的理论分析，我们提出了一套简单的分析工具来表征前向传递中的信号传播，并利用这些工具设计了无需激活归一化层的高性能ResNets。我们成功的关键在于采用了最近提出的权重标准化的一个适应版本。我们的分析工具展示了该技术如何通过确保每通道激活均值不随深度增长来保持ReLU网络中的信号。在一系列FLOP预算范围内，我们的网络在ImageNet上达到了与最先进EfficientNets竞争的性能。",
        "领域": "深度学习架构设计, 图像分类, 神经网络优化",
        "问题": "解决批量归一化在实际应用中带来的挑战，如训练样本独立性破坏、计算和内存开销增加等问题。",
        "动机": "探索无需激活归一化层的高性能ResNets设计，以减少批量归一化的负面影响。",
        "方法": "提出一套分析工具来表征信号传播，并利用这些工具结合权重标准化技术设计高性能ResNets。",
        "关键词": [
            "ResNets",
            "权重标准化",
            "信号传播",
            "ImageNet",
            "EfficientNets"
        ],
        "涉及的技术概念": {
            "权重标准化": "一种技术，用于调整网络权重以保持信号在前向传播过程中的稳定性，特别是在没有批量归一化的情况下。",
            "信号传播": "分析工具用于理解和优化神经网络中信息流动的方式，特别是在深度网络中。",
            "ReLU网络": "使用ReLU激活函数的神经网络，本文中通过特定技术保持其信号不随深度增长而衰减。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 105,
        "title": "ChipNet: Budget-Aware Pruning with Heaviside Continuous Approximations",
        "html": "https://iclr.cc//virtual/2021/poster/2768",
        "abstract": "Structured pruning methods are among the effective strategies for extracting small resource-efficient convolutional neural networks from their dense counterparts with minimal loss in accuracy. However, most existing methods still suffer from one or more limitations, that include 1) the need for training the dense model from scratch with pruning-related parameters embedded in the architecture, 2) requiring model-specific hyperparameter settings, 3) inability to include budget-related constraint in the training process, and 4) instability under scenarios of extreme pruning. In this paper, we present ChipNet, a deterministic pruning strategy that employs continuous Heaviside function and a novel crispness loss to identify a highly sparse network out of an existing dense network. Our choice of continuous Heaviside function is inspired by the field of design optimization, where the material distribution task is posed as a continuous optimization problem, but only discrete values (0 or 1) are practically feasible and expected as final outcomes. Our approach's flexible design facilitates its use with different choices of budget constraints while maintaining stability for very low target budgets. Experimental results show that ChipNet outperforms state-of-the-art structured pruning methods by remarkable margins of up to 16.1% in terms of accuracy. Further, we show that the masks obtained with ChipNet are transferable across datasets. For certain cases, it was observed that masks transferred from a model trained on feature-rich teacher dataset provide better performance on the student dataset than those obtained by directly pruning on the student data itself.",
        "conference": "ICLR",
        "中文标题": "ChipNet：基于海维赛德连续近似的预算感知剪枝",
        "摘要翻译": "结构化剪枝方法是从密集网络中提取小型资源高效卷积神经网络的有效策略之一，且能最小化准确率损失。然而，大多数现有方法仍存在一个或多个限制，包括：1）需要从头开始训练密集模型，并在架构中嵌入与剪枝相关的参数；2）需要模型特定的超参数设置；3）无法在训练过程中包含与预算相关的约束；4）在极端剪枝场景下不稳定。本文提出ChipNet，一种确定性剪枝策略，采用连续海维赛德函数和新颖的清晰度损失，从现有密集网络中识别出高度稀疏的网络。我们选择连续海维赛德函数的灵感来自设计优化领域，其中材料分布任务被视为连续优化问题，但实际可行且期望的最终结果仅为离散值（0或1）。我们方法的灵活设计便于其与不同预算约束选择一起使用，同时在极低目标预算下保持稳定性。实验结果表明，ChipNet在准确率方面以高达16.1%的显著优势优于最先进的结构化剪枝方法。此外，我们还展示了通过ChipNet获得的掩码可在不同数据集间转移。在某些情况下，观察到从特征丰富的教师数据集训练的模型转移来的掩码，在学生数据集上的表现优于直接对学生数据进行剪枝获得的掩码。",
        "领域": "神经网络剪枝、深度学习优化、计算机视觉",
        "问题": "解决现有结构化剪枝方法在训练需求、超参数设置、预算约束和极端剪枝稳定性方面的限制",
        "动机": "开发一种能够在不牺牲准确率的前提下，高效地从密集网络中提取小型资源高效卷积神经网络的剪枝方法",
        "方法": "采用连续海维赛德函数和清晰度损失进行确定性剪枝，支持不同预算约束并保持极端剪枝下的稳定性",
        "关键词": [
            "结构化剪枝",
            "海维赛德函数",
            "预算约束",
            "神经网络优化",
            "模型压缩"
        ],
        "涉及的技术概念": {
            "连续海维赛德函数": "用于在剪枝过程中近似离散决策，使得优化问题可微，便于梯度下降优化",
            "清晰度损失": "一种新颖的损失函数，用于促进剪枝决策的二值化，提高剪枝后的网络性能",
            "预算约束": "在剪枝过程中引入的资源限制，确保剪枝后的网络满足特定的计算或存储预算"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 106,
        "title": "Clairvoyance: A Pipeline Toolkit for Medical Time Series",
        "html": "https://iclr.cc//virtual/2021/poster/2791",
        "abstract": "Time-series learning is the bread and butter of data-driven *clinical decision support*, and the recent explosion in ML research has demonstrated great potential in various healthcare settings. At the same time, medical time-series problems in the wild are challenging due to their highly *composite* nature: They entail design choices and interactions among components that preprocess data, impute missing values, select features, issue predictions, estimate uncertainty, and interpret models. Despite exponential growth in electronic patient data, there is a remarkable gap between the potential and realized utilization of ML for clinical research and decision support. In particular, orchestrating a real-world project lifecycle poses challenges in engineering (i.e. hard to build), evaluation (i.e. hard to assess), and efficiency (i.e. hard to optimize). Designed to address these issues simultaneously, Clairvoyance proposes a unified, end-to-end, autoML-friendly pipeline that serves as a (i) software toolkit, (ii) empirical standard, and (iii) interface for optimization. Our ultimate goal lies in facilitating transparent and reproducible experimentation with complex inference workflows, providing integrated pathways for (1) personalized prediction, (2) treatment-effect estimation, and (3) information acquisition. Through illustrative examples on real-world data in outpatient, general wards, and intensive-care settings, we illustrate the applicability of the pipeline paradigm on core tasks in the healthcare journey. To the best of our knowledge, Clairvoyance is the first to demonstrate viability of a comprehensive and automatable pipeline for clinical time-series ML.",
        "conference": "ICLR",
        "中文标题": "预见力：医疗时间序列的管道工具包",
        "摘要翻译": "时间序列学习是数据驱动的临床决策支持的基石，近期机器学习研究的爆炸性增长展示了在多种医疗场景中的巨大潜力。然而，现实世界中的医疗时间序列问题因其高度复合性而充满挑战：它们涉及数据预处理、缺失值填补、特征选择、预测发布、不确定性估计和模型解释等组件的设计选择和交互。尽管电子患者数据呈指数级增长，但机器学习在临床研究和决策支持中的潜在与实际利用之间仍存在显著差距。特别是，协调现实世界项目生命周期在工程（即难以构建）、评估（即难以评估）和效率（即难以优化）方面提出了挑战。为解决这些问题，预见力提出了一个统一的、端到端的、对自动机器学习友好的管道，作为（i）软件工具包，（ii）实证标准，和（iii）优化接口。我们的最终目标在于促进复杂推理工作流程的透明和可重复实验，为（1）个性化预测，（2）治疗效果估计，和（3）信息获取提供集成路径。通过在门诊、普通病房和重症监护环境中的真实数据上的示例，我们展示了管道范式在医疗旅程核心任务上的适用性。据我们所知，预见力是首个展示临床时间序列机器学习全面且可自动化管道可行性的工作。",
        "领域": "医疗时间序列分析、临床决策支持系统、自动机器学习",
        "问题": "解决医疗时间序列分析中的工程、评估和效率挑战",
        "动机": "促进机器学习在临床研究和决策支持中的透明和可重复利用",
        "方法": "提出一个统一的、端到端的、对自动机器学习友好的管道工具包",
        "关键词": [
            "医疗时间序列",
            "临床决策支持",
            "自动机器学习",
            "管道工具包",
            "个性化预测"
        ],
        "涉及的技术概念": {
            "时间序列学习": "用于分析和预测医疗时间序列数据的技术",
            "自动机器学习（AutoML）": "自动化机器学习流程，包括数据预处理、特征选择、模型选择和优化",
            "临床决策支持系统": "利用机器学习技术辅助医疗决策，提高诊断和治疗的准确性和效率"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 107,
        "title": "Class Normalization for (Continual)? Generalized Zero-Shot Learning",
        "html": "https://iclr.cc//virtual/2021/poster/3288",
        "abstract": "Normalization techniques have proved to be a crucial ingredient of successful training in a traditional supervised learning regime. However, in the zero-shot learning (ZSL) world, these ideas have received only marginal attention. This work studies normalization in ZSL scenario from both theoretical and practical perspectives. First, we give a theoretical explanation to two popular tricks used in zero-shot learning: normalize+scale and attributes normalization and show that they help training by preserving variance during a forward pass. Next, we demonstrate that they are insufficient to normalize a deep ZSL model and propose Class Normalization (CN): a normalization scheme, which alleviates this issue both provably and in practice. Third, we show that ZSL models typically have more irregular loss surface compared to traditional classifiers and that the proposed method partially remedies this problem. Then, we test our approach on 4 standard ZSL datasets and outperform sophisticated modern SotA with a simple MLP optimized without any bells and whistles and having ~50 times faster training speed. Finally, we generalize ZSL to a broader problem — continual ZSL, and introduce some principled metrics and rigorous baselines for this new setup. The source code is available at https://github.com/universome/class-norm.",
        "conference": "ICLR",
        "中文标题": "类别归一化用于（持续）广义零样本学习",
        "摘要翻译": "归一化技术已被证明是传统监督学习成功训练的关键因素。然而，在零样本学习（ZSL）领域，这些思想仅受到了边缘性的关注。本研究从理论和实践两个角度探讨了ZSL场景下的归一化问题。首先，我们对零样本学习中使用的两种流行技巧：归一化+缩放和属性归一化，给出了理论解释，并表明它们通过在前向传播过程中保持方差来帮助训练。接着，我们证明了这些方法不足以归一化一个深度ZSL模型，并提出了类别归一化（CN）：一种归一化方案，它从理论上和实践上都缓解了这一问题。第三，我们展示了ZSL模型通常比传统分类器具有更不规则的损失表面，并且所提出的方法部分解决了这个问题。然后，我们在4个标准的ZSL数据集上测试了我们的方法，并且用一个没有使用任何花哨技巧、训练速度约快50倍的简单MLP优化，超越了复杂的现代SotA。最后，我们将ZSL推广到一个更广泛的问题——持续ZSL，并为这一新设置引入了一些原则性的指标和严格的基线。源代码可在https://github.com/universome/class-norm获取。",
        "领域": "零样本学习, 深度学习优化, 持续学习",
        "问题": "解决零样本学习中的模型归一化问题，以及推广到持续学习环境下的适应性",
        "动机": "探索归一化技术在零样本学习中的应用，提升模型训练效率和性能",
        "方法": "提出类别归一化（CN）方案，通过理论和实践验证其在深度ZSL模型中的有效性，并在持续ZSL环境中引入新的评估指标和基线",
        "关键词": [
            "类别归一化",
            "零样本学习",
            "持续学习",
            "模型优化",
            "深度学习"
        ],
        "涉及的技术概念": {
            "归一化+缩放": "在零样本学习中用于保持前向传播过程中的方差，帮助训练",
            "属性归一化": "对属性进行归一化处理，以提升模型在零样本学习中的表现",
            "类别归一化（CN）": "提出的归一化方案，旨在解决深度ZSL模型中的归一化不足问题，提升模型性能"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 108,
        "title": "C-Learning: Horizon-Aware Cumulative Accessibility Estimation",
        "html": "https://iclr.cc//virtual/2021/poster/3171",
        "abstract": "Multi-goal reaching is an important problem in reinforcement learning needed to achieve algorithmic generalization. Despite recent advances in this field, current algorithms suffer from three major challenges: high sample complexity, learning only a single way of reaching the goals,  and difficulties in solving complex motion planning tasks. In order to address these limitations, we introduce the concept of cumulative accessibility functions, which measure the reachability of a goal from a given state within a specified horizon. We show that these functions obey a recurrence relation, which enables learning from offline interactions. We also prove that optimal cumulative accessibility functions are monotonic in the planning horizon. Additionally, our method can trade off speed and reliability in goal-reaching by suggesting multiple paths to a single goal depending on the provided horizon. We evaluate our approach on a set of multi-goal discrete and continuous control tasks. We show that our method outperforms state-of-the-art goal-reaching algorithms in success rate, sample complexity, and path optimality. Our code is available at https://github.com/layer6ai-labs/CAE, and additional visualizations can be found at https://sites.google.com/view/learning-cae/.",
        "conference": "ICLR",
        "中文标题": "C-学习：基于视野的累积可达性估计",
        "摘要翻译": "多目标达成是强化学习中实现算法泛化的重要问题。尽管该领域最近取得了进展，但现有算法仍面临三大挑战：高样本复杂度、仅学习单一达成目标的方式以及在解决复杂运动规划任务时的困难。为了解决这些限制，我们引入了累积可达性函数的概念，该函数衡量在指定视野内从给定状态到达目标的可达性。我们证明了这些函数遵循递推关系，这使得可以从离线交互中学习。我们还证明了最优累积可达性函数在规划视野中是单调的。此外，我们的方法可以通过根据提供的视野为单一目标建议多条路径，来权衡速度和可靠性。我们在多目标离散和连续控制任务集上评估了我们的方法。结果表明，我们的方法在成功率、样本复杂度和路径最优性方面优于最先进的目标达成算法。我们的代码可在https://github.com/layer6ai-labs/CAE获取，更多可视化内容可在https://sites.google.com/view/learning-cae/找到。",
        "领域": "强化学习、运动规划、算法泛化",
        "问题": "解决多目标达成问题中的高样本复杂度、单一达成路径和复杂运动规划困难",
        "动机": "提高强化学习在多目标达成任务中的效率、多样性和适应性",
        "方法": "引入累积可达性函数，利用递推关系从离线交互中学习，并通过调整视野权衡速度和可靠性",
        "关键词": [
            "累积可达性函数",
            "多目标强化学习",
            "运动规划",
            "算法泛化",
            "离线学习"
        ],
        "涉及的技术概念": {
            "累积可达性函数": "衡量在指定视野内从给定状态到达目标的可达性，用于优化路径规划",
            "递推关系": "使得累积可达性函数可以从离线交互中学习，提高学习效率",
            "规划视野": "影响路径规划的速度和可靠性，通过调整视野可以权衡这两者"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 109,
        "title": "C-Learning: Learning to Achieve Goals via Recursive Classification",
        "html": "https://iclr.cc//virtual/2021/poster/2583",
        "abstract": "We study the problem of predicting and controlling the future state distribution of an autonomous agent. This problem, which can be viewed as a reframing of goal-conditioned reinforcement learning (RL), is centered around learning a conditional probability density function over future states. Instead of directly estimating this density function, we indirectly estimate this density function by training a classifier to predict whether an observation comes from the future. Via Bayes' rule, predictions from our classifier can be transformed into predictions over future states. Importantly, an off-policy variant of our algorithm allows us to predict the future state distribution of a new policy, without collecting new experience. This variant allows us to optimize functionals of a policy's future state distribution, such as the density of reaching a particular goal state. While conceptually similar to Q-learning, our work lays a principled foundation for goal-conditioned RL as density estimation, providing justification for goal-conditioned methods used in prior work. This foundation makes hypotheses about Q-learning, including the optimal goal-sampling ratio, which we confirm experimentally. Moreover, our proposed method is competitive with prior goal-conditioned RL methods.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "C-学习：通过递归分类实现目标的学习",
        "摘要翻译": "我们研究了预测和控制自主代理未来状态分布的问题。这一问题可以被视为目标条件强化学习（RL）的重新框架，其核心是学习一个关于未来状态的条件概率密度函数。我们没有直接估计这个密度函数，而是通过训练一个分类器来预测一个观察是否来自未来，从而间接估计这个密度函数。通过贝叶斯规则，我们分类器的预测可以转化为对未来状态的预测。重要的是，我们算法的一个离策略变体允许我们预测新策略的未来状态分布，而无需收集新的经验。这一变体使我们能够优化策略未来状态分布的函数，例如达到特定目标状态的密度。虽然在概念上与Q学习相似，但我们的工作为目标条件RL作为密度估计奠定了原则性基础，为先前工作中使用的目标条件方法提供了合理性。这一基础对Q学习提出了假设，包括最优目标采样比例，我们通过实验证实了这一点。此外，我们提出的方法与先前的目标条件RL方法相比具有竞争力。",
        "领域": "目标条件强化学习",
        "问题": "预测和控制自主代理未来状态分布的问题",
        "动机": "为目标条件强化学习作为密度估计奠定原则性基础，提供先前工作中使用的目标条件方法的合理性",
        "方法": "通过训练一个分类器来预测一个观察是否来自未来，间接估计未来状态的条件概率密度函数",
        "关键词": [
            "目标条件强化学习",
            "密度估计",
            "递归分类",
            "贝叶斯规则",
            "离策略学习"
        ],
        "涉及的技术概念": {
            "条件概率密度函数": "用于描述在给定条件下未来状态的概率分布",
            "贝叶斯规则": "将分类器的预测转化为对未来状态的预测",
            "离策略学习": "允许预测新策略的未来状态分布，而无需收集新的经验"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 110,
        "title": "Clustering-friendly Representation Learning via Instance Discrimination and Feature Decorrelation",
        "html": "https://iclr.cc//virtual/2021/poster/2836",
        "abstract": "Clustering is one of the most fundamental tasks in machine learning. Recently, deep clustering has become a major trend in clustering techniques. Representation learning often plays an important role in the effectiveness of deep clustering, and thus can be a principal cause of performance degradation. In this paper, we propose a clustering-friendly representation learning method using instance discrimination and feature decorrelation. Our deep-learning-based representation learning method is motivated by the properties of classical spectral clustering. Instance discrimination learns similarities among data and feature decorrelation removes redundant correlation among features. We utilize an instance discrimination method in which learning individual instance classes leads to learning similarity among instances. Through detailed experiments and examination, we show that the approach can be adapted to learning a latent space for clustering. We design novel softmax-formulated decorrelation constraints for learning. In evaluations of image clustering using CIFAR-10 and ImageNet-10, our method achieves accuracy of 81.5% and 95.4%, respectively. We also show that the softmax-formulated constraints are compatible with various neural networks.",
        "conference": "ICLR",
        "中文标题": "通过实例判别与特征解耦实现聚类友好的表示学习",
        "摘要翻译": "聚类是机器学习中最基本的任务之一。近年来，深度聚类已成为聚类技术的主要趋势。表示学习在深度聚类的有效性中常扮演重要角色，因而可能是性能下降的主要原因。在本文中，我们提出了一种使用实例判别和特征解耦的聚类友好表示学习方法。我们基于深度学习的表示学习方法的灵感来源于经典谱聚类的特性。实例判别学习数据间的相似性，而特征解耦则去除特征间的冗余相关性。我们采用了一种实例判别方法，其中学习单个实例类别导致学习实例间的相似性。通过详细的实验和检查，我们展示了该方法可以适应于学习用于聚类的潜在空间。我们设计了新颖的softmax公式化解耦约束用于学习。在使用CIFAR-10和ImageNet-10进行的图像聚类评估中，我们的方法分别达到了81.5%和95.4%的准确率。我们还展示了softmax公式化的约束与各种神经网络兼容。",
        "领域": "深度聚类、表示学习、图像聚类",
        "问题": "解决深度聚类中表示学习导致的性能下降问题",
        "动机": "通过实例判别和特征解耦提升表示学习对深度聚类的友好性",
        "方法": "结合实例判别学习数据相似性和特征解耦去除冗余相关性，设计softmax公式化的解耦约束",
        "关键词": [
            "深度聚类",
            "表示学习",
            "实例判别",
            "特征解耦",
            "softmax约束"
        ],
        "涉及的技术概念": {
            "实例判别": "通过学习单个实例类别来学习实例间的相似性，用于提升聚类的准确性",
            "特征解耦": "去除特征间的冗余相关性，以提高表示学习的效率和效果",
            "softmax公式化约束": "设计用于学习的解耦约束，兼容多种神经网络结构"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 111,
        "title": "CO2: Consistent Contrast for Unsupervised Visual Representation Learning",
        "html": "https://iclr.cc//virtual/2021/poster/3354",
        "abstract": "Contrastive learning has recently been a core for unsupervised visual representation learning. Without human annotation, the common practice is to perform an instance discrimination task: Given a query image crop, label crops from the same image as positives, and crops from other randomly sampled images as negatives. An important limitation of this label assignment is that it can not reflect the heterogeneous similarity of the query crop to crops from other images, but regarding them as equally negative. To address this issue, inspired by consistency regularization in semi-supervised learning, we propose Consistent Contrast (CO2), which introduces a consistency term into unsupervised contrastive learning framework. The consistency term takes the similarity of the query crop to crops from other images as unlabeled, and the corresponding similarity of a positive crop as a pseudo label. It then encourages consistency between these two similarities. Empirically, CO2 improves Momentum Contrast (MoCo) by 2.9% top-1 accuracy on ImageNet linear protocol, 3.8% and 1.1% top-5 accuracy on 1% and 10% labeled semi-supervised settings. It also transfers to image classification, object detection, and semantic segmentation on PASCAL VOC. This shows that CO2 learns better visual representations for downstream tasks.",
        "conference": "ICLR",
        "中文标题": "CO2：无监督视觉表示学习中的一致性对比",
        "摘要翻译": "对比学习最近成为无监督视觉表示学习的核心。在没有人工标注的情况下，常见的做法是执行一个实例判别任务：给定一个查询图像裁剪，将来自同一图像的裁剪标记为正样本，而将来自其他随机采样图像的裁剪标记为负样本。这种标签分配的一个重要限制是它不能反映查询裁剪与其他图像裁剪的异质性相似度，而是将它们视为同等负样本。为了解决这个问题，受半监督学习中一致性正则化的启发，我们提出了一致性对比（CO2），它将一致性项引入无监督对比学习框架中。一致性项将查询裁剪与其他图像裁剪的相似度视为未标记，而将正裁剪的相应相似度视为伪标签。然后，它鼓励这两种相似度之间的一致性。实证上，CO2在ImageNet线性协议上将动量对比（MoCo）的top-1准确率提高了2.9%，在1%和10%标记的半监督设置下，top-5准确率分别提高了3.8%和1.1%。它还可以迁移到PASCAL VOC上的图像分类、目标检测和语义分割。这表明CO2为下游任务学习了更好的视觉表示。",
        "领域": "无监督学习、对比学习、视觉表示学习",
        "问题": "解决无监督对比学习中负样本标签分配不能反映异质性相似度的问题",
        "动机": "通过引入一致性项，改进无监督对比学习中的标签分配策略，以更好地反映样本间的相似度",
        "方法": "提出一致性对比（CO2）方法，通过引入一致性项来鼓励查询裁剪与其他图像裁剪相似度之间的一致性",
        "关键词": [
            "一致性对比",
            "无监督学习",
            "视觉表示学习",
            "对比学习",
            "半监督学习"
        ],
        "涉及的技术概念": {
            "一致性对比（CO2）": "一种改进的无监督对比学习方法，通过引入一致性项来优化标签分配",
            "动量对比（MoCo）": "一种无监督视觉表示学习方法，CO2在其基础上进行了改进",
            "伪标签": "在半监督学习中，用于未标记数据的预测标签，CO2中用于表示正裁剪的相似度"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 112,
        "title": "CoCo: Controllable Counterfactuals for Evaluating Dialogue State Trackers",
        "html": "https://iclr.cc//virtual/2021/poster/3227",
        "abstract": "Dialogue state trackers have made significant progress on benchmark datasets, but their generalization capability to novel and realistic scenarios beyond the held- out conversations is less understood. We propose controllable counterfactuals (COCO) to bridge this gap and evaluate dialogue state tracking (DST) models on novel scenarios, i.e., would the system successfully tackle the request if the user responded differently but still consistently with the dialogue flow? COCO leverages turn-level belief states as counterfactual conditionals to produce novel conversation scenarios in two steps: (i) counterfactual goal generation at turn- level by dropping and adding slots followed by replacing slot values, (ii) counterfactual conversation generation that is conditioned on (i) and consistent with the dialogue flow. Evaluating state-of-the-art DST models on MultiWOZ dataset with COCO-generated counterfactuals results in a significant performance drop of up to 30.8% (from 49.4% to 18.6%) in absolute joint goal accuracy. In comparison, widely used techniques like paraphrasing only affect the accuracy by at most 2%. Human evaluations show that COCO-generated conversations perfectly reflect the underlying user goal with more than 95% accuracy and are as human-like as the original conversations, further strengthening its reliability and promise to be adopted as part of the robustness evaluation of DST models.",
        "conference": "ICLR",
        "中文标题": "CoCo: 用于评估对话状态跟踪器的可控反事实",
        "摘要翻译": "对话状态跟踪器在基准数据集上取得了显著进展，但它们对于超出保留对话的新颖和现实场景的泛化能力了解较少。我们提出了可控反事实（COCO）来弥合这一差距，并在新颖场景下评估对话状态跟踪（DST）模型，即如果用户以不同但仍然符合对话流程的方式回应，系统是否能成功处理请求？COCO利用回合级别的信念状态作为反事实条件，通过两个步骤产生新颖的对话场景：（i）通过丢弃和添加槽位然后替换槽位值，在回合级别生成反事实目标；（ii）生成基于（i）并与对话流程一致的反事实对话。在MultiWOZ数据集上使用COCO生成的反事实评估最先进的DST模型，导致绝对联合目标准确率显著下降高达30.8%（从49.4%降至18.6%）。相比之下，广泛使用的技术如释义最多只影响准确率2%。人类评估显示，COCO生成的对话以超过95%的准确率完美反映了潜在的用户目标，并且与原始对话一样人性化，进一步强化了其可靠性，并有望被采纳为DST模型鲁棒性评估的一部分。",
        "领域": "对话系统、自然语言处理、对话状态跟踪",
        "问题": "评估对话状态跟踪器在新颖和现实场景下的泛化能力",
        "动机": "理解对话状态跟踪器在超出保留对话的新颖和现实场景中的表现",
        "方法": "利用回合级别的信念状态作为反事实条件，通过生成反事实目标和对话来评估模型",
        "关键词": [
            "对话状态跟踪",
            "可控反事实",
            "MultiWOZ数据集",
            "泛化能力",
            "鲁棒性评估"
        ],
        "涉及的技术概念": {
            "可控反事实（COCO）": "用于生成新颖对话场景以评估对话状态跟踪器的方法",
            "回合级别信念状态": "作为反事实条件，用于生成与对话流程一致的新颖对话场景",
            "绝对联合目标准确率": "评估对话状态跟踪器性能的指标，反映模型在所有目标上的准确率"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 113,
        "title": "CoCon: A Self-Supervised Approach for Controlled Text Generation",
        "html": "https://iclr.cc//virtual/2021/poster/3002",
        "abstract": "Pretrained Transformer-based language models (LMs) display remarkable natural language generation capabilities. With their immense potential, controlling text generation of such LMs is getting attention. While there are studies that seek to control high-level attributes (such as sentiment and topic) of generated text, there is still a lack of more precise control over its content at the word- and phrase-level. Here, we propose Content-Conditioner (CoCon) to control an LM's output text with a content input, at a fine-grained level. In our self-supervised approach, the CoCon block learns to help the LM complete a partially-observed text sequence by conditioning with content inputs that are withheld from the LM. Through experiments, we show that CoCon can naturally incorporate target content into generated texts and control high-level text attributes in a zero-shot manner.",
        "conference": "ICLR",
        "中文标题": "CoCon：一种自监督的受控文本生成方法",
        "摘要翻译": "基于Transformer的预训练语言模型（LMs）展现了卓越的自然语言生成能力。随着其巨大潜力的显现，控制这类LMs的文本生成正受到关注。尽管已有研究试图控制生成文本的高级属性（如情感和主题），但在词和短语级别上对其内容进行更精确的控制仍然缺乏。在此，我们提出了内容调节器（CoCon），以细粒度级别通过内容输入来控制LM的输出文本。在我们的自监督方法中，CoCon模块通过学习帮助LM完成部分观察到的文本序列，通过调节被LM保留的内容输入。通过实验，我们展示了CoCon能够自然地将目标内容融入生成的文本中，并以零样本方式控制高级文本属性。",
        "领域": "自然语言处理与视觉结合",
        "问题": "在词和短语级别上对生成文本内容进行精确控制",
        "动机": "解决现有方法在控制生成文本内容时缺乏细粒度控制的问题",
        "方法": "提出内容调节器（CoCon），采用自监督学习方法，通过内容输入细粒度控制LM的输出文本",
        "关键词": [
            "受控文本生成",
            "自监督学习",
            "Transformer语言模型",
            "内容调节",
            "零样本控制"
        ],
        "涉及的技术概念": {
            "内容调节器（CoCon）": "用于在细粒度级别通过内容输入控制LM输出文本的自监督学习模块",
            "自监督学习": "CoCon模块通过学习帮助LM完成部分观察到的文本序列，无需外部标注数据",
            "零样本控制": "CoCon能够以零样本方式控制高级文本属性，无需特定任务的训练数据"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 114,
        "title": "CoDA: Contrast-enhanced and Diversity-promoting Data Augmentation for Natural Language Understanding",
        "html": "https://iclr.cc//virtual/2021/poster/2549",
        "abstract": "Data augmentation has been demonstrated as an effective strategy for improving model generalization and data efficiency.  However, due to the discrete nature of natural language, designing label-preserving transformations for text data tends to be more challenging. In this paper, we propose a novel data augmentation frame-work dubbed CoDA, which synthesizes diverse and informative augmented examples by integrating multiple transformations organically.  Moreover, a contrastive regularization is introduced to capture the global relationship among all the data samples.  A momentum encoder along with a memory bank is further leveraged to better estimate the contrastive loss. To verify the effectiveness of the proposed framework, we apply CoDA to Transformer-based models on a wide range of natural language understanding tasks. On the GLUE benchmark, CoDA gives rise to an average improvement of 2.2%while applied to the Roberta-large model. More importantly, it consistently exhibits stronger results relative to several competitive data augmentation and adversarial training baselines (including the low-resource settings). Extensive experiments show that the proposed contrastive objective can be flexibly combined with various data augmentation approaches to further boost their performance, highlighting the wide applicability of the CoDA framework.",
        "conference": "ICLR",
        "中文标题": "CoDA：增强对比与促进多样性的自然语言理解数据增强方法",
        "摘要翻译": "数据增强已被证明是提高模型泛化能力和数据效率的有效策略。然而，由于自然语言的离散特性，为文本数据设计保留标签的转换往往更具挑战性。本文提出了一种新颖的数据增强框架CoDA，该框架通过有机整合多种转换，合成了多样且信息丰富的增强示例。此外，引入了对比正则化以捕捉所有数据样本之间的全局关系。进一步利用动量编码器和记忆库来更好地估计对比损失。为了验证所提出框架的有效性，我们将CoDA应用于基于Transformer的模型，覆盖了广泛的自然语言理解任务。在GLUE基准测试中，当应用于Roberta-large模型时，CoDA带来了平均2.2%的提升。更重要的是，相对于几种竞争性的数据增强和对抗训练基线（包括低资源设置），它始终展现出更强的结果。大量实验表明，所提出的对比目标可以灵活地与各种数据增强方法结合，进一步提升它们的性能，突出了CoDA框架的广泛适用性。",
        "领域": "自然语言处理与视觉结合、文本数据增强、Transformer模型优化",
        "问题": "如何在自然语言处理中设计有效的标签保留数据增强方法以提高模型性能",
        "动机": "解决由于自然语言的离散特性导致的数据增强设计挑战，提升模型在自然语言理解任务中的表现",
        "方法": "提出CoDA框架，通过整合多种转换合成多样化的增强示例，并引入对比正则化和动量编码器优化对比损失",
        "关键词": [
            "数据增强",
            "对比学习",
            "自然语言理解",
            "Transformer模型",
            "模型泛化"
        ],
        "涉及的技术概念": {
            "对比正则化": "用于捕捉数据样本间的全局关系，增强模型对数据多样性的理解",
            "动量编码器": "与记忆库结合使用，优化对比损失的估计过程，提高模型训练效率",
            "记忆库": "存储历史数据样本的特征表示，辅助动量编码器更准确地估计对比损失"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 115,
        "title": "Collective Robustness Certificates: Exploiting Interdependence in Graph Neural Networks",
        "html": "https://iclr.cc//virtual/2021/poster/2727",
        "abstract": "In tasks like node classification, image segmentation, and named-entity recognition we have a classifier that simultaneously outputs multiple predictions (a vector of labels) based on a single input, i.e. a single graph, image, or document respectively. Existing adversarial robustness certificates consider each prediction independently and are thus overly pessimistic for such tasks. They implicitly assume that an adversary can use different perturbed inputs to attack different predictions, ignoring the fact that we have a single shared input. We propose the first collective robustness certificate which computes the number of predictions that are simultaneously guaranteed to remain stable under perturbation, i.e. cannot be attacked. We focus on Graph Neural Networks and leverage their locality property - perturbations only affect the predictions in a close neighborhood - to fuse multiple single-node certificates into a drastically stronger collective certificate. For example, on the Citeseer dataset our collective certificate for node classification increases the average number of certifiable feature perturbations from $7$ to $351$.\n",
        "conference": "ICLR",
        "中文标题": "集体鲁棒性证书：利用图神经网络中的相互依赖性",
        "摘要翻译": "在节点分类、图像分割和命名实体识别等任务中，我们有一个分类器，它基于单个输入（即单个图、图像或文档）同时输出多个预测（一个标签向量）。现有的对抗性鲁棒性证书独立考虑每个预测，因此对于此类任务过于悲观。它们隐含地假设攻击者可以使用不同的扰动输入来攻击不同的预测，忽略了我们有单一共享输入的事实。我们提出了第一个集体鲁棒性证书，它计算在扰动下同时保证保持稳定的预测数量，即不能被攻击的预测数量。我们专注于图神经网络，并利用它们的局部性属性——扰动只影响邻近区域的预测——将多个单节点证书融合成一个显著更强的集体证书。例如，在Citeseer数据集上，我们的节点分类集体证书将可认证的特征扰动平均数量从7增加到351。",
        "领域": "图神经网络、对抗性鲁棒性、节点分类",
        "问题": "现有对抗性鲁棒性证书独立考虑每个预测，忽略了多个预测基于同一输入的事实，导致证书过于悲观。",
        "动机": "提出一种能够考虑多个预测之间相互依赖性的集体鲁棒性证书，以提高证书的实用性和准确性。",
        "方法": "利用图神经网络的局部性属性，将多个单节点证书融合成一个集体证书，显著提高可认证的扰动数量。",
        "关键词": [
            "集体鲁棒性证书",
            "图神经网络",
            "对抗性鲁棒性",
            "节点分类",
            "局部性属性"
        ],
        "涉及的技术概念": {
            "集体鲁棒性证书": "一种新的证书类型，计算在扰动下同时保持稳定的预测数量，考虑了预测之间的相互依赖性。",
            "图神经网络": "用于处理图结构数据的深度学习模型，本文中利用其局部性属性来增强集体证书。",
            "局部性属性": "图神经网络的一个特性，指扰动只影响输入图中邻近区域的预测，这一特性被用来融合单节点证书。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 116,
        "title": "Colorization Transformer",
        "html": "https://iclr.cc//virtual/2021/poster/2844",
        "abstract": "We present the Colorization Transformer, a novel approach for diverse high fidelity image colorization based on self-attention. Given a grayscale image, the colorization proceeds in three steps. We first use a conditional autoregressive transformer to produce a low resolution coarse coloring of the grayscale image. Our architecture adopts conditional transformer layers to effectively condition grayscale input. Two subsequent fully parallel networks upsample the coarse colored low resolution image into a finely colored high resolution image. Sampling from the Colorization Transformer produces diverse colorings whose fidelity outperforms the previous state-of-the-art on colorising ImageNet based on FID results and based on a human evaluation in a Mechanical Turk test. Remarkably, in  more than 60\\% of cases human evaluators prefer the highest rated among three generated colorings over the ground truth. The code and pre-trained checkpoints for Colorization Transformer are publicly available  at https://github.com/google-research/google-research/tree/master/coltran",
        "conference": "ICLR",
        "中文标题": "色彩化变换器",
        "摘要翻译": "我们提出了色彩化变换器，这是一种基于自注意力的新颖方法，用于实现多样化的高保真图像色彩化。给定一张灰度图像，色彩化过程分为三个步骤。首先，我们使用条件自回归变换器生成灰度图像的低分辨率粗略着色。我们的架构采用条件变换器层来有效地对灰度输入进行条件处理。随后，两个完全并行的网络将粗略着色的低分辨率图像上采样为精细着色的高分辨率图像。从色彩化变换器中采样产生的多样化着色，在基于FID结果和基于Mechanical Turk测试的人类评估中，其保真度超过了之前最先进的ImageNet色彩化方法。值得注意的是，在超过60%的情况下，人类评估者更喜欢三个生成着色中评分最高的那个，而不是真实情况。色彩化变换器的代码和预训练检查点可在https://github.com/google-research/google-research/tree/master/coltran公开获取。",
        "领域": "图像色彩化、自注意力机制、高保真图像生成",
        "问题": "如何实现多样化且高保真的灰度图像色彩化",
        "动机": "开发一种能够生成多样化且高保真色彩化图像的方法，以超越现有的色彩化技术",
        "方法": "采用条件自回归变换器和两个完全并行的上采样网络，通过三个步骤实现灰度图像的高质量色彩化",
        "关键词": [
            "色彩化变换器",
            "自注意力",
            "高保真图像",
            "条件自回归",
            "图像上采样"
        ],
        "涉及的技术概念": {
            "自注意力机制": "用于在色彩化过程中捕捉图像不同区域之间的关系，提高色彩化的质量和多样性",
            "条件自回归变换器": "用于生成灰度图像的初步低分辨率色彩化结果，为后续上采样提供基础",
            "图像上采样": "通过两个完全并行的网络将低分辨率色彩化图像转换为高分辨率图像，保留并增强色彩细节"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 117,
        "title": "Combining Ensembles and Data Augmentation Can Harm Your Calibration",
        "html": "https://iclr.cc//virtual/2021/poster/3282",
        "abstract": "Ensemble methods which average over multiple neural network predictions are a simple approach to improve a model’s calibration and robustness. Similarly, data augmentation techniques, which encode prior information in the form of invariant feature transformations, are effective for improving calibration and robustness. In this paper, we show a surprising pathology: combining ensembles and data augmentation can harm model calibration. This leads to a trade-off in practice, whereby improved accuracy by combining the two techniques comes at the expense of calibration. On the other hand, selecting only one of the techniques ensures good uncertainty estimates at the expense of accuracy. We investigate this pathology and identify a compounding under-confidence among methods which marginalize over sets of weights and data augmentation techniques which soften labels. Finally, we propose a simple correction, achieving the best of both worlds with significant accuracy and calibration gains over using only ensembles or data augmentation individually. Applying the correction produces new state-of-the art in uncertainty calibration and robustness across CIFAR-10, CIFAR-100, and ImageNet.",
        "conference": "ICLR",
        "中文标题": "结合集成方法和数据增强可能损害您的校准",
        "摘要翻译": "集成方法通过对多个神经网络预测进行平均，是一种简单的方法来改善模型的校准和鲁棒性。类似地，数据增强技术以不变特征变换的形式编码先验信息，对于改善校准和鲁棒性也非常有效。在本文中，我们展示了一个令人惊讶的病理现象：结合集成方法和数据增强可能会损害模型的校准。这导致在实践中存在一种权衡，即通过结合这两种技术提高准确性是以牺牲校准为代价的。另一方面，仅选择其中一种技术可以确保良好的不确定性估计，但会牺牲准确性。我们研究了这一病理现象，并确定了在权重集合和数据增强技术之间边际化的方法中，以及软化标签的数据增强技术中，存在一种复合的不自信现象。最后，我们提出了一个简单的修正方法，实现了两全其美，与单独使用集成方法或数据增强相比，在准确性和校准方面都取得了显著的提升。应用这一修正方法在CIFAR-10、CIFAR-100和ImageNet上实现了不确定性校准和鲁棒性的新最先进水平。",
        "领域": "模型校准、深度学习鲁棒性、图像分类",
        "问题": "结合集成方法和数据增强技术时，模型校准性能下降的问题",
        "动机": "探索集成方法和数据增强技术结合使用时对模型校准性能的影响，并提出解决方案",
        "方法": "通过实验分析结合集成方法和数据增强技术对模型校准的影响，并提出一种简单的修正方法以同时提高准确性和校准性能",
        "关键词": [
            "模型校准",
            "集成方法",
            "数据增强",
            "深度学习鲁棒性",
            "不确定性估计"
        ],
        "涉及的技术概念": {
            "集成方法": "通过平均多个神经网络预测来提高模型的校准和鲁棒性",
            "数据增强": "通过不变特征变换编码先验信息，有效提高模型的校准和鲁棒性",
            "模型校准": "模型预测的不确定性估计与实际误差率之间的一致性，本文中通过提出的修正方法显著提高了这一性能"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 118,
        "title": "Combining Label Propagation and Simple Models out-performs Graph Neural Networks",
        "html": "https://iclr.cc//virtual/2021/poster/3274",
        "abstract": "Graph Neural Networks (GNNs) are a predominant technique for learning over graphs. However, there is relatively little understanding of why GNNs are successful in practice and whether they are necessary for good performance. Here, we show that for many standard transductive node classification benchmarks, we can exceed or match the performance of state-of-the-art GNNs by combining shallow models that ignore the graph structure with two simple post-processing steps that exploit correlation in the label structure: (i) an “error correlation” that spreads residual errors in training data to correct errors in test data and (ii) a “prediction correlation” that smooths the predictions on the test data. We call this overall procedure Correct and Smooth (C&S), and the post-processing steps are implemented via simple modifications to standard label propagation techniques that have long been used in graph-based semi-supervised learning. Our approach exceeds or nearly matches the performance of state-of-the-art GNNs on a wide variety of benchmarks, with just a small fraction of the parameters and orders of magnitude faster runtime. For instance, we exceed the best-known GNN performance on the OGB-Products dataset with 137 times fewer parameters and greater than 100 times less training time. The performance of our methods highlights how directly incorporating label information into the learning algorithm (as is common in traditional methods) yields easy and substantial performance gains. We can also incorporate our techniques into big GNN models, providing modest gains in some cases.",
        "conference": "ICLR",
        "中文标题": "结合标签传播与简单模型超越图神经网络",
        "摘要翻译": "图神经网络（GNNs）是学习图数据的主要技术。然而，对于GNNs在实践中成功的原因以及它们是否是实现良好性能的必要条件，人们的理解相对较少。在这里，我们展示，对于许多标准的转导式节点分类基准，通过结合忽略图结构的浅层模型和两个利用标签结构中相关性的简单后处理步骤，我们可以超越或匹配最先进的GNNs的性能：（i）一种“误差相关性”，将训练数据中的残差误差传播以纠正测试数据中的误差；（ii）一种“预测相关性”，平滑测试数据上的预测。我们将这一整体过程称为“纠正与平滑”（C&S），而后处理步骤是通过对长期用于基于图的半监督学习中的标准标签传播技术进行简单修改来实现的。我们的方法在多种基准测试中超越或几乎匹配最先进GNNs的性能，仅使用一小部分参数和数量级更快的运行时间。例如，在OGB-Products数据集上，我们以137倍更少的参数和超过100倍的训练时间超越了已知的最佳GNN性能。我们方法的性能突出了如何将标签信息直接纳入学习算法（这在传统方法中很常见）可以轻松实现显著的性能提升。我们还可以将我们的技术整合到大型GNN模型中，在某些情况下提供适度的增益。",
        "领域": "图学习、半监督学习、节点分类",
        "问题": "探索图神经网络（GNNs）是否是实现良好性能的必要条件，以及是否存在更简单、更高效的方法可以达到或超越GNNs的性能。",
        "动机": "理解GNNs成功的原因，并探索更简单、更高效的方法来达到或超越GNNs在节点分类任务上的性能。",
        "方法": "结合忽略图结构的浅层模型和两个简单的后处理步骤（误差相关性和预测相关性），通过修改标准标签传播技术来实现。",
        "关键词": [
            "标签传播",
            "图神经网络",
            "节点分类",
            "半监督学习",
            "性能优化"
        ],
        "涉及的技术概念": {
            "标签传播": "一种长期用于基于图的半监督学习的技术，用于在图中传播标签信息。",
            "误差相关性": "一种后处理步骤，通过传播训练数据中的残差误差来纠正测试数据中的误差。",
            "预测相关性": "一种后处理步骤，用于平滑测试数据上的预测，以提高模型的性能。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 119,
        "title": "Combining Physics and Machine Learning for Network Flow Estimation",
        "html": "https://iclr.cc//virtual/2021/poster/3316",
        "abstract": "The flow estimation problem consists of predicting missing edge flows in a network (e.g., traffic, power, and water) based on partial observations. These missing flows depend both on the underlying \\textit{physics} (edge features and a flow conservation law) as well as the observed edge flows. This paper introduces an optimization framework for computing missing edge flows and solves the problem using bilevel optimization and deep learning. More specifically, we learn regularizers that depend on edge features (e.g., number of lanes in a road, the resistance of a power line) using neural networks. Empirical results show that our method accurately predicts missing flows, outperforming the best baseline, and is able to capture relevant physical properties in traffic and power networks.",
        "conference": "ICLR",
        "中文标题": "结合物理学与机器学习进行网络流量估计",
        "摘要翻译": "流量估计问题包括基于部分观测预测网络中缺失的边缘流量（如交通、电力和水）。这些缺失的流量既依赖于基础的物理学（边缘特征和流量守恒定律），也依赖于观测到的边缘流量。本文介绍了一个用于计算缺失边缘流量的优化框架，并通过双层优化和深度学习解决了该问题。具体来说，我们使用神经网络学习依赖于边缘特征（如道路的车道数、电力线的电阻）的正则化器。实证结果表明，我们的方法准确预测了缺失的流量，优于最佳基线，并且能够捕捉交通和电力网络中的相关物理特性。",
        "领域": "网络流量预测、深度学习应用、物理信息机器学习",
        "问题": "预测网络中缺失的边缘流量",
        "动机": "结合物理学原理和机器学习方法，提高网络流量预测的准确性",
        "方法": "采用双层优化和深度学习技术，学习依赖于边缘特征的正则化器",
        "关键词": [
            "网络流量估计",
            "双层优化",
            "深度学习",
            "物理信息",
            "正则化器"
        ],
        "涉及的技术概念": {
            "双层优化": "用于同时优化模型参数和正则化器，以提高流量预测的准确性",
            "深度学习": "通过神经网络学习复杂的模式和关系，用于预测缺失的流量",
            "正则化器": "依赖于边缘特征的函数，用于在优化过程中引入额外的约束，以捕捉物理特性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 120,
        "title": "Co-Mixup: Saliency Guided Joint Mixup with Supermodular Diversity",
        "html": "https://iclr.cc//virtual/2021/poster/2766",
        "abstract": "While deep neural networks show great performance on fitting to the training distribution, improving the networks' generalization performance to the test distribution and robustness to the sensitivity to input perturbations still remain as a challenge. Although a number of mixup based augmentation strategies have been proposed to partially address them, it remains unclear as to how to best utilize the supervisory signal within each input data for mixup from the optimization perspective. We propose a new perspective on batch mixup and formulate the optimal construction of a batch of mixup data maximizing the data saliency measure of each individual mixup data and encouraging the supermodular diversity among the constructed mixup data. This leads to a novel discrete optimization problem minimizing the difference between submodular functions. We also propose an efficient modular approximation based iterative submodular minimization algorithm for efficient mixup computation per each minibatch suitable for minibatch based neural network training. Our experiments show the proposed method achieves the state of the art generalization, calibration, and weakly supervised localization results compared to other mixup methods. The source code is available at https://github.com/snu-mllab/Co-Mixup.",
        "conference": "ICLR",
        "中文标题": "Co-Mixup: 基于显著性的联合Mixup与超模多样性",
        "摘要翻译": "尽管深度神经网络在拟合训练分布方面表现出色，但提高网络对测试分布的泛化性能及对输入扰动敏感性的鲁棒性仍是一个挑战。虽然已经提出了许多基于mixup的数据增强策略来部分解决这些问题，但从优化的角度来看，如何最好地利用每个输入数据中的监督信号进行mixup仍不明确。我们提出了一个关于批量mixup的新视角，并构建了一个优化问题，旨在最大化每个mixup数据的显著性度量并鼓励构建的mixup数据之间的超模多样性。这导致了一个新颖的离散优化问题，即最小化子模函数之间的差异。我们还提出了一种高效的基于模逼近的迭代子模最小化算法，用于每个小批量中高效的mixup计算，适用于基于小批量的神经网络训练。我们的实验表明，与其他mixup方法相比，所提出的方法在泛化性、校准性和弱监督定位结果方面达到了最先进的水平。源代码可在https://github.com/snu-mllab/Co-Mixup获取。",
        "领域": "数据增强、深度学习优化、弱监督学习",
        "问题": "如何优化mixup数据增强策略以提高深度神经网络的泛化性能和鲁棒性",
        "动机": "解决现有mixup方法在利用输入数据中的监督信号和优化数据多样性方面的不足",
        "方法": "提出了一种新的批量mixup优化视角，通过最大化数据显著性度量和鼓励超模多样性来构建mixup数据，并开发了一种高效的迭代子模最小化算法",
        "关键词": [
            "mixup数据增强",
            "子模优化",
            "显著性度量",
            "超模多样性",
            "弱监督定位"
        ],
        "涉及的技术概念": {
            "mixup数据增强": "一种通过线性插值输入数据和标签来增强训练数据的技术，旨在提高模型的泛化能力",
            "子模优化": "用于解决特定类型的离散优化问题，本研究中用于最小化子模函数之间的差异以优化mixup数据构建",
            "显著性度量": "衡量数据中重要性的指标，本研究中使用该指标来指导mixup数据的构建，以提高模型的性能"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 121,
        "title": "Communication in Multi-Agent Reinforcement Learning: Intention Sharing",
        "html": "https://iclr.cc//virtual/2021/poster/3363",
        "abstract": "Communication is one of the core components for learning coordinated behavior in multi-agent systems.\nIn this paper, we propose a new communication scheme named  Intention Sharing (IS) for multi-agent reinforcement learning in order to enhance the coordination among agents. In the proposed IS scheme, each agent generates an imagined trajectory by modeling the environment dynamics and other agents' actions. The imagined trajectory is the simulated future trajectory of each agent based on the learned model of the environment dynamics and other agents and represents each agent's future action plan. Each agent compresses this imagined trajectory capturing its future action plan to generate its intention message for communication by applying an attention mechanism to learn the relative importance of the components in the imagined trajectory based on the received message from other agents. Numeral results show that the proposed IS scheme outperforms other communication schemes in multi-agent reinforcement learning.",
        "conference": "ICLR",
        "中文标题": "多智能体强化学习中的通信：意图共享",
        "摘要翻译": "通信是多智能体系统中学习协调行为的核心组成部分之一。在本文中，我们提出了一种名为意图共享（IS）的新通信方案，用于多智能体强化学习，以增强智能体之间的协调。在提出的IS方案中，每个智能体通过建模环境动态和其他智能体的动作生成一个想象的轨迹。这个想象的轨迹是基于学习到的环境动态和其他智能体模型的每个智能体的模拟未来轨迹，代表了每个智能体的未来行动计划。每个智能体通过应用注意力机制来压缩这个捕获其未来行动计划的想象轨迹，以生成其用于通信的意图消息，该注意力机制基于从其他智能体接收到的消息学习想象轨迹中组件的相对重要性。数值结果表明，提出的IS方案在多智能体强化学习中优于其他通信方案。",
        "领域": "多智能体系统、强化学习、协调学习",
        "问题": "如何通过改进通信方案增强多智能体强化学习中的协调行为",
        "动机": "提高多智能体系统中智能体之间的协调效率，通过共享未来行动计划来优化集体行为",
        "方法": "提出了一种名为意图共享（IS）的通信方案，通过生成和压缩想象的未来轨迹来共享智能体的意图，使用注意力机制优化通信内容",
        "关键词": [
            "多智能体强化学习",
            "意图共享",
            "注意力机制",
            "协调学习",
            "环境动态建模"
        ],
        "涉及的技术概念": {
            "意图共享（IS）": "一种新的通信方案，通过共享智能体的未来行动计划来增强协调",
            "注意力机制": "用于学习想象轨迹中组件的相对重要性，优化通信内容",
            "环境动态建模": "智能体通过学习环境动态和其他智能体的动作来生成想象的未来轨迹"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 122,
        "title": "Complex Query Answering with Neural Link Predictors",
        "html": "https://iclr.cc//virtual/2021/poster/3140",
        "abstract": "Neural link predictors are immensely useful for identifying missing edges in large scale Knowledge Graphs. However, it is still not clear how to use these models for answering more complex queries that arise in a number of domains, such as queries using logical conjunctions ($\\land$), disjunctions ($\\lor$) and existential quantifiers ($\\exists$), while accounting for missing edges. In this work, we propose a framework for efficiently answering complex queries on incomplete Knowledge Graphs. We translate each query into an end-to-end differentiable objective, where the truth value of each atom is computed by a pre-trained neural link predictor. We then analyse two solutions to the optimisation problem, including gradient-based and combinatorial search. In our experiments, the proposed approach produces more accurate results than state-of-the-art methods --- black-box neural models trained on millions of generated queries --- without the need of training on a large and diverse set of complex queries. Using orders of magnitude less training data, we obtain relative improvements ranging from 8% up to 40% in Hits@3 across different knowledge graphs containing factual information. Finally, we demonstrate that it is possible to explain the outcome of our model in terms of the intermediate solutions identified for each of the complex query atoms. All our source code and datasets are available online, at https://github.com/uclnlp/cqd.",
        "conference": "ICLR",
        "中文标题": "使用神经链接预测器回答复杂查询",
        "摘要翻译": "神经链接预测器在识别大规模知识图谱中缺失的边缘方面非常有用。然而，目前尚不清楚如何利用这些模型来回答在多个领域中出现的更复杂查询，例如使用逻辑与（∧）、逻辑或（∨）和存在量词（∃）的查询，同时考虑到缺失的边缘。在这项工作中，我们提出了一个框架，用于在不完整的知识图谱上高效回答复杂查询。我们将每个查询转换为一个端到端可微分的目标，其中每个原子的真值由预训练的神经链接预测器计算。然后，我们分析了优化问题的两种解决方案，包括基于梯度的和组合搜索。在我们的实验中，所提出的方法比最先进的方法——在数百万生成的查询上训练的黑盒神经模型——产生更准确的结果，而无需在大量多样的复杂查询集上进行训练。使用数量级更少的训练数据，我们在包含事实信息的不同知识图谱中，Hits@3的相对改进范围从8%到40%。最后，我们证明了可以根据为每个复杂查询原子识别的中间解决方案来解释我们模型的结果。我们所有的源代码和数据集都可以在线获取，网址是https://github.com/uclnlp/cqd。",
        "领域": "知识图谱推理、神经符号集成、复杂查询处理",
        "问题": "如何在不完整的知识图谱上高效回答包含逻辑操作和存在量词的复杂查询",
        "动机": "解决现有神经链接预测器在处理复杂逻辑查询时的局限性，特别是在面对知识图谱中缺失边缘的情况下",
        "方法": "将复杂查询转换为端到端可微分目标，利用预训练的神经链接预测器计算原子真值，并采用基于梯度和组合搜索的优化方法",
        "关键词": [
            "神经链接预测",
            "复杂查询回答",
            "知识图谱推理",
            "可微分目标",
            "优化方法"
        ],
        "涉及的技术概念": {
            "神经链接预测器": "用于预测知识图谱中缺失边缘的神经网络模型，作为基础组件支持复杂查询的回答",
            "端到端可微分目标": "将复杂查询转换为可被神经网络直接优化的形式，使得查询回答过程能够利用梯度下降等方法",
            "组合搜索": "一种优化技术，用于在可能的解空间中高效寻找满足复杂查询条件的解，特别是在处理逻辑操作时"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 123,
        "title": "CompOFA – Compound Once-For-All Networks for Faster Multi-Platform Deployment",
        "html": "https://iclr.cc//virtual/2021/poster/3296",
        "abstract": "The emergence of CNNs in mainstream deployment has necessitated methods to design and train efficient architectures tailored to maximize the accuracy under diverse hardware and latency constraints. To scale these resource-intensive tasks with an increasing number of deployment targets, Once-For-All (OFA) proposed an approach to jointly train several models at once with a constant training cost. However, this cost remains as high as 40-50 GPU days and also suffers from a combinatorial explosion of sub-optimal model configurations. We seek to reduce this search space -- and hence the training budget -- by constraining search to models close to the accuracy-latency Pareto frontier. We incorporate insights of compound relationships between model dimensions to build CompOFA, a design space smaller by several orders of magnitude.  Through experiments on ImageNet, we demonstrate that even with simple heuristics we can achieve a 2x reduction in training time and 216x speedup in model search/extraction time compared to the state of the art, without loss of Pareto optimality! We also show that this smaller design space is dense enough to support equally accurate models for a similar diversity of hardware and latency targets, while also reducing the complexity of the training and subsequent extraction algorithms. Our source code is available at https://github.com/gatech-sysml/CompOFA",
        "conference": "ICLR",
        "中文标题": "CompOFA – 复合一次性全网络以实现更快的多平台部署",
        "摘要翻译": "CNN在主流部署中的出现，需要设计并训练高效架构的方法，以在多样化的硬件和延迟约束下最大化准确率。为了随着部署目标的增加而扩展这些资源密集型任务，一次性全网络（OFA）提出了一种方法，以恒定的训练成本同时训练多个模型。然而，这一成本仍然高达40-50 GPU天，并且还遭受子最优模型配置的组合爆炸的影响。我们试图通过将搜索限制在接近准确率-延迟帕累托前沿的模型来减少这一搜索空间——从而减少训练预算。我们结合了模型维度间复合关系的见解，构建了CompOFA，一个比原来小几个数量级的设计空间。通过在ImageNet上的实验，我们证明，即使使用简单的启发式方法，我们也能实现训练时间减少2倍，模型搜索/提取时间比现有技术快216倍，而不损失帕累托最优性！我们还表明，这个较小的设计空间足够密集，可以支持针对类似多样性的硬件和延迟目标同样准确的模型，同时减少训练和后续提取算法的复杂性。我们的源代码可在https://github.com/gatech-sysml/CompOFA获取。",
        "领域": "神经网络架构搜索, 高效深度学习, 多平台部署",
        "问题": "减少神经网络架构搜索的训练成本和搜索空间，同时保持模型的准确率和延迟性能。",
        "动机": "解决OFA方法中高训练成本和子最优模型配置组合爆炸的问题，以实现更高效的神经网络架构搜索和多平台部署。",
        "方法": "通过限制搜索空间到接近准确率-延迟帕累托前沿的模型，并结合模型维度间的复合关系，构建一个更小的设计空间CompOFA。",
        "关键词": [
            "神经网络架构搜索",
            "高效训练",
            "多平台部署",
            "帕累托最优",
            "复合关系"
        ],
        "涉及的技术概念": {
            "一次性全网络（OFA）": "一种同时训练多个模型以恒定的训练成本的方法，旨在支持多样化的硬件和延迟约束。",
            "帕累托前沿": "在多个目标优化问题中，表示在某一目标上无法进一步改进而不损害其他目标的解集。",
            "复合关系": "模型不同维度间的关系，用于构建更高效的设计空间，减少搜索和训练成本。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 124,
        "title": "Computational Separation Between Convolutional and Fully-Connected Networks",
        "html": "https://iclr.cc//virtual/2021/poster/2557",
        "abstract": "Convolutional neural networks (CNN) exhibit unmatched performance in a multitude of computer vision tasks. However, the advantage of using convolutional networks over fully-connected networks is not understood from a theoretical perspective. In this work, we show how convolutional networks can leverage locality in the data, and thus achieve a computational advantage over fully-connected networks. Specifically, we show a class of problems that can be efficiently solved using convolutional networks trained with gradient-descent, but at the same time is hard to learn using a polynomial-size fully-connected network.",
        "conference": "ICLR",
        "中文标题": "卷积网络与全连接网络之间的计算分离",
        "摘要翻译": "卷积神经网络（CNN）在众多计算机视觉任务中展现出无与伦比的性能。然而，从理论角度来看，使用卷积网络相对于全连接网络的优势尚未被理解。在这项工作中，我们展示了卷积网络如何利用数据中的局部性，从而获得相对于全连接网络的计算优势。具体来说，我们展示了一类问题，这类问题可以通过使用梯度下降训练的卷积网络有效解决，但同时对于多项式大小的全连接网络来说难以学习。",
        "领域": "深度学习理论、计算机视觉、神经网络架构",
        "问题": "理解卷积网络相对于全连接网络在计算上的优势",
        "动机": "探索卷积网络在利用数据局部性方面的理论优势，以及这种优势如何转化为计算上的优势",
        "方法": "通过理论分析，展示一类特定问题，卷积网络能够有效解决而全连接网络难以学习",
        "关键词": [
            "卷积神经网络",
            "全连接网络",
            "计算优势",
            "梯度下降",
            "局部性"
        ],
        "涉及的技术概念": {
            "卷积神经网络": "一种专门用于处理具有类似网格结构数据的神经网络，通过卷积操作利用数据的局部性特征",
            "全连接网络": "每个神经元都与前一层的所有神经元相连的网络结构，缺乏对数据局部性的利用",
            "梯度下降": "一种优化算法，用于通过计算损失函数的梯度来更新网络参数，以最小化损失"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 125,
        "title": "Concept Learners for Few-Shot Learning",
        "html": "https://iclr.cc//virtual/2021/poster/2737",
        "abstract": "Developing algorithms that are able to generalize to a novel task given only a few labeled examples represents a fundamental challenge in closing the gap between machine- and human-level performance. The core of human cognition lies in the structured, reusable concepts that help us to rapidly adapt to new tasks and provide reasoning behind our decisions. However, existing meta-learning methods learn complex representations across prior labeled tasks without imposing any structure on the learned representations. Here we propose COMET, a meta-learning method that improves generalization ability by learning to learn along human-interpretable concept dimensions. Instead of learning a joint unstructured metric space, COMET learns mappings of high-level concepts into semi-structured metric spaces, and effectively combines the outputs of independent concept learners. We evaluate our model on few-shot tasks from diverse domains, including fine-grained image classification, document categorization  and cell type annotation on a novel dataset from a biological domain developed in our work. COMET significantly outperforms strong meta-learning baselines, achieving 6-15% relative improvement on the most challenging 1-shot learning tasks, while unlike existing methods providing interpretations behind the model's predictions.",
        "conference": "ICLR",
        "中文标题": "概念学习器用于少样本学习",
        "摘要翻译": "开发能够仅凭少量标记示例就能泛化到新任务的算法，代表了缩小机器与人类性能差距的基本挑战。人类认知的核心在于结构化、可重用的概念，这些概念帮助我们快速适应新任务，并为我们的决策提供推理依据。然而，现有的元学习方法在先前标记的任务上学习复杂的表示，而没有对学习到的表示施加任何结构。在这里，我们提出了COMET，一种通过沿着人类可解释的概念维度学习来提高泛化能力的元学习方法。COMET不是学习一个非结构化的联合度量空间，而是将高级概念映射到半结构化的度量空间中，并有效地结合独立概念学习器的输出。我们在来自不同领域的少样本任务上评估了我们的模型，包括细粒度图像分类、文档分类以及在我们工作中开发的生物领域新数据集上的细胞类型注释。COMET显著优于强大的元学习基线，在最具挑战性的1样本学习任务上实现了6-15%的相对改进，同时与现有方法不同，提供了模型预测背后的解释。",
        "领域": "元学习",
        "问题": "如何在少量标记示例的情况下，提高模型对新任务的泛化能力",
        "动机": "缩小机器与人类在少样本学习上的性能差距，通过引入人类可解释的概念结构来提高模型的泛化能力和解释性",
        "方法": "提出COMET方法，通过学习将高级概念映射到半结构化的度量空间，并有效结合独立概念学习器的输出，来提高模型的泛化能力",
        "关键词": [
            "少样本学习",
            "元学习",
            "概念学习",
            "泛化能力",
            "解释性"
        ],
        "涉及的技术概念": {
            "元学习": "通过学习如何学习来提高模型在新任务上的表现",
            "概念学习": "通过识别和利用高级概念来增强模型的理解和泛化能力",
            "半结构化度量空间": "一种介于完全结构化和非结构化之间的度量空间，用于更好地组织和表示学习到的概念"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 126,
        "title": "Conditional Generative Modeling via Learning the Latent Space",
        "html": "https://iclr.cc//virtual/2021/poster/2764",
        "abstract": "Although deep learning has achieved appealing results on several machine learning tasks, most of the models are deterministic at inference, limiting their application to single-modal settings. We propose a novel general-purpose framework for conditional generation in multimodal spaces, that uses latent variables to model generalizable learning patterns while minimizing a family of regression cost functions. At inference, the latent variables are optimized to find solutions corresponding to multiple output modes.  Compared to existing generative solutions, our approach demonstrates faster and more stable convergence, and can learn better representations for downstream tasks. Importantly, it provides a simple generic model that can perform better than highly engineered pipelines tailored using domain expertise on a variety of tasks, while generating diverse outputs. Code available at https://github.com/samgregoost/cGML.",
        "conference": "ICLR",
        "中文标题": "通过潜在空间学习实现条件生成建模",
        "摘要翻译": "尽管深度学习在多项机器学习任务上取得了吸引人的成果，但大多数模型在推理时是确定性的，这限制了它们在单模态设置中的应用。我们提出了一种新颖的通用框架，用于在多模态空间中进行条件生成，该框架使用潜在变量来建模可泛化的学习模式，同时最小化一系列回归成本函数。在推理时，优化潜在变量以找到对应于多种输出模式的解决方案。与现有的生成解决方案相比，我们的方法展示了更快且更稳定的收敛性，并且能够为下游任务学习更好的表示。重要的是，它提供了一个简单通用的模型，该模型在各种任务上能够比使用领域专业知识精心设计的管道表现得更好，同时生成多样化的输出。代码可在https://github.com/samgregoost/cGML获取。",
        "领域": "生成对抗网络、多模态学习、表示学习",
        "问题": "解决深度学习模型在推理时的确定性限制，使其能够应用于多模态设置",
        "动机": "开发一个能够生成多样化输出并在多模态空间中有效工作的通用条件生成框架",
        "方法": "提出了一种使用潜在变量建模可泛化学习模式并最小化回归成本函数的框架，优化潜在变量以找到多种输出模式的解决方案",
        "关键词": [
            "条件生成建模",
            "潜在空间学习",
            "多模态生成",
            "回归成本函数",
            "多样化输出"
        ],
        "涉及的技术概念": {
            "潜在变量": "用于建模可泛化的学习模式，使得模型能够在多模态空间中生成多样化的输出",
            "回归成本函数": "框架中最小化的一系列函数，用于优化模型的学习过程",
            "多模态空间": "模型工作的环境，能够处理和生成多种模式的数据"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 127,
        "title": "Conditionally Adaptive Multi-Task Learning: Improving Transfer Learning in NLP Using Fewer Parameters & Less Data",
        "html": "https://iclr.cc//virtual/2021/poster/2893",
        "abstract": "Multi-Task Learning (MTL) networks have emerged as a promising method for transferring learned knowledge across different tasks. However, MTL must deal with challenges such as: overfitting to low resource tasks, catastrophic forgetting, and negative task transfer, or learning interference. Often, in Natural Language Processing (NLP), a separate model per task is needed to obtain the best performance. However, many fine-tuning approaches are both parameter inefficient, i.e., potentially involving one new model per task, and highly susceptible to losing knowledge acquired during pretraining. We propose a novel Transformer based Adapter consisting of a new conditional attention mechanism as well as a set of task-conditioned modules that facilitate weight sharing. Through this construction, we achieve more efficient parameter sharing and mitigate forgetting by keeping half of the weights of a pretrained model fixed. We also use a new multi-task data sampling strategy to mitigate the negative effects of data imbalance across tasks. Using this approach, we are able to surpass single task fine-tuning methods while being parameter and data efficient (using around 66% of the data). Compared to other BERT Large methods on GLUE, our 8-task model surpasses other Adapter methods by 2.8% and our 24-task model outperforms by 0.7-1.0% models that use MTL and single task fine-tuning. We show that a larger variant of our single multi-task model approach performs competitively across 26 NLP tasks and yields state-of-the-art results on a number of test and development sets.",
        "conference": "ICLR",
        "中文标题": "条件自适应多任务学习：使用更少的参数和数据提升NLP中的迁移学习效果",
        "摘要翻译": "多任务学习（MTL）网络已成为跨任务迁移学习知识的一种有前景的方法。然而，MTL必须应对诸如过拟合低资源任务、灾难性遗忘、负任务迁移或学习干扰等挑战。在自然语言处理（NLP）中，通常需要为每个任务单独建立一个模型以获得最佳性能。然而，许多微调方法既参数效率低下，即可能每个任务都需要一个新模型，又极易丢失预训练中获得的知识。我们提出了一种基于Transformer的新型适配器，包括一个新的条件注意力机制和一组促进权重共享的任务条件模块。通过这种结构，我们实现了更高效的参数共享，并通过固定预训练模型的一半权重来减轻遗忘。我们还使用了一种新的多任务数据采样策略，以减轻任务间数据不平衡的负面影响。采用这种方法，我们能够在参数和数据效率上（使用约66%的数据）超越单任务微调方法。与GLUE上的其他BERT Large方法相比，我们的8任务模型超越了其他适配器方法2.8%，我们的24任务模型比使用MTL和单任务微调的模型表现更好，提高了0.7-1.0%。我们展示了我们单多任务模型方法的一个更大变体在26个NLP任务上具有竞争力，并在多个测试和开发集上取得了最先进的结果。",
        "领域": "自然语言处理与视觉结合, 迁移学习, 多任务学习",
        "问题": "解决多任务学习中的过拟合、灾难性遗忘和负任务迁移问题，同时提高参数和数据效率。",
        "动机": "为了在自然语言处理任务中更高效地迁移学习知识，减少对大量参数和数据的依赖，同时避免现有方法中的常见问题。",
        "方法": "提出了一种基于Transformer的新型适配器，包括条件注意力机制和任务条件模块，以及新的多任务数据采样策略。",
        "关键词": [
            "多任务学习",
            "迁移学习",
            "条件注意力机制",
            "参数效率",
            "数据效率"
        ],
        "涉及的技术概念": {
            "条件注意力机制": "用于根据任务条件动态调整注意力权重，促进有效的知识迁移和共享。",
            "任务条件模块": "一组模块，根据特定任务调整模型行为，以支持权重共享和减少遗忘。",
            "多任务数据采样策略": "一种策略，旨在平衡不同任务间的数据分布，减少数据不平衡对模型性能的负面影响。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 128,
        "title": "Conditional Negative Sampling for Contrastive Learning of Visual Representations",
        "html": "https://iclr.cc//virtual/2021/poster/3245",
        "abstract": "Recent methods for learning unsupervised visual representations, dubbed contrastive learning, optimize the noise-contrastive estimation (NCE) bound on mutual information between two transformations of an image. NCE typically uses randomly sampled negative examples to normalize the objective, but this may often include many uninformative examples either because they are too easy or too hard to discriminate. Taking inspiration from  metric learning, we show that choosing semi-hard negatives can yield stronger contrastive representations. To do this, we introduce a family of mutual information estimators that sample negatives conditionally -- in a 'ring' around each positive. We prove that these estimators remain lower-bounds of mutual information, with higher bias but lower variance than NCE. Experimentally, we find our approach, applied on top of existing models (IR, CMC, and MoCo) improves accuracy by 2-5% absolute points in each case, measured by linear evaluation on four standard image benchmarks. Moreover, we find continued benefits when transferring features to a variety of new image distributions from the Meta-Dataset collection and to a variety of downstream tasks such as object detection, instance segmentation, and key-point detection.",
        "conference": "ICLR",
        "中文标题": "对比学习视觉表征的条件负采样",
        "摘要翻译": "最近被称为对比学习的无监督视觉表征学习方法，优化了图像两种变换间互信息的噪声对比估计（NCE）边界。NCE通常使用随机采样的负例来规范化目标，但这可能经常包含许多无信息的例子，因为它们要么太容易区分，要么太难区分。受度量学习的启发，我们展示了选择半难负例可以产生更强的对比表征。为此，我们引入了一系列互信息估计器，这些估计器有条件地采样负例——在每个正例周围形成一个‘环’。我们证明这些估计器仍然是互信息的低界，与NCE相比具有更高的偏差但更低的方差。实验上，我们发现我们的方法应用于现有模型（IR、CMC和MoCo）之上，在每种情况下通过线性评估四个标准图像基准，准确率提高了2-5%绝对百分点。此外，我们发现当将特征转移到Meta-Dataset集合中的各种新图像分布以及各种下游任务（如目标检测、实例分割和关键点检测）时，持续受益。",
        "领域": "无监督学习、对比学习、视觉表征学习",
        "问题": "如何通过改进负采样策略来提升对比学习中的视觉表征质量",
        "动机": "随机采样的负例可能包含大量无信息样本，影响对比学习的效果，因此需要一种更有效的负采样方法",
        "方法": "引入一种条件负采样策略，通过在每个正例周围形成‘环’来采样半难负例，以提高对比表征的质量",
        "关键词": [
            "对比学习",
            "条件负采样",
            "视觉表征",
            "互信息估计",
            "半难负例"
        ],
        "涉及的技术概念": {
            "噪声对比估计（NCE）": "用于估计互信息的边界，通过对比正例和随机负例来学习表征",
            "半难负例": "在对比学习中，选择那些既不太容易也不太难以区分的负例，以提高学习效率",
            "互信息估计器": "用于有条件地采样负例，以形成更有效的对比学习目标"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 129,
        "title": "Conformation-Guided Molecular Representation with Hamiltonian Neural Networks",
        "html": "https://iclr.cc//virtual/2021/poster/2926",
        "abstract": "Well-designed molecular representations (fingerprints) are vital to combine medical chemistry and deep learning. Whereas incorporating 3D geometry of molecules (i.e. conformations) in their representations seems beneficial, current 3D algorithms are still in infancy. In this paper, we propose a novel molecular representation algorithm which preserves 3D conformations of molecules with a Molecular Hamiltonian Network (HamNet). In HamNet, implicit positions and momentums of atoms in a molecule interact in the Hamiltonian Engine following the discretized Hamiltonian equations. These implicit coordinations are supervised with real conformations with translation- & rotation-invariant losses, and further used as inputs to the Fingerprint Generator, a message-passing neural network. Experiments show that the Hamiltonian Engine can well preserve molecular conformations, and that the fingerprints generated by HamNet achieve state-of-the-art performances on MoleculeNet, a standard molecular machine learning benchmark.",
        "conference": "ICLR",
        "中文标题": "基于哈密顿神经网络的构象引导分子表示",
        "摘要翻译": "设计良好的分子表示（指纹）对于将药物化学与深度学习相结合至关重要。虽然在分子表示中融入分子的三维几何结构（即构象）似乎有益，但当前的三维算法仍处于起步阶段。在本文中，我们提出了一种新颖的分子表示算法，该算法通过分子哈密顿网络（HamNet）保留分子的三维构象。在HamNet中，分子中原子的隐式位置和动量在哈密顿引擎中按照离散化的哈密顿方程相互作用。这些隐式坐标通过具有平移和旋转不变性的损失函数与真实构象进行监督，并进一步用作指纹生成器（一种消息传递神经网络）的输入。实验表明，哈密顿引擎能够很好地保留分子构象，并且HamNet生成的指纹在MoleculeNet（一个标准的分子机器学习基准）上实现了最先进的性能。",
        "领域": "分子机器学习、药物化学、深度学习",
        "问题": "如何在分子表示中有效融入三维构象信息",
        "动机": "当前的三维分子表示算法尚不成熟，需要开发能够保留分子三维构象信息的新方法",
        "方法": "提出了一种基于分子哈密顿网络（HamNet）的算法，通过哈密顿引擎保留分子构象，并使用消息传递神经网络生成分子指纹",
        "关键词": [
            "分子表示",
            "哈密顿神经网络",
            "构象保留",
            "药物化学",
            "深度学习"
        ],
        "涉及的技术概念": {
            "分子哈密顿网络（HamNet）": "用于保留分子三维构象的网络结构，通过哈密顿引擎实现原子间相互作用",
            "哈密顿引擎": "模拟分子中原子的隐式位置和动量相互作用的模块，遵循离散化的哈密顿方程",
            "指纹生成器": "一种消息传递神经网络，用于将分子的隐式坐标转换为可用于机器学习的指纹"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 130,
        "title": "Conservative Safety Critics for Exploration",
        "html": "https://iclr.cc//virtual/2021/poster/2600",
        "abstract": "Safe exploration presents a major challenge in reinforcement learning (RL): when active data collection requires deploying partially trained policies, we must ensure that these policies avoid catastrophically unsafe regions, while still enabling trial and error learning. In this paper, we target the problem of safe exploration in RL, by learning a conservative safety estimate of environment states through a critic, and provably upper bound the likelihood of catastrophic failures at every training iteration. We theoretically characterize the tradeoff between safety and policy improvement, show that the safety constraints are satisfied with high probability during training, derive provable convergence guarantees for our approach which is no worse asymptotically then standard RL, and empirically demonstrate the efficacy of the proposed approach on a suite of challenging navigation, manipulation, and locomotion tasks. Our results demonstrate that the proposed approach can achieve competitive task performance, while incurring significantly lower catastrophic failure rates during training as compared to prior methods. Videos are at this URL https://sites.google.com/view/conservative-safety-critics/",
        "conference": "ICLR",
        "中文标题": "保守安全评价器用于探索",
        "摘要翻译": "安全探索在强化学习（RL）中提出了一个主要挑战：当主动数据收集需要部署部分训练的策略时，我们必须确保这些策略避免灾难性的不安全区域，同时仍然允许试错学习。在本文中，我们针对RL中的安全探索问题，通过学习环境状态的保守安全估计通过一个评价器，并在每个训练迭代中可证明地上限灾难性失败的可能性。我们从理论上描述了安全性和策略改进之间的权衡，展示了在训练过程中安全约束以高概率被满足，为我们的方法推导出可证明的收敛保证，该方法在渐进性上不逊于标准RL，并在具有挑战性的导航、操作和移动任务套件上实证证明了所提出方法的有效性。我们的结果表明，与先前的方法相比，所提出的方法可以实现竞争性的任务性能，同时在训练过程中显著降低灾难性失败率。视频请访问此URL https://sites.google.com/view/conservative-safety-critics/",
        "领域": "强化学习安全探索、机器人导航与控制、安全强化学习",
        "问题": "如何在强化学习中实现安全探索，避免灾难性不安全区域，同时允许试错学习。",
        "动机": "解决强化学习在主动数据收集过程中部署部分训练策略时可能遇到的灾难性不安全问题，确保训练过程的安全性和有效性。",
        "方法": "通过学习环境状态的保守安全估计，并在每个训练迭代中可证明地上限灾难性失败的可能性，实现安全探索。",
        "关键词": [
            "安全探索",
            "强化学习",
            "保守安全评价器",
            "灾难性失败率",
            "策略改进"
        ],
        "涉及的技术概念": {
            "保守安全评价器": "用于估计环境状态的安全性，确保在探索过程中避免不安全区域。",
            "灾难性失败率": "指在训练过程中遇到的灾难性不安全事件的频率，本文方法旨在显著降低这一比率。",
            "策略改进": "在确保安全的前提下，通过试错学习优化策略性能的过程。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 131,
        "title": "Contemplating Real-World Object Classification",
        "html": "https://iclr.cc//virtual/2021/poster/2746",
        "abstract": "Deep object recognition models have been very successful over benchmark\ndatasets such as ImageNet. How accurate and robust are they to distribution\nshifts arising from natural and synthetic variations in datasets? Prior research on\nthis problem has primarily focused on ImageNet variations (e.g., ImageNetV2,\nImageNet-A). To avoid potential inherited biases in these studies, we take a\ndifferent approach. Specifically, we reanalyze the ObjectNet dataset recently\nproposed by Barbu et al. containing objects in daily life situations. They showed\na dramatic performance drop of the state of the art object recognition models on\nthis dataset. Due to the importance and implications of their results regarding\nthe generalization ability of deep models, we take a second look at their analysis.\nWe find that applying deep models to the isolated objects, rather than the entire\nscene as is done in the original paper, results in around 20-30% performance\nimprovement. Relative to the numbers reported in Barbu et al., around 10-15%\nof the performance loss is recovered, without any test time data augmentation.\nDespite this gain, however, we conclude that deep models still suffer drastically\non the ObjectNet dataset. We also investigate the robustness of models against\nsynthetic image perturbations such as geometric transformations (e.g., scale,\nrotation, translation), natural image distortions (e.g., impulse noise, blur) as well\nas adversarial attacks (e.g., FGSM and PGD-5). Our results indicate that limiting\nthe object area as much as possible (i.e., from the entire image to the bounding\nbox to the segmentation mask) leads to consistent improvement in accuracy and\nrobustness. Finally, through a qualitative analysis of ObjectNet data, we find that\ni) a large number of images in this dataset are hard to recognize even for humans,\nand ii) easy (hard) samples for models match with easy (hard) samples for humans.\nOverall, our analysis shows that ObjecNet is still a challenging test platform that\ncan be used to measure the generalization ability of models. The code and data\nare available in [masked due to blind review].",
        "conference": "ICLR",
        "中文标题": "对现实世界物体分类的思考",
        "摘要翻译": "深度物体识别模型在如ImageNet等基准数据集上取得了巨大成功。然而，它们对于数据集中自然和合成变化引起的分布偏移的准确性和鲁棒性如何？此前关于这一问题的研究主要集中在ImageNet的变体上（例如ImageNetV2、ImageNet-A）。为了避免这些研究中潜在的继承偏差，我们采取了不同的方法。具体来说，我们重新分析了Barbu等人最近提出的ObjectNet数据集，该数据集包含日常生活情境中的物体。他们展示了当前最先进的物体识别模型在该数据集上性能的急剧下降。鉴于他们的结果对于深度模型泛化能力的重要性和影响，我们对他们的分析进行了再次审视。我们发现，将深度模型应用于孤立的物体，而不是像原论文中那样应用于整个场景，可以带来约20-30%的性能提升。相对于Barbu等人报告的数字，大约10-15%的性能损失得到了恢复，且无需任何测试时的数据增强。然而，尽管有这一增益，我们仍然得出结论，深度模型在ObjectNet数据集上的表现仍然大幅下降。我们还研究了模型对合成图像扰动（如几何变换（例如，缩放、旋转、平移）、自然图像失真（例如，脉冲噪声、模糊）以及对抗攻击（例如，FGSM和PGD-5）的鲁棒性。我们的结果表明，尽可能限制物体区域（即从整个图像到边界框再到分割掩码）可以持续提高准确性和鲁棒性。最后，通过对ObjectNet数据的定性分析，我们发现：i）该数据集中有大量图像即使对人类来说也难以识别，ii）模型认为简单（困难）的样本与人类认为简单（困难）的样本相匹配。总体而言，我们的分析表明，ObjectNet仍然是一个具有挑战性的测试平台，可用于衡量模型的泛化能力。代码和数据可在[因盲审而屏蔽]处获取。",
        "领域": "物体识别、模型泛化能力评估、对抗性鲁棒性",
        "问题": "评估深度物体识别模型在现实世界数据集上的准确性和鲁棒性，特别是在面对自然和合成变化时的表现。",
        "动机": "研究深度物体识别模型在现实世界数据集上的泛化能力，揭示模型在面对分布偏移时的局限性。",
        "方法": "重新分析ObjectNet数据集，通过限制物体区域（从整个图像到边界框再到分割掩码）来评估模型性能，并研究模型对合成图像扰动和对抗攻击的鲁棒性。",
        "关键词": [
            "物体识别",
            "模型泛化",
            "对抗性鲁棒性",
            "ObjectNet数据集",
            "性能评估"
        ],
        "涉及的技术概念": {
            "ObjectNet数据集": "一个包含日常生活情境中物体的数据集，用于评估物体识别模型在现实世界条件下的性能。",
            "对抗攻击": "如FGSM和PGD-5，用于测试模型在面对故意设计的扰动时的鲁棒性。",
            "分割掩码": "用于精确限制物体区域的技术，以提高模型在识别任务中的准确性和鲁棒性。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 132,
        "title": "Contextual Dropout: An Efficient Sample-Dependent Dropout Module",
        "html": "https://iclr.cc//virtual/2021/poster/2698",
        "abstract": "Dropout has been demonstrated as a simple and effective module to not only regularize the training process of deep neural networks, but also provide the uncertainty estimation for prediction. However, the quality of uncertainty estimation is highly dependent on the dropout probabilities. Most current models use the same dropout distributions across all data samples due to its simplicity.  Despite the potential gains in the flexibility of modeling uncertainty, sample-dependent dropout, on the other hand, is less explored as it often encounters scalability issues or involves non-trivial model changes.  In this paper, we propose contextual dropout with an efficient structural design as a simple and scalable sample-dependent dropout module, which can be applied to a wide range of models at the expense of only slightly increased memory and computational cost. We learn the dropout probabilities with a variational objective, compatible with both Bernoulli dropout and Gaussian dropout. We apply the contextual dropout module to various models with applications to image classification and visual question answering and demonstrate the scalability of the method with large-scale datasets, such as ImageNet and VQA 2.0. Our experimental results show that the proposed method outperforms baseline methods in terms of both accuracy and quality of uncertainty estimation.",
        "conference": "ICLR",
        "中文标题": "上下文丢弃：一种高效的样本依赖性丢弃模块",
        "摘要翻译": "丢弃已被证明是一种简单而有效的模块，不仅可以规范化深度神经网络的训练过程，还能为预测提供不确定性估计。然而，不确定性估计的质量高度依赖于丢弃概率。由于简单性，大多数当前模型在所有数据样本中使用相同的丢弃分布。尽管在建模不确定性的灵活性方面有潜在收益，但样本依赖性丢弃另一方面较少被探索，因为它经常遇到可扩展性问题或涉及非平凡的模型更改。在本文中，我们提出了上下文丢弃，其具有高效的结构设计，作为一种简单且可扩展的样本依赖性丢弃模块，可以应用于广泛的模型，仅以稍微增加的内存和计算成本为代价。我们通过一个变分目标学习丢弃概率，兼容伯努利丢弃和高斯丢弃。我们将上下文丢弃模块应用于各种模型，应用于图像分类和视觉问答，并展示了该方法在大规模数据集（如ImageNet和VQA 2.0）上的可扩展性。我们的实验结果表明，所提出的方法在准确性和不确定性估计质量方面均优于基线方法。",
        "领域": "深度学习正则化技术、图像分类、视觉问答",
        "问题": "如何在不显著增加计算成本的情况下，实现样本依赖性的丢弃概率以提高模型的不确定性估计质量",
        "动机": "探索样本依赖性丢弃方法，以提升模型在不确定性估计方面的表现，同时解决现有方法在可扩展性和模型改动方面的限制",
        "方法": "提出了一种名为上下文丢弃的样本依赖性丢弃模块，通过变分目标学习丢弃概率，兼容伯努利和高斯丢弃，适用于多种模型",
        "关键词": [
            "上下文丢弃",
            "样本依赖性",
            "不确定性估计",
            "变分目标",
            "视觉问答"
        ],
        "涉及的技术概念": {
            "上下文丢弃": "一种样本依赖性丢弃模块，通过学习数据样本的上下文信息动态调整丢弃概率，以提高模型的不确定性估计质量",
            "变分目标": "用于学习丢弃概率的优化目标，使得丢弃模块能够根据样本特性自适应调整，兼容不同类型的丢弃策略",
            "伯努利丢弃与高斯丢弃": "两种常见的丢弃策略，上下文丢弃模块能够兼容这两种策略，为模型训练提供灵活性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 133,
        "title": "Contextual Transformation Networks for Online Continual Learning",
        "html": "https://iclr.cc//virtual/2021/poster/2887",
        "abstract": "Continual learning methods with fixed architectures rely on a single network to learn models that can perform well on all tasks.\nAs a result, they often only accommodate common features of those tasks but neglect each task's specific features. On the other hand, dynamic architecture methods can have a separate network for each task, but they are too expensive to train and not scalable in practice, especially in online settings.\nTo address this problem, we propose a novel online continual learning method named ``Contextual Transformation Networks” (CTN) to efficiently model the \\emph{task-specific features} while enjoying neglectable complexity overhead compared to other fixed architecture methods. \nMoreover, inspired by the Complementary Learning Systems (CLS) theory, we propose a novel dual memory design and an objective to train CTN that can address both catastrophic forgetting and knowledge transfer simultaneously. \nOur extensive experiments show that CTN is competitive with a large scale dynamic architecture network and consistently outperforms other fixed architecture methods under the same standard backbone. Our implementation can be found at \\url{https://github.com/phquang/Contextual-Transformation-Network}.",
        "conference": "ICLR",
        "中文标题": "上下文转换网络用于在线持续学习",
        "摘要翻译": "固定架构的持续学习方法依赖于单一网络来学习能够在所有任务上表现良好的模型。因此，它们往往只适应这些任务的共同特征，而忽视了每个任务的特定特征。另一方面，动态架构方法可以为每个任务拥有一个独立的网络，但它们的训练成本过高，在实践中不可扩展，尤其是在在线设置中。为了解决这个问题，我们提出了一种名为“上下文转换网络”（CTN）的新型在线持续学习方法，以高效地建模任务特定特征，同时与其他固定架构方法相比，享受可忽略的复杂性开销。此外，受互补学习系统（CLS）理论的启发，我们提出了一种新颖的双记忆设计和训练CTN的目标，可以同时解决灾难性遗忘和知识转移的问题。我们的大量实验表明，CTN与大规模动态架构网络竞争，并且在相同的标准骨干下持续优于其他固定架构方法。我们的实现可以在https://github.com/phquang/Contextual-Transformation-Network找到。",
        "领域": "在线持续学习、动态架构学习、灾难性遗忘",
        "问题": "如何在在线持续学习中高效建模任务特定特征，同时避免灾难性遗忘和实现知识转移。",
        "动机": "解决固定架构方法忽视任务特定特征和动态架构方法训练成本高、不可扩展的问题。",
        "方法": "提出上下文转换网络（CTN）和双记忆设计，结合互补学习系统理论，以高效建模任务特定特征并解决灾难性遗忘和知识转移。",
        "关键词": [
            "在线持续学习",
            "上下文转换网络",
            "双记忆设计",
            "灾难性遗忘",
            "知识转移"
        ],
        "涉及的技术概念": {
            "上下文转换网络（CTN）": "用于高效建模任务特定特征的网络架构，相比固定架构方法具有可忽略的复杂性开销。",
            "互补学习系统（CLS）理论": "启发双记忆设计的理论，旨在同时解决灾难性遗忘和知识转移的问题。",
            "双记忆设计": "一种新颖的记忆设计，用于训练CTN，以同时解决灾难性遗忘和知识转移的问题。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 134,
        "title": "Continual learning in recurrent neural networks",
        "html": "https://iclr.cc//virtual/2021/poster/2851",
        "abstract": "While a diverse collection of continual learning (CL) methods has been proposed to prevent catastrophic forgetting, a thorough investigation of their effectiveness for processing sequential data with recurrent neural networks (RNNs) is lacking. Here, we provide the first comprehensive evaluation of established CL methods on a variety of sequential data benchmarks. Specifically, we shed light on the particularities that arise when applying weight-importance methods, such as elastic weight consolidation, to RNNs. In contrast to feedforward networks, RNNs iteratively reuse a shared set of weights and require working memory to process input samples. We show that the performance of weight-importance methods is not directly affected by the length of the processed sequences, but rather by high working memory requirements, which lead to an increased need for stability at the cost of decreased plasticity for learning subsequent tasks. We additionally provide theoretical arguments supporting this interpretation by studying linear RNNs. Our study shows that established CL methods can be successfully ported to the recurrent case, and that a recent regularization approach based on hypernetworks outperforms weight-importance methods, thus emerging as a promising candidate for CL in RNNs. Overall, we provide insights on the differences between CL in feedforward networks and RNNs, while guiding towards effective solutions to tackle CL on sequential data.",
        "conference": "ICLR",
        "中文标题": "循环神经网络中的持续学习",
        "摘要翻译": "尽管已经提出了多种持续学习（CL）方法来防止灾难性遗忘，但对于使用循环神经网络（RNN）处理序列数据的这些方法的有效性缺乏彻底的调查。在此，我们首次对各种序列数据基准上已建立的CL方法进行了全面评估。具体来说，我们揭示了将权重重要性方法（如弹性权重巩固）应用于RNN时出现的特殊性。与前馈网络不同，RNN迭代地重用一组共享的权重，并需要工作记忆来处理输入样本。我们表明，权重重要性方法的性能并不直接受处理序列长度的影响，而是受高工作记忆需求的影响，这导致了对稳定性的增加需求，以牺牲学习后续任务的可塑性为代价。我们还通过研究线性RNN提供了支持这一解释的理论论据。我们的研究表明，已建立的CL方法可以成功地迁移到循环情况下，并且基于超网络的最近的正则化方法优于权重重要性方法，因此成为RNN中CL的有希望的候选者。总的来说，我们提供了关于前馈网络和RNN中CL差异的见解，同时指导了处理序列数据上CL的有效解决方案。",
        "领域": "持续学习、循环神经网络、序列数据处理",
        "问题": "评估和比较持续学习方法在循环神经网络处理序列数据时的有效性",
        "动机": "缺乏对持续学习方法在循环神经网络中处理序列数据有效性的全面评估",
        "方法": "全面评估多种持续学习方法在序列数据上的表现，特别关注权重重要性方法在RNN中的应用，并提出基于超网络的正则化方法",
        "关键词": [
            "持续学习",
            "循环神经网络",
            "序列数据处理",
            "权重重要性方法",
            "超网络"
        ],
        "涉及的技术概念": {
            "持续学习": "一种旨在防止模型在学习新任务时忘记旧任务知识的学习范式",
            "循环神经网络": "一类用于处理序列数据的神经网络，能够利用其内部状态（记忆）来处理输入序列",
            "权重重要性方法": "一种通过评估权重对旧任务的重要性来防止灾难性遗忘的持续学习策略"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 135,
        "title": "Continuous Wasserstein-2 Barycenter Estimation without Minimax Optimization",
        "html": "https://iclr.cc//virtual/2021/poster/2713",
        "abstract": "Wasserstein barycenters provide a geometric notion of the weighted average of probability measures based on optimal transport. In this paper, we present a scalable algorithm to compute Wasserstein-2 barycenters given sample access to the input measures, which are not restricted to being discrete. While past approaches rely on entropic or quadratic regularization, we employ input convex neural networks and cycle-consistency regularization to avoid introducing bias. As a result, our approach does not resort to minimax optimization. We provide theoretical analysis on error bounds as well as empirical evidence of the effectiveness of the proposed approach in low-dimensional qualitative scenarios and high-dimensional quantitative experiments.",
        "conference": "ICLR",
        "中文标题": "无需极小极大优化的连续Wasserstein-2重心估计",
        "摘要翻译": "Wasserstein重心基于最优传输提供了一种概率测度加权平均的几何概念。本文提出了一种可扩展的算法，用于在给定输入测度样本访问的情况下计算Wasserstein-2重心，这些测度不限于离散形式。虽然以往的方法依赖于熵或二次正则化，但我们采用输入凸神经网络和循环一致性正则化来避免引入偏差。因此，我们的方法不依赖于极小极大优化。我们提供了关于误差界限的理论分析，以及在低维定性场景和高维定量实验中提出的方法有效性的实证证据。",
        "领域": "最优传输理论、概率测度分析、深度学习优化",
        "问题": "如何在无需极小极大优化的情况下，高效且准确地估计连续概率测度的Wasserstein-2重心。",
        "动机": "现有的Wasserstein重心计算方法通常依赖于正则化技术，这可能会引入偏差，且需要复杂的极小极大优化过程。本研究旨在开发一种更直接、偏差更小的计算方法。",
        "方法": "采用输入凸神经网络和循环一致性正则化技术，避免传统正则化方法引入的偏差，同时不依赖于复杂的极小极大优化过程。",
        "关键词": [
            "Wasserstein重心",
            "最优传输",
            "输入凸神经网络",
            "循环一致性正则化",
            "概率测度"
        ],
        "涉及的技术概念": {
            "Wasserstein-2重心": "基于最优传输理论的概率测度加权平均概念，用于衡量概率分布之间的差异。",
            "输入凸神经网络": "一种特殊设计的神经网络，确保输出对于输入是凸的，用于保持优化问题的凸性。",
            "循环一致性正则化": "一种正则化技术，用于确保模型在不同变换下的输出一致性，避免偏差的引入。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 136,
        "title": "Contrastive Behavioral Similarity Embeddings for Generalization in Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2021/poster/2609",
        "abstract": "Reinforcement learning methods trained on few environments rarely learn policies that generalize to unseen environments. To improve generalization, we incorporate the inherent sequential structure in reinforcement learning into the representation learning process. This approach is orthogonal to recent approaches, which rarely exploit this structure explicitly. Specifically, we introduce a theoretically motivated policy similarity metric (PSM) for measuring behavioral similarity between states. PSM assigns high similarity to states for which the optimal policies in those states as well as in future states are similar. We also present a contrastive representation learning procedure to embed any state similarity metric, which we instantiate with PSM to obtain policy similarity embeddings (PSEs). We demonstrate that PSEs improve generalization on diverse benchmarks, including LQR with spurious correlations, a jumping task from pixels, and Distracting DM Control Suite. ",
        "conference": "ICLR",
        "中文标题": "对比行为相似性嵌入在强化学习泛化中的应用",
        "摘要翻译": "在少量环境上训练的强化学习方法很少能学习到能够泛化到未见环境的策略。为了提高泛化能力，我们将强化学习中固有的顺序结构融入到表示学习过程中。这种方法与最近的方法正交，后者很少明确利用这种结构。具体来说，我们引入了一个理论驱动的策略相似性度量（PSM），用于衡量状态之间的行为相似性。PSM对那些状态以及未来状态中最优策略相似的状态赋予高相似性。我们还提出了一种对比表示学习过程，以嵌入任何状态相似性度量，我们通过PSM实例化以获得策略相似性嵌入（PSEs）。我们证明了PSEs在多样化基准测试上提高了泛化能力，包括具有虚假相关性的LQR、基于像素的跳跃任务以及Distracting DM Control Suite。",
        "领域": "强化学习、表示学习、策略泛化",
        "问题": "强化学习方法在少量环境上训练时难以泛化到未见环境的问题",
        "动机": "通过利用强化学习中的顺序结构，提高策略在未见环境中的泛化能力",
        "方法": "引入策略相似性度量（PSM）和对比表示学习过程，生成策略相似性嵌入（PSEs）",
        "关键词": [
            "策略相似性度量",
            "对比学习",
            "强化学习泛化",
            "表示学习",
            "行为相似性"
        ],
        "涉及的技术概念": {
            "策略相似性度量（PSM）": "用于衡量状态之间行为相似性的理论驱动度量，特别关注最优策略在状态及未来状态中的相似性",
            "对比表示学习": "一种学习过程，旨在通过对比正负样本来学习有效的状态表示，这里用于嵌入PSM",
            "策略相似性嵌入（PSEs）": "通过PSM实例化的嵌入，旨在提高强化学习策略在多样化环境中的泛化能力"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 137,
        "title": "Contrastive Divergence Learning is a Time Reversal Adversarial Game",
        "html": "https://iclr.cc//virtual/2021/poster/2898",
        "abstract": "Contrastive divergence (CD) learning is a classical method for fitting unnormalized statistical models to data samples. Despite its wide-spread use, the convergence properties of this algorithm are still not well understood. The main source of difficulty is an unjustified approximation which has been used to derive the gradient of the loss. In this paper, we present an alternative derivation of CD that does not require any approximation and sheds new light on the objective that is actually being optimized by the algorithm. Specifically, we show that CD is an adversarial learning procedure, where a discriminator attempts to classify whether a Markov chain generated from the model has been time-reversed. Thus, although predating generative adversarial networks (GANs) by more than a decade, CD is, in fact, closely related to these techniques. Our derivation settles well with previous observations, which have concluded that CD's update steps cannot be expressed as the gradients of any fixed objective function. In addition, as a byproduct, our derivation reveals a simple correction that can be used as an alternative to Metropolis-Hastings rejection, which is required when the underlying Markov chain is inexact (e.g., when using Langevin dynamics with a large step).",
        "conference": "ICLR",
        "中文标题": "对比散度学习是一种时间反转对抗游戏",
        "摘要翻译": "对比散度（CD）学习是一种将未归一化的统计模型拟合到数据样本的经典方法。尽管其应用广泛，但该算法的收敛性质仍未得到充分理解。主要困难源于在推导损失梯度时使用了一个未经证实的近似。在本文中，我们提出了CD的另一种推导方法，该方法不需要任何近似，并对算法实际优化的目标提供了新的见解。具体来说，我们展示了CD是一种对抗学习过程，其中判别器试图分类从模型生成的马尔可夫链是否已被时间反转。因此，尽管比生成对抗网络（GANs）早出现十多年，CD实际上与这些技术密切相关。我们的推导与之前的观察结果一致，这些观察结果得出结论，CD的更新步骤不能表示为任何固定目标函数的梯度。此外，作为副产品，我们的推导揭示了一个简单的修正，可以作为Metropolis-Hastings拒绝的替代方案，这在基础马尔可夫链不精确时（例如，当使用大步长的Langevin动力学时）是必需的。",
        "领域": "生成模型、对抗学习、统计机器学习",
        "问题": "理解对比散度学习的收敛性质及其与生成对抗网络的关系",
        "动机": "揭示对比散度学习算法的实际优化目标及其与对抗学习的内在联系",
        "方法": "提出了一种不需要近似的新推导方法，展示了CD作为一种对抗学习过程的性质",
        "关键词": [
            "对比散度",
            "对抗学习",
            "生成对抗网络",
            "马尔可夫链",
            "Langevin动力学"
        ],
        "涉及的技术概念": {
            "对比散度": "一种用于训练未归一化统计模型的经典算法，通过近似梯度下降来优化模型参数",
            "对抗学习": "一种学习框架，其中两个模型（生成器和判别器）相互竞争，以提高生成样本的质量",
            "Langevin动力学": "一种用于从概率分布中采样的方法，通过模拟物理系统中的粒子运动来生成样本"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 138,
        "title": "Contrastive Explanations for Reinforcement Learning via Embedded Self Predictions",
        "html": "https://iclr.cc//virtual/2021/poster/3248",
        "abstract": "We investigate a deep reinforcement learning (RL) architecture that supports explaining why a learned agent prefers one action over another. The key idea is to learn action-values that are directly represented via human-understandable properties of expected futures. This is realized via the embedded self-prediction (ESP) model, which learns said properties in terms of human provided features. Action preferences can then be explained by contrasting the future properties predicted for each action. To address cases where there are a large number of features, we develop a novel method for computing minimal sufficient explanations from an ESP. Our case studies in three domains, including a complex strategy game, show that ESP models can be effectively learned and support insightful explanations. ",
        "conference": "ICLR",
        "中文标题": "通过嵌入式自我预测为强化学习提供对比解释",
        "摘要翻译": "我们研究了一种深度强化学习（RL）架构，该架构支持解释为什么学习到的智能体偏好一个动作而非另一个。关键思想是通过人类可理解的预期未来属性直接表示动作价值。这是通过嵌入式自我预测（ESP）模型实现的，该模型根据人类提供的特征学习上述属性。然后，可以通过对比每个动作预测的未来属性来解释动作偏好。为了解决存在大量特征的情况，我们开发了一种新方法，用于从ESP计算最小充分解释。我们在三个领域（包括一个复杂的策略游戏）的案例研究表明，ESP模型可以有效地学习并支持有洞察力的解释。",
        "领域": "强化学习解释性、策略游戏AI、深度强化学习应用",
        "问题": "如何解释强化学习智能体对动作的偏好",
        "动机": "提高强化学习模型的可解释性，使人类能够理解智能体的决策过程",
        "方法": "采用嵌入式自我预测（ESP）模型学习人类可理解的未来属性，并通过对比这些属性来解释动作偏好",
        "关键词": [
            "强化学习解释性",
            "嵌入式自我预测",
            "动作偏好解释",
            "最小充分解释",
            "策略游戏AI"
        ],
        "涉及的技术概念": {
            "嵌入式自我预测（ESP）模型": "用于学习人类可理解的未来属性，以直接表示动作价值",
            "动作价值": "通过人类可理解的属性直接表示，用于解释动作偏好",
            "最小充分解释": "针对存在大量特征的情况，开发的新方法用于从ESP计算解释"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 139,
        "title": "Contrastive  Learning  with Adversarial Perturbations for Conditional Text Generation",
        "html": "https://iclr.cc//virtual/2021/poster/2762",
        "abstract": "Recently, sequence-to-sequence (seq2seq) models with the Transformer architecture have achieved remarkable performance on various conditional text generation tasks, such as machine translation. However, most of them are trained with teacher forcing with the ground truth label given at each time step, without being exposed to incorrectly generated tokens during training, which hurts its generalization to unseen inputs, that is known as the 'exposure bias' problem. In this work, we propose to solve the conditional text generation problem by contrasting positive pairs with negative pairs, such that the model is exposed to various valid or incorrect perturbations of the inputs, for improved generalization. However, training the model with naïve contrastive learning framework using random non-target sequences as negative examples is suboptimal, since they are easily distinguishable from the correct output, especially so with models pretrained with large text corpora. Also, generating positive examples requires domain-specific augmentation heuristics which may not generalize over diverse domains. To tackle this problem, we propose a principled method to generate positive and negative samples for contrastive learning of seq2seq models. Specifically, we generate negative examples by adding small perturbations to the input sequence to minimize its conditional likelihood, and positive examples by adding  large perturbations while enforcing it to have a high conditional likelihood. Such `'hard'' positive and negative pairs generated using our method guides the model to better distinguish correct outputs from incorrect ones. We empirically show that our proposed method significantly improves the generalization of the seq2seq on three text generation tasks --- machine translation, text summarization, and question generation.",
        "conference": "ICLR",
        "中文标题": "使用对抗性扰动进行对比学习的条件文本生成",
        "摘要翻译": "近年来，采用Transformer架构的序列到序列（seq2seq）模型在各种条件文本生成任务上取得了显著成就，如机器翻译。然而，大多数模型在训练时采用教师强制策略，即在每个时间步提供真实标签，而未在训练过程中暴露于错误生成的标记，这损害了其对未见输入的泛化能力，即所谓的‘暴露偏差’问题。在本工作中，我们提出通过对比正负样本对来解决条件文本生成问题，使模型暴露于输入的各种有效或错误扰动中，以提高泛化能力。然而，使用随机非目标序列作为负样本的简单对比学习框架训练模型效果不佳，因为它们与正确输出易于区分，特别是对于使用大型文本语料库预训练的模型。此外，生成正样本需要领域特定的增强启发式方法，这可能无法跨多样领域泛化。为解决这一问题，我们提出了一种为seq2seq模型的对比学习生成正负样本的原则性方法。具体而言，我们通过向输入序列添加小扰动以最小化其条件似然来生成负样本，通过添加大扰动同时强制其具有高条件似然来生成正样本。使用我们的方法生成的‘困难’正负样本对指导模型更好地区分正确与错误输出。我们实证表明，我们提出的方法显著提高了seq2seq在三个文本生成任务——机器翻译、文本摘要和问题生成上的泛化能力。",
        "领域": "自然语言处理与视觉结合",
        "问题": "解决条件文本生成中的暴露偏差问题，提高模型对未见输入的泛化能力",
        "动机": "通过对比正负样本对，使模型在训练过程中暴露于输入的各种有效或错误扰动，以提高其泛化能力",
        "方法": "提出一种为seq2seq模型的对比学习生成正负样本的原则性方法，通过添加不同扰动生成‘困难’正负样本对",
        "关键词": [
            "对比学习",
            "对抗性扰动",
            "条件文本生成",
            "序列到序列模型",
            "Transformer架构"
        ],
        "涉及的技术概念": {
            "对比学习": "通过对比正负样本对来训练模型，以提高其对输入扰动的泛化能力",
            "对抗性扰动": "通过向输入序列添加扰动来生成具有挑战性的正负样本，以增强模型的鲁棒性",
            "条件文本生成": "指在给定特定条件下生成文本的任务，如机器翻译、文本摘要和问题生成"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 140,
        "title": "Contrastive Learning with Hard Negative Samples",
        "html": "https://iclr.cc//virtual/2021/poster/2801",
        "abstract": "We consider the question: how can you sample good negative examples for contrastive learning? We argue that, as with metric learning, learning contrastive representations benefits from hard negative samples (i.e., points that are difficult to distinguish from an anchor point). The key challenge toward using hard negatives is that contrastive methods must remain unsupervised, making it infeasible to adopt existing negative sampling strategies that use label information. In response, we develop a new class of unsupervised methods for selecting hard negative samples where the user can control the amount of hardness. A limiting case of this sampling results in a representation that tightly clusters each class, and pushes different classes as far apart as possible. The proposed method improves downstream performance across multiple modalities, requires only few additional lines of code to implement, and introduces no computational overhead.\n",
        "conference": "ICLR",
        "中文标题": "对比学习与困难负样本",
        "摘要翻译": "我们探讨了一个问题：如何为对比学习采样好的负样本？我们认为，与度量学习一样，学习对比表示受益于困难负样本（即难以与锚点区分的点）。使用困难负样本的关键挑战在于对比方法必须保持无监督，这使得采用现有的利用标签信息的负采样策略变得不可行。为此，我们开发了一类新的无监督方法，用于选择困难负样本，用户可以控制样本的困难程度。这种采样的极限情况会导致一个表示，它紧密地聚类每个类别，并将不同类别尽可能远地推开。所提出的方法在多种模态上提高了下游性能，仅需少量额外代码即可实现，且不引入计算开销。",
        "领域": "自监督学习、对比学习、深度度量学习",
        "问题": "如何在无监督对比学习中有效选择和利用困难负样本以提高模型性能",
        "动机": "解决无监督对比学习中难以有效利用困难负样本的问题，以提高模型的表示学习能力和下游任务的性能",
        "方法": "开发了一种新的无监督方法，允许用户控制负样本的困难程度，通过这种方法选择困难负样本，以优化对比学习的效果",
        "关键词": [
            "对比学习",
            "困难负样本",
            "无监督学习",
            "深度度量学习",
            "表示学习"
        ],
        "涉及的技术概念": {
            "对比学习": "一种通过比较正负样本来学习数据表示的方法，旨在使相似样本的表示接近，不相似样本的表示远离",
            "困难负样本": "难以与锚点区分的样本，对提高模型性能有重要作用",
            "无监督学习": "不依赖标签信息的学习方法，论文中用于选择和利用困难负样本的策略"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 141,
        "title": "Contrastive Syn-to-Real Generalization",
        "html": "https://iclr.cc//virtual/2021/poster/2949",
        "abstract": "Training on synthetic data can be beneficial for label or data-scarce scenarios. However, synthetically trained models often suffer from poor generalization in real domains due to domain gaps. In this work, we make a key observation that the diversity of the learned feature embeddings plays an important role in the generalization performance. To this end, we propose contrastive synthetic-to-real generalization (CSG), a novel framework that leverage the pre-trained ImageNet knowledge to prevent overfitting to the synthetic domain, while promoting the diversity of feature embeddings as an inductive bias to improve generalization. In addition, we enhance the proposed CSG framework with attentional pooling (A-pool) to let the model focus on semantically important regions and further improve its generalization. We demonstrate the effectiveness of CSG on various synthetic training tasks, exhibiting state-of-the-art performance on zero-shot domain generalization.",
        "conference": "ICLR",
        "中文标题": "对比合成到真实泛化",
        "摘要翻译": "在标签或数据稀缺的场景下，使用合成数据进行训练可能是有益的。然而，由于领域差距，合成数据训练的模型在真实领域中往往泛化能力较差。在这项工作中，我们观察到学习到的特征嵌入的多样性在泛化性能中起着重要作用。为此，我们提出了对比合成到真实泛化（CSG），这是一个新颖的框架，利用预训练的ImageNet知识防止对合成领域的过拟合，同时促进特征嵌入的多样性作为提高泛化的归纳偏置。此外，我们通过注意力池化（A-pool）增强了提出的CSG框架，使模型能够专注于语义上重要的区域，并进一步提高其泛化能力。我们在各种合成训练任务上证明了CSG的有效性，展示了在零样本领域泛化上的最先进性能。",
        "领域": "零样本学习、领域自适应、图像分类",
        "问题": "解决合成数据训练的模型在真实领域中泛化能力差的问题",
        "动机": "提高合成数据训练的模型在真实领域中的泛化能力",
        "方法": "提出对比合成到真实泛化（CSG）框架，利用预训练的ImageNet知识防止过拟合，并通过注意力池化（A-pool）增强模型对语义重要区域的关注",
        "关键词": [
            "对比学习",
            "领域泛化",
            "注意力机制",
            "合成数据训练",
            "零样本学习"
        ],
        "涉及的技术概念": {
            "对比合成到真实泛化（CSG）": "利用预训练的ImageNet知识防止对合成领域的过拟合，同时促进特征嵌入的多样性以提高泛化",
            "注意力池化（A-pool）": "使模型能够专注于语义上重要的区域，进一步提高泛化能力",
            "零样本领域泛化": "在未见过的领域中评估模型的泛化能力，无需额外的训练数据"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 142,
        "title": "Control-Aware Representations for Model-based Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2021/poster/2582",
        "abstract": "A major challenge in modern reinforcement learning (RL) is efficient control of dynamical systems from high-dimensional sensory observations.   Learning controllable embedding (LCE) is a promising approach that addresses this challenge by embedding the observations into a lower-dimensional latent space, estimating the latent dynamics, and utilizing it to perform control in the latent space.  Two important questions in this area are how to learn a representation that is amenable to the control problem at hand, and how to achieve an end-to-end framework for representation learning and control.  In this paper, we take a few steps towards addressing these questions. We first formulate a LCE model to learn representations that are suitable to be used by a policy iteration style algorithm in the latent space.We call this model control-aware representation learning(CARL). We derive a loss function and three implementations for CARL. In the offline implementation, we replace the locally-linear control algorithm (e.g., iLQR) used by the existing LCE methods with a RL algorithm, namely model-based soft actor-critic, and show that it results in significant improvement. In online CARL, we interleave representation learning and control, and demonstrate further gain in performance.  Finally, we propose value-guided CARL, a variation in which we optimize a weighted version of the CARL loss function, where the weights depend on the TD-error of the current policy. We evaluate the proposed algorithms by extensive experiments on benchmark tasks and compare them with several LCE baselines.",
        "conference": "ICLR",
        "中文标题": "基于模型强化学习的控制感知表示",
        "摘要翻译": "现代强化学习（RL）中的一个主要挑战是从高维感官观察中高效控制动态系统。学习可控嵌入（LCE）是一种有前景的方法，它通过将观察嵌入到低维潜在空间，估计潜在动态，并利用它在潜在空间中进行控制来解决这一挑战。这一领域的两个重要问题是如何学习适合手头控制问题的表示，以及如何实现表示学习和控制的端到端框架。在本文中，我们朝着解决这些问题迈出了几步。我们首先制定了一个LCE模型，以学习适合在潜在空间中使用策略迭代风格算法的表示。我们称这个模型为控制感知表示学习（CARL）。我们为CARL推导了一个损失函数和三种实现。在离线实现中，我们用基于模型的软演员-评论家（即模型基础的软行动者-评论家算法）替换了现有LCE方法中使用的局部线性控制算法（如iLQR），并显示这带来了显著的改进。在在线CARL中，我们交替进行表示学习和控制，并展示了性能的进一步提升。最后，我们提出了价值引导的CARL，这是一种变体，其中我们优化了CARL损失函数的加权版本，权重取决于当前策略的TD误差。我们通过在基准任务上的广泛实验评估了提出的算法，并将它们与几种LCE基线进行了比较。",
        "领域": "强化学习、动态系统控制、表示学习",
        "问题": "如何从高维感官观察中高效控制动态系统，并学习适合控制问题的表示",
        "动机": "解决现代强化学习中从高维观察控制动态系统的挑战，以及实现表示学习和控制的端到端框架",
        "方法": "提出控制感知表示学习（CARL）模型，包括离线实现、在线实现和价值引导变体，通过实验验证其有效性",
        "关键词": [
            "强化学习",
            "控制感知表示",
            "模型基础学习",
            "动态系统控制",
            "表示学习"
        ],
        "涉及的技术概念": {
            "控制感知表示学习（CARL）": "一种学习适合控制问题的表示的方法，通过优化特定损失函数实现",
            "模型基础的软行动者-评论家算法": "用于替换现有LCE方法中的局部线性控制算法，以提升性能",
            "TD误差": "在价值引导的CARL中用于加权损失函数，反映当前策略的优劣"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 143,
        "title": "Convex Potential Flows: Universal Probability Distributions with Optimal Transport and Convex Optimization",
        "html": "https://iclr.cc//virtual/2021/poster/3181",
        "abstract": "Flow-based models are powerful tools for designing probabilistic models with tractable density. This paper introduces Convex Potential Flows (CP-Flow), a natural and efficient parameterization of invertible models inspired by the optimal transport (OT) theory. CP-Flows are the gradient map of a strongly convex neural potential function. The convexity implies invertibility and allows us to resort to convex optimization to solve the convex conjugate for efficient inversion. To enable maximum likelihood training, we derive a new gradient estimator of the log-determinant of the Jacobian, which involves solving an inverse-Hessian vector product using the conjugate gradient method. The gradient estimator has constant-memory cost, and can be made effectively unbiased by reducing the error tolerance level of the convex optimization routine. Theoretically, we prove that CP-Flows are universal density approximators and are optimal in the OT sense. Our empirical results show that CP-Flow performs competitively on standard benchmarks of density estimation and variational inference.",
        "conference": "ICLR",
        "中文标题": "凸势流：具有最优传输和凸优化的通用概率分布",
        "摘要翻译": "基于流的模型是设计具有可处理密度的概率模型的强大工具。本文介绍了凸势流（CP-Flow），这是一种受最优传输（OT）理论启发的、自然且高效的可逆模型参数化方法。CP-Flow是强凸神经势函数的梯度映射。凸性意味着可逆性，并允许我们利用凸优化来解决凸共轭问题以实现高效的反转。为了实现最大似然训练，我们推导了一种新的雅可比矩阵对数行列式的梯度估计器，该估计器涉及使用共轭梯度法解决逆Hessian向量积问题。该梯度估计器具有恒定的内存成本，并且可以通过降低凸优化例程的误差容忍水平来实现有效无偏。理论上，我们证明了CP-Flow是通用的密度逼近器，并且在OT意义下是最优的。我们的实证结果表明，CP-Flow在密度估计和变分推理的标准基准测试中表现优异。",
        "领域": "概率模型设计, 最优传输理论, 变分推理",
        "问题": "设计一种高效且可逆的概率模型参数化方法，以解决密度估计和变分推理中的问题",
        "动机": "受最优传输理论启发，开发一种能够实现高效反转和最大似然训练的概率模型",
        "方法": "引入凸势流（CP-Flow）作为强凸神经势函数的梯度映射，利用凸优化解决凸共轭问题，并推导新的雅可比矩阵对数行列式的梯度估计器",
        "关键词": [
            "凸势流",
            "最优传输",
            "密度估计",
            "变分推理",
            "凸优化"
        ],
        "涉及的技术概念": {
            "凸势流（CP-Flow）": "一种受最优传输理论启发的、自然且高效的可逆模型参数化方法，是强凸神经势函数的梯度映射",
            "最优传输（OT）理论": "一种数学框架，用于在两个概率分布之间找到最优的传输方案，CP-Flow在此框架下被证明是最优的",
            "共轭梯度法": "用于解决逆Hessian向量积问题的方法，是实现CP-Flow梯度估计器的关键技术"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 144,
        "title": "Convex Regularization behind Neural Reconstruction",
        "html": "https://iclr.cc//virtual/2021/poster/2630",
        "abstract": "Neural networks have shown tremendous potential for reconstructing high-resolution images in inverse problems. The non-convex and opaque nature of neural networks, however, hinders their utility in sensitive applications such as medical imaging. To cope with this challenge, this paper advocates a convex duality framework that makes a two-layer fully-convolutional ReLU denoising network amenable to convex optimization. The convex dual network not only offers the optimum training with convex solvers, but also facilitates interpreting training and prediction. In particular, it implies training neural networks with weight decay regularization induces path sparsity while the prediction is piecewise linear filtering. A range of experiments with MNIST and fastMRI datasets confirm the efficacy of the dual network optimization problem. ",
        "conference": "ICLR",
        "中文标题": "神经网络重建背后的凸正则化",
        "摘要翻译": "神经网络在逆问题中重建高分辨率图像方面显示出巨大潜力。然而，神经网络的非凸性和不透明性阻碍了其在医学成像等敏感应用中的效用。为了应对这一挑战，本文提倡一种凸对偶框架，使得两层全卷积ReLU去噪网络适用于凸优化。凸对偶网络不仅提供了使用凸求解器的最优训练，而且便于解释训练和预测。特别是，它意味着使用权重衰减正则化训练神经网络会诱导路径稀疏性，而预测则是分段线性滤波。在MNIST和fastMRI数据集上进行的一系列实验证实了对偶网络优化问题的有效性。",
        "领域": "医学图像重建、深度学习优化、图像去噪",
        "问题": "解决神经网络在敏感应用如医学成像中因非凸性和不透明性而受限的问题",
        "动机": "提高神经网络在敏感应用中的可解释性和可靠性，通过凸优化方法优化网络训练和预测",
        "方法": "采用凸对偶框架，将两层全卷积ReLU去噪网络转化为凸优化问题，利用权重衰减正则化诱导路径稀疏性，实现分段线性滤波预测",
        "关键词": [
            "凸正则化",
            "神经网络重建",
            "医学成像",
            "凸优化",
            "权重衰减"
        ],
        "涉及的技术概念": {
            "凸对偶框架": "将非凸的神经网络训练问题转化为凸优化问题，便于使用凸求解器进行最优训练",
            "权重衰减正则化": "在训练过程中应用，以诱导网络的路径稀疏性，提高模型的泛化能力",
            "分段线性滤波": "预测过程中采用的技术，使得输出结果具有更好的解释性和可靠性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 145,
        "title": "Coping with Label Shift via Distributionally Robust Optimisation",
        "html": "https://iclr.cc//virtual/2021/poster/3242",
        "abstract": "The label shift problem refers to the supervised learning setting where the train and test label distributions do not match. Existing work addressing label shift usually assumes access to an unlabelled test sample. This sample may be used to estimate the test label distribution, and to then train a suitably re-weighted classifier. While approaches using this idea have proven effective, their scope is limited as it is not always feasible to access the target domain; further, they require repeated retraining if the model is to be deployed in multiple test environments. Can one instead learn a single classifier that is robust to arbitrary label shifts from a broad family? In this paper, we answer this question by proposing a model that minimises an objective based on distributionally robust optimisation (DRO). We then design and analyse a gradient descent-proximal mirror ascent algorithm tailored for large-scale problems to optimise the proposed objective.  Finally, through experiments on CIFAR-100 and ImageNet, we show that our technique can significantly improve performance over a number of baselines in settings where label shift is present.",
        "conference": "ICLR",
        "中文标题": "通过分布鲁棒优化应对标签偏移问题",
        "摘要翻译": "标签偏移问题指的是在监督学习设置中，训练和测试的标签分布不匹配的情况。现有的解决标签偏移的工作通常假设可以访问未标记的测试样本。这个样本可以用来估计测试标签分布，然后训练一个适当重新加权的分类器。虽然使用这一想法的方法已被证明是有效的，但它们的范围有限，因为访问目标域并不总是可行的；此外，如果模型要在多个测试环境中部署，它们需要重复训练。能否学习一个对来自广泛家族的任意标签偏移都具有鲁棒性的单一分类器呢？在本文中，我们通过提出一个基于分布鲁棒优化（DRO）的目标最小化模型来回答这个问题。然后，我们设计并分析了一个针对大规模问题量身定制的梯度下降-近端镜像上升算法，以优化提出的目标。最后，通过在CIFAR-100和ImageNet上的实验，我们展示了在存在标签偏移的设置中，我们的技术可以显著提高相对于多个基线的性能。",
        "领域": "监督学习、分布鲁棒优化、标签偏移处理",
        "问题": "解决在监督学习中训练和测试标签分布不匹配的问题，即标签偏移问题。",
        "动机": "现有的方法需要访问目标域的未标记数据，并且对于多个测试环境需要重复训练，这在实际应用中存在限制。研究旨在开发一个对任意标签偏移都具有鲁棒性的单一分类器。",
        "方法": "提出一个基于分布鲁棒优化（DRO）的目标最小化模型，并设计了一个针对大规模问题的梯度下降-近端镜像上升算法来优化该目标。",
        "关键词": [
            "标签偏移",
            "分布鲁棒优化",
            "监督学习",
            "梯度下降-近端镜像上升算法",
            "大规模问题"
        ],
        "涉及的技术概念": {
            "标签偏移": "指在监督学习设置中，训练和测试的标签分布不匹配的问题。",
            "分布鲁棒优化（DRO）": "一种优化方法，旨在最小化在最坏情况分布下的预期损失，用于提高模型对分布变化的鲁棒性。",
            "梯度下降-近端镜像上升算法": "一种针对大规模优化问题设计的算法，结合了梯度下降和近端操作，用于有效求解分布鲁棒优化问题。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 146,
        "title": "CopulaGNN: Towards Integrating Representational and Correlational Roles of Graphs in Graph Neural Networks",
        "html": "https://iclr.cc//virtual/2021/poster/2572",
        "abstract": "Graph-structured data are ubiquitous. However, graphs encode diverse types of information and thus play different roles in data representation. In this paper, we distinguish the \\textit{representational} and the \\textit{correlational} roles played by the graphs in node-level prediction tasks, and we investigate how Graph Neural Network (GNN) models can effectively leverage both types of information. Conceptually, the representational information provides guidance for the model to construct better node features; while the correlational information indicates the correlation between node outcomes conditional on node features. Through a simulation study, we find that many popular GNN models are incapable of effectively utilizing the correlational information. By leveraging the idea of the copula, a principled way to describe the dependence among multivariate random variables, we offer a general solution. The proposed Copula Graph Neural Network (CopulaGNN) can take a wide range of GNN models as base models and utilize both representational and correlational information stored in the graphs. Experimental results on two types of regression tasks verify the effectiveness of the proposed method.",
        "conference": "ICLR",
        "中文标题": "CopulaGNN：图神经网络中图表示与相关角色的整合探索",
        "摘要翻译": "图结构数据无处不在。然而，图编码了多样化的信息类型，因此在数据表示中扮演着不同的角色。在本文中，我们区分了图在节点级别预测任务中扮演的表示角色和相关角色，并研究了图神经网络（GNN）模型如何有效利用这两种类型的信息。从概念上讲，表示信息为模型构建更好的节点特征提供了指导；而相关信息则指示了基于节点特征的节点结果之间的相关性。通过一项模拟研究，我们发现许多流行的GNN模型无法有效利用相关信息。通过利用copula的思想，一种描述多变量随机变量之间依赖关系的原则性方法，我们提供了一个通用解决方案。提出的Copula图神经网络（CopulaGNN）可以以广泛的GNN模型作为基础模型，并利用图中存储的表示信息和相关信息。在两种类型的回归任务上的实验结果验证了所提方法的有效性。",
        "领域": "图神经网络、节点级别预测、多变量依赖建模",
        "问题": "如何有效整合图结构数据中的表示信息和相关信息以提升节点级别预测任务的性能",
        "动机": "现有的图神经网络模型在处理图结构数据时，往往无法有效利用图中的相关信息，限制了模型性能的提升",
        "方法": "提出CopulaGNN，通过copula理论整合图结构数据中的表示信息和相关信息，以广泛的GNN模型为基础模型",
        "关键词": [
            "CopulaGNN",
            "图神经网络",
            "节点级别预测",
            "多变量依赖",
            "表示信息"
        ],
        "涉及的技术概念": {
            "Copula": "用于描述多变量随机变量之间依赖关系的数学工具，本文中用于整合图中的相关信息",
            "图神经网络": "处理图结构数据的深度学习模型，本文中作为基础模型用于节点级别预测",
            "节点级别预测": "图数据中的一项基本任务，旨在预测图中节点的属性或标签"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 147,
        "title": "Correcting experience replay for multi-agent communication",
        "html": "https://iclr.cc//virtual/2021/poster/2956",
        "abstract": "We consider the problem of learning to communicate using multi-agent reinforcement learning (MARL). A common approach is to learn off-policy, using data sampled from a replay buffer. However, messages received in the past may not accurately reflect the current communication policy of each agent, and this complicates learning. We therefore introduce a 'communication correction' which accounts for the non-stationarity of observed communication induced by multi-agent learning. It works by relabelling the received message to make it likely under the communicator's current policy, and thus be a better reflection of the receiver's current environment. To account for cases in which agents are both senders and receivers, we introduce an ordered relabelling scheme. Our correction is computationally efficient and can be integrated with a range of off-policy algorithms. We find in our experiments that it substantially improves the ability of communicating MARL systems to learn across a variety of cooperative and competitive tasks.",
        "conference": "ICLR",
        "中文标题": "修正多智能体通信的经验回放",
        "摘要翻译": "我们考虑使用多智能体强化学习（MARL）学习通信的问题。一种常见的方法是使用从回放缓冲区采样的数据进行离策略学习。然而，过去接收到的消息可能无法准确反映每个智能体当前的通信策略，这使学习变得复杂。因此，我们引入了一种‘通信修正’，以解决由多智能体学习引起的观察通信的非平稳性。它通过重新标记接收到的消息，使其在通信者当前策略下更有可能，从而更好地反映接收者当前的环境。为了考虑智能体既是发送者又是接收者的情况，我们引入了一种有序的重新标记方案。我们的修正在计算上是高效的，并且可以与一系列离策略算法集成。在我们的实验中，我们发现它显著提高了通信MARL系统在各种合作和竞争任务中学习的能力。",
        "领域": "多智能体强化学习",
        "问题": "解决多智能体强化学习中由于通信策略变化导致的经验回放数据不准确的问题",
        "动机": "提高多智能体强化学习系统在动态通信策略下的学习效率和效果",
        "方法": "引入通信修正机制，通过重新标记接收到的消息以反映当前通信策略，并提出有序的重新标记方案处理双向通信",
        "关键词": [
            "多智能体强化学习",
            "通信修正",
            "经验回放",
            "离策略学习",
            "非平稳性"
        ],
        "涉及的技术概念": {
            "多智能体强化学习（MARL）": "一种学习方法，多个智能体通过与环境交互学习最优策略，同时可能涉及智能体间的通信",
            "通信修正": "一种技术，用于调整历史通信数据以反映当前通信策略，解决由于策略变化导致的数据不一致问题",
            "离策略学习": "一种强化学习范式，智能体通过学习从历史数据中采样的经验来优化策略，而不是直接从当前策略生成的数据中学习"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 148,
        "title": "Counterfactual Generative Networks",
        "html": "https://iclr.cc//virtual/2021/poster/2892",
        "abstract": "Neural networks are prone to learning shortcuts -- they often model simple correlations, ignoring more complex ones that potentially generalize better. Prior works on image classification show that instead of learning a connection to object shape, deep classifiers tend to exploit spurious correlations with low-level texture or the background for solving the classification task. In this work, we take a step towards more robust and interpretable classifiers that explicitly expose the task's causal structure. Building on current advances in deep generative modeling, we propose to decompose the image generation process into independent causal mechanisms that we train without direct supervision. By exploiting appropriate inductive biases, these mechanisms disentangle object shape, object texture, and background; hence, they allow for generating counterfactual images. We demonstrate the ability of our model to generate such images on MNIST and ImageNet. Further, we show that the counterfactual images can improve out-of-distribution robustness with a marginal drop in performance on the original classification task, despite being synthetic. Lastly, our generative model can be trained efficiently on a single GPU, exploiting common pre-trained models as inductive biases.",
        "conference": "ICLR",
        "中文标题": "反事实生成网络",
        "摘要翻译": "神经网络倾向于学习捷径——它们经常建模简单的相关性，而忽略可能具有更好泛化能力的更复杂相关性。先前关于图像分类的研究表明，深度分类器倾向于利用与低级纹理或背景的虚假相关性来解决分类任务，而不是学习与物体形状的联系。在这项工作中，我们朝着更健壮和可解释的分类器迈出了一步，这些分类器明确暴露了任务的因果结构。基于当前深度生成建模的进展，我们提出将图像生成过程分解为独立的因果机制，这些机制我们在没有直接监督的情况下训练。通过利用适当的归纳偏差，这些机制解耦了物体形状、物体纹理和背景；因此，它们允许生成反事实图像。我们在MNIST和ImageNet上展示了我们模型生成此类图像的能力。此外，我们表明，尽管是合成的，反事实图像可以提高分布外鲁棒性，同时在原始分类任务上的性能略有下降。最后，我们的生成模型可以在单个GPU上高效训练，利用常见的预训练模型作为归纳偏差。",
        "领域": "图像分类、生成模型、因果推理",
        "问题": "解决深度分类器倾向于利用简单相关性而非复杂相关性进行图像分类的问题",
        "动机": "开发更健壮和可解释的分类器，通过明确任务的因果结构来提高模型的泛化能力和鲁棒性",
        "方法": "提出将图像生成过程分解为独立的因果机制，并在没有直接监督的情况下训练这些机制，利用归纳偏差解耦物体形状、纹理和背景，生成反事实图像",
        "关键词": [
            "反事实图像",
            "因果机制",
            "生成模型",
            "图像分类",
            "鲁棒性"
        ],
        "涉及的技术概念": {
            "反事实图像": "通过改变图像中的特定因果机制生成的图像，用于提高模型的泛化能力和鲁棒性",
            "因果机制": "图像生成过程中独立的、影响图像特定方面的机制，如物体形状、纹理和背景",
            "归纳偏差": "模型训练中利用的先验知识或假设，用于引导模型学习特定的数据表示或结构"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 149,
        "title": "Coupled Oscillatory Recurrent Neural Network (coRNN): An accurate and (gradient) stable architecture for learning long time dependencies",
        "html": "https://iclr.cc//virtual/2021/poster/3335",
        "abstract": "Circuits of biological neurons, such as in the functional parts of the brain can be modeled as networks of coupled oscillators. Inspired by the ability of these systems to express a rich set of outputs while keeping (gradients of) state variables bounded, we propose a novel architecture for recurrent neural networks. Our proposed RNN is based on a time-discretization of a system of second-order ordinary differential equations, modeling networks of controlled nonlinear oscillators. We prove precise bounds on the gradients of the hidden states, leading to the mitigation of the exploding and vanishing gradient problem for this RNN. Experiments show that the proposed RNN is comparable in performance to the state of the art on a variety of benchmarks, demonstrating the potential of this architecture to provide stable and accurate RNNs for processing complex sequential data.",
        "conference": "ICLR",
        "中文标题": "耦合振荡循环神经网络（coRNN）：一种准确且（梯度）稳定的长时依赖学习架构",
        "摘要翻译": "生物神经元回路，如大脑功能部分，可以被建模为耦合振荡器网络。受这些系统在保持状态变量（及其梯度）有界的同时能够表达丰富输出能力的启发，我们提出了一种新型循环神经网络架构。我们提出的RNN基于二阶常微分方程系统的时间离散化，模拟受控非线性振荡器网络。我们证明了隐藏状态梯度的精确界限，从而缓解了该RNN的梯度爆炸和消失问题。实验表明，所提出的RNN在各种基准测试中的性能与现有技术相当，展示了该架构在处理复杂序列数据时提供稳定且准确RNN的潜力。",
        "领域": "循环神经网络、时间序列分析、非线性动力学系统",
        "问题": "解决循环神经网络在处理长时依赖数据时的梯度爆炸和消失问题",
        "动机": "受生物神经元回路中耦合振荡器网络的启发，旨在设计一种能够保持梯度稳定同时处理复杂序列数据的RNN架构",
        "方法": "基于二阶常微分方程系统的时间离散化，构建受控非线性振荡器网络模型，并通过理论证明隐藏状态梯度的界限来缓解梯度问题",
        "关键词": [
            "耦合振荡器",
            "循环神经网络",
            "梯度稳定",
            "长时依赖",
            "非线性动力学"
        ],
        "涉及的技术概念": {
            "耦合振荡器": "模拟生物神经元回路的网络行为，作为RNN的基础架构",
            "二阶常微分方程": "用于描述振荡器网络的动态行为，通过时间离散化应用于RNN设计",
            "梯度界限": "理论证明隐藏状态梯度的精确界限，有效缓解梯度爆炸和消失问题"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 150,
        "title": "CPR: Classifier-Projection Regularization for Continual Learning",
        "html": "https://iclr.cc//virtual/2021/poster/3353",
        "abstract": "We propose a general, yet simple patch that can be applied to existing regularization-based continual learning methods called classifier-projection regularization (CPR). Inspired by both recent results on neural networks with wide local minima and information theory, CPR adds an additional regularization term that maximizes the entropy of a classifier's output probability. We demonstrate that this additional term can be interpreted as a projection of the conditional probability given by a classifier's output to the uniform distribution. By applying the Pythagorean theorem for KL divergence, we then prove that this projection may (in theory) improve the performance of continual learning methods. In our extensive experimental results, we apply CPR to several state-of-the-art regularization-based continual learning methods and benchmark performance on popular image recognition datasets. Our results demonstrate that CPR indeed promotes a wide local minima and significantly improves both accuracy and plasticity while simultaneously mitigating the catastrophic forgetting of baseline continual learning methods. The codes and scripts for this work are available at https://github.com/csm9493/CPR_CL.",
        "conference": "ICLR",
        "中文标题": "CPR：持续学习中的分类器投影正则化",
        "摘要翻译": "我们提出了一种通用且简单的补丁方法，称为分类器投影正则化（CPR），可应用于现有的基于正则化的持续学习方法。受到神经网络宽局部极小值最新成果和信息论的启发，CPR增加了一个额外的正则化项，该正则化项最大化分类器输出概率的熵。我们证明了这个额外项可以解释为将分类器输出给出的条件概率投影到均匀分布。通过应用KL散度的毕达哥拉斯定理，我们随后证明了这个投影在理论上可能提高持续学习方法的性能。在我们广泛的实验结果中，我们将CPR应用于几种最先进的基于正则化的持续学习方法，并在流行的图像识别数据集上进行了性能基准测试。我们的结果表明，CPR确实促进了宽局部极小值，并显著提高了准确性和可塑性，同时减轻了基线持续学习方法的灾难性遗忘。本工作的代码和脚本可在https://github.com/csm9493/CPR_CL获取。",
        "领域": "持续学习、图像识别、神经网络优化",
        "问题": "解决持续学习中的灾难性遗忘问题，同时提高模型的准确性和可塑性",
        "动机": "受到神经网络宽局部极小值和信息论的启发，旨在通过增加一个正则化项来优化持续学习方法的性能",
        "方法": "提出分类器投影正则化（CPR），通过最大化分类器输出概率的熵来增加一个额外的正则化项，理论上通过KL散度的毕达哥拉斯定理证明其有效性",
        "关键词": [
            "持续学习",
            "分类器投影正则化",
            "灾难性遗忘",
            "神经网络优化",
            "图像识别"
        ],
        "涉及的技术概念": {
            "分类器投影正则化（CPR）": "一种通过最大化分类器输出概率的熵来增加额外正则化项的方法，旨在优化持续学习性能",
            "KL散度": "用于衡量两个概率分布之间的差异，CPR利用其毕达哥拉斯定理来理论证明方法的有效性",
            "灾难性遗忘": "持续学习中的一个主要问题，指模型在学习新任务时忘记旧任务的知识，CPR旨在减轻这一问题"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 151,
        "title": "CPT: Efficient Deep Neural Network Training via Cyclic Precision",
        "html": "https://iclr.cc//virtual/2021/poster/2552",
        "abstract": "Low-precision deep neural network (DNN) training has gained tremendous attention as reducing precision is one of the most effective knobs for boosting DNNs' training time/energy efficiency. In this paper, we attempt to explore low-precision training from a new perspective as inspired by recent findings in understanding DNN training: we conjecture that DNNs' precision might have a similar effect as the learning rate during DNN training, and advocate dynamic precision along the training trajectory for further boosting the time/energy efficiency of DNN training. Specifically, we propose Cyclic Precision Training (CPT) to cyclically vary the precision between two boundary values which can be identified using a simple precision range test within the first few training epochs. Extensive simulations and ablation studies on five datasets and eleven models demonstrate that CPT's effectiveness is consistent across various models/tasks (including classification and language modeling). Furthermore, through experiments and visualization we show that CPT helps to (1) converge to a wider minima with a lower generalization error and (2) reduce training variance which we believe opens up a new design knob for simultaneously improving the optimization and efficiency of DNN training.",
        "conference": "ICLR",
        "中文标题": "CPT：通过循环精度实现高效的深度神经网络训练",
        "摘要翻译": "低精度深度神经网络（DNN）训练因其作为提升DNN训练时间/能源效率的最有效手段之一而受到极大关注。本文中，我们从理解DNN训练的最新发现中获得灵感，尝试从一个新的视角探索低精度训练：我们推测DNN的精度可能在训练过程中具有与学习率相似的效果，并提倡沿训练轨迹动态调整精度以进一步提升DNN训练的时间/能源效率。具体而言，我们提出了循环精度训练（CPT），在训练过程中循环变化精度，其边界值可以通过在前几个训练周期内进行的简单精度范围测试来确定。在五个数据集和十一个模型上进行的大量模拟和消融研究表明，CPT的有效性在各种模型/任务（包括分类和语言建模）中是一致的。此外，通过实验和可视化，我们展示了CPT有助于（1）收敛到一个更宽的极小值，具有更低的泛化误差；（2）减少训练方差，我们相信这为同时改进DNN训练的优化和效率开辟了新的设计思路。",
        "领域": "深度学习优化",
        "问题": "如何通过动态调整训练精度来提升深度神经网络的训练效率和优化性能",
        "动机": "探索低精度训练的新视角，以提升DNN训练的时间/能源效率",
        "方法": "提出循环精度训练（CPT），在训练过程中循环变化精度，通过简单的精度范围测试确定边界值",
        "关键词": [
            "低精度训练",
            "循环精度训练",
            "训练效率",
            "优化性能",
            "深度神经网络"
        ],
        "涉及的技术概念": {
            "循环精度训练（CPT）": "在训练过程中循环变化精度的技术，旨在提升训练效率和优化性能",
            "精度范围测试": "用于确定CPT中精度变化边界值的简单测试方法",
            "泛化误差": "模型在未见数据上的表现误差，CPT有助于降低这一误差"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 152,
        "title": "Creative Sketch Generation",
        "html": "https://iclr.cc//virtual/2021/poster/2736",
        "abstract": "Sketching or doodling is a popular creative activity that people engage in. However, most existing work in automatic sketch understanding or generation has focused on sketches that are quite mundane. In this work, we introduce two datasets of creative sketches -- Creative Birds and Creative Creatures -- containing 10k sketches each along with part annotations. We propose DoodlerGAN -- a part-based Generative Adversarial Network (GAN) -- to generate unseen compositions of novel part appearances. Quantitative evaluations as well as human studies demonstrate that sketches generated by our approach are more creative and of higher quality than existing approaches. In fact, in Creative Birds, subjects prefer sketches generated by DoodlerGAN over those drawn by humans!",
        "conference": "ICLR",
        "中文标题": "创意草图生成",
        "摘要翻译": "素描或涂鸦是人们参与的一种流行的创意活动。然而，大多数现有的自动草图理解或生成工作都集中在相当普通的草图上。在这项工作中，我们介绍了两个创意草图数据集——创意鸟类和创意生物——每个数据集包含10k个草图以及部分注释。我们提出了DoodlerGAN——一个基于部分的生成对抗网络（GAN）——来生成未见部分外观的新组合。定量评估以及人类研究表明，我们的方法生成的草图比现有方法更具创意和质量更高。事实上，在创意鸟类中，受试者更喜欢DoodlerGAN生成的草图，而不是人类绘制的草图！",
        "领域": "创意生成、图像生成、计算机视觉与艺术结合",
        "问题": "如何自动生成具有高创意和高质量的草图",
        "动机": "现有的草图生成方法大多集中在普通草图上，缺乏对创意草图的关注，本研究旨在填补这一空白",
        "方法": "提出了DoodlerGAN，一个基于部分的生成对抗网络，用于生成新颖部分外观的组合",
        "关键词": [
            "创意草图生成",
            "生成对抗网络",
            "创意数据集",
            "部分注释",
            "草图质量评估"
        ],
        "涉及的技术概念": {
            "生成对抗网络（GAN）": "用于生成新颖且高质量创意草图的核心技术",
            "部分注释": "提供草图中各个部分的标注，帮助模型理解和生成更复杂的创意组合",
            "创意数据集": "包含创意鸟类和创意生物的数据集，为研究提供丰富的创意草图样本"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 153,
        "title": "Cross-Attentional Audio-Visual Fusion for Weakly-Supervised Action Localization",
        "html": "https://iclr.cc//virtual/2021/poster/3001",
        "abstract": "Temporally localizing actions in videos is one of the key components for video understanding. Learning from weakly-labeled data is seen as a potential solution towards avoiding expensive frame-level annotations. Different from other works which only depend on visual-modality, we propose to learn richer audiovisual representation for weakly-supervised action localization. First, we propose a multi-stage cross-attention mechanism to collaboratively fuse audio and visual features, which preserves the intra-modal characteristics. Second, to model both foreground and background frames, we construct an open-max classifier that treats the background class as an open-set. Third, for precise action localization, we design consistency losses to enforce temporal continuity for the action class prediction, and also help with foreground-prediction reliability. Extensive experiments on two publicly available video-datasets (AVE and ActivityNet1.2) show that the proposed method effectively fuses audio and visual modalities, and achieves the state-of-the-art results for weakly-supervised action localization.",
        "conference": "ICLR",
        "中文标题": "跨注意力音频-视觉融合用于弱监督动作定位",
        "摘要翻译": "在视频中时间定位动作是视频理解的关键组成部分之一。从弱标记数据中学习被视为避免昂贵帧级注释的潜在解决方案。与仅依赖视觉模态的其他工作不同，我们提出学习更丰富的音频-视觉表示用于弱监督动作定位。首先，我们提出了一种多阶段跨注意力机制，以协作方式融合音频和视觉特征，保留了模态内特性。其次，为了建模前景和背景帧，我们构建了一个开放最大分类器，将背景类视为开放集。第三，为了精确的动作定位，我们设计了一致性损失，以强制动作类预测的时间连续性，并帮助提高前景预测的可靠性。在两个公开可用的视频数据集（AVE和ActivityNet1.2）上的大量实验表明，所提出的方法有效地融合了音频和视觉模态，并在弱监督动作定位上取得了最先进的结果。",
        "领域": "视频理解",
        "问题": "在弱监督条件下，如何有效地融合音频和视觉信息以进行视频中的动作定位。",
        "动机": "避免昂贵的帧级注释，同时提高动作定位的准确性和可靠性。",
        "方法": "提出多阶段跨注意力机制融合音频和视觉特征，构建开放最大分类器处理背景帧，设计一致性损失确保动作预测的时间连续性和前景预测的可靠性。",
        "关键词": [
            "弱监督学习",
            "动作定位",
            "跨模态融合",
            "开放最大分类器",
            "一致性损失"
        ],
        "涉及的技术概念": {
            "多阶段跨注意力机制": "用于协作融合音频和视觉特征，保留各模态的特性。",
            "开放最大分类器": "将背景类视为开放集，以更好地建模前景和背景帧。",
            "一致性损失": "确保动作类预测的时间连续性，提高前景预测的可靠性。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 154,
        "title": "CT-Net: Channel Tensorization Network for Video Classification",
        "html": "https://iclr.cc//virtual/2021/poster/3012",
        "abstract": "3D convolution is powerful for video classification but often computationally expensive, recent studies mainly focus on decomposing it on spatial-temporal and/or channel dimensions.  Unfortunately,  most approaches fail to achieve a preferable balance between convolutional efficiency and feature-interaction sufficiency.  For this reason,  we propose a concise and novel Channel Tensorization Network (CT-Net),  by treating the channel dimension of input feature as a multiplication of K sub-dimensions. On one hand,  it naturally factorizes convolution in a multiple dimension way,  leading to a light computation burden.  On the other hand, it can effectively enhance feature interaction from different channels,  and progressively enlarge the 3D receptive field of such interaction to boost classification accuracy.  Furthermore, we equip our CT-Module with a Tensor Excitation (TE) mechanism. It can learn to exploit spatial, temporal and channel attention in a high-dimensional manner, to improve the cooperative power of all the feature dimensions in our CT-Module. Finally, we flexibly adapt ResNet as our CT-Net. Extensive experiments are conducted on several challenging video benchmarks, e.g., Kinetics-400, Something-Something V1 and V2. Our CT-Net outperforms a number of recent SOTA approaches, in terms of accuracy and/or efficiency.",
        "conference": "ICLR",
        "中文标题": "CT-Net：用于视频分类的通道张量化网络",
        "摘要翻译": "3D卷积在视频分类中非常强大，但通常计算成本高昂。最近的研究主要集中在空间-时间和/或通道维度上对其进行分解。不幸的是，大多数方法未能在卷积效率和特征交互充分性之间达到理想的平衡。为此，我们提出了一种简洁新颖的通道张量化网络（CT-Net），通过将输入特征的通道维度视为K个子维度的乘积。一方面，它以多维方式自然分解卷积，从而减轻计算负担。另一方面，它能有效增强来自不同通道的特征交互，并逐步扩大这种交互的3D感受野以提高分类准确性。此外，我们为CT模块配备了张量激励（TE）机制。它能够学习以高维方式利用空间、时间和通道注意力，以提高我们CT模块中所有特征维度的协作能力。最后，我们灵活地将ResNet适配为我们的CT-Net。在多个具有挑战性的视频基准测试上进行了广泛的实验，例如Kinetics-400、Something-Something V1和V2。我们的CT-Net在准确性和/或效率方面优于许多最近的SOTA方法。",
        "领域": "视频分类、3D卷积神经网络、注意力机制",
        "问题": "如何在保持3D卷积强大性能的同时，降低其计算成本并增强特征交互。",
        "动机": "解决现有方法在卷积效率和特征交互充分性之间难以达到理想平衡的问题。",
        "方法": "提出通道张量化网络（CT-Net），通过将通道维度视为多个子维度的乘积来分解卷积，并引入张量激励（TE）机制增强特征交互。",
        "关键词": [
            "视频分类",
            "3D卷积",
            "通道张量化",
            "张量激励",
            "特征交互"
        ],
        "涉及的技术概念": {
            "通道张量化": "将输入特征的通道维度视为多个子维度的乘积，以多维方式分解卷积，减轻计算负担。",
            "张量激励（TE）机制": "学习以高维方式利用空间、时间和通道注意力，提高特征维度的协作能力。",
            "3D感受野": "通过逐步扩大特征交互的3D感受野，以提高视频分类的准确性。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 155,
        "title": "Cut out the annotator, keep the cutout: better segmentation with weak supervision",
        "html": "https://iclr.cc//virtual/2021/poster/2918",
        "abstract": "Constructing large, labeled training datasets for segmentation models is an expensive and labor-intensive process. This is a common challenge in machine learning, addressed by methods that require few or no labeled data points such as few-shot learning (FSL) and weakly-supervised learning (WS). Such techniques, however, have limitations when applied to image segmentation---FSL methods often produce noisy results and are strongly dependent on which few datapoints are labeled, while WS models struggle to fully exploit rich image information. We propose a framework that fuses FSL and WS for segmentation tasks, enabling users to train high-performing segmentation networks with very few hand-labeled training points. We use FSL models as weak sources in a WS framework, requiring a very small set of reference labeled images, and introduce a new WS model that focuses on key areas---areas with contention among noisy labels---of the image to fuse these weak sources. Empirically, we evaluate our proposed approach over seven well-motivated segmentation tasks. We show that our methods can achieve within 1.4 Dice points compared to fully supervised networks while only requiring five hand-labeled training points. Compared to existing FSL methods, our approach improves performance by a mean 3.6 Dice points over the next-best method. ",
        "conference": "ICLR",
        "中文标题": "摒弃标注者，保留剪裁：弱监督下的更优分割",
        "摘要翻译": "为分割模型构建大型、标注的训练数据集是一个昂贵且劳动密集型的过程。这是机器学习中的一个常见挑战，通过需要少量或无需标注数据点的方法来解决，如少样本学习（FSL）和弱监督学习（WS）。然而，这些技术在应用于图像分割时存在局限性——FSL方法通常产生噪声结果，并且强烈依赖于哪些少量数据点被标注，而WS模型难以充分利用丰富的图像信息。我们提出了一个框架，将FSL和WS融合用于分割任务，使用户能够用极少的手动标注训练点训练高性能的分割网络。我们在WS框架中使用FSL模型作为弱源，仅需要一小组参考标注图像，并引入一个新的WS模型，该模型专注于图像的关键区域——即噪声标签之间存在争议的区域——以融合这些弱源。经验上，我们在七个充分动机的分割任务上评估了我们提出的方法。结果表明，我们的方法可以达到与全监督网络相比仅差1.4 Dice点的性能，而仅需要五个手动标注的训练点。与现有的FSL方法相比，我们的方法平均比次优方法提高了3.6 Dice点的性能。",
        "领域": "图像分割",
        "问题": "如何在减少标注工作量的同时，保持或提升图像分割模型的性能",
        "动机": "解决构建大型标注数据集的高成本和劳动强度问题，同时克服少样本学习和弱监督学习在图像分割任务中的局限性",
        "方法": "提出一个融合少样本学习和弱监督学习的框架，通过引入专注于关键区域的弱监督模型，融合少样本学习模型作为弱源，以训练高性能的分割网络",
        "关键词": [
            "弱监督学习",
            "少样本学习",
            "图像分割",
            "Dice点",
            "噪声标签"
        ],
        "涉及的技术概念": {
            "少样本学习（FSL）": "在仅有少量标注数据的情况下进行学习的技术，用于减少对大量标注数据的依赖",
            "弱监督学习（WS）": "利用不完全、不精确或噪声标注数据进行学习的技术，旨在降低标注成本",
            "Dice点": "用于评估分割模型性能的指标，衡量预测分割与真实分割之间的相似度"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 156,
        "title": " Dance Revolution: Long-Term Dance Generation with Music via Curriculum Learning",
        "html": "https://iclr.cc//virtual/2021/poster/3263",
        "abstract": "Dancing to music is one of human's innate abilities since ancient times. In machine learning research, however, synthesizing dance movements from music is a challenging problem. Recently, researchers synthesize human motion sequences through autoregressive models like recurrent neural network (RNN). Such an approach often generates short sequences due to an accumulation of prediction errors that are fed back into the neural network. This problem becomes even more severe in the long motion sequence generation. Besides, the consistency between dance and music in terms of style, rhythm and beat is yet to be taken into account during modeling. In this paper, we formalize the music-driven dance generation as a sequence-to-sequence learning problem and devise a novel seq2seq architecture to efficiently process long sequences of music features and capture the fine-grained correspondence between music and dance. Furthermore, we propose a novel curriculum learning strategy to alleviate error accumulation of autoregressive models in long motion sequence generation, which gently changes the training process from a fully guided teacher-forcing scheme using the previous ground-truth movements, towards a less guided autoregressive scheme mostly using the generated movements instead. Extensive experiments show that our approach significantly outperforms the existing state-of-the-arts on automatic metrics and human evaluation. We also make a demo video to demonstrate the superior performance of our proposed approach at https://www.youtube.com/watch?v=lmE20MEheZ8.",
        "conference": "ICLR",
        "中文标题": "舞蹈革命：通过课程学习实现音乐驱动的长期舞蹈生成",
        "摘要翻译": "自古以来，随着音乐起舞是人类与生俱来的能力之一。然而，在机器学习研究中，从音乐合成舞蹈动作是一个具有挑战性的问题。最近，研究人员通过自回归模型如循环神经网络（RNN）合成人体运动序列。这种方法由于预测误差的累积反馈到神经网络中，常常只能生成短序列。在长运动序列生成中，这个问题变得更加严重。此外，舞蹈与音乐在风格、节奏和节拍上的一致性在建模过程中尚未被考虑。在本文中，我们将音乐驱动的舞蹈生成形式化为一个序列到序列的学习问题，并设计了一种新颖的seq2seq架构，以高效处理长序列的音乐特征，并捕捉音乐与舞蹈之间的细粒度对应关系。此外，我们提出了一种新颖的课程学习策略，以减轻自回归模型在长运动序列生成中的误差累积，该策略逐渐将训练过程从完全使用先前真实动作的教师强制方案，转变为主要使用生成动作的自回归方案。大量实验表明，我们的方法在自动指标和人类评估上显著优于现有的最先进技术。我们还制作了一个演示视频，展示我们提出方法的优越性能，视频链接为https://www.youtube.com/watch?v=lmE20MEheZ8。",
        "领域": "动作合成、音乐与舞蹈对应、长期序列生成",
        "问题": "如何从音乐中生成长期且与音乐风格、节奏和节拍一致的舞蹈序列",
        "动机": "解决现有自回归模型在长序列生成中的误差累积问题，并提高舞蹈与音乐的一致性",
        "方法": "采用序列到序列学习框架和课程学习策略，逐步从教师强制训练过渡到自回归训练",
        "关键词": [
            "舞蹈生成",
            "课程学习",
            "序列到序列学习",
            "音乐与舞蹈对应",
            "长期序列生成"
        ],
        "涉及的技术概念": {
            "序列到序列学习": "用于将音乐特征序列映射到舞蹈动作序列的框架",
            "课程学习": "逐步调整训练策略，从教师强制过渡到自回归，以减少误差累积",
            "自回归模型": "用于生成舞蹈动作序列的模型，通过逐步预测下一个动作来构建序列"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 157,
        "title": "DARTS-: Robustly Stepping out of Performance Collapse Without Indicators",
        "html": "https://iclr.cc//virtual/2021/poster/2641",
        "abstract": "Despite the fast development of differentiable architecture search (DARTS), it suffers from a standing instability issue regarding searching performance, which extremely limits its application. Existing robustifying methods draw clues from the outcome instead of finding out the causing factor. Various indicators such as Hessian eigenvalues are proposed as a signal of performance collapse, and the searching should be stopped once an indicator reaches a preset threshold.\nHowever, these methods tend to easily reject good architectures if thresholds are inappropriately set, let alone the searching is intrinsically noisy. In this paper, we undertake a more subtle and direct approach to resolve the collapse. \nWe first demonstrate that skip connections with a learnable architectural coefficient can easily recover from a disadvantageous state and become dominant.  We conjecture that skip connections profit too much from this privilege, hence causing the collapse for the derived model. Therefore, we propose to factor out this benefit with an auxiliary skip connection, ensuring a fairer competition for all operations. Extensive experiments on various datasets verify that our approach can substantially improve the robustness of DARTS. Our code is available at https://github.com/Meituan-AutoML/DARTS-",
        "conference": "ICLR",
        "中文标题": "DARTS-：无需指标即可稳健地走出性能崩溃",
        "摘要翻译": "尽管可微分架构搜索（DARTS）发展迅速，但它面临着搜索性能的不稳定性问题，这极大地限制了其应用。现有的鲁棒化方法从结果中寻找线索，而非找出导致因素。提出了各种指标，如Hessian特征值，作为性能崩溃的信号，一旦指标达到预设阈值，搜索就应该停止。然而，如果阈值设置不当，这些方法容易拒绝好的架构，更不用说搜索本身具有内在的噪声。在本文中，我们采取了一种更微妙和直接的方法来解决崩溃问题。我们首先证明，具有可学习架构系数的跳跃连接可以轻松地从不利状态中恢复并变得主导。我们推测跳跃连接从这一特权中获益过多，因此导致派生模型的崩溃。因此，我们提出通过辅助跳跃连接来排除这一优势，确保所有操作的竞争更加公平。在各种数据集上的大量实验验证了我们的方法可以显著提高DARTS的鲁棒性。我们的代码可在https://github.com/Meituan-AutoML/DARTS-获取。",
        "领域": "神经网络架构搜索、深度学习优化、自动化机器学习",
        "问题": "解决可微分架构搜索（DARTS）中的性能崩溃问题",
        "动机": "现有方法通过预设阈值停止搜索以避免性能崩溃，但这种方法容易错误地拒绝好的架构，且搜索过程本身具有噪声，需要更直接和有效的方法来解决崩溃问题。",
        "方法": "通过分析跳跃连接的优势，提出使用辅助跳跃连接来平衡所有操作的竞争，从而提高DARTS的鲁棒性。",
        "关键词": [
            "可微分架构搜索",
            "性能崩溃",
            "跳跃连接",
            "鲁棒性优化",
            "自动化机器学习"
        ],
        "涉及的技术概念": {
            "可微分架构搜索（DARTS）": "一种自动化机器学习技术，通过梯度下降优化神经网络架构，但在搜索过程中可能遇到性能崩溃问题。",
            "跳跃连接": "神经网络中的一种连接方式，允许信息跳过某些层直接传递，本文中通过辅助跳跃连接来平衡操作间的竞争。",
            "Hessian特征值": "用于评估函数在某点的曲率，本文中作为性能崩溃的指标之一。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 158,
        "title": "Data-Efficient Reinforcement Learning with Self-Predictive Representations",
        "html": "https://iclr.cc//virtual/2021/poster/2797",
        "abstract": "While deep reinforcement learning excels at solving tasks where large amounts of data can be collected through virtually unlimited interaction with the environment, learning from limited interaction remains a key challenge. We posit that an agent can learn more efficiently if we augment reward maximization with self-supervised objectives based on structure in its visual input and sequential interaction with the environment.  Our method, Self-Predictive Representations (SPR), trains an agent to predict its own latent state representations multiple steps into the future. We compute target representations for future states using an encoder which is an exponential moving average of the agent’s parameters and we make predictions using a learned transition model.  On its own,  this future prediction objective outperforms prior methods for sample-efficient deep RL from pixels. We further improve performance by adding data augmentation to the future prediction loss, which forces the agent’s representations to be consistent across multiple views of an observation.  Our full self-supervised objective, which combines future prediction and data augmentation, achieves a median human-normalized score of 0.415 on Atari in a setting limited to 100k steps of environment interaction, which represents a 55% relative improvement over the previous state-of-the-art. Notably, even in this limited data regime, SPR exceeds expert human scores on 7 out of 26 games. We’ve made the code associated with this work available at https://github.com/mila-iqia/spr.",
        "conference": "ICLR",
        "中文标题": "数据高效强化学习与自预测表示",
        "摘要翻译": "尽管深度强化学习在解决可以通过与环境的几乎无限交互收集大量数据的任务方面表现出色，但从有限交互中学习仍然是一个关键挑战。我们认为，如果我们通过基于其视觉输入和与环境的顺序交互中的结构的自监督目标来增强奖励最大化，代理可以更高效地学习。我们的方法，自预测表示（SPR），训练代理预测其自身潜在状态表示多步进入未来。我们使用一个编码器计算未来状态的目标表示，该编码器是代理参数的指数移动平均，并使用学习的转换模型进行预测。单独来看，这个未来预测目标在从像素进行样本高效的深度强化学习方面优于先前的方法。我们通过将数据增强添加到未来预测损失中进一步提高了性能，这迫使代理的表示在观察的多个视图之间保持一致。我们完整的自监督目标，结合了未来预测和数据增强，在Atari上在限制于100k步环境交互的设置中达到了0.415的中位数人类标准化分数，这相对于之前的最先进技术代表了55%的相对改进。值得注意的是，即使在这种有限的数据制度下，SPR在26个游戏中的7个上超过了专家人类分数。我们已经将与此工作相关的代码在https://github.com/mila-iqia/spr上提供。",
        "领域": "深度强化学习、自监督学习、样本效率优化",
        "问题": "在有限的环境交互数据下，如何提高深度强化学习的效率和性能。",
        "动机": "探索通过自监督学习增强奖励最大化，以提高代理在有限数据下的学习效率。",
        "方法": "采用自预测表示（SPR）方法，结合未来预测和数据增强的自监督目标，以提高样本效率和性能。",
        "关键词": [
            "自预测表示",
            "数据高效强化学习",
            "自监督学习",
            "样本效率",
            "Atari游戏"
        ],
        "涉及的技术概念": {
            "自预测表示（SPR）": "一种训练代理预测其未来潜在状态表示的方法，以提高学习效率。",
            "指数移动平均编码器": "用于计算未来状态目标表示的编码器，通过平滑代理参数的变化来提高预测的稳定性。",
            "数据增强": "通过生成观察的多个视图来增强训练数据，迫使代理学习更一致的表示。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 159,
        "title": "Dataset Condensation with Gradient Matching",
        "html": "https://iclr.cc//virtual/2021/poster/2784",
        "abstract": "As the state-of-the-art machine learning methods in many fields rely on larger datasets, storing datasets and training models on them become significantly more expensive. This paper proposes a training set synthesis technique for data-efficient learning, called Dataset Condensation, that learns to condense large dataset into a small set of informative synthetic samples for training deep neural networks from scratch. We formulate this goal as a gradient matching problem between the gradients of deep neural network weights that are trained on the original and our synthetic data. We rigorously evaluate its performance in several computer vision benchmarks and demonstrate that it significantly outperforms the state-of-the-art methods. Finally we explore the use of our method in continual learning and neural architecture search and report promising gains when limited memory and computations are available.",
        "conference": "ICLR",
        "中文标题": "梯度匹配的数据集压缩",
        "摘要翻译": "由于许多领域中最先进的机器学习方法依赖于更大的数据集，存储数据集并在其上训练模型变得显著更加昂贵。本文提出了一种用于数据高效学习的训练集合成技术，称为数据集压缩，该技术学习将大型数据集压缩为一小组信息丰富的合成样本，用于从头开始训练深度神经网络。我们将这一目标表述为在原始数据和我们的合成数据上训练的深度神经网络权重的梯度之间的梯度匹配问题。我们在几个计算机视觉基准上严格评估了其性能，并证明它显著优于最先进的方法。最后，我们探索了我们的方法在持续学习和神经架构搜索中的应用，并报告了在内存和计算有限的情况下有希望的增益。",
        "领域": "数据集压缩、持续学习、神经架构搜索",
        "问题": "如何在减少存储和计算成本的同时，保持或提高深度神经网络的训练效率和性能。",
        "动机": "解决大型数据集存储和训练成本高昂的问题，提高数据使用效率。",
        "方法": "通过梯度匹配技术，将大型数据集压缩为一小组合成样本，用于高效训练深度神经网络。",
        "关键词": [
            "数据集压缩",
            "梯度匹配",
            "持续学习",
            "神经架构搜索",
            "数据高效学习"
        ],
        "涉及的技术概念": {
            "数据集压缩": "将大型数据集压缩为一小组信息丰富的合成样本，以减少存储和计算成本。",
            "梯度匹配": "通过匹配在原始数据和合成数据上训练的深度神经网络权重的梯度，优化合成数据的生成。",
            "持续学习": "在有限的内存和计算资源下，持续学习和适应新任务的能力。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 160,
        "title": "Dataset Inference: Ownership Resolution in Machine Learning",
        "html": "https://iclr.cc//virtual/2021/poster/2745",
        "abstract": "With increasingly more data and computation involved in their training,  machine learning models constitute valuable intellectual property. This has spurred interest in model stealing, which is made more practical by advances in learning with partial, little, or no supervision. Existing defenses focus on inserting unique watermarks in a model's decision surface, but this is insufficient:  the watermarks are not sampled from the training distribution and thus are not always preserved during model stealing. In this paper, we make the key observation that knowledge contained in the stolen model's training set is what is common to all stolen copies. The adversary's goal, irrespective of the attack employed, is always to extract this knowledge or its by-products. This gives the original model's owner a strong advantage over the adversary: model owners have access to the original training data. We thus introduce $\\textit{dataset inference}$, the process of identifying whether a suspected model copy has private knowledge from the original model's dataset, as a defense against model stealing. We develop an approach for dataset inference that combines statistical testing with the ability to estimate the distance of multiple data points to the decision boundary. Our experiments on CIFAR10, SVHN, CIFAR100 and ImageNet show that model owners can claim with confidence greater than 99% that their model (or dataset as a matter of fact) was stolen, despite only exposing 50 of the stolen model's training points. Dataset inference defends against state-of-the-art attacks even when the adversary is adaptive. Unlike prior work, it does not require retraining or overfitting the defended model.",
        "conference": "ICLR",
        "中文标题": "数据集推断：机器学习中的所有权解析",
        "摘要翻译": "随着训练中涉及的数据和计算量日益增加，机器学习模型构成了宝贵的知识产权。这激发了模型窃取的兴趣，而部分、少量或无监督学习的进步使得模型窃取变得更加实用。现有的防御措施主要集中在模型的决策面上插入独特的水印，但这还不够：水印并非从训练分布中采样，因此在模型窃取过程中并不总是被保留。在本文中，我们提出了一个关键观察：被盗模型的训练集中包含的知识是所有被盗副本共有的。无论采用何种攻击方式，对手的目标总是提取这些知识或其副产品。这给了原始模型所有者相对于对手的强有力优势：模型所有者可以访问原始训练数据。因此，我们引入了数据集推断，即识别可疑模型副本是否包含原始模型数据集中的私有知识的过程，作为对抗模型窃取的防御手段。我们开发了一种数据集推断方法，该方法将统计测试与估计多个数据点到决策边界的距离的能力结合起来。我们在CIFAR10、SVHN、CIFAR100和ImageNet上的实验表明，模型所有者可以以超过99%的置信度声称他们的模型（或实际上是数据集）被盗，尽管仅暴露了被盗模型的50个训练点。数据集推断能够防御最先进的攻击，即使对手具有适应性。与之前的工作不同，它不需要重新训练或过度拟合防御模型。",
        "领域": "模型安全、知识产权保护、对抗性机器学习",
        "问题": "解决机器学习模型被窃取的问题，提供一种有效的所有权验证方法。",
        "动机": "随着机器学习模型价值的提升，模型窃取行为日益增多，现有水印技术不足以有效保护模型知识产权。",
        "方法": "提出数据集推断方法，通过统计测试和估计数据点到决策边界的距离，验证模型是否包含原始训练数据中的私有知识。",
        "关键词": [
            "数据集推断",
            "模型窃取防御",
            "知识产权保护",
            "统计测试",
            "决策边界"
        ],
        "涉及的技术概念": {
            "数据集推断": "通过分析模型是否包含特定数据集的知识来验证模型所有权的方法。",
            "统计测试": "用于在数据集推断中确定模型是否包含原始训练数据知识的统计方法。",
            "决策边界": "在机器学习中区分不同类别的界限，数据集推断中用于估计数据点到边界的距离以验证模型知识来源。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 161,
        "title": "Dataset Meta-Learning from Kernel Ridge-Regression",
        "html": "https://iclr.cc//virtual/2021/poster/3251",
        "abstract": "One of the most fundamental aspects of any machine learning algorithm is the training data used by the algorithm. \nWe introduce the novel concept of $\\epsilon$-approximation of datasets, obtaining datasets which are much smaller than or are significant corruptions of the original training data while maintaining similar performance. We introduce a meta-learning algorithm Kernel Inducing Points (KIP) for obtaining such remarkable datasets, drawing inspiration from recent developments in the correspondence between infinitely-wide neural networks and kernel ridge-regression (KRR). For KRR tasks, we demonstrate that KIP can compress datasets by one or two orders of magnitude, significantly improving previous dataset distillation and subset selection methods while obtaining state of the art results for MNIST and CIFAR10 classification. Furthermore, our KIP-learned datasets are transferable to the training of finite-width neural networks even beyond the lazy-training regime. Consequently, we obtain state of the art results for neural network dataset distillation with potential applications to privacy-preservation.",
        "conference": "ICLR",
        "中文标题": "基于核岭回归的数据集元学习",
        "摘要翻译": "任何机器学习算法最基础的方面之一便是算法所使用的训练数据。我们引入了数据集ε-近似的全新概念，获得了比原始训练数据小得多或是对原始数据有显著破坏但仍保持相似性能的数据集。受到无限宽神经网络与核岭回归（KRR）之间对应关系最新发展的启发，我们引入了一种元学习算法——核诱导点（KIP），用于获取这种卓越的数据集。对于KRR任务，我们证明了KIP可以将数据集压缩一到两个数量级，显著改进了之前的数据集蒸馏和子集选择方法，同时在MNIST和CIFAR10分类任务上取得了最先进的结果。此外，我们的KIP学习数据集可转移到有限宽度神经网络的训练中，甚至超越了懒惰训练机制。因此，我们在神经网络数据集蒸馏方面取得了最先进的结果，这在隐私保护方面具有潜在的应用价值。",
        "领域": "元学习、核方法、数据集蒸馏",
        "问题": "如何在保持模型性能的同时，显著减少或破坏训练数据集的规模",
        "动机": "探索在减少数据集规模或对数据集进行显著破坏的情况下，仍能保持模型性能的方法，以应用于隐私保护等领域",
        "方法": "引入核诱导点（KIP）元学习算法，利用核岭回归（KRR）与无限宽神经网络之间的对应关系，进行数据集压缩和蒸馏",
        "关键词": [
            "元学习",
            "核岭回归",
            "数据集蒸馏",
            "核诱导点",
            "隐私保护"
        ],
        "涉及的技术概念": {
            "ε-近似数据集": "通过特定方法获得的数据集，其规模远小于或是对原始数据有显著破坏，但仍能保持相似的模型性能",
            "核诱导点（KIP）": "一种元学习算法，用于从原始数据集中提取关键信息，生成压缩后的数据集",
            "核岭回归（KRR）": "一种基于核方法的回归技术，本文中用于与无限宽神经网络的对应关系，支持数据集蒸馏过程"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 162,
        "title": "DC3: A learning method for optimization with hard constraints",
        "html": "https://iclr.cc//virtual/2021/poster/2868",
        "abstract": "Large optimization problems with hard constraints arise in many settings, yet classical solvers are often prohibitively slow, motivating the use of deep networks as cheap 'approximate solvers.' Unfortunately, naive deep learning approaches typically cannot enforce the hard constraints of such problems, leading to infeasible solutions. In this work, we present Deep Constraint Completion and Correction (DC3), an algorithm to address this challenge. Specifically, this method enforces feasibility via a differentiable procedure, which implicitly completes partial solutions to satisfy equality constraints and unrolls gradient-based corrections to satisfy inequality constraints. We demonstrate the effectiveness of DC3 in both synthetic optimization tasks and the real-world setting of AC optimal power flow, where hard constraints encode the physics of the electrical grid. In both cases, DC3 achieves near-optimal objective values while preserving feasibility.",
        "conference": "ICLR",
        "中文标题": "DC3：一种用于带硬约束优化的学习方法",
        "摘要翻译": "在许多场景中会出现带有硬约束的大规模优化问题，然而传统的求解器往往慢得令人望而却步，这促使人们使用深度网络作为廉价的‘近似求解器’。不幸的是，朴素的深度学习方法通常无法强制执行此类问题的硬约束，导致解决方案不可行。在这项工作中，我们提出了深度约束完成与校正（DC3），一种算法来解决这一挑战。具体而言，该方法通过一种可微过程强制执行可行性，该过程隐式地完成部分解以满足等式约束，并展开基于梯度的校正以满足不等式约束。我们在合成优化任务和现实世界的交流最优潮流设置中展示了DC3的有效性，其中硬约束编码了电网的物理特性。在这两种情况下，DC3在保持可行性的同时实现了接近最优的目标值。",
        "领域": "优化算法、深度学习应用、电力系统优化",
        "问题": "解决在深度学习中强制执行硬约束以生成可行解的问题",
        "动机": "传统优化求解器处理大规模硬约束问题效率低下，而现有深度学习方法无法保证解的可行性",
        "方法": "提出深度约束完成与校正（DC3）算法，通过可微过程隐式完成部分解和梯度校正来满足硬约束",
        "关键词": [
            "硬约束优化",
            "深度学习",
            "DC3算法",
            "交流最优潮流",
            "可行性保持"
        ],
        "涉及的技术概念": {
            "深度约束完成与校正（DC3）": "一种算法，通过可微过程隐式完成部分解和梯度校正来满足优化问题中的硬约束",
            "可微过程": "在DC3算法中用于隐式完成部分解以满足等式约束的技术",
            "梯度校正": "在DC3算法中用于展开以满足不等式约束的技术"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 163,
        "title": "DDPNOpt: Differential Dynamic Programming Neural Optimizer",
        "html": "https://iclr.cc//virtual/2021/poster/2702",
        "abstract": "Interpretation of Deep Neural Networks (DNNs) training as an optimal control problem with nonlinear dynamical systems has received considerable attention recently, yet the algorithmic development remains relatively limited. In this work, we make an attempt along this line by reformulating the training procedure from the trajectory optimization perspective. We first show that most widely-used algorithms for training DNNs can be linked to the Differential Dynamic Programming (DDP), a celebrated second-order method rooted in the Approximate Dynamic Programming. In this vein, we propose a new class of optimizer, DDP Neural Optimizer (DDPNOpt), for training feedforward and convolution networks. DDPNOpt features layer-wise feedback policies which improve convergence and reduce sensitivity to hyper-parameter over existing methods. It outperforms other optimal-control inspired training methods in both convergence and complexity, and is competitive against state-of-the-art first and second order methods. We also observe DDPNOpt has surprising benefit in preventing gradient vanishing. Our work opens up new avenues for principled algorithmic design built upon the optimal control theory.",
        "conference": "ICLR",
        "中文标题": "DDPNOpt：差分动态规划神经优化器",
        "摘要翻译": "将深度神经网络（DNNs）的训练解释为具有非线性动态系统的最优控制问题最近受到了相当大的关注，然而算法的发展仍然相对有限。在这项工作中，我们尝试从轨迹优化的角度重新制定训练过程。我们首先表明，大多数广泛使用的DNN训练算法可以与差分动态规划（DDP）联系起来，DDP是一种根植于近似动态规划的著名二阶方法。基于这一点，我们提出了一类新的优化器——DDP神经优化器（DDPNOpt），用于训练前馈和卷积网络。DDPNOpt的特点是具有分层反馈策略，这些策略提高了收敛性并减少了对超参数的敏感性，优于现有方法。在收敛性和复杂性方面，DDPNOpt优于其他受最优控制启发的训练方法，并且与最先进的一阶和二阶方法竞争。我们还观察到DDPNOpt在防止梯度消失方面有出人意料的益处。我们的工作为基于最优控制理论的原理性算法设计开辟了新途径。",
        "领域": "深度学习优化算法、神经网络训练、最优控制理论应用",
        "问题": "如何从最优控制理论的角度改进深度神经网络的训练过程",
        "动机": "探索将深度神经网络的训练过程视为最优控制问题，以开发更有效的训练算法",
        "方法": "通过将训练过程重新表述为轨迹优化问题，提出基于差分动态规划（DDP）的新优化器DDPNOpt，利用分层反馈策略提高训练效率和稳定性",
        "关键词": [
            "差分动态规划",
            "神经网络训练",
            "最优控制",
            "轨迹优化",
            "梯度消失"
        ],
        "涉及的技术概念": {
            "差分动态规划（DDP）": "一种二阶优化方法，用于改进神经网络的训练过程，通过近似动态规划提高收敛性",
            "分层反馈策略": "DDPNOpt中采用的技术，通过在各层之间引入反馈机制，减少对超参数的依赖并提高训练稳定性",
            "梯度消失防止": "DDPNOpt在训练过程中意外发现的优势，有效缓解了深层网络训练中的梯度消失问题"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 164,
        "title": "Deberta: Decoding-Enhanced Bert With Disentangled Attention",
        "html": "https://iclr.cc//virtual/2021/poster/2562",
        "abstract": "Recent progress in pre-trained neural language models has significantly improved the performance of many natural language processing (NLP) tasks. In this paper we propose a new model architecture DeBERTa (Decoding-enhanced BERT with disentangled attention) that improves the BERT and RoBERTa models using two novel techniques. The first is the disentangled attention mechanism, where each word is represented using two vectors that encode its content and position, respectively, and the attention weights among words are computed using disentangled matrices on their contents and relative positions, respectively. Second, an enhanced mask decoder is used to incorporate absolute positions in the decoding layer to predict the masked tokens in model pre-training. In addition, a new virtual adversarial training method is used for fine-tuning to improve models’ \n generalization. We show that these techniques significantly improve the efficiency of model pre-training and the performance of both natural language understand(NLU) and natural langauge generation (NLG) downstream tasks. Compared to RoBERTa-Large, a DeBERTa model trained on half of the training data performs consistently better on a wide range of NLP tasks, achieving improvements on MNLI by +0.9% (90.2% vs. 91.1%), on SQuAD v2.0 by +2.3% (88.4% vs. 90.7%) and RACE by +3.6% (83.2% vs. 86.8%). Notably, we scale up DeBERTa by training a larger version that consists of 48 Transform layers with 1.5 billion parameters. The significant performance boost makes the single DeBERTa model surpass the human performance on the SuperGLUE benchmark (Wang et al., 2019a) for the first time in terms of macro-average score (89.9 versus 89.8), and the ensemble DeBERTa model sits atop the SuperGLUE leaderboard as of January 6, 2021, outperforming the human baseline by a decent margin (90.3 versus\n89.8). The pre-trained DeBERTa models and the source code were released at: https://github.com/microsoft/DeBERTa.\n",
        "conference": "ICLR",
        "中文标题": "Deberta：具有解耦注意力的解码增强型Bert",
        "摘要翻译": "预训练神经语言模型的最新进展显著提高了许多自然语言处理（NLP）任务的性能。在本文中，我们提出了一种新的模型架构DeBERTa（具有解耦注意力的解码增强型BERT），该架构通过两种新技术改进了BERT和RoBERTa模型。第一种是解耦注意力机制，其中每个单词使用两个向量表示，分别编码其内容和位置，单词之间的注意力权重分别使用其内容和相对位置的解耦矩阵计算。第二种是使用增强的掩码解码器在解码层中融入绝对位置信息，以预测模型预训练中的掩码标记。此外，还采用了一种新的虚拟对抗训练方法进行微调，以提高模型的泛化能力。我们展示了这些技术显著提高了模型预训练的效率和自然语言理解（NLU）及自然语言生成（NLG）下游任务的性能。与RoBERTa-Large相比，使用一半训练数据训练的DeBERTa模型在广泛的NLP任务上表现一致更好，在MNLI上提高了+0.9%（90.2% vs. 91.1%），在SQuAD v2.0上提高了+2.3%（88.4% vs. 90.7%），在RACE上提高了+3.6%（83.2% vs. 86.8%）。值得注意的是，我们通过训练一个由48个Transformer层组成、拥有15亿参数的更大版本DeBERTa来扩大规模。显著的性能提升使得单个DeBERTa模型首次在SuperGLUE基准测试（Wang等人，2019a）上以宏观平均分数（89.9对89.8）超越人类表现，而集成DeBERTa模型截至2021年1月6日位居SuperGLUE排行榜首位，以明显优势超越人类基线（90.3对89.8）。预训练的DeBERTa模型和源代码已在https://github.com/microsoft/DeBERTa发布。",
        "领域": "自然语言处理与视觉结合",
        "问题": "提高预训练语言模型在自然语言理解和生成任务中的性能",
        "动机": "通过引入解耦注意力机制和增强的掩码解码器，以及虚拟对抗训练方法，改进BERT和RoBERTa模型，以提高模型预训练的效率和下游任务的性能",
        "方法": "提出DeBERTa模型架构，采用解耦注意力机制和增强的掩码解码器，以及虚拟对抗训练方法进行微调",
        "关键词": [
            "解耦注意力",
            "增强的掩码解码器",
            "虚拟对抗训练",
            "自然语言理解",
            "自然语言生成"
        ],
        "涉及的技术概念": {
            "解耦注意力机制": "每个单词使用两个向量分别编码其内容和位置，通过解耦矩阵计算注意力权重，以提高模型对单词内容和位置信息的处理能力",
            "增强的掩码解码器": "在解码层中融入绝对位置信息，以更准确地预测预训练中的掩码标记",
            "虚拟对抗训练": "一种微调方法，通过在输入数据上添加小的扰动来增强模型的泛化能力"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 165,
        "title": "Debiasing Concept-based Explanations with Causal Analysis",
        "html": "https://iclr.cc//virtual/2021/poster/2732",
        "abstract": "Studying the concept-based explanation techniques, we provided evidences for potential existence of spurious association between the features and concepts due to  unobserved latent variables or noise. We proposed a new causal prior graph that models the impact of the noise and latent confounding fron the estimated concepts. We showed that using the labels as instruments, we can remove the impact of the context from the explanations. Our experiments showed that our debiasing technique not only improves the quality of the explanations, but also improve the accuracy of predicting labels through the concepts. As future work, we will investigate other two-stage-regression techniques to\nfind the most accurate debiasing method.",
        "conference": "ICLR",
        "中文标题": "通过因果分析消除基于概念的解释中的偏差",
        "摘要翻译": "在研究基于概念的解释技术时，我们提供了证据，表明由于未观察到的潜在变量或噪声，特征与概念之间可能存在虚假关联。我们提出了一个新的因果先验图，该图模拟了噪声和潜在混杂因素对估计概念的影响。我们展示了使用标签作为工具，可以从解释中消除上下文的影响。我们的实验表明，我们的去偏技术不仅提高了解释的质量，还通过概念提高了预测标签的准确性。作为未来的工作，我们将研究其他两阶段回归技术，以找到最准确的去偏方法。",
        "领域": "可解释人工智能、因果推理、深度学习解释性",
        "问题": "解决基于概念的解释技术中因未观察到的潜在变量或噪声导致的特征与概念间虚假关联问题",
        "动机": "提高基于概念的解释技术的质量和预测准确性，消除解释中的偏差",
        "方法": "提出新的因果先验图模拟噪声和潜在混杂因素的影响，使用标签作为工具消除上下文影响",
        "关键词": [
            "因果分析",
            "概念解释",
            "去偏技术",
            "两阶段回归",
            "解释质量"
        ],
        "涉及的技术概念": {
            "因果先验图": "用于模拟噪声和潜在混杂因素对估计概念影响的图形模型",
            "标签作为工具": "在因果推理中，使用标签作为工具变量来消除上下文对解释的影响",
            "两阶段回归技术": "用于寻找最准确去偏方法的统计技术，涉及两个阶段的回归分析"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 166,
        "title": " Decentralized Attribution of Generative Models",
        "html": "https://iclr.cc//virtual/2021/poster/3321",
        "abstract": "Growing applications of generative models have led to new threats such as malicious personation and digital copyright infringement. \nOne solution to these threats is model attribution, i.e., the identification of user-end models where the contents under question are generated.\nExisting studies showed empirical feasibility of attribution through a centralized classifier trained on all existing user-end models. \nHowever, this approach is not scalable in a reality where the number of models ever grows. Neither does it provide an attributability guarantee.\nTo this end, this paper studies decentralized attribution, which relies on binary classifiers associated with each user-end model. \nEach binary classifier is parameterized by a user-specific key and distinguishes its associated model distribution from the authentic data distribution. \nWe develop sufficient conditions of the keys that guarantee an attributability lower bound.\nOur method is validated on MNIST, CelebA, and FFHQ datasets. We also examine the trade-off between generation quality and robustness of attribution against adversarial post-processes.",
        "conference": "ICLR",
        "中文标题": "生成模型的去中心化归属",
        "摘要翻译": "生成模型应用的日益增多带来了新的威胁，如恶意模仿和数字版权侵权。针对这些威胁的一个解决方案是模型归属，即识别生成有疑问内容的用户端模型。现有研究表明，通过在所有现有用户端模型上训练的集中式分类器进行归属在经验上是可行的。然而，这种方法在模型数量不断增长的现实中不具备可扩展性，也不提供归属保证。为此，本文研究了去中心化归属，它依赖于与每个用户端模型相关联的二元分类器。每个二元分类器由用户特定的密钥参数化，并将其关联的模型分布与真实数据分布区分开来。我们开发了保证归属下限的密钥充分条件。我们的方法在MNIST、CelebA和FFHQ数据集上得到了验证。我们还研究了生成质量与对抗后处理归因鲁棒性之间的权衡。",
        "领域": "生成对抗网络、数字版权保护、模型安全",
        "问题": "解决生成模型在恶意模仿和数字版权侵权中的归属问题",
        "动机": "应对生成模型应用中出现的恶意模仿和版权侵权威胁，提供可扩展且具有归属保证的解决方案",
        "方法": "采用去中心化归属方法，通过用户特定密钥参数化的二元分类器区分模型生成内容与真实数据",
        "关键词": [
            "生成模型",
            "去中心化归属",
            "数字版权",
            "模型安全",
            "对抗鲁棒性"
        ],
        "涉及的技术概念": {
            "去中心化归属": "通过每个用户端模型关联的二元分类器实现模型生成内容的归属识别",
            "用户特定密钥": "用于参数化二元分类器，确保分类器能够区分特定模型生成的内容与真实数据",
            "对抗后处理鲁棒性": "研究生成模型在面对旨在干扰归属识别的对抗性处理时的鲁棒性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 167,
        "title": "Deciphering and Optimizing Multi-Task Learning: a Random Matrix Approach",
        "html": "https://iclr.cc//virtual/2021/poster/2634",
        "abstract": "This article provides theoretical insights into the inner workings of multi-task and transfer learning methods, by studying the tractable least-square support vector machine multi-task learning (LS-SVM MTL) method, in the limit of large ($p$) and numerous ($n$) data. By a random matrix analysis applied to a Gaussian mixture data model, the performance of MTL LS-SVM is shown to converge, as $n,p\\to\\infty$, to a deterministic limit involving simple (small-dimensional) statistics of the data.\n\nWe prove (i) that the standard MTL LS-SVM algorithm is in general strongly biased and may dramatically fail (to the point that individual single-task LS-SVMs may outperform the MTL approach, even for quite resembling tasks): our analysis provides a simple method to correct these biases, and that we reveal (ii) the sufficient statistics at play in the method, which can be efficiently estimated, even for quite small datasets. The latter result is exploited to automatically optimize the hyperparameters without resorting to any cross-validation procedure. \n\nExperiments on popular datasets demonstrate that our improved MTL LS-SVM method is computationally-efficient and outperforms sometimes much more elaborate state-of-the-art multi-task and transfer learning techniques.",
        "conference": "ICLR",
        "中文标题": "解读与优化多任务学习：一种随机矩阵方法",
        "摘要翻译": "本文通过研究可处理的最小二乘支持向量机多任务学习（LS-SVM MTL）方法，在大数据量（p）和大量数据（n）的极限情况下，提供了对多任务和迁移学习方法内部工作机制的理论见解。通过应用于高斯混合数据模型的随机矩阵分析，MTL LS-SVM的性能被证明随着n,p→∞，收敛到一个涉及数据简单（小维度）统计量的确定性极限。我们证明（i）标准的MTL LS-SVM算法通常存在强烈偏差，并可能严重失败（以至于单个单任务LS-SVM可能优于MTL方法，即使对于相当相似的任务）：我们的分析提供了一种简单的方法来纠正这些偏差，并且我们揭示了（ii）方法中起作用的充分统计量，这些统计量可以高效估计，即使对于相当小的数据集也是如此。后一结果被用来自动优化超参数，而无需任何交叉验证过程。在流行数据集上的实验表明，我们改进的MTL LS-SVM方法计算效率高，有时甚至优于更复杂的先进多任务和迁移学习技术。",
        "领域": "多任务学习, 迁移学习, 支持向量机",
        "问题": "多任务学习中的偏差问题和超参数优化问题",
        "动机": "解决多任务学习算法中的偏差问题，并提高超参数优化的效率",
        "方法": "通过随机矩阵分析和高斯混合数据模型，研究LS-SVM MTL方法的性能，并提出偏差校正和超参数自动优化方法",
        "关键词": [
            "多任务学习",
            "随机矩阵分析",
            "支持向量机",
            "超参数优化",
            "偏差校正"
        ],
        "涉及的技术概念": {
            "随机矩阵分析": "用于分析多任务学习算法在大数据量和大数据规模下的性能收敛性",
            "高斯混合数据模型": "作为研究多任务学习性能的数据模型，帮助理解算法在不同数据分布下的表现",
            "超参数优化": "通过分析中的充分统计量，实现不依赖交叉验证的超参数自动优化"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 168,
        "title": "Deconstructing the Regularization of BatchNorm",
        "html": "https://iclr.cc//virtual/2021/poster/3375",
        "abstract": "Batch normalization (BatchNorm) has become a standard technique in deep learning. Its popularity is in no small part due to its often positive effect on generalization. Despite this success, the regularization effect of the technique is still poorly understood. This study aims to decompose BatchNorm into separate mechanisms that are much simpler. We identify three effects of BatchNorm and assess their impact directly with ablations and interventions. Our experiments show that preventing explosive growth at the final layer at initialization and during training can recover a large part of BatchNorm's generalization boost. This regularization mechanism can lift accuracy by $2.9\\%$ for Resnet-50 on Imagenet without BatchNorm. We show it is linked to other methods like Dropout and recent initializations like Fixup. Surprisingly, this simple mechanism matches the improvement of $0.9\\%$ of the more complex Dropout regularization for the state-of-the-art Efficientnet-B8 model on Imagenet. This demonstrates the underrated effectiveness of simple regularizations and sheds light on directions to further improve generalization for deep nets.",
        "conference": "ICLR",
        "中文标题": "解构批量归一化的正则化作用",
        "摘要翻译": "批量归一化（BatchNorm）已成为深度学习中的标准技术。其流行很大程度上归功于其对泛化能力的积极影响。尽管取得了这一成功，该技术的正则化效果仍然知之甚少。本研究旨在将BatchNorm分解为更简单的独立机制。我们识别了BatchNorm的三种效应，并通过消融和干预直接评估它们的影响。我们的实验表明，在初始化和训练期间防止最终层的爆炸性增长可以恢复BatchNorm泛化提升的大部分。这种正则化机制可以在不使用BatchNorm的情况下，将Resnet-50在Imagenet上的准确率提高2.9%。我们展示了它与Dropout等其他方法以及Fixup等最新初始化方法的联系。令人惊讶的是，这种简单机制与更复杂的Dropout正则化在Imagenet上对最先进的Efficientnet-B8模型的0.9%的改进相匹配。这证明了简单正则化的被低估的有效性，并为进一步提高深度网络泛化能力的方向提供了启示。",
        "领域": "深度学习优化、神经网络正则化、模型初始化",
        "问题": "理解并分解批量归一化（BatchNorm）的正则化效果，以提高深度神经网络的泛化能力。",
        "动机": "尽管BatchNorm在深度学习中广泛应用且对泛化有积极影响，但其正则化机制的具体作用和效果尚不明确，研究旨在揭示这些机制。",
        "方法": "通过将BatchNorm分解为更简单的机制，识别其三种主要效应，并通过消融实验和干预措施直接评估这些效应的影响。",
        "关键词": [
            "批量归一化",
            "正则化",
            "深度学习优化",
            "神经网络",
            "泛化能力"
        ],
        "涉及的技术概念": {
            "批量归一化（BatchNorm）": "一种标准化神经网络中间层激活值的技术，旨在加速训练并提高模型性能。",
            "正则化": "通过引入额外约束或惩罚项防止模型过拟合的技术，提高模型的泛化能力。",
            "消融实验": "通过系统地移除模型的某些部分或功能来研究其对模型性能影响的实验方法。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 169,
        "title": "Decoupling Global and Local Representations via Invertible Generative Flows",
        "html": "https://iclr.cc//virtual/2021/poster/3271",
        "abstract": "In this work, we propose a new generative model that is capable of automatically decoupling global and local representations of images in an entirely unsupervised setting, by embedding a generative flow in the VAE framework to model the decoder.\nSpecifically, the proposed model utilizes the variational auto-encoding framework to learn a (low-dimensional) vector of latent variables to capture the global information of an image, which is fed as a conditional input to a flow-based invertible decoder with architecture borrowed from style transfer literature.\nExperimental results on standard image benchmarks demonstrate the effectiveness of our model in terms of density estimation, image generation and unsupervised representation learning.\nImportantly, this work demonstrates that with only architectural inductive biases, a generative model with a likelihood-based objective is capable of learning decoupled representations, requiring no explicit supervision.\nThe code for our model is available at \\url{https://github.com/XuezheMax/wolf}.",
        "conference": "ICLR",
        "中文标题": "通过可逆生成流解耦全局与局部表示",
        "摘要翻译": "在这项工作中，我们提出了一种新的生成模型，该模型能够在完全无监督的环境中自动解耦图像的全局和局部表示，这是通过在VAE框架中嵌入生成流来建模解码器实现的。具体来说，所提出的模型利用变分自编码框架学习一个（低维）潜在变量向量来捕获图像的全局信息，该向量作为条件输入被馈送到一个基于流的可逆解码器，其架构借鉴了风格转换文献。在标准图像基准上的实验结果表明，我们的模型在密度估计、图像生成和无监督表示学习方面的有效性。重要的是，这项工作表明，仅通过架构的归纳偏差，具有基于似然的目标的生成模型就能够学习解耦的表示，无需明确的监督。我们的模型代码可在https://github.com/XuezheMax/wolf获取。",
        "领域": "生成模型、图像生成、无监督学习",
        "问题": "如何在无监督设置下自动解耦图像的全局和局部表示",
        "动机": "探索生成模型在无需明确监督的情况下，通过架构设计自动学习解耦的全局和局部表示的能力",
        "方法": "结合变分自编码框架和基于流的可逆解码器，利用风格转换文献中的架构设计，学习图像的全局信息并生成解耦的表示",
        "关键词": [
            "生成模型",
            "可逆流",
            "无监督学习",
            "变分自编码",
            "表示学习"
        ],
        "涉及的技术概念": {
            "变分自编码框架": "用于学习捕获图像全局信息的低维潜在变量向量",
            "基于流的可逆解码器": "借鉴风格转换文献的架构，用于生成解耦的表示",
            "无监督表示学习": "模型在无需明确监督的情况下，通过学习解耦的全局和局部表示来提升图像生成和密度估计的能力"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 170,
        "title": "DeepAveragers: Offline Reinforcement Learning By Solving Derived Non-Parametric MDPs",
        "html": "https://iclr.cc//virtual/2021/poster/3092",
        "abstract": "We study an approach to offline reinforcement learning (RL) based on optimally solving  finitely-represented  MDPs  derived  from  a  static  dataset  of  experience. This approach can be applied on top of any learned representation and has the potential to easily support multiple solution objectives as well as zero-shot adjustment to changing environments and goals.  Our main contribution is to introduce the Deep Averagers with Costs MDP (DAC-MDP) and to investigate its solutions for offline RL.  DAC-MDPs are a non-parametric model that can leverage deep representations and account for limited data by introducing costs for exploiting under-represented parts of the model.  In theory, we show conditions that allow for lower-bounding the performance of DAC-MDP solutions. We also investigate the empirical behavior in a number of environments, including those with image-based observations. Overall, the experiments demonstrate that the framework can work in practice and scale to large complex offline RL problems.",
        "conference": "ICLR",
        "中文标题": "DeepAveragers：通过求解派生非参数MDP进行离线强化学习",
        "摘要翻译": "我们研究了一种基于最优求解从静态经验数据集中派生的有限表示MDP的离线强化学习（RL）方法。这种方法可以应用于任何学习到的表示之上，并有可能轻松支持多种解决方案目标，以及对变化环境和目标的零射调整。我们的主要贡献是引入了带有成本的深度平均器MDP（DAC-MDP），并研究了其在离线RL中的解决方案。DAC-MDP是一种非参数模型，可以利用深度表示，并通过为利用模型中代表性不足的部分引入成本来考虑数据限制。理论上，我们展示了允许下界DAC-MDP解决方案性能的条件。我们还研究了在多个环境中的实证行为，包括那些基于图像观察的环境。总体而言，实验证明该框架可以在实践中工作，并扩展到大型复杂的离线RL问题。",
        "领域": "离线强化学习、深度强化学习、非参数模型",
        "问题": "如何在离线强化学习中有效地利用静态数据集进行策略优化，同时适应环境变化和目标调整。",
        "动机": "为了解决离线强化学习中数据利用效率低、难以适应环境变化和目标调整的问题。",
        "方法": "引入带有成本的深度平均器MDP（DAC-MDP），一种非参数模型，通过引入成本来优化对数据集中代表性不足部分的使用，从而在离线RL中实现有效的策略优化。",
        "关键词": [
            "离线强化学习",
            "非参数模型",
            "深度平均器",
            "DAC-MDP",
            "零射调整"
        ],
        "涉及的技术概念": {
            "DAC-MDP": "一种非参数模型，用于离线强化学习，通过引入成本来优化对数据集中代表性不足部分的使用。",
            "非参数模型": "在模型复杂度不固定，可以随着数据量的增加而增加的模型，DAC-MDP利用这一点来适应不同的数据分布。",
            "零射调整": "指模型能够在没有额外训练的情况下，适应新的环境或目标，DAC-MDP框架支持这种能力。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 171,
        "title": "Deep Encoder, Shallow Decoder: Reevaluating Non-autoregressive Machine Translation",
        "html": "https://iclr.cc//virtual/2021/poster/3096",
        "abstract": "Much recent effort has been invested in non-autoregressive neural machine translation, which appears to be an efficient alternative to state-of-the-art autoregressive machine translation on modern GPUs.  In contrast to the latter, where generation is sequential, the former allows generation to be parallelized across target token positions. Some of the latest non-autoregressive models have achieved impressive translation quality-speed tradeoffs compared to autoregressive baselines. In this work, we reexamine this tradeoff and argue that autoregressive baselines can be substantially sped up without loss in accuracy. Specifically, we study autoregressive models with encoders and decoders of varied depths. Our extensive experiments show that given a sufficiently deep encoder, a single-layer autoregressive decoder can substantially outperform strong non-autoregressive models with comparable inference speed. We show that the speed disadvantage for autoregressive baselines compared to non-autoregressive methods has been overestimated in three aspects: suboptimal layer allocation, insufficient speed measurement, and lack of knowledge distillation. Our results establish a new protocol for future research toward fast, accurate machine translation. Our code is available at https://github.com/jungokasai/deep-shallow.",
        "conference": "ICLR",
        "中文标题": "深度编码器，浅层解码器：重新评估非自回归机器翻译",
        "摘要翻译": "近年来，大量研究投入于非自回归神经机器翻译，这似乎是在现代GPU上替代当前最先进的自回归机器翻译的高效方案。与后者生成过程是顺序的不同，前者允许在目标标记位置上并行生成。一些最新的非自回归模型与自回归基线相比，已经实现了令人印象深刻的翻译质量与速度的权衡。在这项工作中，我们重新审视了这一权衡，并认为自回归基线可以在不损失准确性的情况下显著加速。具体来说，我们研究了编码器和解码器深度不一的自回归模型。我们的大量实验表明，给定足够深的编码器，单层自回归解码器可以显著超越具有可比推理速度的强非自回归模型。我们展示了自回归基线与非自回归方法相比的速度劣势在三个方面被高估了：次优的层分配、速度测量不足以及缺乏知识蒸馏。我们的结果为未来快速、准确的机器翻译研究建立了新的协议。我们的代码可在https://github.com/jungokasai/deep-shallow获取。",
        "领域": "神经机器翻译、自回归模型、非自回归模型",
        "问题": "重新评估非自回归机器翻译与自回归机器翻译在翻译质量和速度上的权衡",
        "动机": "探讨自回归机器翻译模型在不损失翻译准确性的情况下提高翻译速度的可能性",
        "方法": "研究编码器和解码器深度不一的自回归模型，通过实验比较不同配置下的翻译质量和速度",
        "关键词": [
            "神经机器翻译",
            "自回归模型",
            "非自回归模型",
            "编码器-解码器架构",
            "知识蒸馏"
        ],
        "涉及的技术概念": {
            "自回归模型": "生成目标序列时，每一步的生成依赖于之前已生成的标记，导致生成过程是顺序的",
            "非自回归模型": "允许在目标标记位置上并行生成，提高了生成速度",
            "知识蒸馏": "通过训练一个较小的模型（学生模型）来模仿一个较大的模型（教师模型）的行为，用于提升小模型的性能"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 172,
        "title": "Deep Equals Shallow for ReLU Networks in Kernel Regimes",
        "html": "https://iclr.cc//virtual/2021/poster/2645",
        "abstract": "Deep networks are often considered to be more expressive than shallow ones in terms of approximation. Indeed, certain functions can be approximated by deep networks provably more efficiently than by shallow ones, however, no tractable algorithms are known for learning such deep models. Separately, a recent line of work has shown that deep networks trained with gradient descent may behave like (tractable) kernel methods in a certain over-parameterized regime, where the kernel is determined by the architecture and initialization, and this paper focuses on approximation for such kernels. We show that for ReLU activations, the kernels derived from deep fully-connected networks have essentially the same approximation properties as their shallow two-layer counterpart, namely the same eigenvalue decay for the corresponding integral operator. This highlights the limitations of the kernel framework for understanding the benefits of such deep architectures. Our main theoretical result relies on characterizing such eigenvalue decays through differentiability properties of the kernel function, which also easily applies to the study of other kernels defined on the sphere.",
        "conference": "ICLR",
        "中文标题": "深度等于浅度：ReLU网络在核机制中的表现",
        "摘要翻译": "在近似表达方面，深度网络通常被认为比浅层网络更具表现力。确实，某些函数可以通过深度网络比浅层网络更有效地近似，然而，目前尚无可行的算法来学习这样的深度模型。另外，最近的一系列研究表明，在某种过度参数化的机制下，通过梯度下降训练的深度网络可能表现得像（可处理的）核方法，其中核由架构和初始化决定，本文重点研究此类核的近似性质。我们表明，对于ReLU激活函数，从深度全连接网络导出的核与其浅层两层对应物具有基本相同的近似性质，即对应积分算子的相同特征值衰减。这凸显了核框架在理解此类深度架构优势方面的局限性。我们的主要理论结果依赖于通过核函数的不同可微性特性来表征这种特征值衰减，这也容易适用于研究定义在球面上的其他核。",
        "领域": "深度学习理论、神经网络架构、核方法",
        "问题": "探讨深度ReLU网络在核机制下的近似性质是否优于浅层网络",
        "动机": "理解深度网络在特定条件下（如过度参数化）表现出的核方法行为，以及这种行为的近似性质",
        "方法": "通过分析ReLU激活函数的深度全连接网络导出的核的性质，比较其与浅层网络核的近似效率，特别是特征值衰减的特性",
        "关键词": [
            "ReLU网络",
            "核方法",
            "深度与浅层网络比较",
            "特征值衰减",
            "过度参数化"
        ],
        "涉及的技术概念": {
            "核方法": "在过度参数化机制下，深度网络的行为类似于核方法，核由网络架构和初始化决定",
            "特征值衰减": "用于比较深度和浅层网络核的近似性质，反映核的积分算子的性质",
            "过度参数化": "指网络参数数量远大于训练样本数的情况，影响网络训练时的行为"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 173,
        "title": "Deep Learning meets Projective Clustering",
        "html": "https://iclr.cc//virtual/2021/poster/3076",
        "abstract": "A common approach for compressing Natural Language Processing (NLP) networks is to encode the embedding layer as a matrix $A\\in\\mathbb{R}^{n\\times d}$, compute its rank-$j$ approximation $A_j$ via SVD (Singular Value Decomposition), and then factor $A_j$ into a pair of matrices that correspond to smaller fully-connected layers to replace the original embedding layer. Geometrically, the rows of $A$ represent points in $\\mathbb{R}^d$, and the rows of $A_j$ represent their projections onto the $j$-dimensional subspace that minimizes the sum of squared distances (``errors'') to the points. \nIn practice, these rows of $A$ may be spread around $k>1$ subspaces, so factoring $A$ based on a single subspace may lead to large errors that turn into large drops in accuracy.\n\nInspired by \\emph{projective clustering} from computational geometry,  we suggest replacing this subspace by a set of $k$ subspaces, each of dimension $j$, that minimizes the sum of squared distances over every point (row in $A$) to its \\emph{closest} subspace. Based on this approach, we provide a novel architecture that replaces the original embedding layer by a set of $k$ small layers that operate in parallel and are then recombined with a single fully-connected layer. \n\nExtensive experimental results on the GLUE benchmark yield networks that are both more accurate and smaller compared to the standard matrix factorization (SVD). For example, we further compress DistilBERT by reducing the size of the embedding layer by $40\\%$ while incurring only a $0.5\\%$ average drop in accuracy over all nine GLUE tasks, compared to a $2.8\\%$ drop using the existing SVD approach.\nOn RoBERTa we achieve $43\\%$ compression of the embedding layer with less than a $0.8\\%$ average drop in accuracy as compared to a $3\\%$ drop previously.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "深度学习与投影聚类相结合",
        "摘要翻译": "压缩自然语言处理（NLP）网络的常用方法是将嵌入层编码为矩阵 A ∈ R^(n×d)，通过奇异值分解（SVD）计算其秩为 j 的近似矩阵 Aj，然后将 Aj 分解成一对矩阵，这两个矩阵对应于更小的全连接层，用于替换原始嵌入层。从几何角度来看，A 的行代表 R^d 中的点，而 Aj 的行代表它们在 j 维子空间上的投影，该子空间最小化到这些点的平方距离之和（即“误差”）。\\n\\n在实践中，A 的这些行可能分布在 k>1 个子空间周围，因此基于单个子空间分解 A 可能会导致较大的误差，进而导致精度大幅下降。\\n\\n受到计算几何学中投影聚类的启发，我们建议用一组 k 个子空间（每个子空间的维度为 j）来替换这个子空间，这组子空间最小化每个点（A 中的每一行）到其最近子空间的平方距离之和。基于这种方法，我们提供了一种新颖的架构，该架构用一组 k 个并行运行的小层替换原始嵌入层，然后通过单个全连接层重新组合。\\n\\n在 GLUE 基准测试上的大量实验结果表明，与标准矩阵分解（SVD）相比，我们得到的网络更准确、更小。例如，我们进一步压缩了 DistilBERT，将嵌入层的大小减少了 40%，而在所有九个 GLUE 任务中，平均精度仅下降了 0.5%，而使用现有的 SVD 方法则下降了 2.8%。\\n\\n在 RoBERTa 上，我们实现了嵌入层 43% 的压缩，平均精度下降不到 0.8%，而之前下降了 3%。",
        "领域": "自然语言处理",
        "问题": "如何更有效地压缩自然语言处理 (NLP) 网络的嵌入层，在压缩的同时尽量减少精度损失。",
        "动机": "现有的基于奇异值分解 (SVD) 的矩阵分解方法在压缩嵌入层时，由于数据可能分布在多个子空间中，会导致较大的误差和精度下降。研究的动机在于找到一种能更好适应数据分布的压缩方法，以在保证精度的前提下进一步压缩模型。",
        "方法": "提出了一种基于投影聚类的嵌入层压缩方法。该方法使用一组 k 个子空间来代替单个子空间，并通过最小化每个点到其最近子空间的平方距离之和来进行优化。基于此，设计了一种新的网络架构，使用 k 个并行的小层来替换原始嵌入层，并通过一个全连接层进行重组。",
        "关键词": [
            "嵌入层压缩",
            "投影聚类",
            "奇异值分解(SVD)",
            "自然语言处理(NLP)",
            "模型压缩"
        ],
        "涉及的技术概念": {
            "嵌入层": "在自然语言处理模型中，嵌入层用于将离散的词汇转换为连续的向量表示，是模型的重要组成部分。",
            "奇异值分解(SVD)": "一种常用的矩阵分解技术，用于将矩阵分解为三个矩阵的乘积，可以用于降维和数据压缩。"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 174,
        "title": "Deep Networks and the Multiple Manifold Problem",
        "html": "https://iclr.cc//virtual/2021/poster/2530",
        "abstract": "We study the multiple manifold problem, a binary classification task modeled on applications in machine vision, in which a deep fully-connected neural network is trained to separate two low-dimensional submanifolds of the unit sphere. We provide an analysis of the one-dimensional case, proving for a simple manifold configuration that when the network depth $L$ is large relative to certain geometric and statistical properties of the data, the network width $n$ grows as a sufficiently large polynomial in $L$, and the number of i.i.d. samples from the manifolds is polynomial in $L$, randomly-initialized gradient descent rapidly learns to classify the two manifolds perfectly with high probability. Our analysis demonstrates concrete benefits of depth and width in the context of a practically-motivated model problem: the depth acts as a fitting resource, with larger depths corresponding to smoother networks that can more readily separate the class manifolds, and the width acts as a statistical resource, enabling concentration of the randomly-initialized network and its gradients. The argument centers around the 'neural tangent kernel' of Jacot et al. and its role in the nonasymptotic analysis of training overparameterized neural networks; to this literature, we contribute essentially optimal rates of concentration for the neural tangent kernel of deep fully-connected ReLU networks, requiring width $n \\geq L\\,\\mathrm{poly}(d_0)$ to achieve uniform concentration of the initial kernel over a $d_0$-dimensional submanifold of the unit sphere $\\mathbb{S}^{n_0-1}$, and a nonasymptotic framework for establishing generalization of networks trained in the 'NTK regime' with structured data. The proof makes heavy use of martingale concentration to optimally treat statistical dependencies across layers of the initial random network. This approach should be of use in establishing similar results for other network architectures.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "深度网络与多重流形问题",
        "摘要翻译": "我们研究多重流形问题，这是一个基于机器视觉应用建模的二元分类任务，其中一个深度全连接神经网络被训练来分离单位球面的两个低维子流形。我们提供了对一维情况的分析，证明对于一个简单的流形配置，当网络深度L相对于数据的某些几何和统计属性较大时，网络宽度n以L中的一个足够大的多项式增长，并且来自流形的i.i.d.样本的数量是L中的多项式，随机初始化的梯度下降能够以高概率快速学习完美地分类这两个流形。我们的分析展示了在实际驱动的模型问题中深度和宽度的具体好处：深度充当拟合资源，更大的深度对应于可以更容易分离类流形的更平滑的网络，而宽度充当统计资源，使随机初始化的网络及其梯度能够集中。该论点围绕Jacot等人提出的“神经正切核”及其在过度参数化神经网络训练的非渐近分析中的作用展开；对于该文献，我们贡献了深度全连接ReLU网络的神经正切核的本质上最优的集中率，需要宽度n ≥ L*poly(d0)才能实现初始核在单位球面S^(n0-1)的d0维子流形上的均匀集中，以及一个用于建立在具有结构化数据的“NTK机制”中训练的网络泛化的非渐近框架。该证明大量使用鞅集中来优化处理初始随机网络各层之间的统计依赖性。这种方法应该有助于为其他网络架构建立类似的结果。",
        "领域": "流形学习, 神经网络优化, 泛化理论",
        "问题": "如何有效地训练深度神经网络来区分嵌入在高维空间中的多个低维流形。",
        "动机": "理解深度神经网络在处理具有特定几何结构的实际问题（如机器视觉中的多重流形问题）时的优势和局限性，并为深度学习的理论分析提供更实际的视角。",
        "方法": "通过对一维情况进行分析，证明在一定条件下，深度和宽度对神经网络的训练具有积极作用。使用神经正切核（NTK）理论分析网络的训练过程，并利用鞅集中不等式处理网络层之间的统计依赖性。",
        "关键词": [
            "多重流形",
            "深度神经网络",
            "神经正切核",
            "梯度下降",
            "泛化能力"
        ],
        "涉及的技术概念": {
            "神经正切核 (NTK)": "用于分析过度参数化神经网络训练行为的工具，通过研究NTK的性质来推断网络的收敛速度和泛化能力。",
            "流形学习": "一种非线性降维方法，用于发现高维数据中隐藏的低维流形结构。在本论文中，它用于描述数据所处的几何空间。"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 175,
        "title": "Deep Neural Network Fingerprinting by Conferrable Adversarial Examples",
        "html": "https://iclr.cc//virtual/2021/poster/2859",
        "abstract": "In Machine Learning as a Service, a provider trains a deep neural network and gives many users access. The hosted (source) model is susceptible to model stealing attacks, where an adversary derives a surrogate model from API access to the source model. For post hoc detection of such attacks, the provider needs a robust method to determine whether a suspect model is a surrogate of their model. We propose a fingerprinting method for deep neural network classifiers that extracts a set of inputs from the source model so that only surrogates agree with the source model on the classification of such inputs. These inputs are a subclass of transferable adversarial examples which we call conferrable adversarial examples that exclusively transfer with a target label from a source model to its surrogates. We propose a new method to generate these conferrable adversarial examples. We present an extensive study on the irremovability of our fingerprint against fine-tuning, weight pruning, retraining, retraining with different architectures, three model extraction attacks from related work, transfer learning, adversarial training, and two new adaptive attacks. Our fingerprint is robust against distillation, related model extraction attacks, and even transfer learning when the attacker has no access to the model provider's dataset. Our fingerprint is the first method that reaches a ROC AUC of 1.0 in verifying surrogates, compared to a ROC AUC of 0.63 by previous fingerprints. ",
        "conference": "ICLR",
        "中文标题": "通过可传递对抗样本进行深度神经网络指纹识别",
        "摘要翻译": "在机器学习即服务中，提供商训练一个深度神经网络并为许多用户提供访问权限。托管的（源）模型容易受到模型窃取攻击，攻击者通过API访问源模型来推导出一个替代模型。为了事后检测此类攻击，提供商需要一个稳健的方法来确定可疑模型是否是其模型的替代品。我们提出了一种深度神经网络分类器的指纹识别方法，该方法从源模型中提取一组输入，使得只有替代模型在这些输入的分类上与源模型一致。这些输入是可转移对抗样本的一个子类，我们称之为可传递对抗样本，它们专门以目标标签从源模型转移到其替代模型。我们提出了一种新方法来生成这些可传递对抗样本。我们对我们的指纹在微调、权重剪枝、重新训练、使用不同架构重新训练、相关工作提出的三种模型提取攻击、迁移学习、对抗训练以及两种新的自适应攻击下的不可移除性进行了广泛研究。我们的指纹对于蒸馏、相关模型提取攻击、甚至在攻击者无法访问模型提供商数据集时的迁移学习都是稳健的。与之前指纹的ROC AUC为0.63相比，我们的指纹是第一个在验证替代模型时ROC AUC达到1.0的方法。",
        "领域": "模型安全、对抗样本、深度学习安全",
        "问题": "如何有效识别和验证深度神经网络模型是否被窃取或替代",
        "动机": "为了解决机器学习即服务中模型被窃取或替代的安全问题，提供一种有效的指纹识别方法",
        "方法": "提出了一种基于可传递对抗样本的指纹识别方法，通过生成特定的对抗样本来验证模型是否为源模型的替代品",
        "关键词": [
            "深度神经网络",
            "指纹识别",
            "对抗样本",
            "模型安全",
            "机器学习即服务"
        ],
        "涉及的技术概念": {
            "可传递对抗样本": "专门设计的一类对抗样本，能够以目标标签从源模型转移到其替代模型，用于指纹识别",
            "ROC AUC": "接收者操作特征曲线下的面积，用于评估指纹识别方法的性能",
            "模型提取攻击": "攻击者通过API访问源模型来推导出替代模型的攻击方式"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 176,
        "title": "Deep Neural Tangent Kernel and Laplace Kernel Have the Same RKHS",
        "html": "https://iclr.cc//virtual/2021/poster/2680",
        "abstract": "We prove that the reproducing kernel Hilbert spaces (RKHS) of a deep neural tangent kernel and the Laplace kernel include the same set of functions, when both kernels are restricted to the sphere $\\mathbb{S}^{d-1}$. Additionally, we prove that the exponential power kernel with a smaller power (making the kernel less smooth) leads to a larger RKHS, when it is restricted to the sphere $\\mathbb{S}^{d-1}$ and when it is defined on the entire $\\mathbb{R}^d$.",
        "conference": "ICLR",
        "中文标题": "深度神经正切核与拉普拉斯核具有相同的再生核希尔伯特空间",
        "摘要翻译": "我们证明了深度神经正切核和拉普拉斯核的再生核希尔伯特空间（RKHS）在两者都被限制在球面𝕊^{d-1}上时包含相同的函数集。此外，我们还证明了当指数幂核被限制在球面𝕊^{d-1}上以及定义在整个ℝ^d上时，较小的幂（使核不那么平滑）会导致更大的RKHS。",
        "领域": "核方法、深度学习理论、函数空间分析",
        "问题": "探讨深度神经正切核与拉普拉斯核在特定条件下的函数空间等价性，以及指数幂核的平滑度对RKHS大小的影响。",
        "动机": "理解不同核函数在特定条件下的性质差异，为深度学习模型的理论分析提供新的视角。",
        "方法": "通过数学证明，比较深度神经正切核和拉普拉斯核在球面上的RKHS，以及分析指数幂核的平滑度与RKHS大小的关系。",
        "关键词": [
            "深度神经正切核",
            "拉普拉斯核",
            "再生核希尔伯特空间",
            "指数幂核",
            "函数空间"
        ],
        "涉及的技术概念": {
            "再生核希尔伯特空间（RKHS）": "用于描述核函数对应的函数空间，是核方法理论中的核心概念。",
            "深度神经正切核": "一种与深度神经网络训练动态相关的核函数，用于理论分析神经网络的泛化行为。",
            "指数幂核": "一类灵活的核函数，其平滑度可通过调整幂次来控制，影响模型的表达能力。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 177,
        "title": "Deep Partition Aggregation: Provable Defenses against General Poisoning Attacks",
        "html": "https://iclr.cc//virtual/2021/poster/2867",
        "abstract": "Adversarial poisoning attacks distort training data in order to corrupt the test-time behavior of a classifier. A provable defense provides a certificate for each test sample, which is a lower bound on the magnitude of any adversarial distortion of the training set that can corrupt the test sample's classification.\nWe propose two novel provable defenses against poisoning attacks: (i) Deep Partition Aggregation (DPA), a certified defense against a general poisoning threat model, defined as the insertion or deletion of a bounded number of samples to the training set --- by implication, this threat model also includes arbitrary distortions to a bounded number of images and/or labels; and (ii) Semi-Supervised DPA (SS-DPA), a certified defense against label-flipping poisoning attacks. DPA is an ensemble method where base models are trained on partitions of the training set determined by a hash function. DPA is related to both subset aggregation, a well-studied ensemble method in classical machine learning, as well as to randomized smoothing, a popular provable defense against evasion (inference) attacks. Our defense against label-flipping poison attacks, SS-DPA, uses a semi-supervised learning algorithm as its base classifier model: each base classifier is trained using the entire unlabeled training set in addition to the labels for a partition. SS-DPA significantly outperforms the existing certified defense for label-flipping attacks (Rosenfeld et al., 2020) on both MNIST and CIFAR-10: provably tolerating, for at least half of test images, over 600 label flips (vs. < 200 label flips) on MNIST and over 300 label flips (vs. 175 label flips) on CIFAR-10. Against general poisoning attacks where no prior certified defenses exists, DPA can certify $\\geq$ 50% of test images against over 500 poison image insertions on MNIST, and nine insertions on CIFAR-10. These results establish new state-of-the-art provable defenses against general and label-flipping poison attacks. Code is available at https://github.com/alevine0/DPA",
        "conference": "ICLR",
        "中文标题": "深度分区聚合：针对通用投毒攻击的可证明防御",
        "摘要翻译": "对抗性投毒攻击通过扭曲训练数据来破坏分类器在测试时的行为。可证明防御为每个测试样本提供一个证书，该证书是对训练集任何可能导致测试样本分类错误的对抗性扭曲幅度的下限。我们提出了两种针对投毒攻击的新型可证明防御：（i）深度分区聚合（DPA），一种针对通用投毒威胁模型的可证明防御，该模型定义为向训练集中插入或删除有限数量的样本——这意味着该威胁模型还包括对有限数量的图像和/或标签的任意扭曲；（ii）半监督DPA（SS-DPA），一种针对标签翻转投毒攻击的可证明防御。DPA是一种集成方法，其中基础模型在由哈希函数确定的训练集分区上进行训练。DPA与子集聚合（经典机器学习中一种经过充分研究的集成方法）以及随机平滑（一种流行的针对逃避（推理）攻击的可证明防御）相关。我们针对标签翻转投毒攻击的防御SS-DPA，使用半监督学习算法作为其基础分类器模型：每个基础分类器除了使用分区的标签外，还使用整个未标记的训练集进行训练。SS-DPA在MNIST和CIFAR-10上显著优于现有的针对标签翻转攻击的可证明防御（Rosenfeld等人，2020）：对于至少一半的测试图像，可证明容忍超过600次标签翻转（对比<200次标签翻转）在MNIST上，以及超过300次标签翻转（对比175次标签翻转）在CIFAR-10上。针对尚无现有可证明防御的通用投毒攻击，DPA可以为MNIST上超过500次毒图像插入和CIFAR-10上九次插入的≥50%测试图像提供证明。这些结果确立了针对通用和标签翻转投毒攻击的最新可证明防御。代码可在https://github.com/alevine0/DPA获取。",
        "领域": "对抗性机器学习、深度学习安全、图像分类",
        "问题": "如何提供可证明的防御机制来对抗训练数据投毒攻击，包括通用投毒和标签翻转攻击。",
        "动机": "现有的防御方法无法为对抗性投毒攻击提供可证明的安全保证，特别是在通用投毒和标签翻转攻击场景下。",
        "方法": "提出了深度分区聚合（DPA）和半监督DPA（SS-DPA）两种方法，通过集成学习和半监督学习技术，为对抗性投毒攻击提供可证明的防御。",
        "关键词": [
            "对抗性投毒攻击",
            "可证明防御",
            "深度分区聚合",
            "半监督学习",
            "集成方法"
        ],
        "涉及的技术概念": {
            "深度分区聚合（DPA）": "一种集成方法，通过哈希函数将训练集分区，并在每个分区上训练基础模型，以提供对通用投毒攻击的可证明防御。",
            "半监督DPA（SS-DPA）": "利用半监督学习算法作为基础分类器模型，结合整个未标记训练集和分区标签，针对标签翻转投毒攻击提供可证明防御。",
            "随机平滑": "一种流行的可证明防御技术，用于对抗逃避（推理）攻击，DPA方法中借鉴了其思想。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 178,
        "title": "Deep Repulsive Clustering of Ordered Data Based on Order-Identity Decomposition",
        "html": "https://iclr.cc//virtual/2021/poster/3134",
        "abstract": "We propose the deep repulsive clustering (DRC) algorithm of ordered data for effective order learning. First, we develop the order-identity decomposition (ORID) network to divide the information of an object instance into an order-related feature and an identity feature. Then, we group object instances into clusters according to their identity features using a repulsive term. Moreover, we estimate the rank of a test instance, by comparing it with references within the same cluster. Experimental results on facial age estimation, aesthetic score regression, and historical color image classification show that the proposed algorithm can cluster ordered data effectively and also yield excellent rank estimation performance.",
        "conference": "ICLR",
        "中文标题": "基于顺序-身份分解的有序数据深度排斥聚类",
        "摘要翻译": "我们提出了用于有效顺序学习的有序数据深度排斥聚类（DRC）算法。首先，我们开发了顺序-身份分解（ORID）网络，将对象实例的信息分为顺序相关特征和身份特征。然后，我们使用排斥项根据对象的身份特征将其分组到聚类中。此外，我们通过将测试实例与同一聚类内的参考实例进行比较来估计其排名。在面部年龄估计、美学评分回归和历史彩色图像分类上的实验结果表明，所提出的算法能够有效地聚类有序数据，并且还能产生优异的排名估计性能。",
        "领域": "人脸年龄估计, 美学评分回归, 历史图像分类",
        "问题": "如何有效地聚类有序数据并估计其排名",
        "动机": "为了解决有序数据聚类和排名估计的问题，提高相关应用的性能",
        "方法": "开发顺序-身份分解网络分离特征，使用排斥项进行聚类，并通过比较同一聚类内的实例进行排名估计",
        "关键词": [
            "深度排斥聚类",
            "顺序-身份分解",
            "有序数据",
            "排名估计",
            "特征分离"
        ],
        "涉及的技术概念": {
            "顺序-身份分解（ORID）网络": "用于将对象实例的信息分解为顺序相关特征和身份特征，以便于后续的聚类和排名估计",
            "排斥项": "在聚类过程中使用，以确保不同聚类的身份特征之间有足够的区分度",
            "排名估计": "通过比较测试实例与同一聚类内的参考实例来估计其顺序或排名"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 179,
        "title": "Deep symbolic regression: Recovering mathematical expressions from data via risk-seeking policy gradients",
        "html": "https://iclr.cc//virtual/2021/poster/2578",
        "abstract": "Discovering the underlying mathematical expressions describing a dataset is a core challenge for artificial intelligence. This is the problem of $\\textit{symbolic regression}$. Despite recent advances in training neural networks to solve complex tasks, deep learning approaches to symbolic regression are underexplored. We propose a framework that leverages deep learning for symbolic regression via a simple idea: use a large model to search the space of small models. Specifically, we use a recurrent neural network to emit a distribution over tractable mathematical expressions and employ a novel risk-seeking policy gradient to train the network to generate better-fitting expressions. Our algorithm outperforms several baseline methods (including Eureqa, the gold standard for symbolic regression) in its ability to exactly recover symbolic expressions on a series of benchmark problems, both with and without added noise. More broadly, our contributions include a framework that can be applied to optimize hierarchical, variable-length objects under a black-box performance metric, with the ability to incorporate constraints in situ, and a risk-seeking policy gradient formulation that optimizes for best-case performance instead of expected performance.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "深度符号回归：通过风险寻求策略梯度从数据中恢复数学表达式",
        "摘要翻译": "发现描述数据集的基础数学表达式是人工智能的核心挑战之一，这就是所谓的符号回归问题。尽管最近在训练神经网络解决复杂任务方面取得了进展，但深度学习方法在符号回归领域的应用仍显不足。我们提出了一个框架，通过一个简单的想法利用深度学习进行符号回归：使用一个大模型来搜索小模型的空间。具体来说，我们使用循环神经网络来发射一个可处理的数学表达式的分布，并采用一种新颖的风险寻求策略梯度来训练网络，以生成拟合度更高的表达式。我们的算法在一系列基准问题上（包括添加噪声和不添加噪声的情况）精确恢复符号表达式的能力上优于几种基线方法（包括符号回归的黄金标准Eureqa）。更广泛地说，我们的贡献包括一个可以应用于优化层次化、可变长度对象在黑色箱性能度量下的框架，具有在适当位置纳入约束的能力，以及一个风险寻求策略梯度公式，该公式优化了最佳情况性能而非期望性能。",
        "领域": "符号回归、深度学习、数学表达式发现",
        "问题": "如何从数据中准确恢复描述其基础规律的数学表达式",
        "动机": "解决符号回归问题，即从数据中发现基础数学表达式，是人工智能领域的一个核心挑战。尽管深度学习在多个领域取得了成功，但在符号回归方面的应用仍有待探索。",
        "方法": "提出了一种利用深度学习进行符号回归的框架，通过使用循环神经网络生成数学表达式的分布，并采用风险寻求策略梯度来优化这些表达式，以提高其拟合度。",
        "关键词": [
            "符号回归",
            "深度学习",
            "风险寻求策略梯度",
            "数学表达式发现",
            "循环神经网络"
        ],
        "涉及的技术概念": {
            "符号回归": "从数据中发现描述其基础规律的数学表达式的问题",
            "风险寻求策略梯度": "一种优化方法，旨在优化最佳情况性能而非期望性能，用于训练网络生成更好的数学表达式",
            "循环神经网络": "用于生成可处理的数学表达式分布的网络结构，是本框架中生成数学表达式的核心组件"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 180,
        "title": "Deformable DETR: Deformable Transformers for End-to-End Object Detection",
        "html": "https://iclr.cc//virtual/2021/poster/3105",
        "abstract": "DETR has been recently proposed to eliminate the need for many hand-designed components in object detection while demonstrating good performance. However, it suffers from slow convergence and limited feature spatial resolution, due to the limitation of Transformer attention modules in processing image feature maps. To mitigate these issues, we proposed Deformable DETR, whose attention modules only attend to a small set of key sampling points around a reference. Deformable DETR can achieve better performance than DETR (especially on small objects) with 10$\\times$ less training epochs. Extensive experiments on the COCO benchmark demonstrate the effectiveness of our approach. Code is released at https://github.com/fundamentalvision/Deformable-DETR.",
        "conference": "ICLR",
        "中文标题": "可变形DETR：用于端到端目标检测的可变形Transformer",
        "摘要翻译": "DETR最近被提出，旨在消除目标检测中许多手工设计组件的需求，同时展示出良好的性能。然而，由于Transformer注意力模块在处理图像特征图时的限制，它存在收敛速度慢和特征空间分辨率有限的问题。为了缓解这些问题，我们提出了可变形DETR，其注意力模块仅关注参考点周围的一小部分关键采样点。可变形DETR能够在训练周期减少10倍的情况下，实现比DETR更好的性能（特别是在小物体上）。在COCO基准上的大量实验证明了我们方法的有效性。代码已在https://github.com/fundamentalvision/Deformable-DETR发布。",
        "领域": "目标检测",
        "问题": "解决DETR在目标检测中收敛速度慢和特征空间分辨率有限的问题",
        "动机": "提高目标检测模型的性能，特别是在小物体检测上，同时减少训练周期",
        "方法": "提出可变形DETR，通过使注意力模块仅关注参考点周围的一小部分关键采样点，来优化Transformer注意力模块的处理效率",
        "关键词": [
            "可变形DETR",
            "目标检测",
            "Transformer",
            "端到端学习",
            "小物体检测"
        ],
        "涉及的技术概念": {
            "可变形DETR": "一种改进的DETR模型，通过可变形注意力机制提高模型对小物体的检测性能和训练效率",
            "Transformer注意力模块": "用于处理图像特征图的核心组件，但在原始DETR中存在收敛慢和分辨率限制的问题",
            "端到端学习": "直接从输入到输出进行学习的方法，无需手工设计复杂的组件，简化了目标检测流程"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 181,
        "title": "Degree-Quant: Quantization-Aware Training for Graph Neural Networks",
        "html": "https://iclr.cc//virtual/2021/poster/2990",
        "abstract": "Graph neural networks (GNNs) have demonstrated strong performance on a wide variety of tasks due to their ability to model non-uniform structured data. Despite their promise, there exists little research exploring methods to make them more efficient at inference time. In this work, we explore the viability of training quantized GNNs, enabling the usage of low precision integer arithmetic during inference. For GNNs seemingly unimportant choices in quantization implementation cause dramatic changes in performance. We identify the sources of error that uniquely arise when attempting to quantize GNNs, and propose an architecturally-agnostic and stable method, Degree-Quant, to improve performance over existing quantization-aware training baselines commonly used on other architectures, such as CNNs. We validate our method on six datasets and show, unlike previous quantization attempts, that models generalize to unseen graphs. Models trained with Degree-Quant for INT8 quantization perform as well as FP32 models in most cases; for INT4 models, we obtain up to 26% gains over the baselines. Our work enables up to 4.7x speedups on CPU when using INT8 arithmetic.",
        "conference": "ICLR",
        "中文标题": "Degree-Quant：图神经网络的量化感知训练",
        "摘要翻译": "图神经网络（GNNs）因其能够建模非均匀结构化数据而在各种任务中表现出强大的性能。尽管前景广阔，但关于如何使它们在推理时更加高效的研究却很少。在这项工作中，我们探索了训练量化GNNs的可行性，使得在推理时能够使用低精度整数运算。对于GNNs来说，量化实现中看似不重要的选择会导致性能的显著变化。我们识别了在尝试量化GNNs时独特出现的误差来源，并提出了一种架构无关且稳定的方法——Degree-Quant，以提高性能，超越常用于其他架构（如CNNs）的现有量化感知训练基线。我们在六个数据集上验证了我们的方法，并显示，与之前的量化尝试不同，模型能够泛化到未见过的图。使用Degree-Quant进行INT8量化的模型在大多数情况下表现得与FP32模型一样好；对于INT4模型，我们比基线获得了高达26%的提升。我们的工作在使用INT8运算时，在CPU上实现了高达4.7倍的加速。",
        "领域": "图神经网络、模型量化、高效推理",
        "问题": "如何提高图神经网络在推理时的效率，特别是在使用低精度整数运算时保持或提升模型性能。",
        "动机": "探索量化图神经网络的可行性，以实现在推理时使用低精度整数运算，从而提高效率。",
        "方法": "提出了一种名为Degree-Quant的架构无关且稳定的方法，用于改进图神经网络的量化感知训练，识别并解决了量化过程中特有的误差来源。",
        "关键词": [
            "图神经网络",
            "模型量化",
            "量化感知训练",
            "高效推理",
            "低精度运算"
        ],
        "涉及的技术概念": {
            "量化感知训练": "一种在训练过程中考虑量化影响的技术，旨在优化模型以便在量化后仍能保持高性能。",
            "INT8/INT4量化": "将模型权重和激活值量化为8位或4位整数的过程，以减少模型大小和加速推理。",
            "架构无关方法": "一种不依赖于特定神经网络架构的技术，可以广泛应用于不同类型的网络结构。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 182,
        "title": "DeLighT: Deep and Light-weight Transformer",
        "html": "https://iclr.cc//virtual/2021/poster/2739",
        "abstract": "We introduce a deep and light-weight transformer, DeLighT, that delivers similar or better performance than standard transformer-based models with significantly fewer parameters. DeLighT more efficiently allocates parameters both (1) within each Transformer block using the DeLighT transformation, a deep and light-weight transformation and (2) across blocks using block-wise scaling, that allows for shallower and narrower DeLighT blocks near the input and wider and deeper DeLighT blocks near the output. Overall, DeLighT networks are 2.5 to 4 times deeper than standard transformer models and yet have fewer parameters and operations. Experiments on benchmark machine translation and language modeling tasks show that DeLighT matches or improves the performance of baseline Transformers with 2 to 3 times fewer parameters on average. ",
        "conference": "ICLR",
        "中文标题": "DeLighT：深度轻量级Transformer",
        "摘要翻译": "我们介绍了一种深度轻量级的Transformer模型——DeLighT，它在参数数量显著减少的情况下，提供了与标准基于Transformer的模型相似或更好的性能。DeLighT通过（1）在每个Transformer块内部使用DeLighT变换，一种深度轻量级的变换，以及（2）通过块间缩放跨块分配参数，使得靠近输入的DeLighT块更浅更窄，靠近输出的DeLighT块更深更宽，从而更高效地分配参数。总体而言，DeLighT网络比标准Transformer模型深2.5到4倍，但参数和操作数量更少。在基准机器翻译和语言建模任务上的实验表明，DeLighT平均使用2到3倍少的参数，就能匹配或超越基线Transformer的性能。",
        "领域": "自然语言处理与视觉结合",
        "问题": "如何在减少参数数量的同时，保持或提升Transformer模型的性能",
        "动机": "为了解决标准Transformer模型参数过多、计算资源消耗大的问题，提出一种更高效的参数分配方法",
        "方法": "采用DeLighT变换和块间缩放技术，优化Transformer块的参数分配，实现模型的深度和轻量化",
        "关键词": [
            "轻量级Transformer",
            "参数效率",
            "机器翻译",
            "语言建模",
            "模型优化"
        ],
        "涉及的技术概念": {
            "DeLighT变换": "一种深度轻量级的变换，用于在每个Transformer块内部高效分配参数",
            "块间缩放": "一种技术，允许模型在不同深度和宽度的块间动态调整参数分配",
            "Transformer模型": "一种基于自注意力机制的深度学习模型，广泛应用于自然语言处理任务"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 183,
        "title": "Denoising Diffusion Implicit Models",
        "html": "https://iclr.cc//virtual/2021/poster/2804",
        "abstract": "Denoising diffusion probabilistic models (DDPMs) have achieved high quality image generation without adversarial training, yet they require simulating a Markov chain for many steps in order to produce a sample. To accelerate sampling, we present denoising diffusion implicit models (DDIMs), a more efficient class of iterative implicit probabilistic models with the same training procedure as DDPMs. In DDPMs, the generative process is defined as the reverse of a particular Markovian diffusion process. We generalize DDPMs via a class of non-Markovian diffusion processes that lead to the same training objective. These non-Markovian processes can correspond to generative processes that are deterministic, giving rise to implicit models that produce high quality samples much faster. We empirically demonstrate that DDIMs can produce high quality samples $10 \\times$ to $50 \\times$ faster in terms of wall-clock time compared to DDPMs, allow us to trade off computation for sample quality, perform semantically meaningful image interpolation directly in the latent space, and reconstruct observations with very low error. ",
        "conference": "ICLR",
        "中文标题": "去噪扩散隐式模型",
        "摘要翻译": "去噪扩散概率模型（DDPMs）在不进行对抗训练的情况下实现了高质量的图像生成，但它们需要模拟马尔可夫链多步以产生样本。为了加速采样，我们提出了去噪扩散隐式模型（DDIMs），这是一类更高效的迭代隐式概率模型，其训练过程与DDPMs相同。在DDPMs中，生成过程被定义为特定马尔可夫扩散过程的逆过程。我们通过一类导致相同训练目标的非马尔可夫扩散过程来推广DDPMs。这些非马尔可夫过程可以对应于确定性的生成过程，从而产生能够更快生成高质量样本的隐式模型。我们实证表明，DDIMs可以比DDPMs在壁钟时间上快10倍到50倍地生成高质量样本，允许我们在计算和样本质量之间进行权衡，直接在潜在空间中执行语义上有意义的图像插值，并以非常低的误差重建观测。",
        "领域": "图像生成、深度学习优化、概率模型",
        "问题": "加速去噪扩散概率模型的采样过程",
        "动机": "提高图像生成效率，减少高质量样本生成所需的时间",
        "方法": "提出去噪扩散隐式模型（DDIMs），通过非马尔可夫扩散过程推广DDPMs，实现更高效的采样",
        "关键词": [
            "去噪扩散模型",
            "隐式概率模型",
            "图像生成加速",
            "非马尔可夫过程",
            "潜在空间插值"
        ],
        "涉及的技术概念": {
            "去噪扩散概率模型（DDPMs）": "一种不依赖对抗训练的高质量图像生成模型，通过模拟马尔可夫链多步生成样本",
            "非马尔可夫扩散过程": "在DDIMs中用于推广DDPMs的过程，允许更高效的样本生成",
            "潜在空间插值": "在DDIMs中直接在潜在空间进行图像插值，实现语义上有意义的图像变换"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 184,
        "title": "Deployment-Efficient Reinforcement Learning via Model-Based Offline Optimization",
        "html": "https://iclr.cc//virtual/2021/poster/3081",
        "abstract": "Most reinforcement learning (RL) algorithms assume online access to the environment, in which one may readily interleave updates to the policy with experience collection using that policy. However, in many real-world applications such as health, education, dialogue agents, and robotics, the cost or potential risk of deploying a new data-collection policy is high, to the point that it can become prohibitive to update the data-collection policy more than a few times during learning. With this view, we propose a novel concept of deployment efficiency, measuring the number of distinct data-collection policies that are used during policy learning. We observe that naïvely applying existing model-free offline RL algorithms recursively does not lead to a practical deployment-efficient and sample-efficient algorithm. We propose a novel model-based algorithm, Behavior-Regularized Model-ENsemble (BREMEN), that not only performs better than or comparably as the state-of-the-art dynamic-programming-based and concurrently-proposed model-based offline approaches on existing benchmarks, but can also effectively optimize a policy offline using 10-20 times fewer data than prior works. Furthermore, the recursive application of BREMEN achieves impressive deployment efficiency while maintaining the same or better sample efficiency, learning successful policies from scratch on simulated robotic environments with only 5-10 deployments, compared to typical values of hundreds to millions in standard RL baselines.",
        "conference": "ICLR",
        "中文标题": "基于模型离线优化的部署高效强化学习",
        "摘要翻译": "大多数强化学习（RL）算法假设可以在线访问环境，其中可以随时将策略的更新与使用该策略的经验收集交替进行。然而，在许多现实世界的应用中，如健康、教育、对话代理和机器人技术，部署新的数据收集策略的成本或潜在风险很高，以至于在学习过程中更新数据收集策略的次数可能变得非常有限。基于这一观点，我们提出了一个新颖的部署效率概念，用于衡量在策略学习过程中使用的不同数据收集策略的数量。我们观察到，简单地递归应用现有的无模型离线RL算法并不能产生一个实际部署高效且样本高效的算法。我们提出了一种新颖的基于模型的算法，行为正则化模型集成（BREMEN），该算法不仅在现有基准测试中表现优于或与最先进的基于动态规划和同时提出的基于模型的离线方法相当，而且可以使用比先前工作少10-20倍的数据离线优化策略。此外，BREMEN的递归应用在保持相同或更好的样本效率的同时，实现了令人印象深刻的部署效率，在模拟机器人环境中仅用5-10次部署就从零开始学习成功的策略，而标准RL基线中的典型值为数百到数百万次。",
        "领域": "强化学习、机器人学习、离线优化",
        "问题": "解决在现实世界应用中部署新数据收集策略成本高、风险大的问题，提高强化学习的部署效率和样本效率。",
        "动机": "在健康、教育、对话代理和机器人技术等领域，频繁更新数据收集策略的成本和风险限制了强化学习的应用，因此需要开发部署高效和样本高效的算法。",
        "方法": "提出了一种基于模型的算法BREMEN，通过行为正则化和模型集成技术，实现了在少量部署次数下高效学习策略。",
        "关键词": [
            "部署效率",
            "样本效率",
            "离线强化学习",
            "模型集成",
            "行为正则化"
        ],
        "涉及的技术概念": {
            "部署效率": "衡量在策略学习过程中使用的不同数据收集策略的数量，旨在减少实际部署次数。",
            "行为正则化": "在模型训练中引入正则化项，以防止策略偏离行为策略太远，保持策略的稳定性。",
            "模型集成": "通过集成多个模型来减少预测的不确定性，提高离线策略优化的准确性和鲁棒性。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 185,
        "title": "DialoGraph: Incorporating Interpretable Strategy-Graph Networks into Negotiation Dialogues",
        "html": "https://iclr.cc//virtual/2021/poster/2701",
        "abstract": "To successfully negotiate a deal, it is not enough to communicate fluently: pragmatic planning of persuasive negotiation strategies is essential. While modern dialogue agents excel at generating fluent sentences, they still lack pragmatic grounding and cannot reason strategically. We present DialoGraph, a negotiation system that incorporates pragmatic strategies in a negotiation dialogue using graph neural networks. DialoGraph explicitly incorporates dependencies between sequences of strategies to enable improved and interpretable prediction of next optimal strategies, given the dialogue context. Our graph-based method outperforms prior state-of-the-art negotiation models both in the accuracy of strategy/dialogue act prediction and in the quality of downstream dialogue response generation. We qualitatively show further benefits of learned strategy-graphs in providing explicit associations between effective negotiation strategies over the course of the dialogue, leading to interpretable and strategic dialogues.",
        "conference": "ICLR",
        "中文标题": "DialoGraph：将可解释的策略图网络融入谈判对话",
        "摘要翻译": "为了成功谈判达成协议，仅流畅交流是不够的：有说服力的谈判策略的实用规划至关重要。虽然现代对话代理在生成流畅句子方面表现出色，但它们仍然缺乏实用基础，无法进行战略性推理。我们提出了DialoGraph，一个利用图神经网络在谈判对话中融入实用策略的谈判系统。DialoGraph明确地结合了策略序列之间的依赖关系，以实现在给定对话上下文的情况下，改进并可解释地预测下一个最优策略。我们的基于图的方法在策略/对话行为预测的准确性和下游对话响应生成的质量上均优于先前的最先进谈判模型。我们定性地展示了学习到的策略图在对话过程中提供有效谈判策略之间明确关联的进一步好处，从而产生可解释和战略性的对话。",
        "领域": "对话系统、图神经网络、谈判策略",
        "问题": "现代对话代理缺乏实用基础和战略性推理能力，无法有效规划和预测谈判策略。",
        "动机": "提升对话代理在谈判对话中的实用性和战略性推理能力，使其能够规划和预测有效的谈判策略。",
        "方法": "利用图神经网络明确结合策略序列之间的依赖关系，改进并可解释地预测下一个最优策略。",
        "关键词": [
            "谈判对话",
            "图神经网络",
            "策略预测",
            "对话系统",
            "可解释性"
        ],
        "涉及的技术概念": {
            "图神经网络": "用于建模和预测谈判策略之间的复杂依赖关系，提升策略预测的准确性和对话的实用性。",
            "策略预测": "基于对话上下文和历史策略，预测下一个最优谈判策略，以指导对话代理的响应生成。",
            "可解释性": "通过策略图明确展示策略之间的关联，使对话代理的决策过程更加透明和可理解。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 186,
        "title": "DICE: Diversity in Deep Ensembles via Conditional Redundancy Adversarial Estimation",
        "html": "https://iclr.cc//virtual/2021/poster/2650",
        "abstract": "Deep ensembles perform better than a single network thanks to the diversity among their members. Recent approaches regularize predictions to increase diversity; however, they also drastically decrease individual members’ performances. In this paper, we argue that learning strategies for deep ensembles need to tackle the trade-off between ensemble diversity and individual accuracies. Motivated by arguments from information theory and leveraging recent advances in neural estimation of conditional mutual information, we introduce a novel training criterion called DICE: it increases diversity by reducing spurious correlations among features. The main idea is that features extracted from pairs of members should only share information useful for target class prediction without being conditionally redundant. Therefore, besides the classification loss with information bottleneck, we adversarially prevent features from being conditionally predictable from each other. We manage to reduce simultaneous errors while protecting class information. We obtain state-of-the-art accuracy results on CIFAR-10/100: for example, an ensemble of 5 networks trained with DICE matches an ensemble of 7 networks trained independently. We further analyze the consequences on calibration, uncertainty estimation, out-of-distribution detection and online co-distillation.",
        "conference": "ICLR",
        "中文标题": "DICE：通过条件冗余对抗估计实现深度集成中的多样性",
        "摘要翻译": "深度集成由于其成员间的多样性而表现优于单一网络。最近的方法通过正则化预测来增加多样性；然而，这也会显著降低单个成员的性能。在本文中，我们认为深度集成的学习策略需要解决集成多样性与个体准确性之间的权衡。受信息论观点的启发，并利用条件互信息神经估计的最新进展，我们引入了一种名为DICE的新训练标准：它通过减少特征间的虚假相关性来增加多样性。主要思想是，从成员对中提取的特征应仅共享对目标类别预测有用的信息，而不应存在条件冗余。因此，除了带有信息瓶颈的分类损失外，我们还通过对抗方式防止特征间有条件可预测性。我们设法在保护类别信息的同时减少同时错误。我们在CIFAR-10/100上获得了最先进的准确率结果：例如，使用DICE训练的5个网络集成与独立训练的7个网络集成相匹配。我们进一步分析了校准、不确定性估计、分布外检测和在线共蒸馏的后果。",
        "领域": "深度学习集成方法、计算机视觉、模型校准与不确定性估计",
        "问题": "解决深度集成中多样性增加与个体成员性能下降之间的权衡问题",
        "动机": "通过减少特征间的虚假相关性，增加集成模型的多样性而不牺牲个体准确性",
        "方法": "引入DICE训练标准，结合信息瓶颈和对抗训练，减少特征间的条件冗余",
        "关键词": [
            "深度集成",
            "条件冗余",
            "对抗估计",
            "信息瓶颈",
            "模型多样性"
        ],
        "涉及的技术概念": {
            "条件冗余对抗估计": "通过对抗训练减少特征间的条件冗余，增加集成模型的多样性",
            "信息瓶颈": "在分类损失中应用，保护对目标类别预测有用的信息",
            "深度集成": "通过组合多个网络模型提高整体性能，关键在于成员间的多样性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 187,
        "title": "Differentiable Segmentation of Sequences",
        "html": "https://iclr.cc//virtual/2021/poster/2993",
        "abstract": "Segmented models are widely used to describe non-stationary sequential data with discrete change points. Their estimation usually requires solving a mixed discrete-continuous optimization problem, where the segmentation is the discrete part and all other model parameters are continuous. A number of estimation algorithms have been developed that are highly specialized for their specific model assumptions. The dependence on non-standard algorithms makes it hard to integrate segmented models in state-of-the-art deep learning architectures that critically depend on gradient-based optimization techniques. In this work, we formulate a relaxed variant of segmented models that enables joint estimation of all model parameters, including the segmentation, with gradient descent. We build on recent advances in learning continuous warping functions and propose a novel family of warping functions based on the two-sided power (TSP) distribution. TSP-based warping functions are differentiable, have simple closed-form expressions, and can represent segmentation functions exactly. Our formulation includes the important class of segmented generalized linear models as a special case, which makes it highly versatile. We use our approach to model the spread of COVID-19 with Poisson regression, apply it on a change point detection task, and learn classification models with concept drift. The experiments show that our approach effectively learns all these tasks with standard algorithms for gradient descent.",
        "conference": "ICLR",
        "中文标题": "序列的可微分分割",
        "摘要翻译": "分段模型被广泛用于描述具有离散变化点的非平稳序列数据。其估计通常需要解决一个混合离散-连续优化问题，其中分割是离散部分，而所有其他模型参数是连续的。已经开发了许多高度专门化于其特定模型假设的估计算法。对非标准算法的依赖使得将分段模型集成到严重依赖基于梯度的优化技术的最先进深度学习架构中变得困难。在这项工作中，我们提出了分段模型的一个松弛变体，使得所有模型参数，包括分割，都可以通过梯度下降联合估计。我们基于在学习连续扭曲函数方面的最新进展，提出了一种基于双面幂（TSP）分布的新型扭曲函数家族。基于TSP的扭曲函数是可微分的，具有简单的闭式表达式，并且可以精确表示分割函数。我们的公式包括分段广义线性模型这一重要类别作为特例，这使得它具有高度的通用性。我们使用我们的方法来建模COVID-19的传播与泊松回归，将其应用于变化点检测任务，并学习具有概念漂移的分类模型。实验表明，我们的方法有效地利用标准梯度下降算法学习了所有这些任务。",
        "领域": "序列分割、变化点检测、概念漂移",
        "问题": "如何在深度学习框架中有效地估计分段模型的所有参数，包括分割点，使用基于梯度的优化技术。",
        "动机": "解决分段模型在集成到深度学习架构中时，由于依赖非标准算法而面临的困难。",
        "方法": "提出了一种基于双面幂（TSP）分布的新型可微分扭曲函数家族，使得所有模型参数可以通过梯度下降联合估计。",
        "关键词": [
            "可微分分割",
            "双面幂分布",
            "梯度下降优化",
            "分段广义线性模型",
            "概念漂移"
        ],
        "涉及的技术概念": {
            "可微分分割": "允许通过梯度下降优化分割点，使得分段模型可以集成到深度学习架构中。",
            "双面幂（TSP）分布": "用于构建新型扭曲函数家族，这些函数是可微分的，能够精确表示分割函数。",
            "梯度下降优化": "用于联合估计分段模型的所有参数，包括分割点，使得模型训练更加高效和灵活。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 188,
        "title": "Differentiable Trust Region Layers for Deep Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2021/poster/2985",
        "abstract": "Trust region methods are a popular tool in reinforcement learning as they yield robust policy updates in continuous and discrete action spaces. However, enforcing such trust regions in deep reinforcement learning is difficult. Hence, many approaches, such as Trust Region Policy Optimization (TRPO) and Proximal Policy Optimization (PPO), are based on approximations. Due to those approximations, they violate the constraints or fail to find the optimal solution within the trust region. Moreover, they are difficult to implement, often lack sufficient exploration, and have been shown to depend on seemingly unrelated implementation choices. In this work, we propose differentiable neural network layers to enforce trust regions for deep Gaussian policies via closed-form projections. Unlike existing methods, those layers formalize trust regions for each state individually and can complement existing reinforcement learning algorithms. We derive trust region projections based on the Kullback-Leibler divergence, the Wasserstein L2 distance, and the Frobenius norm for Gaussian distributions. We empirically demonstrate that those projection layers achieve similar or better results than existing methods while being almost agnostic to specific implementation choices. The code is available at https://git.io/Jthb0.\n",
        "conference": "ICLR",
        "中文标题": "深度强化学习中的可微分信任区域层",
        "摘要翻译": "信任区域方法是强化学习中的一个流行工具，因为它们能在连续和离散的动作空间中产生稳健的策略更新。然而，在深度强化学习中实施这样的信任区域是困难的。因此，许多方法，如信任区域策略优化（TRPO）和近端策略优化（PPO），都是基于近似。由于这些近似，它们要么违反了约束，要么未能在信任区域内找到最优解。此外，它们难以实现，往往缺乏足够的探索，并且已被证明依赖于看似无关的实现选择。在这项工作中，我们提出了可微分的神经网络层，通过闭式投影为深度高斯策略实施信任区域。与现有方法不同，这些层为每个状态单独形式化信任区域，并且可以补充现有的强化学习算法。我们基于Kullback-Leibler散度、Wasserstein L2距离和高斯分布的Frobenius范数推导了信任区域投影。我们通过实验证明，这些投影层在几乎不依赖于特定实现选择的情况下，实现了与现有方法相似或更好的结果。代码可在https://git.io/Jthb0获取。",
        "领域": "深度强化学习、策略优化、高斯策略",
        "问题": "在深度强化学习中实施信任区域的困难，以及现有方法基于近似导致的问题",
        "动机": "解决现有信任区域方法在深度强化学习中的实施困难，提高策略更新的稳健性和效率",
        "方法": "提出可微分的神经网络层，通过闭式投影为深度高斯策略实施信任区域，基于不同的距离度量推导信任区域投影",
        "关键词": [
            "可微分信任区域层",
            "深度强化学习",
            "高斯策略",
            "策略优化",
            "闭式投影"
        ],
        "涉及的技术概念": {
            "可微分神经网络层": "用于实施信任区域的神经网络层，能够通过闭式投影为每个状态单独形式化信任区域",
            "Kullback-Leibler散度": "用于衡量两个概率分布之间的差异，作为信任区域投影的一种距离度量",
            "Wasserstein L2距离": "另一种距离度量，用于在信任区域投影中衡量分布之间的差异，特别适用于高斯分布"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 189,
        "title": "Differentially Private Learning Needs Better Features (or Much More Data)",
        "html": "https://iclr.cc//virtual/2021/poster/3021",
        "abstract": "We demonstrate that differentially private machine learning has not yet reached its ''AlexNet moment'' on many canonical vision tasks: linear models trained on handcrafted features significantly outperform end-to-end deep neural networks for moderate privacy budgets.\nTo exceed the performance of handcrafted features, we show that private learning requires either much more private data, or access to features learned on public data from a similar domain.\nOur work introduces simple yet strong baselines for differentially private learning that can inform the evaluation of future progress in this area.",
        "conference": "ICLR",
        "中文标题": "差分隐私学习需要更好的特征（或更多数据）",
        "摘要翻译": "我们证明，在许多典型的视觉任务上，差分隐私机器学习尚未达到其'AlexNet时刻'：对于中等隐私预算，基于手工特征训练的线性模型显著优于端到端的深度神经网络。为了超越手工特征的性能，我们展示了隐私学习需要更多的隐私数据，或者需要访问来自相似领域的公共数据学习的特征。我们的工作为差分隐私学习引入了简单而强大的基线，可以为该领域未来进展的评估提供参考。",
        "领域": "隐私保护机器学习、计算机视觉、深度学习",
        "问题": "差分隐私机器学习在典型视觉任务上的性能不足",
        "动机": "探索如何通过改进特征或增加数据量来提升差分隐私机器学习的性能",
        "方法": "比较基于手工特征的线性模型和端到端深度神经网络的性能，提出使用更多隐私数据或公共数据学习特征的方法",
        "关键词": [
            "差分隐私",
            "机器学习",
            "特征学习",
            "隐私预算",
            "视觉任务"
        ],
        "涉及的技术概念": {
            "差分隐私": "在机器学习中保护数据隐私的技术，确保模型训练过程中不泄露个体数据信息",
            "手工特征": "由专家设计的特征提取方法，用于描述数据的特定属性",
            "端到端学习": "直接从原始数据学习到最终输出的深度学习模型，无需手工设计特征"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 190,
        "title": "DiffWave: A Versatile Diffusion Model for Audio Synthesis",
        "html": "https://iclr.cc//virtual/2021/poster/2979",
        "abstract": "In this work, we propose DiffWave, a versatile diffusion probabilistic model for conditional and unconditional waveform generation. The model is non-autoregressive, and converts the white noise signal into structured waveform through a Markov chain with a constant number of steps at synthesis. It is efficiently trained by optimizing a variant of variational bound on the data likelihood. DiffWave produces high-fidelity audios in different waveform generation tasks, including neural vocoding conditioned on mel spectrogram, class-conditional generation, and unconditional generation. We demonstrate that DiffWave matches a strong WaveNet vocoder in terms of speech quality (MOS: 4.44 versus 4.43), while synthesizing orders of magnitude faster. In particular, it significantly outperforms autoregressive and GAN-based waveform models in the challenging unconditional generation task in terms of audio quality and sample diversity from various automatic and human evaluations.",
        "conference": "ICLR",
        "中文标题": "DiffWave：一种用于音频合成的多功能扩散模型",
        "摘要翻译": "在这项工作中，我们提出了DiffWave，一种用于条件和非条件波形生成的多功能扩散概率模型。该模型是非自回归的，通过在合成时具有恒定步数的马尔可夫链将白噪声信号转换为结构化波形。它通过优化数据似然的一个变分边界变体来高效训练。DiffWave在不同的波形生成任务中产生高保真音频，包括基于梅尔频谱图的神经声码、类条件生成和非条件生成。我们证明，DiffWave在语音质量（MOS：4.44对4.43）方面与强大的WaveNet声码器相匹配，同时合成速度快了几个数量级。特别是，在各种自动和人工评估中，它在具有挑战性的非条件生成任务中，在音频质量和样本多样性方面显著优于自回归和基于GAN的波形模型。",
        "领域": "音频合成, 神经声码, 生成模型",
        "问题": "解决高质量音频波形生成的问题，特别是在非条件生成任务中提高音频质量和样本多样性",
        "动机": "开发一种能够高效生成高质量音频的模型，同时解决现有自回归和GAN模型在音频质量和生成速度上的限制",
        "方法": "采用非自回归的扩散概率模型，通过优化数据似然的变分边界变体进行训练，将白噪声转换为结构化波形",
        "关键词": [
            "DiffWave",
            "扩散模型",
            "音频合成",
            "非自回归",
            "高保真音频"
        ],
        "涉及的技术概念": {
            "扩散概率模型": "用于从白噪声生成结构化波形的概率模型，通过马尔可夫链实现",
            "非自回归模型": "在生成过程中不依赖于之前生成的样本，提高了生成速度",
            "变分边界优化": "用于训练模型的方法，通过优化数据似然的变分边界变体来提高模型性能"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 191,
        "title": "DINO: A Conditional Energy-Based GAN for Domain Translation",
        "html": "https://iclr.cc//virtual/2021/poster/3166",
        "abstract": "Domain translation is the process of transforming data from one domain to another while preserving the common semantics. Some of the most popular domain translation systems are based on conditional generative adversarial networks, which use source domain data to drive the generator and as an input to the discriminator. However, this approach does not enforce the preservation of shared semantics since the conditional input can often be ignored by the discriminator. We propose an alternative method for conditioning and present a new framework, where two networks are simultaneously trained, in a supervised manner, to perform domain translation in opposite directions. Our method is not only better at capturing the shared information between two domains but is more generic and can be applied to a broader range of problems. The proposed framework performs well even in challenging cross-modal translations, such as video-driven speech reconstruction, for which other systems struggle to maintain correspondence.",
        "conference": "ICLR",
        "中文标题": "DINO：一种基于条件能量GAN的领域转换方法",
        "摘要翻译": "领域转换是将数据从一个领域转换到另一个领域同时保留共同语义的过程。一些最流行的领域转换系统基于条件生成对抗网络，这些网络使用源领域数据驱动生成器并作为判别器的输入。然而，这种方法并不强制保留共享语义，因为判别器经常可以忽略条件输入。我们提出了一种替代的条件方法，并提出了一个新框架，其中两个网络以监督方式同时训练，以执行相反方向的领域转换。我们的方法不仅在捕捉两个领域之间的共享信息方面表现更好，而且更通用，可以应用于更广泛的问题范围。所提出的框架即使在具有挑战性的跨模态转换中，如视频驱动的语音重建，也能表现良好，而其他系统难以保持对应关系。",
        "领域": "生成对抗网络、跨模态学习、领域适应",
        "问题": "解决在领域转换过程中共享语义保留不足的问题",
        "动机": "提高领域转换过程中共享语义的保留能力，扩展应用范围",
        "方法": "提出一种基于条件能量GAN的新框架，通过同时训练两个网络以监督方式进行相反方向的领域转换",
        "关键词": [
            "领域转换",
            "条件生成对抗网络",
            "跨模态学习",
            "语义保留",
            "监督学习"
        ],
        "涉及的技术概念": {
            "条件生成对抗网络": "用于生成与特定条件相符的数据，本研究中用于驱动领域转换过程",
            "监督学习": "通过同时训练两个网络以监督方式进行领域转换，提高语义保留能力",
            "跨模态转换": "研究中的一个应用方向，指在不同模态（如视频和语音）之间进行转换，展示方法的通用性和有效性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 192,
        "title": "Directed Acyclic Graph Neural Networks",
        "html": "https://iclr.cc//virtual/2021/poster/3236",
        "abstract": "Graph-structured data ubiquitously appears in science and engineering. Graph neural networks (GNNs) are designed to exploit the relational inductive bias exhibited in graphs; they have been shown to outperform other forms of neural networks in scenarios where structure information supplements node features. The most common GNN architecture aggregates information from neighborhoods based on message passing. Its generality has made it broadly applicable. In this paper, we focus on a special, yet widely used, type of graphs---DAGs---and inject a stronger inductive bias---partial ordering---into the neural network design. We propose the directed acyclic graph neural network, DAGNN, an architecture that processes information according to the flow defined by the partial order. DAGNN can be considered a framework that entails earlier works as special cases (e.g., models for trees and models updating node representations recurrently), but we identify several crucial components that prior architectures lack. We perform comprehensive experiments, including ablation studies, on representative DAG datasets (i.e., source code, neural architectures, and probabilistic graphical models) and demonstrate the superiority of DAGNN over simpler DAG architectures as well as general graph architectures.",
        "conference": "ICLR",
        "中文标题": "有向无环图神经网络",
        "摘要翻译": "图结构数据在科学和工程领域无处不在。图神经网络（GNNs）旨在利用图中展示的关系归纳偏置；在结构信息补充节点特征的场景中，它们已被证明优于其他形式的神经网络。最常见的GNN架构基于消息传递从邻域聚合信息。其通用性使其广泛适用。在本文中，我们关注一种特殊但广泛使用的图类型——有向无环图（DAGs），并将更强的归纳偏置——偏序——注入神经网络设计中。我们提出了有向无环图神经网络（DAGNN），一种根据偏序定义的流处理信息的架构。DAGNN可以被视为一个框架，包含早期工作作为特例（例如，树模型和递归更新节点表示的模型），但我们识别出先前架构缺乏的几个关键组件。我们在代表性DAG数据集（即源代码、神经架构和概率图模型）上进行了包括消融研究在内的全面实验，并证明了DAGNN比简单的DAG架构以及通用图架构的优越性。",
        "领域": "图神经网络、有向无环图处理、深度学习模型架构",
        "问题": "如何在有向无环图（DAGs）中更有效地利用偏序关系进行信息处理",
        "动机": "现有的图神经网络在处理有向无环图时未能充分利用其偏序关系，限制了模型性能和应用范围",
        "方法": "提出有向无环图神经网络（DAGNN），通过注入偏序关系作为更强的归纳偏置，优化信息处理流程",
        "关键词": [
            "有向无环图",
            "图神经网络",
            "偏序关系",
            "信息处理",
            "模型架构"
        ],
        "涉及的技术概念": {
            "有向无环图（DAGs）": "一种没有有向环的图结构，广泛用于表示具有偏序关系的数据",
            "偏序关系": "在DAG中定义的一种部分排序关系，用于指导信息处理的顺序和方向",
            "消息传递机制": "图神经网络中用于在节点间传递和聚合信息的基本机制，DAGNN在此基础上引入了偏序关系的考虑"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 193,
        "title": "Direction Matters: On the Implicit Bias of Stochastic Gradient Descent with Moderate Learning Rate",
        "html": "https://iclr.cc//virtual/2021/poster/2821",
        "abstract": "Understanding the algorithmic bias of stochastic gradient descent (SGD) is one of the key challenges in modern machine learning and deep learning theory. Most of the existing works, however, focus on very small or even infinitesimal learning rate regime, and fail to cover practical scenarios where the learning rate is moderate and annealing. In this paper, we make an initial attempt to characterize the particular regularization effect of SGD in the moderate learning rate regime by studying its behavior for optimizing an overparameterized linear regression problem. In this case, SGD and GD are known to converge to the unique minimum-norm solution; however, with the moderate and annealing learning rate, we show that they exhibit different directional bias: SGD converges along the large eigenvalue directions of the data matrix, while GD goes after the small eigenvalue directions. Furthermore, we show that such directional bias does matter when early stopping is adopted, where the SGD output is nearly optimal but the GD output is suboptimal. Finally, our theory explains several folk arts in practice used for SGD hyperparameter tuning, such as (1) linearly scaling the initial learning rate with batch size; and (2) overrunning SGD with high learning rate even when the loss stops decreasing.",
        "conference": "ICLR",
        "中文标题": "方向至关重要：论中等学习率下随机梯度下降的隐式偏差",
        "摘要翻译": "理解随机梯度下降（SGD）的算法偏差是现代机器学习和深度学习理论中的关键挑战之一。然而，大多数现有工作集中在非常小甚至无限小的学习率制度上，未能涵盖学习率中等且逐渐衰减的实际场景。在本文中，我们通过研究SGD在优化过参数化线性回归问题中的行为，初步尝试描述中等学习率制度下SGD的特殊正则化效应。在这种情况下，已知SGD和GD会收敛到唯一的最小范数解；然而，在中等且逐渐衰减的学习率下，我们展示了它们表现出不同的方向偏差：SGD沿着数据矩阵的大特征值方向收敛，而GD则追随小特征值方向。此外，我们表明，当采用早期停止时，这种方向偏差确实重要，其中SGD输出几乎是最优的，而GD输出则是次优的。最后，我们的理论解释了实践中用于SGD超参数调整的几种民间艺术，例如（1）将初始学习率与批量大小线性缩放；（2）即使损失停止下降，也以高学习率过度运行SGD。",
        "领域": "优化算法、深度学习理论、机器学习",
        "问题": "研究在中等学习率下随机梯度下降（SGD）的隐式偏差及其对优化过程的影响",
        "动机": "现有研究多集中于极小学习率下的SGD行为，忽视了中等学习率在实际应用中的重要性，本研究旨在填补这一空白",
        "方法": "通过分析SGD在过参数化线性回归问题中的行为，比较SGD与梯度下降（GD）在不同学习率下的方向偏差及其对早期停止策略的影响",
        "关键词": [
            "随机梯度下降",
            "学习率",
            "隐式偏差",
            "优化算法",
            "早期停止"
        ],
        "涉及的技术概念": {
            "随机梯度下降（SGD）": "一种常用的优化算法，通过随机采样数据点来估计梯度，用于训练机器学习模型",
            "学习率": "控制模型参数更新步长的超参数，对模型的训练过程和最终性能有重要影响",
            "隐式偏差": "指优化算法在训练过程中倾向于找到特定类型的解，即使在没有显式正则化的情况下"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 194,
        "title": "Disambiguating Symbolic Expressions in Informal Documents",
        "html": "https://iclr.cc//virtual/2021/poster/2931",
        "abstract": "We propose the task of \\emph{disambiguating} symbolic expressions in informal STEM documents in the form of \\LaTeX files -- that is, determining their precise semantics and abstract syntax tree -- as a neural machine translation task. We discuss the distinct challenges involved and present a dataset with roughly 33,000 entries. We evaluated several baseline models on this dataset, which failed to yield even syntactically valid \\LaTeX before overfitting. Consequently, we describe a methodology using a \\emph{transformer} language model pre-trained on sources obtained from \\url{arxiv.org}, which yields promising results despite the small size of the dataset. We evaluate our model using a plurality of dedicated techniques, taking syntax and semantics of symbolic expressions into account.",
        "conference": "ICLR",
        "中文标题": "非正式文档中符号表达式的消歧",
        "摘要翻译": "我们提出了一个任务，即在非正式STEM文档（以LaTeX文件形式）中对符号表达式进行消歧——即确定它们的精确语义和抽象语法树——作为神经机器翻译任务。我们讨论了涉及的不同挑战，并提出了一个包含大约33,000个条目的数据集。我们在这个数据集上评估了几个基线模型，这些模型在过拟合之前甚至无法生成语法上有效的LaTeX。因此，我们描述了一种使用在从arxiv.org获取的源上预训练的transformer语言模型的方法，尽管数据集规模较小，但仍取得了有希望的结果。我们使用多种专门的技术评估我们的模型，考虑了符号表达式的语法和语义。",
        "领域": "自然语言处理与视觉结合、符号计算、文档分析",
        "问题": "在非正式STEM文档中准确理解和解析符号表达式的语义和结构",
        "动机": "解决非正式文档中符号表达式语义不明确和结构复杂的问题，提高文档分析的准确性和效率",
        "方法": "使用预训练的transformer语言模型对符号表达式进行消歧，将其视为神经机器翻译任务",
        "关键词": [
            "符号表达式消歧",
            "神经机器翻译",
            "transformer模型",
            "STEM文档分析",
            "抽象语法树"
        ],
        "涉及的技术概念": {
            "神经机器翻译": "将符号表达式的消歧任务视为翻译问题，利用神经网络模型实现从非正式表达式到精确语义的转换",
            "transformer语言模型": "利用预训练的transformer模型处理和理解复杂的符号表达式结构",
            "抽象语法树": "用于表示符号表达式的精确语义和结构，是消歧任务的目标输出"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 195,
        "title": "Discovering a set of policies for the worst case reward",
        "html": "https://iclr.cc//virtual/2021/poster/2571",
        "abstract": "We study the problem of how to construct a set of policies that can be composed together to solve a collection of reinforcement learning tasks. Each task is a different reward function defined as a linear combination of  known features. We consider a specific class of policy compositions which we call set improving policies (SIPs): given a set of policies and a set of tasks, a SIP is any composition of the former whose performance is at least as good as that of its constituents across all the tasks. We focus on the most conservative instantiation of SIPs, set-max policies (SMPs), so our analysis extends to any SIP. This includes known policy-composition operators like generalized policy improvement. Our main contribution is an algorithm that builds a set of policies in order to maximize the worst-case performance of the resulting SMP on the set of tasks. The algorithm works by successively adding new policies to the set. We show that the worst-case performance of the resulting SMP strictly improves at each iteration, and the algorithm only stops when there does not exist a policy that leads to improved performance. We empirically evaluate our algorithm on a grid world and also on a set of domains from the DeepMind control suite. We confirm our theoretical results regarding the monotonically improving performance of our algorithm. Interestingly, we also show empirically that the sets of policies computed by the algorithm are diverse, leading to different trajectories in the grid world and very distinct locomotion skills in the control suite.",
        "conference": "ICLR",
        "中文标题": "发现一组策略以获得最坏情况下的最大奖励",
        "摘要翻译": "我们研究了如何构建一组策略，这些策略可以组合起来解决一系列强化学习任务的问题。每个任务都是一个不同的奖励函数，定义为已知特征的线性组合。我们考虑了一类特定的策略组合，称为集合改进策略（SIPs）：给定一组策略和一组任务，SIP是前者的任何组合，其在所有任务上的表现至少与其组成部分一样好。我们专注于SIPs的最保守实例化，即集合最大策略（SMPs），因此我们的分析适用于任何SIP。这包括已知的策略组合操作符，如广义策略改进。我们的主要贡献是一种算法，该算法构建一组策略，以最大化所得SMP在任务集上的最坏情况表现。该算法通过逐步向集合中添加新策略来工作。我们表明，所得SMP的最坏情况表现在每次迭代中严格提高，并且算法仅在不存在能带来性能改进的策略时停止。我们在网格世界和DeepMind控制套件的一组领域上对我们的算法进行了实证评估。我们证实了关于我们算法性能单调提高的理论结果。有趣的是，我们还通过实证表明，算法计算的策略集是多样化的，导致网格世界中的不同轨迹和控制套件中非常不同的运动技能。",
        "领域": "强化学习、策略组合、多任务学习",
        "问题": "如何构建一组策略，这些策略可以组合起来解决一系列强化学习任务，以最大化最坏情况下的表现。",
        "动机": "研究动机是为了解决在多任务强化学习中，如何有效地组合策略以提高在最坏情况下的表现。",
        "方法": "提出了一种算法，通过逐步向策略集中添加新策略，以构建能够最大化最坏情况表现的集合最大策略（SMPs）。",
        "关键词": [
            "强化学习",
            "策略组合",
            "多任务学习",
            "集合最大策略",
            "最坏情况表现"
        ],
        "涉及的技术概念": {
            "集合改进策略（SIPs）": "一类特定的策略组合，其在所有任务上的表现至少与其组成部分一样好。",
            "集合最大策略（SMPs）": "SIPs的最保守实例化，用于分析任何SIP的性能。",
            "广义策略改进": "一种已知的策略组合操作符，用于提升策略性能。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 196,
        "title": "Discovering Diverse Multi-Agent Strategic Behavior via Reward Randomization",
        "html": "https://iclr.cc//virtual/2021/poster/2775",
        "abstract": "We propose a simple, general and effective technique, Reward Randomization for discovering diverse strategic policies in complex multi-agent games. Combining reward randomization and policy gradient, we derive a new algorithm, Reward-Randomized Policy Gradient (RPG). RPG is able to discover a set of multiple distinctive human-interpretable strategies in challenging temporal trust dilemmas, including grid-world games and a real-world game Agar.io, where multiple equilibria exist but standard multi-agent policy gradient algorithms always converge to a fixed one with a sub-optimal payoff for every player even using state-of-the-art exploration techniques. Furthermore, with the set of diverse strategies from RPG, we can (1) achieve higher payoffs by fine-tuning the best policy from the set; and (2) obtain an adaptive agent by using this set of strategies as its training opponents. ",
        "conference": "ICLR",
        "中文标题": "通过奖励随机化发现多样化的多智能体策略行为",
        "摘要翻译": "我们提出了一种简单、通用且有效的技术——奖励随机化，用于在复杂的多智能体游戏中发现多样化的策略政策。结合奖励随机化和策略梯度，我们推导出一种新算法——奖励随机化策略梯度（RPG）。RPG能够在具有挑战性的时间信任困境中，包括网格世界游戏和现实世界游戏Agar.io，发现一组多个独特且人类可理解的策略，这些情况下存在多个均衡点，但标准的多智能体策略梯度算法即使使用最先进的探索技术也总是收敛到一个固定点，对每个玩家来说收益次优。此外，利用RPG提供的多样化策略集合，我们可以（1）通过微调集合中的最佳策略实现更高的收益；（2）通过将这组策略作为训练对手来获得一个适应性强的智能体。",
        "领域": "多智能体系统、策略学习、游戏AI",
        "问题": "解决在复杂多智能体游戏中发现多样化策略的挑战，避免标准算法收敛到次优均衡点的问题。",
        "动机": "探索如何在存在多个均衡点的多智能体环境中，发现多样化的策略，以提高游戏的策略深度和玩家的收益。",
        "方法": "提出奖励随机化策略梯度（RPG）算法，结合奖励随机化和策略梯度，以发现多样化的策略。",
        "关键词": [
            "奖励随机化",
            "策略梯度",
            "多智能体游戏",
            "多样化策略",
            "RPG算法"
        ],
        "涉及的技术概念": {
            "奖励随机化": "通过随机化奖励函数来鼓励探索不同的策略，避免算法过早收敛到局部最优解。",
            "策略梯度": "一种直接优化策略参数的强化学习方法，用于在连续动作空间中寻找最优策略。",
            "多智能体系统": "研究多个智能体在共享环境中如何相互作用和学习的系统，特别关注于策略的多样性和均衡点的发现。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 197,
        "title": "Discovering Non-monotonic Autoregressive Orderings with Variational Inference",
        "html": "https://iclr.cc//virtual/2021/poster/2984",
        "abstract": "The predominant approach for language modeling is to encode a sequence of tokens from left to right, but this eliminates a source of information: the order by which the sequence was naturally generated. One strategy to recover this information is to decode both the content and ordering of tokens. Some prior work supervises content and ordering with hand-designed loss functions to encourage specific orders or bootstraps from a predefined ordering. These approaches require domain-specific insight. Other prior work searches over valid insertion operations that lead to ground truth sequences during training, which has high time complexity and cannot be efficiently parallelized. We address these limitations with an unsupervised learner that can be trained in a fully-parallelizable manner to discover high-quality autoregressive orders in a data driven way without a domain-specific prior. The learner is a neural network that performs variational inference with the autoregressive ordering as a latent variable. Since the corresponding variational lower bound is not differentiable, we develop a practical algorithm for end-to-end optimization using policy gradients. Strong empirical results with our solution on sequence modeling tasks suggest that our algorithm is capable of discovering various autoregressive orders for different sequences that are competitive with or even better than fixed orders.",
        "conference": "ICLR",
        "中文标题": "利用变分推断发现非单调自回归排序",
        "摘要翻译": "语言建模的主要方法是从左到右编码一系列标记，但这消除了一个信息来源：序列自然生成的顺序。恢复这一信息的一种策略是解码标记的内容和顺序。一些先前的工作通过手工设计的损失函数来监督内容和顺序，以鼓励特定的顺序或从预定义的顺序中引导。这些方法需要领域特定的洞察力。其他先前的工作在训练期间搜索导致真实序列的有效插入操作，这具有较高的时间复杂度且无法高效并行化。我们通过一个无监督学习器解决了这些限制，该学习器可以以完全可并行化的方式进行训练，以数据驱动的方式发现高质量的自回归顺序，而无需领域特定的先验。该学习器是一个神经网络，它执行变分推断，将自回归顺序作为潜在变量。由于相应的变分下界不可微分，我们开发了一种使用策略梯度进行端到端优化的实用算法。我们的解决方案在序列建模任务上的强大实证结果表明，我们的算法能够为不同的序列发现各种自回归顺序，这些顺序与固定顺序相比具有竞争力甚至更好。",
        "领域": "自然语言处理与视觉结合、序列建模、变分推断",
        "问题": "如何在不依赖领域特定先验的情况下，以数据驱动的方式发现高质量的自回归顺序。",
        "动机": "传统的从左到右的语言建模方法忽略了序列自然生成的顺序信息，限制了模型的表达能力。",
        "方法": "开发了一个无监督学习器，通过变分推断将自回归顺序作为潜在变量，并使用策略梯度进行端到端优化。",
        "关键词": [
            "自回归顺序",
            "变分推断",
            "无监督学习",
            "策略梯度",
            "序列建模"
        ],
        "涉及的技术概念": {
            "变分推断": "用于将自回归顺序作为潜在变量进行推断，以发现高质量的顺序。",
            "策略梯度": "用于优化不可微分的变分下界，实现端到端的训练。",
            "自回归顺序": "作为潜在变量，通过学习器发现，以增强序列建模的表达能力。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 198,
        "title": "Discrete Graph Structure Learning for Forecasting Multiple Time Series",
        "html": "https://iclr.cc//virtual/2021/poster/2800",
        "abstract": "Time series forecasting is an extensively studied subject in statistics, economics, and computer science. Exploration of the correlation and causation among the variables in a multivariate time series shows promise in enhancing the performance of a time series model. When using deep neural networks as forecasting models, we hypothesize that exploiting the pairwise information among multiple (multivariate) time series also improves their forecast. If an explicit graph structure is known, graph neural networks (GNNs) have been demonstrated as powerful tools to exploit the structure. In this work, we propose learning the structure simultaneously with the GNN if the graph is unknown. We cast the problem as learning a probabilistic graph model through optimizing the mean performance over the graph distribution. The distribution is parameterized by a neural network so that discrete graphs can be sampled differentiably through reparameterization. Empirical evaluations show that our method is simpler, more efficient, and better performing than a recently proposed bilevel learning approach for graph structure learning, as well as a broad array of forecasting models, either deep or non-deep learning based, and graph or non-graph based.",
        "conference": "ICLR",
        "中文标题": "离散图结构学习用于多时间序列预测",
        "摘要翻译": "时间序列预测是统计学、经济学和计算机科学中广泛研究的课题。探索多元时间序列中变量之间的相关性和因果关系，有望提升时间序列模型的性能。当使用深度神经网络作为预测模型时，我们假设利用多个（多元）时间序列之间的成对信息也能提高其预测能力。如果已知明确的图结构，图神经网络（GNNs）已被证明是利用该结构的强大工具。在这项工作中，我们提出如果图结构未知，则与GNN同时学习该结构。我们将问题转化为通过学习图分布上的平均性能来优化概率图模型。该分布由神经网络参数化，以便通过重新参数化可微分地采样离散图。实证评估表明，我们的方法比最近提出的用于图结构学习的双层学习方法以及一系列广泛的预测模型（无论是基于深度学习还是非深度学习，基于图还是非基于图）更简单、更高效且性能更好。",
        "领域": "时间序列预测、图神经网络、深度学习",
        "问题": "如何在图结构未知的情况下，同时学习图结构和进行多时间序列预测",
        "动机": "探索多元时间序列中变量之间的相关性和因果关系，以提高预测模型的性能",
        "方法": "提出一种同时学习图结构和图神经网络的方法，通过优化图分布上的平均性能来学习概率图模型",
        "关键词": [
            "离散图结构学习",
            "多时间序列预测",
            "图神经网络",
            "深度学习",
            "概率图模型"
        ],
        "涉及的技术概念": {
            "图神经网络（GNNs）": "用于利用图结构进行预测的强大工具",
            "概率图模型": "通过学习图分布上的平均性能来优化模型",
            "重新参数化": "使离散图能够可微分地采样"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 199,
        "title": "Disentangled Recurrent Wasserstein Autoencoder ",
        "html": "https://iclr.cc//virtual/2021/poster/3257",
        "abstract": "Learning disentangled representations leads to interpretable models and facilitates data generation with style transfer, which has been extensively studied on static data such as images in an unsupervised learning framework. However, only a few works have explored unsupervised disentangled sequential representation learning due to challenges of generating sequential data. In this paper, we propose recurrent Wasserstein Autoencoder (R-WAE), a new framework for generative modeling of sequential data. R-WAE disentangles the representation of an input sequence into static and dynamic factors (i.e., time-invariant and time-varying parts). Our theoretical analysis shows that, R-WAE minimizes an upper bound of a penalized form of the Wasserstein distance between model distribution and sequential data distribution, and simultaneously maximizes the mutual information between input data and different disentangled latent factors, respectively. This is superior to (recurrent) VAE which does not explicitly enforce mutual information maximization between input data and disentangled latent representations. When the number of actions in sequential data is available as weak supervision information, R-WAE is extended to learn a categorical latent representation of actions to improve its disentanglement. Experiments on a variety of datasets show that our models outperform other baselines with the same settings in terms of disentanglement and unconditional video generation both quantitatively and qualitatively.",
        "conference": "ICLR",
        "中文标题": "解耦循环Wasserstein自编码器",
        "摘要翻译": "学习解耦表示可以产生可解释的模型，并促进带有风格转换的数据生成，这在静态数据（如图像）的无监督学习框架中已被广泛研究。然而，由于生成序列数据的挑战，只有少数工作探索了无监督解耦序列表示学习。在本文中，我们提出了循环Wasserstein自编码器（R-WAE），一种新的序列数据生成建模框架。R-WAE将输入序列的表示解耦为静态和动态因素（即时间不变和时间变化部分）。我们的理论分析表明，R-WAE最小化了模型分布与序列数据分布之间Wasserstein距离的惩罚形式的上界，并同时分别最大化输入数据与不同解耦潜在因素之间的互信息。这优于（循环）VAE，后者没有明确强制输入数据与解耦潜在表示之间的互信息最大化。当序列数据中的动作数量可作为弱监督信息时，R-WAE被扩展以学习动作的分类潜在表示，以改善其解耦。在各种数据集上的实验表明，我们的模型在解耦和无条件视频生成方面，在定量和定性上都优于相同设置下的其他基线。",
        "领域": "序列数据生成、无监督学习、风格转换",
        "问题": "解决序列数据中无监督解耦表示学习的挑战",
        "动机": "探索序列数据的解耦表示学习，以促进可解释模型的构建和风格转换的数据生成",
        "方法": "提出循环Wasserstein自编码器（R-WAE）框架，通过解耦序列数据的静态和动态因素，最小化模型与数据分布间的Wasserstein距离上界，并最大化输入数据与潜在因素的互信息",
        "关键词": [
            "解耦表示",
            "Wasserstein自编码器",
            "序列数据生成",
            "无监督学习",
            "风格转换"
        ],
        "涉及的技术概念": {
            "解耦表示": "将数据表示分解为独立且可解释的因素，便于模型解释和风格转换",
            "Wasserstein距离": "用于衡量模型分布与真实数据分布之间的差异，优化生成模型",
            "互信息最大化": "增强输入数据与潜在因素之间的关联，提高解耦效果"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 200,
        "title": "Disentangling 3D Prototypical Networks for Few-Shot Concept Learning",
        "html": "https://iclr.cc//virtual/2021/poster/3303",
        "abstract": "We present neural architectures that disentangle RGB-D images into objects’ shapes and styles and a map of the background scene, and explore their applications for few-shot 3D object detection and few-shot concept classification. Our networks incorporate architectural biases that reflect the image formation process, 3D  geometry of the world scene, and shape-style interplay. They are trained end-to-end self-supervised by predicting views in static scenes, alongside a small number of 3D object boxes. Objects and scenes are represented in terms of 3D feature grids in the bottleneck of the network. We show the proposed 3D neural representations are compositional: they can generate novel 3D scene feature maps by mixing object shapes and styles, resizing and adding the resulting object 3D feature maps over background scene feature maps. We show object detectors trained on hallucinated 3D neural scenes generalize better to novel environments. We show classifiers for object categories, color, materials, and spatial relationships trained over the  disentangled 3D feature sub-spaces generalize better with dramatically fewer exemplars over the current state-of-the-art, and enable a visual question answering system that uses them as its modules to generalize one-shot to novel objects in the scene.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "解耦三维原型网络用于少样本概念学习",
        "摘要翻译": "我们提出了能够将RGB-D图像解耦为物体形状与风格以及背景场景地图的神经网络架构，并探索了它们在少样本三维物体检测和少样本概念分类中的应用。我们的网络融入了反映图像形成过程、世界场景的三维几何以及形状-风格相互作用的架构偏置。它们通过预测静态场景中的视图以及少量三维物体框，以端到端自监督的方式进行训练。物体和场景以网络瓶颈中的三维特征网格形式表示。我们展示了所提出的三维神经表示具有组合性：它们可以通过混合物体形状和风格、调整大小并将生成的物体三维特征网格添加到背景场景特征网格上，来生成新的三维场景特征图。我们展示了在幻觉三维神经场景上训练的物体检测器能够更好地泛化到新环境。我们还展示了在解耦的三维特征子空间上训练的物体类别、颜色、材料和空间关系分类器，与当前最先进技术相比，能够以显著更少的样本实现更好的泛化，并且使得一个使用它们作为模块的视觉问答系统能够一次性泛化到场景中的新物体。",
        "领域": "三维物体检测",
        "问题": "解决少样本学习中的三维物体检测和概念分类问题",
        "动机": "探索通过解耦三维特征表示来提高少样本学习任务的性能",
        "方法": "采用自监督学习训练能够解耦物体形状、风格和背景的三维神经网络架构",
        "关键词": [
            "三维原型网络",
            "少样本学习",
            "RGB-D图像解耦",
            "自监督学习",
            "视觉问答系统"
        ],
        "涉及的技术概念": {
            "三维特征网格": "用于在网络瓶颈中表示物体和场景的三维结构",
            "自监督学习": "通过预测视图和物体框来训练网络，无需大量标注数据",
            "解耦表示": "将图像分离为形状、风格和背景，以便于组合和泛化"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 201,
        "title": "Distance-Based Regularisation of Deep Networks for Fine-Tuning",
        "html": "https://iclr.cc//virtual/2021/poster/3044",
        "abstract": "We investigate approaches to regularisation during fine-tuning of deep neural networks. First we provide a neural network generalisation bound based on Rademacher complexity that uses the distance the weights have moved from their initial values. This bound has no direct dependence on the number of weights and compares favourably to other bounds when applied to convolutional networks. Our bound is highly relevant for fine-tuning, because providing a network with a good initialisation based on transfer learning means that learning can modify the weights less, and hence achieve tighter generalisation. Inspired by this, we develop a simple yet effective fine-tuning algorithm that constrains the hypothesis class to a small sphere centred on the initial pre-trained weights, thus obtaining provably better generalisation performance than conventional transfer learning. Empirical evaluation shows that our algorithm works well, corroborating our theoretical results. It outperforms both state of the art fine-tuning competitors, and penalty-based alternatives that we show do not directly constrain the radius of the search space.",
        "conference": "ICLR",
        "中文标题": "基于距离的深度网络微调正则化方法",
        "摘要翻译": "我们研究了深度神经网络微调过程中的正则化方法。首先，我们提供了一个基于Rademacher复杂度的神经网络泛化边界，该边界利用了权重从其初始值移动的距离。这个边界不直接依赖于权重的数量，并且在应用于卷积网络时比其他边界表现更好。我们的边界对于微调非常相关，因为基于迁移学习为网络提供良好的初始化意味着学习可以较少地修改权重，从而实现更紧密的泛化。受此启发，我们开发了一种简单而有效的微调算法，该算法将假设类限制在一个以初始预训练权重为中心的小球体内，从而获得了比传统迁移学习更好的泛化性能。实证评估表明，我们的算法表现良好，证实了我们的理论结果。它既优于最先进的微调竞争对手，也优于我们展示的不直接约束搜索空间半径的基于惩罚的替代方法。",
        "领域": "迁移学习",
        "问题": "如何在深度神经网络的微调过程中有效地进行正则化，以提高模型的泛化能力",
        "动机": "通过限制权重变化的范围，减少模型在微调过程中的过拟合风险，从而提高泛化性能",
        "方法": "开发了一种基于距离的正则化方法，通过将权重变化限制在一个小球体内来优化微调过程",
        "关键词": [
            "深度网络微调",
            "正则化",
            "泛化边界",
            "迁移学习",
            "Rademacher复杂度"
        ],
        "涉及的技术概念": {
            "Rademacher复杂度": "用于衡量假设类的复杂性，帮助推导泛化边界",
            "迁移学习": "通过预训练模型提供良好的初始权重，减少微调时的权重变化",
            "正则化": "通过限制权重变化的范围，防止模型在微调过程中过拟合"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 202,
        "title": "Distilling Knowledge from Reader to Retriever for Question Answering",
        "html": "https://iclr.cc//virtual/2021/poster/2774",
        "abstract": "The task of information retrieval is an important component of many natural language processing systems, such as open domain question answering. While traditional methods were based on hand-crafted features, continuous representations based on neural networks recently obtained competitive results. A challenge of using such methods is to obtain supervised data to train the retriever model, corresponding to pairs of query and support documents. In this paper, we propose a technique to learn retriever models for downstream tasks, inspired by knowledge distillation, and which does not require annotated pairs of query and documents. Our approach leverages attention scores of a reader model, used to solve the task based on retrieved documents, to obtain synthetic labels for the retriever. We evaluate our method on question answering, obtaining state-of-the-art results.",
        "conference": "ICLR",
        "中文标题": "从阅读器到检索器的知识蒸馏用于问答系统",
        "摘要翻译": "信息检索任务是许多自然语言处理系统的重要组成部分，例如开放领域问答。虽然传统方法基于手工制作的特征，但基于神经网络的连续表示最近取得了竞争性结果。使用这种方法的一个挑战是获取监督数据来训练检索器模型，这些数据对应于查询和支持文档的对。在本文中，我们提出了一种技术，用于学习下游任务的检索器模型，受到知识蒸馏的启发，并且不需要查询和文档的注释对。我们的方法利用阅读器模型的注意力分数，用于基于检索到的文档解决任务，以获得检索器的合成标签。我们在问答上评估了我们的方法，取得了最先进的结果。",
        "领域": "开放领域问答、信息检索、知识蒸馏",
        "问题": "如何在没有查询和文档注释对的情况下训练检索器模型",
        "动机": "解决传统方法需要大量标注数据的问题，通过知识蒸馏技术减少对标注数据的依赖",
        "方法": "利用阅读器模型的注意力分数生成检索器的合成标签，无需查询和文档的注释对",
        "关键词": [
            "知识蒸馏",
            "信息检索",
            "问答系统",
            "注意力机制",
            "合成标签"
        ],
        "涉及的技术概念": {
            "知识蒸馏": "通过从复杂的阅读器模型中提取知识来训练检索器模型，减少对标注数据的依赖",
            "注意力机制": "用于从阅读器模型中提取注意力分数，作为训练检索器模型的监督信号",
            "合成标签": "通过阅读器模型的注意力分数生成的标签，用于训练检索器模型，无需人工标注"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 203,
        "title": "Distributed Momentum for Byzantine-resilient Stochastic Gradient Descent",
        "html": "https://iclr.cc//virtual/2021/poster/2636",
        "abstract": "Byzantine-resilient Stochastic Gradient Descent (SGD) aims at shielding model training from Byzantine faults, be they ill-labeled training datapoints, exploited software/hardware vulnerabilities, or malicious worker nodes in a distributed setting.\nTwo recent attacks have been challenging state-of-the-art defenses though, often successfully precluding the model from even fitting the training set.\nThe main identified weakness in current defenses is their requirement of a sufficiently low variance-norm ratio for the stochastic gradients.\nWe propose a practical method which, despite increasing the variance, reduces the variance-norm ratio, mitigating the identified weakness.\nWe assess the effectiveness of our method over 736 different training configurations, comprising the 2 state-of-the-art attacks and 6 defenses.\nFor confidence and reproducibility purposes, each configuration is run 5 times with specified seeds (1 to 5), totalling 3680 runs.\nIn our experiments, when the attack is effective enough to decrease the highest observed top-1 cross-accuracy by at least 20% compared to the unattacked run, our technique systematically increases back the highest observed accuracy, and is able to recover at least 20% in more than 60% of the cases.",
        "conference": "ICLR",
        "中文标题": "分布式动量用于拜占庭容错的随机梯度下降",
        "摘要翻译": "拜占庭容错的随机梯度下降（SGD）旨在保护模型训练免受拜占庭故障的影响，无论是错误标记的训练数据点、被利用的软件/硬件漏洞，还是分布式环境中的恶意工作节点。然而，最近的两种攻击对现有最先进的防御措施提出了挑战，常常成功地阻止模型甚至拟合训练集。当前防御措施中识别出的主要弱点是它们对随机梯度的方差-范数比要求足够低。我们提出了一种实用方法，尽管增加了方差，但降低了方差-范数比，从而缓解了识别出的弱点。我们在736种不同的训练配置上评估了我们方法的有效性，包括2种最先进的攻击和6种防御措施。为了确保置信度和可重复性，每种配置都使用指定的种子（1到5）运行5次，总计3680次运行。在我们的实验中，当攻击足够有效，使得观察到的最高top-1交叉准确率相比未受攻击的运行至少下降20%时，我们的技术系统地提高了观察到的最高准确率，并且在超过60%的情况下能够恢复至少20%的准确率。",
        "领域": "分布式机器学习安全、对抗性机器学习、深度学习优化",
        "问题": "解决拜占庭故障对随机梯度下降（SGD）模型训练的干扰问题",
        "动机": "针对当前防御措施在面对特定攻击时的不足，提出一种能够有效降低方差-范数比的方法，以提高模型训练的鲁棒性",
        "方法": "提出一种实用方法，通过增加方差但降低方差-范数比，来缓解当前防御措施的弱点，并在多种训练配置上进行验证",
        "关键词": [
            "拜占庭容错",
            "随机梯度下降",
            "分布式机器学习",
            "对抗性攻击",
            "模型训练安全"
        ],
        "涉及的技术概念": {
            "拜占庭容错": "在分布式系统中，即使部分节点因故障或恶意行为提供错误信息，系统仍能正确运行的能力",
            "随机梯度下降（SGD）": "一种优化算法，用于最小化损失函数，通过迭代更新模型参数来训练机器学习模型",
            "方差-范数比": "衡量随机梯度稳定性的指标，较低的比率有助于提高模型训练的鲁棒性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 204,
        "title": "Distributional Sliced-Wasserstein and Applications to Generative Modeling",
        "html": "https://iclr.cc//virtual/2021/poster/3072",
        "abstract": "Sliced-Wasserstein distance (SW) and its variant, Max Sliced-Wasserstein distance (Max-SW), have been used widely in the recent years due to their fast computation and scalability even when the probability measures lie in a very high dimensional space. However, SW requires many unnecessary projection samples to approximate its value while Max-SW only uses the most important projection, which ignores the information of other useful directions. In order to account for these weaknesses, we propose a novel distance, named Distributional Sliced-Wasserstein distance (DSW), that finds an optimal distribution over projections that can balance between exploring distinctive projecting directions and the informativeness of projections themselves. We show that the DSW is a generalization of Max-SW, and it can be computed efficiently by searching for the optimal push-forward measure over a set of probability measures over the unit sphere satisfying certain regularizing constraints that favor distinct directions. Finally, we conduct extensive experiments with large-scale datasets to demonstrate the favorable performances of the proposed distances over the previous sliced-based distances in generative modeling applications.",
        "conference": "ICLR",
        "中文标题": "分布切片-瓦瑟斯坦距离及其在生成模型中的应用",
        "摘要翻译": "切片-瓦瑟斯坦距离（SW）及其变体最大切片-瓦瑟斯坦距离（Max-SW）近年来因其快速计算和可扩展性而被广泛使用，即使概率测度位于非常高维的空间中。然而，SW需要许多不必要的投影样本来近似其值，而Max-SW仅使用最重要的投影，忽略了其他有用方向的信息。为了弥补这些弱点，我们提出了一种新的距离，称为分布切片-瓦瑟斯坦距离（DSW），它找到一个在投影上的最优分布，可以在探索独特的投影方向和投影本身的信息量之间取得平衡。我们表明，DSW是Max-SW的推广，并且可以通过在满足某些倾向于不同方向的正则化约束的单位球面上的概率测度集合上搜索最优的前推测度来高效计算。最后，我们使用大规模数据集进行了广泛的实验，以证明在生成模型应用中，所提出的距离相对于之前的基于切片的距离具有优越的性能。",
        "领域": "生成模型、概率测度、高维数据分析",
        "问题": "解决切片-瓦瑟斯坦距离和最大切片-瓦瑟斯坦距离在计算效率和信息利用上的不足",
        "动机": "为了在保持计算效率的同时，更充分地利用投影方向的信息，提高生成模型的性能",
        "方法": "提出分布切片-瓦瑟斯坦距离（DSW），通过寻找投影上的最优分布来平衡探索独特投影方向和投影信息量",
        "关键词": [
            "分布切片-瓦瑟斯坦距离",
            "生成模型",
            "概率测度",
            "高维数据",
            "投影优化"
        ],
        "涉及的技术概念": {
            "切片-瓦瑟斯坦距离（SW）": "用于衡量高维空间中两个概率分布之间的距离，计算效率高",
            "最大切片-瓦瑟斯坦距离（Max-SW）": "SW的变体，仅使用最重要的投影方向，忽略了其他有用信息",
            "分布切片-瓦瑟斯坦距离（DSW）": "提出的新距离，通过优化投影分布来平衡探索方向和投影信息量，提高生成模型的性能"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 205,
        "title": "Diverse Video Generation using a Gaussian Process Trigger",
        "html": "https://iclr.cc//virtual/2021/poster/2565",
        "abstract": "Generating future frames given a few context (or past) frames is a challenging task. It requires modeling the temporal coherence of videos as well as multi-modality in terms of diversity in the potential future states. Current variational approaches for video generation tend to marginalize over multi-modal future outcomes. Instead, we propose to explicitly model the multi-modality in the future outcomes and leverage it to sample diverse futures. Our approach, Diverse Video Generator, uses a GP to learn priors on future states given the past and maintains a probability distribution over possible futures given a particular sample. We leverage the changes in this distribution over time to control the sampling of diverse future states by estimating the end of on-going sequences. In particular, we use the variance of GP over the output function space to trigger a change in the action sequence. We achieve state-of-the-art results on diverse future frame generation in terms of reconstruction quality and diversity of the generated sequences.",
        "conference": "ICLR",
        "中文标题": "使用高斯过程触发器生成多样化视频",
        "摘要翻译": "给定少量上下文（或过去）帧生成未来帧是一项具有挑战性的任务。它需要建模视频的时间连贯性以及潜在未来状态的多样性方面的多模态性。当前用于视频生成的变分方法倾向于对多模态未来结果进行边缘化处理。相反，我们提出明确建模未来结果中的多模态性，并利用它来采样多样化的未来。我们的方法，多样化视频生成器，使用高斯过程（GP）在给定过去帧的情况下学习未来状态的先验，并保持对给定特定样本的可能未来的概率分布。我们利用这种分布随时间的变化，通过估计正在进行序列的结束来控制多样化未来状态的采样。特别是，我们使用高斯过程在输出函数空间上的方差来触发动作序列的变化。我们在多样化未来帧生成方面，就重建质量和生成序列的多样性而言，取得了最先进的结果。",
        "领域": "视频生成、时间序列预测、多模态学习",
        "问题": "如何在视频生成中有效建模和采样多样化的未来帧",
        "动机": "解决当前视频生成方法在多样化未来帧生成上的不足，特别是在建模多模态未来结果方面的局限性",
        "方法": "提出了一种使用高斯过程学习未来状态先验并控制多样化未来帧采样的方法",
        "关键词": [
            "多样化视频生成",
            "高斯过程",
            "多模态学习",
            "时间序列预测",
            "视频帧预测"
        ],
        "涉及的技术概念": {
            "高斯过程": "用于学习未来状态的先验分布，建模视频帧之间的时间连贯性和多样性",
            "多模态学习": "明确建模未来结果中的多模态性，以采样多样化的未来帧",
            "时间序列预测": "通过分析视频帧的时间连贯性，预测和生成未来的视频帧"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 206,
        "title": "Do 2D GANs Know 3D Shape? Unsupervised 3D Shape Reconstruction from 2D Image GANs",
        "html": "https://iclr.cc//virtual/2021/poster/2881",
        "abstract": "Natural images are projections of 3D objects on a 2D image plane. While state-of-the-art 2D generative models like GANs show unprecedented quality in modeling the natural image manifold, it is unclear whether they implicitly capture the underlying 3D object structures. And if so, how could we exploit such knowledge to recover the 3D shapes of objects in the images? To answer these questions, in this work, we present the first attempt to directly mine 3D geometric cues from an off-the-shelf 2D GAN that is trained on RGB images only. Through our investigation, we found that such a pre-trained GAN indeed contains rich 3D knowledge and thus can be used to recover 3D shape from a single 2D image in an unsupervised manner. The core of our framework is an iterative strategy that explores and exploits diverse viewpoint and lighting variations in the GAN image manifold. The framework does not require 2D keypoint or 3D annotations, or strong assumptions on object shapes (e.g. shapes are symmetric), yet it successfully recovers 3D shapes with high precision for human faces, cats, cars, and buildings. The recovered 3D shapes immediately allow high-quality image editing like relighting and object rotation. We quantitatively demonstrate the effectiveness of our approach compared to previous methods in both 3D shape reconstruction and face rotation. Our code is available at https://github.com/XingangPan/GAN2Shape.",
        "conference": "ICLR",
        "中文标题": "二维GAN是否理解三维形状？从二维图像GAN中无监督重建三维形状",
        "摘要翻译": "自然图像是三维物体在二维图像平面上的投影。虽然像GAN这样的先进二维生成模型在模拟自然图像流形方面展现了前所未有的质量，但它们是否隐式地捕捉了底层的三维物体结构尚不明确。如果是这样，我们如何利用这种知识来恢复图像中物体的三维形状？为了回答这些问题，在这项工作中，我们首次尝试直接从仅使用RGB图像训练的现成二维GAN中挖掘三维几何线索。通过我们的调查，我们发现这样的预训练GAN确实包含丰富的三维知识，因此可以用于以无监督的方式从单张二维图像中恢复三维形状。我们框架的核心是一种迭代策略，该策略探索并利用了GAN图像流形中多样化的视角和光照变化。该框架不需要二维关键点或三维注释，也不需要对物体形状做出强假设（例如形状是对称的），但它成功地以高精度恢复了人脸、猫、汽车和建筑物的三维形状。恢复的三维形状立即允许高质量的图像编辑，如重新打光和物体旋转。我们定量地展示了我们的方法在三维形状重建和面部旋转方面与之前方法相比的有效性。我们的代码可在https://github.com/XingangPan/GAN2Shape获取。",
        "领域": "三维重建、生成对抗网络、计算机视觉",
        "问题": "如何从仅使用RGB图像训练的二维GAN中无监督地恢复三维形状",
        "动机": "探索二维生成模型是否隐式地捕捉了三维物体结构，并利用这种知识恢复图像中物体的三维形状",
        "方法": "提出一种迭代策略，探索并利用GAN图像流形中多样化的视角和光照变化，无需二维关键点或三维注释，也不需要对物体形状做出强假设",
        "关键词": [
            "三维重建",
            "生成对抗网络",
            "无监督学习",
            "图像编辑",
            "计算机视觉"
        ],
        "涉及的技术概念": {
            "生成对抗网络": "用于模拟自然图像流形的先进二维生成模型，本研究中用于挖掘三维几何线索",
            "无监督学习": "研究中使用的方法，不需要二维关键点或三维注释，直接从GAN中恢复三维形状",
            "三维重建": "研究的核心目标，从单张二维图像中恢复物体的三维形状"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 207,
        "title": "Does enhanced shape bias improve neural network robustness to common corruptions?",
        "html": "https://iclr.cc//virtual/2021/poster/3235",
        "abstract": "Convolutional neural networks (CNNs) learn to extract representations of complex features, such as object shapes and textures to solve image recognition tasks. Recent work indicates that CNNs trained on ImageNet are biased towards features that encode textures and that these alone are sufficient to generalize to unseen test data from the same distribution as the training data but often fail to generalize to out-of-distribution data. It has been shown that augmenting the training data with different image styles decreases this texture bias in favor of increased shape bias while at the same time improving robustness to common corruptions, such as noise and blur. Commonly, this is interpreted as shape bias increasing corruption robustness. However, this relationship is only hypothesized. We perform a systematic study of different ways of composing inputs based on natural images, explicit edge information, and stylization. While stylization is essential for achieving high corruption robustness, we do not find a clear correlation between shape bias and robustness. We conclude that the data augmentation caused by style-variation  accounts for the improved corruption robustness and increased shape bias is only a byproduct.",
        "conference": "ICLR",
        "中文标题": "增强的形状偏差是否提高了神经网络对常见损坏的鲁棒性？",
        "摘要翻译": "卷积神经网络（CNNs）学习提取复杂特征的表示，如物体形状和纹理，以解决图像识别任务。最近的工作表明，在ImageNet上训练的CNNs偏向于编码纹理的特征，这些特征足以泛化到与训练数据相同分布的未见测试数据，但往往无法泛化到分布外的数据。已经证明，通过不同图像风格增强训练数据可以减少这种纹理偏差，有利于增加形状偏差，同时提高对常见损坏（如噪声和模糊）的鲁棒性。通常，这被解释为形状偏差增加了损坏鲁棒性。然而，这种关系仅是假设。我们对基于自然图像、显式边缘信息和风格化的不同输入组合方式进行了系统研究。虽然风格化对于实现高损坏鲁棒性至关重要，但我们没有发现形状偏差与鲁棒性之间存在明确的相关性。我们得出结论，由风格变化引起的数据增强解释了改进的损坏鲁棒性，而增加的形状偏差只是一个副产品。",
        "领域": "图像识别、神经网络鲁棒性、数据增强",
        "问题": "研究形状偏差增强是否真正提高了神经网络对图像常见损坏的鲁棒性。",
        "动机": "探索和验证形状偏差与神经网络鲁棒性之间的实际关系，以更有效地提升模型性能。",
        "方法": "系统研究不同输入组合方式（自然图像、显式边缘信息、风格化）对形状偏差和鲁棒性的影响。",
        "关键词": [
            "形状偏差",
            "神经网络鲁棒性",
            "数据增强",
            "风格化",
            "图像识别"
        ],
        "涉及的技术概念": {
            "形状偏差": "指神经网络在处理图像时更倾向于依赖形状信息而非纹理信息进行决策的倾向。",
            "数据增强": "通过变换训练数据（如风格化）来增加数据的多样性，以提高模型的泛化能力和鲁棒性。",
            "风格化": "一种数据增强技术，通过改变图像的风格（如艺术风格）来增加训练数据的多样性，旨在减少模型对特定纹理的依赖。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 208,
        "title": "Domain Generalization with MixStyle",
        "html": "https://iclr.cc//virtual/2021/poster/2738",
        "abstract": "Though convolutional neural networks (CNNs) have demonstrated remarkable ability in learning discriminative features, they often generalize poorly to unseen domains. Domain generalization aims to address this problem by learning from a set of source domains a model that is generalizable to any unseen domain. In this paper, a novel approach is proposed based on probabilistically mixing instance-level feature statistics of training samples across source domains. Our method, termed MixStyle, is motivated by the observation that visual domain is closely related to image style (e.g., photo vs.~sketch images). Such style information is captured by the bottom layers of a CNN where our proposed style-mixing takes place. Mixing styles of training instances results in novel domains being synthesized implicitly, which increase the domain diversity of the source domains, and hence the generalizability of the trained model. MixStyle fits into mini-batch training perfectly and is extremely easy to implement. The effectiveness of MixStyle is demonstrated on a wide range of tasks including category classification, instance retrieval and reinforcement learning.",
        "conference": "ICLR",
        "中文标题": "使用MixStyle进行领域泛化",
        "摘要翻译": "尽管卷积神经网络（CNNs）在学习判别性特征方面表现出了非凡的能力，但它们往往对未见过的领域泛化能力较差。领域泛化的目标是通过从一组源领域学习一个可以泛化到任何未见领域的模型来解决这个问题。本文提出了一种基于概率混合源领域间训练样本实例级特征统计的新方法。我们的方法，称为MixStyle，其动机是观察到视觉领域与图像风格（例如，照片与素描图像）密切相关。这种风格信息由CNN的底层捕捉，我们提出的风格混合就在这些层进行。混合训练实例的风格会隐式合成新的领域，从而增加了源领域的领域多样性，进而提高了训练模型的泛化能力。MixStyle非常适合小批量训练，并且非常容易实现。MixStyle的有效性在包括类别分类、实例检索和强化学习在内的广泛任务中得到了证明。",
        "领域": "领域泛化、图像风格迁移、深度学习",
        "问题": "解决卷积神经网络在未见领域上泛化能力差的问题",
        "动机": "通过增加训练数据的领域多样性来提高模型的泛化能力",
        "方法": "提出MixStyle方法，通过概率混合源领域间训练样本的实例级特征统计来隐式合成新领域",
        "关键词": [
            "领域泛化",
            "MixStyle",
            "图像风格迁移",
            "卷积神经网络",
            "模型泛化"
        ],
        "涉及的技术概念": {
            "实例级特征统计": "用于捕捉和混合不同训练样本的风格特征，以增加领域多样性",
            "风格混合": "在CNN的底层进行，通过混合不同图像风格来合成新的训练领域",
            "领域多样性": "通过隐式合成新领域来增加，从而提高模型的泛化能力"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 209,
        "title": "Domain-Robust Visual Imitation Learning with Mutual Information Constraints",
        "html": "https://iclr.cc//virtual/2021/poster/2896",
        "abstract": "Human beings are able to understand objectives and learn by simply observing others perform a task. Imitation learning methods aim to replicate such capabilities, however, they generally depend on access to a full set of optimal states and actions taken with the agent's actuators and from the agent's point of view. In this paper, we introduce a new algorithm - called Disentangling Generative Adversarial Imitation Learning (DisentanGAIL) - with the purpose of bypassing such constraints. Our algorithm enables autonomous agents to learn directly from high dimensional observations of an expert performing a task, by making use of adversarial learning with a latent representation inside the discriminator network. Such latent representation is regularized through mutual information constraints to incentivize learning only features that encode information about the completion levels of the task being demonstrated. This allows to obtain a shared feature space to successfully perform imitation while disregarding the differences between the expert's and the agent's domains. Empirically, our algorithm is able to efficiently imitate in a diverse range of control problems including balancing, manipulation and locomotive tasks, while being robust to various domain differences in terms of both environment appearance and agent embodiment.",
        "conference": "ICLR",
        "中文标题": "基于互信息约束的领域鲁棒视觉模仿学习",
        "摘要翻译": "人类能够通过简单地观察他人执行任务来理解目标并学习。模仿学习方法旨在复制这种能力，然而，它们通常依赖于访问一组完整的最优状态和从代理的执行器和视角采取的行动。在本文中，我们介绍了一种新算法——称为解缠生成对抗模仿学习（DisentanGAIL）——目的是绕过这些约束。我们的算法使自主代理能够通过利用判别器网络内部潜在表示的对抗学习，直接从专家执行任务的高维观察中学习。这种潜在表示通过互信息约束进行正则化，以激励仅学习编码关于被演示任务完成水平信息的特征。这允许获得一个共享的特征空间，以成功执行模仿，同时忽略专家和代理领域之间的差异。经验上，我们的算法能够在包括平衡、操作和运动任务在内的多样化控制问题中高效模仿，同时对环境外观和代理体现的各种领域差异表现出鲁棒性。",
        "领域": "模仿学习、生成对抗网络、机器人控制",
        "问题": "模仿学习方法通常需要访问完整的最优状态和动作集，这限制了其应用范围。",
        "动机": "开发一种能够直接从专家观察中学习，而不受限于专家和代理领域差异的模仿学习算法。",
        "方法": "提出了一种名为DisentanGAIL的算法，利用判别器网络中的潜在表示和互信息约束，直接从高维观察中学习，忽略领域差异。",
        "关键词": [
            "模仿学习",
            "生成对抗网络",
            "互信息约束",
            "领域鲁棒性",
            "机器人控制"
        ],
        "涉及的技术概念": {
            "解缠生成对抗模仿学习（DisentanGAIL）": "一种新算法，通过对抗学习和潜在表示正则化，直接从专家观察中学习。",
            "互信息约束": "用于正则化潜在表示，确保学习到的特征仅编码任务完成水平的信息。",
            "领域鲁棒性": "算法能够在不同领域（如环境外观和代理体现）之间保持性能的能力。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 210,
        "title": "Do not Let Privacy Overbill Utility:  Gradient Embedding Perturbation for Private Learning",
        "html": "https://iclr.cc//virtual/2021/poster/2834",
        "abstract": "The privacy leakage of the model about the training data can be bounded in the differential privacy mechanism. However, for meaningful privacy parameters, a differentially private model degrades the utility drastically when the model comprises a large number of trainable parameters.  In this paper, we propose an algorithm  \\emph{Gradient Embedding Perturbation (GEP)} towards training differentially private deep models with decent accuracy. Specifically, in each gradient descent step, GEP first projects individual private gradient into a non-sensitive anchor subspace, producing a low-dimensional gradient embedding and a small-norm residual gradient. Then, GEP perturbs the low-dimensional embedding and the residual gradient separately according to the privacy budget. Such a decomposition permits a small perturbation variance, which greatly helps to break the dimensional barrier of private learning. With GEP, we achieve decent accuracy with low computational cost and modest privacy guarantee for deep models.  Especially, with privacy bound $\\epsilon=8$, we achieve $74.9\\%$ test accuracy on CIFAR10 and $95.1\\%$ test accuracy on  SVHN, significantly improving over existing results.",
        "conference": "ICLR",
        "中文标题": "勿让隐私过度消耗效用：用于隐私学习的梯度嵌入扰动",
        "摘要翻译": "在差分隐私机制下，模型关于训练数据的隐私泄露可以被限定在一定范围内。然而，对于有意义的隐私参数，当模型包含大量可训练参数时，差分隐私模型会显著降低效用。本文提出了一种算法——梯度嵌入扰动（GEP），旨在训练具有良好准确性的差分隐私深度模型。具体而言，在每个梯度下降步骤中，GEP首先将个体私有梯度投影到一个非敏感的锚子空间中，产生一个低维梯度嵌入和一个小范数残差梯度。然后，GEP根据隐私预算分别扰动低维嵌入和残差梯度。这种分解允许小的扰动方差，极大地有助于打破隐私学习的维度障碍。通过GEP，我们以低计算成本和适度的隐私保证为深度模型实现了良好的准确性。特别是在隐私界限ε=8时，我们在CIFAR10上实现了74.9%的测试准确率，在SVHN上实现了95.1%的测试准确率，显著优于现有结果。",
        "领域": "差分隐私学习、深度学习优化、隐私保护机器学习",
        "问题": "如何在保证模型隐私的同时，减少对模型效用的负面影响",
        "动机": "解决差分隐私模型在包含大量可训练参数时效用显著降低的问题",
        "方法": "提出梯度嵌入扰动（GEP）算法，通过将梯度投影到非敏感子空间并分别扰动低维嵌入和残差梯度，以减少扰动方差",
        "关键词": [
            "差分隐私",
            "梯度嵌入扰动",
            "深度学习",
            "隐私保护",
            "模型效用"
        ],
        "涉及的技术概念": {
            "差分隐私": "一种隐私保护框架，确保模型输出对训练数据中的任何单个记录的变化不敏感",
            "梯度嵌入扰动（GEP）": "一种算法，通过将梯度投影到低维子空间并分别扰动，以减少隐私保护对模型效用的影响",
            "锚子空间": "一个非敏感的子空间，用于投影梯度以减少扰动对模型训练的影响"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 211,
        "title": "DOP: Off-Policy Multi-Agent Decomposed Policy Gradients",
        "html": "https://iclr.cc//virtual/2021/poster/2751",
        "abstract": "Multi-agent policy gradient (MAPG) methods recently witness vigorous progress. However, there is a significant performance discrepancy between MAPG methods and state-of-the-art multi-agent value-based approaches. In this paper, we investigate causes that hinder the performance of MAPG algorithms and present a multi-agent decomposed policy gradient method (DOP). This method introduces the idea of value function decomposition into the multi-agent actor-critic framework. Based on this idea, DOP supports efficient off-policy learning and addresses the issue of centralized-decentralized mismatch and credit assignment in both discrete and continuous action spaces. We formally show that DOP critics have sufficient representational capability to guarantee convergence. In addition, empirical evaluations on the StarCraft II micromanagement benchmark and multi-agent particle environments demonstrate that DOP outperforms both state-of-the-art value-based and policy-based multi-agent reinforcement learning algorithms. Demonstrative videos are available at https://sites.google.com/view/dop-mapg/.",
        "conference": "ICLR",
        "中文标题": "DOP：离策略多智能体分解策略梯度",
        "摘要翻译": "多智能体策略梯度（MAPG）方法近年来取得了显著进展。然而，MAPG方法与最先进的多智能体基于价值的方法之间存在显著的性能差距。在本文中，我们研究了阻碍MAPG算法性能的原因，并提出了一种多智能体分解策略梯度方法（DOP）。该方法将价值函数分解的思想引入多智能体演员-评论家框架中。基于这一思想，DOP支持高效的离策略学习，并解决了在离散和连续动作空间中的集中式-分散式不匹配和信用分配问题。我们正式表明，DOP评论家具有足够的表示能力以保证收敛。此外，在《星际争霸II》微操基准和多智能体粒子环境上的实证评估表明，DOP优于最先进的基于价值和基于策略的多智能体强化学习算法。演示视频可在https://sites.google.com/view/dop-mapg/获取。",
        "领域": "多智能体强化学习、策略梯度方法、演员-评论家框架",
        "问题": "解决多智能体策略梯度方法与基于价值方法之间的性能差距问题",
        "动机": "研究多智能体策略梯度算法性能不佳的原因，并提出改进方法",
        "方法": "引入价值函数分解思想到多智能体演员-评论家框架中，支持高效的离策略学习，解决集中式-分散式不匹配和信用分配问题",
        "关键词": [
            "多智能体强化学习",
            "策略梯度",
            "价值函数分解",
            "离策略学习",
            "信用分配"
        ],
        "涉及的技术概念": {
            "多智能体策略梯度（MAPG）": "一种在多智能体环境中直接优化策略以最大化累积奖励的方法",
            "价值函数分解": "将全局价值函数分解为局部价值函数的技术，用于解决多智能体环境中的信用分配问题",
            "离策略学习": "允许智能体从不同于其当前策略生成的数据中学习，提高数据利用效率"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 212,
        "title": "Do Wide and Deep Networks Learn the Same Things? Uncovering How Neural Network Representations Vary with Width and Depth",
        "html": "https://iclr.cc//virtual/2021/poster/2813",
        "abstract": "A key factor in the success of deep neural networks is the ability to scale models to improve performance by varying the architecture depth and width. This simple property of neural network design has resulted in highly effective architectures for a variety of tasks. Nevertheless, there is limited understanding of effects of depth and width on the learned representations. In this paper, we study this fundamental question. We begin by investigating how varying depth and width affects model hidden representations, finding a characteristic block structure in the hidden representations of larger capacity (wider or deeper) models. We demonstrate that this block structure arises when model capacity is large relative to the size of the training set, and is indicative of the underlying layers preserving and propagating the dominant principal component of their representations. This discovery has important ramifications for features learned by different models, namely, representations outside the block structure are often similar across architectures with varying widths and depths, but the block structure is unique to each model. We analyze the output predictions of different model architectures, finding that even when the overall accuracy is similar, wide and deep models exhibit distinctive error patterns and variations across classes.",
        "conference": "ICLR",
        "中文标题": "宽与深的网络学习相同的内容吗？揭示神经网络表示如何随宽度和深度变化",
        "摘要翻译": "深度神经网络成功的一个关键因素是通过改变架构的深度和宽度来扩展模型以提高性能。神经网络设计的这一简单特性已经为各种任务产生了高效的架构。然而，对于深度和宽度对学习表示的影响理解有限。在本文中，我们研究了这个基本问题。我们首先调查了改变深度和宽度如何影响模型的隐藏表示，发现在更大容量（更宽或更深）模型的隐藏表示中存在一种特征性的块结构。我们证明，当模型容量相对于训练集的大小较大时，这种块结构就会出现，并且表明底层层保留并传播了其表示的主要主成分。这一发现对不同模型学习的特征有重要影响，即块结构之外的表示通常在宽度和深度不同的架构之间相似，但块结构对每个模型是独特的。我们分析了不同模型架构的输出预测，发现即使总体准确度相似，宽模型和深模型也表现出独特的错误模式和类别间的变化。",
        "领域": "神经网络架构分析、深度学习理论、模型表示学习",
        "问题": "理解深度和宽度对神经网络学习表示的具体影响",
        "动机": "探索神经网络设计中深度和宽度变化对模型学习表示的影响，以提高模型性能和理解其工作机制",
        "方法": "通过改变模型的深度和宽度，研究其对隐藏表示的影响，发现并分析特征性的块结构及其对模型表示的影响",
        "关键词": [
            "神经网络架构",
            "表示学习",
            "模型容量",
            "块结构",
            "主成分分析"
        ],
        "涉及的技术概念": {
            "块结构": "在更大容量模型的隐藏表示中发现的特征性结构，表明模型保留并传播了其表示的主要主成分",
            "主成分分析": "用于分析和理解模型隐藏表示中保留和传播的主要成分的技术",
            "模型容量": "指模型通过增加深度或宽度来提高性能的能力，是影响学习表示的关键因素"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 213,
        "title": "DrNAS: Dirichlet Neural Architecture Search",
        "html": "https://iclr.cc//virtual/2021/poster/3124",
        "abstract": "This paper proposes a novel differentiable architecture search method by formulating it into a distribution learning problem. We treat the continuously relaxed architecture mixing weight as random variables, modeled by Dirichlet distribution. With recently developed pathwise derivatives, the Dirichlet parameters can be easily optimized with gradient-based optimizer in an end-to-end manner. This formulation improves the generalization ability and induces stochasticity that naturally encourages exploration in the search space. Furthermore, to alleviate the large memory consumption of differentiable NAS, we propose a simple yet effective progressive learning scheme that enables searching directly on large-scale tasks, eliminating the gap between search and evaluation phases. Extensive experiments demonstrate the effectiveness of our method. Specifically, we obtain a test error of 2.46\\% for CIFAR-10, 23.7\\% for ImageNet under the mobile setting. On NAS-Bench-201, we also achieve state-of-the-art results on all three datasets and provide insights for the effective design of neural architecture search algorithms.",
        "conference": "ICLR",
        "中文标题": "DrNAS: 狄利克雷神经架构搜索",
        "摘要翻译": "本文提出了一种新颖的可微分架构搜索方法，将其表述为一个分布学习问题。我们将连续松弛的架构混合权重视为随机变量，通过狄利克雷分布进行建模。利用最近开发的路径导数，狄利克雷参数可以通过基于梯度的优化器以端到端的方式轻松优化。这种表述提高了泛化能力，并引入了随机性，自然鼓励在搜索空间中进行探索。此外，为了减轻可微分NAS的大内存消耗，我们提出了一种简单而有效的渐进学习方案，使得能够直接在大型任务上进行搜索，消除了搜索和评估阶段之间的差距。大量实验证明了我们方法的有效性。具体来说，我们在CIFAR-10上获得了2.46%的测试错误率，在移动设置下的ImageNet上获得了23.7%的错误率。在NAS-Bench-201上，我们还在所有三个数据集上实现了最先进的结果，并为神经架构搜索算法的有效设计提供了见解。",
        "领域": "神经架构搜索、深度学习优化、自动化机器学习",
        "问题": "如何在神经架构搜索中提高泛化能力和探索效率，同时减少内存消耗。",
        "动机": "为了解决传统神经架构搜索方法在泛化能力、探索效率和内存消耗方面的限制。",
        "方法": "提出了一种基于狄利克雷分布的可微分架构搜索方法，结合渐进学习方案以减少内存消耗。",
        "关键词": [
            "狄利克雷分布",
            "可微分架构搜索",
            "渐进学习",
            "神经架构搜索",
            "自动化机器学习"
        ],
        "涉及的技术概念": {
            "狄利克雷分布": "用于建模架构混合权重的随机变量，引入随机性以鼓励探索。",
            "可微分架构搜索": "通过梯度优化方法直接搜索最优神经架构，提高搜索效率。",
            "渐进学习方案": "一种减少内存消耗的技术，允许直接在大型任务上进行架构搜索。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 214,
        "title": "Drop-Bottleneck: Learning Discrete Compressed Representation for Noise-Robust Exploration",
        "html": "https://iclr.cc//virtual/2021/poster/3127",
        "abstract": "We propose a novel information bottleneck (IB) method named Drop-Bottleneck, which discretely drops features that are irrelevant to the target variable. Drop-Bottleneck not only enjoys a simple and tractable compression objective but also additionally provides a deterministic compressed representation of the input variable, which is useful for inference tasks that require consistent representation. Moreover, it can jointly learn a feature extractor and select features considering each feature dimension's relevance to the target task, which is unattainable by most neural network-based IB methods. We propose an exploration method based on Drop-Bottleneck for reinforcement learning tasks. In a multitude of noisy and reward sparse maze navigation tasks in VizDoom (Kempka et al., 2016) and DMLab (Beattie et al., 2016), our exploration method achieves state-of-the-art performance. As a new IB framework, we demonstrate that Drop-Bottleneck outperforms Variational Information Bottleneck (VIB) (Alemi et al., 2017) in multiple aspects including adversarial robustness and dimensionality reduction.",
        "conference": "ICLR",
        "中文标题": "Drop-Bottleneck：学习离散压缩表示以实现噪声鲁棒性探索",
        "摘要翻译": "我们提出了一种新颖的信息瓶颈（IB）方法，名为Drop-Bottleneck，该方法离散地丢弃与目标变量无关的特征。Drop-Bottleneck不仅拥有简单且易于处理的压缩目标，而且还额外提供了输入变量的确定性压缩表示，这对于需要一致表示的推理任务非常有用。此外，它能够联合学习特征提取器并考虑每个特征维度与目标任务的相关性来选择特征，这是大多数基于神经网络的IB方法无法实现的。我们提出了一种基于Drop-Bottleneck的探索方法，用于强化学习任务。在VizDoom（Kempka等人，2016）和DMLab（Beattie等人，2016）中的大量噪声和奖励稀疏的迷宫导航任务中，我们的探索方法实现了最先进的性能。作为一个新的IB框架，我们证明了Drop-Bottleneck在多个方面（包括对抗鲁棒性和降维）优于变分信息瓶颈（VIB）（Alemi等人，2017）。",
        "领域": "强化学习探索、信息瓶颈方法、噪声鲁棒性学习",
        "问题": "如何在噪声和奖励稀疏的环境中有效地进行强化学习探索",
        "动机": "开发一种能够离散地丢弃无关特征、提供确定性压缩表示，并在噪声环境中实现高效探索的信息瓶颈方法",
        "方法": "提出Drop-Bottleneck方法，通过离散地丢弃无关特征来学习压缩表示，并基于此开发强化学习探索策略",
        "关键词": [
            "信息瓶颈",
            "强化学习探索",
            "噪声鲁棒性",
            "特征选择",
            "确定性压缩表示"
        ],
        "涉及的技术概念": {
            "信息瓶颈（IB）": "一种信息理论框架，用于在保持与目标任务相关信息的同时压缩输入数据",
            "Drop-Bottleneck": "一种新颖的IB方法，通过离散地丢弃无关特征来学习压缩表示，适用于噪声环境中的探索任务",
            "变分信息瓶颈（VIB）": "一种基于变分推理的IB方法，Drop-Bottleneck在多个方面（包括对抗鲁棒性和降维）上优于VIB"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 215,
        "title": "Dual-mode ASR: Unify and Improve Streaming ASR with Full-context Modeling",
        "html": "https://iclr.cc//virtual/2021/poster/3075",
        "abstract": "Streaming automatic speech recognition (ASR) aims to emit each hypothesized word as quickly and accurately as possible, while full-context ASR waits for the completion of a full speech utterance before emitting completed hypotheses. In this work, we propose a unified framework, Dual-mode ASR, to train a single end-to-end ASR model with shared weights for both streaming and full-context speech recognition. We show that the latency and accuracy of streaming ASR significantly benefit from weight sharing and joint training of full-context ASR, especially with inplace knowledge distillation during the training. The Dual-mode ASR framework can be applied to recent state-of-the-art convolution-based and transformer-based ASR networks. We present extensive experiments with two state-of-the-art ASR networks, ContextNet and Conformer, on two datasets, a widely used public dataset LibriSpeech and a large-scale dataset MultiDomain. Experiments and ablation studies demonstrate that Dual-mode ASR not only simplifies the workflow of training and deploying streaming and full-context ASR models, but also significantly improves both emission latency and recognition accuracy of streaming ASR. With Dual-mode ASR, we achieve new state-of-the-art streaming ASR results on both LibriSpeech and MultiDomain in terms of accuracy and latency.",
        "conference": "ICLR",
        "中文标题": "双模式自动语音识别：通过全上下文建模统一并改进流式自动语音识别",
        "摘要翻译": "流式自动语音识别（ASR）旨在尽可能快速且准确地发出每个假设的单词，而全上下文ASR则等待完整语音话语完成后才发出完整的假设。在这项工作中，我们提出了一个统一的框架——双模式ASR，用于训练一个共享权重的端到端ASR模型，同时适用于流式和全上下文语音识别。我们展示了流式ASR的延迟和准确性显著受益于权重共享和全上下文ASR的联合训练，特别是在训练期间使用原地知识蒸馏时。双模式ASR框架可以应用于最近基于卷积和基于变换器的最先进ASR网络。我们使用两种最先进的ASR网络——ContextNet和Conformer，在两个数据集上进行了广泛的实验，一个是广泛使用的公共数据集LibriSpeech，另一个是大规模数据集MultiDomain。实验和消融研究表明，双模式ASR不仅简化了训练和部署流式及全上下文ASR模型的工作流程，还显著提高了流式ASR的发射延迟和识别准确性。通过双模式ASR，我们在LibriSpeech和MultiDomain上实现了在准确性和延迟方面新的最先进流式ASR结果。",
        "领域": "语音识别",
        "问题": "如何统一并改进流式自动语音识别和全上下文自动语音识别",
        "动机": "为了简化训练和部署流程，同时提高流式ASR的延迟和准确性",
        "方法": "提出一个统一的框架——双模式ASR，通过共享权重和联合训练流式及全上下文ASR模型，利用原地知识蒸馏优化性能",
        "关键词": [
            "双模式ASR",
            "流式语音识别",
            "全上下文建模",
            "知识蒸馏",
            "端到端模型"
        ],
        "涉及的技术概念": {
            "双模式ASR": "一个统一的框架，用于训练同时适用于流式和全上下文语音识别的共享权重端到端ASR模型",
            "原地知识蒸馏": "在训练期间使用的一种技术，用于优化模型性能，特别是在共享权重和联合训练流式及全上下文ASR模型时",
            "端到端模型": "一种直接从输入到输出进行学习的模型架构，简化了传统语音识别系统中的多个处理步骤"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 216,
        "title": "Dynamic Tensor Rematerialization",
        "html": "https://iclr.cc//virtual/2021/poster/2537",
        "abstract": "Checkpointing enables the training of deep learning models under restricted memory budgets by freeing intermediate activations from memory and recomputing them on demand. Current checkpointing techniques statically plan these recomputations offline and assume static computation graphs. We demonstrate that a simple online algorithm can achieve comparable performance by introducing Dynamic Tensor Rematerialization (DTR), a greedy online algorithm for checkpointing that is extensible and general, is parameterized by eviction policy, and supports dynamic models. We prove that DTR can train an $N$-layer linear feedforward network on an  $\\Omega(\\sqrt{N})$ memory budget with only $\\mathcal{O}(N)$ tensor operations. DTR closely matches the performance of optimal static checkpointing in simulated experiments. We incorporate a DTR prototype into PyTorch merely by interposing on tensor allocations and operator calls and collecting lightweight metadata on tensors.",
        "conference": "ICLR",
        "中文标题": "动态张量重计算",
        "摘要翻译": "检查点技术通过释放中间激活值的内存并按需重新计算，使得在有限内存预算下训练深度学习模型成为可能。当前的检查点技术静态地离线规划这些重新计算，并假设计算图是静态的。我们证明，通过引入动态张量重计算（DTR），一个可扩展且通用的、由驱逐策略参数化的、支持动态模型的贪心在线检查点算法，一个简单的在线算法可以达到类似的性能。我们证明了DTR可以在Ω(√N)的内存预算下，仅用O(N)张量操作训练一个N层线性前馈网络。在模拟实验中，DTR与最优静态检查点的性能非常接近。我们通过仅对张量分配和操作调用进行干预，并收集张量的轻量级元数据，将DTR原型集成到PyTorch中。",
        "领域": "深度学习优化、内存管理、动态计算图",
        "问题": "在有限内存预算下高效训练深度学习模型",
        "动机": "解决静态检查点技术在动态计算图模型中的局限性，提供更灵活的内存管理方案",
        "方法": "提出动态张量重计算（DTR），一种贪心在线算法，通过动态管理张量的存储和重计算来优化内存使用",
        "关键词": [
            "动态张量重计算",
            "内存优化",
            "深度学习训练",
            "在线算法",
            "PyTorch集成"
        ],
        "涉及的技术概念": {
            "动态张量重计算（DTR）": "一种在线算法，用于动态管理深度学习模型中的张量存储和重计算，以优化内存使用",
            "贪心算法": "DTR采用贪心策略来决定哪些张量应该被保留或重计算，以达到内存使用的最优化",
            "内存预算": "指在训练深度学习模型时可用的内存资源限制，DTR旨在在这一限制下最大化模型训练效率"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 217,
        "title": "DynaTune: Dynamic Tensor Program Optimization in Deep Neural Network Compilation",
        "html": "https://iclr.cc//virtual/2021/poster/2753",
        "abstract": "Recently, the DL compiler, together with Learning to Compile has proven to be a powerful technique for optimizing deep learning models. However, existing methods focus on accelerating the convergence speed of the individual tensor operator rather than the convergence speed of the entire model, which results in long optimization time to obtain a desired latency.\n\nIn this paper, we present a new method called DynaTune, which provides significantly faster convergence speed to optimize a DNN model. In particular, we consider a Multi-Armed Bandit (MAB) model for the tensor program optimization problem. We use UCB to handle the decision-making of time-slot-based optimization, and we devise a Bayesian belief model that allows predicting the potential performance gain of each operator with uncertainty quantification, which guides the optimization process. We evaluate and compare DynaTune with the state-of-the-art DL compiler. The experiment results show that DynaTune is 1.2--2.4 times faster to achieve the same optimization quality for a range of models across different hardware architectures. ",
        "conference": "ICLR",
        "中文标题": "DynaTune：深度神经网络编译中的动态张量程序优化",
        "摘要翻译": "最近，深度学习（DL）编译器与学习编译技术相结合，已被证明是优化深度学习模型的强大技术。然而，现有方法侧重于加速单个张量操作符的收敛速度，而非整个模型的收敛速度，这导致获得期望延迟所需的优化时间较长。在本文中，我们提出了一种名为DynaTune的新方法，它能显著加快优化深度神经网络（DNN）模型的收敛速度。具体而言，我们将张量程序优化问题视为一个多臂老虎机（MAB）模型。我们使用UCB（上置信界）来处理基于时间槽优化的决策制定，并设计了一个贝叶斯信念模型，该模型能够预测每个操作符在不确定性量化下的潜在性能增益，从而指导优化过程。我们对DynaTune与最先进的DL编译器进行了评估和比较。实验结果表明，对于跨不同硬件架构的一系列模型，DynaTune在达到相同优化质量时快1.2至2.4倍。",
        "领域": "深度学习编译器优化、张量程序优化、多臂老虎机模型应用",
        "问题": "现有深度学习编译器优化方法在优化整个模型的收敛速度上效率不高，导致优化时间较长。",
        "动机": "提高深度学习模型优化的整体收敛速度，减少优化时间。",
        "方法": "提出DynaTune方法，采用多臂老虎机模型和贝叶斯信念模型，结合UCB算法优化张量程序。",
        "关键词": [
            "深度学习编译器",
            "张量程序优化",
            "多臂老虎机模型",
            "贝叶斯信念模型",
            "UCB算法"
        ],
        "涉及的技术概念": {
            "多臂老虎机模型": "用于建模张量程序优化问题，帮助在多个可能的优化策略中选择最优策略。",
            "贝叶斯信念模型": "用于预测每个张量操作符的潜在性能增益，包括不确定性量化，以指导优化过程。",
            "UCB算法": "用于处理基于时间槽的优化决策制定，平衡探索和利用，以加速优化过程。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 218,
        "title": "Early Stopping in Deep Networks: Double Descent and How to Eliminate it",
        "html": "https://iclr.cc//virtual/2021/poster/2647",
        "abstract": "Over-parameterized models, such as large deep networks, often exhibit a double descent phenomenon, whereas a function of model size, error first decreases, increases, and decreases at last. This intriguing double descent behavior also occurs as a function of training epochs and has been conjectured to arise because training epochs control the model complexity. In this paper, we show that such epoch-wise double descent occurs for a different reason: It is caused by a superposition of two or more bias-variance tradeoffs that arise because different parts of the network are learned at different epochs, and mitigating this by proper scaling of stepsizes can significantly improve the early stopping performance. We show this analytically for i) linear regression, where differently scaled features give rise to a superposition of bias-variance tradeoffs, and for ii) a wide two-layer neural network, where the first and second layers govern bias-variance tradeoffs. Inspired by this theory, we study two standard convolutional networks empirically and show that eliminating epoch-wise double descent through adjusting stepsizes of different layers improves the early stopping performance.",
        "conference": "ICLR",
        "中文标题": "深度网络中的早停：双下降现象及其消除方法",
        "摘要翻译": "过参数化模型，如大型深度网络，常常表现出双下降现象，即随着模型大小的变化，误差首先减小，然后增大，最后再次减小。这种引人注目的双下降行为也随着训练周期的变化而发生，并且被推测是因为训练周期控制了模型的复杂性。在本文中，我们展示了这种周期性的双下降现象出于不同的原因：它是由两个或多个偏差-方差权衡的叠加引起的，这些权衡因为网络的不同部分在不同的周期被学习而产生，而通过适当调整步长可以显著改善早停性能。我们通过分析展示了这一点：i) 对于线性回归，不同缩放的特征导致了偏差-方差权衡的叠加；ii) 对于一个宽的两层神经网络，第一层和第二层主导了偏差-方差权衡。受此理论启发，我们实证研究了两类标准卷积网络，并展示了通过调整不同层的步长消除周期性双下降现象，从而改善了早停性能。",
        "领域": "深度学习优化、神经网络训练、模型泛化",
        "问题": "解决深度网络训练中出现的双下降现象及其对早停性能的影响",
        "动机": "探究周期性双下降现象的根本原因，并提出改善早停性能的方法",
        "方法": "通过理论分析和实证研究，调整不同层的步长以消除周期性双下降现象",
        "关键词": [
            "双下降现象",
            "早停",
            "偏差-方差权衡",
            "步长调整",
            "深度学习优化"
        ],
        "涉及的技术概念": {
            "双下降现象": "描述模型误差随模型大小或训练周期变化先减后增再减的现象",
            "偏差-方差权衡": "模型复杂度和泛化能力之间的平衡，影响模型性能",
            "步长调整": "通过调整学习率来控制不同层的学习速度，以优化训练过程"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 219,
        "title": "Economic Hyperparameter Optimization With Blended Search Strategy",
        "html": "https://iclr.cc//virtual/2021/poster/3052",
        "abstract": "We study the problem of using low cost to search for hyperparameter configurations in a large search space with heterogeneous evaluation cost and model quality.\nWe propose a blended search strategy to combine the strengths of global and local search, and prioritize them on the fly with the goal of minimizing the total cost spent in finding good configurations. Our approach demonstrates robust performance for tuning both tree-based models and deep neural networks on a large AutoML benchmark, as well as superior performance in model quality, time, and resource consumption for a production transformer-based NLP model fine-tuning task.",
        "conference": "ICLR",
        "中文标题": "经济型超参数优化与混合搜索策略",
        "摘要翻译": "我们研究了在具有异构评估成本和模型质量的大搜索空间中以低成本搜索超参数配置的问题。我们提出了一种混合搜索策略，结合了全局和局部搜索的优势，并根据实时目标动态优先考虑它们，以最小化在寻找良好配置过程中所花费的总成本。我们的方法在大型AutoML基准测试中调整基于树的模型和深度神经网络时表现出稳健的性能，并在基于Transformer的NLP模型微调任务中，在模型质量、时间和资源消耗方面表现出卓越的性能。",
        "领域": "自动化机器学习（AutoML）、超参数优化、深度学习模型调优",
        "问题": "在大规模异构评估成本和模型质量的搜索空间中，如何以低成本高效搜索最优超参数配置。",
        "动机": "为了在资源有限的情况下，高效地找到高质量的超参数配置，减少模型调优的时间和成本。",
        "方法": "提出一种混合搜索策略，动态结合全局和局部搜索的优势，实时调整搜索优先级，以最小化总成本。",
        "关键词": [
            "超参数优化",
            "混合搜索策略",
            "AutoML",
            "深度学习调优",
            "成本效率"
        ],
        "涉及的技术概念": {
            "混合搜索策略": "结合全局和局部搜索的方法，动态调整搜索优先级，以提高搜索效率和效果。",
            "超参数优化": "自动化调整模型参数以优化模型性能的过程，特别是在大规模搜索空间中。",
            "AutoML": "自动化机器学习，旨在自动化模型选择和调优过程，减少人工干预。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 220,
        "title": "EEC: Learning to Encode and Regenerate Images for Continual Learning",
        "html": "https://iclr.cc//virtual/2021/poster/2587",
        "abstract": "The two main impediments to continual learning are catastrophic forgetting and memory limitations on the storage of data. To cope with these challenges, we propose a novel, cognitively-inspired approach which trains autoencoders with Neural Style Transfer to encode and store images. Reconstructed images from encoded episodes are replayed when training the classifier model on a new task to avoid catastrophic forgetting. The loss function for the reconstructed images is weighted to reduce its effect during classifier training to cope with image degradation. When the system runs out of memory the encoded episodes are converted into centroids and covariance matrices, which are used to generate pseudo-images during classifier training, keeping classifier performance stable with less memory. Our approach increases classification accuracy by 13-17% over state-of-the-art methods on benchmark datasets, while requiring 78% less storage space.",
        "conference": "ICLR",
        "中文标题": "EEC：学习编码与再生图像以实现持续学习",
        "摘要翻译": "持续学习的两大障碍是灾难性遗忘和数据存储的内存限制。为了应对这些挑战，我们提出了一种新颖的、受认知启发的学习方法，该方法通过神经风格转移训练自编码器来编码和存储图像。在分类器模型训练新任务时，重放从编码片段重建的图像以避免灾难性遗忘。重建图像的损失函数被加权，以减少其在分类器训练期间的影响，从而应对图像退化。当系统内存不足时，编码片段被转换为质心和协方差矩阵，用于在分类器训练期间生成伪图像，以较少的内存保持分类器性能稳定。我们的方法在基准数据集上比最先进的方法提高了13-17%的分类准确率，同时减少了78%的存储空间需求。",
        "领域": "持续学习、图像编码与再生、神经风格转移",
        "问题": "解决持续学习中的灾难性遗忘和内存限制问题",
        "动机": "通过编码和再生图像来减少存储需求并避免灾难性遗忘，提高持续学习的效率和效果",
        "方法": "使用神经风格转移训练自编码器编码和存储图像，通过加权损失函数减少重建图像的影响，内存不足时使用质心和协方差矩阵生成伪图像",
        "关键词": [
            "持续学习",
            "图像编码",
            "神经风格转移",
            "灾难性遗忘",
            "内存优化"
        ],
        "涉及的技术概念": {
            "神经风格转移": "用于训练自编码器编码和存储图像，以实现图像风格和内容的分离与重组",
            "自编码器": "用于编码和存储图像，减少存储需求并支持图像重建",
            "质心和协方差矩阵": "在内存不足时用于生成伪图像，保持分类器性能稳定"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 221,
        "title": "Effective Abstract Reasoning with Dual-Contrast Network",
        "html": "https://iclr.cc//virtual/2021/poster/2833",
        "abstract": "As a step towards improving the abstract reasoning capability of machines, we aim to solve Raven’s Progressive Matrices (RPM) with neural networks, since solving RPM puzzles is highly correlated with human intelligence. Unlike previous methods that use auxiliary annotations or assume hidden rules to produce appropriate feature representation, we only use the ground truth answer of each question for model learning,  aiming for an intelligent agent to have a strong learning capability with a small amount of supervision.  Based on the RPM problem formulation,  the correct answer filled into the missing entry of the third row/column has  to  best  satisfy  the  same  rules  shared  between  the  first  two  rows/columns.Thus  we  design  a  simple  yet  effective  Dual-Contrast  Network  (DCNet)  to  exploit the inherent structure of RPM puzzles.  Specifically, a rule contrast module is  designed  to  compare  the  latent  rules  between  the  filled  row/column  and  the first two rows/columns; a choice contrast module is designed to increase the relative differences between candidate choices.  Experimental results on the RAVEN and  PGM  datasets  show  that  DCNet  outperforms  the  state-of-the-art  methods by a large margin of 5.77%.   Further experiments on few training samples and model generalization also show the effectiveness of DCNet.  Code is available at https://github.com/visiontao/dcnet.",
        "conference": "ICLR",
        "中文标题": "利用双对比网络进行有效抽象推理",
        "摘要翻译": "作为提升机器抽象推理能力的一步，我们旨在利用神经网络解决瑞文渐进矩阵（RPM）问题，因为解决RPM谜题与人类智能高度相关。不同于以往使用辅助注释或假设隐藏规则以产生适当特征表示的方法，我们仅使用每个问题的真实答案进行模型学习，旨在使智能代理在少量监督下具备强大的学习能力。基于RPM问题的表述，填入第三行/列缺失处的正确答案必须最好地满足前两行/列共享的相同规则。因此，我们设计了一个简单而有效的双对比网络（DCNet）来利用RPM谜题的固有结构。具体而言，设计了一个规则对比模块来比较填充行/列与前两行/列之间的潜在规则；设计了一个选择对比模块来增加候选选择之间的相对差异。在RAVEN和PGM数据集上的实验结果表明，DCNet以5.77%的大幅度优于现有最先进方法。关于少量训练样本和模型泛化的进一步实验也显示了DCNet的有效性。代码可在https://github.com/visiontao/dcnet获取。",
        "领域": "抽象推理、神经网络应用、智能代理",
        "问题": "解决瑞文渐进矩阵（RPM）问题，提升机器的抽象推理能力",
        "动机": "旨在使智能代理在少量监督下具备强大的学习能力，解决与人类智能高度相关的RPM谜题",
        "方法": "设计双对比网络（DCNet），包括规则对比模块和选择对比模块，利用RPM谜题的固有结构进行学习",
        "关键词": [
            "抽象推理",
            "瑞文渐进矩阵",
            "双对比网络",
            "神经网络",
            "智能代理"
        ],
        "涉及的技术概念": {
            "双对比网络（DCNet）": "设计用于解决RPM问题的网络，包含规则对比和选择对比两个模块，以提高模型的抽象推理能力",
            "规则对比模块": "比较填充行/列与前两行/列之间的潜在规则，确保填入的答案满足共享规则",
            "选择对比模块": "增加候选选择之间的相对差异，帮助模型更准确地区分最佳答案"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 222,
        "title": "Effective and Efficient Vote Attack on Capsule Networks",
        "html": "https://iclr.cc//virtual/2021/poster/2711",
        "abstract": "Standard Convolutional Neural Networks (CNNs) can be easily fooled by images with small quasi-imperceptible artificial perturbations. As alternatives to CNNs, the recently proposed Capsule Networks (CapsNets) are shown to be more robust to white-box attack than CNNs under popular attack protocols. Besides, the class-conditional reconstruction part of CapsNets is also used to detect adversarial examples. In this work, we investigate the adversarial robustness of CapsNets, especially how the inner workings of CapsNets change when the output capsules are attacked. The first observation is that adversarial examples misled CapsNets by manipulating the votes from primary capsules. Another observation is the high computational cost, when we directly apply multi-step attack methods designed for CNNs to attack CapsNets, due to the computationally expensive routing mechanism. Motivated by these two observations, we propose a novel vote attack where we attack votes of CapsNets directly. Our vote attack is not only effective, but also efficient by circumventing the routing process. Furthermore, we integrate our vote attack into the detection-aware attack paradigm, which can successfully bypass the class-conditional reconstruction based detection method. Extensive experiments demonstrate the superior attack performance of our vote attack on CapsNets.",
        "conference": "ICLR",
        "中文标题": "针对胶囊网络的有效且高效投票攻击",
        "摘要翻译": "标准的卷积神经网络（CNNs）容易被带有微小、几乎不可察觉的人工扰动的图像所欺骗。作为CNNs的替代方案，最近提出的胶囊网络（CapsNets）在流行的攻击协议下显示出比CNNs更强的白盒攻击鲁棒性。此外，CapsNets的类条件重建部分也被用于检测对抗样本。在这项工作中，我们研究了CapsNets的对抗鲁棒性，特别是当输出胶囊受到攻击时，CapsNets的内部工作机制如何变化。第一个观察是，对抗样本通过操纵来自初级胶囊的投票误导了CapsNets。另一个观察是，当我们直接将为CNNs设计的多步攻击方法应用于攻击CapsNets时，由于计算昂贵的路由机制，导致高计算成本。基于这两个观察，我们提出了一种新颖的投票攻击，直接攻击CapsNets的投票。我们的投票攻击不仅有效，而且通过绕过路由过程实现了高效。此外，我们将投票攻击集成到检测感知攻击范式中，可以成功绕过基于类条件重建的检测方法。大量实验证明了我们的投票攻击在CapsNets上的优越攻击性能。",
        "领域": "对抗性攻击、胶囊网络、深度学习安全",
        "问题": "研究胶囊网络在对抗攻击下的鲁棒性，特别是攻击如何通过操纵胶囊间的投票影响网络决策",
        "动机": "探索胶囊网络对抗攻击的脆弱性，并提出一种绕过其路由机制的高效攻击方法",
        "方法": "提出直接攻击胶囊网络投票的方法，绕过昂贵的路由过程，并将此攻击方法集成到检测感知攻击范式中",
        "关键词": [
            "胶囊网络",
            "对抗性攻击",
            "投票攻击",
            "路由机制",
            "检测感知攻击"
        ],
        "涉及的技术概念": {
            "胶囊网络": "一种替代传统卷积神经网络的架构，通过胶囊和动态路由机制捕捉实体间的空间层次关系",
            "投票攻击": "直接针对胶囊网络中的投票机制设计的攻击方法，有效且高效",
            "路由机制": "胶囊网络中用于决定信息如何在不同胶囊间传递的机制，计算成本高"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 223,
        "title": "Effective Distributed Learning with Random Features: Improved Bounds and Algorithms",
        "html": "https://iclr.cc//virtual/2021/poster/2922",
        "abstract": "In this paper, we study the statistical properties of distributed kernel ridge regression together with random features (DKRR-RF), and obtain optimal generalization bounds under the basic setting, which can substantially relax the restriction on the number of local machines in the existing state-of-art bounds. Specifically, we first show that the simple combination of divide-and-conquer technique and random features can achieve the same statistical accuracy as the exact KRR in expectation requiring only $\\mathcal{O}(|\\mathcal{D}|)$ memory and $\\mathcal{O}(|\\mathcal{D}|^{1.5})$ time. Then, beyond the generalization bounds in expectation that demonstrate the average information for multiple trails, we derive generalization bounds in probability to capture the learning performance for a single trail. Finally, we propose an effective communication strategy to further improve the performance of DKRR-RF, and validate the theoretical bounds via numerical experiments.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "基于随机特征的有效分布式学习：改进的界限和算法",
        "摘要翻译": "本文研究了分布式核岭回归与随机特征（DKRR-RF）的统计特性，并在基本设置下获得了最优的泛化界限，这可以大大放宽现有最佳界限中对本地机器数量的限制。具体而言，我们首先证明了分而治之技术和随机特征的简单组合可以达到与精确核岭回归相同的统计精度，期望只需要O(|D|)的内存和O(|D|^1.5)的时间。然后，除了展示多次试验平均信息的期望泛化界限外，我们还推导了概率泛化界限，以捕捉单次试验的学习性能。最后，我们提出了一种有效的通信策略来进一步提高DKRR-RF的性能，并通过数值实验验证了理论界限。",
        "领域": "分布式机器学习, 核方法, 统计学习理论",
        "问题": "如何提高分布式核岭回归在随机特征下的泛化性能，并降低对本地机器数量的限制。",
        "动机": "现有的分布式核岭回归方法对本地机器数量有限制，且泛化性能有待提高，因此需要研究更有效的分布式学习算法。",
        "方法": "采用分而治之的技术与随机特征相结合，推导出期望和概率泛化界限，并提出一种有效的通信策略来优化算法性能。",
        "关键词": [
            "分布式学习",
            "核岭回归",
            "随机特征",
            "泛化界限",
            "通信策略"
        ],
        "涉及的技术概念": {
            "随机特征": "使用随机特征来近似核函数，从而降低计算复杂度并加速训练过程。",
            "泛化界限": "理论上衡量模型在未见数据上的性能，用于分析算法的统计性质。"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 224,
        "title": "Efficient Certified Defenses Against Patch Attacks on Image Classifiers",
        "html": "https://iclr.cc//virtual/2021/poster/2629",
        "abstract": "Adversarial patches pose a realistic threat model for physical world attacks on autonomous systems via their perception component. Autonomous systems in safety-critical domains such as automated driving should thus contain a fail-safe fallback component that combines certifiable robustness against patches with efficient inference while maintaining high performance on clean inputs. We propose BagCert, a novel combination of model architecture and certification procedure that allows efficient certification. We derive a loss that enables end-to-end optimization of certified robustness against patches of different sizes and locations. On CIFAR10, BagCert certifies 10.000 examples in 43 seconds on a single GPU and obtains 86% clean and 60% certified accuracy against 5x5 patches.",
        "conference": "ICLR",
        "中文标题": "针对图像分类器补丁攻击的高效认证防御",
        "摘要翻译": "对抗性补丁通过感知组件对自主系统构成现实世界攻击的实际威胁模型。因此，在安全关键领域（如自动驾驶）的自主系统应包含一个故障安全回退组件，该组件结合了对补丁的可认证鲁棒性与高效推理，同时保持对干净输入的高性能。我们提出了BagCert，一种新颖的模型架构和认证程序组合，允许高效认证。我们推导出一种损失，使得能够端到端优化针对不同大小和位置补丁的认证鲁棒性。在CIFAR10上，BagCert在单个GPU上43秒内认证了10,000个例子，并获得了86%的干净准确率和针对5x5补丁的60%认证准确率。",
        "领域": "对抗性攻击防御、图像分类、自动驾驶安全",
        "问题": "如何在保持高清洁输入性能的同时，提供对对抗性补丁攻击的高效认证防御。",
        "动机": "对抗性补丁对自主系统的感知组件构成实际威胁，特别是在安全关键领域如自动驾驶中，需要一种既能够提供可认证鲁棒性又能保持高效推理的防御机制。",
        "方法": "提出BagCert，一种结合了特定模型架构和认证程序的方法，通过端到端优化损失函数来认证不同大小和位置补丁的鲁棒性。",
        "关键词": [
            "对抗性补丁",
            "认证防御",
            "图像分类",
            "自动驾驶安全",
            "高效推理"
        ],
        "涉及的技术概念": {
            "对抗性补丁": "一种通过在图像中添加特定补丁来欺骗分类器的攻击方法，论文中针对此类攻击提出了防御机制。",
            "认证鲁棒性": "论文中提出的方法能够提供数学上的保证，证明模型对于特定大小的对抗性补丁攻击具有鲁棒性。",
            "端到端优化": "通过优化特定的损失函数，论文中的方法能够同时处理不同大小和位置的对抗性补丁，提高模型的防御能力。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 225,
        "title": "Efficient Conformal Prediction via Cascaded Inference with Expanded Admission",
        "html": "https://iclr.cc//virtual/2021/poster/2933",
        "abstract": "In this paper, we present a novel approach for conformal prediction (CP), in which we aim to identify a set of promising prediction candidates---in place of a single prediction. This set is guaranteed to contain a correct answer with high probability, and is well-suited for many open-ended classification tasks. In the standard CP paradigm, the predicted set can often be unusably large and also costly to obtain. This is particularly pervasive in settings where the correct answer is not unique, and the number of total possible answers is high. We first expand the CP correctness criterion to allow for additional, inferred 'admissible' answers, which can substantially reduce the size of the predicted set while still providing valid performance guarantees. Second, we amortize costs by conformalizing prediction cascades, in which we aggressively prune implausible labels early on by using progressively stronger classifiers---again, while still providing valid performance guarantees. We demonstrate the empirical effectiveness of our approach for multiple applications in natural language processing and computational chemistry for drug discovery.",
        "conference": "ICLR",
        "中文标题": "通过级联推理与扩展准入实现高效共形预测",
        "摘要翻译": "本文提出了一种新颖的共形预测（CP）方法，旨在识别一组有希望的预测候选，而非单一预测。这组候选保证以高概率包含正确答案，非常适合许多开放式分类任务。在标准的CP范式中，预测集往往过大且获取成本高昂。这在正确答案不唯一且总可能答案数量众多的设置中尤为普遍。我们首先扩展了CP的正确性标准，允许额外的推断‘可接受’答案，这可以显著减小预测集的规模，同时仍提供有效的性能保证。其次，我们通过共形化预测级联来分摊成本，其中我们通过使用逐渐增强的分类器早期积极修剪不合理的标签——同样，同时仍提供有效的性能保证。我们展示了我们的方法在自然语言处理和计算化学药物发现等多个应用中的实证有效性。",
        "领域": "自然语言处理, 计算化学, 药物发现",
        "问题": "解决共形预测中预测集过大和获取成本高的问题",
        "动机": "在开放式分类任务中，提供一组包含正确答案的预测候选，同时减少预测集的大小和计算成本",
        "方法": "扩展CP的正确性标准以包含额外‘可接受’答案，并通过共形化预测级联来分摊成本",
        "关键词": [
            "共形预测",
            "预测级联",
            "自然语言处理",
            "计算化学",
            "药物发现"
        ],
        "涉及的技术概念": {
            "共形预测": "一种统计方法，用于生成包含正确答案的预测集，保证一定的置信水平",
            "预测级联": "通过一系列逐渐增强的分类器逐步修剪不合理的预测候选，以提高效率",
            "可接受答案": "在共形预测中，除了标准答案外，允许的额外正确答案，用于减小预测集的大小"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 226,
        "title": "Efficient Continual Learning with Modular Networks and Task-Driven Priors",
        "html": "https://iclr.cc//virtual/2021/poster/3040",
        "abstract": "Existing literature in Continual Learning (CL) has focused on overcoming catastrophic forgetting, the inability of the learner to recall how to perform tasks observed in the past. \nThere are however other desirable properties of a CL system, such as the ability to transfer knowledge from previous tasks and to scale memory and compute sub-linearly with the number of tasks. Since most current benchmarks focus only on forgetting using short streams of tasks, we first propose a new suite of benchmarks to probe CL algorithms across these new axes. \nFinally, we introduce a new modular architecture, whose modules represent atomic skills that can be composed to perform a certain task. Learning a task reduces to figuring out which past modules to re-use, and which new modules to instantiate to solve the current task. Our learning algorithm leverages a task-driven prior over the exponential search space of all possible ways to combine modules, enabling efficient learning on long streams of tasks. \nOur experiments show that this modular architecture and learning algorithm perform competitively on widely used CL benchmarks while yielding superior performance on the more challenging benchmarks we introduce in this work. The Benchmark is publicly available at https://github.com/facebookresearch/CTrLBenchmark.",
        "conference": "ICLR",
        "中文标题": "高效持续学习：模块化网络与任务驱动先验",
        "摘要翻译": "现有的持续学习（CL）文献主要集中于克服灾难性遗忘，即学习者无法回忆如何执行过去观察到的任务。然而，持续学习系统还有其他理想属性，如能够从先前任务中转移知识，以及能够随着任务数量的增加而以亚线性方式扩展内存和计算。由于当前大多数基准测试仅关注使用短任务流的遗忘问题，我们首先提出了一套新的基准测试，以在这些新维度上探究持续学习算法。最后，我们介绍了一种新的模块化架构，其模块代表可以组合以执行特定任务的原子技能。学习一个任务简化为确定重用哪些过去的模块，以及实例化哪些新模块来解决当前任务。我们的学习算法利用了一个任务驱动的先验，在所有可能的模块组合方式的指数搜索空间上，实现了在长任务流上的高效学习。我们的实验表明，这种模块化架构和学习算法在广泛使用的持续学习基准测试上表现具有竞争力，同时在我们引入的更具挑战性的基准测试上表现出更优的性能。该基准测试公开于https://github.com/facebookresearch/CTrLBenchmark。",
        "领域": "持续学习、模块化神经网络、任务驱动学习",
        "问题": "解决持续学习中的灾难性遗忘问题，同时实现知识转移和资源的高效利用。",
        "动机": "探索持续学习系统除了克服灾难性遗忘外，还应具备的其他理想属性，如知识转移能力和资源的高效扩展能力。",
        "方法": "提出一种模块化架构和任务驱动的先验学习算法，通过重用和实例化模块来高效学习长任务流。",
        "关键词": [
            "持续学习",
            "模块化网络",
            "任务驱动先验",
            "灾难性遗忘",
            "知识转移"
        ],
        "涉及的技术概念": {
            "模块化架构": "一种将学习任务分解为可重用和可组合的原子技能模块的架构。",
            "任务驱动先验": "一种在学习过程中指导模块选择和组合的策略，以提高学习效率和效果。",
            "灾难性遗忘": "持续学习中的一个主要挑战，指的是在学习新任务时忘记如何执行旧任务的现象。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 227,
        "title": "Efficient Empowerment Estimation for Unsupervised Stabilization",
        "html": "https://iclr.cc//virtual/2021/poster/3285",
        "abstract": "Intrinsically motivated artificial agents learn advantageous behavior without externally-provided rewards. Previously, it was shown that maximizing mutual information between agent actuators and future states, known as the empowerment principle, enables unsupervised stabilization of dynamical systems at upright positions, which is a prototypical intrinsically motivated behavior for upright standing and walking. This follows from the coincidence between the objective of stabilization and the objective of empowerment. Unfortunately, sample-based estimation of this kind of mutual information is challenging. Recently, various variational lower bounds (VLBs) on empowerment have been proposed as solutions; however, they are often biased, unstable in training, and have high sample complexity. In this work, we propose an alternative solution based on a trainable representation of a dynamical system as a Gaussian channel, which allows us to efficiently calculate an unbiased estimator of empowerment by convex optimization. We demonstrate our solution for sample-based unsupervised stabilization on different dynamical control systems and show the advantages of our method by comparing it to the existing VLB approaches. Specifically, we show that our method has a lower sample complexity, is more stable in training, possesses the essential properties of the empowerment function, and allows estimation of empowerment from images. Consequently, our method opens a path to wider and easier adoption of empowerment for various applications.",
        "conference": "ICLR",
        "中文标题": "高效的无监督稳定化赋能估计",
        "摘要翻译": "内在动机的人工智能代理无需外部提供的奖励即可学习有利行为。先前研究表明，最大化代理执行器与未来状态之间的互信息，即赋能原则，能够实现动态系统在直立位置的无监督稳定化，这是直立站立和行走的典型内在动机行为。这源于稳定化目标与赋能目标的一致性。然而，基于样本的此类互信息估计具有挑战性。最近，提出了各种赋能变分下界（VLBs）作为解决方案；然而，它们往往存在偏差、训练不稳定且样本复杂度高。在本工作中，我们提出了一种基于将动态系统可训练表示为高斯通道的替代解决方案，这使我们能够通过凸优化高效计算无偏的赋能估计器。我们在不同的动态控制系统上展示了基于样本的无监督稳定化解决方案，并通过与现有VLB方法的比较展示了我们方法的优势。具体而言，我们展示了我们的方法具有更低的样本复杂度、训练更稳定、拥有赋能函数的基本特性，并允许从图像中估计赋能。因此，我们的方法为赋能在各种应用中的更广泛和更容易采用开辟了道路。",
        "领域": "强化学习、动态系统控制、无监督学习",
        "问题": "如何高效且无偏地估计赋能，以实现动态系统的无监督稳定化",
        "动机": "解决现有赋能变分下界方法在样本复杂度高、训练不稳定和存在偏差方面的问题",
        "方法": "提出一种基于将动态系统表示为高斯通道的方法，通过凸优化高效计算无偏的赋能估计器",
        "关键词": [
            "赋能估计",
            "无监督稳定化",
            "高斯通道",
            "凸优化",
            "动态系统控制"
        ],
        "涉及的技术概念": {
            "赋能原则": "通过最大化代理执行器与未来状态之间的互信息来实现动态系统的无监督稳定化",
            "变分下界（VLBs）": "用于估计赋能的方法，但存在偏差、训练不稳定和样本复杂度高的问题",
            "高斯通道": "将动态系统表示为高斯通道，以高效计算无偏的赋能估计器"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 228,
        "title": "Efficient Generalized Spherical CNNs",
        "html": "https://iclr.cc//virtual/2021/poster/2722",
        "abstract": "Many problems across computer vision and the natural sciences require the analysis of spherical data, for which representations may be learned efficiently by encoding equivariance to rotational symmetries.  We present a generalized spherical CNN framework that encompasses various existing approaches and allows them to be leveraged alongside each other.  The only existing non-linear spherical CNN layer that is strictly equivariant has complexity $\\mathcal{O}(C^2L^5)$, where $C$ is a measure of representational capacity and $L$ the spherical harmonic bandlimit.  Such a high computational cost often prohibits the use of strictly equivariant spherical CNNs.  We develop two new strictly equivariant layers with reduced complexity $\\mathcal{O}(CL^4)$ and $\\mathcal{O}(CL^3 \\log L)$, making larger, more expressive models computationally feasible.  Moreover, we adopt efficient sampling theory to achieve further computational savings. We show that these developments allow the construction of more expressive hybrid models that achieve state-of-the-art accuracy and parameter efficiency on spherical benchmark problems.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "高效的广义球面卷积神经网络",
        "摘要翻译": "计算机视觉和自然科学中的许多问题都需要分析球面数据，通过编码对旋转对称性的等变性，可以有效地学习球面数据的表示。我们提出了一个广义球面CNN框架，该框架包含各种现有方法，并允许它们相互利用。目前唯一严格等变的非线性球面CNN层的复杂度为O(C^2L^5)，其中C是表示容量的度量，L是球谐带限。如此高的计算成本通常会禁止使用严格等变的球面CNN。我们开发了两种新的严格等变层，其复杂度降低为O(CL^4)和O(CL^3 log L)，使得更大、更具表现力的模型在计算上可行。此外，我们采用高效的采样理论来实现进一步的计算节省。我们表明，这些发展使得构建更具表现力的混合模型成为可能，从而在球面基准问题上实现最先进的准确性和参数效率。",
        "领域": "球面图像分析, 等变神经网络, 几何深度学习",
        "问题": "现有严格等变的球面CNN计算复杂度高，限制了其在实际问题中的应用。",
        "动机": "降低球面CNN的计算复杂度，使其能够应用于更大、更复杂的模型，从而提升在球面数据分析任务中的性能。",
        "方法": "开发了两种新的严格等变层，降低了计算复杂度，并采用高效采样理论进一步节省计算资源。通过构建混合模型，结合不同方法的优势。",
        "关键词": [
            "球面CNN",
            "等变性",
            "计算效率",
            "球谐函数",
            "采样理论"
        ],
        "涉及的技术概念": {
            "等变性": "确保模型输出以与输入相同的形式变换，这对于处理具有对称性的数据至关重要。论文中保证了模型对于旋转操作的等变性。",
            "球谐函数": "用于在球面上表示信号的基函数。论文中，球谐函数被用于构建球面卷积操作。"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 229,
        "title": "Efficient Inference of Flexible Interaction in Spiking-neuron Networks",
        "html": "https://iclr.cc//virtual/2021/poster/2648",
        "abstract": "Hawkes process provides an effective statistical framework for analyzing the time-dependent interaction of neuronal spiking activities. Although utilized in many real applications, the classic Hawkes process is incapable of modelling inhibitory interactions among neurons. Instead, the nonlinear Hawkes process allows for a more flexible influence pattern with excitatory or inhibitory interactions. In this paper, three sets of auxiliary latent variables (Polya-Gamma variables, latent marked Poisson processes and sparsity variables) are augmented to make functional connection weights in a Gaussian form, which allows for a simple iterative algorithm with analytical updates. As a result, an efficient expectation-maximization (EM) algorithm is derived to obtain the maximum a posteriori (MAP) estimate. We demonstrate the accuracy and efficiency performance of our algorithm on synthetic and real data. For real neural recordings, we show our algorithm can estimate the temporal dynamics of interaction and reveal the interpretable functional connectivity underlying neural spike trains. ",
        "conference": "ICLR",
        "中文标题": "脉冲神经元网络中灵活交互的高效推理",
        "摘要翻译": "霍克斯过程为分析神经元脉冲活动的时间依赖性交互提供了一个有效的统计框架。尽管在许多实际应用中被使用，经典的霍克斯过程无法模拟神经元之间的抑制性交互。相比之下，非线性霍克斯过程允许更灵活的影响模式，包括兴奋性或抑制性交互。本文中，我们增加了三组辅助潜在变量（Polya-Gamma变量、潜在标记泊松过程和稀疏性变量），使得功能连接权重呈高斯形式，从而允许使用具有解析更新的简单迭代算法。因此，我们推导出了一个高效的期望最大化（EM）算法，以获得最大后验（MAP）估计。我们在合成数据和真实数据上展示了我们算法的准确性和效率性能。对于真实的神经记录，我们展示了我们的算法能够估计交互的时间动态，并揭示神经脉冲序列下可解释的功能连接性。",
        "领域": "神经计算建模、时间序列分析、神经网络动力学",
        "问题": "如何高效地建模和推理神经元网络中的灵活交互，特别是包括抑制性交互的情况。",
        "动机": "经典的霍克斯过程无法有效模拟神经元间的抑制性交互，限制了其在神经科学中的应用。",
        "方法": "通过引入三组辅助潜在变量，将功能连接权重转化为高斯形式，开发了一个高效的EM算法进行最大后验估计。",
        "关键词": [
            "霍克斯过程",
            "神经元交互",
            "EM算法",
            "功能连接性",
            "时间序列分析"
        ],
        "涉及的技术概念": {
            "霍克斯过程": "用于建模神经元脉冲活动的时间依赖性交互的统计框架。",
            "期望最大化算法": "用于在存在潜在变量的统计模型中寻找参数的最大似然或最大后验估计的迭代方法。",
            "功能连接性": "描述神经元或脑区之间在功能上的相互作用和连接模式。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 230,
        "title": "Efficient Reinforcement Learning in Factored MDPs with Application to Constrained RL",
        "html": "https://iclr.cc//virtual/2021/poster/2756",
        "abstract": "Reinforcement learning (RL) in episodic, factored Markov decision processes (FMDPs) is studied. We propose an algorithm called FMDP-BF, which leverages the factorization structure of FMDP.  The regret of FMDP-BF is shown to be exponentially smaller than that of optimal algorithms designed for non-factored MDPs, and improves on the best previous result for FMDPs~\\citep{osband2014near} by a factor of $\\sqrt{nH|\\mathcal{S}_i|}$, where $|\\mathcal{S}_i|$ is the cardinality of the factored state subspace, $H$ is the planning horizon and $n$ is the number of factored transition. To show the optimality of our bounds, we also provide a lower bound for FMDP, which indicates that our algorithm is near-optimal w.r.t. timestep $T$, horizon $H$ and factored state-action subspace cardinality. Finally, as an application, we study a new formulation of constrained RL, known as RL with knapsack constraints (RLwK), and provides the first sample-efficient algorithm based on FMDP-BF.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "因子化MDPs中的高效强化学习及其在约束强化学习中的应用",
        "摘要翻译": "研究了情景化的、因子化马尔可夫决策过程（FMDPs）中的强化学习（RL）。我们提出了一种名为FMDP-BF的算法，该算法利用了FMDP的因子化结构。FMDP-BF的遗憾值被证明比为非因子化MDP设计的最佳算法的遗憾值呈指数级小，并且比之前FMDP的最佳结果~\\citep{osband2014near} 提高了$\\sqrt{nH|\\mathcal{S}_i|}$倍，其中$|\\mathcal{S}_i|$是因子化状态子空间的基数，$H$是规划范围，$n$是因子化转移的数量。为了展示我们边界的最优性，我们还提供了FMDP的下界，表明我们的算法在时间步长$T$、范围$H$和因子化状态-动作子空间基数方面接近最优。最后，作为一个应用，我们研究了一种新的约束强化学习公式，称为带有背包约束的强化学习（RLwK），并提供了第一个基于FMDP-BF的样本高效算法。",
        "领域": "强化学习、马尔可夫决策过程、约束优化",
        "问题": "如何在因子化马尔可夫决策过程中实现样本高效的强化学习，并将其应用于解决带有背包约束的强化学习问题。",
        "动机": "现有的强化学习算法在因子化MDPs中效率较低，而带有背包约束的强化学习问题缺乏高效的解决方案。研究旨在设计一种能够利用FMDPs结构的强化学习算法，并解决RLwK问题。",
        "方法": "提出了一种名为FMDP-BF的算法，该算法利用了FMDP的因子化结构，并证明了其遗憾值比现有算法更小。通过提供FMDP的下界证明了算法的近最优性。并将该算法应用于带有背包约束的强化学习问题，提供了一种样本高效的解决方案。",
        "关键词": [
            "强化学习",
            "因子化马尔可夫决策过程",
            "约束强化学习",
            "遗憾值",
            "背包约束"
        ],
        "涉及的技术概念": {
            "因子化马尔可夫决策过程 (FMDP)": "一种马尔可夫决策过程的特殊形式，其状态空间可以分解为多个独立的子空间，从而降低了学习的复杂性。",
            "遗憾值": "衡量算法性能的指标，表示算法的累积奖励与最优策略的累积奖励之间的差距。较低的遗憾值意味着更好的性能。"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 231,
        "title": "Efficient Transformers in Reinforcement Learning using Actor-Learner Distillation",
        "html": "https://iclr.cc//virtual/2021/poster/2694",
        "abstract": "Many real-world applications such as robotics provide hard constraints on power and compute that limit the viable model complexity of Reinforcement Learning (RL) agents. Similarly, in many distributed RL settings, acting is done on un-accelerated hardware such as CPUs, which likewise restricts model size to prevent intractable experiment run times. These 'actor-latency' constrained settings present a major obstruction to the scaling up of model complexity that has recently been extremely successful in supervised learning. To be able to utilize large model capacity while still operating within the limits imposed by the system during acting, we develop an 'Actor-Learner Distillation' (ALD) procedure that leverages a continual form of distillation that transfers learning progress from a large capacity learner model to a small capacity actor model. As a case study, we develop this procedure in the context of partially-observable environments, where transformer models have had large improvements over LSTMs recently, at the cost of significantly higher computational complexity. With transformer models as the learner and LSTMs as the actor, we demonstrate in several challenging memory environments that using Actor-Learner Distillation largely recovers the clear sample-efficiency gains of the transformer learner model while maintaining the fast inference and reduced total training time of the LSTM actor model.",
        "conference": "ICLR",
        "中文标题": "在强化学习中使用行动者-学习者蒸馏的高效变换器",
        "摘要翻译": "许多现实世界的应用，如机器人技术，对功率和计算能力有严格的限制，这些限制限制了强化学习（RL）代理的可行模型复杂性。同样，在许多分布式RL设置中，行动是在未加速的硬件（如CPU）上进行的，这同样限制了模型大小以防止实验运行时间不可行。这些'行动者延迟'受限的设置对模型复杂性的扩展构成了主要障碍，而这种扩展在监督学习中最近非常成功。为了能够在行动期间仍然在系统施加的限制内利用大模型容量，我们开发了一种'行动者-学习者蒸馏'（ALD）程序，该程序利用一种持续的蒸馏形式，将学习进展从大容量的学习者模型转移到小容量的行动者模型。作为案例研究，我们在部分可观察的环境中开发了这一程序，其中变换器模型最近比LSTM有了很大的改进，但代价是计算复杂性显著提高。以变换器模型为学习者，LSTM为行动者，我们在几个具有挑战性的记忆环境中证明，使用行动者-学习者蒸馏在很大程度上恢复了变换器学习者模型的明显样本效率增益，同时保持了LSTM行动者模型的快速推理和减少的总训练时间。",
        "领域": "强化学习",
        "问题": "在功率和计算能力受限的环境中，如何利用大模型容量进行强化学习",
        "动机": "解决在受限环境中扩展模型复杂性的障碍，同时保持高效的学习和行动",
        "方法": "开发了一种'行动者-学习者蒸馏'（ALD）程序，通过持续的蒸馏将学习进展从大容量的学习者模型转移到小容量的行动者模型",
        "关键词": [
            "强化学习",
            "变换器模型",
            "LSTM",
            "模型蒸馏",
            "样本效率"
        ],
        "涉及的技术概念": {
            "行动者-学习者蒸馏（ALD）": "一种持续的蒸馏形式，用于将学习进展从大容量的学习者模型转移到小容量的行动者模型",
            "变换器模型": "在部分可观察的环境中，变换器模型比LSTM有显著改进，但计算复杂性更高",
            "LSTM": "作为行动者模型，具有快速推理和减少的总训练时间的优势"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 232,
        "title": "Efficient Wasserstein Natural Gradients for Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2021/poster/2903",
        "abstract": "A novel optimization approach is proposed for application to policy gradient methods and evolution strategies for reinforcement learning (RL). The procedure uses a computationally efficient \\emph{Wasserstein natural gradient} (WNG) descent that takes advantage of the geometry induced by a Wasserstein penalty to speed optimization. This method follows the recent theme in RL of including divergence penalties in the objective to establish trust regions. Experiments on challenging tasks demonstrate improvements in both computational cost and performance over advanced baselines. \n",
        "conference": "ICLR",
        "中文标题": "强化学习中高效的Wasserstein自然梯度方法",
        "摘要翻译": "本文提出了一种新颖的优化方法，应用于强化学习（RL）中的策略梯度方法和进化策略。该方法利用计算高效的Wasserstein自然梯度（WNG）下降，通过利用由Wasserstein惩罚诱导的几何结构来加速优化。这一方法遵循了RL中最近的主题，即在目标中包含散度惩罚以建立信任区域。在具有挑战性的任务上的实验表明，与先进的基线相比，该方法在计算成本和性能上都有所改进。",
        "领域": "强化学习优化",
        "问题": "如何在强化学习中更高效地进行策略优化",
        "动机": "为了在强化学习中提高策略优化的效率和性能，通过利用Wasserstein惩罚诱导的几何结构来加速优化过程。",
        "方法": "提出了一种使用Wasserstein自然梯度下降的优化方法，该方法在目标中包含散度惩罚以建立信任区域。",
        "关键词": [
            "Wasserstein自然梯度",
            "强化学习",
            "策略优化",
            "计算效率",
            "信任区域"
        ],
        "涉及的技术概念": {
            "Wasserstein自然梯度": "用于加速强化学习中的策略优化过程，通过利用Wasserstein距离诱导的几何结构。",
            "散度惩罚": "在优化目标中加入散度惩罚，以建立信任区域，防止策略更新过大。",
            "信任区域": "通过限制策略更新的幅度，确保学习的稳定性和效率。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 233,
        "title": "EigenGame: PCA as a Nash Equilibrium",
        "html": "https://iclr.cc//virtual/2021/poster/3125",
        "abstract": "We present a novel view on principal components analysis as a competitive game in which each approximate eigenvector is controlled by a player whose goal is to maximize their own utility function. We analyze the properties of this PCA game and the behavior of its gradient based updates. The resulting algorithm---which combines elements from Oja's rule with a  generalized Gram-Schmidt orthogonalization---is naturally decentralized and hence parallelizable through message passing. We demonstrate the scalability of the algorithm with experiments on large image datasets and neural network activations. We discuss how this new view of PCA as a differentiable game can lead to further algorithmic developments and insights.",
        "conference": "ICLR",
        "中文标题": "特征博弈：主成分分析作为纳什均衡",
        "摘要翻译": "我们提出了一种新颖的观点，将主成分分析视为一种竞争游戏，其中每个近似特征向量由一名玩家控制，其目标是最大化自己的效用函数。我们分析了这种PCA游戏的性质及其基于梯度的更新行为。所得到的算法——结合了Oja规则与广义Gram-Schmidt正交化的元素——自然分散，因此可通过消息传递并行化。我们通过在大规模图像数据集和神经网络激活上的实验证明了算法的可扩展性。我们讨论了这种将PCA视为可微分游戏的新观点如何能够带来进一步的算法发展和洞察。",
        "领域": "机器学习优化、数据分析、神经网络",
        "问题": "如何将主成分分析（PCA）重新构想为一个竞争游戏，以探索其性质和算法的并行化潜力。",
        "动机": "探索PCA的新视角，以促进算法的并行化和可扩展性，同时为未来的算法发展提供新的见解。",
        "方法": "将PCA视为一个竞争游戏，每个特征向量由玩家控制以最大化自身效用，结合Oja规则和广义Gram-Schmidt正交化，开发出一种分散且可并行化的算法。",
        "关键词": [
            "主成分分析",
            "竞争游戏",
            "并行算法",
            "梯度更新",
            "效用最大化"
        ],
        "涉及的技术概念": {
            "竞争游戏": "将PCA中的每个特征向量视为游戏中的玩家，通过最大化各自的效用函数来竞争，从而重新解释PCA的过程。",
            "Oja规则": "一种用于在线学习主成分的规则，本研究中用于更新特征向量的近似值。",
            "广义Gram-Schmidt正交化": "用于确保算法中的特征向量保持正交性，是算法能够正确收敛的关键技术。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 234,
        "title": "Emergent Road Rules In Multi-Agent Driving Environments",
        "html": "https://iclr.cc//virtual/2021/poster/2663",
        "abstract": "For autonomous vehicles to safely share the road with human drivers, autonomous vehicles must abide by specific 'road rules' that human drivers have agreed to follow. 'Road rules' include rules that drivers are required to follow by law – such as the requirement that vehicles stop at red lights – as well as more subtle social rules – such as the implicit designation of fast lanes on the highway. In this paper, we provide empirical evidence that suggests that – instead of hard-coding road rules into self-driving algorithms – a scalable alternative may be to design multi-agent environments in which road rules emerge as optimal solutions to the problem of maximizing traffic flow.  We analyze what ingredients in driving environments cause the emergence of these road rules and find that two crucial factors are noisy perception and agents’ spatial density.  We provide qualitative and quantitative evidence of the emergence of seven social driving behaviors, ranging from obeying traffic signals to following lanes, all of which emerge from training agents to drive quickly to destinations without colliding. Our results add empirical support for the social road rules that countries worldwide have agreed on for safe, efficient driving.",
        "conference": "ICLR",
        "中文标题": "多智能体驾驶环境中涌现的道路规则",
        "摘要翻译": "为了让自动驾驶车辆与人类驾驶员安全共享道路，自动驾驶车辆必须遵守人类驾驶员同意遵循的特定‘道路规则’。‘道路规则’包括法律要求驾驶员遵守的规则——如车辆在红灯时必须停止——以及更微妙的社会规则——如高速公路上快车道的隐式指定。在本文中，我们提供的实证证据表明，与其将道路规则硬编码到自动驾驶算法中，一个可扩展的替代方案可能是设计多智能体环境，其中道路规则作为最大化交通流量问题的最优解决方案涌现。我们分析了驾驶环境中哪些因素导致了这些道路规则的涌现，并发现两个关键因素是感知噪声和智能体的空间密度。我们提供了七种社会驾驶行为涌现的定性和定量证据，从遵守交通信号到跟随车道，所有这些行为都源于训练智能体快速到达目的地而不发生碰撞。我们的结果为世界各国同意的安全、高效驾驶的社会道路规则提供了实证支持。",
        "领域": "自动驾驶系统、多智能体系统、交通流优化",
        "问题": "如何在多智能体驾驶环境中自然地涌现出道路规则，而不是通过硬编码实现。",
        "动机": "探索自动驾驶车辆与人类驾驶员共享道路时，如何通过多智能体环境设计使道路规则自然涌现，以实现安全高效的交通流。",
        "方法": "设计多智能体驾驶环境，通过训练智能体快速到达目的地而不发生碰撞，观察和分析道路规则的涌现过程及其关键影响因素。",
        "关键词": [
            "自动驾驶",
            "多智能体系统",
            "道路规则涌现",
            "交通流优化",
            "社会驾驶行为"
        ],
        "涉及的技术概念": {
            "多智能体环境": "设计用于模拟和训练多个自动驾驶智能体交互的环境，以研究道路规则的涌现。",
            "感知噪声": "模拟人类驾驶员感知的不完美性，是多智能体环境中道路规则涌现的关键因素之一。",
            "空间密度": "智能体在环境中的分布密度，影响交通流和道路规则的涌现过程。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 235,
        "title": "Emergent Symbols through Binding in External Memory",
        "html": "https://iclr.cc//virtual/2021/poster/2965",
        "abstract": "A key aspect of human intelligence is the ability to infer abstract rules directly from high-dimensional sensory data, and to do so given only a limited amount of training experience. Deep neural network algorithms have proven to be a powerful tool for learning directly from high-dimensional data, but currently lack this capacity for data-efficient induction of abstract rules, leading some to argue that symbol-processing mechanisms will be necessary to account for this capacity. In this work, we take a step toward bridging this gap by introducing the Emergent Symbol Binding Network (ESBN), a recurrent network augmented with an external memory that enables a form of variable-binding and indirection. This binding mechanism allows symbol-like representations to emerge through the learning process without the need to explicitly incorporate symbol-processing machinery, enabling the ESBN to learn rules in a manner that is abstracted away from the particular entities to which those rules apply. Across a series of tasks, we show that this architecture displays nearly perfect generalization of learned rules to novel entities given only a limited number of training examples, and outperforms a number of other competitive neural network architectures.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "通过外部记忆中的绑定涌现符号",
        "摘要翻译": "人类智能的一个关键方面是能够直接从高维感官数据中推断出抽象规则，并且在仅有限训练经验的情况下做到这一点。深度神经网络算法已被证明是从高维数据直接学习的强大工具，但目前缺乏这种数据高效的抽象规则归纳能力，导致一些人认为符号处理机制将是解释这一能力所必需的。在这项工作中，我们通过引入涌现符号绑定网络（ESBN）向弥合这一差距迈出了一步，这是一种增加了外部记忆的循环网络，使得一种变量绑定和间接形式成为可能。这种绑定机制允许符号般的表示通过学习过程涌现，而无需显式地融入符号处理机制，使ESBN能够以一种抽象于这些规则所适用的特定实体的方式学习规则。在一系列任务中，我们展示了这种架构在仅有限数量的训练示例下，对学习规则到新实体的近乎完美泛化能力，并且优于许多其他竞争性神经网络架构。",
        "领域": "符号学习与推理、神经网络架构设计、认知计算模型",
        "问题": "如何使深度神经网络能够高效地从有限的高维数据中归纳抽象规则",
        "动机": "解决深度神经网络在数据高效归纳抽象规则方面的不足，探索符号处理机制与神经网络结合的可能性",
        "方法": "引入涌现符号绑定网络（ESBN），一种增加外部记忆的循环网络，通过绑定机制使符号般的表示能够通过学习过程涌现",
        "关键词": [
            "符号学习",
            "外部记忆",
            "变量绑定",
            "抽象规则归纳",
            "神经网络架构"
        ],
        "涉及的技术概念": {
            "涌现符号绑定网络（ESBN）": "一种循环网络架构，通过外部记忆实现变量绑定和间接，使符号般的表示能够通过学习过程涌现",
            "变量绑定": "一种技术，允许网络将变量与值关联，支持符号处理和抽象规则的表示",
            "外部记忆": "网络架构的一部分，用于存储和检索信息，增强网络的记忆能力和处理复杂任务的能力"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 236,
        "title": "Empirical Analysis of Unlabeled Entity Problem in Named Entity Recognition",
        "html": "https://iclr.cc//virtual/2021/poster/2529",
        "abstract": "In many scenarios, named entity recognition (NER) models severely suffer from unlabeled entity problem, where the entities of a sentence may not be fully annotated. Through empirical studies performed on synthetic datasets, we find two causes of performance degradation. One is the reduction of annotated entities and the other is treating unlabeled entities as negative instances. The first cause has less impact than the second one and can be mitigated by adopting pretraining language models. The second cause seriously misguides a model in training and greatly affects its performances. Based on the above observations, we propose a general approach, which can almost eliminate the misguidance brought by unlabeled entities. The key idea is to use negative sampling that, to a large extent, avoids training NER models with unlabeled entities. Experiments on synthetic datasets and real-world datasets show that our model is robust to unlabeled entity problem and surpasses prior baselines. On well-annotated datasets, our model is competitive with the state-of-the-art method.",
        "conference": "ICLR",
        "中文标题": "命名实体识别中未标注实体问题的实证分析",
        "摘要翻译": "在许多场景下，命名实体识别（NER）模型严重受到未标注实体问题的影响，即句子的实体可能未被完全标注。通过在合成数据集上进行的实证研究，我们发现了导致性能下降的两个原因。一是标注实体的减少，二是将未标注实体视为负面实例。第一个原因的影响小于第二个原因，并且可以通过采用预训练语言模型来缓解。第二个原因在训练过程中严重误导模型，并极大地影响其性能。基于上述观察，我们提出了一种通用方法，几乎可以消除未标注实体带来的误导。关键思想是使用负采样，这在很大程度上避免了用未标注实体训练NER模型。在合成数据集和真实世界数据集上的实验表明，我们的模型对未标注实体问题具有鲁棒性，并且超越了之前的基线。在标注良好的数据集上，我们的模型与最先进的方法具有竞争力。",
        "领域": "命名实体识别、自然语言处理、信息抽取",
        "问题": "解决命名实体识别中未标注实体导致的模型性能下降问题",
        "动机": "未标注实体在训练过程中被错误地视为负面实例，严重误导模型训练，影响性能",
        "方法": "提出一种基于负采样的通用方法，避免使用未标注实体训练模型",
        "关键词": [
            "命名实体识别",
            "未标注实体",
            "负采样",
            "模型鲁棒性",
            "实证分析"
        ],
        "涉及的技术概念": {
            "未标注实体问题": "指在命名实体识别任务中，部分实体未被标注，导致模型训练时性能下降的问题",
            "负采样": "一种避免使用未标注实体训练模型的技术，通过选择性地忽略这些实体来减少误导",
            "预训练语言模型": "用于缓解标注实体减少对模型性能影响的预训练技术，提升模型的基础理解能力"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 237,
        "title": "Empirical or Invariant Risk Minimization? A Sample Complexity Perspective",
        "html": "https://iclr.cc//virtual/2021/poster/2580",
        "abstract": "Recently, invariant risk minimization (IRM) was proposed as a promising solution to address out-of-distribution (OOD) generalization. However, it is unclear when IRM should be preferred over the widely-employed empirical risk minimization (ERM) framework. In this work, we analyze both these frameworks from the perspective of sample complexity, thus taking a firm step towards answering this important question. We find that depending on the type of data generation mechanism, the two approaches might have very different finite sample and asymptotic behavior. For example, in the covariate shift setting we see that the two approaches not only arrive at the same asymptotic solution, but also have similar finite sample behavior with no clear winner. For other distribution shifts such as those involving confounders or anti-causal variables, however, the two approaches arrive at different asymptotic solutions where IRM is guaranteed to be close to the desired OOD solutions in the finite sample regime, while ERM is biased even asymptotically.  We further investigate how different factors --- the number of environments, complexity of the model, and IRM penalty weight ---  impact the sample complexity of IRM in relation to its distance from the OOD solutions. ",
        "conference": "ICLR",
        "中文标题": "经验风险最小化还是不变风险最小化？从样本复杂度的视角看",
        "摘要翻译": "最近，不变风险最小化（IRM）被提出作为解决分布外（OOD）泛化的一个有前景的解决方案。然而，尚不清楚在什么情况下IRM应优先于广泛使用的经验风险最小化（ERM）框架。在这项工作中，我们从样本复杂度的角度分析了这两种框架，从而朝着回答这一重要问题迈出了坚实的一步。我们发现，根据数据生成机制的类型，这两种方法可能具有非常不同的有限样本和渐进行为。例如，在协变量偏移设置中，我们看到这两种方法不仅达到了相同的渐近解，而且在有限样本行为上也相似，没有明显的赢家。然而，对于其他分布偏移，如涉及混杂因素或反因果变量的情况，这两种方法达到了不同的渐近解，其中IRM在有限样本制度下保证接近所需的OOD解，而ERM即使在渐近情况下也是有偏的。我们进一步研究了不同因素——环境数量、模型的复杂性以及IRM惩罚权重——如何影响IRM的样本复杂度与其与OOD解的距离之间的关系。",
        "领域": "机器学习理论",
        "问题": "在什么情况下不变风险最小化（IRM）应优先于经验风险最小化（ERM）框架",
        "动机": "解决分布外（OOD）泛化问题，明确IRM和ERM在不同数据生成机制下的适用性",
        "方法": "从样本复杂度的角度分析IRM和ERM框架，比较它们在不同数据生成机制下的有限样本和渐进行为",
        "关键词": [
            "不变风险最小化",
            "经验风险最小化",
            "分布外泛化",
            "样本复杂度",
            "数据生成机制"
        ],
        "涉及的技术概念": {
            "不变风险最小化（IRM）": "一种旨在通过在不同环境下保持预测规则不变来解决分布外泛化问题的框架",
            "经验风险最小化（ERM）": "一种通过最小化训练数据上的平均损失来训练模型的传统框架",
            "样本复杂度": "指学习算法达到特定性能水平所需的样本数量，用于分析IRM和ERM在不同条件下的表现"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 238,
        "title": "End-to-end Adversarial Text-to-Speech",
        "html": "https://iclr.cc//virtual/2021/poster/2778",
        "abstract": "Modern text-to-speech synthesis pipelines typically involve multiple processing stages, each of which is designed or learnt independently from the rest. In this work, we take on the challenging task of learning to synthesise speech from normalised text or phonemes in an end-to-end manner, resulting in models which operate directly on character or phoneme input sequences and produce raw speech audio outputs. Our proposed generator is feed-forward and thus efficient for both training and inference, using a differentiable alignment scheme based on token length prediction. It learns to produce high fidelity audio through a combination of adversarial feedback and prediction losses constraining the generated audio to roughly match the ground truth in terms of its total duration and mel-spectrogram. To allow the model to capture temporal variation in the generated audio, we employ soft dynamic time warping in the spectrogram-based prediction loss. The resulting model achieves a mean opinion score exceeding 4 on a 5 point scale, which is comparable to the state-of-the-art models relying on multi-stage training and additional supervision.",
        "conference": "ICLR",
        "中文标题": "端到端对抗性文本到语音",
        "摘要翻译": "现代文本到语音合成流程通常涉及多个处理阶段，每个阶段的设计或学习都是独立于其他阶段的。在这项工作中，我们承担了从规范化文本或音素中以端到端方式学习合成语音的挑战性任务，从而产生了直接操作字符或音素输入序列并产生原始语音音频输出的模型。我们提出的生成器是前馈的，因此对于训练和推理都是高效的，使用了基于令牌长度预测的可微分对齐方案。它通过对抗性反馈和预测损失的组合学习产生高保真音频，这些损失约束生成的音频在总时长和梅尔频谱图上大致与真实情况匹配。为了使模型能够捕捉生成音频中的时间变化，我们在基于频谱图的预测损失中采用了软动态时间规整。最终模型在5分制上实现了超过4的平均意见分数，这与依赖于多阶段训练和额外监督的最先进模型相当。",
        "领域": "语音合成, 深度学习, 生成对抗网络",
        "问题": "如何直接从文本或音素端到端地合成高质量的语音，而不依赖于传统的多阶段处理流程。",
        "动机": "减少语音合成系统的复杂性，提高合成效率和质量，通过端到端学习简化流程。",
        "方法": "提出了一种前馈生成器模型，结合对抗性反馈和预测损失，使用基于令牌长度预测的可微分对齐方案和软动态时间规整技术。",
        "关键词": [
            "端到端学习",
            "语音合成",
            "对抗性训练",
            "动态时间规整",
            "梅尔频谱图"
        ],
        "涉及的技术概念": {
            "对抗性反馈": "用于提高生成音频的质量，通过对抗性训练使生成的音频更接近真实音频。",
            "可微分对齐方案": "基于令牌长度预测，用于在训练过程中对齐输入文本和输出音频，提高模型的训练效率。",
            "软动态时间规整": "在频谱图预测损失中应用，允许模型捕捉和处理生成音频中的时间变化，提高音频的自然度和质量。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 239,
        "title": "End-to-End Egospheric Spatial Memory",
        "html": "https://iclr.cc//virtual/2021/poster/3268",
        "abstract": "Spatial memory, or the ability to remember and recall specific locations and objects, is central to autonomous agents' ability to carry out tasks in real environments. However, most existing artificial memory modules are not very adept at storing spatial information. We propose a parameter-free module, Egospheric Spatial Memory (ESM), which encodes the memory in an ego-sphere around the agent, enabling expressive 3D representations. ESM can be trained end-to-end via either imitation or reinforcement learning, and improves both training efficiency and final performance against other memory baselines on both drone and manipulator visuomotor control tasks. The explicit egocentric geometry also enables us to seamlessly combine the learned controller with other non-learned modalities, such as local obstacle avoidance. We further show applications to semantic segmentation on the ScanNet dataset, where ESM naturally combines image-level and map-level inference modalities. Through our broad set of experiments, we show that ESM provides a general computation graph for embodied spatial reasoning, and the module forms a bridge between real-time mapping systems and differentiable memory architectures. Implementation at: https://github.com/ivy-dl/memory.",
        "conference": "ICLR",
        "中文标题": "端到端的自我中心空间记忆",
        "摘要翻译": "空间记忆，即记住并回忆特定位置和物体的能力，是自主代理在真实环境中执行任务的核心能力。然而，现有的大多数人工记忆模块并不擅长存储空间信息。我们提出了一个无参数模块——自我中心空间记忆（ESM），该模块在代理周围的自我球体中编码记忆，实现了表达性的3D表示。ESM可以通过模仿学习或强化学习进行端到端训练，并在无人机和机械臂的视觉运动控制任务中，与其他记忆基线相比，提高了训练效率和最终性能。显式的自我中心几何还使我们能够无缝地将学习到的控制器与其他非学习模态（如局部避障）结合起来。我们进一步展示了在ScanNet数据集上的语义分割应用，其中ESM自然地结合了图像级和地图级的推理模态。通过我们广泛的实验，我们展示了ESM为体现空间推理提供了一个通用的计算图，并且该模块构成了实时映射系统和可微分记忆架构之间的桥梁。实现见：https://github.com/ivy-dl/memory。",
        "领域": "自主代理导航, 视觉运动控制, 语义分割",
        "问题": "现有的人工记忆模块在存储空间信息方面的不足",
        "动机": "提高自主代理在真实环境中执行任务时的空间记忆能力",
        "方法": "提出了一个无参数的自我中心空间记忆模块（ESM），支持端到端训练，并能够与其他非学习模态结合使用",
        "关键词": [
            "自我中心空间记忆",
            "端到端学习",
            "视觉运动控制",
            "语义分割",
            "空间推理"
        ],
        "涉及的技术概念": {
            "自我中心空间记忆（ESM）": "在代理周围的自我球体中编码记忆，实现表达性的3D表示",
            "端到端训练": "通过模仿学习或强化学习训练ESM模块，无需手动设计特征",
            "可微分记忆架构": "ESM模块作为实时映射系统和可微分记忆架构之间的桥梁，支持广泛的空间推理任务"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 240,
        "title": "Enforcing robust control guarantees within neural network policies",
        "html": "https://iclr.cc//virtual/2021/poster/2899",
        "abstract": "When designing controllers for safety-critical systems, practitioners often face a challenging tradeoff between robustness and performance. While robust control methods provide rigorous guarantees on system stability under certain worst-case disturbances, they often yield simple controllers that perform poorly in the average (non-worst) case. In contrast, nonlinear control methods trained using deep learning have achieved state-of-the-art performance on many control tasks, but often lack robustness guarantees. In this paper, we propose a technique that combines the strengths of these two approaches: constructing a generic nonlinear control policy class, parameterized by neural networks, that nonetheless enforces the same provable robustness criteria as robust control. Specifically, our approach entails integrating custom convex-optimization-based projection layers into a neural network-based policy. We demonstrate the power of this approach on several domains, improving in average-case performance over existing robust control methods and in worst-case stability over (non-robust) deep RL methods.",
        "conference": "ICLR",
        "中文标题": "在神经网络策略中实施鲁棒控制保证",
        "摘要翻译": "在设计安全关键系统的控制器时，实践者常常面临鲁棒性与性能之间的艰难权衡。虽然鲁棒控制方法在某些最坏情况干扰下为系统稳定性提供了严格的保证，但它们往往产生在平均（非最坏）情况下表现不佳的简单控制器。相比之下，使用深度学习训练的非线性控制方法在许多控制任务上实现了最先进的性能，但往往缺乏鲁棒性保证。在本文中，我们提出了一种结合这两种方法优势的技术：构建一个由神经网络参数化的通用非线性控制策略类，尽管如此，它仍然强制执行与鲁棒控制相同的可证明鲁棒性标准。具体来说，我们的方法需要将基于自定义凸优化的投影层集成到基于神经网络的策略中。我们在几个领域展示了这种方法的威力，在平均性能上优于现有的鲁棒控制方法，在最坏情况稳定性上优于（非鲁棒的）深度强化学习方法。",
        "领域": "鲁棒控制、深度学习控制、安全关键系统",
        "问题": "如何在保持神经网络控制策略高性能的同时，确保其在安全关键系统中的鲁棒性和稳定性。",
        "动机": "解决鲁棒控制方法在平均性能上的不足和深度学习控制在鲁棒性保证上的缺乏，结合两者的优势。",
        "方法": "提出了一种结合鲁棒控制和深度学习的方法，通过集成基于凸优化的投影层到神经网络策略中，以强制执行鲁棒性标准。",
        "关键词": [
            "鲁棒控制",
            "神经网络策略",
            "安全关键系统",
            "凸优化",
            "深度强化学习"
        ],
        "涉及的技术概念": {
            "鲁棒控制": "提供系统在最坏情况干扰下的稳定性保证，但可能在平均情况下表现不佳。",
            "神经网络策略": "由神经网络参数化的控制策略，能够实现高性能但缺乏鲁棒性保证。",
            "凸优化投影层": "集成到神经网络中的自定义层，用于强制执行鲁棒性标准，结合了鲁棒控制和深度学习的优势。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 241,
        "title": "Enjoy Your Editing: Controllable GANs for Image Editing via Latent Space Navigation",
        "html": "https://iclr.cc//virtual/2021/poster/2858",
        "abstract": "Controllable semantic image editing enables a user to change entire image attributes with a few clicks, e.g., gradually making a summer scene look like it was taken in winter. Classic approaches for this task use a Generative Adversarial Net (GAN) to learn a latent space and suitable latent-space transformations. However, current approaches often suffer from attribute edits that are entangled, global image identity changes, and diminished photo-realism. To address these concerns, we learn multiple attribute transformations simultaneously, integrate attribute regression into the training of transformation functions, and apply a content loss and an adversarial loss that encourages the maintenance of image identity and photo-realism. We propose quantitative evaluation strategies for measuring controllable editing performance, unlike prior work, which primarily focuses on qualitative evaluation. Our model permits better control for both single- and multiple-attribute editing while preserving image identity and realism during transformation. We provide empirical results for both natural and synthetic images, highlighting that our model achieves state-of-the-art performance for targeted image manipulation. ",
        "conference": "ICLR",
        "中文标题": "享受您的编辑：通过潜在空间导航实现可控GANs图像编辑",
        "摘要翻译": "可控的语义图像编辑使用户能够通过几次点击改变整个图像的属性，例如，逐渐使夏季场景看起来像是在冬季拍摄的。这项任务的经典方法使用生成对抗网络（GAN）来学习潜在空间和合适的潜在空间变换。然而，当前的方法常常受到属性编辑纠缠、全局图像身份变化和照片真实感减弱的问题。为了解决这些问题，我们同时学习多个属性变换，将属性回归集成到变换函数的训练中，并应用内容损失和对抗损失，以鼓励保持图像身份和照片真实感。我们提出了定量评估策略来衡量可控编辑性能，与之前主要关注定性评估的工作不同。我们的模型允许在单属性和多属性编辑中实现更好的控制，同时在变换过程中保持图像身份和真实感。我们为自然图像和合成图像提供了实证结果，强调我们的模型在目标图像操作方面实现了最先进的性能。",
        "领域": "图像生成与编辑、生成对抗网络、语义图像编辑",
        "问题": "解决当前可控语义图像编辑中属性编辑纠缠、全局图像身份变化和照片真实感减弱的问题",
        "动机": "提升图像编辑的精确度和真实感，同时保持图像身份，使用户能够更灵活地进行单属性和多属性编辑",
        "方法": "同时学习多个属性变换，集成属性回归于变换函数训练中，应用内容损失和对抗损失以保持图像身份和真实感",
        "关键词": [
            "可控GANs",
            "潜在空间导航",
            "语义图像编辑",
            "图像身份保持",
            "照片真实感"
        ],
        "涉及的技术概念": {
            "生成对抗网络（GAN）": "用于学习潜在空间和合适的潜在空间变换，是实现可控图像编辑的基础",
            "内容损失": "在变换过程中用于保持图像内容的连贯性和身份",
            "对抗损失": "鼓励生成的图像保持高水平的照片真实感，防止图像质量下降"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 242,
        "title": "Entropic gradient descent algorithms and wide flat minima",
        "html": "https://iclr.cc//virtual/2021/poster/2728",
        "abstract": "The properties of flat minima in the empirical risk landscape of neural networks have been debated for some time. Increasing evidence suggests they possess better generalization capabilities with respect to sharp ones. In this work we first discuss the relationship between alternative measures of flatness: The local entropy, which is useful for analysis and algorithm development, and the local energy, which is easier to compute and was shown empirically in extensive tests on state-of-the-art networks to be the best predictor of generalization capabilities. We show semi-analytically in simple controlled scenarios that these two measures correlate strongly with each other and with generalization. Then, we extend the analysis to the deep learning scenario by extensive numerical validations. We study two algorithms, Entropy-SGD and Replicated-SGD, that explicitly include the local entropy in the optimization objective. We devise a training schedule by which we consistently find flatter minima (using both flatness measures), and improve the generalization error for common architectures (e.g. ResNet, EfficientNet).",
        "conference": "ICLR",
        "中文标题": "熵梯度下降算法与宽平最小值",
        "摘要翻译": "神经网络经验风险景观中平最小值的性质已被讨论了一段时间。越来越多的证据表明，相对于尖锐最小值，平最小值具有更好的泛化能力。在这项工作中，我们首先讨论了平最小值的替代度量之间的关系：局部熵，这对分析和算法开发有用；以及局部能量，这更容易计算，并且在最先进网络上的大量测试中被经验证明是泛化能力的最佳预测因子。我们在简单的控制场景中半分析地展示了这两种度量彼此之间以及与泛化能力之间的强相关性。然后，通过广泛的数值验证，我们将分析扩展到深度学习场景。我们研究了两种算法，熵-SGD和复制-SGD，它们明确地将局部熵包含在优化目标中。我们设计了一个训练计划，通过这个计划我们一致地找到了更平的最小值（使用两种平度量），并提高了常见架构（如ResNet、EfficientNet）的泛化误差。",
        "领域": "深度学习优化、神经网络泛化、梯度下降算法",
        "问题": "探讨平最小值在神经网络经验风险景观中的性质及其对泛化能力的影响",
        "动机": "研究平最小值与泛化能力之间的关系，以开发能够找到更平最小值的优化算法，从而提高神经网络的泛化性能",
        "方法": "通过分析局部熵和局部能量两种平最小值的度量，设计包含局部熵的优化算法（熵-SGD和复制-SGD），并通过训练计划寻找更平的最小值",
        "关键词": [
            "平最小值",
            "局部熵",
            "泛化能力",
            "熵-SGD",
            "复制-SGD"
        ],
        "涉及的技术概念": {
            "局部熵": "用于分析和算法开发，作为平最小值的度量之一，帮助理解神经网络的泛化能力",
            "局部能量": "作为平最小值的另一种度量，易于计算，被证明是泛化能力的有效预测因子",
            "熵-SGD": "一种优化算法，明确将局部熵包含在优化目标中，旨在找到更平的最小值以提高泛化能力"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 243,
        "title": "Estimating and Evaluating Regression Predictive Uncertainty in Deep Object Detectors",
        "html": "https://iclr.cc//virtual/2021/poster/2594",
        "abstract": "Predictive uncertainty estimation is an essential next step for the reliable deployment of deep object detectors in safety-critical tasks. In this work, we focus on estimating predictive distributions for bounding box regression output with variance networks. We show that in the context of object detection, training variance networks with negative log likelihood (NLL) can lead to high entropy predictive distributions regardless of the correctness of the output mean. We propose to use the energy score as a non-local proper scoring rule and find that when used for training, the energy score leads to better calibrated and lower entropy predictive distributions than NLL. We also address the widespread use of non-proper scoring metrics for evaluating predictive distributions from deep object detectors by proposing an alternate evaluation approach founded on proper scoring rules. Using the proposed evaluation tools, we show that although variance networks can be used to produce high quality predictive distributions, ad-hoc approaches used by seminal object detectors for choosing regression targets during training do not provide wide enough data support for reliable variance learning. We hope that our work helps shift evaluation in probabilistic object detection to better align with predictive uncertainty evaluation in other machine learning domains. Code for all models, evaluation, and datasets is available at: https://github.com/asharakeh/probdet.git.",
        "conference": "ICLR",
        "中文标题": "深度目标检测器中回归预测不确定性的估计与评估",
        "摘要翻译": "预测不确定性估计是深度目标检测器在安全关键任务中可靠部署的重要下一步。在这项工作中，我们专注于通过方差网络估计边界框回归输出的预测分布。我们展示，在目标检测的背景下，使用负对数似然（NLL）训练方差网络可能导致高熵预测分布，无论输出均值是否正确。我们提出使用能量评分作为一种非局部适当评分规则，并发现当用于训练时，能量评分比NLL产生更好校准和更低熵的预测分布。我们还通过提出一种基于适当评分规则的替代评估方法，解决了深度目标检测器评估预测分布时广泛使用非适当评分指标的问题。使用提出的评估工具，我们表明，尽管方差网络可用于产生高质量的预测分布，但开创性目标检测器在训练期间选择回归目标的临时方法并未为可靠的方差学习提供足够广泛的数据支持。我们希望我们的工作有助于将概率目标检测中的评估转向更好地与其他机器学习领域中的预测不确定性评估对齐。所有模型、评估和数据集的代码可在https://github.com/asharakeh/probdet.git获取。",
        "领域": "目标检测、不确定性估计、深度学习",
        "问题": "深度目标检测器中回归预测不确定性的准确估计与评估",
        "动机": "提高深度目标检测器在安全关键任务中的可靠性和预测不确定性估计的准确性",
        "方法": "使用方差网络估计边界框回归输出的预测分布，并提出基于能量评分的训练方法和适当评分规则的评估方法",
        "关键词": [
            "预测不确定性",
            "目标检测",
            "方差网络",
            "能量评分",
            "适当评分规则"
        ],
        "涉及的技术概念": {
            "方差网络": "用于估计边界框回归输出的预测分布，提高不确定性估计的准确性",
            "能量评分": "作为一种非局部适当评分规则，用于训练方差网络，以产生更好校准和更低熵的预测分布",
            "适当评分规则": "用于评估预测分布的质量，确保评估方法的合理性和准确性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 244,
        "title": "Estimating informativeness of samples with Smooth Unique Information",
        "html": "https://iclr.cc//virtual/2021/poster/3309",
        "abstract": "We define a notion of information that an individual sample provides to the training of a neural network, and we specialize it to measure both how much a sample informs the final weights and how much it informs the function computed by the weights. Though related, we show that these quantities have a  qualitatively different behavior. We give efficient approximations of these quantities using a linearized network and demonstrate empirically that the approximation is accurate for real-world architectures, such as pre-trained ResNets. We apply these measures to several problems, such as dataset summarization, analysis of under-sampled classes, comparison of informativeness of different data sources, and detection of adversarial and corrupted examples. Our work generalizes existing frameworks, but enjoys better computational properties for heavily over-parametrized models, which makes it possible to apply it to real-world networks.",
        "conference": "ICLR",
        "中文标题": "估计样本信息量的平滑独特信息方法",
        "摘要翻译": "我们定义了一个衡量单个样本对神经网络训练提供信息量的概念，并将其专门化以测量样本对最终权重的信息量以及它对权重计算函数的信息量。尽管相关，我们展示了这些量在性质上有不同的行为。我们使用线性化网络给出了这些量的有效近似，并通过实验证明这种近似对于真实世界的架构（如预训练的ResNets）是准确的。我们将这些度量应用于几个问题，如数据集摘要、欠采样类别的分析、不同数据源信息量的比较以及对抗性和损坏样本的检测。我们的工作概括了现有框架，但对于高度过参数化的模型具有更好的计算特性，这使得将其应用于真实世界的网络成为可能。",
        "领域": "深度学习理论、神经网络优化、数据选择与清洗",
        "问题": "如何量化单个样本在神经网络训练中的信息贡献，并区分其对模型权重和模型功能的不同影响。",
        "动机": "为了更有效地理解和利用训练数据中的信息，特别是在高度过参数化的模型中，提高数据选择和模型训练的效率和效果。",
        "方法": "通过定义样本信息量的概念，并使用线性化网络进行有效近似，应用于多种实际问题中。",
        "关键词": [
            "样本信息量",
            "线性化网络",
            "数据选择",
            "过参数化模型",
            "对抗样本检测"
        ],
        "涉及的技术概念": {
            "样本信息量": "衡量单个样本对模型训练贡献的信息量，包括对权重和模型功能的影响。",
            "线性化网络": "用于近似样本信息量的技术，使得在复杂模型中计算变得可行。",
            "过参数化模型": "指参数数量远大于训练样本数的模型，本研究特别针对这类模型优化了信息量估计的计算方法。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 245,
        "title": "Estimating Lipschitz constants of monotone deep equilibrium models",
        "html": "https://iclr.cc//virtual/2021/poster/3308",
        "abstract": "Several methods have been proposed in recent years to provide bounds on the Lipschitz constants of deep networks, which can be used to provide robustness guarantees, generalization bounds, and characterize the smoothness of decision boundaries. However, existing bounds get substantially weaker with increasing depth of the network, which makes it unclear how to apply such bounds to recently proposed models such as the deep equilibrium (DEQ) model, which can be viewed as representing an infinitely-deep network. In this paper, we show that monotone DEQs, a recently-proposed subclass of DEQs, have Lipschitz constants that can be bounded as a simple function of the strong monotonicity parameter of the network. We derive simple-yet-tight bounds on both the input-output mapping and the weight-output mapping defined by these networks, and demonstrate that they are small relative to those for comparable standard DNNs. We show that one can use these bounds to design monotone DEQ models, even with e.g. multi-scale convolutional structure, that still have constraints on the Lipschitz constant. We also highlight how to use these bounds to develop PAC-Bayes generalization bounds that do not depend on any depth of the network, and which avoid the exponential depth-dependence of comparable DNN bounds.",
        "conference": "ICLR",
        "中文标题": "估计单调深度平衡模型的Lipschitz常数",
        "摘要翻译": "近年来，已经提出了几种方法来提供深度网络的Lipschitz常数的界限，这些界限可以用来提供鲁棒性保证、泛化界限，并描述决策边界的平滑度。然而，现有的界限随着网络深度的增加而显著减弱，这使得如何将此类界限应用于最近提出的模型（如深度平衡（DEQ）模型）变得不明确，该模型可以被视为表示一个无限深的网络。在本文中，我们展示了单调DEQs，这是DEQs的一个最近提出的子类，其Lipschitz常数可以作为网络强单调性参数的简单函数来界定。我们为这些网络定义的输入-输出映射和权重-输出映射导出了简单而紧密的界限，并证明它们相对于可比较的标准DNNs的界限较小。我们展示了如何使用这些界限来设计单调DEQ模型，即使具有例如多尺度卷积结构，仍然对Lipschitz常数有约束。我们还强调了如何使用这些界限来开发不依赖于网络任何深度的PAC-Bayes泛化界限，并避免了可比较的DNN界限的指数深度依赖性。",
        "领域": "深度学习理论、神经网络稳定性分析、泛化理论",
        "问题": "如何为深度平衡模型（DEQ）提供有效的Lipschitz常数界限，以解决现有方法在深度增加时界限显著减弱的问题。",
        "动机": "研究动机是为了解决现有Lipschitz常数界限方法在应用于无限深度的深度平衡模型时效果不佳的问题，提供更紧密的界限以支持模型的鲁棒性保证和泛化能力分析。",
        "方法": "通过分析单调深度平衡模型的强单调性参数，推导出输入-输出映射和权重-输出映射的简单而紧密的Lipschitz常数界限，并应用于模型设计和泛化理论中。",
        "关键词": [
            "Lipschitz常数",
            "深度平衡模型",
            "单调性",
            "泛化界限",
            "PAC-Bayes"
        ],
        "涉及的技术概念": {
            "Lipschitz常数": "用于衡量函数或映射的平滑度，本文中用于提供深度平衡模型的鲁棒性保证和泛化界限。",
            "深度平衡模型（DEQ）": "一种可以视为无限深度网络的模型，本文研究的对象，特别是其单调子类。",
            "强单调性参数": "单调深度平衡模型的一个关键属性，本文中用于推导Lipschitz常数的界限。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 246,
        "title": "Evaluating the Disentanglement of Deep Generative Models through Manifold Topology",
        "html": "https://iclr.cc//virtual/2021/poster/3269",
        "abstract": "Learning disentangled representations is regarded as a fundamental task for improving the generalization, robustness, and interpretability of generative models. However, measuring disentanglement has been challenging and inconsistent, often dependent on an ad-hoc external model or specific to a certain dataset. To address this, we present a method for quantifying disentanglement that only uses the generative model, by measuring the topological similarity of conditional submanifolds in the learned representation. This method showcases both unsupervised and supervised variants. To illustrate the effectiveness and applicability of our method, we empirically evaluate several state-of-the-art models across multiple datasets. We find that our method ranks models similarly to existing methods. We make our code publicly available at https://github.com/stanfordmlgroup/disentanglement.",
        "conference": "ICLR",
        "中文标题": "通过流形拓扑评估深度生成模型的解缠结能力",
        "摘要翻译": "学习解缠结表示被视为提高生成模型泛化能力、鲁棒性和可解释性的基本任务。然而，衡量解缠结一直具有挑战性且不一致，往往依赖于临时外部模型或特定于某个数据集。为了解决这个问题，我们提出了一种量化解缠结的方法，该方法仅使用生成模型，通过测量学习表示中条件子流形的拓扑相似性来实现。该方法展示了无监督和有监督的变体。为了说明我们方法的有效性和适用性，我们实证评估了多个数据集上的几种最先进模型。我们发现我们的方法与现有方法对模型的排名相似。我们在https://github.com/stanfordmlgroup/disentanglement上公开了我们的代码。",
        "领域": "生成模型、表示学习、深度学习评估",
        "问题": "如何有效且一致地量化深度生成模型的解缠结能力",
        "动机": "当前衡量解缠结的方法依赖于外部模型或特定数据集，缺乏通用性和一致性",
        "方法": "通过测量学习表示中条件子流形的拓扑相似性来量化解缠结，包括无监督和有监督的变体",
        "关键词": [
            "解缠结表示",
            "生成模型",
            "流形拓扑",
            "深度学习评估",
            "表示学习"
        ],
        "涉及的技术概念": {
            "解缠结表示": "指在生成模型中，将数据的不同解释因素分离到表示空间的不同维度，以提高模型的可解释性和泛化能力",
            "流形拓扑": "用于衡量和比较数据表示空间中子流形的结构相似性，作为解缠结程度的指标",
            "条件子流形": "在特定条件下生成的表示空间中的子流形，用于评估生成模型在不同条件下的解缠结表现"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 247,
        "title": "Evaluation of Neural Architectures Trained With Square Loss vs Cross-Entropy in Classification Tasks",
        "html": "https://iclr.cc//virtual/2021/poster/3379",
        "abstract": "Modern neural architectures for classification tasks are trained using the cross-entropy loss, which is widely believed to be empirically superior to the square loss. In this work we provide evidence indicating that this belief may not be well-founded. \nWe explore several major neural architectures and a range of standard benchmark datasets for NLP, automatic speech recognition (ASR) and computer vision tasks to show that these architectures, with the same hyper-parameter settings as reported in the literature, perform comparably or better when trained with the square loss, even after equalizing computational resources.\nIndeed, we observe that the square loss produces better results in the dominant majority of NLP and ASR experiments. Cross-entropy appears to have a slight edge on computer vision tasks.\n\nWe argue that there is little compelling empirical or theoretical evidence indicating a clear-cut advantage to the cross-entropy loss. Indeed, in our experiments, performance on nearly all non-vision tasks  can be improved, sometimes significantly, by switching to the square loss. Furthermore, training with square loss appears to be less sensitive to the randomness in initialization. We posit that\ntraining using the square loss for classification needs to be a part of best practices of modern deep learning on equal footing with cross-entropy. ",
        "conference": "ICLR",
        "中文标题": "分类任务中采用平方损失与交叉熵训练的神经网络架构评估",
        "摘要翻译": "现代神经网络架构在分类任务中通常使用交叉熵损失进行训练，普遍认为交叉熵损失在经验上优于平方损失。本工作提供的证据表明，这一观点可能缺乏充分依据。我们探索了几种主要的神经网络架构和一系列标准基准数据集，涵盖自然语言处理（NLP）、自动语音识别（ASR）和计算机视觉任务，结果显示，在保持文献报道的超参数设置不变的情况下，这些架构在使用平方损失训练时表现相当或更优，即使在计算资源均等化后也是如此。实际上，我们观察到在绝大多数NLP和ASR实验中，平方损失产生了更好的结果。交叉熵在计算机视觉任务上似乎略有优势。我们认为，几乎没有强有力的经验或理论证据表明交叉熵损失具有明显优势。实际上，在我们的实验中，几乎所有非视觉任务的性能都可以通过切换到平方损失而得到提升，有时提升显著。此外，使用平方损失训练似乎对初始化的随机性不那么敏感。我们提出，将平方损失用于分类任务的训练应成为现代深度学习最佳实践的一部分，与交叉熵同等重要。",
        "领域": "自然语言处理, 自动语音识别, 计算机视觉",
        "问题": "评估在分类任务中使用平方损失与交叉熵损失训练的神经网络架构的性能差异",
        "动机": "挑战交叉熵损失在分类任务中普遍被认为优于平方损失的观点，探索平方损失在实际应用中的潜力",
        "方法": "通过比较不同神经网络架构在多种标准数据集上的表现，评估平方损失与交叉熵损失的性能差异",
        "关键词": [
            "平方损失",
            "交叉熵损失",
            "神经网络架构",
            "分类任务",
            "性能评估"
        ],
        "涉及的技术概念": {
            "平方损失": "用于衡量模型预测值与真实值之间差异的损失函数，本研究中用于分类任务的训练",
            "交叉熵损失": "常用于分类任务的损失函数，衡量模型预测概率分布与真实分布之间的差异",
            "神经网络架构": "研究中评估的不同深度学习模型结构，用于比较不同损失函数的效果"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 248,
        "title": "Evaluation of Similarity-based Explanations",
        "html": "https://iclr.cc//virtual/2021/poster/2619",
        "abstract": "Explaining the predictions made by complex machine learning models helps users to understand and accept the predicted outputs with confidence. One promising way is to use similarity-based explanation that provides similar instances as evidence to support model predictions. Several relevance metrics are used for this purpose. In this study, we investigated relevance metrics that can provide reasonable explanations to users. Specifically, we adopted three tests to evaluate whether the relevance metrics satisfy the minimal requirements for similarity-based explanation. Our experiments revealed that the cosine similarity of the gradients of the loss performs best, which would be a recommended choice in practice. In addition, we showed that some metrics perform poorly in our tests and analyzed the reasons of their failure. We expect our insights to help practitioners in selecting appropriate relevance metrics and also aid further researches for designing better relevance metrics for explanations.",
        "conference": "ICLR",
        "中文标题": "基于相似性的解释评估",
        "摘要翻译": "解释复杂机器学习模型的预测有助于用户理解并自信地接受预测输出。一种有前景的方法是使用基于相似性的解释，提供相似的实例作为支持模型预测的证据。为此，使用了多种相关性度量。在本研究中，我们调查了能够为用户提供合理解释的相关性度量。具体来说，我们采用了三种测试来评估相关性度量是否满足基于相似性解释的最低要求。我们的实验表明，损失梯度的余弦相似性表现最佳，这在实际应用中是一个推荐的选择。此外，我们还展示了一些度量在我们的测试中表现不佳，并分析了它们失败的原因。我们希望我们的见解能帮助从业者选择合适的相关性度量，并有助于进一步研究设计更好的解释相关性度量。",
        "领域": "可解释人工智能、机器学习模型解释、相似性度量",
        "问题": "评估和选择能够为复杂机器学习模型预测提供合理解释的相关性度量",
        "动机": "帮助用户理解和接受机器学习模型的预测输出，通过提供基于相似性的解释来增强模型的可信度和透明度",
        "方法": "采用三种测试方法评估不同相关性度量在提供基于相似性解释方面的有效性，包括损失梯度的余弦相似性分析",
        "关键词": [
            "可解释性",
            "相似性度量",
            "机器学习解释",
            "相关性度量",
            "模型透明度"
        ],
        "涉及的技术概念": {
            "基于相似性的解释": "通过提供与预测实例相似的其他实例作为证据，来解释机器学习模型的预测",
            "相关性度量": "用于衡量实例之间相似性的指标，支持基于相似性的解释",
            "损失梯度的余弦相似性": "一种特定的相关性度量方法，通过计算损失函数的梯度之间的余弦相似性来评估实例间的相似性，在本研究中表现最佳"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 249,
        "title": "Evaluations and Methods for Explanation through Robustness Analysis",
        "html": "https://iclr.cc//virtual/2021/poster/3083",
        "abstract": "Feature based explanations, that provide importance of each feature towards the model prediction, is arguably one of the most intuitive ways to explain a model. In this paper, we establish a novel set of evaluation criteria for such feature based explanations by robustness analysis. In contrast to existing evaluations which require us to specify some way to 'remove' features that could inevitably introduces biases and artifacts, we make use of the subtler notion of smaller adversarial perturbations. By optimizing towards our proposed evaluation criteria, we obtain new explanations that are loosely necessary and sufficient for a prediction. We further extend the explanation to extract the set of features that would move the current prediction to a target class by adopting targeted adversarial attack for the robustness analysis. Through experiments across multiple domains and a user study, we validate the usefulness of our evaluation criteria and our derived explanations.",
        "conference": "ICLR",
        "中文标题": "通过鲁棒性分析的解释评估与方法",
        "摘要翻译": "基于特征的解释，即提供每个特征对模型预测的重要性，可以说是解释模型最直观的方式之一。在本文中，我们通过鲁棒性分析为这类基于特征的解释建立了一套新颖的评估标准。与现有的需要指定某种方式来'移除'特征的评估方法相比，这种方法不可避免地引入了偏见和人为因素，我们利用了更细微的较小对抗性扰动的概念。通过优化我们提出的评估标准，我们获得了对预测来说既宽松必要又充分的解释。我们进一步通过采用目标对抗攻击进行鲁棒性分析，将解释扩展到提取那些会将当前预测移动到目标类别的特征集。通过跨多个领域的实验和用户研究，我们验证了我们的评估标准和派生解释的有用性。",
        "领域": "模型解释性、对抗性机器学习、特征重要性分析",
        "问题": "如何评估和生成基于特征的解释，以提高模型解释的直观性和鲁棒性。",
        "动机": "现有的基于特征的解释评估方法需要'移除'特征，这可能会引入偏见和人为因素，因此需要更鲁棒和直观的评估方法。",
        "方法": "通过鲁棒性分析建立评估标准，利用较小对抗性扰动优化解释，并扩展解释以提取影响预测的特征集。",
        "关键词": [
            "模型解释性",
            "鲁棒性分析",
            "对抗性扰动",
            "特征重要性",
            "目标对抗攻击"
        ],
        "涉及的技术概念": {
            "鲁棒性分析": "用于评估基于特征的解释的标准，通过分析模型对扰动的鲁棒性来提高解释的可靠性。",
            "对抗性扰动": "在模型中引入的微小变化，用于测试和优化模型的解释性，而不需要移除特征。",
            "目标对抗攻击": "一种特定的对抗性攻击方法，用于识别那些能够改变模型预测到特定类别的特征集。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 250,
        "title": "Evolving Reinforcement Learning Algorithms",
        "html": "https://iclr.cc//virtual/2021/poster/3056",
        "abstract": "We propose a method for meta-learning reinforcement learning algorithms by searching over the space of computational graphs which compute the loss function for a value-based model-free RL agent to optimize. The learned algorithms are domain-agnostic and can generalize to new environments not seen during training. Our method can both learn from scratch and bootstrap off known existing algorithms, like DQN, enabling interpretable modifications which improve performance. Learning from scratch on simple classical control and gridworld tasks, our method rediscovers the temporal-difference (TD) algorithm. Bootstrapped from DQN, we highlight two learned algorithms which obtain good generalization performance over other classical control tasks, gridworld type tasks, and Atari games. The analysis of the learned algorithm behavior shows resemblance to recently proposed RL algorithms that address overestimation in value-based methods.",
        "conference": "ICLR",
        "中文标题": "进化强化学习算法",
        "摘要翻译": "我们提出了一种通过搜索计算图空间来元学习强化学习算法的方法，这些计算图用于计算基于价值的无模型RL代理的损失函数以进行优化。学习到的算法与领域无关，并且可以推广到训练期间未见的新环境。我们的方法既可以从零开始学习，也可以从已知的现有算法（如DQN）引导，实现可解释的修改以提高性能。在简单的经典控制和网格世界任务上从零开始学习，我们的方法重新发现了时间差分（TD）算法。从DQN引导，我们重点介绍了两种学习到的算法，这些算法在其他经典控制任务、网格世界类型任务和Atari游戏上获得了良好的泛化性能。对学习算法行为的分析显示，与最近提出的解决基于价值方法中高估问题的RL算法有相似之处。",
        "领域": "强化学习、元学习、算法优化",
        "问题": "如何自动发现和优化强化学习算法，使其能够泛化到未见过的环境。",
        "动机": "旨在通过自动化方法发现和优化强化学习算法，减少人工设计算法的需求，提高算法在新环境中的泛化能力。",
        "方法": "通过搜索计算图空间来元学习强化学习算法，支持从零开始学习和从现有算法引导，实现算法的自动优化和泛化。",
        "关键词": [
            "元学习",
            "强化学习",
            "算法优化",
            "计算图",
            "泛化性能"
        ],
        "涉及的技术概念": {
            "计算图": "用于表示和优化强化学习算法的损失函数，是实现算法自动搜索和优化的基础。",
            "时间差分算法": "一种强化学习算法，通过本次预测与下次预测的差异来更新价值函数，论文中通过方法重新发现。",
            "DQN引导": "从深度Q网络（DQN）算法出发，通过修改和优化生成新的强化学习算法，提高泛化性能。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 251,
        "title": "Exemplary Natural Images Explain CNN Activations Better than State-of-the-Art Feature Visualization",
        "html": "https://iclr.cc//virtual/2021/poster/3153",
        "abstract": "Feature visualizations such as synthetic maximally activating images are a widely used explanation method to better understand the information processing of convolutional neural networks (CNNs). At the same time, there are concerns that these visualizations might not accurately represent CNNs' inner workings. Here, we measure how much extremely activating images help humans to predict CNN activations.\nUsing a well-controlled psychophysical paradigm, we compare the informativeness of synthetic images by Olah et al. (2017) with a simple baseline visualization, namely exemplary natural images that also strongly activate a specific feature map. Given either synthetic or natural reference images, human participants choose which of two query images leads to strong positive activation. The experiment is designed to maximize participants' performance, and is the first to probe intermediate instead of final layer representations. We find that synthetic images indeed provide helpful information about feature map activations ($82\\pm4\\%$ accuracy; chance would be $50\\%$). However, natural images --- originally intended to be a baseline --- outperform these synthetic images by a wide margin ($92\\pm2\\%$). Additionally, participants are faster and more confident for natural images, whereas subjective impressions about the interpretability of the feature visualizations by Olah et al. (2017) are mixed. The higher informativeness of natural images holds across most layers, for both expert and lay participants as well as for hand- and randomly-picked feature visualizations. Even if only a single reference image is given, synthetic images provide less information than natural images ($65\\pm5\\%$ vs. $73\\pm4\\%$). In summary, synthetic images from a popular feature visualization method are significantly less informative for assessing CNN activations than natural images. We argue that visualization methods should improve over this simple baseline.",
        "conference": "ICLR",
        "中文标题": "典范自然图像比最先进的特征可视化方法更能解释CNN激活",
        "摘要翻译": "诸如合成最大激活图像之类的特征可视化方法是一种广泛使用的解释方法，旨在更好地理解卷积神经网络（CNNs）的信息处理过程。然而，人们担心这些可视化可能无法准确反映CNNs的内部工作机制。在此，我们测量了极端激活图像在帮助人类预测CNN激活方面的效果。通过一个控制良好的心理物理实验范式，我们比较了Olah等人（2017年）提出的合成图像与一种简单的基线可视化方法——即同样能强烈激活特定特征图的典范自然图像——的信息量。给定合成或自然的参考图像，人类参与者选择哪一对查询图像会导致强烈的正激活。该实验设计旨在最大化参与者的表现，并且是首次探究中间层而非最终层的表征。我们发现，合成图像确实提供了关于特征图激活的有用信息（准确率为82±4%；随机猜测的准确率为50%）。然而，原本作为基线使用的自然图像，其表现远超这些合成图像（准确率为92±2%）。此外，参与者对自然图像的反应更快、更有信心，而对于Olah等人（2017年）提出的特征可视化的可解释性，主观印象则褒贬不一。自然图像更高的信息量在大多数层中都成立，无论是对专家还是普通参与者，也无论是手工挑选还是随机挑选的特征可视化。即使只提供单一参考图像，合成图像提供的信息也少于自然图像（65±5% vs. 73±4%）。总之，来自一种流行特征可视化方法的合成图像在评估CNN激活方面的信息量显著低于自然图像。我们认为，可视化方法应超越这一简单基线。",
        "领域": "计算机视觉解释性研究、深度学习模型可视化、神经网络可解释性",
        "问题": "评估和比较合成特征可视化图像与自然图像在解释CNN激活方面的有效性",
        "动机": "探究当前流行的特征可视化方法是否能准确反映CNN的内部工作机制，以及是否存在更简单有效的方法",
        "方法": "通过心理物理实验范式，比较合成特征可视化图像与自然图像在帮助人类预测CNN激活方面的表现",
        "关键词": [
            "特征可视化",
            "CNN激活解释",
            "自然图像",
            "模型可解释性",
            "心理物理实验"
        ],
        "涉及的技术概念": {
            "特征可视化": "通过生成能够最大激活CNN特定特征图的图像，来理解和解释CNN的内部工作机制",
            "心理物理实验范式": "用于测量人类参与者对不同类型图像在预测CNN激活方面表现的科学实验方法",
            "CNN激活": "指卷积神经网络在处理输入图像时，各层特征图的响应强度，是理解网络行为的关键指标"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 252,
        "title": "Explainable Deep One-Class Classification",
        "html": "https://iclr.cc//virtual/2021/poster/2521",
        "abstract": "Deep one-class classification variants for anomaly detection learn a mapping that concentrates nominal samples in feature space causing anomalies to be mapped away. Because this transformation is highly non-linear, finding interpretations poses a significant challenge. In this paper we present an explainable deep one-class classification method, Fully Convolutional Data Description (FCDD), where the mapped samples are themselves also an explanation heatmap. FCDD yields competitive detection performance and provides reasonable explanations on common anomaly detection benchmarks with CIFAR-10 and ImageNet. On MVTec-AD, a recent manufacturing dataset offering ground-truth anomaly maps, FCDD sets a new state of the art in the unsupervised setting. Our method can incorporate ground-truth anomaly maps during training and using even a few of these (~5) improves performance significantly. Finally, using FCDD's explanations we demonstrate the vulnerability of deep one-class classification models to spurious image features such as image watermarks.",
        "conference": "ICLR",
        "中文标题": "可解释的深度单类分类",
        "摘要翻译": "用于异常检测的深度单类分类变体学习一种映射，该映射将正常样本集中在特征空间中，导致异常样本被映射远离。由于这种变换是高度非线性的，寻找解释构成了一个重大挑战。在本文中，我们提出了一种可解释的深度单类分类方法，全卷积数据描述（FCDD），其中映射的样本本身也是一个解释热图。FCDD在常见的异常检测基准测试中，如CIFAR-10和ImageNet，提供了有竞争力的检测性能和合理的解释。在MVTec-AD上，这是一个提供真实异常图的最新制造数据集，FCDD在无监督设置下设立了新的技术状态。我们的方法可以在训练过程中融入真实异常图，并且使用其中的少数（约5个）可以显著提高性能。最后，利用FCDD的解释，我们展示了深度单类分类模型对虚假图像特征（如图像水印）的脆弱性。",
        "领域": "异常检测",
        "问题": "深度单类分类模型的可解释性问题",
        "动机": "解决深度单类分类模型在异常检测中由于高度非线性变换导致解释困难的问题",
        "方法": "提出全卷积数据描述（FCDD）方法，通过生成解释热图来提高模型的可解释性",
        "关键词": [
            "异常检测",
            "单类分类",
            "可解释性",
            "全卷积数据描述",
            "热图"
        ],
        "涉及的技术概念": {
            "全卷积数据描述（FCDD）": "一种可解释的深度单类分类方法，通过生成解释热图来提高模型的可解释性",
            "解释热图": "用于可视化模型决策过程的工具，帮助理解模型为何将某些样本识别为异常",
            "异常检测": "识别与大多数数据显著不同的数据点或模式的技术"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 253,
        "title": "Explainable Subgraph Reasoning for Forecasting on Temporal Knowledge Graphs",
        "html": "https://iclr.cc//virtual/2021/poster/3378",
        "abstract": "Modeling time-evolving knowledge graphs (KGs) has recently gained increasing interest. Here, graph representation learning has become the dominant paradigm for link prediction on temporal KGs. However, the embedding-based approaches largely operate in a black-box fashion, lacking the ability to interpret their predictions. This paper provides a link forecasting framework that reasons over query-relevant subgraphs of temporal KGs and jointly models the structural dependencies and the temporal dynamics. Especially, we propose a temporal relational attention mechanism and a novel reverse representation update scheme to guide the extraction of an enclosing subgraph around the query. The subgraph is expanded by an iterative sampling of temporal neighbors and by attention propagation. Our approach provides human-understandable evidence explaining the forecast. We evaluate our model on four benchmark temporal knowledge graphs for the link forecasting task. While being more explainable, our model obtains a relative improvement of up to 20 $\\%$ on Hits@1 compared to the previous best temporal KG forecasting method. We also conduct a survey with 53 respondents, and the results show that the evidence extracted by the model for link forecasting is aligned with human understanding. ",
        "conference": "ICLR",
        "success": true,
        "中文标题": "可解释的子图推理在时序知识图谱预测中的应用",
        "摘要翻译": "近年来，对时间演化知识图谱（KGs）的建模越来越受到关注。在此背景下，图表示学习已成为时序KGs上链接预测的主导范式。然而，基于嵌入的方法大多以黑盒方式运行，缺乏解释其预测的能力。本文提供了一个链接预测框架，该框架对时序KGs的查询相关子图进行推理，并共同建模结构依赖性和时间动态性。特别是，我们提出了一种时序关系注意力机制和一种新颖的反向表示更新方案，以指导围绕查询提取封闭子图。通过迭代采样时序邻居和注意力传播，子图得以扩展。我们的方法提供了可被人理解的证据来解释预测。我们在四个基准时序知识图谱上评估了我们的模型，用于链接预测任务。在更具解释性的同时，我们的模型在Hits@1上相比之前最佳的时序KG预测方法获得了高达20%的相对改进。我们还对53名受访者进行了调查，结果显示模型为链接预测提取的证据与人类理解一致。",
        "领域": "时序知识图谱推理",
        "问题": "如何提高时序知识图谱链接预测的解释性和准确性",
        "动机": "解决现有基于嵌入的时序知识图谱链接预测方法缺乏解释性的问题",
        "方法": "提出了一种时序关系注意力机制和反向表示更新方案，用于提取和扩展查询相关的子图",
        "关键词": [
            "时序知识图谱",
            "链接预测",
            "可解释性",
            "注意力机制",
            "子图推理"
        ],
        "涉及的技术概念": {
            "时序关系注意力机制": "用于指导提取查询相关的子图，增强模型对时序动态性的捕捉",
            "反向表示更新方案": "一种新颖的表示更新方法，用于优化子图的扩展过程",
            "子图推理": "通过迭代采样和注意力传播扩展子图，为链接预测提供可解释的证据"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 254,
        "title": "Explaining by Imitating: Understanding Decisions by Interpretable Policy Learning",
        "html": "https://iclr.cc//virtual/2021/poster/2780",
        "abstract": "Understanding human behavior from observed data is critical for transparency and accountability in decision-making. Consider real-world settings such as healthcare, in which modeling a decision-maker’s policy is challenging—with no access to underlying states, no knowledge of environment dynamics, and no allowance for live experimentation. We desire learning a data-driven representation of decision- making behavior that (1) inheres transparency by design, (2) accommodates partial observability, and (3) operates completely offline. To satisfy these key criteria, we propose a novel model-based Bayesian method for interpretable policy learning (“Interpole”) that jointly estimates an agent’s (possibly biased) belief-update process together with their (possibly suboptimal) belief-action mapping. Through experiments on both simulated and real-world data for the problem of Alzheimer’s disease diagnosis, we illustrate the potential of our approach as an investigative device for auditing, quantifying, and understanding human decision-making behavior.",
        "conference": "ICLR",
        "中文标题": "通过模仿解释：通过可解释策略学习理解决策",
        "摘要翻译": "从观察数据中理解人类行为对于决策的透明度和问责制至关重要。考虑现实世界中的设置，如医疗保健，其中建模决策者的策略具有挑战性——无法访问底层状态，不了解环境动态，也不允许进行实时实验。我们希望学习一种数据驱动的决策行为表示，该表示（1）设计上具有透明度，（2）适应部分可观察性，（3）完全离线操作。为了满足这些关键标准，我们提出了一种新颖的基于模型的贝叶斯方法，用于可解释的策略学习（“Interpole”），该方法联合估计代理的（可能有偏见的）信念更新过程及其（可能次优的）信念-行动映射。通过对阿尔茨海默病诊断问题的模拟和真实世界数据的实验，我们展示了我们的方法作为审计、量化和理解人类决策行为的调查工具的潜力。",
        "领域": "医疗决策分析、可解释人工智能、行为建模",
        "问题": "在无法访问底层状态、不了解环境动态且不允许实时实验的情况下，如何从观察数据中学习透明、适应部分可观察性且完全离线操作的决策行为表示。",
        "动机": "提高决策过程的透明度和可解释性，特别是在医疗保健等关键领域，以支持审计、量化和理解人类决策行为。",
        "方法": "提出了一种基于模型的贝叶斯方法（Interpole），联合估计代理的信念更新过程和信念-行动映射，以学习可解释的策略。",
        "关键词": [
            "可解释策略学习",
            "贝叶斯方法",
            "医疗决策",
            "行为建模",
            "透明度"
        ],
        "涉及的技术概念": {
            "可解释策略学习": "旨在通过学习决策策略来提高决策过程的透明度和可解释性，特别是在复杂或关键的应用场景中。",
            "贝叶斯方法": "用于联合估计代理的信念更新过程和信念-行动映射，以处理不确定性和部分可观察性。",
            "信念-行动映射": "描述了代理如何根据其当前信念选择行动，是理解决策行为的关键组成部分。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 255,
        "title": "Explaining the Efficacy of Counterfactually Augmented Data",
        "html": "https://iclr.cc//virtual/2021/poster/3111",
        "abstract": "In attempts to produce machine learning models less reliant on spurious patterns in NLP datasets, researchers have recently proposed curating counterfactually augmented data (CAD) via a human-in-the-loop process in which given some documents and their (initial) labels, humans must revise the text to make a counterfactual label applicable. Importantly, edits that are not necessary to flip the applicable label are prohibited. Models trained on the augmented (original and revised) data appear, empirically, to rely less on semantically irrelevant words and to generalize better out of domain. While this work draws loosely on causal thinking, the underlying causal model (even at an abstract level) and the principles underlying the observed out-of-domain improvements remain unclear. In this paper, we introduce a toy analog based on linear Gaussian models, observing interesting relationships between causal models, measurement noise, out-of-domain generalization, and reliance on spurious signals. Our analysis provides some insights that help to explain the efficacy of CAD. Moreover, we develop the hypothesis that while adding noise to causal features should degrade both in-domain and out-of-domain performance, adding noise to non-causal features should lead to relative improvements in out-of-domain performance. This idea inspires a speculative test for determining whether a feature attribution technique has identified the causal spans. If adding noise (e.g., by random word flips) to the highlighted spans degrades both in-domain and out-of-domain performance on a battery of challenge datasets, but adding noise to the complement gives improvements out-of-domain, this suggests we have identified causal spans. Thus, we present a large scale empirical study comparing spans edited to create CAD to those selected by attention and saliency maps. Across numerous challenge domains and models, we find that the hypothesized phenomenon is pronounced for CAD.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "解释反事实增强数据的有效性",
        "摘要翻译": "在尝试生产较少依赖NLP数据集中虚假模式的机器学习模型时，研究人员最近提出通过人在环过程来策划反事实增强数据（CAD），其中给定一些文档及其（初始）标签，人类必须修改文本以使反事实标签适用。重要的是，禁止进行不必要翻转适用标签的编辑。经验上，训练于增强（原始和修订）数据的模型似乎较少依赖语义上无关的词语，并且在域外泛化得更好。虽然这项工作松散地借鉴了因果思维，但基础的因果模型（即使在抽象层面上）以及观察到的域外改进背后的原则仍不清楚。在本文中，我们引入了一个基于线性高斯模型的玩具类比，观察了因果模型、测量噪声、域外泛化和对虚假信号的依赖之间有趣的关系。我们的分析提供了一些有助于解释CAD有效性的见解。此外，我们提出了一个假设，即虽然向因果特征添加噪声应该会降低域内和域外的性能，但向非因果特征添加噪声应该会导致域外性能的相对改善。这一想法激发了一个推测性测试，用于确定特征归因技术是否已经识别出因果跨度。如果在突出显示的跨度上添加噪声（例如，通过随机单词翻转）会在一系列挑战数据集上降低域内和域外的性能，但在补集上添加噪声会提高域外性能，这表明我们已经识别出了因果跨度。因此，我们提出了一项大规模实证研究，比较了为创建CAD而编辑的跨度与通过注意力和显著性图选择的跨度。在众多挑战领域和模型中，我们发现假设的现象在CAD中尤为明显。",
        "领域": "自然语言处理与视觉结合",
        "问题": "如何减少机器学习模型对NLP数据集中虚假模式的依赖",
        "动机": "探索反事实增强数据（CAD）在提高模型泛化能力和减少对无关语义依赖方面的有效性",
        "方法": "通过人在环过程策划CAD，并基于线性高斯模型进行玩具类比分析",
        "关键词": [
            "反事实增强数据",
            "域外泛化",
            "因果模型",
            "虚假信号",
            "特征归因"
        ],
        "涉及的技术概念": {
            "反事实增强数据（CAD）": "通过人类编辑文本以适用反事实标签，旨在减少模型对虚假模式的依赖",
            "线性高斯模型": "用于分析因果模型、测量噪声与域外泛化之间关系的简化模型",
            "特征归因技术": "用于识别文本中对模型预测有因果影响的特定部分的技术"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 256,
        "title": "Exploring Balanced Feature Spaces for Representation Learning",
        "html": "https://iclr.cc//virtual/2021/poster/2977",
        "abstract": "Existing self-supervised learning (SSL) methods are mostly applied for training representation models from artificially balanced datasets (e.g., ImageNet). It is unclear how well they will perform in the practical scenarios where datasets are often imbalanced w.r.t. the classes. Motivated by this question, we conduct a series of studies on the performance of self-supervised contrastive learning and supervised learning methods over multiple datasets where training instance distributions vary from a balanced one to a long-tailed one. Our findings are quite intriguing. Different from supervised methods with large performance drop, the self-supervised contrastive learning methods perform stably well even when the datasets are heavily imbalanced. This motivates us to explore the balanced feature spaces learned by contrastive learning, where the feature representations present similar linear separability w.r.t. all the classes. Our further experiments reveal that a representation model generating a balanced feature space can generalize better than that yielding an imbalanced one across multiple settings. Inspired by these insights, we develop a novel representation learning method, called $k$-positive contrastive learning. It effectively combines strengths of the supervised method and the contrastive learning method to learn representations that are both discriminative and balanced. Extensive experiments demonstrate its superiority on multiple recognition tasks. Remarkably, it achieves new state-of-the-art on challenging long-tailed recognition benchmarks. Code and models will be released.",
        "conference": "ICLR",
        "中文标题": "探索平衡特征空间用于表示学习",
        "摘要翻译": "现有的自监督学习（SSL）方法大多用于从人工平衡的数据集（如ImageNet）中训练表示模型。目前尚不清楚这些方法在数据集类别不平衡的实际场景中表现如何。受此问题启发，我们对自监督对比学习和监督学习方法在多个数据集上的性能进行了一系列研究，这些数据集的训练实例分布从平衡到长尾不等。我们的发现相当有趣。与性能大幅下降的监督方法不同，自监督对比学习方法即使在数据集严重不平衡的情况下也能稳定表现良好。这激励我们探索通过对比学习学到的平衡特征空间，其中特征表示在所有类别上都呈现相似的线性可分性。我们进一步的实验揭示，生成平衡特征空间的表示模型在多种设置下比产生不平衡特征空间的模型具有更好的泛化能力。受这些见解的启发，我们开发了一种新的表示学习方法，称为$k$-正对比学习。它有效地结合了监督方法和对比学习方法的优势，学习既具有区分性又平衡的表示。大量实验证明了其在多个识别任务上的优越性。值得注意的是，它在具有挑战性的长尾识别基准上达到了新的最先进水平。代码和模型将公开发布。",
        "领域": "自监督学习",
        "问题": "研究自监督学习方法在类别不平衡数据集上的表现",
        "动机": "探索自监督对比学习在类别不平衡数据集上的稳定性和有效性",
        "方法": "开发了一种新的表示学习方法，称为$k$-正对比学习，结合监督和对比学习的优势",
        "关键词": [
            "自监督学习",
            "对比学习",
            "长尾识别",
            "表示学习",
            "特征空间"
        ],
        "涉及的技术概念": {
            "自监督学习": "一种不依赖人工标注数据的学习方法，通过数据自身的结构来学习表示",
            "对比学习": "一种自监督学习方法，通过比较正负样本来学习数据的表示",
            "长尾识别": "处理类别分布极不平衡的数据集的识别任务，其中少数类别有大量样本，而多数类别样本稀少"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 257,
        "title": "Exploring the Uncertainty Properties of Neural Networks’ Implicit Priors in the Infinite-Width Limit",
        "html": "https://iclr.cc//virtual/2021/poster/2865",
        "abstract": "Modern deep learning models have achieved great success in predictive accuracy for many data modalities. However, their application to many real-world tasks is restricted by poor uncertainty estimates, such as overconfidence on out-of-distribution (OOD) data and ungraceful failing under distributional shift. Previous benchmarks have found that ensembles of neural networks (NNs) are typically the best calibrated models on OOD data. Inspired by this, we leverage recent theoretical advances that characterize the function-space prior of an infinitely-wide NN as a Gaussian process, termed the neural network Gaussian process (NNGP). We use the NNGP with a softmax link function to build a probabilistic model for multi-class classification and marginalize over the latent Gaussian outputs to sample from the posterior. This gives us a better understanding of the implicit prior NNs place on function space and allows a direct comparison of the calibration of the NNGP and its finite-width analogue. We also examine the calibration of previous approaches to classification with the NNGP, which treat classification problems as regression to the one-hot labels. In this case the Bayesian posterior is exact, and we compare several heuristics to generate a categorical distribution over classes. We find these methods are well calibrated under distributional shift. Finally, we consider an infinite-width final layer in conjunction with a pre-trained embedding. This replicates the important practical use case of transfer learning and allows scaling to significantly larger datasets. As well as achieving competitive predictive accuracy, this approach is better calibrated than its finite width analogue.",
        "conference": "ICLR",
        "中文标题": "探索无限宽度极限下神经网络隐式先验的不确定性特性",
        "摘要翻译": "现代深度学习模型在许多数据模态的预测准确性方面取得了巨大成功。然而，它们在许多现实世界任务中的应用受到不良不确定性估计的限制，例如对分布外（OOD）数据的过度自信以及在分布变化下的不优雅失败。之前的基准测试发现，神经网络（NNs）的集成通常是在OOD数据上校准最好的模型。受此启发，我们利用最近的理论进展，将无限宽度NN的函数空间先验特征化为高斯过程，称为神经网络高斯过程（NNGP）。我们使用带有softmax链接函数的NNGP来构建多类分类的概率模型，并对潜在高斯输出进行边缘化以从后验中采样。这使我们更好地理解了NNs在函数空间上放置的隐式先验，并允许直接比较NNGP及其有限宽度类似物的校准。我们还检查了之前使用NNGP进行分类的方法的校准，这些方法将分类问题视为对one-hot标签的回归。在这种情况下，贝叶斯后验是精确的，我们比较了几种启发式方法来生成类别的分类分布。我们发现这些方法在分布变化下校准良好。最后，我们考虑与预训练嵌入相结合的无限宽度最终层。这复制了迁移学习的重要实际用例，并允许扩展到更大的数据集。除了实现有竞争力的预测准确性外，这种方法比其有限宽度类似物校准得更好。",
        "领域": "深度学习不确定性估计, 高斯过程应用, 神经网络校准",
        "问题": "解决深度学习模型在不确定性估计上的不足，特别是在分布外数据和分布变化下的表现问题。",
        "动机": "受神经网络集成在OOD数据上表现良好的启发，探索无限宽度神经网络隐式先验的不确定性特性，以提升模型的校准能力和预测准确性。",
        "方法": "利用神经网络高斯过程（NNGP）构建多类分类的概率模型，通过边缘化潜在高斯输出来采样后验，比较NNGP与有限宽度网络的校准性能，并探索在迁移学习中的应用。",
        "关键词": [
            "神经网络高斯过程",
            "不确定性估计",
            "模型校准",
            "无限宽度极限",
            "迁移学习"
        ],
        "涉及的技术概念": {
            "神经网络高斯过程（NNGP）": "将无限宽度神经网络的特征化为高斯过程，用于构建概率模型和理解神经网络的隐式先验。",
            "边缘化潜在高斯输出": "通过对潜在高斯输出进行边缘化处理，从后验分布中采样，以评估模型的不确定性。",
            "迁移学习": "在预训练嵌入的基础上应用无限宽度最终层，扩展模型到更大数据集，同时保持或提升预测准确性和校准性能。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 258,
        "title": "Expressive Power of Invariant and Equivariant Graph Neural Networks",
        "html": "https://iclr.cc//virtual/2021/poster/2559",
        "abstract": "Various classes of Graph Neural Networks (GNN) have been proposed and shown to be successful in a wide range of applications with graph structured data. In this paper, we propose a theoretical framework able to compare the expressive power of these GNN architectures. The current universality theorems only apply to intractable classes of GNNs. Here, we prove the first approximation guarantees for practical GNNs, paving the way for a better understanding of their generalization. Our theoretical results are proved for invariant GNNs computing a graph embedding (permutation of the nodes of the input graph does not affect the output) and equivariant GNNs computing an embedding of the nodes (permutation of the input permutes the output). We show that Folklore Graph Neural Networks (FGNN), which are tensor based GNNs augmented with matrix multiplication are the most expressive architectures proposed so far for a given tensor order. We illustrate our results on the Quadratic Assignment Problem (a NP-Hard combinatorial problem) by showing that FGNNs are able to learn how to solve the problem, leading to much better average performances than existing algorithms (based on spectral, SDP or other GNNs architectures). On a practical side, we also implement masked tensors to handle batches of graphs of varying sizes. ",
        "conference": "ICLR",
        "中文标题": "不变与等变图神经网络的表达能力",
        "摘要翻译": "各类图神经网络（GNN）已被提出，并在图结构数据的广泛应用中显示出成功。在本文中，我们提出了一个理论框架，能够比较这些GNN架构的表达能力。当前的普遍性定理仅适用于难以处理的GNN类别。在此，我们首次证明了实用GNN的近似保证，为更好地理解其泛化能力铺平了道路。我们的理论结果针对计算图嵌入的不变GNN（输入图的节点排列不影响输出）和计算节点嵌入的等变GNN（输入的排列会排列输出）进行了证明。我们展示了基于张量的GNN（FGNN）通过矩阵乘法增强，是迄今为止提出的对于给定张量阶数最具表达力的架构。我们通过在二次分配问题（一个NP难组合问题）上展示FGNN能够学习如何解决问题，从而比现有算法（基于谱、SDP或其他GNN架构）获得更好的平均性能，来阐明我们的结果。在实际应用方面，我们还实现了掩码张量以处理不同大小的图批次。",
        "领域": "图神经网络、组合优化、深度学习理论",
        "问题": "比较不同图神经网络架构的表达能力，并证明实用GNN的近似保证",
        "动机": "为了更好地理解图神经网络的泛化能力，并推动其在组合优化等领域的应用",
        "方法": "提出理论框架比较GNN表达能力，证明实用GNN的近似保证，并通过FGNN架构在二次分配问题上的应用验证理论",
        "关键词": [
            "图神经网络",
            "表达能力",
            "组合优化",
            "二次分配问题",
            "掩码张量"
        ],
        "涉及的技术概念": {
            "不变GNN": "计算图嵌入的GNN，输入图的节点排列不影响输出",
            "等变GNN": "计算节点嵌入的GNN，输入的排列会排列输出",
            "FGNN": "基于张量的GNN通过矩阵乘法增强，对于给定张量阶数最具表达力的架构"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 259,
        "title": "Extracting Strong Policies for Robotics Tasks from Zero-Order Trajectory Optimizers",
        "html": "https://iclr.cc//virtual/2021/poster/3209",
        "abstract": "Solving high-dimensional, continuous robotic tasks is a challenging optimization problem. Model-based methods that rely on zero-order optimizers like the cross-entropy method (CEM) have so far shown strong performance and are considered state-of-the-art in the model-based reinforcement learning community. However, this success comes at the cost of high computational complexity, being therefore not suitable for real-time control. In this paper, we propose a technique to jointly optimize the trajectory and distill a policy, which is essential for fast execution in real robotic systems. Our method builds upon standard approaches, like guidance cost and dataset aggregation, and introduces a novel adaptive factor which prevents the optimizer from collapsing to the learner's behavior at the beginning of the training. The extracted policies reach unprecedented performance on challenging tasks as making a humanoid stand up and opening a door without reward shaping",
        "conference": "ICLR",
        "中文标题": "从零阶轨迹优化器中提取机器人任务的强策略",
        "摘要翻译": "解决高维、连续的机器人任务是一个具有挑战性的优化问题。迄今为止，依赖于零阶优化器（如交叉熵方法CEM）的基于模型的方法表现出了强大的性能，并被认为是基于模型的强化学习领域的先进技术。然而，这种成功是以高计算复杂度为代价的，因此不适合实时控制。在本文中，我们提出了一种技术，联合优化轨迹并提炼策略，这对于在真实机器人系统中快速执行至关重要。我们的方法建立在标准方法之上，如指导成本和数据集聚合，并引入了一种新的自适应因子，防止优化器在训练开始时崩溃到学习者的行为。提取的策略在具有挑战性的任务上达到了前所未有的性能，如让一个人形机器人站立起来和打开门，而无需奖励塑造。",
        "领域": "机器人控制、强化学习、轨迹优化",
        "问题": "如何在保证性能的同时，降低高维连续机器人任务优化过程中的计算复杂度，使其适用于实时控制。",
        "动机": "现有的基于零阶优化器的方法虽然性能强大，但计算复杂度高，不适合实时控制，因此需要一种既能保持性能又能快速执行的方法。",
        "方法": "提出了一种联合优化轨迹和提炼策略的技术，引入了自适应因子防止优化器过早崩溃到学习者的行为，结合了指导成本和数据集聚合等标准方法。",
        "关键词": [
            "机器人控制",
            "强化学习",
            "轨迹优化",
            "策略提炼",
            "自适应优化"
        ],
        "涉及的技术概念": {
            "零阶优化器": "如交叉熵方法（CEM），用于基于模型的强化学习中的高维连续任务优化。",
            "策略提炼": "从优化的轨迹中提取策略，以实现快速执行。",
            "自适应因子": "防止优化器在训练初期崩溃到学习者的行为，保持优化过程的稳定性。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 260,
        "title": "Extreme Memorization via Scale of Initialization",
        "html": "https://iclr.cc//virtual/2021/poster/3091",
        "abstract": "We construct an experimental setup in which changing the scale of initialization strongly impacts the implicit regularization induced by SGD, interpolating from good generalization performance to completely memorizing the training set while making little progress on the test set. Moreover, we find that the extent and manner in which generalization ability is affected depends on the activation and loss function used, with sin activation being the most extreme. In the case of the homogeneous ReLU activation, we show that this behavior can be attributed to the loss function. Our empirical investigation reveals that increasing the scale of initialization correlates with misalignment of representations and gradients across examples in the same class. This insight allows us to device an alignment measure over gradients and representations which can capture this phenomenon. We demonstrate that our alignment measure correlates with generalization of deep models trained on image classification tasks.",
        "conference": "ICLR",
        "中文标题": "通过初始化规模实现极端记忆",
        "摘要翻译": "我们构建了一个实验设置，其中改变初始化的规模强烈影响了由SGD引起的隐式正则化，从良好的泛化性能到完全记忆训练集而在测试集上进展甚微之间进行插值。此外，我们发现泛化能力受影响的程度和方式取决于所使用的激活和损失函数，其中sin激活最为极端。在均匀ReLU激活的情况下，我们表明这种行为可以归因于损失函数。我们的实证调查显示，增加初始化规模与同一类别中示例之间的表示和梯度的不对齐相关。这一见解使我们能够设计出对梯度和表示的对齐度量，可以捕捉到这一现象。我们证明了我们的对齐度量与在图像分类任务上训练的深度模型的泛化相关。",
        "领域": "深度学习优化、神经网络训练、图像分类",
        "问题": "研究初始化规模对SGD隐式正则化的影响，以及如何通过调整初始化规模来控制模型的记忆能力和泛化能力。",
        "动机": "探索初始化规模如何影响深度学习模型的记忆和泛化能力，以及如何通过设计对齐度量来预测模型的泛化性能。",
        "方法": "通过实验改变初始化规模，观察其对模型记忆训练数据和泛化能力的影响，并设计一种对齐度量来捕捉表示和梯度的不对齐现象。",
        "关键词": [
            "初始化规模",
            "隐式正则化",
            "记忆能力",
            "泛化能力",
            "对齐度量"
        ],
        "涉及的技术概念": {
            "隐式正则化": "由SGD优化过程中自然引入的正则化效果，影响模型的泛化能力。",
            "初始化规模": "神经网络权重初始化的规模，影响训练动态和模型的最终性能。",
            "对齐度量": "设计用于衡量不同示例间梯度和表示对齐程度的指标，用于预测模型的泛化能力。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 261,
        "title": "Factorizing Declarative and Procedural Knowledge in Structured, Dynamical Environments",
        "html": "https://iclr.cc//virtual/2021/poster/2917",
        "abstract": "Modeling a structured, dynamic environment like a video game requires keeping track of the objects and their states (declarative knowledge) as well as predicting how objects behave (procedural knowledge). Black-box models with a monolithic hidden state often fail to apply procedural knowledge consistently and uniformly, i.e., they lack systematicity. For example, in a video game, correct prediction of one enemy's trajectory does not ensure correct prediction of another's. We address this issue via an architecture that factorizes declarative and procedural knowledge and that imposes modularity within each form of knowledge. The architecture consists of active modules called object files that maintain the state of a single object and invoke passive external knowledge sources called schemata that prescribe state updates. To use a video game as an illustration, two enemies of the same type will share schemata but will have separate object files to encode their distinct state (e.g., health, position). We propose to use attention to determine which object files to update, the selection of schemata, and the propagation of information between object files. The resulting architecture is a drop-in replacement conforming to the same input-output interface as normal recurrent networks (e.g., LSTM, GRU) yet achieves substantially better generalization on environments that have multiple object tokens of the same type, including a challenging intuitive physics benchmark.\n",
        "conference": "ICLR",
        "中文标题": "结构化动态环境中声明性与程序性知识的分解",
        "摘要翻译": "建模一个结构化、动态的环境，如视频游戏，需要跟踪对象及其状态（声明性知识）以及预测对象行为（程序性知识）。具有单一隐藏状态的黑盒模型往往无法一致且统一地应用程序性知识，即它们缺乏系统性。例如，在视频游戏中，正确预测一个敌人的轨迹并不能确保正确预测另一个敌人的轨迹。我们通过一种架构来解决这个问题，该架构分解了声明性和程序性知识，并在每种知识形式内强加了模块化。该架构由称为对象文件的主动模块组成，这些模块维护单个对象的状态并调用称为图式的被动外部知识源来规定状态更新。以视频游戏为例，两个相同类型的敌人将共享图式，但将有单独的对象文件来编码它们的不同状态（例如，健康、位置）。我们建议使用注意力来确定要更新的对象文件、图式的选择以及对象文件之间的信息传播。由此产生的架构是一个即插即用的替代品，符合与普通循环网络（如LSTM、GRU）相同的输入-输出接口，但在具有多个相同类型对象令牌的环境上实现了显著更好的泛化，包括一个具有挑战性的直观物理基准。",
        "领域": "动态环境建模、知识表示与推理、注意力机制应用",
        "问题": "如何在结构化动态环境中一致且系统地应用声明性和程序性知识",
        "动机": "解决黑盒模型在处理动态环境时缺乏系统性和一致性的问题",
        "方法": "提出一种分解声明性和程序性知识的架构，利用对象文件和图式模块化知识表示，并通过注意力机制管理信息流",
        "关键词": [
            "知识分解",
            "模块化架构",
            "注意力机制",
            "动态环境建模",
            "系统泛化"
        ],
        "涉及的技术概念": {
            "对象文件": "主动模块，用于维护单个对象的状态并调用外部知识源进行状态更新",
            "图式": "被动外部知识源，规定对象状态更新的规则",
            "注意力机制": "用于确定更新哪些对象文件、选择哪些图式以及如何在对象文件之间传播信息的技术"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 262,
        "title": "FairBatch: Batch Selection for Model Fairness",
        "html": "https://iclr.cc//virtual/2021/poster/2652",
        "abstract": "Training a fair machine learning model is essential to prevent demographic disparity. Existing techniques for improving model fairness require broad changes in either data preprocessing or model training, rendering themselves difficult-to-adopt for potentially already complex machine learning systems. We address this problem via the lens of bilevel optimization. While keeping the standard training algorithm as an inner optimizer, we incorporate an outer optimizer so as to equip the inner problem with an additional functionality: Adaptively selecting minibatch sizes for the purpose of improving model fairness. Our batch selection algorithm, which we call FairBatch, implements this optimization and supports prominent fairness measures: equal opportunity, equalized odds, and demographic parity. FairBatch comes with a significant implementation benefit -- it does not require any modification to data preprocessing or model training. For instance, a single-line change of PyTorch code for replacing batch selection part of model training suffices to employ FairBatch. Our experiments conducted both on synthetic and benchmark real data demonstrate that FairBatch can provide such functionalities while achieving comparable (or even greater) performances against the state of the arts.  Furthermore, FairBatch can readily improve fairness of any pre-trained model simply via fine-tuning. It is also compatible with existing batch selection techniques intended for different purposes, such as faster convergence, thus gracefully achieving multiple purposes.",
        "conference": "ICLR",
        "中文标题": "FairBatch：面向模型公平性的批次选择",
        "摘要翻译": "训练一个公平的机器学习模型对于防止人口统计差异至关重要。现有的提高模型公平性的技术需要在数据预处理或模型训练中进行广泛的更改，这使得它们难以在可能已经复杂的机器学习系统中采用。我们通过双层优化的视角来解决这个问题。在保持标准训练算法作为内部优化器的同时，我们引入了一个外部优化器，以便为内部问题配备一个额外的功能：为了改善模型公平性而自适应地选择小批量大小。我们的批次选择算法，我们称之为FairBatch，实现了这种优化，并支持突出的公平性度量：平等机会、平等化赔率和人口统计平等。FairBatch带来了一个显著的实现优势——它不需要对数据预处理或模型训练进行任何修改。例如，只需更改PyTorch代码中的一行以替换模型训练的批次选择部分，就足以使用FairBatch。我们在合成数据和基准真实数据上进行的实验表明，FairBatch可以提供这样的功能，同时实现与现有技术相当（甚至更好）的性能。此外，FairBatch可以通过微调轻松提高任何预训练模型的公平性。它还与旨在不同目的的现有批次选择技术兼容，例如更快收敛，从而优雅地实现多个目的。",
        "领域": "机器学习公平性、优化算法、深度学习",
        "问题": "如何在不需要广泛更改数据预处理或模型训练的情况下，提高机器学习模型的公平性。",
        "动机": "解决现有提高模型公平性技术难以在复杂机器学习系统中采用的问题。",
        "方法": "通过双层优化视角，引入外部优化器自适应选择小批量大小以改善模型公平性。",
        "关键词": [
            "模型公平性",
            "批次选择",
            "双层优化",
            "自适应学习",
            "微调"
        ],
        "涉及的技术概念": {
            "双层优化": "在保持标准训练算法作为内部优化器的同时，引入外部优化器以自适应选择小批量大小，旨在改善模型公平性。",
            "公平性度量": "包括平等机会、平等化赔率和人口统计平等，用于评估和指导模型公平性的改善。",
            "批次选择算法": "FairBatch算法，通过自适应选择小批量大小来改善模型公平性，无需修改数据预处理或模型训练过程。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 263,
        "title": "FairFil: Contrastive Neural Debiasing Method for Pretrained Text Encoders",
        "html": "https://iclr.cc//virtual/2021/poster/2555",
        "abstract": "Pretrained text encoders, such as BERT, have been applied increasingly in various natural language processing (NLP) tasks, and have recently demonstrated significant performance gains. However, recent studies have demonstrated the existence of social bias in these pretrained NLP models. Although prior works have made progress on word-level debiasing, improved sentence-level fairness of pretrained encoders still lacks exploration. In this paper, we proposed the first neural debiasing method for a pretrained sentence encoder, which transforms the pretrained encoder outputs into debiased representations via a fair filter (FairFil) network. To learn the FairFil, we introduce a contrastive learning framework that not only minimizes the correlation between filtered embeddings and bias words but also preserves rich semantic information of the original sentences. On real-world datasets, our FairFil effectively reduces the bias degree of pretrained text encoders, while continuously showing desirable performance on downstream tasks. Moreover, our post hoc method does not require any retraining of the text encoders, further enlarging FairFil's application space.",
        "conference": "ICLR",
        "中文标题": "FairFil：预训练文本编码器的对比神经去偏方法",
        "摘要翻译": "预训练的文本编码器，如BERT，已越来越多地应用于各种自然语言处理（NLP）任务，并最近显示出显著的性能提升。然而，最近的研究表明这些预训练的NLP模型中存在社会偏见。尽管先前的工作在词级去偏方面取得了进展，但预训练编码器在句子级公平性的提升仍缺乏探索。在本文中，我们提出了第一个针对预训练句子编码器的神经去偏方法，该方法通过公平过滤器（FairFil）网络将预训练编码器的输出转换为去偏表示。为了学习FairFil，我们引入了一个对比学习框架，该框架不仅最小化过滤后的嵌入与偏见词之间的相关性，还保留了原始句子的丰富语义信息。在真实世界的数据集上，我们的FairFil有效地降低了预训练文本编码器的偏见程度，同时在下游任务上持续显示出理想的性能。此外，我们的后处理方法不需要对文本编码器进行任何重新训练，进一步扩大了FairFil的应用空间。",
        "领域": "自然语言处理与视觉结合、文本表示学习、公平机器学习",
        "问题": "解决预训练文本编码器中存在的社会偏见问题，特别是在句子级别的公平性提升。",
        "动机": "预训练文本编码器如BERT在NLP任务中表现出色，但存在社会偏见，影响公平性。现有方法多在词级别去偏，句子级别去偏研究不足。",
        "方法": "提出FairFil方法，通过公平过滤器网络和对比学习框架，将预训练编码器的输出转换为去偏表示，同时保留语义信息。",
        "关键词": [
            "神经去偏",
            "对比学习",
            "公平过滤器",
            "预训练编码器",
            "句子级公平性"
        ],
        "涉及的技术概念": {
            "公平过滤器（FairFil）": "用于将预训练编码器的输出转换为去偏表示的神经网络。",
            "对比学习框架": "用于训练FairFil的框架，旨在减少偏见同时保留语义信息。",
            "后处理方法": "不需要重新训练预训练编码器的方法，扩大了应用范围。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 264,
        "title": "Fair Mixup: Fairness via Interpolation",
        "html": "https://iclr.cc//virtual/2021/poster/2612",
        "abstract": "Training classifiers under fairness constraints such as group fairness, regularizes the disparities of predictions between the groups. Nevertheless, even though the constraints are satisfied during training, they might not generalize at evaluation time. To improve the generalizability of fair classifiers, we propose fair mixup, a new data augmentation strategy for imposing the fairness constraint. In particular, we show that fairness can be achieved by regularizing the models on paths of interpolated samples  between the groups. We use mixup, a powerful data augmentation strategy  to generate these interpolates. We analyze fair mixup and empirically show that it ensures a better generalization for both accuracy and fairness measurement in tabular, vision, and language benchmarks.",
        "conference": "ICLR",
        "中文标题": "公平混合：通过插值实现公平性",
        "摘要翻译": "在诸如群体公平性等公平性约束下训练分类器，可以规范化不同群体间预测的差异。然而，尽管在训练过程中满足了这些约束，它们在评估时可能无法泛化。为了提高公平分类器的泛化能力，我们提出了公平混合，一种新的数据增强策略，用于施加公平性约束。特别是，我们展示了通过在群体间的插值样本路径上规范化模型，可以实现公平性。我们使用混合，一种强大的数据增强策略来生成这些插值。我们分析了公平混合，并通过实验证明，在表格、视觉和语言基准测试中，它确保了更好的准确性和公平性测量的泛化。",
        "领域": "公平机器学习, 数据增强, 分类器泛化",
        "问题": "提高公平分类器在评估时的泛化能力",
        "动机": "解决公平性约束在训练时满足但在评估时可能无法泛化的问题",
        "方法": "提出公平混合策略，通过在群体间的插值样本路径上规范化模型来实现公平性",
        "关键词": [
            "公平机器学习",
            "数据增强",
            "分类器泛化",
            "公平混合",
            "插值样本"
        ],
        "涉及的技术概念": {
            "公平混合": "一种新的数据增强策略，用于施加公平性约束，通过在群体间的插值样本路径上规范化模型",
            "数据增强": "用于生成插值样本，以提高模型的泛化能力",
            "群体公平性": "训练分类器时考虑的公平性约束，旨在减少不同群体间预测的差异"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 265,
        "title": "Fantastic Four: Differentiable and Efficient Bounds on Singular Values of Convolution Layers",
        "html": "https://iclr.cc//virtual/2021/poster/2548",
        "abstract": "In deep neural networks, the spectral norm of the Jacobian of a layer bounds the factor by which the norm of a signal changes during forward/backward propagation. Spectral norm regularizations have been shown to improve generalization, robustness and optimization of deep learning methods. Existing methods to compute the spectral norm of convolution layers either rely on heuristics that are efficient in computation but lack guarantees or are theoretically-sound but computationally expensive. In this work, we obtain the best of both worlds by deriving {\\it four} provable upper bounds on the spectral norm of a standard 2D multi-channel convolution layer. These bounds are differentiable and can be computed efficiently during training with negligible overhead. One of these bounds is in fact the popular heuristic method of Miyato et al. (multiplied by a constant factor depending on filter sizes). Each of these four bounds can achieve the tightest gap depending on convolution filters. Thus, we propose to use the minimum of these four bounds as a tight, differentiable and efficient upper bound on the spectral norm of convolution layers. Moreover, our spectral bound is an effective regularizer and can be used to bound either the lipschitz constant or curvature values (eigenvalues of the Hessian) of neural networks. Through experiments on MNIST and CIFAR-10, we demonstrate the effectiveness of our spectral bound in improving generalization and robustness of deep networks.",
        "conference": "ICLR",
        "中文标题": "神奇四侠：卷积层奇异值的可微分与高效边界",
        "摘要翻译": "在深度神经网络中，层的雅可比矩阵的谱范数限制了信号在前向/反向传播过程中范数变化的因子。谱范数正则化已被证明能够改善深度学习方法的泛化能力、鲁棒性和优化。现有的计算卷积层谱范数的方法要么依赖于计算高效但缺乏保证的启发式方法，要么是理论可靠但计算成本高昂。在这项工作中，我们通过推导标准2D多通道卷积层谱范数的四个可证明上界，实现了两者的最佳结合。这些边界是可微分的，并且可以在训练过程中以可忽略的开销高效计算。其中一个边界实际上是Miyato等人的流行启发式方法（乘以一个取决于滤波器大小的常数因子）。这四个边界中的每一个都可以根据卷积滤波器实现最紧密的间隙。因此，我们建议使用这四个边界的最小值作为卷积层谱范数的紧密、可微分和高效上界。此外，我们的谱边界是一种有效的正则化器，可用于限制神经网络的Lipschitz常数或曲率值（Hessian矩阵的特征值）。通过在MNIST和CIFAR-10上的实验，我们证明了我们的谱边界在提高深度网络的泛化能力和鲁棒性方面的有效性。",
        "领域": "深度学习优化、卷积神经网络、谱范数正则化",
        "问题": "如何高效且可微分地计算卷积层的谱范数，以改善深度学习模型的泛化能力和鲁棒性。",
        "动机": "现有的计算卷积层谱范数的方法要么计算高效但缺乏理论保证，要么理论可靠但计算成本高，研究旨在找到一种既高效又有理论保证的方法。",
        "方法": "推导了四个可证明的卷积层谱范数上界，这些上界是可微分的，计算高效，并提出了使用这四个边界的最小值作为谱范数的紧密上界。",
        "关键词": [
            "谱范数",
            "卷积层",
            "可微分边界",
            "深度学习正则化",
            "Lipschitz常数"
        ],
        "涉及的技术概念": {
            "谱范数": "用于衡量矩阵变换对向量长度影响的最大因子，本文中用于正则化神经网络以提高泛化能力和鲁棒性。",
            "雅可比矩阵": "描述神经网络层输入输出之间变化率的矩阵，其谱范数用于控制信号传播的变化。",
            "Lipschitz常数": "衡量函数输出变化对输入变化的敏感度，本文中通过谱范数限制神经网络的Lipschitz常数以提高模型稳定性。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 266,
        "title": "Fast and Complete: Enabling Complete Neural Network Verification with Rapid and Massively Parallel Incomplete Verifiers",
        "html": "https://iclr.cc//virtual/2021/poster/3365",
        "abstract": "Formal verification of neural networks (NNs) is a challenging and important problem. Existing efficient complete solvers typically require the branch-and-bound (BaB) process, which splits the problem domain into sub-domains and solves each sub-domain using faster but weaker incomplete verifiers, such as Linear Programming (LP) on linearly relaxed sub-domains.  In this paper, we propose to use the backward mode linear relaxation based perturbation analysis (LiRPA) to replace LP during the BaB process, which can be efficiently implemented on the typical machine learning accelerators such as GPUs and TPUs.  However, unlike LP, LiRPA when applied naively can produce much weaker bounds and even cannot check certain conflicts of sub-domains during splitting, making the entire procedure incomplete after BaB. To address these challenges, we apply a fast gradient based bound tightening procedure combined with batch splits and the design of minimal usage of LP bound procedure, enabling us to effectively use LiRPA on the accelerator hardware for the challenging complete NN verification problem and significantly outperform LP-based approaches. On a single GPU, we demonstrate an order of magnitude speedup compared to existing LP-based approaches.",
        "conference": "ICLR",
        "中文标题": "快速且完整：通过快速且大规模并行不完整验证器实现完整神经网络验证",
        "摘要翻译": "神经网络的正式验证是一个具有挑战性且重要的问题。现有的高效完整求解器通常需要分支定界（BaB）过程，该过程将问题域分割成子域，并使用更快但较弱的不完整验证器（如线性规划（LP）在线性松弛的子域上）来解决每个子域。在本文中，我们提出在BaB过程中使用基于反向模式线性松弛的扰动分析（LiRPA）来替代LP，这可以在典型的机器学习加速器（如GPU和TPU）上高效实现。然而，与LP不同，LiRPA在简单应用时可能产生更弱的边界，甚至无法检查分割过程中子域的某些冲突，使得整个BaB过程不完整。为了解决这些挑战，我们应用了一个基于快速梯度的边界收紧过程，结合批量分割和最小化使用LP边界过程的设计，使我们能够有效地在加速器硬件上使用LiRPA来解决具有挑战性的完整神经网络验证问题，并显著优于基于LP的方法。在单个GPU上，我们展示了与现有基于LP的方法相比一个数量级的加速。",
        "领域": "神经网络验证、机器学习加速、形式化方法",
        "问题": "如何高效且完整地验证神经网络的正确性和安全性",
        "动机": "现有的神经网络验证方法在效率和完整性之间存在权衡，特别是在使用分支定界过程时，需要更高效且完整的方法来验证神经网络",
        "方法": "提出使用基于反向模式线性松弛的扰动分析（LiRPA）替代传统的线性规划（LP）方法，结合快速梯度边界收紧和批量分割技术，优化在GPU和TPU上的实现",
        "关键词": [
            "神经网络验证",
            "LiRPA",
            "GPU加速",
            "分支定界",
            "形式化方法"
        ],
        "涉及的技术概念": {
            "分支定界（BaB）": "一种将问题域分割成子域并分别求解的方法，用于神经网络的完整验证",
            "线性松弛的扰动分析（LiRPA）": "一种替代线性规划的方法，能够在机器学习加速器上高效实现，用于神经网络验证",
            "快速梯度边界收紧": "一种技术，用于优化LiRPA在神经网络验证中的应用，提高验证的效率和完整性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 267,
        "title": "Fast And Slow Learning Of Recurrent Independent Mechanisms",
        "html": "https://iclr.cc//virtual/2021/poster/2822",
        "abstract": "Decomposing knowledge into interchangeable pieces promises a generalization advantage when there are changes in distribution. A learning agent interacting with its environment is likely to be faced with situations requiring novel combinations of existing pieces of knowledge. We hypothesize that such a decomposition of knowledge is particularly relevant for being able to generalize in a systematic way to out-of-distribution changes. To study these ideas, we propose a particular training framework in which we assume that the pieces of knowledge an agent needs and its reward function are stationary and can be re-used across tasks. An attention mechanism dynamically selects which modules can be adapted to the current task, and the parameters of the \\textit{selected} modules are allowed to change quickly as the learner is confronted with variations in what it experiences, while the parameters of the attention mechanisms act as stable, slowly changing, meta-parameters. We focus on pieces of knowledge captured by an ensemble of  modules sparsely communicating with each other via a bottleneck of attention. We find that meta-learning the  modular aspects of the proposed system greatly helps in achieving faster adaptation in a reinforcement learning setup involving navigation in a partially observed grid world with image-level input.  We also find that reversing the role of parameters and meta-parameters does not work nearly as well, suggesting a particular role for fast adaptation of the dynamically selected modules.",
        "conference": "ICLR",
        "中文标题": "快速与慢速学习的循环独立机制",
        "摘要翻译": "将知识分解为可互换的部分，有望在分布变化时带来泛化优势。一个与其环境互动的学习代理很可能会遇到需要现有知识部分新组合的情况。我们假设，这种知识的分解对于能够系统地泛化到分布外变化特别相关。为了研究这些想法，我们提出了一个特定的训练框架，其中我们假设代理需要的知识部分及其奖励函数是固定的，并且可以在任务间重复使用。一个注意力机制动态选择哪些模块可以适应当前任务，而所选模块的参数允许在学习者面对经验变化时快速变化，而注意力机制的参数则作为稳定的、缓慢变化的元参数。我们专注于由一组模块捕获的知识部分，这些模块通过注意力的瓶颈稀疏地相互通信。我们发现，元学习所提出系统的模块化方面极大地有助于在涉及部分观察网格世界中图像级输入的导航的强化学习设置中实现更快的适应。我们还发现，颠倒参数和元参数的角色效果远不如前者，这表明动态选择模块的快速适应具有特定的作用。",
        "领域": "强化学习、元学习、注意力机制",
        "问题": "如何在分布变化的情况下实现知识的快速适应和泛化",
        "动机": "研究知识分解和模块化学习在系统泛化到分布外变化中的作用",
        "方法": "提出一个训练框架，通过注意力机制动态选择可适应模块，并允许这些模块的参数快速变化，同时保持注意力机制的参数稳定",
        "关键词": [
            "知识分解",
            "模块化学习",
            "注意力机制",
            "强化学习",
            "元学习"
        ],
        "涉及的技术概念": {
            "注意力机制": "动态选择哪些模块可以适应当前任务，实现知识的快速适应",
            "元学习": "通过学习模块化系统的元参数，实现更快的适应能力",
            "强化学习": "在部分观察的网格世界中进行导航任务，验证方法的有效性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 268,
        "title": "Fast convergence of stochastic subgradient method under interpolation",
        "html": "https://iclr.cc//virtual/2021/poster/3185",
        "abstract": "This paper studies the behaviour of the stochastic subgradient descent (SSGD) method applied to over-parameterized nonsmooth optimization problems that satisfy an interpolation condition. By leveraging the composite structure of the empirical risk minimization problems, we prove that SSGD converges, respectively, with rates $O(1/\\epsilon)$ and $O(\\log(1/\\epsilon))$ for convex and strongly-convex objectives when interpolation holds. These rates coincide with established rates for the stochastic gradient descent (SGD) method applied to smooth problems that also satisfy an interpolation condition. Our analysis provides a partial explanation for the empirical observation that sometimes SGD and SSGD behave similarly for training smooth and nonsmooth machine learning models. We also prove that the rate $O(1/\\epsilon)$ is optimal for the subgradient method in the convex and interpolation setting.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "插值条件下随机次梯度法的快速收敛",
        "摘要翻译": "本文研究了随机次梯度下降（SSGD）方法应用于满足插值条件的过度参数化非光滑优化问题的行为。通过利用经验风险最小化问题的复合结构，我们证明了当插值成立时，SSGD对于凸目标和强凸目标分别以O(1/epsilon)和O(log(1/epsilon))的速度收敛。这些速率与应用于同样满足插值条件的平滑问题的随机梯度下降（SGD）方法的既定速率一致。我们的分析部分解释了经验观察，即有时SGD和SSGD在训练平滑和非平滑机器学习模型时表现相似。我们还证明了速率O(1/epsilon)对于凸和插值设置中的次梯度方法是最佳的。",
        "领域": "优化算法、随机优化、机器学习理论",
        "问题": "研究随机次梯度下降法（SSGD）在满足插值条件的非光滑优化问题中的收敛速度。",
        "动机": "解释为什么在训练机器学习模型时，随机梯度下降（SGD）和随机次梯度下降（SSGD）的行为有时相似，并探究次梯度法在插值条件下的最优收敛速度。",
        "方法": "通过利用经验风险最小化问题的复合结构，对SSGD的收敛速度进行理论分析，并将其与SGD在平滑问题上的收敛速度进行比较。",
        "关键词": [
            "随机次梯度下降",
            "插值条件",
            "非光滑优化",
            "收敛速度",
            "经验风险最小化"
        ],
        "涉及的技术概念": {
            "随机次梯度下降（SSGD）": "一种用于优化非光滑目标函数的迭代算法，每次迭代使用随机选择的次梯度。",
            "插值条件": "一种描述数据之间关系的假设，即存在一个模型能够完全拟合训练数据，使得训练误差为零。"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 269,
        "title": "Faster Binary Embeddings for Preserving Euclidean Distances",
        "html": "https://iclr.cc//virtual/2021/poster/3243",
        "abstract": "We propose a fast, distance-preserving, binary embedding algorithm to transform a high-dimensional dataset $\\mathcal{T}\\subseteq\\mathbb{R}^n$ into binary sequences in the cube $\\{\\pm 1\\}^m$. When $\\mathcal{T}$ consists of well-spread (i.e., non-sparse) vectors, our embedding method applies a stable noise-shaping quantization scheme to $A x$ where $A\\in\\mathbb{R}^{m\\times n}$ is a sparse Gaussian random matrix. This contrasts with most binary embedding methods, which usually use $x\\mapsto \\mathrm{sign}(Ax)$ for the embedding. Moreover, we show that Euclidean distances among the elements of $\\mathcal{T}$ are approximated by the $\\ell_1$ norm on the images of $\\{\\pm 1\\}^m$ under a fast linear transformation. This again contrasts with standard methods, where the Hamming distance is used instead.  Our method is both fast and memory efficient, with time complexity  $O(m)$ and space complexity $O(m)$ on well-spread data. When the data is not well-spread, we show that the approach still works provided that data is transformed via a Walsh-Hadamard matrix, but now the cost is $O(n\\log n)$ per data point.  Further, we prove that the method is accurate and its associated error is comparable to that of a continuous valued Johnson-Lindenstrauss embedding plus a quantization error that admits a polynomial decay as the embedding dimension $m$ increases.\n\tThus the length of the binary codes required to achieve a desired accuracy is quite small, and we show it can even be compressed further without compromising the accuracy. To illustrate our results, we test the proposed method on natural images and show that it achieves strong performance.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "保持欧几里得距离的快速二值嵌入",
        "摘要翻译": "我们提出了一种快速、保持距离的二值嵌入算法，用于将高维数据集 $\\mathcal{T}\\subseteq\\mathbb{R}^n$ 转换为立方体 $\\{\\pm 1\\}^m$ 中的二值序列。当 $\\mathcal{T}$ 由分布良好的（即，非稀疏的）向量组成时，我们的嵌入方法将稳定的噪声整形量化方案应用于 $A x$，其中 $A\\in\\mathbb{R}^{m\\times n}$ 是一个稀疏高斯随机矩阵。这与大多数二值嵌入方法形成对比，后者通常使用 $x\\mapsto \\mathrm{sign}(Ax)$ 进行嵌入。此外，我们表明 $\\mathcal{T}$ 元素之间的欧几里得距离可以通过快速线性变换下 $\\{\\pm 1\\}^m$ 图像上的 $\\ell_1$ 范数来近似。这再次与标准方法形成对比，在标准方法中，使用汉明距离代替。我们的方法既快速又节省内存，对于分布良好的数据，时间复杂度为 $O(m)$，空间复杂度为 $O(m)$。当数据分布不佳时，我们证明该方法仍然有效，前提是通过 Walsh-Hadamard 矩阵转换数据，但现在的成本是每个数据点 $O(n\\log n)$。此外，我们证明了该方法的准确性，并且其相关误差与连续值的 Johnson-Lindenstrauss 嵌入加上量化误差相当，随着嵌入维度 $m$ 的增加，量化误差呈多项式衰减。因此，实现所需精度所需的二值码的长度非常小，我们表明可以在不影响精度的情况下进一步压缩它。为了说明我们的结果，我们在自然图像上测试了所提出的方法，并表明它取得了良好的性能。",
        "领域": "图像检索, 度量学习, 图像压缩",
        "问题": "如何高效地将高维数据嵌入到低维二值空间，同时保持原始数据的欧几里得距离，从而实现快速相似性搜索和降低存储成本。",
        "动机": "现有二值嵌入方法通常使用符号函数进行嵌入，并依赖汉明距离来近似原始距离，效率和精度有待提高。研究旨在找到一种更快、更节省内存且能更好保持距离信息的二值嵌入方法。",
        "方法": "提出一种基于稀疏高斯随机矩阵和噪声整形量化的二值嵌入算法。该方法首先使用稀疏高斯随机矩阵对高维数据进行降维，然后应用噪声整形量化方案生成二值码。最后，使用快速线性变换和 l1 范数来近似原始欧几里得距离。",
        "关键词": [
            "二值嵌入",
            "欧几里得距离保持",
            "噪声整形量化",
            "稀疏高斯随机矩阵",
            "l1范数"
        ],
        "涉及的技术概念": {
            "二值嵌入": "将高维数据映射到低维二值空间的技术，用于降低存储成本和提高检索效率。",
            "噪声整形量化": "一种量化技术，通过控制量化误差的频谱分布，从而降低量化误差对信号的影响。"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 270,
        "title": "Fast Geometric Projections for Local Robustness Certification",
        "html": "https://iclr.cc//virtual/2021/poster/3325",
        "abstract": "Local robustness ensures that a model classifies all inputs within an $\\ell_p$-ball consistently, which precludes various forms of adversarial inputs.\nIn this paper, we present a fast procedure for checking local robustness in feed-forward neural networks with piecewise-linear activation functions.\nSuch networks partition the input space into a set of convex polyhedral regions in which the network’s behavior is linear; \nhence, a systematic search for decision boundaries within the regions around a given input is sufficient for assessing robustness.\nCrucially, we show how the regions around a point can be analyzed using simple geometric projections, thus admitting an efficient, highly-parallel GPU implementation that excels particularly for the $\\ell_2$ norm, where previous work has been less effective.\nEmpirically we find this approach to be far more precise than many approximate verification approaches, while at the same time performing multiple orders of magnitude faster than complete verifiers, and scaling to much deeper networks.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "局部鲁棒性认证的快速几何投影",
        "摘要翻译": "局部鲁棒性确保模型对一个ℓp球内的所有输入进行一致的分类，从而排除各种形式的对抗性输入。\\n在本文中，我们提出了一种快速程序，用于检查具有分段线性激活函数的前馈神经网络中的局部鲁棒性。这种网络将输入空间划分为一组凸多面体区域，在这些区域中，网络的行为是线性的；因此，在给定输入周围的区域内系统地搜索决策边界足以评估鲁棒性。\\n至关重要的是，我们展示了如何使用简单的几何投影来分析一个点周围的区域，从而实现高效、高度并行的GPU实现，尤其是在ℓ2范数方面表现出色，而之前的工作在这方面效果较差。经验表明，我们发现这种方法比许多近似验证方法更精确，同时比完整的验证器快几个数量级，并且可以扩展到更深层的网络。",
        "领域": "对抗样本防御, 神经网络验证, 鲁棒性分析",
        "问题": "如何高效地验证深度神经网络的局部鲁棒性，特别是对于ℓ2范数下的对抗性攻击。",
        "动机": "现有的神经网络鲁棒性验证方法要么不够精确，要么计算成本过高，难以应用于大规模深度网络，尤其是在ℓ2范数下验证效果不佳。",
        "方法": "提出了一种基于快速几何投影的局部鲁棒性验证方法，该方法通过分析神经网络输入空间中的凸多面体区域，并利用GPU并行计算来高效地搜索决策边界。",
        "关键词": [
            "局部鲁棒性",
            "几何投影",
            "神经网络验证",
            "对抗攻击",
            "分段线性激活函数"
        ],
        "涉及的技术概念": {
            "局部鲁棒性": "模型在输入扰动范围内保持预测一致性的能力，是抵抗对抗攻击的关键指标。",
            "几何投影": "将高维数据投影到低维空间，用于简化凸多面体区域的分析，从而加速决策边界的搜索。"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 271,
        "title": "FastSpeech 2: Fast and High-Quality End-to-End Text to Speech",
        "html": "https://iclr.cc//virtual/2021/poster/2919",
        "abstract": "Non-autoregressive text to speech (TTS) models such as FastSpeech can synthesize speech significantly faster than previous autoregressive models with comparable quality. The training of FastSpeech model relies on an autoregressive teacher model for duration prediction (to provide more information as input) and knowledge distillation (to simplify the data distribution in output), which can ease the one-to-many mapping problem (i.e., multiple speech variations correspond to the same text) in TTS. However, FastSpeech has several disadvantages: 1) the teacher-student distillation pipeline is complicated and time-consuming, 2) the duration extracted from the teacher model is not accurate enough, and the target mel-spectrograms distilled from teacher model suffer from information loss due to data simplification, both of which limit the voice quality. In this paper, we propose FastSpeech 2, which addresses the issues in FastSpeech and better solves the one-to-many mapping problem in TTS by 1) directly training the model with ground-truth target instead of the simplified output from teacher, and 2) introducing more variation information of speech (e.g., pitch, energy and more accurate duration) as conditional inputs. Specifically, we extract duration, pitch and energy from speech waveform and directly take them as conditional inputs in training and use predicted values in inference. We further design FastSpeech 2s, which is the first attempt to directly generate speech waveform from text in parallel, enjoying the benefit of fully end-to-end inference. Experimental results show that 1) FastSpeech 2 achieves a 3x training speed-up over FastSpeech, and FastSpeech 2s enjoys even faster inference speed; 2) FastSpeech 2 and 2s outperform FastSpeech in voice quality, and FastSpeech 2 can even surpass autoregressive models. Audio samples are available at https://speechresearch.github.io/fastspeech2/.",
        "conference": "ICLR",
        "中文标题": "FastSpeech 2：快速且高质量的端到端文本到语音转换",
        "摘要翻译": "非自回归文本到语音（TTS）模型，如FastSpeech，可以比之前的自回归模型更快地合成语音，且质量相当。FastSpeech模型的训练依赖于自回归教师模型进行持续时间预测（以提供更多输入信息）和知识蒸馏（以简化输出中的数据分布），这可以缓解TTS中的一对多映射问题（即，同一文本对应多种语音变化）。然而，FastSpeech有几个缺点：1）师生蒸馏流程复杂且耗时，2）从教师模型中提取的持续时间不够准确，且从教师模型蒸馏的目标梅尔频谱由于数据简化而遭受信息损失，这两者都限制了语音质量。在本文中，我们提出了FastSpeech 2，它解决了FastSpeech中的问题，并通过1）直接使用真实目标而非教师模型的简化输出来训练模型，和2）引入更多语音的变化信息（如音高、能量和更准确的持续时间）作为条件输入，更好地解决了TTS中的一对多映射问题。具体来说，我们从语音波形中提取持续时间、音高和能量，并直接将其作为训练中的条件输入，在推理中使用预测值。我们进一步设计了FastSpeech 2s，这是首次尝试直接从文本并行生成语音波形，享受完全端到端推理的好处。实验结果表明：1）FastSpeech 2比FastSpeech实现了3倍的训练加速，FastSpeech 2s的推理速度更快；2）FastSpeech 2和2s在语音质量上优于FastSpeech，FastSpeech 2甚至可以超越自回归模型。音频样本可在https://speechresearch.github.io/fastspeech2/获取。",
        "领域": "语音合成、端到端学习、非自回归模型",
        "问题": "解决FastSpeech模型在训练流程复杂、持续时间预测不准确以及信息损失方面的问题，提高语音合成的速度和质量。",
        "动机": "简化语音合成的训练流程，提高合成语音的质量和速度，解决一对多映射问题。",
        "方法": "直接使用真实目标训练模型，引入更多语音变化信息作为条件输入，设计FastSpeech 2s实现完全端到端的语音波形生成。",
        "关键词": [
            "非自回归模型",
            "语音合成",
            "端到端学习",
            "知识蒸馏",
            "条件输入"
        ],
        "涉及的技术概念": {
            "非自回归模型": "用于加速语音合成过程，避免自回归模型中的顺序生成延迟。",
            "知识蒸馏": "用于简化数据分布，缓解一对多映射问题，但可能导致信息损失。",
            "条件输入": "引入音高、能量和持续时间等语音变化信息，以提高合成语音的质量和自然度。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 272,
        "title": "FedBE: Making Bayesian Model Ensemble Applicable to Federated Learning",
        "html": "https://iclr.cc//virtual/2021/poster/2944",
        "abstract": "Federated learning aims to collaboratively train a strong global model by accessing users' locally trained models but not their own data. A crucial step is therefore to aggregate local models into a global model, which has been shown challenging when users have non-i.i.d. data. In this paper, we propose a novel aggregation algorithm named FedBE, which takes a Bayesian inference perspective by sampling higher-quality global models and combining them via Bayesian model Ensemble, leading to much robust aggregation. We show that an effective model distribution can be constructed by simply fitting a Gaussian or Dirichlet distribution to the local models. Our empirical studies validate FedBE's superior performance, especially when users' data are not i.i.d. and when the neural networks go deeper. Moreover, FedBE is compatible with recent efforts in regularizing users' model training, making it an easily applicable module: you only need to replace the aggregation method but leave other parts of your federated learning algorithm intact.",
        "conference": "ICLR",
        "中文标题": "FedBE：使贝叶斯模型集成适用于联邦学习",
        "摘要翻译": "联邦学习旨在通过访问用户本地训练的模型而非其数据，协作训练一个强大的全局模型。因此，一个关键步骤是将局部模型聚合成全局模型，这在用户数据非独立同分布（non-i.i.d.）时已被证明具有挑战性。本文提出了一种名为FedBE的新型聚合算法，该算法从贝叶斯推理的角度出发，通过采样更高质量的全局模型并通过贝叶斯模型集成将它们结合起来，从而实现更稳健的聚合。我们表明，通过简单地将高斯分布或狄利克雷分布拟合到局部模型，可以构建一个有效的模型分布。我们的实证研究验证了FedBE的卓越性能，尤其是在用户数据非独立同分布和神经网络更深时。此外，FedBE与最近在规范化用户模型训练方面的努力兼容，使其成为一个易于应用的模块：您只需替换聚合方法，而保持联邦学习算法的其他部分不变。",
        "领域": "联邦学习、贝叶斯模型集成、深度学习优化",
        "问题": "解决在用户数据非独立同分布（non-i.i.d.）情况下，联邦学习中局部模型聚合成全局模型的挑战。",
        "动机": "为了提高在非独立同分布数据条件下联邦学习的模型聚合效果，提出一种更稳健的聚合方法。",
        "方法": "提出FedBE算法，采用贝叶斯推理视角，通过采样高质量全局模型并使用贝叶斯模型集成进行聚合。",
        "关键词": [
            "联邦学习",
            "贝叶斯模型集成",
            "非独立同分布数据",
            "模型聚合",
            "深度学习优化"
        ],
        "涉及的技术概念": {
            "贝叶斯模型集成": "在FedBE中用于结合采样到的全局模型，提高聚合的稳健性。",
            "非独立同分布数据": "指用户数据不满足独立同分布条件，FedBE特别针对这种情况优化了模型聚合。",
            "高斯分布或狄利克雷分布": "用于拟合局部模型，构建有效的模型分布，是FedBE算法的关键步骤。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 273,
        "title": "FedBN: Federated Learning on Non-IID Features via Local Batch Normalization",
        "html": "https://iclr.cc//virtual/2021/poster/2846",
        "abstract": "The emerging paradigm of federated learning (FL) strives to enable collaborative training of deep models on the network edge without centrally aggregating raw data and hence improving data privacy. In most cases, the assumption of independent and identically distributed samples across local clients does not hold for federated learning setups. Under this setting, neural network training performance may vary significantly according to the data distribution and even hurt training convergence. Most of the previous work has focused on a difference in the distribution of labels or client shifts. Unlike those settings, we address an important problem of FL, e.g., different scanners/sensors in medical imaging, different scenery distribution in autonomous driving (highway vs. city), where local clients store examples with different distributions compared to other clients, which we denote as feature shift non-iid. In this work, we propose an effective method that uses local batch normalization to alleviate the feature shift before averaging models. The resulting scheme, called FedBN, outperforms both classical FedAvg, as well as the state-of-the-art for non-iid data (FedProx) on our extensive experiments. These empirical results are supported by a convergence analysis that shows in a simplified setting that FedBN has a faster convergence rate than FedAvg. Code is available at https://github.com/med-air/FedBN.",
        "conference": "ICLR",
        "中文标题": "FedBN：通过本地批量归一化在非独立同分布特征上的联邦学习",
        "摘要翻译": "联邦学习（FL）这一新兴范式致力于在网络边缘实现深度模型的协作训练，而无需集中聚合原始数据，从而提升数据隐私性。在大多数情况下，联邦学习设置中本地客户端间样本独立同分布的假设并不成立。在此设置下，神经网络训练性能可能因数据分布差异而有显著变化，甚至影响训练收敛。以往的研究大多关注标签分布或客户端偏移的差异。与这些设置不同，我们解决了联邦学习中的一个重要问题，例如医学成像中不同的扫描仪/传感器、自动驾驶中不同的场景分布（高速公路与城市），其中本地客户端存储的样本与其他客户端相比具有不同的分布，我们称之为特征偏移非独立同分布。在这项工作中，我们提出了一种有效的方法，使用本地批量归一化在模型平均之前缓解特征偏移。这一方案被称为FedBN，在我们的大量实验中，其表现优于经典的FedAvg以及针对非独立同分布数据的最新方法（FedProx）。这些实证结果得到了收敛分析的支持，该分析在一个简化设置中显示FedBN比FedAvg具有更快的收敛速度。代码可在https://github.com/med-air/FedBN获取。",
        "领域": "联邦学习、医学影像分析、自动驾驶",
        "问题": "解决联邦学习中因特征分布不同（特征偏移非独立同分布）导致的模型训练性能下降和收敛问题",
        "动机": "在联邦学习中，不同客户端的数据分布差异（如医学影像中的不同扫描仪或自动驾驶中的不同场景）会影响模型训练的效果和收敛速度，需要一种方法来缓解这种特征偏移",
        "方法": "提出FedBN方法，通过在模型平均之前使用本地批量归一化来缓解特征偏移，提高模型训练的性能和收敛速度",
        "关键词": [
            "联邦学习",
            "非独立同分布",
            "批量归一化",
            "特征偏移",
            "模型收敛"
        ],
        "涉及的技术概念": {
            "联邦学习": "一种分布式机器学习方法，允许多个客户端协作训练模型而不共享原始数据，保护数据隐私",
            "非独立同分布": "指数据样本在不同客户端间不满足独立同分布假设，这在联邦学习中常见且影响模型性能",
            "本地批量归一化": "在联邦学习中，每个客户端独立进行批量归一化处理，以缓解特征分布差异对模型训练的影响"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 274,
        "title": "Federated Learning Based on Dynamic Regularization",
        "html": "https://iclr.cc//virtual/2021/poster/2748",
        "abstract": "We propose a novel federated learning method for distributively training neural network models, where the server orchestrates cooperation between a subset of randomly chosen devices in each round. We view Federated Learning problem primarily from a communication perspective and allow more device level computations to save transmission costs. We point out a fundamental dilemma, in that the minima of the local-device level empirical loss are inconsistent with those of the global empirical loss. Different from recent prior works, that either attempt inexact minimization or utilize devices for parallelizing gradient computation, we propose a dynamic regularizer for each device at each round, so that in the limit the global and device solutions are aligned. We demonstrate both through empirical results on real and synthetic data as well as analytical results that our scheme leads to efficient training, in both convex and non-convex settings, while being fully agnostic to device heterogeneity and robust to large number of devices, partial participation and unbalanced data.",
        "conference": "ICLR",
        "中文标题": "基于动态正则化的联邦学习",
        "摘要翻译": "我们提出了一种新颖的联邦学习方法，用于分布式训练神经网络模型，其中服务器在每一轮中协调随机选择的设备子集之间的合作。我们主要从通信的角度来看待联邦学习问题，并允许更多的设备级计算以节省传输成本。我们指出了一个基本的困境，即局部设备级经验损失的最小值与全局经验损失的最小值不一致。与最近的研究不同，这些研究要么尝试不精确的最小化，要么利用设备并行化梯度计算，我们为每一轮的每个设备提出了一个动态正则化器，以便在极限情况下，全局和设备解决方案是一致的。我们通过真实和合成数据的实证结果以及分析结果表明，我们的方案在凸和非凸设置下都能实现高效的训练，同时对设备异质性完全不可知，并且对大量设备、部分参与和不平衡数据具有鲁棒性。",
        "领域": "联邦学习、分布式机器学习、深度学习优化",
        "问题": "解决联邦学习中局部设备级经验损失与全局经验损失最小值不一致的问题",
        "动机": "通过减少通信成本和提高训练效率，解决联邦学习中的设备异质性和数据不平衡问题",
        "方法": "提出了一种动态正则化器，用于在每一轮训练中调整每个设备的损失函数，以对齐全局和设备级解决方案",
        "关键词": [
            "联邦学习",
            "动态正则化",
            "分布式训练",
            "设备异质性",
            "数据不平衡"
        ],
        "涉及的技术概念": {
            "联邦学习": "一种分布式机器学习方法，允许多个设备或服务器协同训练模型，而无需共享原始数据",
            "动态正则化": "在每一轮训练中为每个设备调整的正则化器，旨在解决局部和全局损失函数最小值不一致的问题",
            "设备异质性": "指在联邦学习中，参与设备在计算能力、存储空间和数据分布上的差异，影响训练效率和模型性能"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 275,
        "title": "Federated Learning via Posterior Averaging: A New Perspective and Practical Algorithms",
        "html": "https://iclr.cc//virtual/2021/poster/2670",
        "abstract": "Federated learning is typically approached as an optimization problem, where the goal is to minimize a global loss function by distributing computation across client devices that possess local data and specify different parts of the global objective.  We present an alternative perspective and formulate federated learning as a posterior inference problem, where the goal is to infer a global posterior distribution by having client devices each infer the posterior of their local data.  While exact inference is often intractable, this perspective provides a principled way to search for global optima in federated settings.  Further, starting with the analysis of federated quadratic objectives, we develop a computation- and communication-efficient approximate posterior inference algorithm—federated posterior averaging (FedPA).  Our algorithm uses MCMC for approximate inference of local posteriors on the clients and efficiently communicates their statistics to the server, where the latter uses them to refine a global estimate of the posterior mode.  Finally, we show that FedPA generalizes federated averaging (FedAvg), can similarly benefit from adaptive optimizers, and yields state-of-the-art results on four realistic and challenging benchmarks, converging faster, to better optima.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "联邦学习通过后验平均：新视角与实用算法",
        "摘要翻译": "联邦学习通常被视为一个优化问题，其目标是通过分布在拥有本地数据并指定全局目标不同部分的客户端设备上的计算，最小化全局损失函数。我们提出了一个替代视角，并将联邦学习表述为一个后验推断问题，其目标是通过让每个客户端设备推断其本地数据的后验，来推断全局后验分布。虽然精确推断通常是难以处理的，但这一视角为在联邦设置中寻找全局最优提供了一种原则性的方法。此外，从分析联邦二次目标开始，我们开发了一种计算和通信效率高的近似后验推断算法——联邦后验平均（FedPA）。我们的算法使用MCMC在客户端上近似推断局部后验，并有效地将其统计信息通信到服务器，后者使用这些信息来细化后验模式的全局估计。最后，我们展示了FedPA推广了联邦平均（FedAvg），可以类似地从自适应优化器中受益，并在四个现实且具有挑战性的基准测试中取得了最先进的结果，收敛更快，达到更好的最优。",
        "领域": "联邦学习",
        "问题": "如何在联邦学习环境中高效且有效地推断全局后验分布",
        "动机": "提供一种原则性的方法来在联邦设置中寻找全局最优，同时减少计算和通信开销",
        "方法": "开发了一种基于MCMC的近似后验推断算法FedPA，用于在客户端上近似推断局部后验，并在服务器上细化全局后验估计",
        "关键词": [
            "联邦学习",
            "后验推断",
            "MCMC",
            "FedPA",
            "自适应优化"
        ],
        "涉及的技术概念": {
            "后验推断": "在联邦学习中，通过客户端推断本地数据的后验分布来推断全局后验分布",
            "MCMC": "马尔可夫链蒙特卡洛方法，用于在客户端上近似推断局部后验分布",
            "FedPA": "联邦后验平均算法，一种计算和通信效率高的近似后验推断算法"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 276,
        "title": "Federated Semi-Supervised Learning with Inter-Client Consistency & Disjoint Learning",
        "html": "https://iclr.cc//virtual/2021/poster/2819",
        "abstract": "While existing federated learning approaches mostly require that clients have fully-labeled data to train on, in realistic settings, data obtained at the client-side often comes without any accompanying labels. Such deficiency of labels may result from either high labeling cost, or difficulty of annotation due to the requirement of expert knowledge. Thus the private data at each client may be either partly labeled, or completely unlabeled with labeled data being available only at the server, which leads us to a new practical federated learning problem, namely Federated Semi-Supervised Learning (FSSL). In this work, we study two essential scenarios of FSSL based on the location of the labeled data. The first scenario considers a conventional case where clients have both labeled and unlabeled data (labels-at-client), and the second scenario considers a more challenging case, where the labeled data is only available at the server (labels-at-server). We then propose a novel method to tackle the problems, which we refer to as Federated Matching (FedMatch). FedMatch improves upon naive combinations of federated learning and semi-supervised learning approaches with a new inter-client consistency loss and decomposition of the parameters for disjoint learning on labeled and unlabeled data. Through extensive experimental validation of our method in the two different scenarios, we show that our method outperforms both local semi-supervised learning and baselines which naively combine federated learning with semi-supervised learning.",
        "conference": "ICLR",
        "中文标题": "联邦半监督学习：客户端间一致性与分离学习",
        "摘要翻译": "虽然现有的联邦学习方法大多要求客户端拥有完全标记的数据进行训练，但在现实环境中，客户端获取的数据往往没有任何伴随的标签。这种标签的缺乏可能是由于高标注成本，或由于需要专家知识而难以进行标注。因此，每个客户端的私有数据可能是部分标记的，或者完全未标记，而标记数据仅在服务器端可用，这引出了一个新的实际联邦学习问题，即联邦半监督学习（FSSL）。在这项工作中，我们基于标记数据的位置研究了FSSL的两个基本场景。第一个场景考虑了一个常规情况，即客户端同时拥有标记和未标记的数据（标签在客户端），第二个场景考虑了一个更具挑战性的情况，即标记数据仅在服务器端可用（标签在服务器）。然后，我们提出了一种新方法来解决问题，我们称之为联邦匹配（FedMatch）。FedMatch通过新的客户端间一致性损失和参数分解，用于在标记和未标记数据上进行分离学习，改进了联邦学习和半监督学习方法的简单组合。通过在不同场景下对我们方法进行广泛的实验验证，我们展示了我们的方法在本地半监督学习和简单结合联邦学习与半监督学习的基线方法上的优越性。",
        "领域": "联邦学习、半监督学习、分布式机器学习",
        "问题": "解决在客户端数据部分标记或完全未标记情况下的联邦学习问题",
        "动机": "现实环境中客户端数据往往缺乏标签，导致传统联邦学习方法难以直接应用",
        "方法": "提出FedMatch方法，通过客户端间一致性损失和参数分解改进联邦半监督学习",
        "关键词": [
            "联邦学习",
            "半监督学习",
            "客户端间一致性",
            "分离学习",
            "FedMatch"
        ],
        "涉及的技术概念": {
            "联邦半监督学习（FSSL）": "在联邦学习框架下处理部分标记或完全未标记数据的学习问题",
            "客户端间一致性损失": "用于增强不同客户端间模型预测的一致性，提高模型泛化能力",
            "参数分解": "将模型参数分解为用于标记数据和未标记数据的不同部分，以优化学习过程"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 277,
        "title": "FedMix: Approximation of Mixup under Mean Augmented Federated Learning",
        "html": "https://iclr.cc//virtual/2021/poster/3145",
        "abstract": "Federated learning (FL) allows edge devices to collectively learn a model without directly sharing data within each device, thus preserving privacy and eliminating the need to store data globally. While there are promising results under the assumption of independent and identically distributed (iid) local data, current state-of-the-art algorithms suffer a performance degradation as the heterogeneity of local data across clients increases. To resolve this issue, we propose a simple framework, \\emph{Mean Augmented Federated Learning (MAFL)}, where clients send and receive \\emph{averaged} local data, subject to the privacy requirements of target applications. Under our framework, we propose a new augmentation algorithm, named \\emph{FedMix}, which is inspired by a phenomenal yet simple data augmentation method, Mixup, but does not require local raw data to be directly shared among devices. Our method shows greatly improved performance in the standard benchmark datasets of FL, under highly non-iid federated settings, compared to conventional algorithms.",
        "conference": "ICLR",
        "中文标题": "FedMix：均值增强联邦学习下的Mixup近似方法",
        "摘要翻译": "联邦学习（FL）允许边缘设备在不直接共享各自设备内数据的情况下共同学习一个模型，从而保护隐私并消除了全局存储数据的需要。虽然在独立同分布（iid）本地数据的假设下取得了有希望的结果，但随着跨客户端本地数据的异质性增加，当前最先进的算法性能会下降。为了解决这个问题，我们提出了一个简单的框架，即均值增强联邦学习（MAFL），在该框架下，客户端发送和接收平均化的本地数据，以满足目标应用的隐私要求。在我们的框架下，我们提出了一种新的增强算法，名为FedMix，它受到了一种现象级且简单的数据增强方法Mixup的启发，但不需要在设备之间直接共享本地原始数据。与传统算法相比，我们的方法在高度非iid的联邦设置下，在FL的标准基准数据集上显示出极大的性能提升。",
        "领域": "联邦学习、数据增强、非独立同分布学习",
        "问题": "解决联邦学习中因本地数据异质性增加导致的性能下降问题",
        "动机": "提高在高度非独立同分布数据下的联邦学习性能，同时保护数据隐私",
        "方法": "提出均值增强联邦学习（MAFL）框架和FedMix数据增强算法，通过平均化本地数据并在不直接共享原始数据的情况下近似Mixup方法",
        "关键词": [
            "联邦学习",
            "数据增强",
            "非独立同分布",
            "隐私保护",
            "Mixup"
        ],
        "涉及的技术概念": {
            "均值增强联邦学习（MAFL）": "一个允许客户端在不直接共享原始数据的情况下，通过发送和接收平均化的本地数据来共同学习模型的框架",
            "FedMix": "一种在MAFL框架下提出的数据增强算法，受到Mixup方法的启发，但不需要直接共享本地原始数据",
            "非独立同分布（non-iid）": "指数据在不同客户端之间分布不一致的情况，是联邦学习中的一个主要挑战"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 278,
        "title": "Few-Shot Bayesian Optimization with Deep Kernel Surrogates",
        "html": "https://iclr.cc//virtual/2021/poster/3163",
        "abstract": "Hyperparameter optimization (HPO) is a central pillar in the automation of machine learning solutions and is mainly performed via Bayesian optimization, where a parametric surrogate is learned to approximate the black box response function (e.g. validation error). Unfortunately, evaluating the response function is computationally intensive. As a remedy, earlier work emphasizes the need for transfer learning surrogates which learn to optimize hyperparameters for an algorithm from other tasks. In contrast to previous work, we propose to rethink HPO as a few-shot learning problem in which we train a shared deep surrogate model to quickly adapt (with few response evaluations) to the response function of a new task. We propose the use of a deep kernel network for a Gaussian process surrogate that is meta-learned in an end-to-end fashion in order to jointly approximate the response functions of a collection of training data sets. As a result, the novel few-shot optimization of our deep kernel surrogate leads to new state-of-the-art results at HPO compared to several recent methods on diverse metadata sets.",
        "conference": "ICLR",
        "中文标题": "基于深度核代理的少样本贝叶斯优化",
        "摘要翻译": "超参数优化（HPO）是机器学习解决方案自动化中的核心支柱，主要通过贝叶斯优化进行，其中学习一个参数化代理来近似黑盒响应函数（例如验证误差）。不幸的是，评估响应函数的计算量很大。作为补救措施，早期的工作强调了转移学习代理的必要性，这些代理学习从其他任务中优化算法的超参数。与之前的工作不同，我们提出将HPO重新思考为一个少样本学习问题，其中我们训练一个共享的深度代理模型，以快速适应（通过少量响应评估）新任务的响应函数。我们提出使用深度核网络作为高斯过程代理，该网络以端到端的方式进行元学习，以便共同近似一系列训练数据集的响应函数。因此，我们的深度核代理的新型少样本优化在HPO上相比几种最近的方法在多样化的元数据集上取得了新的最先进结果。",
        "领域": "超参数优化、贝叶斯优化、元学习",
        "问题": "如何在少量样本的情况下高效地进行超参数优化",
        "动机": "减少超参数优化过程中响应函数的计算量，提高优化效率",
        "方法": "提出一种基于深度核网络的高斯过程代理模型，通过元学习快速适应新任务的响应函数",
        "关键词": [
            "少样本学习",
            "深度核网络",
            "贝叶斯优化",
            "超参数优化",
            "元学习"
        ],
        "涉及的技术概念": {
            "深度核网络": "用于构建高斯过程代理模型，通过深度学习方法学习核函数，以提高模型的适应性和表达能力",
            "贝叶斯优化": "一种基于概率模型的全局优化方法，用于在少量样本下高效寻找最优超参数",
            "元学习": "通过学习多个任务的经验，使模型能够快速适应新任务，减少对新任务数据的需求"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 279,
        "title": "Few-Shot Learning via Learning the Representation, Provably",
        "html": "https://iclr.cc//virtual/2021/poster/2535",
        "abstract": "This paper studies few-shot learning via representation learning, where one uses $T$ source tasks with $n_1$ data per task to learn a representation in order to reduce the sample complexity of a target task for which there is only $n_2 (\\ll n_1)$ data. Specifically, we focus on the setting where there exists a good common representation between source and target, and our goal is to understand how much a sample size reduction is possible. First, we study the setting where this common representation is low-dimensional and provide a risk bound of $\\tilde{O}(\\frac{dk}{n_1T} + \\frac{k}{n_2})$ on the target task for the linear representation class; here $d$ is the ambient input dimension and $k (\\ll d)$ is the dimension of the representation. This result bypasses the $\\Omega(\\frac{1}{T})$ barrier under the i.i.d. task assumption, and can capture the desired property that all $n_1T$ samples from source tasks can be \\emph{pooled} together for representation learning. We further extend this result to handle a general representation function class and obtain a similar result. Next, we consider the setting where the common representation may be high-dimensional but is capacity-constrained (say in norm); here, we again demonstrate the advantage of representation learning in both high-dimensional linear regression and neural networks, and show that representation learning can fully utilize all $n_1T$ samples from source tasks.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "通过学习表征进行少样本学习，可证明有效",
        "摘要翻译": "本文研究了通过表征学习进行少样本学习的方法。在该方法中，使用T个源任务，每个任务有n1个数据，来学习一种表征，从而降低目标任务的样本复杂度，因为目标任务只有n2（远小于n1）个数据。具体来说，我们关注源任务和目标任务之间存在良好通用表征的场景，我们的目标是理解样本大小可以减少多少。首先，我们研究了这种通用表征是低维的情况，并为线性表征类提供了目标任务上的风险界限，为 O(dk/n1T + k/n2)；其中d是环境输入维度，k（远小于d）是表征的维度。该结果绕过了i.i.d.任务假设下的Ω(1/T)障碍，并且可以捕获期望的属性，即来自源任务的所有n1T个样本可以\\emph{汇集}在一起用于表征学习。我们进一步扩展了该结果以处理一般的表征函数类，并获得了类似的结果。接下来，我们考虑了通用表征可能是高维但容量受限（例如在范数中）的设置；在这里，我们再次证明了表征学习在高维线性回归和神经网络中的优势，并表明表征学习可以充分利用来自源任务的所有n1T个样本。",
        "领域": "元学习, 表征学习, 迁移学习",
        "问题": "如何在少量样本的情况下，利用源任务的知识，学习目标任务的模型？",
        "动机": "传统的机器学习方法需要大量的标注数据才能训练出有效的模型，但在很多实际应用中，标注数据往往是稀缺的。因此，如何利用少量的样本进行学习，成为了一个重要的研究问题。",
        "方法": "通过学习源任务和目标任务之间的通用表征，从而降低目标任务的样本复杂度。具体地，针对低维表征和高维容量约束表征两种情况，分别给出了相应的风险界限，并证明了该方法在理论上的有效性。",
        "关键词": [
            "少样本学习",
            "表征学习",
            "元学习",
            "迁移学习",
            "泛化误差"
        ],
        "涉及的技术概念": {
            "表征学习": "通过学习一种有效的特征表示，将原始数据转换为更易于学习和泛化的形式。在本文中，表征学习旨在找到源任务和目标任务之间的通用特征表示。",
            "风险界限": "用于衡量模型泛化能力的指标。本文通过推导风险界限，从理论上分析了所提出方法的有效性。"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 280,
        "title": "Fidelity-based Deep Adiabatic Scheduling",
        "html": "https://iclr.cc//virtual/2021/poster/3327",
        "abstract": "Adiabatic quantum computation is a form of computation that acts by slowly interpolating a quantum system between an easy to prepare initial state and a final state that represents a solution to a given computational problem. The choice of the interpolation schedule is critical to the performance: if at a certain time point, the evolution is too rapid, the system has a high probability to transfer to a higher energy state, which does not represent a solution to the problem. On the other hand, an evolution that is too slow leads to a loss of computation time and increases the probability of failure due to decoherence. In this work, we train deep neural models to produce optimal schedules that are conditioned on the problem at hand.  We consider two types of problem representation: the Hamiltonian form, and the Quadratic Unconstrained Binary Optimization (QUBO) form. A novel loss function that scores schedules according to their approximated success probability is introduced. We benchmark our approach on random QUBO problems, Grover search, 3-SAT, and MAX-CUT problems and show that our approach outperforms, by a sizable margin, the linear schedules as well as alternative approaches that were very recently proposed.",
        "conference": "ICLR",
        "中文标题": "基于保真度的深度绝热调度",
        "摘要翻译": "绝热量子计算是一种通过缓慢插值量子系统从易于准备的初始状态到代表给定计算问题解的最后状态来进行计算的形式。插值时间表的选择对性能至关重要：如果在某个时间点，演化过快，系统有很高的概率转移到更高的能量状态，这不代表问题的解。另一方面，演化过慢会导致计算时间的损失，并由于退相干增加失败的概率。在这项工作中，我们训练深度神经网络模型以生成针对手头问题优化的调度。我们考虑了两种问题表示形式：哈密顿形式和二次无约束二进制优化（QUBO）形式。引入了一种新颖的损失函数，根据其近似成功概率对调度进行评分。我们在随机QUBO问题、Grover搜索、3-SAT和MAX-CUT问题上对我们的方法进行了基准测试，并显示我们的方法在性能上大幅优于线性调度以及最近提出的替代方法。",
        "领域": "量子计算优化、绝热量子计算、深度学习应用",
        "问题": "如何优化绝热量子计算中的插值调度，以提高计算成功率和效率",
        "动机": "解决绝热量子计算中因调度选择不当导致的计算效率低下和失败率高的问题",
        "方法": "使用深度神经网络模型生成针对特定问题优化的绝热调度，并引入新的损失函数评估调度质量",
        "关键词": [
            "绝热量子计算",
            "深度神经网络",
            "调度优化",
            "QUBO",
            "损失函数"
        ],
        "涉及的技术概念": {
            "绝热量子计算": "一种通过缓慢改变量子系统哈密顿量来寻找问题解的计算方法",
            "深度神经网络": "用于生成和优化绝热调度的模型，能够根据问题特性自适应调整调度策略",
            "损失函数": "新引入的评估标准，用于根据调度的近似成功概率对其进行评分，指导模型优化"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 281,
        "title": "Filtered Inner Product Projection for Crosslingual Embedding Alignment",
        "html": "https://iclr.cc//virtual/2021/poster/2958",
        "abstract": "Due to widespread interest in machine translation and transfer learning, there are numerous algorithms for mapping multiple embeddings to a shared representation space. Recently, these algorithms have been studied in the setting of bilingual lexicon induction where one seeks to align the embeddings of a source and a target language such that translated word pairs lie close to one another in a common representation space. In this paper, we propose a method, Filtered Inner Product Projection (FIPP), for mapping embeddings to a common representation space. As semantic shifts are pervasive across languages and domains, FIPP first identifies the common geometric structure in both embeddings and then, only on the common structure, aligns the Gram matrices of these embeddings. FIPP is applicable even when the source and target embeddings are of differing dimensionalities. Additionally, FIPP provides computational benefits in ease of implementation and is faster to compute than current approaches. Following the baselines in Glavas et al. 2019, we evaluate FIPP both in the context of bilingual lexicon induction and downstream language tasks. We show that FIPP outperforms existing methods on the XLING BLI dataset for most language pairs while also providing robust performance across downstream tasks. ",
        "conference": "ICLR",
        "中文标题": "跨语言嵌入对齐的滤波内积投影方法",
        "摘要翻译": "由于机器翻译和迁移学习的广泛兴趣，存在多种算法用于将多个嵌入映射到共享的表示空间。最近，这些算法在双语词典诱导的背景下被研究，其中人们试图对齐源语言和目标语言的嵌入，使得翻译词对在共同的表示空间中彼此靠近。在本文中，我们提出了一种方法，滤波内积投影（FIPP），用于将嵌入映射到共同的表示空间。由于语义变化在语言和领域之间普遍存在，FIPP首先识别两个嵌入中的共同几何结构，然后仅在这些共同结构上对齐这些嵌入的Gram矩阵。FIPP即使在源和目标嵌入的维度不同时也适用。此外，FIPP在实现简便性和计算速度上提供了计算优势，比当前方法更快。遵循Glavas等人2019年的基线，我们在双语词典诱导和下游语言任务的背景下评估FIPP。我们表明，FIPP在XLING BLI数据集上对大多数语言对的表现优于现有方法，同时在下游任务中也提供了稳健的性能。",
        "领域": "跨语言嵌入对齐、双语词典诱导、迁移学习",
        "问题": "如何有效地将不同语言的词嵌入映射到一个共享的表示空间，以实现双语词典诱导和下游语言任务的高效处理。",
        "动机": "研究动机是为了解决跨语言嵌入对齐中的语义变化问题，以及提高映射方法的计算效率和实现简便性。",
        "方法": "提出滤波内积投影（FIPP）方法，通过识别和利用嵌入中的共同几何结构，对齐Gram矩阵，实现跨语言嵌入的有效对齐。",
        "关键词": [
            "跨语言嵌入对齐",
            "双语词典诱导",
            "滤波内积投影",
            "Gram矩阵对齐",
            "迁移学习"
        ],
        "涉及的技术概念": {
            "滤波内积投影（FIPP）": "一种用于跨语言嵌入对齐的新方法，通过识别共同几何结构并仅在这些结构上对齐Gram矩阵，提高对齐效率和效果。",
            "Gram矩阵对齐": "在FIPP方法中用于对齐不同语言嵌入的技术，通过比较和调整嵌入的Gram矩阵来实现共同表示空间的对齐。",
            "双语词典诱导": "研究背景之一，旨在通过跨语言嵌入对齐技术，实现源语言和目标语言词汇之间的自动翻译对应。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 282,
        "title": "Flowtron: an Autoregressive Flow-based Generative Network for Text-to-Speech Synthesis",
        "html": "https://iclr.cc//virtual/2021/poster/3204",
        "abstract": "In this paper we propose Flowtron: an autoregressive flow-based generative network for text-to-speech synthesis with style transfer and speech variation. Flowtron borrows insights from Autoregressive Flows and revamps Tacotron 2 in order to provide high-quality and expressive mel-spectrogram synthesis. Flowtron is optimized by maximizing the likelihood of the training data, which makes training simple and stable. Flowtron learns an invertible mapping of data to a latent space that can be used to modulate many aspects of speech synthesis (timbre, expressivity, accent). Our mean opinion scores (MOS) show that Flowtron matches state-of-the-art TTS models in terms of speech quality. We provide results on speech variation, interpolation over time between samples and style transfer between seen and unseen speakers. Code and pre-trained models are publicly available at \\href{https://github.com/NVIDIA/flowtron}{https://github.com/NVIDIA/flowtron}.",
        "conference": "ICLR",
        "中文标题": "Flowtron：一种基于自回归流的生成网络用于文本到语音合成",
        "摘要翻译": "在本文中，我们提出了Flowtron：一种基于自回归流的生成网络，用于具有风格转换和语音变化的文本到语音合成。Flowtron借鉴了自回归流的见解，并对Tacotron 2进行了改进，以提供高质量和富有表现力的梅尔频谱图合成。Flowtron通过最大化训练数据的可能性进行优化，这使得训练既简单又稳定。Flowtron学习了一个数据到潜在空间的可逆映射，该映射可用于调节语音合成的许多方面（音色、表现力、口音）。我们的平均意见分数（MOS）显示，Flowtron在语音质量方面与最先进的TTS模型相匹配。我们提供了关于语音变化、样本间时间插值以及已知和未知说话者之间风格转换的结果。代码和预训练模型可在https://github.com/NVIDIA/flowtron公开获取。",
        "领域": "语音合成, 风格转换, 语音变化",
        "问题": "如何提高文本到语音合成的质量和表现力，同时实现风格转换和语音变化",
        "动机": "为了提供更高质量和更富有表现力的文本到语音合成，同时实现风格转换和语音变化，以满足多样化的语音合成需求",
        "方法": "提出了一种基于自回归流的生成网络Flowtron，通过最大化训练数据的可能性进行优化，学习数据到潜在空间的可逆映射，以调节语音合成的多个方面",
        "关键词": [
            "文本到语音合成",
            "自回归流",
            "风格转换",
            "语音变化",
            "梅尔频谱图"
        ],
        "涉及的技术概念": {
            "自回归流": "Flowtron中采用的技术，用于生成高质量的梅尔频谱图，通过最大化训练数据的可能性进行优化",
            "Tacotron 2": "Flowtron改进的基础模型，用于提供高质量和富有表现力的语音合成",
            "平均意见分数（MOS）": "用于评估Flowtron语音质量的指标，结果显示其与最先进的TTS模型相匹配"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 283,
        "title": "FOCAL: Efficient Fully-Offline Meta-Reinforcement Learning via Distance Metric Learning and Behavior Regularization",
        "html": "https://iclr.cc//virtual/2021/poster/3343",
        "abstract": "We study the offline meta-reinforcement learning (OMRL) problem, a paradigm which enables reinforcement learning (RL) algorithms to quickly adapt to unseen tasks without any interactions with the environments, making RL truly practical in many real-world applications. This problem is still not fully understood, for which two major challenges need to be addressed. First, offline RL usually suffers from bootstrapping errors of out-of-distribution state-actions which leads to divergence of value functions. Second, meta-RL requires efficient and robust task inference learned jointly with control policy. In this work, we enforce behavior regularization on learned policy as a general approach to offline RL, combined with a deterministic context encoder for efficient task inference. We propose a novel negative-power distance metric on bounded context embedding space, whose gradients propagation is detached from the Bellman backup. We provide analysis and insight showing that some simple design choices can yield substantial improvements over recent approaches involving meta-RL and distance metric learning. To the best of our knowledge, our method is the first model-free and end-to-end OMRL algorithm, which is computationally efficient and demonstrated to outperform prior algorithms on several meta-RL benchmarks.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "FOCAL：通过距离度量学习和行为正则化的高效全离线元强化学习",
        "摘要翻译": "我们研究了离线元强化学习（OMRL）问题，这一范式使得强化学习（RL）算法能够无需与环境交互即可快速适应未见过的任务，从而使RL在许多实际应用中真正实用。这一问题尚未完全理解，需要解决两个主要挑战。首先，离线RL通常遭受分布外状态动作的引导误差，导致价值函数发散。其次，元RL需要与控制策略联合学习的高效且鲁棒的任务推断。在这项工作中，我们通过对学习策略实施行为正则化作为离线RL的一般方法，结合确定性上下文编码器以实现高效的任务推断。我们提出了一种在有界上下文嵌入空间上的新型负幂距离度量，其梯度传播与Bellman备份分离。我们提供的分析和见解表明，一些简单的设计选择可以比涉及元RL和距离度量学习的最新方法带来实质性改进。据我们所知，我们的方法是第一个无模型且端到端的OMRL算法，计算效率高，并在多个元RL基准测试中表现出优于先前算法的性能。",
        "领域": "元强化学习",
        "问题": "解决离线元强化学习中的分布外状态动作引导误差和高效任务推断问题",
        "动机": "使强化学习算法能够无需与环境交互即可快速适应新任务，提高在实际应用中的实用性",
        "方法": "通过行为正则化和确定性上下文编码器结合，提出新型负幂距离度量，实现高效任务推断和策略优化",
        "关键词": [
            "离线元强化学习",
            "行为正则化",
            "距离度量学习",
            "任务推断",
            "无模型算法"
        ],
        "涉及的技术概念": {
            "行为正则化": "用于约束学习策略，防止在离线强化学习中因分布外状态动作导致的策略退化",
            "负幂距离度量": "在有界上下文嵌入空间上定义的新型距离度量，用于高效任务推断，其梯度传播与Bellman备份分离",
            "确定性上下文编码器": "用于从少量样本中高效提取任务上下文信息，支持快速适应新任务"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 284,
        "title": "Fooling a Complete Neural Network Verifier",
        "html": "https://iclr.cc//virtual/2021/poster/3351",
        "abstract": "The efficient and accurate characterization of the robustness of neural networks to input perturbation is an important open problem. Many approaches exist including heuristic and exact (or complete) methods. Complete methods are expensive but their mathematical formulation guarantees that they provide exact robustness metrics. However, this guarantee is valid only if we assume that the verified network applies arbitrary-precision arithmetic and the verifier is reliable. In practice, however, both the networks and the verifiers apply limited-precision floating point arithmetic. In this paper, we show that numerical roundoff errors can be exploited to craft adversarial networks, in which the actual robustness and the robustness computed by a state-of-the-art complete verifier radically differ. We also show that such adversarial networks can be used to insert a backdoor into any network in such a way that the backdoor is completely missed by the verifier. The attack is easy to detect in its naive form but, as we show, the adversarial network can be transformed to make its detection less trivial. We offer a simple defense against our particular attack based on adding a very small perturbation to the network weights. However, our conjecture is that other numerical attacks are possible, and exact verification has to take into account all the details of the computation executed by the verified networks, which makes the problem significantly harder.\n\n",
        "conference": "ICLR",
        "中文标题": "欺骗完整的神经网络验证器",
        "摘要翻译": "神经网络对输入扰动的鲁棒性的高效准确表征是一个重要的开放性问题。存在许多方法，包括启发式和精确（或完整）方法。完整方法虽然昂贵，但其数学公式保证了它们提供精确的鲁棒性度量。然而，这一保证仅在假设验证的网络应用任意精度算术且验证器可靠的情况下有效。实际上，网络和验证器都应用了有限精度的浮点算术。在本文中，我们展示了可以利用数值舍入误差来制作对抗性网络，其中实际鲁棒性与由最先进的完整验证器计算的鲁棒性截然不同。我们还展示了这种对抗性网络可用于以验证器完全忽略的方式向任何网络插入后门。攻击在其原始形式下易于检测，但正如我们所示，对抗性网络可以被转换以使其检测变得不那么简单。我们提供了一种基于向网络权重添加非常小的扰动的简单防御措施来抵御我们的特定攻击。然而，我们的推测是，其他数值攻击是可能的，精确验证必须考虑到验证网络执行的计算的所有细节，这使得问题变得更加困难。",
        "领域": "神经网络验证、对抗性攻击、网络安全",
        "问题": "如何利用数值舍入误差制作对抗性网络，使得实际鲁棒性与验证器计算的鲁棒性存在显著差异。",
        "动机": "揭示在有限精度浮点算术下，完整验证器可能无法准确评估网络鲁棒性的问题，并提出对抗性网络的概念。",
        "方法": "通过利用数值舍入误差制作对抗性网络，展示其在实际鲁棒性与验证器计算结果之间的差异，并提出简单的防御措施。",
        "关键词": [
            "对抗性网络",
            "神经网络验证",
            "数值舍入误差",
            "后门攻击",
            "鲁棒性评估"
        ],
        "涉及的技术概念": {
            "对抗性网络": "通过精心设计的输入扰动，使得神经网络产生错误输出的网络，用于测试和攻击神经网络的鲁棒性。",
            "数值舍入误差": "在有限精度算术运算中，由于无法精确表示所有数值而产生的误差，本文中用于制作对抗性网络。",
            "完整验证器": "一种能够提供数学上精确鲁棒性度量的神经网络验证方法，但在实际应用中可能受到有限精度算术的限制。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 285,
        "title": "For self-supervised learning, Rationality implies generalization, provably",
        "html": "https://iclr.cc//virtual/2021/poster/2603",
        "abstract": "We prove a new upper bound on the generalization gap of classifiers that are obtained by first using self-supervision to learn a representation $r$ of the training~data, and then fitting a simple (e.g., linear) classifier $g$ to the labels. Specifically, we show that (under the assumptions described below) the generalization gap of such classifiers tends to zero if $\\mathsf{C}(g) \\ll n$, where $\\mathsf{C}(g)$ is an appropriately-defined measure of the simple classifier $g$'s complexity, and $n$ is the number of training samples. We stress that our bound is independent of the complexity of the representation $r$. \nWe do not make any structural or conditional-independence  assumptions on the representation-learning task, which can use the same training dataset that is later used for classification. Rather, we assume that the training procedure satisfies certain natural noise-robustness (adding small amount of label noise causes small degradation in performance) and rationality  (getting the wrong label is not better than getting no label at all) conditions that widely hold across many standard architectures.\nWe also conduct an extensive empirical study of the generalization gap and the quantities used in our assumptions for a variety of self-supervision based algorithms, including SimCLR, AMDIM and BigBiGAN,  on the CIFAR-10 and ImageNet datasets. We show that, unlike standard supervised classifiers, these algorithms display small generalization gap, and the bounds we prove on this gap are often non vacuous. ",
        "conference": "ICLR",
        "success": true,
        "中文标题": "对于自监督学习，理性意味着泛化，可证明",
        "摘要翻译": "我们证明了通过首先使用自监督学习来学习训练数据的表示r，然后将一个简单的（例如，线性）分类器g拟合到标签而获得的分类器的泛化差距的一个新的上限。具体来说，我们表明（在下面描述的假设下），如果C(g) << n，则这种分类器的泛化差距趋于零，其中C(g)是适当定义的简单分类器g的复杂度的度量，n是训练样本的数量。我们强调，我们的界限与表示r的复杂度无关。 我们不对表示学习任务做任何结构或条件独立性假设，该任务可以使用与稍后用于分类的相同训练数据集。相反，我们假设训练过程满足某些自然的噪声鲁棒性（添加少量标签噪声会导致性能略有下降）和理性（获得错误的标签并不比根本没有标签更好）条件，这些条件在许多标准架构中广泛存在。 我们还对基于各种自监督算法（包括SimCLR，AMDIM和BigBiGAN）在CIFAR-10和ImageNet数据集上的泛化差距和我们假设中使用的量进行了广泛的实证研究。我们表明，与标准监督分类器不同，这些算法显示出较小的泛化差距，并且我们在此差距上证明的界限通常是非空的。",
        "领域": "自监督学习, 泛化理论, 表示学习",
        "问题": "如何从理论上证明自监督学习的泛化能力，并为自监督学习模型的泛化差距提供更严格的界限。",
        "动机": "现有的自监督学习方法缺乏对其泛化能力的理论保证，且泛化差距较大。因此，需要研究自监督学习的泛化能力，并提供理论支撑。",
        "方法": "通过对训练过程施加噪声鲁棒性和理性等自然条件，推导出自监督学习模型的泛化差距的新上限，并进行了广泛的实验验证，包括在CIFAR-10和ImageNet数据集上对SimCLR、AMDIM和BigBiGAN等算法进行评估。",
        "关键词": [
            "自监督学习",
            "泛化差距",
            "理性",
            "噪声鲁棒性",
            "表示学习"
        ],
        "涉及的技术概念": {
            "自监督学习": "一种利用未标记数据进行预训练，从而学习数据表示的方法，旨在提高模型在下游任务上的性能。",
            "泛化差距": "模型在训练数据上的性能与在未见过的数据上的性能之间的差异，用于衡量模型的泛化能力。"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 286,
        "title": "Fourier Neural Operator for Parametric Partial Differential Equations",
        "html": "https://iclr.cc//virtual/2021/poster/3281",
        "abstract": "The classical development of neural networks has primarily focused on learning mappings between finite-dimensional Euclidean spaces.  Recently, this has been generalized to neural operators that learn mappings between function spaces. For partial differential equations (PDEs), neural operators directly learn the mapping from any functional parametric dependence to the solution. Thus, they learn an entire family of PDEs, in contrast to classical methods which solve one instance of the equation. In this work, we formulate a new neural operator by parameterizing the integral kernel directly in Fourier space, allowing for an expressive and efficient architecture. We perform experiments on Burgers' equation, Darcy flow, and Navier-Stokes equation. The Fourier neural operator is the first ML-based method to successfully model turbulent flows with zero-shot super-resolution. It is up to three orders of magnitude faster compared to traditional PDE solvers. Additionally, it achieves superior accuracy compared to previous learning-based solvers under fixed resolution.",
        "conference": "ICLR",
        "中文标题": "傅里叶神经算子用于参数偏微分方程",
        "摘要翻译": "神经网络的经典发展主要集中在对有限维欧几里得空间之间的映射学习上。最近，这一概念被推广到了学习函数空间之间映射的神经算子。对于偏微分方程（PDEs），神经算子直接从任何函数参数依赖关系到解的学习映射。因此，它们学习的是整个PDE家族，与解决方程单一实例的经典方法形成对比。在这项工作中，我们通过在傅里叶空间中直接参数化积分核，提出了一种新的神经算子，从而允许一个表达性强且高效的架构。我们在Burgers方程、Darcy流和Navier-Stokes方程上进行了实验。傅里叶神经算子是第一个成功模拟零样本超分辨率湍流流动的基于机器学习的方法。与传统PDE求解器相比，它的速度提高了三个数量级。此外，在固定分辨率下，它实现了比之前基于学习的求解器更优的准确性。",
        "领域": "偏微分方程求解、湍流模拟、机器学习在物理建模中的应用",
        "问题": "解决传统偏微分方程求解方法在处理不同参数和整个方程家族时的效率和灵活性问题",
        "动机": "开发一种能够高效学习整个偏微分方程家族映射的方法，以克服传统方法在解决单一实例时的限制",
        "方法": "通过在傅里叶空间中直接参数化积分核，提出了一种新的神经算子架构，用于高效学习偏微分方程的映射",
        "关键词": [
            "傅里叶神经算子",
            "偏微分方程",
            "湍流模拟",
            "零样本超分辨率",
            "机器学习求解器"
        ],
        "涉及的技术概念": {
            "傅里叶神经算子": "通过在傅里叶空间中直接参数化积分核，提出的一种新的神经算子架构，用于高效学习偏微分方程的映射",
            "零样本超分辨率": "指模型能够在没有经过特定分辨率训练的情况下，处理超出训练分辨率的数据",
            "偏微分方程求解": "研究如何找到满足特定偏微分方程的函数解的过程，本研究中通过机器学习方法提高求解效率和准确性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 287,
        "title": "Free Lunch for Few-shot Learning:  Distribution Calibration",
        "html": "https://iclr.cc//virtual/2021/poster/2633",
        "abstract": "Learning from a limited number of samples is challenging since the learned model can easily become overfitted based on the biased distribution formed by only a few training examples. In this paper, we calibrate the distribution of these few-sample classes by transferring statistics from the classes with sufficient examples. Then an adequate number of examples can be sampled from the calibrated distribution to expand the inputs to the classifier. We assume every dimension in the feature representation follows a Gaussian distribution so that the mean and the variance of the distribution can borrow from that of similar classes whose statistics are better estimated with an adequate number of samples. Our method can be built on top of off-the-shelf pretrained feature extractors and classification models without extra parameters. We show that a simple logistic regression classifier trained using the features sampled from our calibrated distribution can outperform the state-of-the-art accuracy on three datasets (~5% improvement on miniImageNet compared to the next best). The visualization of these generated features demonstrates that our calibrated distribution is an accurate estimation. ",
        "conference": "ICLR",
        "中文标题": "少样本学习的免费午餐：分布校准",
        "摘要翻译": "从有限数量的样本中学习具有挑战性，因为学习到的模型很容易基于仅由少数训练样本形成的偏态分布而过拟合。在本文中，我们通过从有足够样本的类别转移统计量来校准这些少样本类别的分布。然后，可以从校准后的分布中采样足够数量的样本来扩展分类器的输入。我们假设特征表示中的每个维度都遵循高斯分布，因此可以从那些统计量通过足够数量的样本更好估计的相似类别中借用分布的均值和方差。我们的方法可以建立在现成的预训练特征提取器和分类模型之上，无需额外参数。我们展示了使用从我们校准的分布中采样的特征训练的简单逻辑回归分类器可以在三个数据集上超越最先进的准确率（在miniImageNet上相比次优方法提高了约5%）。这些生成特征的可视化表明，我们的校准分布是一个准确的估计。",
        "领域": "少样本学习, 图像分类, 迁移学习",
        "问题": "解决在少样本学习场景中，由于训练样本不足导致的模型过拟合问题。",
        "动机": "通过从样本充足的类别转移统计量来校准少样本类别的分布，以生成更多样本来改善模型性能。",
        "方法": "假设特征表示遵循高斯分布，从相似类别借用统计量来校准少样本类别的分布，并采样扩展输入。",
        "关键词": [
            "少样本学习",
            "分布校准",
            "高斯分布",
            "迁移学习",
            "逻辑回归"
        ],
        "涉及的技术概念": {
            "分布校准": "通过从样本充足的类别转移统计量来调整少样本类别的分布，以生成更多训练样本。",
            "高斯分布": "假设特征表示中的每个维度遵循高斯分布，便于借用相似类别的统计量进行校准。",
            "迁移学习": "利用从样本充足类别学习到的知识来帮助校准少样本类别的分布，提升模型性能。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 288,
        "title": "Fully Unsupervised Diversity Denoising with Convolutional Variational Autoencoders",
        "html": "https://iclr.cc//virtual/2021/poster/2637",
        "abstract": "Deep Learning based methods have emerged as the indisputable leaders for virtually all image restoration tasks. Especially in the domain of microscopy images, various content-aware image restoration (CARE) approaches are now used to improve the interpretability of acquired data. Naturally, there are limitations to what can be restored in corrupted images, and like for all inverse problems, many potential solutions exist, and one of them must be chosen. Here, we propose DivNoising, a denoising approach based on fully convolutional variational autoencoders (VAEs), overcoming the problem of having to choose a single solution by predicting a whole distribution of denoised images. First we introduce a principled way of formulating the unsupervised denoising problem within the VAE framework by explicitly incorporating imaging noise models into the decoder. Our approach is fully unsupervised, only requiring noisy images and a suitable description of the imaging noise distribution. We show that such a noise model can either be measured, bootstrapped from noisy data, or co-learned during training. If desired, consensus predictions can be inferred from a set of DivNoising predictions, leading to competitive results with other unsupervised methods and, on occasion, even with the supervised state-of-the-art. DivNoising samples from the posterior enable a plethora of useful applications. We are (i) showing denoising results for 13 datasets, (ii) discussing how optical character recognition (OCR) applications can benefit from diverse predictions, and are (iii) demonstrating how instance cell segmentation improves when using diverse DivNoising predictions.",
        "conference": "ICLR",
        "中文标题": "基于卷积变分自编码器的完全无监督多样性去噪",
        "摘要翻译": "基于深度学习的方法已成为几乎所有图像修复任务中无可争议的领导者。特别是在显微镜图像领域，各种内容感知的图像修复（CARE）方法现在被用来提高获取数据的可解释性。自然，对于损坏图像中可以修复的内容存在限制，并且像所有逆问题一样，存在许多潜在的解决方案，必须从中选择一个。在这里，我们提出了DivNoising，一种基于完全卷积变分自编码器（VAEs）的去噪方法，通过预测去噪图像的整个分布来克服必须选择单一解决方案的问题。首先，我们介绍了一种在VAE框架内制定无监督去噪问题的原则性方法，通过将成像噪声模型明确地纳入解码器。我们的方法完全无监督，仅需要噪声图像和成像噪声分布的合适描述。我们展示了这样的噪声模型可以从噪声数据中测量、自举或在训练过程中共同学习。如果需要，可以从一组DivNoising预测中推断出共识预测，从而与其他无监督方法竞争，有时甚至与监督的最先进技术竞争。DivNoising从后验中采样实现了大量有用的应用。我们（i）展示了13个数据集的去噪结果，（ii）讨论了光学字符识别（OCR）应用如何从多样化的预测中受益，以及（iii）演示了当使用多样化的DivNoising预测时，实例细胞分割如何改善。",
        "领域": "图像去噪、显微镜图像处理、光学字符识别",
        "问题": "解决在无监督条件下从损坏的图像中选择单一去噪解决方案的问题",
        "动机": "通过预测去噪图像的整个分布，克服必须选择单一解决方案的限制，提高图像修复的多样性和质量",
        "方法": "基于完全卷积变分自编码器（VAEs）的无监督去噪方法，将成像噪声模型明确地纳入解码器",
        "关键词": [
            "无监督学习",
            "变分自编码器",
            "图像去噪",
            "多样性预测",
            "显微镜图像"
        ],
        "涉及的技术概念": {
            "变分自编码器（VAEs）": "用于构建去噪模型，通过编码器-解码器结构学习图像的低维表示",
            "成像噪声模型": "在解码器中明确纳入，帮助模型理解和去除图像中的噪声",
            "多样性预测": "通过预测去噪图像的整个分布，提供多种可能的解决方案，增加应用的灵活性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 289,
        "title": "Fuzzy Tiling Activations: A Simple Approach to Learning Sparse Representations Online",
        "html": "https://iclr.cc//virtual/2021/poster/2951",
        "abstract": "Recent work has shown that sparse representations---where only a small percentage of units are active---can significantly reduce interference. Those works, however, relied on relatively complex regularization or meta-learning approaches, that have only been used offline in a pre-training phase. In this work, we pursue a direction that achieves sparsity by design, rather than by learning. Specifically, we design an activation function that produces sparse representations deterministically by construction, and so is more amenable to online training. The idea relies on the simple approach of binning, but overcomes the two key limitations of binning: zero gradients for the flat regions almost everywhere,  and lost precision---reduced discrimination---due to coarse aggregation. We introduce a Fuzzy Tiling Activation (FTA) that provides non-negligible gradients and produces overlap between bins that improves discrimination. We first show that FTA is robust under covariate shift in a synthetic online supervised learning problem, where we can vary the level of correlation and drift. Then we move to the deep reinforcement learning setting and investigate both value-based and policy gradient algorithms that use neural networks with FTAs, in classic discrete control and Mujoco continuous control environments. We show that algorithms equipped with FTAs are able to learn a stable policy faster without needing target networks on most domains. ",
        "conference": "ICLR",
        "中文标题": "模糊平铺激活：一种在线学习稀疏表示的简单方法",
        "摘要翻译": "最近的研究表明，稀疏表示——只有一小部分单元活跃——可以显著减少干扰。然而，这些研究依赖于相对复杂的正则化或元学习方法，这些方法仅在离线预训练阶段使用。在这项工作中，我们追求一种通过设计而非学习实现稀疏性的方向。具体来说，我们设计了一种激活函数，通过构造确定性地产生稀疏表示，因此更适合在线训练。这一想法依赖于简单的分箱方法，但克服了分箱的两个关键限制：几乎处处平坦区域的零梯度，以及由于粗粒度聚合而丢失的精度——降低了区分度。我们引入了一种模糊平铺激活（FTA），它提供了不可忽略的梯度，并在分箱之间产生重叠，从而提高了区分度。我们首先展示了FTA在合成在线监督学习问题中对协变量偏移的鲁棒性，其中我们可以改变相关性和漂移的水平。然后，我们转向深度强化学习设置，并在经典离散控制和Mujoco连续控制环境中研究了使用带有FTA的神经网络的价值基础和策略梯度算法。我们展示了配备FTA的算法能够在大多数领域更快地学习稳定策略，而无需目标网络。",
        "领域": "稀疏表示学习, 深度强化学习, 在线学习",
        "问题": "如何在线训练中有效实现稀疏表示以减少干扰",
        "动机": "探索一种通过设计而非复杂学习过程实现稀疏表示的方法，以提高在线训练的效率和稳定性",
        "方法": "设计了一种名为模糊平铺激活（FTA）的激活函数，通过构造确定性地产生稀疏表示，克服传统分箱方法的限制",
        "关键词": [
            "稀疏表示",
            "模糊平铺激活",
            "在线学习",
            "深度强化学习",
            "激活函数"
        ],
        "涉及的技术概念": {
            "稀疏表示": "只有一小部分单元活跃的表示方式，可以减少干扰",
            "模糊平铺激活（FTA）": "一种新型激活函数，通过构造确定性地产生稀疏表示，提供非零梯度和分箱间重叠以提高区分度",
            "在线学习": "模型在接收数据流时实时更新，适用于动态变化的环境"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 290,
        "title": "GAN2GAN: Generative Noise Learning for Blind Denoising with Single Noisy Images",
        "html": "https://iclr.cc//virtual/2021/poster/3355",
        "abstract": "We tackle a challenging blind image denoising problem, in which only single distinct noisy images are available for training a denoiser, and no information about noise is known, except for it being zero-mean, additive, and independent of the clean image. In such a setting, which often occurs in practice, it is not possible to train a denoiser with the standard discriminative training or with the recently developed Noise2Noise (N2N) training; the former requires the underlying clean image for the given noisy image, and the latter requires two independently realized noisy image pair for a clean image. To that end, we propose GAN2GAN (Generated-Artificial-Noise to Generated-Artificial-Noise) method that first learns a generative model that can 1) simulate the noise in the given noisy images and 2) generate a rough, noisy estimates of the clean images, then 3) iteratively trains a denoiser with subsequently synthesized noisy image pairs (as in N2N), obtained from the generative model. In results, we show the denoiser trained with our GAN2GAN achieves an impressive denoising performance on both synthetic and real-world datasets for the blind denoising setting; it almost approaches the performance of the standard discriminatively-trained or N2N-trained models that have more information than ours, and it significantly outperforms the recent baseline for the same setting, \\textit{e.g.}, Noise2Void, and a more conventional yet strong one, BM3D. The official code of our method is available at https://github.com/csm9493/GAN2GAN.",
        "conference": "ICLR",
        "中文标题": "GAN2GAN：基于生成噪声学习的单噪声图像盲去噪",
        "摘要翻译": "我们解决了一个具有挑战性的盲图像去噪问题，在该问题中，仅有一张不同的噪声图像可用于训练去噪器，且除了噪声为零均值、加性且与干净图像独立之外，没有关于噪声的其他信息。在这种实际中常见的设置下，无法使用标准的判别式训练或最近开发的Noise2Noise（N2N）训练方法来训练去噪器；前者需要给定噪声图像的基础干净图像，后者需要一个干净图像的两个独立实现的噪声图像对。为此，我们提出了GAN2GAN（生成-人工噪声到生成-人工噪声）方法，该方法首先学习一个生成模型，该模型能够1）模拟给定噪声图像中的噪声，2）生成干净图像的粗略噪声估计，然后3）使用从生成模型获得的随后合成的噪声图像对（如N2N中那样）迭代训练去噪器。结果显示，使用我们的GAN2GAN训练的去噪器在盲去噪设置下，在合成和真实世界数据集上都实现了令人印象深刻的去噪性能；它几乎接近了比我们拥有更多信息的标准判别式训练或N2N训练模型的性能，并且显著优于相同设置下的最新基线，例如Noise2Void，以及更传统但强大的BM3D。我们方法的官方代码可在https://github.com/csm9493/GAN2GAN获取。",
        "领域": "图像去噪、生成对抗网络、盲去噪",
        "问题": "在仅有单张噪声图像且噪声信息未知的情况下进行盲去噪",
        "动机": "解决在实际应用中常见的、缺乏干净图像或噪声图像对的盲去噪问题",
        "方法": "提出GAN2GAN方法，通过生成模型学习噪声特性并生成噪声图像对，用于迭代训练去噪器",
        "关键词": [
            "盲去噪",
            "生成对抗网络",
            "噪声学习",
            "单噪声图像",
            "图像去噪"
        ],
        "涉及的技术概念": {
            "生成对抗网络": "用于模拟噪声和生成噪声图像对的核心技术",
            "盲去噪": "在噪声特性未知的情况下进行图像去噪的技术",
            "噪声学习": "通过学习噪声特性来生成可用于训练去噪器的噪声图像对"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 291,
        "title": "GANs Can Play Lottery Tickets Too",
        "html": "https://iclr.cc//virtual/2021/poster/2934",
        "abstract": "Deep generative adversarial networks (GANs) have gained growing popularity in numerous scenarios, while usually suffer from high parameter complexities for resource-constrained real-world applications. However, the compression of GANs has less been explored. A few works show that heuristically applying compression techniques normally leads to unsatisfactory results, due to the notorious training instability of GANs. In parallel, the lottery ticket hypothesis shows prevailing success on discriminative models, in locating sparse matching subnetworks capable of training in isolation to full model performance. In this work, we for the first time study the existence of such trainable matching subnetworks in deep GANs. For a range of GANs, we certainly find matching subnetworks at $67\\%$-$74\\%$ sparsity. We observe that with or without pruning discriminator has a minor effect on the existence and quality of matching subnetworks, while the initialization weights used in the discriminator plays a significant role. We then show the powerful transferability of these subnetworks to unseen tasks. Furthermore, extensive experimental results demonstrate that our found subnetworks substantially outperform previous state-of-the-art GAN compression approaches in both image generation (e.g. SNGAN) and image-to-image translation GANs (e.g. CycleGAN). Codes available at https://github.com/VITA-Group/GAN-LTH.",
        "conference": "ICLR",
        "中文标题": "GAN也能玩彩票假设",
        "摘要翻译": "深度生成对抗网络（GANs）在众多场景中越来越受欢迎，但通常因其高参数复杂度而难以应用于资源受限的现实场景。然而，GANs的压缩研究较少。少数工作表明，由于GANs众所周知的训练不稳定性，启发式地应用压缩技术通常会导致不满意的结果。与此同时，彩票假设在判别模型上显示出普遍的成功，能够定位出稀疏的匹配子网络，这些子网络能够独立训练以达到完整模型的性能。在这项工作中，我们首次研究了在深度GANs中是否存在这样的可训练匹配子网络。对于一系列GANs，我们确实在67%到74%的稀疏度下找到了匹配子网络。我们观察到，是否对判别器进行剪枝对匹配子网络的存在和质量影响较小，而判别器中使用的初始化权重则起着重要作用。然后，我们展示了这些子网络对未见任务的强大迁移能力。此外，大量的实验结果表明，我们发现的子网络在图像生成（如SNGAN）和图像到图像转换GANs（如CycleGAN）中，大大优于之前最先进的GAN压缩方法。代码可在https://github.com/VITA-Group/GAN-LTH获取。",
        "领域": "生成对抗网络压缩、图像生成、图像到图像转换",
        "问题": "如何在保持生成对抗网络性能的同时，减少其参数复杂度以适应资源受限的应用场景。",
        "动机": "探索在深度生成对抗网络中是否存在可训练的稀疏匹配子网络，以实现高效的模型压缩。",
        "方法": "研究彩票假设在GANs中的应用，寻找稀疏匹配子网络，并评估其性能和迁移能力。",
        "关键词": [
            "生成对抗网络",
            "模型压缩",
            "彩票假设",
            "稀疏子网络",
            "迁移学习"
        ],
        "涉及的技术概念": {
            "彩票假设": "在判别模型中成功应用的理论，用于定位能够独立训练达到完整模型性能的稀疏子网络。",
            "生成对抗网络压缩": "减少GANs的参数复杂度，使其更适合资源受限的应用场景。",
            "稀疏子网络": "在GANs中找到的能够以较低参数复杂度保持或接近原始模型性能的子网络。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 292,
        "title": "GAN 'Steerability' without optimization ",
        "html": "https://iclr.cc//virtual/2021/poster/2885",
        "abstract": "Recent research has shown remarkable success in revealing 'steering' directions in the latent spaces of pre-trained GANs. These directions correspond to semantically meaningful image transformations (e.g., shift, zoom, color manipulations), and have the same interpretable effect across all categories that the GAN can generate. Some methods focus on user-specified transformations, while others discover transformations in an unsupervised manner. However, all existing techniques rely on an optimization procedure to expose those directions, and offer no control over the degree of allowed interaction between different transformations. In this paper, we show that 'steering' trajectories can be computed in closed form directly from the generator's weights without any form of training or optimization. This applies to user-prescribed geometric transformations, as well as to unsupervised discovery of more complex effects. Our approach allows determining both linear and nonlinear trajectories, and has many advantages over previous methods. In particular, we can control whether one transformation is allowed to come on the expense of another (e.g., zoom-in with or without allowing translation to keep the object centered). Moreover, we can determine the natural end-point of the trajectory, which corresponds to the largest extent to which a transformation can be applied without incurring degradation. Finally, we show how transferring attributes between images can be achieved without optimization, even across different categories.\n",
        "conference": "ICLR",
        "中文标题": "无需优化的GAN'可操控性'",
        "摘要翻译": "最近的研究在揭示预训练GANs潜在空间中的'操控'方向上取得了显著成功。这些方向对应于语义上有意义的图像变换（例如，移动、缩放、颜色操作），并且在GAN可以生成的所有类别中具有相同的可解释效果。一些方法专注于用户指定的变换，而其他方法则以无监督的方式发现变换。然而，所有现有技术都依赖于优化过程来暴露这些方向，并且不提供对不同变换之间允许的交互程度的控制。在本文中，我们展示了'操控'轨迹可以直接从生成器的权重中以封闭形式计算，无需任何形式的训练或优化。这适用于用户规定的几何变换，以及无监督发现的更复杂效果。我们的方法允许确定线性和非线性轨迹，并且比之前的方法有许多优势。特别是，我们可以控制是否允许一个变换以另一个变换为代价（例如，放大时是否允许平移以保持对象居中）。此外，我们可以确定轨迹的自然终点，这对应于在不引起退化的情况下可以应用变换的最大程度。最后，我们展示了如何无需优化即可实现图像之间的属性转移，甚至跨不同类别。",
        "领域": "生成对抗网络、图像生成、图像编辑",
        "问题": "如何在无需优化的情况下揭示和控制预训练GANs潜在空间中的'操控'方向",
        "动机": "现有方法依赖于优化过程来发现和操控GANs潜在空间中的方向，缺乏对不同变换之间交互程度的控制，且计算效率不高。",
        "方法": "提出一种直接从生成器权重中以封闭形式计算'操控'轨迹的方法，无需训练或优化，支持线性和非线性轨迹的确定，并能控制变换间的交互。",
        "关键词": [
            "GAN可操控性",
            "潜在空间操控",
            "无优化方法",
            "图像变换",
            "属性转移"
        ],
        "涉及的技术概念": {
            "潜在空间操控": "指在生成对抗网络的潜在空间中识别和操作特定方向，以实现对生成图像的语义上有意义的变换。",
            "封闭形式计算": "指无需迭代优化即可直接通过数学表达式计算结果的方法，提高了计算效率和可控性。",
            "变换交互控制": "指在图像变换过程中，能够控制不同变换之间的相互影响和优先级，以实现更精确的图像编辑效果。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 293,
        "title": "Gauge Equivariant Mesh CNNs: Anisotropic convolutions on geometric graphs",
        "html": "https://iclr.cc//virtual/2021/poster/3367",
        "abstract": "A common approach to define convolutions on meshes is to interpret them as a graph and apply graph convolutional networks (GCNs).  Such GCNs utilize isotropic kernels and are therefore insensitive to the relative orientation of vertices and thus to the geometry of the mesh as a whole. We propose Gauge Equivariant Mesh CNNs which generalize GCNs to apply anisotropic gauge equivariant kernels. Since the resulting features carry orientation information, we introduce a geometric message passing scheme defined by parallel transporting features over mesh edges. Our experiments validate the significantly improved expressivity of the proposed model over conventional GCNs and other methods.",
        "conference": "ICLR",
        "中文标题": "规范等变网格卷积网络：几何图上的各向异性卷积",
        "摘要翻译": "在网格上定义卷积的一种常见方法是将其解释为图并应用图卷积网络（GCNs）。这类GCNs使用各向同性核，因此对顶点的相对方向不敏感，从而对整个网格的几何形状不敏感。我们提出了规范等变网格卷积网络，它将GCNs推广到应用各向异性的规范等变核。由于所得特征携带方向信息，我们引入了一种由在网格边上平行传输特征定义的几何消息传递方案。我们的实验验证了所提出模型相比传统GCNs及其他方法在表达能力上的显著提升。",
        "领域": "几何深度学习、图神经网络、三维形状分析",
        "问题": "传统图卷积网络在处理网格数据时无法有效捕捉几何形状的方向信息",
        "动机": "提升图卷积网络对网格几何形状方向信息的敏感度和表达能力",
        "方法": "提出规范等变网格卷积网络，引入各向异性规范等变核和几何消息传递方案",
        "关键词": [
            "规范等变卷积",
            "几何图",
            "各向异性核",
            "网格处理",
            "几何消息传递"
        ],
        "涉及的技术概念": {
            "规范等变核": "用于在各向异性方向上捕捉网格几何形状的特征，提升模型对方向信息的敏感度",
            "几何消息传递": "通过在网格边上平行传输特征，保留和传递方向信息",
            "各向异性卷积": "不同于传统各向同性卷积，能够区分不同方向上的特征，更好地捕捉几何形状"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 294,
        "title": "Generalization bounds via distillation",
        "html": "https://iclr.cc//virtual/2021/poster/3261",
        "abstract": "This paper theoretically investigates the following empirical phenomenon: given a high-complexity network with poor generalization bounds, one can distill it into a network with nearly identical predictions but low complexity and vastly smaller generalization bounds.  The main contribution is an analysis showing that the original network inherits this good generalization bound from its distillation, assuming the use of well-behaved data augmentation.  This bound is presented both in an abstract and in a concrete form, the latter complemented by a reduction technique to handle modern computation graphs featuring convolutional layers, fully-connected layers, and skip connections, to name a few.  To round out the story, a (looser) classical uniform convergence analysis of compression is also presented, as well as a variety of experiments on cifar and mnist demonstrating similar generalization performance between the original network and its distillation.  \n",
        "conference": "ICLR",
        "中文标题": "通过蒸馏实现的泛化界限",
        "摘要翻译": "本文从理论上研究了以下经验现象：给定一个泛化界限较差的高复杂度网络，可以将其蒸馏成一个预测几乎相同但复杂度低且泛化界限显著减小的网络。主要贡献是一个分析，表明原始网络从其蒸馏中继承了这一良好的泛化界限，假设使用了表现良好的数据增强。这一界限以抽象和具体两种形式呈现，后者辅以一种减少技术来处理现代计算图，包括卷积层、全连接层和跳跃连接等。为了完善这一研究，还提出了一个（较宽松的）经典压缩均匀收敛分析，以及在cifar和mnist上进行的一系列实验，展示了原始网络与其蒸馏之间相似的泛化性能。",
        "领域": "模型压缩、知识蒸馏、深度学习理论",
        "问题": "如何通过蒸馏技术改善高复杂度网络的泛化性能",
        "动机": "探索高复杂度网络通过蒸馏技术转化为低复杂度网络后，泛化性能改善的理论基础",
        "方法": "理论分析蒸馏过程中泛化界限的继承性，结合数据增强和减少技术处理现代计算图，辅以实验验证",
        "关键词": [
            "知识蒸馏",
            "泛化界限",
            "模型压缩",
            "数据增强",
            "深度学习理论"
        ],
        "涉及的技术概念": {
            "知识蒸馏": "将高复杂度网络的知识转移到低复杂度网络的技术，用于改善泛化性能",
            "泛化界限": "衡量模型在未见数据上表现的理论界限，本文通过蒸馏技术改善这一界限",
            "数据增强": "在训练过程中通过变换输入数据增加数据多样性，本文假设使用表现良好的数据增强以支持理论分析"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 295,
        "title": "Generalization in data-driven models of primary visual cortex",
        "html": "https://iclr.cc//virtual/2021/poster/3042",
        "abstract": "Deep neural networks (DNN) have set new standards at predicting responses of neural populations to visual input.  Most such DNNs consist of a convolutional network (core) shared across all neurons which learns a representation of neural computation in visual cortex and a neuron-specific readout that linearly combines the relevant features in this representation. The goal of this paper is to test whether such a representation is indeed generally characteristic for visual cortex, i.e. generalizes between animals of a species, and what factors contribute to obtaining such a generalizing core. To push all non-linear computations into the core where the generalizing cortical features should be learned, we devise a novel readout that reduces the number of parameters per neuron in the readout by up to two orders of magnitude compared to the previous state-of-the-art. It does so by taking advantage of retinotopy and learns a Gaussian distribution over the neuron’s receptive field position.  With this new readout we train our network on neural responses from mouse primary visual cortex (V1) and obtain a gain in performance of 7% compared to the previous state-of-the-art network.  We then investigate whether the convolutional core indeed captures general cortical features by using the core in transfer learning to a different animal.  When transferring a core trained on thousands of neurons from various animals and scans we exceed the performance of training directly on that animal by 12%, and outperform a commonly used VGG16 core pre-trained on imagenet by 33%. In addition, transfer learning with our data-driven core is more data-efficient than direct training, achieving the same performance with only 40% of the data. Our model with its novel readout thus sets a new state-of-the-art for neural response prediction in mouse visual cortex from natural images, generalizes between animals, and captures better characteristic cortical features than current task-driven pre-training approaches such as VGG16.",
        "conference": "ICLR",
        "中文标题": "数据驱动的初级视觉皮层模型中的泛化能力",
        "摘要翻译": "深度神经网络（DNN）在预测神经群体对视觉输入的反应方面设定了新标准。大多数此类DNN由一个在所有神经元之间共享的卷积网络（核心）组成，该网络学习视觉皮层中神经计算的表现，以及一个神经元特定的读出器，线性组合这一表现中的相关特征。本文的目标是测试这样的表现是否确实是视觉皮层的一般特征，即在同种动物之间泛化，以及哪些因素有助于获得这样的泛化核心。为了将所有非线性计算推入核心，在那里应该学习泛化的皮层特征，我们设计了一种新型读出器，与之前的最先进技术相比，将每个神经元在读出器中的参数数量减少了多达两个数量级。它通过利用视网膜拓扑结构并学习神经元感受野位置的高斯分布来实现这一点。使用这种新的读出器，我们在小鼠初级视觉皮层（V1）的神经反应上训练我们的网络，并获得了比之前最先进网络高出7%的性能提升。然后，我们通过在不同动物中使用核心进行迁移学习，研究卷积核心是否确实捕捉到了一般的皮层特征。当使用来自各种动物和扫描的数千个神经元训练的核心进行迁移时，我们比直接在该动物上训练的性能高出12%，并且比常用的在imagenet上预训练的VGG16核心高出33%。此外，使用我们数据驱动的核心进行迁移学习比直接训练更高效，仅使用40%的数据就能达到相同的性能。因此，我们的模型及其新型读出器为从自然图像中预测小鼠视觉皮层的神经反应设定了新的最先进标准，能够在动物之间泛化，并且比当前的任务驱动预训练方法（如VGG16）更好地捕捉特征性皮层特征。",
        "领域": "神经科学计算模型、视觉皮层模拟、深度学习在神经科学中的应用",
        "问题": "测试卷积网络核心是否能够捕捉视觉皮层的一般特征，并在不同动物之间泛化，以及探索影响泛化能力的因素。",
        "动机": "探索深度神经网络在模拟视觉皮层神经反应时的泛化能力，以及如何通过改进模型设计来提高这种能力。",
        "方法": "设计了一种新型读出器，显著减少每个神经元的参数数量，利用视网膜拓扑结构学习感受野位置的高斯分布，并在小鼠初级视觉皮层数据上进行训练和迁移学习测试。",
        "关键词": [
            "深度神经网络",
            "视觉皮层模拟",
            "迁移学习",
            "神经反应预测",
            "数据效率"
        ],
        "涉及的技术概念": {
            "卷积网络核心": "学习视觉皮层中神经计算的表现，旨在捕捉一般性的皮层特征。",
            "神经元特定读出器": "线性组合卷积核心中的特征，新型设计显著减少了参数数量。",
            "迁移学习": "在不同动物之间转移学习到的卷积核心，测试其泛化能力和数据效率。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 296,
        "title": "Generalized Energy Based Models",
        "html": "https://iclr.cc//virtual/2021/poster/3223",
        "abstract": "We introduce the Generalized Energy Based Model (GEBM) for generative modelling. These models combine two  trained components: a base distribution (generally an implicit model), which can learn the support of data with low intrinsic dimension in a high dimensional space; and an energy function, to refine the probability mass on the learned support. \nBoth the energy function and base jointly constitute the final model, unlike GANs, which retain only the base distribution (the 'generator').  \nGEBMs are trained by alternating between learning the energy and the base. \nWe show that both training stages are well-defined: the energy is learned by maximising a generalized likelihood, and the resulting energy-based loss provides informative gradients for learning the base.\nSamples from the posterior on the latent space of the trained model can be obtained via MCMC, thus finding regions in this space that produce better quality samples.\nEmpirically, the GEBM samples on image-generation tasks are of much better quality than those from the learned generator alone, indicating that all else being equal, the GEBM will outperform a GAN of the same complexity. When using normalizing flows as base measures, GEBMs succeed on density modelling tasks returning comparable performance to direct maximum likelihood of the same networks.",
        "conference": "ICLR",
        "中文标题": "广义能量基于模型",
        "摘要翻译": "我们介绍了用于生成建模的广义能量基于模型（GEBM）。这些模型结合了两个训练组件：一个基础分布（通常是一个隐式模型），它可以在高维空间中学习具有低内在维度的数据的支持；以及一个能量函数，用于在学习的支持上细化概率质量。与仅保留基础分布（'生成器'）的GANs不同，能量函数和基础共同构成了最终模型。GEBMs通过交替学习能量和基础来进行训练。我们展示了两个训练阶段都是定义良好的：能量是通过最大化广义似然来学习的，并且由此产生的基于能量的损失为学习基础提供了信息梯度。通过MCMC可以从训练模型的潜在空间后验中获得样本，从而在该空间中找到产生更高质量样本的区域。实证上，GEBM在图像生成任务上的样本质量远高于单独学习的生成器，表明在其他条件相同的情况下，GEBM将优于相同复杂度的GAN。当使用归一化流作为基础度量时，GEBMs在密度建模任务上取得了成功，返回了与相同网络的直接最大似然相当的性能。",
        "领域": "生成模型, 图像生成, 密度估计",
        "问题": "如何在生成建模中结合基础分布和能量函数以提高样本质量",
        "动机": "提高生成模型的样本质量，特别是在图像生成和密度估计任务中",
        "方法": "结合基础分布和能量函数，通过交替训练两者来优化模型",
        "关键词": [
            "广义能量基于模型",
            "生成建模",
            "图像生成",
            "密度估计",
            "MCMC采样"
        ],
        "涉及的技术概念": {
            "广义能量基于模型": "结合基础分布和能量函数的生成模型，用于提高样本质量",
            "基础分布": "模型中的一个组件，用于学习数据的支持",
            "能量函数": "模型中的另一个组件，用于在学习的支持上细化概率质量"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 297,
        "title": "Generalized Multimodal ELBO",
        "html": "https://iclr.cc//virtual/2021/poster/2632",
        "abstract": "Multiple data types naturally co-occur when describing real-world phenomena and learning from them is a long-standing goal in machine learning research. However, existing self-supervised generative models approximating an ELBO are not able to fulfill all desired requirements of multimodal models: their posterior approximation functions lead to a trade-off between the semantic coherence and the ability to learn the joint data distribution. We propose a new, generalized ELBO formulation for multimodal data that overcomes these limitations. The new objective encompasses two previous methods as special cases and combines their benefits without compromises. In extensive experiments, we demonstrate the advantage of the proposed method compared to state-of-the-art models in self-supervised, generative learning tasks.",
        "conference": "ICLR",
        "中文标题": "广义多模态ELBO",
        "摘要翻译": "多种数据类型在描述现实世界现象时自然共存，从中学习是机器学习研究的长期目标。然而，现有的自监督生成模型近似ELBO无法满足多模态模型的所有期望要求：它们的后验近似函数导致在语义连贯性和学习联合数据分布能力之间的权衡。我们提出了一种新的、广义的多模态数据ELBO公式，克服了这些限制。新目标将两种先前的方法作为特例包含在内，并无妥协地结合了它们的优点。在大量实验中，我们证明了所提出的方法在自监督生成学习任务中相比最先进模型的优势。",
        "领域": "多模态学习、自监督学习、生成模型",
        "问题": "现有自监督生成模型在多模态学习中无法同时保证语义连贯性和学习联合数据分布的能力。",
        "动机": "克服现有方法在多模态学习中的局限性，提出一种能够同时保持语义连贯性和学习联合数据分布能力的广义ELBO公式。",
        "方法": "提出了一种新的广义ELBO公式，该公式能够包含并超越两种现有方法，实现无妥协的多模态学习。",
        "关键词": [
            "多模态学习",
            "自监督学习",
            "生成模型",
            "ELBO",
            "语义连贯性"
        ],
        "涉及的技术概念": {
            "ELBO": "证据下界，用于近似难以直接计算的模型证据，是变分推断中的核心概念。",
            "多模态学习": "处理和学习来自不同数据源（如文本、图像、声音）的信息，以实现更全面的理解和生成。",
            "自监督学习": "一种无需人工标注数据的学习方法，通过数据本身的结构或关系来生成监督信号。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 298,
        "title": "Generalized Variational Continual Learning",
        "html": "https://iclr.cc//virtual/2021/poster/3146",
        "abstract": "Continual learning deals with training models on new tasks and datasets in an online fashion. One strand of research has used probabilistic regularization for continual learning, with two of the main approaches in this vein being Online Elastic Weight Consolidation (Online EWC) and Variational Continual Learning (VCL). VCL employs variational inference, which in other settings has been improved empirically by applying likelihood-tempering. We show that applying this modification to VCL recovers Online EWC as a limiting case, allowing for interpolation between the two approaches. We term the general algorithm Generalized VCL (GVCL). In order to mitigate the observed overpruning effect of VI, we take inspiration from a common multi-task architecture, neural networks with task-specific FiLM layers, and find that this addition leads to significant performance gains, specifically for variational methods. In the small-data regime, GVCL strongly outperforms existing baselines. In larger datasets, GVCL with FiLM layers outperforms or is competitive with existing baselines in terms of accuracy, whilst also providing significantly better calibration.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "广义变分持续学习",
        "摘要翻译": "持续学习涉及以在线方式在新任务和数据集上训练模型。一种研究方向使用概率正则化进行持续学习，其中两种主要方法是在线弹性权重巩固（Online EWC）和变分持续学习（VCL）。VCL采用变分推断，在其他设置中，通过应用似然温度调节已实证改进。我们展示，将这一修改应用于VCL可以恢复Online EWC作为一个极限情况，允许在两种方法之间进行插值。我们将这一通用算法称为广义VCL（GVCL）。为了减轻观察到的变分推断过度剪枝效应，我们从一个常见的多任务架构中获得灵感，即具有任务特定FiLM层的神经网络，并发现这一添加导致显著的性能提升，特别是对于变分方法。在小数据体制下，GVCL显著优于现有基线。在更大的数据集中，带有FiLM层的GVCL在准确性方面优于或与现有基线竞争，同时还提供了显著更好的校准。",
        "领域": "持续学习",
        "问题": "解决持续学习中的模型训练问题，特别是在新任务和数据集上的在线学习",
        "动机": "改进持续学习方法，特别是在小数据和大数据集上的性能和校准",
        "方法": "应用似然温度调节改进VCL，引入广义VCL（GVCL）算法，并使用任务特定FiLM层减轻变分推断的过度剪枝效应",
        "关键词": [
            "持续学习",
            "变分推断",
            "FiLM层",
            "概率正则化",
            "模型校准"
        ],
        "涉及的技术概念": {
            "变分推断": "用于持续学习中的概率模型推断，通过似然温度调节改进",
            "FiLM层": "任务特定的神经网络层，用于提升变分方法的性能",
            "概率正则化": "在持续学习中用于防止模型遗忘先前学习任务的技术"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 299,
        "title": "Generating Adversarial Computer Programs using Optimized Obfuscations",
        "html": "https://iclr.cc//virtual/2021/poster/3346",
        "abstract": "Machine learning (ML) models that learn and predict properties of computer programs are increasingly being adopted and deployed. \nThese models have demonstrated success in applications such as auto-completing code, summarizing large programs, and detecting bugs and malware in programs. \nIn this work, we investigate principled ways to adversarially perturb a computer program to fool such learned models, and thus determine their adversarial robustness. We use program obfuscations, which have conventionally been used to avoid attempts at reverse engineering programs, as adversarial perturbations. These perturbations modify programs in ways that do not alter their functionality but can be crafted to deceive an ML model when making a decision. We provide a general formulation for an adversarial program that allows applying multiple obfuscation transformations to a program in any language. We develop first-order optimization algorithms to  efficiently determine two key aspects -- which parts of the program to transform, and what transformations to use. We show that it is important to optimize both these aspects to generate the best adversarially perturbed program. Due to the discrete nature of this problem, we also propose using randomized smoothing to improve the attack loss landscape to ease optimization. \nWe evaluate our work on Python and Java programs on the problem of program summarization. \nWe show that our best attack proposal achieves a $52\\%$ improvement over a state-of-the-art attack generation approach for programs trained on a \\textsc{seq2seq} model.\nWe further show that our formulation is better at training models that are robust to adversarial attacks.",
        "conference": "ICLR",
        "中文标题": "使用优化混淆生成对抗性计算机程序",
        "摘要翻译": "学习和预测计算机程序属性的机器学习（ML）模型正越来越多地被采用和部署。这些模型在自动完成代码、总结大型程序以及检测程序中的错误和恶意软件等应用中已显示出成功。在这项工作中，我们研究了原则性的方法来对抗性地扰动计算机程序以欺骗这些学习模型，从而确定它们的对抗鲁棒性。我们使用程序混淆作为对抗性扰动，这些扰动传统上用于避免对程序进行逆向工程的尝试。这些扰动以不改变程序功能但可以精心设计以欺骗ML模型做出决策的方式修改程序。我们为对抗性程序提供了一个通用公式，允许对任何语言的程序应用多种混淆转换。我们开发了一阶优化算法，以有效确定两个关键方面——程序的哪些部分需要转换，以及使用什么转换。我们表明，优化这两个方面以生成最佳对抗性扰动程序非常重要。由于这个问题的离散性质，我们还提出了使用随机平滑来改善攻击损失景观以简化优化。我们在Python和Java程序上评估了我们的工作，针对程序摘要的问题。我们表明，我们的最佳攻击提案在针对训练于\textsc{seq2seq}模型的程序上，比最先进的攻击生成方法提高了52%。我们进一步表明，我们的公式在训练对抗攻击鲁棒的模型方面表现更好。",
        "领域": "程序分析、对抗性机器学习、代码生成",
        "问题": "如何生成对抗性计算机程序以测试和提升机器学习模型的鲁棒性",
        "动机": "研究如何通过对抗性扰动来评估和改进机器学习模型在程序分析和代码生成任务中的鲁棒性",
        "方法": "使用程序混淆作为对抗性扰动，开发一阶优化算法确定程序的转换部分和转换方式，并应用随机平滑优化攻击损失景观",
        "关键词": [
            "对抗性程序",
            "程序混淆",
            "优化算法",
            "随机平滑",
            "程序摘要"
        ],
        "涉及的技术概念": {
            "程序混淆": "用于生成对抗性扰动，修改程序以欺骗机器学习模型而不改变其功能",
            "一阶优化算法": "用于有效确定程序的哪些部分需要转换以及使用什么转换",
            "随机平滑": "用于改善攻击损失景观，简化优化过程"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 300,
        "title": "Generating Furry Cars: Disentangling Object Shape and Appearance across Multiple Domains",
        "html": "https://iclr.cc//virtual/2021/poster/3300",
        "abstract": "We consider the novel task of learning disentangled representations of object shape and appearance across multiple domains (e.g., dogs and cars).  The goal is to learn a generative model that learns an intermediate distribution, which borrows a subset of properties from each domain, enabling the generation of images that did not exist in any domain exclusively.  This challenging problem requires an accurate disentanglement of object shape, appearance, and background from each domain, so that the appearance and shape factors from the two domains can be interchanged. We augment an existing approach that can disentangle factors within a single domain but struggles to do so across domains.  Our key technical contribution is to represent object appearance with a differentiable histogram of visual features, and to optimize the generator so that two images with the same latent appearance factor but different latent shape factors produce similar histograms. On multiple multi-domain datasets, we demonstrate our method leads to accurate and consistent appearance and shape transfer across domains.",
        "conference": "ICLR",
        "中文标题": "生成毛茸茸的汽车：跨多个领域的对象形状与外观解耦",
        "摘要翻译": "我们考虑了一项新颖的任务：跨多个领域（如狗和汽车）学习对象形状和外观的解耦表示。目标是学习一个生成模型，该模型学习一个中间分布，该分布从每个领域借用一部分属性，从而能够生成在任何领域都不存在的图像。这一挑战性问题需要准确地将对象形状、外观和背景从每个领域中解耦，以便两个领域的外观和形状因素可以互换。我们对现有方法进行了增强，该方法可以在单个领域内解耦因素，但在跨领域时表现不佳。我们的关键技术贡献是使用视觉特征的可微分直方图表示对象外观，并优化生成器，使得具有相同潜在外观因素但不同潜在形状因素的两个图像产生相似的直方图。在多个多领域数据集上，我们证明了我们的方法能够实现跨领域的准确且一致的外观和形状转换。",
        "领域": "生成对抗网络、图像生成、跨域学习",
        "问题": "如何在跨多个领域的图像生成任务中，准确解耦对象形状和外观，以实现不同领域间形状和外观的自由组合。",
        "动机": "探索跨领域图像生成中对象形状和外观的解耦表示，以生成在单一领域中不存在的图像，扩展生成模型的创造性和应用范围。",
        "方法": "通过使用视觉特征的可微分直方图表示对象外观，并优化生成器以确保相同外观不同形状的图像产生相似的外观直方图，实现跨领域的形状和外观准确转换。",
        "关键词": [
            "解耦表示",
            "跨域生成",
            "可微分直方图",
            "形状转换",
            "外观转换"
        ],
        "涉及的技术概念": {
            "解耦表示": "将对象的形状和外观因素从图像中分离出来，使得这些因素可以独立控制和组合。",
            "可微分直方图": "用于表示对象外观的技术，通过直方图的形式捕捉视觉特征的分布，支持梯度下降优化。",
            "跨域学习": "在不同领域（如狗和汽车）之间学习和转换知识，以实现领域间的形状和外观因素的互换。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 301,
        "title": "Generative Language-Grounded Policy in Vision-and-Language Navigation with Bayes' Rule",
        "html": "https://iclr.cc//virtual/2021/poster/2660",
        "abstract": "Vision-and-language navigation (VLN) is a task in which an agent is embodied in a realistic 3D environment and follows an instruction to reach the goal node. While most of the previous studies have built and investigated a discriminative approach, we notice that there are in fact two possible approaches to building such a VLN agent: discriminative and generative. In this paper, we design and investigate a generative language-grounded policy which uses a language model to compute the distribution over all possible instructions i.e. all possible sequences of vocabulary tokens given action and the transition history. In experiments, we show that the proposed generative approach outperforms the discriminative approach in the Room-2-Room (R2R) and Room-4-Room (R4R) datasets, especially in the unseen environments. We further show that the combination of the generative and discriminative policies achieves close to the state-of-the art results in the R2R dataset, demonstrating that the generative and discriminative policies capture the different aspects of VLN.",
        "conference": "ICLR",
        "中文标题": "基于贝叶斯规则的视觉与语言导航中生成式语言基础策略",
        "摘要翻译": "视觉与语言导航（VLN）是一项任务，其中代理被置于一个逼真的3D环境中，并遵循指令到达目标节点。虽然之前的大多数研究都建立并研究了一种判别式方法，但我们注意到实际上有两种可能的方法来构建这样的VLN代理：判别式和生成式。在本文中，我们设计并研究了一种生成式语言基础策略，该策略使用语言模型来计算所有可能指令的分布，即给定动作和转移历史的所有可能的词汇标记序列。在实验中，我们表明所提出的生成式方法在Room-2-Room（R2R）和Room-4-Room（R4R）数据集中优于判别式方法，特别是在未见过的环境中。我们进一步表明，生成式和判别式策略的组合在R2R数据集中实现了接近最先进的结果，证明生成式和判别式策略捕捉了VLN的不同方面。",
        "领域": "视觉与语言导航、生成式模型、3D环境理解",
        "问题": "如何在视觉与语言导航任务中更有效地结合生成式和判别式方法以提高导航性能，特别是在未见过的环境中。",
        "动机": "探索和比较生成式与判别式方法在视觉与语言导航任务中的表现，以及它们如何互补以提高导航的准确性和适应性。",
        "方法": "设计了一种生成式语言基础策略，利用语言模型计算所有可能指令的分布，并结合判别式策略以优化导航性能。",
        "关键词": [
            "视觉与语言导航",
            "生成式模型",
            "判别式模型",
            "贝叶斯规则",
            "3D环境导航"
        ],
        "涉及的技术概念": {
            "生成式语言基础策略": "使用语言模型计算所有可能指令的分布，以生成导航策略。",
            "判别式方法": "传统的基于分类的方法，直接预测最佳动作。",
            "贝叶斯规则": "在生成式策略中用于更新指令分布的概率规则，以反映最新的动作和状态信息。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 302,
        "title": "Generative Scene Graph Networks",
        "html": "https://iclr.cc//virtual/2021/poster/3373",
        "abstract": "Human perception excels at building compositional hierarchies of parts and objects from unlabeled scenes that help systematic generalization. Yet most work on generative scene modeling either ignores the part-whole relationship or assumes access to predefined part labels. In this paper, we propose Generative Scene Graph Networks (GSGNs), the first deep generative model that learns to discover the primitive parts and infer the part-whole relationship jointly from multi-object scenes without supervision and in an end-to-end trainable way. We formulate GSGN as a variational autoencoder in which the latent representation is a tree-structured probabilistic scene graph. The leaf nodes in the latent tree correspond to primitive parts, and the edges represent the symbolic pose variables required for recursively composing the parts into whole objects and then the full scene. This allows novel objects and scenes to be generated both by sampling from the prior and by manual configuration of the pose variables, as we do with graphics engines. We evaluate GSGN on datasets of scenes containing multiple compositional objects, including a challenging Compositional CLEVR dataset that we have developed. We show that GSGN is able to infer the latent scene graph, generalize out of the training regime, and improve data efficiency in downstream tasks.",
        "conference": "ICLR",
        "中文标题": "生成式场景图网络",
        "摘要翻译": "人类感知擅长从无标签的场景中构建部分和对象的组合层次，这有助于系统性泛化。然而，大多数关于生成式场景建模的工作要么忽略了部分与整体的关系，要么假设可以访问预定义的部分标签。在本文中，我们提出了生成式场景图网络（GSGNs），这是第一个深度生成模型，能够在无监督的情况下，以端到端可训练的方式，从多对象场景中学习发现原始部分并推断部分与整体的关系。我们将GSGN表述为一个变分自编码器，其中潜在表示是一个树状结构的概率场景图。潜在树中的叶节点对应于原始部分，边代表符号姿态变量，这些变量用于递归地将部分组合成完整的对象，然后是整个场景。这使得新的对象和场景既可以通过从先验中采样生成，也可以通过手动配置姿态变量生成，就像我们使用图形引擎所做的那样。我们在包含多个组合对象的场景数据集上评估GSGN，包括我们开发的具有挑战性的组合CLEVR数据集。我们表明，GSGN能够推断潜在场景图，泛化超出训练范围，并提高下游任务的数据效率。",
        "领域": "生成模型、场景理解、无监督学习",
        "问题": "如何在无监督的情况下从多对象场景中学习发现原始部分并推断部分与整体的关系",
        "动机": "解决现有生成式场景建模工作忽略部分与整体关系或依赖预定义部分标签的问题",
        "方法": "提出生成式场景图网络（GSGNs），作为变分自编码器，其潜在表示是树状结构的概率场景图，通过递归组合部分生成对象和场景",
        "关键词": [
            "生成模型",
            "场景图",
            "无监督学习",
            "变分自编码器",
            "组合性"
        ],
        "涉及的技术概念": {
            "变分自编码器": "用于构建潜在表示的树状结构概率场景图，实现无监督学习",
            "树状结构的概率场景图": "表示场景的潜在结构，叶节点为原始部分，边为符号姿态变量",
            "符号姿态变量": "用于递归地将部分组合成完整的对象和场景，支持新场景的生成和手动配置"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 303,
        "title": "Generative Time-series Modeling with Fourier Flows",
        "html": "https://iclr.cc//virtual/2021/poster/2750",
        "abstract": "Generating synthetic time-series data is crucial in various application domains, such as medical prognosis, wherein research is hamstrung by the lack of access to data due to concerns over privacy. Most of the recently proposed methods for generating synthetic time-series rely on implicit likelihood modeling using generative adversarial networks (GANs)—but such models can be difficult to train, and may jeopardize privacy by “memorizing” temporal patterns in training data. In this paper, we propose an explicit likelihood model based on a novel class of normalizing flows that view time-series data in the frequency-domain rather than the time-domain. The proposed flow, dubbed a Fourier flow, uses a discrete Fourier transform (DFT) to convert variable-length time-series with arbitrary sampling periods into fixed-length spectral representations, then applies a (data-dependent) spectral filter to the frequency-transformed time-series. We show that, by virtue of the DFT analytic properties, the Jacobian determinants and inverse mapping for the Fourier flow can be computed efficiently in linearithmic time, without imposing explicit structural constraints as in existing flows such as NICE (Dinh et al. (2014)), RealNVP (Dinh et al. (2016)) and GLOW (Kingma & Dhariwal (2018)). Experiments show that Fourier flows perform competitively compared to state-of-the-art baselines.",
        "conference": "ICLR",
        "中文标题": "基于傅里叶流的生成性时间序列建模",
        "摘要翻译": "生成合成时间序列数据在多个应用领域至关重要，例如医疗预后研究，这些研究由于隐私问题导致数据获取受限而受到阻碍。最近提出的大多数生成合成时间序列的方法依赖于使用生成对抗网络（GANs）的隐式似然建模——但这些模型可能难以训练，并且可能通过“记忆”训练数据中的时间模式而危及隐私。在本文中，我们提出了一种基于新型归一化流类的显式似然模型，该模型在频域而非时域中查看时间序列数据。所提出的流，称为傅里叶流，使用离散傅里叶变换（DFT）将具有任意采样周期的可变长度时间序列转换为固定长度的频谱表示，然后对频率转换后的时间序列应用（数据依赖的）频谱滤波器。我们表明，凭借DFT的解析特性，傅里叶流的雅可比行列式和逆映射可以在线性对数时间内高效计算，而无需像现有的流（如NICE（Dinh等人，2014）、RealNVP（Dinh等人，2016）和GLOW（Kingma & Dhariwal，2018）那样施加显式结构约束。实验表明，傅里叶流与最先进的基线相比表现具有竞争力。",
        "领域": "时间序列生成、医疗数据分析、隐私保护数据合成",
        "问题": "解决在隐私保护前提下生成高质量合成时间序列数据的问题",
        "动机": "由于隐私问题导致的数据获取限制阻碍了医疗预后等领域的研究，需要一种既能保护隐私又能生成高质量时间序列数据的方法",
        "方法": "提出了一种基于傅里叶变换的显式似然模型，通过将时间序列转换到频域并应用频谱滤波器来生成数据",
        "关键词": [
            "傅里叶流",
            "时间序列生成",
            "隐私保护",
            "频域分析",
            "显式似然模型"
        ],
        "涉及的技术概念": {
            "傅里叶流": "一种新型归一化流，通过在频域处理时间序列数据来高效生成合成数据",
            "离散傅里叶变换（DFT）": "用于将时间序列数据从时域转换到频域，便于后续处理和分析",
            "显式似然模型": "与隐式模型（如GANs）相对，直接建模数据的概率分布，便于训练和隐私保护"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 304,
        "title": "Genetic Soft Updates for Policy Evolution in Deep Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2021/poster/3046",
        "abstract": "The combination of Evolutionary Algorithms (EAs) and Deep Reinforcement Learning (DRL) has been recently proposed to merge the benefits of both solutions. Existing mixed approaches, however, have been successfully applied only to actor-critic methods and present significant overhead. We address these issues by introducing a novel mixed framework that exploits a periodical genetic evaluation to soft update the weights of a DRL agent. The resulting approach is applicable with any DRL method and, in a worst-case scenario, it does not exhibit detrimental behaviours. Experiments in robotic applications and continuous control benchmarks demonstrate the versatility of our approach that significantly outperforms prior DRL, EAs, and mixed approaches. Finally, we employ formal verification to confirm the policy improvement, mitigating the inefficient exploration and hyper-parameter sensitivity of DRL.ment, mitigating the inefficient exploration and hyper-parameter sensitivity of DRL.",
        "conference": "ICLR",
        "中文标题": "深度强化学习中策略进化的遗传软更新",
        "摘要翻译": "最近提出了将进化算法（EAs）与深度强化学习（DRL）结合的方法，以融合两种解决方案的优势。然而，现有的混合方法仅成功应用于演员-评论家方法，并且存在显著的开销。我们通过引入一种新颖的混合框架来解决这些问题，该框架利用周期性遗传评估来软更新DRL代理的权重。所得方法可与任何DRL方法一起使用，并且在最坏情况下不会表现出有害行为。在机器人应用和连续控制基准测试中的实验证明了我们方法的多样性，其性能显著优于先前的DRL、EAs和混合方法。最后，我们采用形式验证来确认策略的改进，缓解了DRL的低效探索和超参数敏感性。",
        "领域": "深度强化学习、进化算法、机器人控制",
        "问题": "解决现有混合进化算法与深度强化学习方法仅适用于特定方法且存在显著开销的问题",
        "动机": "融合进化算法与深度强化学习的优势，提高方法的适用性和效率",
        "方法": "引入周期性遗传评估来软更新DRL代理权重的混合框架",
        "关键词": [
            "遗传软更新",
            "策略进化",
            "深度强化学习",
            "进化算法",
            "机器人控制"
        ],
        "涉及的技术概念": {
            "遗传软更新": "通过周期性遗传评估来调整DRL代理的权重，以优化策略",
            "策略进化": "在深度强化学习中通过进化算法优化策略，以提高学习效率和性能",
            "形式验证": "用于确认策略改进的技术，确保方法的有效性和可靠性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 305,
        "title": "Geometry-Aware Gradient Algorithms for Neural Architecture Search",
        "html": "https://iclr.cc//virtual/2021/poster/2618",
        "abstract": "Recent state-of-the-art methods for neural architecture search (NAS) exploit gradient-based optimization by relaxing the problem into continuous optimization over architectures and shared-weights, a noisy process that remains poorly understood. We argue for the study of single-level empirical risk minimization to understand NAS with weight-sharing, reducing the design of NAS methods to devising optimizers and regularizers that can quickly obtain high-quality solutions to this problem. Invoking the theory of mirror descent, we present a geometry-aware framework that exploits the underlying structure of this optimization to return sparse architectural parameters, leading to simple yet novel algorithms that enjoy fast convergence guarantees and achieve state-of-the-art accuracy on the latest NAS benchmarks in computer vision. Notably, we exceed the best published results for both CIFAR and ImageNet on both the DARTS search space and NAS-Bench-201; on the latter we achieve near-oracle-optimal performance on CIFAR-10 and CIFAR-100. Together, our theory and experiments demonstrate a principled way to co-design optimizers and continuous relaxations of discrete NAS search spaces.",
        "conference": "ICLR",
        "中文标题": "几何感知的梯度算法用于神经架构搜索",
        "摘要翻译": "最近，神经架构搜索（NAS）的最先进方法通过将问题放松为对架构和共享权重的连续优化，利用基于梯度的优化，这一噪声过程仍然知之甚少。我们主张研究单级经验风险最小化以理解带权重共享的NAS，将NAS方法的设计简化为设计能够快速获得这一问题高质量解决方案的优化器和正则化器。借鉴镜像下降理论，我们提出了一个几何感知框架，该框架利用这一优化的底层结构返回稀疏的架构参数，从而产生简单而新颖的算法，这些算法享有快速收敛保证，并在最新的计算机视觉NAS基准上达到了最先进的准确度。值得注意的是，我们在DARTS搜索空间和NAS-Bench-201上均超过了CIFAR和ImageNet上发布的最佳结果；在后者上，我们在CIFAR-10和CIFAR-100上实现了接近预言机最优的性能。我们的理论和实验共同展示了一种原则性的方法，共同设计优化器和离散NAS搜索空间的连续松弛。",
        "领域": "神经架构搜索、计算机视觉、深度学习优化",
        "问题": "如何有效地进行神经架构搜索，以快速获得高质量的架构解决方案",
        "动机": "理解带权重共享的NAS，并设计能够快速获得高质量解决方案的优化器和正则化器",
        "方法": "利用镜像下降理论，提出几何感知框架，设计简单而新颖的算法，实现快速收敛和高准确度",
        "关键词": [
            "神经架构搜索",
            "几何感知",
            "镜像下降",
            "连续优化",
            "权重共享"
        ],
        "涉及的技术概念": {
            "神经架构搜索（NAS）": "一种自动化设计神经网络架构的技术，旨在减少人工设计的工作量",
            "镜像下降": "一种优化算法，用于在特定几何结构下进行梯度下降，以提高优化效率",
            "权重共享": "在神经架构搜索中，不同架构共享相同的权重，以减少计算资源的需求"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 306,
        "title": "Geometry-aware Instance-reweighted Adversarial Training",
        "html": "https://iclr.cc//virtual/2021/poster/2758",
        "abstract": "In adversarial machine learning, there was a common belief that robustness and accuracy hurt each other. The belief was challenged by recent studies where we can maintain the robustness and improve the accuracy. However, the other direction, whether we can keep the accuracy and improve the robustness, is conceptually and practically more interesting, since robust accuracy should be lower than standard accuracy for any model. In this paper, we show this direction is also promising. Firstly, we find even over-parameterized deep networks may still have insufficient model capacity, because adversarial training has an overwhelming smoothing effect. Secondly, given limited model capacity, we argue adversarial data should have unequal importance: geometrically speaking, a natural data point closer to/farther from the class boundary is less/more robust, and the corresponding adversarial data point should be assigned with larger/smaller weight. Finally, to implement the idea, we propose geometry-aware instance-reweighted adversarial training, where the weights are based on how difficult it is to attack a natural data point. Experiments show that our proposal boosts the robustness of standard adversarial training; combining two directions, we improve both robustness and accuracy of standard adversarial training.",
        "conference": "ICLR",
        "中文标题": "几何感知的实例重加权对抗训练",
        "摘要翻译": "在对抗性机器学习中，曾有一种普遍观点认为鲁棒性和准确性相互损害。这一观点被最近的研究所挑战，这些研究表明我们可以在保持鲁棒性的同时提高准确性。然而，另一个方向，即我们是否可以在保持准确性的同时提高鲁棒性，在概念上和实际上都更为有趣，因为对于任何模型来说，鲁棒性准确性都应低于标准准确性。在本文中，我们展示了这一方向也很有前景。首先，我们发现即使是过度参数化的深度网络可能仍然模型容量不足，因为对抗训练具有压倒性的平滑效应。其次，考虑到有限的模型容量，我们认为对抗性数据应具有不等的重要性：从几何上讲，一个自然数据点越接近/远离类别边界，其鲁棒性越低/越高，相应的对抗性数据点应被赋予更大/更小的权重。最后，为了实现这一想法，我们提出了几何感知的实例重加权对抗训练，其中权重基于攻击一个自然数据点的难度。实验表明，我们的提议提升了标准对抗训练的鲁棒性；结合两个方向，我们同时提高了标准对抗训练的鲁棒性和准确性。",
        "领域": "对抗性机器学习、深度学习鲁棒性、图像分类",
        "问题": "如何在保持模型准确性的同时提高其对抗攻击的鲁棒性",
        "动机": "探索在保持模型准确性的同时提高对抗攻击鲁棒性的可能性，因为传统观点认为这两者是相互矛盾的",
        "方法": "提出几何感知的实例重加权对抗训练方法，根据自然数据点被攻击的难度动态调整对抗性数据的权重",
        "关键词": [
            "对抗训练",
            "模型鲁棒性",
            "实例重加权",
            "几何感知",
            "深度学习"
        ],
        "涉及的技术概念": {
            "对抗训练": "一种通过引入对抗性样本来增强模型鲁棒性的训练方法",
            "实例重加权": "根据数据点的重要性动态调整其在训练过程中的权重，以优化模型性能",
            "几何感知": "利用数据点在特征空间中的几何位置信息来指导模型训练，特别是在对抗训练中调整对抗性数据的重要性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 307,
        "title": "Getting a CLUE: A  Method for Explaining Uncertainty Estimates",
        "html": "https://iclr.cc//virtual/2021/poster/2741",
        "abstract": "Both uncertainty estimation and interpretability are important factors for trustworthy machine learning systems. However, there is little work at the intersection of these two areas. We address this gap by proposing a novel method for interpreting uncertainty estimates from differentiable probabilistic models, like Bayesian Neural Networks (BNNs). Our method, Counterfactual Latent Uncertainty Explanations (CLUE), indicates how to change an input, while keeping it on the data manifold, such that a BNN becomes more confident about the input's prediction. We validate CLUE through 1) a novel framework for evaluating counterfactual explanations of uncertainty, 2) a series of ablation experiments, and 3) a user study. Our experiments show that CLUE outperforms baselines and enables practitioners to better understand which input patterns are responsible for predictive uncertainty.",
        "conference": "ICLR",
        "中文标题": "获取线索：一种解释不确定性估计的方法",
        "摘要翻译": "不确定性估计和可解释性都是构建可信赖机器学习系统的重要因素。然而，在这两个领域的交叉点上，研究工作却相对较少。我们通过提出一种新颖的方法来填补这一空白，该方法用于解释来自可微分概率模型（如贝叶斯神经网络BNNs）的不确定性估计。我们的方法，称为反事实潜在不确定性解释（CLUE），指出了如何改变输入，同时保持其在数据流形上，使得BNN对其预测更加自信。我们通过1）一个评估不确定性反事实解释的新框架，2）一系列消融实验，以及3）一项用户研究来验证CLUE。我们的实验表明，CLUE优于基线方法，并使从业者能够更好地理解哪些输入模式对预测不确定性负责。",
        "领域": "贝叶斯深度学习、不确定性估计、模型可解释性",
        "问题": "如何解释可微分概率模型（如贝叶斯神经网络）产生的不确定性估计",
        "动机": "填补不确定性估计和模型可解释性交叉领域的研究空白，提高机器学习系统的可信赖性",
        "方法": "提出反事实潜在不确定性解释（CLUE）方法，通过改变输入同时保持其在数据流形上，来增加模型对预测的置信度",
        "关键词": [
            "不确定性估计",
            "模型可解释性",
            "贝叶斯神经网络",
            "反事实解释",
            "数据流形"
        ],
        "涉及的技术概念": {
            "贝叶斯神经网络": "一种概率深度学习模型，能够提供预测的不确定性估计",
            "反事实潜在不确定性解释（CLUE）": "一种解释不确定性估计的方法，通过生成反事实样本来揭示影响模型不确定性的输入特征",
            "数据流形": "在机器学习中，指数据点在高维空间中的分布结构，保持输入在数据流形上是生成有意义反事实样本的关键"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 308,
        "title": "Global Convergence of Three-layer Neural Networks in the Mean Field Regime",
        "html": "https://iclr.cc//virtual/2021/poster/2699",
        "abstract": "In the mean field regime, neural networks are appropriately scaled so that as the width tends to infinity, the learning dynamics tends to a nonlinear and nontrivial dynamical limit, known as the mean field limit. This lends a way to study large-width neural networks via analyzing the mean field limit. Recent works have successfully applied such analysis to two-layer networks and provided global convergence guarantees. The extension to multilayer ones however has been a highly challenging puzzle, and little is known about the optimization efficiency in the mean field regime when there are more than two layers.\n\nIn this work, we prove a global convergence result for unregularized feedforward three-layer networks in the mean field regime. We first develop a rigorous framework to establish the mean field limit of three-layer networks under stochastic gradient descent training. To that end, we propose the idea of a neuronal embedding, which comprises of a fixed probability space that encapsulates neural networks of arbitrary sizes. The identified mean field limit is then used to prove a global convergence guarantee under suitable regularity and convergence mode assumptions, which – unlike previous works on two-layer networks – does not rely critically on convexity. Underlying the result is a universal approximation property, natural of neural networks, which importantly is shown to hold at any finite training time (not necessarily at convergence) via an algebraic topology argument.",
        "conference": "ICLR",
        "中文标题": "平均场机制下三层神经网络全局收敛性研究",
        "摘要翻译": "在平均场机制下，神经网络被适当缩放，使得当宽度趋向于无穷大时，学习动态趋向于一个非线性且非平凡的动态极限，称为平均场极限。这为通过分析平均场极限来研究大宽度神经网络提供了一种方法。最近的研究已成功将这种分析应用于两层网络，并提供了全局收敛保证。然而，将其扩展到多层网络一直是一个极具挑战性的难题，对于超过两层的网络在平均场机制下的优化效率知之甚少。在这项工作中，我们证明了在平均场机制下未经正则化的前馈三层网络的全局收敛结果。我们首先开发了一个严格的框架，以建立随机梯度下降训练下三层网络的平均场极限。为此，我们提出了神经元嵌入的概念，它包括一个固定的概率空间，该空间封装了任意大小的神经网络。然后，所识别的平均场极限被用来证明在适当的正则性和收敛模式假设下的全局收敛保证，这与之前关于两层网络的研究不同，不严格依赖于凸性。结果的基础是神经网络的通用逼近性质，重要的是，通过代数拓扑论证，这一性质在任何有限的训练时间（不一定在收敛时）都被证明成立。",
        "领域": "深度学习理论、神经网络优化、平均场理论",
        "问题": "研究在平均场机制下，三层神经网络的全局收敛性问题",
        "动机": "扩展对多层神经网络在平均场机制下优化效率的理解，特别是针对超过两层的网络",
        "方法": "开发了一个严格的框架来建立三层网络的平均场极限，并利用神经元嵌入的概念证明全局收敛性",
        "关键词": [
            "平均场极限",
            "全局收敛",
            "三层神经网络",
            "神经元嵌入",
            "代数拓扑"
        ],
        "涉及的技术概念": {
            "平均场极限": "在神经网络宽度趋向于无穷大时，学习动态趋向的非线性且非平凡的动态极限，用于研究大宽度神经网络",
            "神经元嵌入": "一个固定的概率空间，封装了任意大小的神经网络，用于建立三层网络的平均场极限",
            "代数拓扑论证": "用于证明神经网络在任何有限训练时间下的通用逼近性质，不依赖于收敛时的条件"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 309,
        "title": "Global optimality of softmax policy gradient with single hidden layer neural networks in the mean-field regime",
        "html": "https://iclr.cc//virtual/2021/poster/3208",
        "abstract": "We study the problem of policy optimization for infinite-horizon discounted Markov Decision Processes with softmax policy and nonlinear function approximation trained with policy gradient algorithms. We concentrate on the training dynamics in the mean-field regime, modeling e.g. the behavior of wide single hidden layer neural networks, when exploration is encouraged through entropy regularization. The dynamics of these models is established as a Wasserstein gradient flow of distributions in parameter space.  We further prove global optimality of the fixed points of this dynamics  under mild conditions on their initialization.",
        "conference": "ICLR",
        "中文标题": "在均值场机制下单隐藏层神经网络的Softmax策略梯度的全局最优性",
        "摘要翻译": "我们研究了使用Softmax策略和非线性函数逼近训练的无限时间折扣马尔可夫决策过程的策略优化问题，该策略通过策略梯度算法进行训练。我们专注于均值场机制下的训练动态，例如宽单隐藏层神经网络的行为，当通过熵正则化鼓励探索时。这些模型的动态被建立为参数空间中分布的Wasserstein梯度流。我们进一步证明了在这些模型的初始化条件下，该动态的固定点的全局最优性。",
        "领域": "强化学习、策略优化、神经网络",
        "问题": "研究在均值场机制下，使用Softmax策略和非线性函数逼近训练的无限时间折扣马尔可夫决策过程的策略优化问题",
        "动机": "探索在熵正则化鼓励探索的条件下，宽单隐藏层神经网络在策略优化中的行为及其动态",
        "方法": "将模型的动态建立为参数空间中分布的Wasserstein梯度流，并证明在特定初始化条件下动态固定点的全局最优性",
        "关键词": [
            "策略梯度",
            "均值场机制",
            "Softmax策略",
            "Wasserstein梯度流",
            "全局最优性"
        ],
        "涉及的技术概念": {
            "Softmax策略": "在策略优化中使用的一种策略，用于在多个动作中选择一个动作的概率分布",
            "Wasserstein梯度流": "用于描述参数空间中分布动态变化的数学工具，有助于理解模型训练过程中的行为",
            "熵正则化": "一种鼓励探索的技术，通过增加策略的熵来防止过早收敛到局部最优解"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 310,
        "title": "Go with the flow: Adaptive control for Neural ODEs",
        "html": "https://iclr.cc//virtual/2021/poster/3217",
        "abstract": "Despite their elegant formulation and lightweight memory cost, neural ordinary differential equations (NODEs) suffer from known representational limitations. In particular, the single flow learned by NODEs cannot express all homeomorphisms from a given data space to itself, and their static weight parameterization restricts the type of functions they can learn compared to discrete architectures with layer-dependent weights. Here, we describe a new module called neurally-controlled ODE (N-CODE) designed to improve the expressivity of NODEs. The parameters of N-CODE modules are dynamic variables governed by a trainable map from initial or current activation state, resulting in forms of open-loop and closed-loop control, respectively. A single module is sufficient for learning a distribution on non-autonomous flows that adaptively drive neural representations. We provide theoretical and empirical evidence that N-CODE circumvents limitations of previous NODEs models and show how increased model expressivity manifests in several supervised and unsupervised learning problems. These favorable empirical results indicate the potential of using data- and activity-dependent plasticity in neural networks across numerous domains.",
        "conference": "ICLR",
        "中文标题": "顺势而为：神经常微分方程的自适应控制",
        "摘要翻译": "尽管神经常微分方程（NODEs）具有优雅的表述和轻量级的内存成本，但它们存在已知的表征限制。特别是，NODEs学习的单一流无法表达从给定数据空间到自身的所有同胚映射，并且与具有层依赖权重的离散架构相比，它们的静态权重参数化限制了它们可以学习的函数类型。在这里，我们描述了一个名为神经控制ODE（N-CODE）的新模块，旨在提高NODEs的表达能力。N-CODE模块的参数是由从初始或当前激活状态的可训练映射控制的动态变量，分别导致开环和闭环控制的形式。单个模块足以学习自适应驱动神经表示的非自主流的分布。我们提供了理论和实证证据，表明N-CODE规避了先前NODEs模型的限制，并展示了模型表达能力的增强如何在几个监督和非监督学习问题中体现。这些有利的实证结果表明，在众多领域中利用数据和活动依赖的可塑性在神经网络中具有潜力。",
        "领域": "深度学习、自适应控制、神经网络优化",
        "问题": "神经常微分方程（NODEs）的表达能力和灵活性不足，无法适应复杂的数据映射需求。",
        "动机": "提高神经常微分方程的表达能力，使其能够学习更广泛的函数类型，适应更复杂的数据处理任务。",
        "方法": "引入神经控制ODE（N-CODE）模块，通过动态变量和可训练映射实现开环和闭环控制，增强模型的表达能力。",
        "关键词": [
            "神经常微分方程",
            "自适应控制",
            "模型表达能力",
            "动态变量",
            "非自主流"
        ],
        "涉及的技术概念": {
            "神经控制ODE（N-CODE）": "一种新模块，通过动态变量和可训练映射提高神经常微分方程的表达能力。",
            "开环和闭环控制": "N-CODE模块实现的两种控制形式，分别基于初始或当前激活状态，用于动态调整模型参数。",
            "非自主流": "N-CODE模块学习的一种流类型，能够自适应地驱动神经表示，提高模型对复杂数据的处理能力。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 311,
        "title": "Gradient Descent on Neural Networks Typically Occurs at the Edge of Stability",
        "html": "https://iclr.cc//virtual/2021/poster/2577",
        "abstract": "We empirically demonstrate that full-batch gradient descent on neural network training objectives typically operates in a regime we call the Edge of Stability. In this regime, the maximum eigenvalue of the training loss Hessian hovers just above the value $2 / \\text{(step size)}$, and the training loss behaves non-monotonically over short timescales, yet consistently decreases over long timescales. Since this behavior is inconsistent with several widespread presumptions in the field of optimization, our findings raise questions as to whether these presumptions are relevant to neural network training. We hope that our findings will inspire future efforts aimed at rigorously understanding optimization at the Edge of Stability.",
        "conference": "ICLR",
        "中文标题": "神经网络梯度下降通常发生在稳定性的边缘",
        "摘要翻译": "我们通过实证表明，在神经网络训练目标上使用全批量梯度下降通常运行在我们称之为‘稳定性边缘’的区域内。在这一区域内，训练损失Hessian矩阵的最大特征值略高于$2 / \text{步长}$的值，并且训练损失在短时间内表现出非单调性，但在长时间尺度上持续下降。由于这种行为与优化领域中几个广泛假设不一致，我们的发现对这些假设是否与神经网络训练相关提出了疑问。我们希望我们的发现能够激发未来旨在严格理解‘稳定性边缘’优化的努力。",
        "领域": "深度学习优化、神经网络训练、梯度下降算法",
        "问题": "理解神经网络训练中梯度下降算法的行为特性",
        "动机": "探索神经网络训练过程中梯度下降算法的实际行为与现有优化理论假设之间的不一致性",
        "方法": "通过实证研究分析全批量梯度下降在神经网络训练目标上的行为，特别是在‘稳定性边缘’区域内的表现",
        "关键词": [
            "梯度下降",
            "稳定性边缘",
            "神经网络训练",
            "Hessian矩阵",
            "优化理论"
        ],
        "涉及的技术概念": {
            "稳定性边缘": "指在神经网络训练过程中，梯度下降算法运行的一个特定区域，其中Hessian矩阵的最大特征值略高于2/步长，导致训练损失表现出特定的非单调但长期下降的行为",
            "Hessian矩阵": "在优化问题中，Hessian矩阵是目标函数的二阶导数矩阵，用于描述损失函数在特定点的曲率，对理解优化算法的行为至关重要",
            "全批量梯度下降": "一种优化算法，它在每次迭代中使用整个训练数据集来计算梯度，与随机梯度下降相比，能提供更准确的梯度估计但计算成本更高"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 312,
        "title": "Gradient Origin Networks",
        "html": "https://iclr.cc//virtual/2021/poster/3137",
        "abstract": "This paper proposes a new type of generative model that is able to quickly learn a latent representation without an encoder. This is achieved using empirical Bayes to calculate the expectation of the posterior, which is implemented by initialising a latent vector with zeros, then using the gradient of the log-likelihood of the data with respect to this zero vector as new latent points. The approach has similar characteristics to autoencoders, but with a simpler architecture, and is demonstrated in a variational autoencoder equivalent that permits sampling. This also allows implicit representation networks to learn a space of implicit functions without requiring a hypernetwork, retaining their representation advantages across datasets. The experiments show that the proposed method converges faster, with significantly lower reconstruction error than autoencoders, while requiring half the parameters.",
        "conference": "ICLR",
        "中文标题": "梯度起源网络",
        "摘要翻译": "本文提出了一种新型的生成模型，该模型能够无需编码器快速学习潜在表示。这是通过使用经验贝叶斯计算后验期望来实现的，具体做法是将潜在向量初始化为零，然后使用数据对数似然相对于这个零向量的梯度作为新的潜在点。该方法具有与自动编码器相似的特征，但架构更为简单，并在一个允许采样的变分自动编码器等效模型中进行了演示。这也使得隐式表示网络能够在不需要超网络的情况下学习隐式函数空间，同时保留其在跨数据集中的表示优势。实验表明，所提出的方法收敛速度更快，重建误差显著低于自动编码器，同时所需参数仅为后者的一半。",
        "领域": "生成模型、变分自动编码器、隐式表示学习",
        "问题": "如何无需编码器快速学习潜在表示",
        "动机": "简化生成模型的架构，提高学习效率和降低参数需求",
        "方法": "使用经验贝叶斯计算后验期望，通过梯度更新潜在向量",
        "关键词": [
            "梯度起源网络",
            "经验贝叶斯",
            "隐式表示学习",
            "变分自动编码器",
            "参数效率"
        ],
        "涉及的技术概念": {
            "经验贝叶斯": "用于计算后验期望，实现无需编码器的潜在表示学习",
            "隐式表示学习": "允许模型学习隐式函数空间，保留跨数据集的表示优势",
            "变分自动编码器": "作为演示模型，展示了方法的有效性和参数效率"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 313,
        "title": "Gradient Projection Memory for Continual Learning",
        "html": "https://iclr.cc//virtual/2021/poster/3289",
        "abstract": "The ability to learn continually without forgetting the past tasks is a desired attribute for artificial learning systems. Existing approaches to enable such learning in artificial neural networks usually rely on network growth, importance based weight update or replay of old data from the memory. In contrast, we propose a novel approach where a neural network learns new tasks by taking gradient steps in the orthogonal direction to the gradient subspaces deemed important for the past tasks. We find the bases of these subspaces by analyzing network representations (activations) after learning each task with Singular Value Decomposition (SVD) in a single shot manner and store them in the memory as Gradient Projection Memory (GPM). With qualitative and quantitative analyses, we show that such orthogonal gradient descent induces minimum to no interference with the past tasks, thereby mitigates forgetting. We evaluate our algorithm on diverse image classification datasets with short and long sequences of tasks and report better or on-par performance compared to the state-of-the-art approaches. ",
        "conference": "ICLR",
        "中文标题": "梯度投影记忆用于持续学习",
        "摘要翻译": "在不忘记过去任务的情况下持续学习的能力是人工学习系统所期望的属性。现有方法通常依赖于网络增长、基于重要性的权重更新或从内存中重放旧数据来实现这种学习。相比之下，我们提出了一种新方法，其中神经网络通过在正交于对过去任务重要的梯度子空间的方向上采取梯度步骤来学习新任务。我们通过在学习每个任务后使用奇异值分解（SVD）以单次方式分析网络表示（激活）来找到这些子空间的基，并将它们作为梯度投影记忆（GPM）存储在内存中。通过定性和定量分析，我们表明这种正交梯度下降对过去任务的干扰最小甚至没有，从而减轻了遗忘。我们在多样化的图像分类数据集上评估了我们的算法，包括短和长的任务序列，并报告了与最先进方法相比更好或相当的性能。",
        "领域": "持续学习",
        "问题": "如何在神经网络中实现持续学习而不遗忘过去任务",
        "动机": "解决现有方法在持续学习中可能导致的遗忘问题，提出一种减少对过去任务干扰的新方法",
        "方法": "通过分析网络表示并使用奇异值分解（SVD）找到梯度子空间的基，存储在梯度投影记忆（GPM）中，采用正交梯度下降学习新任务",
        "关键词": [
            "持续学习",
            "梯度投影记忆",
            "正交梯度下降",
            "奇异值分解",
            "任务干扰"
        ],
        "涉及的技术概念": {
            "梯度投影记忆（GPM）": "用于存储对过去任务重要的梯度子空间的基，以减少学习新任务时的干扰",
            "正交梯度下降": "通过在正交于过去任务重要梯度子空间的方向上采取梯度步骤来学习新任务，以减少遗忘",
            "奇异值分解（SVD）": "用于分析网络表示（激活）以找到梯度子空间的基，支持梯度投影记忆的构建"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 314,
        "title": "Gradient Vaccine: Investigating and Improving Multi-task Optimization in Massively Multilingual Models",
        "html": "https://iclr.cc//virtual/2021/poster/2550",
        "abstract": "Massively multilingual models subsuming tens or even hundreds of languages pose great challenges to multi-task optimization. While it is a common practice to apply a language-agnostic procedure optimizing a joint multilingual task objective, how to properly characterize and take advantage of its underlying problem structure for improving optimization efficiency remains under-explored. In this paper, we attempt to peek into the black-box of multilingual optimization through the lens of loss function geometry. We find that gradient similarity measured along the optimization trajectory is an important signal, which correlates well with not only language proximity but also the overall model performance. Such observation helps us to identify a critical limitation of existing gradient-based multi-task learning methods, and thus we derive a simple and scalable optimization procedure, named Gradient Vaccine, which encourages more geometrically aligned parameter updates for close tasks. Empirically, our method obtains significant model performance gains on multilingual machine translation and XTREME benchmark tasks for multilingual language models. Our work reveals the importance of properly measuring and utilizing language proximity in multilingual optimization, and has broader implications for multi-task learning beyond multilingual modeling.",
        "conference": "ICLR",
        "中文标题": "梯度疫苗：探究并改进大规模多语言模型中的多任务优化",
        "摘要翻译": "包含数十甚至数百种语言的大规模多语言模型对多任务优化提出了巨大挑战。虽然应用一种语言无关的程序来优化联合多语言任务目标是一种常见做法，但如何正确描述并利用其底层问题结构以提高优化效率仍然未被充分探索。在本文中，我们试图通过损失函数几何的视角窥视多语言优化的黑箱。我们发现，沿着优化轨迹测量的梯度相似性是一个重要信号，它不仅与语言接近性密切相关，还与整体模型性能密切相关。这样的观察帮助我们识别了现有基于梯度的多任务学习方法的临界限制，因此我们推导出了一个简单且可扩展的优化程序，名为梯度疫苗，它鼓励对接近任务进行更多几何对齐的参数更新。经验上，我们的方法在多语言机器翻译和XTREME基准任务上为多语言语言模型获得了显著的模型性能提升。我们的工作揭示了在多语言优化中正确测量和利用语言接近性的重要性，并对超越多语言建模的多任务学习具有更广泛的意义。",
        "领域": "多语言机器翻译、多任务学习、自然语言处理与视觉结合",
        "问题": "大规模多语言模型中的多任务优化效率低下",
        "动机": "探究多语言优化中的问题结构，以提高优化效率和模型性能",
        "方法": "通过损失函数几何分析梯度相似性，提出梯度疫苗优化程序",
        "关键词": [
            "多语言优化",
            "梯度疫苗",
            "损失函数几何",
            "多任务学习",
            "语言接近性"
        ],
        "涉及的技术概念": {
            "梯度相似性": "用于衡量不同任务在优化过程中的梯度方向一致性，是优化效率的重要信号",
            "梯度疫苗": "一种优化程序，通过促进几何对齐的参数更新来提高多任务学习的效率",
            "语言接近性": "在多语言模型中，不同语言之间的相似程度，影响模型优化和性能"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 315,
        "title": "gradSim: Differentiable simulation for system identification and visuomotor control",
        "html": "https://iclr.cc//virtual/2021/poster/3082",
        "abstract": "In this paper, we tackle the problem of estimating object physical properties such as mass, friction, and elasticity directly from video sequences. Such a system identification problem is fundamentally ill-posed due to the loss of information during image formation. Current best solutions to the problem require precise 3D labels which are labor intensive to gather, and infeasible to create for many systems such as deformable solids or cloth. In this work we present gradSim, a framework that overcomes the dependence on 3D supervision by combining differentiable multiphysics simulation and differentiable rendering to jointly model the evolution of scene dynamics and image formation. This unique combination enables backpropagation from pixels in a video sequence through to the underlying physical attributes that generated them. Furthermore, our unified computation graph across dynamics and rendering engines enables the learning of challenging visuomotor control tasks, without relying on state-based (3D) supervision, while obtaining performance competitive to/better than techniques that require precise 3D labels.",
        "conference": "ICLR",
        "中文标题": "gradSim：用于系统识别和视觉运动控制的可微分模拟",
        "摘要翻译": "在本文中，我们解决了直接从视频序列中估计物体物理属性（如质量、摩擦力和弹性）的问题。由于图像形成过程中的信息丢失，这样的系统识别问题本质上是病态的。当前对该问题的最佳解决方案需要精确的3D标签，这些标签不仅收集起来劳动密集，而且对于许多系统（如可变形固体或布料）来说是不可行的。在这项工作中，我们提出了gradSim，一个通过结合可微分多物理模拟和可微分渲染来共同建模场景动力学和图像形成的框架，从而克服了对3D监督的依赖。这种独特的组合使得能够从视频序列中的像素反向传播到生成它们的底层物理属性。此外，我们在动力学和渲染引擎上的统一计算图使得能够学习具有挑战性的视觉运动控制任务，而不依赖于基于状态（3D）的监督，同时获得与需要精确3D标签的技术相竞争或更好的性能。",
        "领域": "物理属性估计、视觉运动控制、可微分模拟",
        "问题": "直接从视频序列中估计物体的物理属性（如质量、摩擦力和弹性）",
        "动机": "克服当前解决方案对精确3D标签的依赖，这些标签收集劳动密集且对许多系统不可行",
        "方法": "结合可微分多物理模拟和可微分渲染来共同建模场景动力学和图像形成，实现从像素到物理属性的反向传播",
        "关键词": [
            "可微分模拟",
            "系统识别",
            "视觉运动控制",
            "物理属性估计",
            "可微分渲染"
        ],
        "涉及的技术概念": {
            "可微分多物理模拟": "用于建模场景动力学，允许通过模拟反向传播梯度以估计物理属性",
            "可微分渲染": "用于建模图像形成过程，使得可以从像素反向传播到物理属性",
            "统一计算图": "结合动力学和渲染引擎的计算图，支持无需3D监督的视觉运动控制任务学习"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 316,
        "title": "Graph-Based Continual Learning",
        "html": "https://iclr.cc//virtual/2021/poster/2524",
        "abstract": "Despite significant advances, continual learning models still suffer from catastrophic forgetting when exposed to incrementally available data from non-stationary distributions. Rehearsal approaches alleviate the problem by maintaining and replaying a small episodic memory of previous samples, often implemented as an array of independent memory slots. In this work, we propose to augment such an array with a learnable random graph that captures pairwise similarities between its samples, and use it not only to learn new tasks but also to guard against forgetting. Empirical results on several benchmark datasets show that our model consistently outperforms recently proposed baselines for task-free continual learning.",
        "conference": "ICLR",
        "中文标题": "基于图的持续学习",
        "摘要翻译": "尽管取得了显著进展，持续学习模型在面对来自非平稳分布的增量可用数据时，仍然遭受灾难性遗忘的困扰。排练方法通过维护并重放先前样本的小型情景记忆来缓解这一问题，这些方法通常实现为一组独立的内存槽。在这项工作中，我们提出通过一个可学习的随机图来增强这样的数组，该图捕获了样本之间的成对相似性，并不仅用于学习新任务，还用于防止遗忘。在几个基准数据集上的实证结果表明，我们的模型在无任务持续学习方面一致优于最近提出的基线。",
        "领域": "持续学习",
        "问题": "解决持续学习中的灾难性遗忘问题",
        "动机": "通过引入可学习的随机图来捕获样本间的相似性，以增强持续学习模型的记忆能力，防止遗忘",
        "方法": "提出了一种基于图的持续学习方法，通过可学习的随机图捕获样本间的成对相似性，用于学习新任务和防止遗忘",
        "关键词": [
            "持续学习",
            "灾难性遗忘",
            "随机图",
            "任务无关学习",
            "记忆增强"
        ],
        "涉及的技术概念": {
            "持续学习": "一种学习范式，旨在使模型能够从连续的数据流中学习新知识，同时保留旧知识",
            "灾难性遗忘": "指在学习新任务时，模型突然且显著地忘记之前学到的知识的现象",
            "随机图": "一种图结构，其中节点之间的边以一定的概率存在，用于捕获样本间的相似性关系"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 317,
        "title": "Graph Coarsening with Neural Networks",
        "html": "https://iclr.cc//virtual/2021/poster/2646",
        "abstract": "As large scale-graphs become increasingly more prevalent, it poses significant computational challenges to process, extract and analyze large graph data. Graph coarsening is one popular technique to reduce the size of a graph while maintaining essential properties. Despite rich graph coarsening literature, there is only limited exploration of data-driven method in the field. In this work, we leverage the recent progress of deep learning on graphs for graph coarsening. We first propose a framework for measuring the quality of coarsening algorithm and show that depending on the goal, we need to carefully choose the Laplace operator on the coarse graph and associated projection/lift operators. Motivated by the observation that the current choice of edge weight for the coarse graph may be sub-optimal, we parametrize the weight assignment map with graph neural networks and train it to improve the coarsening quality in an unsupervised way. Through extensive experiments on both synthetic and real networks, we demonstrate that our method significantly improves common graph coarsening methods under various metrics, reduction ratios, graph sizes, and graph types. It generalizes to graphs of larger size (more than $25\\times$ of training graphs), adaptive to different losses (both differentiable and non-differentiable), and scales to much larger graphs than previous work.",
        "conference": "ICLR",
        "中文标题": "基于神经网络的图粗化方法",
        "摘要翻译": "随着大规模图数据的日益普遍，处理和提取大型图数据带来了重大的计算挑战。图粗化是一种流行的技术，用于在保持图的基本属性的同时减小图的规模。尽管图粗化文献丰富，但在该领域中数据驱动方法的探索仍然有限。在这项工作中，我们利用图深度学习的最新进展来进行图粗化。我们首先提出了一个衡量粗化算法质量的框架，并表明根据目标的不同，我们需要仔细选择粗化图上的拉普拉斯算子以及相关的投影/提升算子。观察到当前粗化图的边权重选择可能不是最优的，我们使用图神经网络参数化权重分配图，并以无监督的方式训练它以提高粗化质量。通过对合成和真实网络的广泛实验，我们证明了我们的方法在各种指标、缩减比例、图大小和图类型下显著改善了常见的图粗化方法。它能够泛化到更大尺寸的图（超过训练图的25倍），适应不同的损失（可微分和不可微分），并且能够扩展到比之前工作更大的图。",
        "领域": "图神经网络、图数据处理、图粗化技术",
        "问题": "如何在保持图基本属性的同时，有效地减小大规模图的规模，以解决计算挑战。",
        "动机": "当前图粗化方法中数据驱动方法的探索有限，且边权重选择可能不是最优的，因此需要开发更有效的图粗化技术。",
        "方法": "利用图深度学习的最新进展，提出一个衡量粗化算法质量的框架，并使用图神经网络参数化权重分配图，以无监督方式训练提高粗化质量。",
        "关键词": [
            "图粗化",
            "图神经网络",
            "无监督学习",
            "拉普拉斯算子",
            "权重分配"
        ],
        "涉及的技术概念": {
            "图粗化": "一种技术，用于在保持图的基本属性的同时减小图的规模，以解决大规模图数据处理的计算挑战。",
            "图神经网络": "用于参数化权重分配图的技术，通过深度学习的方法提高图粗化的质量。",
            "拉普拉斯算子": "在粗化图上选择的算子，用于保持图的结构属性，是衡量粗化算法质量的关键因素。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 318,
        "title": "GraphCodeBERT: Pre-training Code Representations with Data Flow",
        "html": "https://iclr.cc//virtual/2021/poster/2598",
        "abstract": "Pre-trained models for programming language have achieved dramatic empirical improvements on a variety of code-related tasks such as code search, code completion, code summarization, etc. However, existing pre-trained models regard a code snippet as a sequence of tokens, while ignoring the inherent structure of code, which provides crucial code semantics and would enhance the code understanding process. We present GraphCodeBERT, a pre-trained model for programming language that considers the inherent structure of code. Instead of taking syntactic-level structure of code like abstract syntax tree (AST), we use data flow in the pre-training stage, which is a semantic-level structure of code that encodes the relation of 'where-the-value-comes-from' between variables. Such a semantic-level structure is neat and does not bring an unnecessarily deep hierarchy of AST, the property of which makes the model more efficient. We develop GraphCodeBERT based on Transformer. In addition to using the task of masked language modeling, we introduce two structure-aware pre-training tasks. One is to predict code structure edges, and the other is to align representations between source code and code structure. We implement the model in an efficient way with a graph-guided masked attention function to incorporate the code structure. We evaluate our model on four tasks, including code search, clone detection, code translation, and code refinement. Results show that code structure and newly introduced pre-training tasks can improve GraphCodeBERT and achieves state-of-the-art performance on the four downstream tasks. We further show that the model prefers structure-level attentions over token-level attentions in the task of code search.",
        "conference": "ICLR",
        "中文标题": "GraphCodeBERT：利用数据流预训练代码表示",
        "摘要翻译": "编程语言的预训练模型在代码搜索、代码补全、代码摘要等多种代码相关任务上取得了显著的实证改进。然而，现有的预训练模型将代码片段视为一系列标记，而忽略了代码的固有结构，这些结构提供了关键的代码语义，并将增强代码理解过程。我们提出了GraphCodeBERT，一种考虑代码固有结构的编程语言预训练模型。与采用抽象语法树（AST）这样的语法级代码结构不同，我们在预训练阶段使用数据流，这是一种代码的语义级结构，编码了变量之间'值来自哪里'的关系。这种语义级结构简洁，不会带来AST不必要的深层层次结构，这一特性使模型更加高效。我们基于Transformer开发了GraphCodeBERT。除了使用掩码语言建模任务外，我们还引入了两个结构感知的预训练任务。一个是预测代码结构边，另一个是对齐源代码和代码结构之间的表示。我们以高效的方式实现了模型，使用图引导的掩码注意力函数来整合代码结构。我们在四个任务上评估了我们的模型，包括代码搜索、克隆检测、代码翻译和代码精炼。结果表明，代码结构和新引入的预训练任务可以改进GraphCodeBERT，并在四个下游任务上实现了最先进的性能。我们进一步表明，在代码搜索任务中，模型更倾向于结构级注意力而非标记级注意力。",
        "领域": "代码表示学习、程序理解、代码语义分析",
        "问题": "现有预训练模型忽略代码的固有结构，限制了代码理解的深度和效率。",
        "动机": "通过利用代码的语义级结构（如数据流）来增强预训练模型对代码的理解能力。",
        "方法": "基于Transformer开发GraphCodeBERT，引入数据流作为代码的语义级结构，并设计两个结构感知的预训练任务，以及使用图引导的掩码注意力函数整合代码结构。",
        "关键词": [
            "代码表示学习",
            "数据流",
            "结构感知预训练",
            "Transformer",
            "代码理解"
        ],
        "涉及的技术概念": {
            "数据流": "编码变量之间'值来自哪里'的关系，作为代码的语义级结构用于预训练。",
            "图引导的掩码注意力函数": "用于高效整合代码结构到预训练模型中，增强模型对代码结构的理解。",
            "结构感知预训练任务": "包括预测代码结构边和对齐源代码与代码结构的表示，旨在提升模型对代码结构的理解能力。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 319,
        "title": "Graph Convolution with Low-rank Learnable Local Filters",
        "html": "https://iclr.cc//virtual/2021/poster/2849",
        "abstract": "Geometric variations like rotation, scaling, and viewpoint changes pose a significant challenge to visual understanding. One common solution is to directly model certain intrinsic structures, e.g., using landmarks. However, it then becomes non-trivial to build effective deep models, especially when the underlying non-Euclidean grid is irregular and coarse. Recent deep models using graph convolutions provide an appropriate framework to handle such non-Euclidean data, but many of them, particularly those based on global graph Laplacians, lack expressiveness to capture local features required for representation of signals lying on the non-Euclidean grid. The current paper introduces a new type of graph convolution with learnable low-rank local filters, which is provably more expressive than previous spectral graph convolution methods. The model also provides a unified framework for both spectral and spatial graph convolutions. To improve model robustness, regularization by local graph Laplacians is introduced. The representation stability against input graph data perturbation is theoretically proved, making use of the graph filter locality and the local graph regularization. Experiments on spherical mesh data, real-world facial expression recognition/skeleton-based action recognition data, and data with simulated graph noise show the empirical advantage of the proposed model.",
        "conference": "ICLR",
        "中文标题": "低秩可学习局部滤波器的图卷积",
        "摘要翻译": "几何变化如旋转、缩放和视角变化对视觉理解构成了重大挑战。一种常见的解决方案是直接建模某些内在结构，例如使用地标。然而，构建有效的深度模型变得不平凡，尤其是当基础的非欧几里得网格不规则且粗糙时。最近使用图卷积的深度模型提供了一个适当的框架来处理这种非欧几里得数据，但其中许多模型，特别是那些基于全局图拉普拉斯算子的模型，缺乏捕捉非欧几里得网格上信号表示所需的局部特征的表达能力。本文介绍了一种新型的图卷积，具有可学习的低秩局部滤波器，理论上比以前的谱图卷积方法更具表达力。该模型还为谱和空间图卷积提供了一个统一的框架。为了提高模型的鲁棒性，引入了局部图拉普拉斯算子的正则化。利用图滤波器的局部性和局部图正则化，理论上证明了输入图数据扰动下的表示稳定性。在球形网格数据、真实世界面部表情识别/基于骨架的动作识别数据以及模拟图噪声数据上的实验显示了所提出模型的经验优势。",
        "领域": "图神经网络、非欧几里得数据处理、几何深度学习",
        "问题": "解决非欧几里得数据（如不规则和粗糙网格）上的几何变化（如旋转、缩放和视角变化）对视觉理解的挑战。",
        "动机": "现有的基于全局图拉普拉斯算子的图卷积方法在捕捉非欧几里得网格上信号表示所需的局部特征方面表达能力不足。",
        "方法": "提出了一种新型的图卷积方法，采用可学习的低秩局部滤波器，结合局部图拉普拉斯算子的正则化，以提高模型的表达能力和鲁棒性。",
        "关键词": [
            "图卷积",
            "低秩滤波器",
            "非欧几里得数据",
            "局部特征",
            "模型鲁棒性"
        ],
        "涉及的技术概念": {
            "图卷积": "用于处理非欧几里得数据的一种深度学习方法，通过图结构上的卷积操作捕捉数据特征。",
            "低秩滤波器": "一种可学习的滤波器，通过低秩近似减少参数数量，同时保持模型的表达能力。",
            "局部图拉普拉斯正则化": "通过引入局部图拉普拉斯算子的正则化项，提高模型对输入图数据扰动的鲁棒性。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 320,
        "title": "Graph Edit Networks",
        "html": "https://iclr.cc//virtual/2021/poster/3122",
        "abstract": "While graph neural networks have made impressive progress in classification and regression, few approaches to date perform time series prediction on graphs, and those that do are mostly limited to edge changes. We suggest that graph edits are a more natural interface for graph-to-graph learning. In particular,  graph edits are general enough to describe any graph-to-graph change, not only edge changes; they are sparse, making them easier to understand for humans and more efficient computationally; and they are local, avoiding the need for pooling layers in graph neural networks. In this paper, we propose a novel output layer - the graph edit network - which takes node embeddings as input and generates a sequence of graph edits that transform the input graph to the output graph. We prove that a mapping between the node sets of two graphs is sufficient to construct training data for a graph edit network and that an optimal mapping yields edit scripts that are almost as short as the graph edit distance between the graphs. We further provide a proof-of-concept empirical evaluation on several graph dynamical systems, which are difficult to learn for baselines from the literature.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "图编辑网络",
        "摘要翻译": "尽管图神经网络在分类和回归任务上取得了显著进展，但迄今为止，很少有方法能够对图进行时间序列预测，而那些能够进行预测的方法大多仅限于边的变化。我们认为图编辑是图到图学习更为自然的接口。特别是，图编辑足够通用，可以描述任何图到图的变化，而不仅仅是边的变化；它们是稀疏的，这使得人类更容易理解，计算上更高效；并且它们是局部的，避免了在图神经网络中使用池化层的需要。在本文中，我们提出了一种新颖的输出层——图编辑网络，它以节点嵌入作为输入，生成一系列图编辑操作，将输入图转换为输出图。我们证明了两个图的节点集之间的映射足以构建图编辑网络的训练数据，并且最优映射产生的编辑脚本几乎与图之间的编辑距离一样短。我们进一步提供了几个图动力系统的概念验证实证评估，这些系统对于文献中的基线方法来说难以学习。",
        "领域": "图神经网络、图编辑距离、图动力系统",
        "问题": "解决图神经网络在图到图学习中的时间序列预测问题，特别是如何更自然和高效地描述和实现图的变化。",
        "动机": "图编辑作为一种更自然、通用、稀疏和局部的接口，能够更有效地描述图到图的变化，避免传统方法的限制。",
        "方法": "提出图编辑网络，一种新型输出层，通过节点嵌入生成图编辑序列，实现输入图到输出图的转换。",
        "关键词": [
            "图编辑网络",
            "图神经网络",
            "图编辑距离",
            "节点嵌入",
            "图动力系统"
        ],
        "涉及的技术概念": {
            "图编辑网络": "一种新型输出层，用于生成图编辑序列，实现图到图的转换。",
            "图编辑距离": "衡量两个图之间差异的指标，图编辑网络旨在生成接近此距离的编辑脚本。",
            "节点嵌入": "图编辑网络的输入，用于捕捉和表示图中节点的特征和结构信息。"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 321,
        "title": "Graph Information Bottleneck for Subgraph Recognition",
        "html": "https://iclr.cc//virtual/2021/poster/2997",
        "abstract": "Given the input graph and its label/property, several key problems  of graph learning, such as finding interpretable subgraphs, graph denoising and graph compression,  can be  attributed to the fundamental problem of recognizing a subgraph of the original one.  This subgraph shall be as informative as possible, yet contains less redundant and noisy structure. This problem setting is closely related to the well-known information bottleneck (IB) principle, which, however, has less been studied for the irregular graph data and graph neural networks (GNNs). In this paper, we propose a framework of Graph Information Bottleneck (GIB) for the subgraph recognition problem in deep graph learning. Under this framework, one can recognize the maximally informative yet compressive subgraph, named IB-subgraph.  However, the GIB objective is notoriously hard to optimize, mostly due to the intractability of the mutual information of irregular graph data and the unstable optimization process. In order to tackle these challenges, we propose:  i) a GIB objective based-on a mutual information estimator for the irregular graph data; ii) a bi-level optimization scheme to maximize the GIB objective; iii) a connectivity loss to stabilize the optimization process. We evaluate the properties of the IB-subgraph in three application scenarios: improvement of graph classification, graph interpretation and graph denoising. Extensive experiments demonstrate that the information-theoretic  IB-subgraph  enjoys superior graph properties. ",
        "conference": "ICLR",
        "中文标题": "图信息瓶颈用于子图识别",
        "摘要翻译": "给定输入图及其标签/属性，图学习中的几个关键问题，如寻找可解释的子图、图去噪和图压缩，可以归因于识别原始图的一个子图的基本问题。这个子图应尽可能信息丰富，同时包含较少冗余和噪声结构。这一问题设置与著名的信息瓶颈（IB）原则密切相关，然而，对于不规则图数据和图神经网络（GNNs）的研究较少。在本文中，我们提出了一个图信息瓶颈（GIB）框架，用于深度图学习中的子图识别问题。在这一框架下，可以识别出信息量最大但压缩的子图，称为IB子图。然而，GIB目标因其难以优化而闻名，主要是由于不规则图数据的互信息难以处理以及优化过程不稳定。为了应对这些挑战，我们提出了：i) 基于不规则图数据的互信息估计器的GIB目标；ii) 一个双层优化方案以最大化GIB目标；iii) 一个连接性损失以稳定优化过程。我们在三个应用场景中评估了IB子图的属性：图分类的改进、图解释和图去噪。大量实验表明，信息论IB子图具有优越的图属性。",
        "领域": "图神经网络、图分类、图去噪",
        "问题": "识别原始图中信息丰富且压缩的子图",
        "动机": "解决图学习中寻找可解释子图、图去噪和图压缩等关键问题",
        "方法": "提出图信息瓶颈（GIB）框架，包括基于互信息估计器的GIB目标、双层优化方案和连接性损失",
        "关键词": [
            "图信息瓶颈",
            "子图识别",
            "图神经网络",
            "互信息估计",
            "双层优化"
        ],
        "涉及的技术概念": {
            "图信息瓶颈（GIB）": "用于识别信息丰富且压缩的子图的框架",
            "互信息估计器": "用于估计不规则图数据的互信息，以优化GIB目标",
            "双层优化方案": "用于最大化GIB目标的优化策略"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 322,
        "title": "Graph Traversal with Tensor Functionals: A Meta-Algorithm for Scalable Learning",
        "html": "https://iclr.cc//virtual/2021/poster/2564",
        "abstract": "Graph Representation Learning (GRL) methods have impacted fields from chemistry to social science. However, their algorithmic implementations are specialized to specific use-cases e.g. 'message passing' methods are run differently from 'node embedding' ones. Despite their apparent differences, all these methods utilize the graph structure,  and therefore, their learning can be approximated with stochastic graph traversals.  We propose Graph Traversal via Tensor Functionals (GTTF), a unifying meta-algorithm framework for easing the implementation of diverse graph algorithms and enabling transparent and efficient scaling to large graphs.  GTTF is founded upon a data structure (stored as a sparse tensor) and a stochastic graph traversal algorithm (described using tensor operations). The algorithm is a functional that accept two functions, and can be specialized to obtain a variety of GRL models and objectives, simply by changing those two functions. We show for a wide class of methods, our algorithm learns in an unbiased fashion and, in expectation, approximates the learning as if the specialized implementations were run directly.\nWith these capabilities, we scale otherwise non-scalable methods to set state-of-the-art on large graph datasets while being more efficient than existing GRL libraries -- with only a handful of lines of code for each method specialization.",
        "conference": "ICLR",
        "中文标题": "使用张量泛函进行图遍历：一种可扩展学习的元算法",
        "摘要翻译": "图表示学习（GRL）方法已从化学到社会科学等多个领域产生影响。然而，它们的算法实现针对特定用例进行了专门化，例如，'消息传递'方法与'节点嵌入'方法的运行方式不同。尽管这些方法表面上存在差异，但它们都利用了图结构，因此，它们的学习可以通过随机图遍历来近似。我们提出了通过张量泛函进行图遍历（GTTF），这是一个统一的元算法框架，旨在简化多样图算法的实现，并实现透明且高效地扩展到大型图。GTTF基于一个数据结构（存储为稀疏张量）和一个随机图遍历算法（使用张量操作描述）。该算法是一个泛函，接受两个函数，并且可以通过改变这两个函数来专门化，以获得各种GRL模型和目标。我们展示了对于广泛的方法类别，我们的算法以无偏的方式进行学习，并且在期望中，近似于直接运行专门化实现的学习。凭借这些能力，我们将原本不可扩展的方法扩展到大型图数据集上，设置了最先进的性能，同时比现有的GRL库更高效——每种方法专门化仅需少量代码行。",
        "领域": "图表示学习、图算法、张量计算",
        "问题": "解决图表示学习方法实现专门化、难以统一和扩展的问题",
        "动机": "为了简化多样图算法的实现，并实现透明且高效地扩展到大型图",
        "方法": "提出了一个基于稀疏张量数据结构和随机图遍历算法的统一元算法框架GTTF",
        "关键词": [
            "图表示学习",
            "张量泛函",
            "图遍历",
            "元算法",
            "可扩展性"
        ],
        "涉及的技术概念": {
            "图表示学习": "利用图结构进行学习的方法，广泛应用于多个领域",
            "张量泛函": "用于描述和实现图遍历算法的数学工具，提供灵活性和扩展性",
            "随机图遍历": "一种近似学习方法，通过随机访问图中的节点和边来学习图结构"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 323,
        "title": "GraPPa: Grammar-Augmented Pre-Training for Table Semantic Parsing",
        "html": "https://iclr.cc//virtual/2021/poster/3307",
        "abstract": "We present GraPPa, an effective pre-training approach for table semantic parsing that learns a compositional inductive bias in the joint representations of textual and tabular data. We construct synthetic question-SQL pairs over high-quality tables via a synchronous context-free grammar (SCFG). We pre-train our model on the synthetic data to inject important structural properties commonly found in semantic parsing into the pre-training language model. To maintain the model's ability to represent real-world data, we also include masked language modeling (MLM) on several existing table-related datasets to regularize our pre-training process.  Our proposed pre-training strategy is much data-efficient. When incorporated with strong base semantic parsers, GraPPa achieves new state-of-the-art results on four popular fully supervised and weakly supervised table semantic parsing tasks.",
        "conference": "ICLR",
        "中文标题": "GraPPa：用于表格语义解析的语法增强预训练方法",
        "摘要翻译": "我们提出了GraPPa，一种有效的表格语义解析预训练方法，该方法在文本和表格数据的联合表示中学习组合性归纳偏置。我们通过同步上下文无关文法（SCFG）在高质量表格上构建合成的问题-SQL对。我们在合成数据上预训练我们的模型，以将语义解析中常见的重要结构特性注入预训练语言模型中。为了保持模型表示现实世界数据的能力，我们还在几个现有的与表格相关的数据集上包括掩码语言建模（MLM），以规范化我们的预训练过程。我们提出的预训练策略数据效率极高。当与强大的基础语义解析器结合时，GraPPa在四个流行的全监督和弱监督表格语义解析任务上实现了新的最先进结果。",
        "领域": "表格语义解析、自然语言处理与视觉结合、预训练语言模型",
        "问题": "提高表格语义解析的准确性和效率",
        "动机": "通过预训练方法学习文本和表格数据的联合表示，以提高语义解析的性能",
        "方法": "使用同步上下文无关文法构建合成数据，结合掩码语言建模进行预训练",
        "关键词": [
            "表格语义解析",
            "预训练语言模型",
            "同步上下文无关文法",
            "掩码语言建模",
            "数据效率"
        ],
        "涉及的技术概念": {
            "同步上下文无关文法（SCFG）": "用于构建合成的问题-SQL对，以注入语义解析中的结构特性",
            "掩码语言建模（MLM）": "用于保持模型表示现实世界数据的能力，规范化预训练过程",
            "组合性归纳偏置": "在文本和表格数据的联合表示中学习，以提高语义解析的性能"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 324,
        "title": "Greedy-GQ with Variance Reduction: Finite-time Analysis and Improved Complexity",
        "html": "https://iclr.cc//virtual/2021/poster/2968",
        "abstract": "Greedy-GQ is a value-based reinforcement learning (RL) algorithm for optimal control. Recently, the finite-time analysis of Greedy-GQ has been developed under linear function approximation and Markovian sampling, and the algorithm is shown to achieve an $\\epsilon$-stationary point with a sample complexity in the order of $\\mathcal{O}(\\epsilon^{-3})$. Such a high sample complexity is due to the large variance induced by the Markovian samples. In this paper, we propose a variance-reduced Greedy-GQ (VR-Greedy-GQ) algorithm for off-policy optimal control. In particular, the algorithm applies the SVRG-based variance reduction scheme to reduce the stochastic variance of the two time-scale updates. We study the finite-time convergence of VR-Greedy-GQ under linear function approximation and Markovian sampling and show that the algorithm achieves a much smaller bias and variance error than the original Greedy-GQ. In particular, we prove that VR-Greedy-GQ achieves an improved sample complexity that is in the order of $\\mathcal{O}(\\epsilon^{-2})$. We further compare the performance of VR-Greedy-GQ with that of Greedy-GQ in various RL experiments to corroborate our theoretical findings.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "贪婪-GQ与方差缩减：有限时间分析及改进的复杂度",
        "摘要翻译": "贪婪-GQ是一种基于价值的强化学习（RL）算法，用于最优控制。最近，在线性函数逼近和马尔可夫采样下，贪婪-GQ的有限时间分析已经发展起来，并且该算法被证明能够达到一个ε-稳定点，其样本复杂度在O(ε^-3)的量级。如此高的样本复杂度是由于马尔可夫样本引起的大方差。在本文中，我们提出了一种方差缩减的贪婪-GQ（VR-Greedy-GQ）算法，用于离策略最优控制。特别是，该算法应用基于SVRG的方差缩减方案来减少两个时间尺度更新的随机方差。我们研究了在线性函数逼近和马尔可夫采样下VR-Greedy-GQ的有限时间收敛性，并表明该算法比原始贪婪-GQ实现了更小的偏差和方差误差。特别是，我们证明了VR-Greedy-GQ实现了改进的样本复杂度，其量级为O(ε^-2)。我们进一步在各种RL实验中比较了VR-Greedy-GQ与贪婪-GQ的性能，以证实我们的理论发现。",
        "领域": "强化学习",
        "问题": "减少贪婪-GQ算法在最优控制中的样本复杂度",
        "动机": "由于马尔可夫样本引起的大方差导致贪婪-GQ算法的样本复杂度较高，研究旨在通过方差缩减技术改进这一状况",
        "方法": "提出了一种基于SVRG的方差缩减贪婪-GQ（VR-Greedy-GQ）算法，用于减少两个时间尺度更新的随机方差",
        "关键词": [
            "贪婪-GQ",
            "方差缩减",
            "强化学习",
            "最优控制",
            "样本复杂度"
        ],
        "涉及的技术概念": {
            "贪婪-GQ": "一种基于价值的强化学习算法，用于最优控制",
            "方差缩减": "通过SVRG技术减少算法中的随机方差，以提高效率",
            "样本复杂度": "衡量算法达到特定性能所需样本数量的指标，改进后的算法显著降低了这一需求"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 325,
        "title": "Grounded Language Learning Fast and Slow",
        "html": "https://iclr.cc//virtual/2021/poster/3017",
        "abstract": "Recent work has shown that large text-based neural language models acquire a surprising propensity for one-shot learning. Here, we show that an agent situated in a simulated 3D world, and endowed with a novel dual-coding external memory, can exhibit similar one-shot word learning when trained with conventional RL algorithms. After a single introduction to a novel object via visual perception and language ('This is a dax'), the agent can manipulate the object as instructed ('Put the dax on the bed'), combining short-term, within-episode knowledge of the nonsense word with long-term lexical and motor knowledge. We find that, under certain training conditions and with a particular memory writing mechanism, the agent's one-shot word-object binding generalizes to novel exemplars within the same ShapeNet category, and is effective in settings with unfamiliar numbers of objects. We further show how dual-coding memory can be exploited as a signal for intrinsic motivation, stimulating the agent to seek names for objects that may be useful later. Together, the results demonstrate that deep neural networks can exploit meta-learning, episodic memory and an explicitly multi-modal environment to account for 'fast-mapping', a fundamental pillar of human cognitive development and a potentially transformative capacity for artificial agents.   ",
        "conference": "ICLR",
        "success": true,
        "中文标题": "基于语言学习的快速与慢速基础",
        "摘要翻译": "最近的研究表明，基于文本的大型神经语言模型意外地获得了一次性学习的倾向。本文展示了一个位于模拟3D世界中的代理，配备了一种新颖的双编码外部记忆，当使用传统的强化学习算法训练时，可以表现出类似的一次性单词学习能力。通过视觉感知和语言（'这是一个dax'）对新颖物体进行单次介绍后，代理能够按照指令操作物体（'把dax放在床上'），将无意义单词的短期、情节内知识与长期词汇和运动知识结合起来。我们发现，在特定的训练条件和特定的记忆写入机制下，代理的一次性单词-物体绑定能够推广到同一ShapeNet类别中的新样本，并且在具有不熟悉数量物体的设置中有效。我们进一步展示了如何利用双编码记忆作为内在动机的信号，激励代理寻找可能以后有用的物体名称。总之，结果表明，深度神经网络可以利用元学习、情节记忆和明确的多模态环境来解释'快速映射'，这是人类认知发展的基本支柱，也是人工代理潜在变革能力的关键。",
        "领域": "自然语言处理与视觉结合",
        "问题": "如何使人工代理在模拟3D环境中通过一次性学习快速掌握新词汇并执行相关指令",
        "动机": "探索深度神经网络如何模仿人类快速映射学习能力，以提升人工代理的认知和学习效率",
        "方法": "采用双编码外部记忆和传统强化学习算法，结合视觉感知和语言输入，实现一次性单词学习和指令执行",
        "关键词": [
            "一次性学习",
            "双编码记忆",
            "强化学习",
            "快速映射",
            "多模态学习"
        ],
        "涉及的技术概念": {
            "双编码外部记忆": "用于存储和处理视觉与语言信息，支持代理的一次性学习和长期知识结合",
            "强化学习算法": "训练代理在模拟环境中通过试错学习执行指令，优化其行为策略",
            "快速映射": "指代理能够通过单次接触快速学习新词汇并应用于新情境的能力，模仿人类认知发展中的关键学习机制"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 326,
        "title": "Grounding Language to Autonomously-Acquired Skills via Goal Generation",
        "html": "https://iclr.cc//virtual/2021/poster/3190",
        "abstract": "We are interested in the autonomous acquisition of repertoires of skills. Language-conditioned reinforcement learning (LC-RL) approaches are great tools in this quest, as they allow to express abstract goals as sets of constraints on the states. However, most LC-RL agents are not autonomous and cannot learn without external instructions and feedback. Besides, their direct language condition cannot account for the goal-directed behavior of pre-verbal infants and strongly limits the expression of behavioral diversity for a given language input. To resolve these issues, we propose a new conceptual approach to language-conditioned RL: the Language-Goal-Behavior architecture (LGB). LGB decouples skill learning and language grounding via an intermediate semantic representation of the world. To showcase the properties of LGB, we present a specific implementation called DECSTR. DECSTR is an intrinsically motivated learning agent endowed with an innate semantic representation describing spatial relations between physical objects. In a first stage G -> B, it freely explores its environment and targets self-generated semantic configurations. In a second stage (L -> G), it trains a language-conditioned  goal generator to generate semantic goals that match the constraints expressed in language-based inputs. We showcase the additional properties of LGB w.r.t. both an end-to-end LC-RL approach and a similar approach leveraging non-semantic, continuous intermediate representations. Intermediate semantic representations help satisfy language commands in a diversity of ways, enable strategy switching after a failure and facilitate language grounding.",
        "conference": "ICLR",
        "中文标题": "通过目标生成将语言与自主获取技能相结合",
        "摘要翻译": "我们对技能的自主获取感兴趣。语言条件强化学习（LC-RL）方法是这一探索中的强大工具，因为它们允许将抽象目标表达为状态的约束集合。然而，大多数LC-RL代理不具备自主性，无法在没有外部指令和反馈的情况下学习。此外，它们的直接语言条件无法解释前语言婴儿的目标导向行为，并极大地限制了给定语言输入下行为多样性的表达。为了解决这些问题，我们提出了一种新的语言条件强化学习概念方法：语言-目标-行为架构（LGB）。LGB通过世界的中间语义表示，将技能学习和语言基础解耦。为了展示LGB的特性，我们提出了一个名为DECSTR的具体实现。DECSTR是一个具有内在动机的学习代理，拥有描述物理对象之间空间关系的先天语义表示。在第一阶段G -> B中，它自由探索其环境并针对自生成的语义配置。在第二阶段（L -> G），它训练一个语言条件目标生成器，以生成与基于语言的输入中表达的约束相匹配的语义目标。我们展示了LGB相对于端到端LC-RL方法和利用非语义连续中间表示的类似方法的附加特性。中间语义表示有助于以多种方式满足语言命令，在失败后启用策略切换，并促进语言基础。",
        "领域": "语言条件强化学习、自主技能获取、语义表示学习",
        "问题": "解决语言条件强化学习代理缺乏自主性和行为多样性的问题",
        "动机": "探索如何使强化学习代理在没有外部指令的情况下自主获取技能，并增加行为多样性",
        "方法": "提出语言-目标-行为架构（LGB），通过中间语义表示解耦技能学习和语言基础，并实现DECSTR代理进行验证",
        "关键词": [
            "语言条件强化学习",
            "自主技能获取",
            "语义表示",
            "目标生成",
            "行为多样性"
        ],
        "涉及的技术概念": {
            "语言条件强化学习（LC-RL）": "一种允许将抽象目标表达为状态约束集合的强化学习方法",
            "语言-目标-行为架构（LGB）": "通过中间语义表示解耦技能学习和语言基础的新概念方法",
            "DECSTR代理": "一个具有内在动机的学习代理，利用先天语义表示进行自主探索和目标生成"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 327,
        "title": "Grounding Physical Concepts of Objects and Events Through Dynamic Visual Reasoning",
        "html": "https://iclr.cc//virtual/2021/poster/2994",
        "abstract": "We study the problem of dynamic visual reasoning on raw videos. This is a challenging problem; currently, state-of-the-art models often require dense supervision on physical object properties and events from simulation, which are impractical to obtain in real life. In this paper, we present the Dynamic Concept Learner (DCL), a unified framework that grounds physical objects and events from video and language. DCL first adopts a trajectory extractor to track each object over time and to represent it as a latent, object-centric feature vector. Building upon this object-centric representation, DCL learns to approximate the dynamic interaction among objects using graph networks. DCL further incorporates a semantic parser to parse question into semantic programs and, finally, a program executor to run the program to answer the question, levering the learned dynamics model. After training, DCL can detect and associate objects across the frames, ground visual properties and physical events, understand the causal relationship between events, make future and counterfactual predictions, and leverage these extracted presentations for answering queries. DCL achieves state-of-the-art performance on CLEVRER, a challenging causal video reasoning dataset, even without using ground-truth attributes and collision labels from simulations for training. We further test DCL on a newly proposed video-retrieval and event localization dataset derived from CLEVRER, showing its strong generalization capacity.",
        "conference": "ICLR",
        "中文标题": "通过动态视觉推理基础化物体与事件的物理概念",
        "摘要翻译": "我们研究了在原始视频上进行动态视觉推理的问题。这是一个具有挑战性的问题；目前，最先进的模型通常需要从模拟中获得关于物理对象属性和事件的密集监督，这在实际生活中是不切实际的。在本文中，我们提出了动态概念学习器（DCL），一个统一的框架，用于从视频和语言中基础化物理对象和事件。DCL首先采用轨迹提取器来跟踪每个对象随时间的变化，并将其表示为潜在的、以对象为中心的特征向量。基于这种以对象为中心的表示，DCL学习使用图网络近似对象之间的动态交互。DCL进一步结合了一个语义解析器来将问题解析为语义程序，最后是一个程序执行器来运行程序以回答问题，利用学习到的动态模型。训练后，DCL可以检测并关联跨帧的对象，基础化视觉属性和物理事件，理解事件之间的因果关系，做出未来和反事实预测，并利用这些提取的表示来回答问题。DCL在CLEVRER上实现了最先进的性能，这是一个具有挑战性的因果视频推理数据集，甚至在训练中没有使用来自模拟的真实属性和碰撞标签。我们进一步在从CLEVRER派生出的新提出的视频检索和事件定位数据集上测试了DCL，展示了其强大的泛化能力。",
        "领域": "动态视觉推理、因果推理、视频理解",
        "问题": "解决在原始视频上进行动态视觉推理的挑战，特别是在缺乏密集监督的情况下基础化物理对象和事件。",
        "动机": "当前最先进的模型需要密集监督，这在实际应用中不切实际，因此需要开发能够在缺乏此类监督的情况下进行动态视觉推理的方法。",
        "方法": "提出了动态概念学习器（DCL），一个统一的框架，通过轨迹提取器、图网络、语义解析器和程序执行器来基础化物理对象和事件，并进行动态视觉推理。",
        "关键词": [
            "动态视觉推理",
            "因果推理",
            "视频理解",
            "对象跟踪",
            "语义解析"
        ],
        "涉及的技术概念": {
            "轨迹提取器": "用于跟踪视频中每个对象随时间的变化，并将其表示为以对象为中心的特征向量。",
            "图网络": "用于近似对象之间的动态交互，学习对象之间的关系和动态变化。",
            "语义解析器": "将自然语言问题解析为可执行的语义程序，使模型能够理解和回答复杂的问题。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 328,
        "title": "Group Equivariant Conditional Neural Processes",
        "html": "https://iclr.cc//virtual/2021/poster/3103",
        "abstract": "We present the group equivariant conditional neural process (EquivCNP), a meta-learning method with permutation invariance in a data set as in conventional conditional neural processes (CNPs), and it also has transformation equivariance in data space. Incorporating group equivariance, such as rotation and scaling equivariance, provides a way to consider the symmetry of real-world data. We give a decomposition theorem for permutation-invariant and group-equivariant maps, which leads us to construct EquivCNPs with an infinite-dimensional latent space to handle group symmetries. In this paper, we build architecture using Lie group convolutional layers for practical implementation. We show that EquivCNP with translation equivariance achieves comparable performance to conventional CNPs in a 1D regression task. Moreover, we demonstrate that incorporating an appropriate Lie group equivariance, EquivCNP is capable of zero-shot generalization for an image-completion task by selecting an appropriate Lie group equivariance.",
        "conference": "ICLR",
        "中文标题": "群等变条件神经过程",
        "摘要翻译": "我们提出了群等变条件神经过程（EquivCNP），这是一种在数据集中具有与传统条件神经过程（CNPs）相同的排列不变性的元学习方法，同时在数据空间中具有变换等变性。通过引入群等变性，如旋转和缩放等变性，提供了一种考虑现实世界数据对称性的方法。我们给出了排列不变和群等变映射的分解定理，这引导我们构建具有无限维潜在空间的EquivCNPs来处理群对称性。在本文中，我们使用李群卷积层构建架构以实现实际应用。我们展示了具有平移等变性的EquivCNP在一维回归任务中实现了与传统CNPs相当的性能。此外，我们证明了通过选择适当的李群等变性，EquivCNP能够通过选择适当的李群等变性，在图像完成任务中实现零样本泛化。",
        "领域": "元学习、图像处理、对称性学习",
        "问题": "如何在保持数据排列不变性的同时，实现数据空间中的变换等变性，以更好地处理现实世界数据的对称性。",
        "动机": "现实世界的数据往往具有内在的对称性，如旋转和缩放等，传统的条件神经过程（CNPs）虽然具有排列不变性，但缺乏对这些对称性的考虑。因此，研究旨在通过引入群等变性，提升模型对数据对称性的理解和处理能力。",
        "方法": "通过分解定理构建具有无限维潜在空间的群等变条件神经过程（EquivCNP），使用李群卷积层实现架构，以处理群对称性。",
        "关键词": [
            "群等变性",
            "条件神经过程",
            "元学习",
            "李群卷积",
            "零样本泛化"
        ],
        "涉及的技术概念": {
            "群等变性": "在数据空间中保持变换等变性，如旋转和缩放等，以考虑数据的对称性。",
            "条件神经过程": "一种元学习方法，具有数据集的排列不变性，用于预测或生成任务。",
            "李群卷积层": "用于构建EquivCNP架构的技术，实现群对称性的处理，适用于实际应用。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 329,
        "title": "Group Equivariant Generative Adversarial Networks",
        "html": "https://iclr.cc//virtual/2021/poster/3005",
        "abstract": "Recent improvements in generative adversarial visual synthesis incorporate real and fake image transformation in a self-supervised setting, leading to increased stability and perceptual fidelity. However, these approaches typically involve image augmentations via additional regularizers in the GAN objective and thus spend valuable network capacity towards approximating transformation equivariance instead of their desired task. In this work, we explicitly incorporate inductive symmetry priors into the network architectures via group-equivariant convolutional networks. Group-convolutions have higher expressive power with fewer samples and lead to better gradient feedback between generator and discriminator. We show that group-equivariance integrates seamlessly with recent techniques for GAN training across regularizers, architectures, and loss functions. We demonstrate the utility of our methods for conditional synthesis by improving generation in the limited data regime across symmetric imaging datasets and even find benefits for natural images with preferred orientation.",
        "conference": "ICLR",
        "中文标题": "群等变生成对抗网络",
        "摘要翻译": "近年来，生成对抗视觉合成技术的改进在自监督设置中结合了真实与伪造图像的变换，从而提高了稳定性和感知保真度。然而，这些方法通常通过在GAN目标中添加额外的正则化器来进行图像增强，因此将宝贵的网络容量用于近似变换等变性，而非其期望的任务。在这项工作中，我们通过群等变卷积网络明确地将归纳对称性先验纳入网络架构中。群卷积具有更高的表达能力和更少的样本需求，并在生成器和判别器之间提供了更好的梯度反馈。我们展示了群等变性与最近的GAN训练技术（包括正则化器、架构和损失函数）的无缝集成。通过在对称成像数据集的有限数据体制中改进生成，我们证明了我们的方法在条件合成中的实用性，甚至发现对于具有首选方向的自然图像也有益处。",
        "领域": "生成对抗网络、图像合成、对称性学习",
        "问题": "如何在生成对抗网络中有效利用对称性先验，以提高生成图像的质量和训练效率",
        "动机": "现有的GAN方法在实现图像变换等变性时消耗了过多的网络容量，影响了模型的主要任务性能",
        "方法": "通过群等变卷积网络将对称性先验显式地整合到网络架构中，以提高表达能力和训练效率",
        "关键词": [
            "群等变性",
            "生成对抗网络",
            "图像合成",
            "对称性学习",
            "条件生成"
        ],
        "涉及的技术概念": {
            "群等变卷积网络": "通过数学群理论定义的卷积操作，使网络能够自然地处理对称变换，提高模型对对称性的利用效率",
            "生成对抗网络": "由生成器和判别器组成的框架，通过对抗训练生成高质量的数据样本",
            "对称性先验": "在模型设计中预先考虑数据的对称性特性，以提高模型的泛化能力和样本效率"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 330,
        "title": "Group Equivariant Stand-Alone Self-Attention For Vision",
        "html": "https://iclr.cc//virtual/2021/poster/3118",
        "abstract": "We provide a general self-attention formulation to impose group equivariance to arbitrary symmetry groups. This is achieved by defining positional encodings that are invariant to the action of the group considered. Since the group acts on the positional encoding directly, group equivariant self-attention networks (GSA-Nets) are steerable by nature. Our experiments on vision benchmarks demonstrate consistent improvements of GSA-Nets over non-equivariant self-attention networks.",
        "conference": "ICLR",
        "中文标题": "视觉中的群等变独立自注意力机制",
        "摘要翻译": "我们提出了一种通用的自注意力机制公式，用于将群等变性施加于任意对称群。这是通过定义对所考虑群的作用不变的位置编码来实现的。由于群直接作用于位置编码，群等变自注意力网络（GSA-Nets）本质上是可导向的。我们在视觉基准上的实验表明，GSA-Nets相对于非等变自注意力网络有持续的改进。",
        "领域": "自注意力机制、群等变学习、计算机视觉",
        "问题": "如何在自注意力机制中实现群等变性以适应任意对称群",
        "动机": "研究动机是为了提升自注意力网络在处理具有对称性视觉任务时的性能和灵活性",
        "方法": "通过定义群作用不变的位置编码，构建群等变自注意力网络（GSA-Nets）",
        "关键词": [
            "群等变性",
            "自注意力机制",
            "位置编码",
            "对称群",
            "视觉基准"
        ],
        "涉及的技术概念": {
            "群等变性": "在自注意力网络中实现对于任意对称群的不变性，提升模型对对称性变换的适应性",
            "位置编码": "定义对于群作用不变的位置编码，是实现群等变自注意力网络的关键技术",
            "自注意力机制": "通过自注意力机制捕捉输入数据内部的依赖关系，群等变性进一步增强了其在对称性任务中的应用"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 331,
        "title": "Growing Efficient Deep Networks by Structured Continuous Sparsification",
        "html": "https://iclr.cc//virtual/2021/poster/3063",
        "abstract": "We develop an approach to growing deep network architectures over the course of training, driven by a principled combination of accuracy and sparsity objectives.  Unlike existing pruning or architecture search techniques that operate on full-sized models or supernet architectures, our method can start from a small, simple seed architecture and dynamically grow and prune both layers and filters.  By combining a continuous relaxation of discrete network structure optimization with a scheme for sampling sparse subnetworks, we produce compact, pruned networks, while also drastically reducing the computational expense of training.  For example, we achieve $49.7\\%$ inference FLOPs and $47.4\\%$ training FLOPs savings compared to a baseline ResNet-50 on ImageNet, while maintaining $75.2\\%$ top-1 validation accuracy --- all without any dedicated fine-tuning stage.  Experiments across CIFAR, ImageNet, PASCAL VOC, and Penn Treebank, with convolutional networks for image classification and semantic segmentation, and recurrent networks for language modeling, demonstrate that we both train faster and produce more efficient networks than competing architecture pruning or search methods.",
        "conference": "ICLR",
        "中文标题": "通过结构化连续稀疏化发展高效深度网络",
        "摘要翻译": "我们开发了一种在训练过程中逐步增长深度网络架构的方法，该方法由准确性和稀疏性目标的合理组合驱动。与现有的在全尺寸模型或超级网络架构上操作的剪枝或架构搜索技术不同，我们的方法可以从一个小的、简单的种子架构开始，动态地增长和剪枝层和过滤器。通过将离散网络结构优化的连续松弛与采样稀疏子网络的方案相结合，我们生成了紧凑的、经过剪枝的网络，同时大幅减少了训练的计算开销。例如，与基线ResNet-50在ImageNet上相比，我们实现了推理FLOPs节省49.7%和训练FLOPs节省47.4%，同时保持了75.2%的top-1验证准确率——所有这些都不需要任何专门的微调阶段。在CIFAR、ImageNet、PASCAL VOC和Penn Treebank上的实验，包括用于图像分类和语义分割的卷积网络，以及用于语言建模的循环网络，表明我们不仅训练速度更快，而且生成了比竞争的架构剪枝或搜索方法更高效的网络。",
        "领域": "神经网络架构优化, 模型剪枝, 深度学习效率提升",
        "问题": "如何在训练过程中动态调整网络架构以提高效率和性能",
        "动机": "减少深度网络训练和推理时的计算资源消耗，同时保持或提高模型的准确率",
        "方法": "结合连续松弛的离散网络结构优化和稀疏子网络采样，动态增长和剪枝网络架构",
        "关键词": [
            "结构化稀疏化",
            "动态网络增长",
            "模型剪枝",
            "计算效率",
            "深度学习优化"
        ],
        "涉及的技术概念": {
            "连续松弛": "用于将离散的网络结构优化问题转化为连续优化问题，便于梯度下降等优化方法的应用",
            "稀疏子网络采样": "通过采样技术从网络中提取高效的子网络结构，减少冗余计算",
            "动态架构调整": "在训练过程中根据模型性能动态增加或减少网络层和过滤器，优化网络结构"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 332,
        "title": "GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding",
        "html": "https://iclr.cc//virtual/2021/poster/3196",
        "abstract": "Neural network scaling has been critical for improving the model quality in many real-world machine learning applications with vast amounts of training data and compute. Although this trend of scaling is affirmed to be a sure-fire approach for better model quality, there are challenges on the path such as the computation cost,ease of programming, and efficient implementation on parallel devices.  In this paper we demonstrate conditional computation as a remedy to the above mentioned impediments, and demonstrate its efficacy and utility.  We make extensive use of GShard, a module composed of a set of lightweight annotation APIs and an extension to the XLA compiler to enable large scale models with up to trillions of parameters. GShard and conditional computation enable us to scale up multilingual neural machine translation Transformer model with Sparsely-Gated Mixture-of-Experts. We demonstrate that such a giant model with 600 billion parameters can efficiently be trained on 2048 TPU v3 cores in 4 days to achieve far superior quality for translation from 100 languages to English compared to the prior art.",
        "conference": "ICLR",
        "中文标题": "GShard：通过条件计算与自动分片扩展巨型模型",
        "摘要翻译": "神经网络扩展对于在拥有大量训练数据和计算资源的现实世界机器学习应用中提升模型质量至关重要。尽管这种扩展趋势被确认为提升模型质量的有效途径，但在这一过程中仍面临计算成本、编程便捷性以及在并行设备上高效实现等挑战。本文中，我们展示了条件计算作为解决上述障碍的方法，并证明了其有效性和实用性。我们广泛使用了GShard，这是一个由一组轻量级注释API和XLA编译器扩展组成的模块，以支持参数高达数万亿的大型模型。GShard和条件计算使我们能够扩展使用稀疏门控专家混合的多语言神经机器翻译Transformer模型。我们证明，这样一个拥有6000亿参数的巨型模型可以在2048个TPU v3核心上高效训练4天，实现从100种语言到英语的翻译质量远超现有技术。",
        "领域": "大规模模型训练",
        "问题": "解决在大规模神经网络训练中面临的计算成本高、编程复杂性和并行设备高效实现的问题",
        "动机": "探索如何有效扩展神经网络模型规模以提升模型质量，同时克服扩展过程中的技术和计算挑战",
        "方法": "采用条件计算和自动分片技术，结合GShard模块和XLA编译器扩展，实现大规模模型的高效训练",
        "关键词": [
            "条件计算",
            "自动分片",
            "大规模模型训练",
            "多语言机器翻译",
            "稀疏门控专家混合"
        ],
        "涉及的技术概念": {
            "条件计算": "在模型训练过程中动态决定哪些部分的网络需要被激活，以减少计算资源的消耗",
            "自动分片": "自动将模型参数分配到不同的计算设备上，以实现高效的并行计算",
            "稀疏门控专家混合": "一种模型架构，通过稀疏激活的专家网络来处理不同的输入，以提高模型的表达能力和效率"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 333,
        "title": "HalentNet: Multimodal Trajectory Forecasting with Hallucinative Intents",
        "html": "https://iclr.cc//virtual/2021/poster/2883",
        "abstract": "Motion forecasting is essential for making intelligent decisions in robotic navigation. As a result, the multi-agent behavioral prediction has become a core component of modern human-robot interaction applications such as autonomous driving. Due to various intentions and interactions among agents, agent trajectories can have multiple possible futures. Hence, the motion forecasting model's ability to cover possible modes becomes essential to enable accurate prediction. Towards this goal, we introduce HalentNet to better model the future motion distribution in addition to a traditional trajectory regression learning objective by incorporating generative augmentation losses. We model intents with unsupervised discrete random variables whose training is guided by a collaboration between two key signals: A discriminative loss that encourages intents' diversity and a hallucinative loss that explores intent transitions (i.e., mixed intents) and encourages their smoothness. This regulates the neural network behavior to be more accurately predictive on uncertain scenarios due to the active yet careful exploration of possible future agent behavior. Our model's learned representation leads to better and more semantically meaningful coverage of the trajectory distribution. Our experiments show that our method can improve over the state-of-the-art trajectory forecasting benchmarks, including vehicles and pedestrians, for about 20% on average FDE and 50% on road boundary violation rate when predicting 6 seconds future. We also conducted human experiments to show that our predicted trajectories received 39.6% more votes than the runner-up approach and 32.2% more votes than our variant without hallucinative mixed intent loss. The code will be released soon. ",
        "conference": "ICLR",
        "中文标题": "HalentNet：基于幻觉意图的多模态轨迹预测",
        "摘要翻译": "运动预测对于机器人导航中的智能决策至关重要。因此，多智能体行为预测已成为现代人机交互应用（如自动驾驶）的核心组成部分。由于智能体之间的各种意图和交互，智能体轨迹可能有多种可能的未来。因此，运动预测模型覆盖可能模式的能力对于实现准确预测变得至关重要。为了实现这一目标，我们引入了HalentNet，除了传统的轨迹回归学习目标外，还通过引入生成增强损失来更好地建模未来运动分布。我们用无监督的离散随机变量建模意图，其训练由两个关键信号的协作指导：一个鼓励意图多样性的判别性损失和一个探索意图转换（即混合意图）并鼓励其平滑性的幻觉损失。这通过积极而谨慎地探索未来智能体行为的可能性，调节神经网络行为，使其在不确定场景下更准确预测。我们模型学习到的表示导致了对轨迹分布更好且更具语义意义的覆盖。我们的实验表明，我们的方法可以在最先进的轨迹预测基准上改进，包括车辆和行人，在预测6秒未来时，平均FDE提高约20%，道路边界违规率降低50%。我们还进行了人类实验，显示我们预测的轨迹比亚军方法多获得了39.6%的投票，比没有幻觉混合意图损失的变体多获得了32.2%的投票。代码即将发布。",
        "领域": "自动驾驶、多智能体系统、轨迹预测",
        "问题": "解决多智能体行为预测中未来轨迹多样性和准确性的问题",
        "动机": "提高自动驾驶等应用中运动预测的准确性和多样性，以更好地覆盖未来可能的轨迹分布",
        "方法": "引入HalentNet，结合生成增强损失和无监督离散随机变量建模意图，通过判别性损失和幻觉损失指导训练",
        "关键词": [
            "多模态轨迹预测",
            "幻觉意图",
            "自动驾驶",
            "行为预测",
            "生成增强损失"
        ],
        "涉及的技术概念": {
            "生成增强损失": "用于增强模型对未来运动分布的建模能力，通过引入额外的损失项来覆盖更多可能的未来轨迹",
            "无监督离散随机变量": "用于建模智能体的意图，通过无监督学习捕捉意图的多样性和复杂性",
            "幻觉损失": "探索意图转换并鼓励其平滑性，帮助模型在不确定场景下做出更准确的预测"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 334,
        "title": "Heating up decision boundaries: isocapacitory saturation, adversarial scenarios and generalization bounds",
        "html": "https://iclr.cc//virtual/2021/poster/2788",
        "abstract": "In the present work we study classifiers' decision boundaries via Brownian motion processes in ambient data space and associated probabilistic techniques. Intuitively, our ideas correspond to placing a heat source at the decision boundary and observing how effectively the sample points warm up. We are largely motivated by the search for a soft measure that sheds further light on the decision boundary's geometry. En route, we  bridge aspects of potential theory and geometric analysis (Maz'ya 2011, Grigor'Yan and Saloff-Coste 2002) with active fields of ML research such as adversarial examples and generalization bounds. First, we focus on the geometric behavior of decision boundaries in the light of adversarial attack/defense mechanisms. Experimentally, we observe a certain capacitory trend over different adversarial defense strategies: decision boundaries locally become flatter as measured by isoperimetric inequalities (Ford et al 2019); however, our more sensitive heat-diffusion metrics  extend this analysis and further reveal that some non-trivial geometry invisible to plain distance-based methods is still preserved. Intuitively, we provide evidence that the decision boundaries nevertheless retain many persistent 'wiggly and fuzzy' regions on a finer scale.\nSecond, we show how Brownian hitting probabilities translate to soft generalization bounds which are in turn connected to compression and noise stability (Arora et al 2018), and these bounds are significantly stronger if the decision boundary has controlled geometric features.",
        "conference": "ICLR",
        "中文标题": "加热决策边界：等容饱和、对抗场景与泛化界限",
        "摘要翻译": "在本工作中，我们通过环境数据空间中的布朗运动过程及相关概率技术研究分类器的决策边界。直观上，我们的想法对应于在决策边界放置一个热源，并观察样本点如何有效地升温。我们主要受到寻找一种软度量的动机，该度量能进一步揭示决策边界的几何特性。在此过程中，我们将潜在理论和几何分析（Maz'ya 2011, Grigor'Yan and Saloff-Coste 2002）的方面与机器学习研究的活跃领域如对抗样本和泛化界限联系起来。首先，我们关注在对抗攻击/防御机制视角下决策边界的几何行为。实验上，我们观察到不同对抗防御策略之间存在某种容量趋势：通过等周不等式（Ford et al 2019）测量，决策边界局部变得更平坦；然而，我们更敏感的热扩散度量扩展了这一分析，并进一步揭示了一些基于普通距离方法不可见的非平凡几何特性仍然保留。直观上，我们提供的证据表明，决策边界在更精细的尺度上仍然保留了许多持久的‘波动和模糊’区域。其次，我们展示了布朗击中概率如何转化为软泛化界限，这些界限又与压缩和噪声稳定性（Arora et al 2018）相关联，并且如果决策边界具有受控的几何特征，这些界限会显著更强。",
        "领域": "对抗性机器学习、泛化理论、几何深度学习",
        "问题": "研究分类器决策边界的几何特性及其在对抗攻击和泛化界限中的影响",
        "动机": "寻找一种软度量，以进一步理解决策边界的几何特性，并探索其在对抗性防御和泛化界限中的应用",
        "方法": "通过布朗运动过程和热扩散度量分析决策边界的几何行为，结合潜在理论和几何分析的方法",
        "关键词": [
            "决策边界",
            "对抗性防御",
            "泛化界限",
            "布朗运动",
            "热扩散度量"
        ],
        "涉及的技术概念": {
            "布朗运动过程": "用于在环境数据空间中模拟和分析决策边界的动态变化",
            "热扩散度量": "作为一种敏感的度量方法，用于揭示决策边界的非平凡几何特性",
            "等周不等式": "用于测量决策边界局部平坦度的工具，帮助理解对抗防御策略的效果"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 335,
        "title": "HeteroFL: Computation and Communication Efficient Federated Learning for Heterogeneous Clients",
        "html": "https://iclr.cc//virtual/2021/poster/3165",
        "abstract": "Federated Learning (FL) is a method of training machine learning models on private data distributed over a large number of possibly heterogeneous clients such as mobile phones and IoT devices. In this work, we propose a new federated learning framework named HeteroFL to address heterogeneous clients equipped with very different computation and communication capabilities. Our solution can enable the training of heterogeneous local models with varying computation complexities and still produce a single global inference model. For the first time, our method challenges the underlying assumption of existing work that local models have to share the same architecture as the global model. We demonstrate several strategies to enhance FL training and conduct extensive empirical evaluations, including five computation complexity levels of three model architecture on three datasets. We show that adaptively distributing subnetworks according to clients' capabilities is both computation and communication efficient.",
        "conference": "ICLR",
        "中文标题": "HeteroFL：面向异构客户端的计算与通信高效联邦学习",
        "摘要翻译": "联邦学习（FL）是一种在分布在大量可能异构的客户端（如手机和物联网设备）上的私有数据上训练机器学习模型的方法。在这项工作中，我们提出了一个名为HeteroFL的新联邦学习框架，以解决配备有非常不同的计算和通信能力的异构客户端问题。我们的解决方案能够训练具有不同计算复杂度的异构本地模型，并且仍然产生一个单一的全局推理模型。我们的方法首次挑战了现有工作的基本假设，即本地模型必须与全局模型共享相同的架构。我们展示了几种增强FL训练的策略，并进行了广泛的实证评估，包括在三个数据集上的三种模型架构的五个计算复杂度级别。我们表明，根据客户端的能力自适应地分配子网络既计算高效又通信高效。",
        "领域": "联邦学习、异构计算、通信优化",
        "问题": "解决在异构客户端（具有不同计算和通信能力）上高效进行联邦学习的问题。",
        "动机": "挑战现有联邦学习框架中本地模型必须与全局模型共享相同架构的假设，以适应不同客户端的计算和通信能力差异。",
        "方法": "提出HeteroFL框架，通过自适应地分配不同复杂度的子网络给不同能力的客户端，实现计算和通信的高效性。",
        "关键词": [
            "联邦学习",
            "异构客户端",
            "计算效率",
            "通信效率",
            "自适应分配"
        ],
        "涉及的技术概念": {
            "联邦学习": "一种在分布式设备上训练机器学习模型的方法，保护数据隐私。",
            "异构计算": "指处理能力不同的计算设备，HeteroFL框架针对这类设备优化。",
            "自适应分配": "根据客户端的能力动态分配不同复杂度的模型子网络，以提高整体效率。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 336,
        "title": "Heteroskedastic and Imbalanced Deep Learning with Adaptive Regularization",
        "html": "https://iclr.cc//virtual/2021/poster/2712",
        "abstract": "Real-world large-scale datasets are heteroskedastic and imbalanced --- labels have varying levels of uncertainty and label distributions are long-tailed. Heteroskedasticity and imbalance challenge deep learning algorithms due to the difficulty of distinguishing among mislabeled, ambiguous, and rare examples. Addressing heteroskedasticity and imbalance simultaneously is under-explored. We propose a data-dependent regularization technique for heteroskedastic datasets that regularizes different regions of the input space differently. Inspired by the theoretical derivation of the optimal regularization strength in a one-dimensional nonparametric classification setting, our approach adaptively regularizes the data points in higher-uncertainty, lower-density regions more heavily. We test our method on several benchmark tasks, including a real-world heteroskedastic and imbalanced dataset, WebVision. Our experiments corroborate our theory and demonstrate a significant improvement over other methods in noise-robust deep learning. ",
        "conference": "ICLR",
        "中文标题": "异方差与不平衡深度学习中的自适应正则化",
        "摘要翻译": "现实世界的大规模数据集具有异方差性和不平衡性——标签具有不同程度的不确定性，且标签分布呈现长尾特性。异方差性和不平衡性对深度学习算法提出了挑战，因为难以区分错误标记、模糊和稀少的样本。同时解决异方差性和不平衡性的研究尚未充分探索。我们提出了一种针对异方差数据集的数据依赖正则化技术，该技术对输入空间的不同区域进行不同程度的正则化。受到一维非参数分类设置中最优正则化强度理论推导的启发，我们的方法自适应地对高不确定性、低密度区域的数据点施加更强的正则化。我们在多个基准任务上测试了我们的方法，包括一个真实的异方差和不平衡数据集WebVision。我们的实验验证了我们的理论，并展示了在噪声鲁棒深度学习中相对于其他方法的显著改进。",
        "领域": "噪声鲁棒学习, 长尾分布学习, 自适应正则化",
        "问题": "解决深度学习在处理异方差性和不平衡性数据集时的挑战，特别是区分错误标记、模糊和稀少样本的困难。",
        "动机": "现实世界的数据集往往具有异方差性和不平衡性，这给深度学习算法的性能带来了挑战。当前同时解决这两个问题的研究不足，因此需要开发新的方法来提高模型在这些复杂数据集上的表现。",
        "方法": "提出了一种数据依赖的自适应正则化技术，根据不同区域的输入空间特性（如不确定性和数据密度）调整正则化强度，特别是在高不确定性和低密度区域施加更强的正则化。",
        "关键词": [
            "异方差性",
            "不平衡学习",
            "自适应正则化",
            "噪声鲁棒",
            "长尾分布"
        ],
        "涉及的技术概念": {
            "异方差性": "数据集中标签的不确定性水平不同，影响模型的训练和泛化能力。",
            "自适应正则化": "根据数据点的特性（如不确定性和密度）动态调整正则化强度，以提高模型在复杂数据集上的性能。",
            "长尾分布": "数据集中少数类别拥有大量样本，而多数类别样本稀少，导致模型难以学习稀少类别的特征。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 337,
        "title": "Hierarchical Autoregressive Modeling for Neural Video Compression",
        "html": "https://iclr.cc//virtual/2021/poster/2626",
        "abstract": "Recent work by Marino et al. (2020) showed improved performance in sequential density estimation by combining masked autoregressive flows with hierarchical latent variable models. We draw a connection between such autoregressive generative models and the task of lossy video compression. Specifically, we view recent neural video compression methods (Lu et al., 2019; Yang et al., 2020b; Agustssonet al., 2020) as instances of a generalized stochastic temporal autoregressive transform, and propose avenues for enhancement based on this insight. Comprehensive evaluations on large-scale video data show improved rate-distortion performance over both state-of-the-art neural and conventional video compression methods.",
        "conference": "ICLR",
        "中文标题": "分层自回归建模用于神经视频压缩",
        "摘要翻译": "Marino等人（2020）的最新工作表明，通过将掩码自回归流与分层潜变量模型相结合，可以在序列密度估计中获得更好的性能。我们将这种自回归生成模型与有损视频压缩任务联系起来。具体来说，我们将最近的神经视频压缩方法（Lu等人，2019；Yang等人，2020b；Agustsson等人，2020）视为广义随机时间自回归变换的实例，并基于这一见解提出了改进途径。在大规模视频数据上的全面评估显示，与最先进的神经和传统视频压缩方法相比，率失真性能有所提高。",
        "领域": "视频压缩、深度学习、生成模型",
        "问题": "提高视频压缩的率失真性能",
        "动机": "结合自回归生成模型和分层潜变量模型，探索神经视频压缩的新方法以提高压缩效率",
        "方法": "将神经视频压缩方法视为广义随机时间自回归变换的实例，并提出基于此的改进途径",
        "关键词": [
            "神经视频压缩",
            "自回归模型",
            "分层潜变量模型",
            "率失真优化",
            "生成模型"
        ],
        "涉及的技术概念": {
            "掩码自回归流": "用于序列密度估计，通过掩码技术控制自回归依赖关系",
            "分层潜变量模型": "通过分层结构捕捉数据的多层次特征，提高模型的表达能力",
            "广义随机时间自回归变换": "将视频压缩问题转化为时间序列的自回归建模问题，利用随机性提高压缩效率"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 338,
        "title": "Hierarchical Reinforcement Learning by Discovering Intrinsic Options",
        "html": "https://iclr.cc//virtual/2021/poster/2805",
        "abstract": "We propose a hierarchical reinforcement learning method, HIDIO, that can learn task-agnostic options in a self-supervised manner while jointly learning to utilize them to solve sparse-reward tasks. Unlike current hierarchical RL approaches that tend to formulate goal-reaching low-level tasks or pre-define ad hoc lower-level policies, HIDIO encourages lower-level option learning that is independent of the task at hand, requiring few assumptions or little knowledge about the task structure. These options are learned through an intrinsic entropy minimization objective conditioned on the option sub-trajectories. The learned options are diverse and task-agnostic. In experiments on sparse-reward robotic manipulation and navigation tasks, HIDIO achieves higher success rates with greater sample efficiency than regular RL baselines and two state-of-the-art hierarchical RL methods. Code at: https://github.com/jesbu1/hidio.",
        "conference": "ICLR",
        "中文标题": "通过发现内在选项的分层强化学习",
        "摘要翻译": "我们提出了一种分层强化学习方法HIDIO，它能够以自监督的方式学习与任务无关的选项，同时学习如何利用这些选项来解决稀疏奖励任务。与当前倾向于制定达到目标的低级任务或预定义特定低级策略的分层强化学习方法不同，HIDIO鼓励学习与手头任务无关的低级选项，这需要很少的假设或对任务结构的了解。这些选项是通过基于选项子轨迹的内在熵最小化目标学习的。学习到的选项多样且与任务无关。在稀疏奖励的机器人操作和导航任务的实验中，HIDIO比常规强化学习基线和两种最先进的分层强化学习方法实现了更高的成功率和更高的样本效率。代码位于：https://github.com/jesbu1/hidio。",
        "领域": "分层强化学习",
        "问题": "如何在稀疏奖励任务中有效地学习并利用与任务无关的低级选项",
        "动机": "当前的分层强化学习方法往往需要预先定义低级任务或策略，限制了方法的通用性和效率",
        "方法": "提出HIDIO方法，通过内在熵最小化目标自监督学习多样且与任务无关的低级选项，并有效利用这些选项解决任务",
        "关键词": [
            "分层强化学习",
            "自监督学习",
            "稀疏奖励",
            "任务无关选项",
            "内在熵最小化"
        ],
        "涉及的技术概念": {
            "分层强化学习": "一种通过在不同层次上组织和学习策略来解决复杂任务的方法",
            "自监督学习": "在没有外部标签的情况下，通过数据本身的结构或特性进行学习",
            "内在熵最小化": "通过最小化选项子轨迹的熵来促进选项的多样性和独立性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 339,
        "title": "High-Capacity Expert Binary Networks",
        "html": "https://iclr.cc//virtual/2021/poster/2953",
        "abstract": "Network binarization is a promising hardware-aware direction for creating efficient deep models. Despite its memory and computational advantages, reducing the accuracy gap between binary models and their real-valued counterparts remains an unsolved challenging research problem. To this end, we make the following 3 contributions: (a) To increase model capacity, we propose Expert Binary Convolution, which, for the first time, tailors conditional computing to binary networks by learning to select one data-specific expert binary filter at a time conditioned on input features. (b) To increase representation capacity, we propose to address the inherent information bottleneck in binary networks by introducing an efficient width expansion mechanism which keeps the binary operations within the same budget. (c) To improve network design, we propose a principled binary network growth mechanism that unveils a set of network topologies of favorable properties. Overall, our method improves upon prior work, with no increase in computational cost, by $\\sim6 \\%$, reaching a groundbreaking $\\sim 71\\%$ on ImageNet classification. Code will be made available $\\href{https://www.adrianbulat.com/binary-networks}{here}$.",
        "conference": "ICLR",
        "中文标题": "高容量专家二进制网络",
        "摘要翻译": "网络二值化是创建高效深度模型的一个有前景的硬件感知方向。尽管其在内存和计算上的优势，减少二进制模型与其实值对应物之间的准确度差距仍然是一个未解决的具有挑战性的研究问题。为此，我们做出了以下三项贡献：(a) 为了提高模型容量，我们提出了专家二进制卷积，首次通过根据输入特征学习选择一种数据特定的专家二进制滤波器，将条件计算定制到二进制网络中。(b) 为了提高表示容量，我们提出通过引入一种高效的宽度扩展机制来解决二进制网络中固有的信息瓶颈问题，该机制保持二进制操作在相同的预算内。(c) 为了改进网络设计，我们提出了一种原则性的二进制网络增长机制，揭示了一组具有良好特性的网络拓扑结构。总体而言，我们的方法在计算成本不增加的情况下，比先前的工作提高了约6%，在ImageNet分类上达到了突破性的约71%。代码将在此处提供。",
        "领域": "神经网络优化、图像分类、模型压缩",
        "问题": "减少二进制模型与其实值对应物之间的准确度差距",
        "动机": "提高二进制网络的模型容量和表示容量，同时保持计算成本不变",
        "方法": "提出专家二进制卷积、宽度扩展机制和二进制网络增长机制",
        "关键词": [
            "二进制网络",
            "模型容量",
            "表示容量",
            "网络设计",
            "ImageNet分类"
        ],
        "涉及的技术概念": {
            "专家二进制卷积": "通过根据输入特征学习选择数据特定的专家二进制滤波器，提高模型容量",
            "宽度扩展机制": "通过引入高效的宽度扩展机制解决二进制网络中的信息瓶颈问题",
            "二进制网络增长机制": "提出一种原则性的二进制网络增长机制，揭示具有良好特性的网络拓扑结构"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 340,
        "title": "Hopfield Networks is All You Need",
        "html": "https://iclr.cc//virtual/2021/poster/2657",
        "abstract": "We introduce a modern Hopfield network with continuous states and a corresponding update rule. The new Hopfield network can store exponentially (with the dimension of the associative space) many patterns, retrieves the pattern with one update, and has exponentially small retrieval errors. It has three types of energy minima (fixed points of the update): (1) global fixed point averaging over all patterns, (2) metastable states averaging over a subset of patterns, and (3) fixed points which store a single pattern. The new update rule is equivalent to the attention mechanism used in transformers. This equivalence enables a characterization of the heads of transformer models. These heads perform in the first layers preferably global averaging and in higher layers partial averaging via metastable states. The new modern Hopfield network can be integrated  into deep learning architectures as layers to allow the storage of and access to raw input data, intermediate results, or learned prototypes.\nThese Hopfield layers enable new ways of deep learning, beyond fully-connected, convolutional, or recurrent networks, and provide pooling, memory, association, and attention mechanisms. We demonstrate the broad applicability of the Hopfield layers\nacross various domains. Hopfield layers improved state-of-the-art on three out of four considered multiple instance learning problems as well as on immune repertoire classification with several hundreds of thousands of instances. On the UCI benchmark collections of small classification tasks, where deep learning methods typically struggle, Hopfield layers yielded a new state-of-the-art when compared to different machine learning methods. Finally, Hopfield layers achieved state-of-the-art on two drug design datasets. The implementation is available at: \\url{https://github.com/ml-jku/hopfield-layers}",
        "conference": "ICLR",
        "中文标题": "霍普菲尔德网络是你所需要的一切",
        "摘要翻译": "我们介绍了一种具有连续状态的现代霍普菲尔德网络及其相应的更新规则。这种新型霍普菲尔德网络能够存储与关联空间维度成指数级数量的模式，通过一次更新即可检索模式，并且具有指数级小的检索误差。它拥有三种类型的能量最小值（更新的固定点）：（1）对所有模式进行平均的全局固定点，（2）对模式子集进行平均的亚稳态，（3）存储单个模式的固定点。新的更新规则等同于变换器中使用的注意力机制。这种等同性使得变换器模型的头部特征化成为可能。这些头部在前几层中更倾向于进行全局平均，在更高层中通过亚稳态进行部分平均。这种新型现代霍普菲尔德网络可以作为层集成到深度学习架构中，以允许存储和访问原始输入数据、中间结果或学习到的原型。这些霍普菲尔德层为深度学习提供了超越全连接、卷积或循环网络的新方法，并提供了池化、记忆、关联和注意力机制。我们展示了霍普菲尔德层在各个领域的广泛适用性。霍普菲尔德层在四个考虑的多实例学习问题中的三个以及具有数十万个实例的免疫库分类上改进了最先进的技术。在UCI小分类任务基准集合上，深度学习方法通常难以应对，霍普菲尔德层与不同的机器学习方法相比，产生了新的最先进技术。最后，霍普菲尔德层在两个药物设计数据集上达到了最先进的水平。实现可在以下网址获取：https://github.com/ml-jku/hopfield-layers",
        "领域": "深度学习与注意力机制、多实例学习、药物设计",
        "问题": "如何提高模式存储和检索的效率及准确性，以及如何将霍普菲尔德网络集成到现代深度学习架构中",
        "动机": "探索霍普菲尔德网络在现代深度学习中的应用潜力，特别是在模式存储、检索及注意力机制方面的优势",
        "方法": "引入具有连续状态的现代霍普菲尔德网络及其更新规则，将其作为层集成到深度学习架构中，应用于多种学习任务",
        "关键词": [
            "霍普菲尔德网络",
            "注意力机制",
            "多实例学习",
            "药物设计",
            "深度学习"
        ],
        "涉及的技术概念": {
            "连续状态的霍普菲尔德网络": "一种能够存储与关联空间维度成指数级数量模式的现代霍普菲尔德网络",
            "注意力机制": "新的更新规则等同于变换器中使用的注意力机制，用于特征化变换器模型的头部",
            "能量最小值": "描述网络更新过程中的三种固定点状态，包括全局固定点、亚稳态和存储单个模式的固定点"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 341,
        "title": "Hopper: Multi-hop Transformer for Spatiotemporal Reasoning",
        "html": "https://iclr.cc//virtual/2021/poster/3260",
        "abstract": "This paper considers the problem of spatiotemporal object-centric reasoning in videos. Central to our approach is the notion of object permanence, i.e., the ability to reason about the location of objects as they move through the video while being occluded, contained or carried by other objects. Existing deep learning based approaches often suffer from spatiotemporal biases when applied to video reasoning problems. We propose Hopper, which uses a Multi-hop Transformer for reasoning object permanence in videos. Given a video and a localization query, Hopper reasons over image and object tracks to automatically hop over critical frames in an iterative fashion to predict the final position of the object of interest. We demonstrate the effectiveness of using a contrastive loss to reduce spatiotemporal biases. We evaluate over CATER dataset and find that Hopper achieves 73.2% Top-1 accuracy using just 1 FPS by hopping through just a few critical frames. We also demonstrate Hopper can perform long-term reasoning by building a CATER-h dataset that requires multi-step reasoning to localize objects of interest correctly.",
        "conference": "ICLR",
        "中文标题": "Hopper：用于时空推理的多跳Transformer",
        "摘要翻译": "本文探讨了视频中以对象为中心的时空推理问题。我们方法的核心是对象持久性的概念，即在对象被遮挡、包含或由其他对象携带时，能够推理出对象在视频中的位置。现有的基于深度学习的方法在应用于视频推理问题时常常受到时空偏差的影响。我们提出了Hopper，它使用多跳Transformer来推理视频中的对象持久性。给定一个视频和一个定位查询，Hopper通过图像和对象轨迹进行推理，以迭代方式自动跳过关键帧，预测感兴趣对象的最终位置。我们证明了使用对比损失减少时空偏差的有效性。我们在CATER数据集上进行了评估，发现Hopper仅通过跳过几个关键帧，以1 FPS的速度实现了73.2%的Top-1准确率。我们还通过构建需要多步推理来正确定位感兴趣对象的CATER-h数据集，展示了Hopper能够进行长期推理。",
        "领域": "视频理解、时空推理、对象跟踪",
        "问题": "解决视频中对象持久性推理的时空偏差问题",
        "动机": "提高视频中对象在遮挡、包含或携带情况下的位置推理能力",
        "方法": "使用多跳Transformer进行迭代式关键帧跳跃推理，结合对比损失减少偏差",
        "关键词": [
            "多跳Transformer",
            "对象持久性",
            "时空推理",
            "对比损失",
            "视频理解"
        ],
        "涉及的技术概念": {
            "多跳Transformer": "用于在视频中迭代跳过关键帧，进行对象持久性推理的Transformer架构",
            "对象持久性": "指在对象被遮挡、包含或由其他对象携带时，仍能推理其位置的能力",
            "对比损失": "用于减少模型在时空推理中的偏差，提高推理准确性的损失函数"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 342,
        "title": "How Benign is Benign Overfitting ?",
        "html": "https://iclr.cc//virtual/2021/poster/2955",
        "abstract": "We investigate two causes for adversarial vulnerability in deep neural networks: bad data and (poorly) trained models. When trained with SGD, deep neural networks essentially achieve zero training error, even in the presence of label noise, while also exhibiting good generalization on natural test data, something referred to as benign overfitting (Bartlett et al., 2020; Chatterji & Long, 2020).  However, these models are vulnerable to adversarial attacks. We identify label noise as one of the causes for adversarial vulnerability, and provide theoretical and empirical evidence in support of this. Surprisingly, we find several instances of label noise in datasets such as MNIST and CIFAR, and that robustly trained models incur training error on some of these, i.e. they don’t fit the noise. However, removing noisy labels alone does not suffice to achieve adversarial robustness. We conjecture that in part sub-optimal representation learning is also responsible for adversarial vulnerability. By means of simple theoretical setups, we show how the choice of representation can drastically affect adversarial robustness.",
        "conference": "ICLR",
        "中文标题": "良性过拟合究竟有多良性？",
        "摘要翻译": "我们研究了深度神经网络中对抗性脆弱性的两个原因：不良数据和（训练不足的）模型。当使用随机梯度下降（SGD）训练时，深度神经网络即使在存在标签噪声的情况下也能基本实现零训练误差，同时在自然测试数据上表现出良好的泛化能力，这种现象被称为良性过拟合（Bartlett等人，2020；Chatterji & Long，2020）。然而，这些模型容易受到对抗性攻击。我们将标签噪声识别为对抗性脆弱性的原因之一，并提供了理论和实证证据支持这一点。令人惊讶的是，我们在MNIST和CIFAR等数据集中发现了多个标签噪声的实例，并且经过稳健训练的模型在某些情况下会产生训练误差，即它们不拟合噪声。然而，仅去除噪声标签并不足以实现对抗性鲁棒性。我们推测，部分原因是次优的表示学习也是对抗性脆弱性的原因。通过简单的理论设置，我们展示了表示选择如何极大地影响对抗性鲁棒性。",
        "领域": "对抗性机器学习",
        "问题": "深度神经网络在训练过程中出现的良性过拟合现象及其对对抗性攻击的脆弱性",
        "动机": "探究深度神经网络在实现零训练误差和良好泛化能力的同时，为何仍易受对抗性攻击，并识别导致这种脆弱性的具体原因",
        "方法": "通过理论和实证分析，识别标签噪声和次优表示学习作为对抗性脆弱性的原因，并通过简单理论设置展示表示选择对对抗性鲁棒性的影响",
        "关键词": [
            "对抗性脆弱性",
            "良性过拟合",
            "标签噪声",
            "表示学习",
            "对抗性鲁棒性"
        ],
        "涉及的技术概念": {
            "良性过拟合": "指深度神经网络在训练数据上实现零误差同时在测试数据上表现良好的现象",
            "标签噪声": "训练数据中错误的标签，被识别为导致模型对抗性脆弱性的原因之一",
            "表示学习": "模型学习数据表示的过程，次优的表示学习被认为是导致对抗性脆弱性的另一个原因"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 343,
        "title": "How Does Mixup Help With Robustness and Generalization?",
        "html": "https://iclr.cc//virtual/2021/poster/2734",
        "abstract": "Mixup is a popular data augmentation technique based on on convex combinations of pairs of examples and their labels. This simple technique has shown to substantially improve both the model's robustness as well as the generalization of the trained model. However,  it is not well-understood why such improvement occurs. In this paper, we provide theoretical analysis to demonstrate how using Mixup in training helps model robustness and generalization. For robustness, we show that minimizing the Mixup loss corresponds to approximately minimizing an upper bound of the adversarial loss. This explains why models obtained by Mixup training exhibits robustness to several kinds of adversarial attacks such as Fast Gradient Sign Method (FGSM). For generalization, we prove that Mixup augmentation corresponds to a specific type of data-adaptive regularization which reduces overfitting. Our analysis provides new insights and a framework to understand Mixup.\n",
        "conference": "ICLR",
        "中文标题": "Mixup如何助力模型的鲁棒性和泛化能力？",
        "摘要翻译": "Mixup是一种流行的数据增强技术，基于对样本及其标签的凸组合。这一简单技术已被证明能显著提高模型的鲁棒性以及训练模型的泛化能力。然而，这种改进为何发生尚不十分清楚。在本文中，我们提供理论分析，以展示在训练中使用Mixup如何帮助模型的鲁棒性和泛化能力。对于鲁棒性，我们表明最小化Mixup损失大约相当于最小化对抗损失的上界。这解释了为何通过Mixup训练获得的模型对几种对抗攻击（如快速梯度符号法（FGSM））表现出鲁棒性。对于泛化能力，我们证明Mixup增强对应于一种特定类型的数据自适应正则化，减少了过拟合。我们的分析提供了新的见解和一个理解Mixup的框架。",
        "领域": "数据增强、模型鲁棒性、泛化能力",
        "问题": "理解Mixup数据增强技术为何能提高模型的鲁棒性和泛化能力",
        "动机": "探索Mixup技术背后的理论机制，解释其在提高模型鲁棒性和泛化能力方面的有效性",
        "方法": "通过理论分析，展示Mixup在训练中如何对应于最小化对抗损失的上界和实现数据自适应正则化",
        "关键词": [
            "Mixup",
            "数据增强",
            "模型鲁棒性",
            "泛化能力",
            "对抗攻击"
        ],
        "涉及的技术概念": {
            "Mixup": "一种数据增强技术，通过样本及其标签的凸组合来提高模型的鲁棒性和泛化能力",
            "对抗损失": "用于衡量模型对对抗攻击的脆弱性，Mixup通过最小化其上限来提高鲁棒性",
            "数据自适应正则化": "Mixup实现的一种正则化形式，通过减少过拟合来提高模型的泛化能力"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 344,
        "title": "How Much Over-parameterization Is Sufficient to Learn Deep ReLU Networks?",
        "html": "https://iclr.cc//virtual/2021/poster/2621",
        "abstract": "A recent line of research on deep learning focuses on the extremely over-parameterized setting, and shows that when the network width is larger than a high degree polynomial of the training sample size $n$ and the inverse of the target error $\\epsilon^{-1}$, deep neural networks learned by (stochastic) gradient descent enjoy nice optimization and generalization guarantees. Very recently, it is shown that under certain margin assumptions on the training data, a polylogarithmic width condition suffices for two-layer ReLU networks to converge and generalize (Ji and Telgarsky, 2020). However, whether deep neural networks can be learned with such a mild over-parameterization is still an open question. In this work, we answer this question affirmatively and establish sharper learning guarantees for deep ReLU networks trained by (stochastic) gradient descent. In specific, under certain assumptions made in previous work, our optimization and generalization guarantees hold with network width polylogarithmic in $n$ and $\\epsilon^{-1}$. Our results push the study of over-parameterized deep neural networks towards more practical settings.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "学习深度ReLU网络需要多少过度参数化？",
        "摘要翻译": "最近关于深度学习的一系列研究集中在极度过度参数化的设置上，并表明当网络宽度大于训练样本大小n和目标误差的倒数epsilon^{-1}的高度多项式时，通过（随机）梯度下降学习的深度神经网络具有良好的优化和泛化保证。最近，研究表明，在训练数据的某些边缘假设下，对数多项式宽度条件足以使两层ReLU网络收敛和泛化（Ji and Telgarsky，2020）。然而，深度神经网络是否可以在如此温和的过度参数化下学习仍然是一个悬而未决的问题。在这项工作中，我们肯定地回答了这个问题，并为通过（随机）梯度下降训练的深度ReLU网络建立了更清晰的学习保证。具体而言，在先前工作中做出的一些假设下，我们的优化和泛化保证在网络宽度上以n和epsilon^{-1}的多对数形式成立。我们的结果将过度参数化深度神经网络的研究推向了更实际的设置。",
        "领域": "神经网络优化, 泛化理论, 深度学习理论",
        "问题": "确定学习深度ReLU网络所需的最小过度参数化程度，即在保证优化和泛化性能的前提下，网络宽度需要多大？",
        "动机": "现有的深度学习理论研究主要关注极度过度参数化的场景，但在实际应用中，这种过度参数化是不现实的。因此，研究更温和的过度参数化条件，并证明深度网络在这种条件下也能有效学习，具有重要的理论和实践意义。",
        "方法": "通过理论分析，在一定的假设条件下，证明了深度ReLU网络在网络宽度为训练样本大小和目标误差的倒数的多对数函数时，仍然可以通过（随机）梯度下降进行有效学习。",
        "关键词": [
            "过度参数化",
            "深度ReLU网络",
            "梯度下降",
            "泛化保证",
            "网络宽度"
        ],
        "涉及的技术概念": {
            "ReLU激活函数": "ReLU（Rectified Linear Unit）激活函数：深度神经网络中常用的激活函数，具有计算简单、能够缓解梯度消失等优点。本论文研究使用ReLU激活函数的深度神经网络的学习理论。",
            "过度参数化": "过度参数化：指神经网络的参数数量远大于训练样本数量的现象。适当的过度参数化有助于神经网络的优化和泛化。本论文研究在保证网络有效学习的前提下，所需的最小过度参数化程度。"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 345,
        "title": "How Neural Networks Extrapolate: From Feedforward to Graph Neural Networks",
        "html": "https://iclr.cc//virtual/2021/poster/3229",
        "abstract": "We study how neural networks trained by gradient descent  extrapolate, i.e., what they learn outside the support of the training distribution. Previous works report mixed empirical results when extrapolating with neural networks: while feedforward neural networks, a.k.a. multilayer perceptrons (MLPs), do not extrapolate well in certain simple tasks, Graph Neural Networks (GNNs) -- structured networks with MLP modules -- have shown some success in more complex tasks.  Working towards a theoretical explanation, we identify conditions under which MLPs and GNNs extrapolate well. First, we quantify the observation that ReLU MLPs quickly converge to linear functions along any direction from the origin, which implies that ReLU MLPs do not extrapolate most nonlinear functions. But, they can provably learn a linear target function when the training distribution is sufficiently diverse. Second, in connection to analyzing the successes and limitations of GNNs, these results suggest a hypothesis for which we provide theoretical and empirical evidence: the success of GNNs in extrapolating algorithmic tasks to new data (e.g., larger graphs or edge weights) relies on encoding task-specific non-linearities in the architecture or features. Our theoretical analysis builds on a connection of over-parameterized networks to the neural tangent kernel.  Empirically, our theory holds across different training settings.",
        "conference": "ICLR",
        "中文标题": "神经网络如何外推：从前馈神经网络到图神经网络",
        "摘要翻译": "我们研究了通过梯度下降训练的神经网络如何进行外推，即它们在训练分布支持之外学习什么。先前的工作在神经网络外推方面报告了混合的实证结果：虽然前馈神经网络，也称为多层感知机（MLPs），在某些简单任务中表现不佳，但图神经网络（GNNs）——具有MLP模块的结构化网络——在更复杂的任务中显示出了一定的成功。为了寻求理论解释，我们确定了MLPs和GNNs外推表现良好的条件。首先，我们量化了ReLU MLPs沿任何从原点出发的方向快速收敛到线性函数的观察结果，这意味着ReLU MLPs不能外推大多数非线性函数。但是，当训练分布足够多样化时，它们可以证明学习线性目标函数。其次，在分析GNNs成功和局限性的过程中，这些结果提出了一个假设，我们为此提供了理论和实证证据：GNNs在将算法任务外推到新数据（例如，更大的图或边权重）方面的成功依赖于在架构或特征中编码任务特定的非线性。我们的理论分析建立在过参数化网络与神经切线核的联系上。实证上，我们的理论在不同的训练设置中都成立。",
        "领域": "深度学习理论、图神经网络、算法外推",
        "问题": "研究神经网络在训练分布之外的数据上的外推能力及其条件。",
        "动机": "理解并解释神经网络，特别是MLPs和GNNs，在不同条件下外推能力的差异及其背后的原因。",
        "方法": "通过理论分析和实证研究，探讨ReLU MLPs和GNNs在外推任务中的表现，并基于神经切线核理论建立理论框架。",
        "关键词": [
            "外推能力",
            "图神经网络",
            "多层感知机",
            "神经切线核",
            "算法任务"
        ],
        "涉及的技术概念": {
            "ReLU MLPs": "使用ReLU激活函数的多层感知机，研究其在非线性函数外推中的局限性。",
            "图神经网络（GNNs）": "结构化网络，具有MLP模块，研究其在复杂任务中成功外推的能力。",
            "神经切线核": "理论分析工具，用于理解过参数化网络的行为及其在外推任务中的应用。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 346,
        "title": "How to Find Your Friendly Neighborhood: Graph Attention Design with Self-Supervision",
        "html": "https://iclr.cc//virtual/2021/poster/2604",
        "abstract": "Attention mechanism in graph neural networks is designed to assign larger weights to important neighbor nodes for better representation. However, what graph attention learns is not understood well, particularly when graphs are noisy. In this paper, we propose a self-supervised graph attention network (SuperGAT), an improved graph attention model for noisy graphs. Specifically, we exploit two attention forms compatible with a self-supervised task to predict edges, whose presence and absence contain the inherent information about the importance of the relationships between nodes. By encoding edges, SuperGAT learns more expressive attention in distinguishing mislinked neighbors. We find two graph characteristics influence the effectiveness of attention forms and self-supervision: homophily and average degree. Thus, our recipe provides guidance on which attention design to use when those two graph characteristics are known. Our experiment on 17 real-world datasets demonstrates that our recipe generalizes across 15 datasets of them, and our models designed by recipe show improved performance over baselines.",
        "conference": "ICLR",
        "中文标题": "如何找到你的友好邻居：基于自监督的图注意力设计",
        "摘要翻译": "图神经网络中的注意力机制旨在为重要的邻居节点分配更大的权重，以获得更好的表示。然而，图注意力学习的内容尚未被充分理解，尤其是在图数据存在噪声的情况下。本文提出了一种自监督图注意力网络（SuperGAT），这是一种针对噪声图改进的图注意力模型。具体来说，我们利用两种与自监督任务兼容的注意力形式来预测边，边的存在与否包含了节点间关系重要性的固有信息。通过编码边，SuperGAT在学习区分错误连接的邻居时能够表达出更具表现力的注意力。我们发现两种图特性影响注意力形式及自监督的有效性：同质性和平均度数。因此，我们的方法提供了在这两种图特性已知时选择哪种注意力设计的指导。我们在17个真实世界数据集上的实验表明，我们的方法在其中的15个数据集上具有普适性，并且根据我们的方法设计的模型在性能上优于基线模型。",
        "领域": "图神经网络、自监督学习、图表示学习",
        "问题": "在图数据存在噪声的情况下，如何设计有效的图注意力机制以更好地理解节点间的关系。",
        "动机": "解决图注意力机制在噪声图数据中学习内容不明确的问题，提升图神经网络在噪声环境下的表现。",
        "方法": "提出自监督图注意力网络（SuperGAT），利用两种与自监督任务兼容的注意力形式预测边，通过编码边学习更具表现力的注意力，同时考虑图的同质性和平均度数特性。",
        "关键词": [
            "图注意力网络",
            "自监督学习",
            "噪声图",
            "同质性",
            "平均度数"
        ],
        "涉及的技术概念": {
            "图注意力网络": "用于为图中的重要邻居节点分配更大权重的机制，以提升图表示的质量。",
            "自监督学习": "通过设计预测边的自监督任务，利用边的存在与否信息来指导注意力机制的学习。",
            "同质性和平均度数": "影响注意力形式及自监督有效性的两种图特性，用于指导注意力设计的选择。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 347,
        "title": "Human-Level Performance in No-Press Diplomacy via Equilibrium Search",
        "html": "https://iclr.cc//virtual/2021/poster/2843",
        "abstract": "Prior AI breakthroughs in complex games have focused on either the purely adversarial or purely cooperative settings. In contrast, Diplomacy is a game of shifting alliances that involves both cooperation and competition. For this reason, Diplomacy has proven to be a formidable research challenge. In this paper we describe an agent for the no-press variant of Diplomacy that combines supervised learning on human data with one-step lookahead search via regret minimization. Regret minimization techniques have been behind previous AI successes in adversarial games, most notably poker, but have not previously been shown to be successful in large-scale games involving cooperation. We show that our agent greatly exceeds the performance of past no-press Diplomacy bots, is unexploitable by expert humans, and ranks in the top 2% of human players when playing anonymous games on a popular Diplomacy website.",
        "conference": "ICLR",
        "中文标题": "通过均衡搜索实现无交流外交游戏中的人类水平表现",
        "摘要翻译": "先前AI在复杂游戏中的突破主要集中在纯对抗性或纯合作性场景。相比之下，外交游戏是一个涉及合作与竞争的联盟变换游戏。因此，外交游戏已被证明是一个艰巨的研究挑战。在本文中，我们描述了一个用于无交流外交游戏变体的智能体，该智能体结合了基于人类数据的监督学习和通过遗憾最小化的一步前瞻搜索。遗憾最小化技术曾是AI在对抗性游戏中取得成功的关键，尤其是在扑克游戏中，但此前未在涉及合作的大规模游戏中显示出成功。我们表明，我们的智能体大大超过了过去的无交流外交游戏机器人的性能，不会被人类专家利用，并且在流行外交游戏网站上的匿名游戏中排名前2%的人类玩家之中。",
        "领域": "多智能体系统、博弈论、强化学习",
        "问题": "解决在涉及合作与竞争的无交流外交游戏中实现人类水平表现的问题",
        "动机": "探索在联盟变换游戏中结合合作与竞争的AI性能，扩展遗憾最小化技术的应用范围",
        "方法": "结合基于人类数据的监督学习和通过遗憾最小化的一步前瞻搜索",
        "关键词": [
            "无交流外交游戏",
            "遗憾最小化",
            "监督学习",
            "均衡搜索",
            "多智能体系统"
        ],
        "涉及的技术概念": {
            "遗憾最小化": "用于优化智能体在游戏中的决策策略，以减少未来可能的遗憾",
            "监督学习": "利用人类游戏数据训练智能体，以模仿人类玩家的行为模式",
            "均衡搜索": "通过搜索策略均衡点来优化智能体的决策，特别是在涉及合作与竞争的场景中"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 348,
        "title": "HW-NAS-Bench: Hardware-Aware Neural Architecture Search Benchmark",
        "html": "https://iclr.cc//virtual/2021/poster/3199",
        "abstract": "HardWare-aware Neural Architecture Search (HW-NAS) has recently gained tremendous attention by automating the design of deep neural networks deployed in more resource-constrained daily life devices. Despite its promising performance, developing optimal HW-NAS solutions can be prohibitively challenging as it requires cross-disciplinary knowledge in the algorithm, micro-architecture, and device-specific compilation. First, to determine the hardware-cost to be incorporated into the NAS process, existing works mostly adopt either pre-collected hardware-cost look-up tables or device-specific hardware-cost models. The former can be time-consuming due to the required knowledge of the device’s compilation method and how to set up the measurement pipeline, while building the latter is often a barrier for non-hardware experts like NAS researchers. Both of them limit the development of HW-NAS innovations and impose a barrier-to-entry to non-hardware experts. Second, similar to generic NAS, it can be notoriously difficult to benchmark HW-NAS algorithms due to their significant required computational resources and the differences in adopted search spaces, hyperparameters, and hardware devices. To this end, we develop HW-NAS-Bench, the first public dataset for HW-NAS research which aims to democratize HW-NAS research to non-hardware experts and make HW-NAS research more reproducible and accessible. To design HW-NAS-Bench, we carefully collected the measured/estimated hardware performance (e.g., energy cost and latency) of all the networks in the search spaces of both NAS-Bench-201 and FBNet, on six hardware devices that fall into three categories (i.e., commercial edge devices, FPGA, and ASIC). Furthermore, we provide a comprehensive analysis of the collected measurements in HW-NAS-Bench to provide insights for HW-NAS research. Finally, we demonstrate exemplary user cases to (1) show that HW-NAS-Bench allows non-hardware experts to perform HW-NAS by simply querying our pre-measured dataset and (2) verify that dedicated device-specific HW-NAS can indeed lead to optimal accuracy-cost trade-offs. The codes and all collected data are available at https://github.com/RICE-EIC/HW-NAS-Bench.",
        "conference": "ICLR",
        "中文标题": "HW-NAS-Bench：硬件感知的神经架构搜索基准",
        "摘要翻译": "硬件感知的神经架构搜索（HW-NAS）最近因其能够自动化设计部署在资源受限的日常设备中的深度神经网络而获得了极大的关注。尽管其性能前景广阔，但开发最优的HW-NAS解决方案可能极具挑战性，因为它需要算法、微架构和设备特定编译的跨学科知识。首先，为了确定要纳入NAS过程的硬件成本，现有工作大多采用预先收集的硬件成本查找表或设备特定的硬件成本模型。前者由于需要了解设备的编译方法以及如何设置测量管道而可能耗时，而构建后者对于非硬件专家如NAS研究人员来说往往是一个障碍。这两者都限制了HW-NAS创新的发展，并对非硬件专家设置了入门障碍。其次，与通用NAS类似，由于HW-NAS算法需要大量的计算资源以及采用的搜索空间、超参数和硬件设备的差异，对其进行基准测试可能非常困难。为此，我们开发了HW-NAS-Bench，这是第一个用于HW-NAS研究的公共数据集，旨在使HW-NAS研究对非硬件专家民主化，并使HW-NAS研究更具可重复性和可访问性。为了设计HW-NAS-Bench，我们仔细收集了NAS-Bench-201和FBNet搜索空间中所有网络在六种属于三类（即商业边缘设备、FPGA和ASIC）的硬件设备上的测量/估计硬件性能（例如，能源成本和延迟）。此外，我们对HW-NAS-Bench中收集的测量数据进行了全面分析，为HW-NAS研究提供了见解。最后，我们展示了示例用户案例，以（1）表明HW-NAS-Bench允许非硬件专家通过简单查询我们预先测量的数据集来执行HW-NAS，（2）验证专用的设备特定HW-NAS确实可以导致最优的准确性-成本权衡。代码和所有收集的数据可在https://github.com/RICE-EIC/HW-NAS-Bench获取。",
        "领域": "神经架构搜索、硬件感知优化、深度学习部署",
        "问题": "解决硬件感知神经架构搜索（HW-NAS）中的硬件成本测量和算法基准测试难题",
        "动机": "降低HW-NAS研究的门槛，使其对非硬件专家更加可访问和可重复",
        "方法": "开发HW-NAS-Bench数据集，包含多种硬件设备上的网络性能测量数据，并提供分析工具和用户案例",
        "关键词": [
            "硬件感知",
            "神经架构搜索",
            "基准测试",
            "深度学习部署",
            "资源优化"
        ],
        "涉及的技术概念": {
            "硬件感知神经架构搜索（HW-NAS）": "一种考虑硬件性能指标（如能源成本和延迟）的神经架构搜索方法，旨在自动化设计适合特定硬件设备的深度神经网络",
            "硬件成本模型": "用于预测或测量神经网络在特定硬件上运行时的性能指标（如能源消耗和执行时间）的模型",
            "基准测试": "通过标准化方法评估和比较不同HW-NAS算法性能的过程，确保研究结果的可重复性和公平性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 349,
        "title": "Hyperbolic Neural Networks++",
        "html": "https://iclr.cc//virtual/2021/poster/3337",
        "abstract": "Hyperbolic spaces, which have the capacity to embed tree structures without distortion owing to their exponential volume growth, have recently been applied to machine learning to better capture the hierarchical nature of data. In this study, we generalize the fundamental components of neural networks in a single hyperbolic geometry model, namely, the Poincaré ball model. This novel methodology constructs a multinomial logistic regression, fully-connected layers, convolutional layers, and attention mechanisms under a unified mathematical interpretation, without increasing the parameters. Experiments show the superior parameter efficiency of our methods compared to conventional hyperbolic components, and stability and outperformance over their Euclidean counterparts.",
        "conference": "ICLR",
        "中文标题": "双曲神经网络++",
        "摘要翻译": "双曲空间由于其指数级的体积增长能力，能够无失真地嵌入树结构，最近被应用于机器学习中，以更好地捕捉数据的层次性质。在本研究中，我们在单一的双曲几何模型——即庞加莱球模型中，推广了神经网络的基本组件。这一新方法在统一的数学解释下构建了多项逻辑回归、全连接层、卷积层和注意力机制，且不增加参数。实验表明，与传统的双曲组件相比，我们的方法在参数效率上具有优势，并且相较于其欧几里得对应物，表现更为稳定和优越。",
        "领域": "深度学习与几何学习结合、图神经网络、注意力机制",
        "问题": "如何在双曲空间中有效地构建和优化神经网络组件，以更好地处理具有层次结构的数据。",
        "动机": "利用双曲空间的特性来更有效地表示和处理具有层次结构的数据，同时保持或提升神经网络的性能和参数效率。",
        "方法": "在庞加莱球模型中统一构建多项逻辑回归、全连接层、卷积层和注意力机制，不增加额外参数。",
        "关键词": [
            "双曲神经网络",
            "庞加莱球模型",
            "层次数据处理",
            "参数效率",
            "几何深度学习"
        ],
        "涉及的技术概念": {
            "双曲空间": "用于无失真嵌入树结构的数据表示空间，因其指数级体积增长特性适合表示层次结构。",
            "庞加莱球模型": "本研究采用的双曲几何模型，用于统一构建和解释神经网络的各种组件。",
            "注意力机制": "在双曲空间中构建的注意力机制，用于增强模型对数据层次结构的捕捉能力。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 350,
        "title": "HyperDynamics: Meta-Learning Object and Agent Dynamics with Hypernetworks",
        "html": "https://iclr.cc//virtual/2021/poster/3305",
        "abstract": "We propose HyperDynamics, a dynamics meta-learning framework that conditions on an agent’s interactions with the environment and optionally its visual observations, and generates the parameters of neural dynamics models based on inferred properties of the dynamical system. Physical and visual properties of the environment that are not part of the low-dimensional state yet affect its temporal dynamics are inferred from the interaction history and visual observations, and are implicitly captured in the generated parameters. We test HyperDynamics on a set of object pushing and locomotion tasks. It outperforms existing dynamics models in the literature that adapt to environment variations by learning dynamics over high dimensional visual observations, capturing the interactions of the agent in recurrent state representations, or using gradient-based meta-optimization. We also show our method matches the performance of an ensemble of separately trained experts, while also being able to generalize well to unseen environment variations at test time. We attribute its good performance to the multiplicative interactions between the inferred system properties—captured in the generated parameters—and the low-dimensional state representation of the dynamical system.",
        "conference": "ICLR",
        "中文标题": "HyperDynamics：利用超网络进行对象与代理动态的元学习",
        "摘要翻译": "我们提出了HyperDynamics，一个动态元学习框架，该框架基于代理与环境的交互及其视觉观察（可选），并根据推断出的动态系统属性生成神经动态模型的参数。环境中未包含在低维状态中但影响其时间动态的物理和视觉属性，从交互历史和视觉观察中推断出来，并隐含地捕获在生成的参数中。我们在对象推动和运动任务集上测试了HyperDynamics。它在适应环境变化方面优于文献中现有的动态模型，这些模型通过学习高维视觉观察的动态、在循环状态表示中捕获代理的交互或使用基于梯度的元优化来适应环境变化。我们还展示了我们的方法匹配了分别训练的专家集合的性能，同时还能在测试时很好地泛化到未见过的环境变化。我们将其良好的性能归因于推断的系统属性（在生成的参数中捕获）与动态系统的低维状态表示之间的乘法交互。",
        "领域": "元学习、动态系统建模、视觉与动态结合",
        "问题": "如何有效地从代理与环境的交互中学习并适应动态系统的变化",
        "动机": "为了解决现有动态模型在适应环境变化方面的不足，特别是在处理高维视觉观察和未见过的环境变化时的性能问题",
        "方法": "提出了一个基于超网络的动态元学习框架，通过推断动态系统的属性并生成神经动态模型的参数，来适应环境的变化",
        "关键词": [
            "元学习",
            "动态系统建模",
            "超网络",
            "视觉观察",
            "环境适应"
        ],
        "涉及的技术概念": {
            "超网络": "用于生成神经动态模型参数的网络，能够根据推断出的动态系统属性调整模型",
            "元学习": "通过学习如何学习，使模型能够快速适应新的任务或环境变化",
            "动态系统建模": "对随时间变化的系统行为进行建模，特别是在代理与环境的交互中"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 351,
        "title": "HyperGrid Transformers: Towards A Single Model for Multiple Tasks",
        "html": "https://iclr.cc//virtual/2021/poster/2967",
        "abstract": "Achieving state-of-the-art performance on natural language understanding tasks typically relies on fine-tuning a fresh model for every task. Consequently, this approach leads to a higher overall parameter cost, along with higher technical maintenance for serving multiple models. Learning a single multi-task model that is able to do well for all the tasks has been a challenging and yet attractive proposition. In this paper, we propose HyperGrid Transformers, a new Transformer architecture that leverages task-conditioned hyper networks for controlling its feed-forward layers. Specifically, we propose a decomposable hypernetwork that learns grid-wise projections that help to specialize regions in weight matrices for different tasks. In order to construct the proposed hypernetwork, our method learns the interactions and composition between a global (task-agnostic) state and a local task-specific state. We conduct an extensive set of experiments on GLUE/SuperGLUE. On the SuperGLUE test set, we match the performance of the state-of-the-art while being $16$ times more parameter efficient. Our method helps bridge the gap between fine-tuning and multi-task learning approaches.",
        "conference": "ICLR",
        "中文标题": "超网格变换器：迈向单一模型处理多任务",
        "摘要翻译": "在自然语言理解任务上实现最先进的性能通常依赖于为每个任务微调一个新模型。因此，这种方法导致了更高的总体参数成本，以及为服务多个模型带来的更高技术维护。学习一个能够对所有任务表现良好的单一多任务模型一直是一个具有挑战性但又吸引人的提议。在本文中，我们提出了超网格变换器，一种新的变换器架构，它利用任务条件超网络来控制其前馈层。具体来说，我们提出了一种可分解的超网络，它学习网格化投影，帮助为不同任务专门化权重矩阵中的区域。为了构建所提出的超网络，我们的方法学习了全局（任务无关）状态和局部任务特定状态之间的相互作用和组合。我们在GLUE/SuperGLUE上进行了广泛的实验。在SuperGLUE测试集上，我们匹配了最先进技术的性能，同时参数效率提高了16倍。我们的方法有助于缩小微调和多任务学习方法之间的差距。",
        "领域": "自然语言处理与视觉结合、多任务学习、模型效率优化",
        "问题": "如何通过单一模型高效处理多个自然语言理解任务，减少参数成本和技术维护需求",
        "动机": "解决为每个任务单独微调模型导致的高参数成本和技术维护问题，探索单一模型处理多任务的可行性",
        "方法": "提出超网格变换器架构，利用任务条件超网络控制前馈层，通过可分解超网络学习网格化投影，专门化权重矩阵区域以适应不同任务",
        "关键词": [
            "超网格变换器",
            "多任务学习",
            "参数效率",
            "自然语言理解",
            "超网络"
        ],
        "涉及的技术概念": {
            "超网格变换器": "一种新的变换器架构，利用任务条件超网络控制前馈层，实现多任务处理",
            "任务条件超网络": "用于根据任务动态调整模型参数的网络，使单一模型能够适应多种任务",
            "网格化投影": "通过可分解超网络学习，专门化权重矩阵中的区域，以适应不同任务的需求"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 352,
        "title": "Identifying nonlinear dynamical systems with multiple time scales and long-range dependencies",
        "html": "https://iclr.cc//virtual/2021/poster/3338",
        "abstract": "A main theoretical interest in biology and physics is to identify the nonlinear dynamical system (DS) that generated observed time series. Recurrent Neural Networks (RNN) are, in principle, powerful enough to approximate any underlying DS, but in their vanilla form suffer from the exploding vs. vanishing gradients problem. Previous attempts to alleviate this problem resulted either in more complicated, mathematically less tractable RNN architectures, or strongly limited the dynamical expressiveness of the RNN. \nHere we address this issue by suggesting a simple regularization scheme for vanilla RNN with ReLU activation which enables them to solve long-range dependency problems and express slow time scales, while retaining a simple mathematical structure which makes their DS properties partly analytically accessible. We prove two theorems that establish a tight connection between the regularized RNN dynamics and their gradients, illustrate on DS benchmarks that our regularization approach strongly eases the reconstruction of DS which harbor widely differing time scales, and show that our method is also en par with other long-range architectures like LSTMs on several tasks.",
        "conference": "ICLR",
        "中文标题": "识别具有多时间尺度和长程依赖性的非线性动力系统",
        "摘要翻译": "生物学和物理学中的一个主要理论兴趣是识别生成观测时间序列的非线性动力系统（DS）。循环神经网络（RNN）原则上足够强大，可以近似任何潜在的DS，但在其原始形式下，它们遭受梯度爆炸或消失的问题。之前尝试缓解这一问题的方法要么导致了更复杂、数学上更难以处理的RNN架构，要么严重限制了RNN的动态表达能力。在这里，我们通过为具有ReLU激活的原始RNN提出一个简单的正则化方案来解决这个问题，该方案使它们能够解决长程依赖问题并表达慢时间尺度，同时保留了一个简单的数学结构，这使得它们的DS属性部分可以通过分析获得。我们证明了两个定理，这些定理建立了正则化RNN动态与其梯度之间的紧密联系，在DS基准上说明了我们的正则化方法极大地简化了包含广泛不同时间尺度的DS的重建，并展示了我们的方法在几项任务上也与其他长程架构（如LSTMs）相当。",
        "领域": "非线性动力系统识别、循环神经网络、时间序列分析",
        "问题": "解决循环神经网络在处理多时间尺度和长程依赖性问题时的梯度爆炸或消失问题",
        "动机": "提高循环神经网络在识别非线性动力系统中的表现，尤其是在处理多时间尺度和长程依赖性时，同时保持模型的数学简洁性和可解析性",
        "方法": "提出了一种简单的正则化方案，用于具有ReLU激活的原始循环神经网络，以解决长程依赖问题和表达慢时间尺度",
        "关键词": [
            "非线性动力系统",
            "循环神经网络",
            "正则化",
            "长程依赖",
            "时间尺度"
        ],
        "涉及的技术概念": {
            "正则化": "用于防止模型过拟合或解决特定问题（如梯度爆炸或消失）的技术，通过添加额外的约束或惩罚项来调整模型的学习过程",
            "ReLU激活": "一种常用的神经网络激活函数，有助于解决梯度消失问题，同时保持计算的高效性",
            "长程依赖": "指在时间序列或序列数据中，当前状态与远距离过去状态之间的依赖关系，这对于循环神经网络来说是一个挑战"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 353,
        "title": "Identifying Physical Law of Hamiltonian Systems via Meta-Learning",
        "html": "https://iclr.cc//virtual/2021/poster/3130",
        "abstract": "Hamiltonian mechanics is an effective tool to represent many physical processes with concise yet well-generalized mathematical expressions. A well-modeled Hamiltonian makes it easy for researchers to analyze and forecast many related phenomena that are governed by the same physical law. However, in general, identifying a functional or shared expression of the Hamiltonian is very difficult. It requires carefully designed experiments and the researcher's insight that comes from years of experience. We propose that meta-learning algorithms can be potentially powerful data-driven tools for identifying the physical law governing Hamiltonian systems without any mathematical assumptions on the representation, but with observations from a set of systems governed by the same physical law. We show that a well meta-trained learner can identify the shared representation of the Hamiltonian by evaluating our method on several types of physical systems with various experimental settings.",
        "conference": "ICLR",
        "中文标题": "通过元学习识别哈密顿系统的物理定律",
        "摘要翻译": "哈密顿力学是一种有效的工具，能够用简洁且具有良好泛化性的数学表达式表示许多物理过程。一个良好建模的哈密顿量使研究人员能够轻松分析和预测由相同物理定律支配的许多相关现象。然而，一般来说，识别哈密顿量的函数或共享表达式非常困难。它需要精心设计的实验和研究人员多年经验积累的洞察力。我们提出，元学习算法可能是强大的数据驱动工具，用于识别支配哈密顿系统的物理定律，而无需对表示形式进行任何数学假设，只需观察由相同物理定律支配的一组系统。我们通过在各种实验设置下对几种类型的物理系统评估我们的方法，展示了一个经过良好元训练的学习者能够识别哈密顿量的共享表示。",
        "领域": "物理系统建模、元学习应用、哈密顿力学",
        "问题": "如何在没有数学假设的情况下，通过数据驱动的方法识别哈密顿系统的物理定律",
        "动机": "解决传统方法在识别哈密顿量函数或共享表达式时面临的困难，减少对精心设计实验和专家经验的依赖",
        "方法": "采用元学习算法，通过观察由相同物理定律支配的一组系统，无需数学假设即可识别哈密顿系统的物理定律",
        "关键词": [
            "元学习",
            "哈密顿系统",
            "物理定律识别",
            "数据驱动方法",
            "物理系统建模"
        ],
        "涉及的技术概念": {
            "元学习": "用于从多个相关任务中学习，以提高在新任务上的学习效率和性能",
            "哈密顿力学": "提供了一种描述物理系统动态的框架，通过哈密顿量表示系统的总能量",
            "物理定律识别": "指通过数据驱动的方法自动发现支配物理系统行为的数学规律或定律"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 354,
        "title": "IDF++: Analyzing and Improving Integer Discrete Flows for Lossless Compression",
        "html": "https://iclr.cc//virtual/2021/poster/2779",
        "abstract": "In this paper we analyse and improve integer discrete flows for lossless compression. Integer discrete flows are a recently proposed class of models that learn invertible transformations for integer-valued random variables. Their discrete nature makes them particularly suitable for lossless compression with entropy coding schemes. We start by investigating a recent theoretical claim that states that invertible flows for discrete random variables are less flexible than their continuous counterparts. We demonstrate with a proof that this claim does not hold for integer discrete flows due to the embedding of data with finite support into the countably infinite integer lattice. Furthermore, we zoom in on the effect of gradient bias due to the straight-through estimator in integer discrete flows, and demonstrate that its influence is highly dependent on architecture choices and less prominent than previously thought. Finally, we show how different architecture modifications improve the performance of this model class for lossless compression, and that they also enable more efficient compression: a model with half the number of flow layers performs on par with or better than the original integer discrete flow model.",
        "conference": "ICLR",
        "中文标题": "IDF++：分析与改进用于无损压缩的整数离散流",
        "摘要翻译": "本文中，我们分析并改进了用于无损压缩的整数离散流。整数离散流是最近提出的一类模型，它们学习整数值随机变量的可逆变换。其离散特性使它们特别适合与熵编码方案一起用于无损压缩。我们首先研究了一个最近的理论主张，该主张指出离散随机变量的可逆流比其连续对应物灵活性低。我们通过证明表明，由于将有限支持的数据嵌入到可数无限的整数格中，这一主张对整数离散流不成立。此外，我们深入研究了由于整数离散流中的直通估计器导致的梯度偏差效应，并证明其影响高度依赖于架构选择，且不如之前认为的那样显著。最后，我们展示了不同的架构修改如何提高此类模型在无损压缩中的性能，并且它们还实现了更高效的压缩：一个流层数减半的模型表现与原整数离散流模型相当或更好。",
        "领域": "无损压缩、深度学习模型优化、熵编码",
        "问题": "分析和改进整数离散流在无损压缩中的应用效果和效率",
        "动机": "探索整数离散流在无损压缩中的潜力，解决其灵活性和效率问题",
        "方法": "通过理论证明和实验分析，研究整数离散流的灵活性、梯度偏差效应，并通过架构修改提升性能",
        "关键词": [
            "整数离散流",
            "无损压缩",
            "熵编码",
            "梯度偏差",
            "架构优化"
        ],
        "涉及的技术概念": {
            "整数离散流": "一类学习整数值随机变量可逆变换的模型，特别适合无损压缩",
            "直通估计器": "用于处理离散变量的梯度估计方法，可能导致梯度偏差",
            "熵编码": "一种利用数据统计特性进行高效编码的技术，与整数离散流结合用于无损压缩"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 355,
        "title": "IEPT: Instance-Level and Episode-Level Pretext Tasks for Few-Shot Learning",
        "html": "https://iclr.cc//virtual/2021/poster/2770",
        "abstract": "The need of collecting large quantities of labeled training data for each new task has limited the usefulness of deep neural networks. Given data from a set of source tasks, this limitation can be overcome using two transfer learning approaches: few-shot learning (FSL) and self-supervised learning (SSL). The former aims to learn `how to learn' by designing learning episodes using source tasks to simulate the challenge of solving the target new task with few labeled samples. In contrast, the latter exploits an annotation-free pretext task across all source tasks in order to learn generalizable feature representations. In this work, we propose a novel Instance-level and Episode-level Pretext Task (IEPT) framework that seamlessly integrates SSL into FSL. Specifically, given an FSL episode, we first apply geometric transformations to each instance to generate extended episodes. At the instance-level, transformation recognition is performed as per standard SSL. Importantly, at the episode-level, two SSL-FSL hybrid learning objectives are devised: (1) The consistency across the predictions of an FSL classifier from different extended episodes is maximized as an episode-level pretext task. (2) The features extracted from each instance across different episodes are integrated to construct a single FSL classifier for meta-learning. Extensive experiments show that our proposed model (i.e., FSL with IEPT) achieves the new state-of-the-art. ",
        "conference": "ICLR",
        "中文标题": "IEPT：面向少样本学习的实例级与片段级前置任务",
        "摘要翻译": "为每个新任务收集大量标记训练数据的需求限制了深度神经网络的实用性。给定来自一组源任务的数据，可以通过两种迁移学习方法来克服这一限制：少样本学习（FSL）和自监督学习（SSL）。前者旨在通过设计使用源任务的学习片段来模拟用少量标记样本解决目标新任务的挑战，从而学习‘如何学习’。相比之下，后者利用所有源任务中的无标注前置任务来学习可泛化的特征表示。在这项工作中，我们提出了一种新颖的实例级和片段级前置任务（IEPT）框架，将SSL无缝集成到FSL中。具体来说，给定一个FSL片段，我们首先对每个实例应用几何变换以生成扩展片段。在实例级别，按照标准SSL执行变换识别。重要的是，在片段级别，设计了两个SSL-FSL混合学习目标：（1）最大化来自不同扩展片段的FSL分类器预测的一致性，作为片段级前置任务。（2）整合来自不同片段的每个实例提取的特征，构建用于元学习的单一FSL分类器。大量实验表明，我们提出的模型（即带有IEPT的FSL）达到了新的最先进水平。",
        "领域": "少样本学习",
        "问题": "如何在少量标记样本的情况下有效学习新任务",
        "动机": "克服为每个新任务收集大量标记数据的需求，提高深度神经网络的实用性",
        "方法": "提出实例级和片段级前置任务（IEPT）框架，将自监督学习（SSL）集成到少样本学习（FSL）中，通过几何变换生成扩展片段，并在实例和片段级别设计学习目标",
        "关键词": [
            "少样本学习",
            "自监督学习",
            "迁移学习",
            "前置任务",
            "元学习"
        ],
        "涉及的技术概念": {
            "实例级前置任务": "在实例级别应用几何变换并执行变换识别，作为自监督学习的一部分",
            "片段级前置任务": "在片段级别设计学习目标，包括最大化不同扩展片段预测的一致性和整合特征构建单一分类器",
            "元学习": "通过整合来自不同片段的特征构建单一分类器，用于学习如何快速适应新任务"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 356,
        "title": "Image Augmentation Is All You Need: Regularizing Deep Reinforcement Learning from Pixels",
        "html": "https://iclr.cc//virtual/2021/poster/3188",
        "abstract": "We propose a simple data augmentation technique that can be applied to standard model-free reinforcement learning algorithms, enabling robust learning directly from pixels without the need for auxiliary losses or pre-training.  The approach leverages input perturbations commonly used in computer vision tasks to transform input examples, as well as regularizing the value function and policy.  Existing model-free approaches, such as Soft Actor-Critic (SAC), are not able to train deep networks effectively from image pixels. However, the addition of our augmentation method dramatically improves SAC’s performance, enabling it to reach state-of-the-art performance on the DeepMind control suite, surpassing model-based (Hafner et al., 2019; Lee et al., 2019; Hafner et al., 2018) methods and recently proposed contrastive learning (Srinivas et al., 2020).  Our approach, which we dub DrQ: Data-regularized Q, can be combined with any model-free reinforcement learning algorithm. We further demonstrate this by applying it to DQN and significantly improve its data-efficiency on the Atari 100k benchmark.",
        "conference": "ICLR",
        "中文标题": "图像增强就是您所需的一切：从像素中正则化深度强化学习",
        "摘要翻译": "我们提出了一种简单的数据增强技术，该技术可应用于标准的无模型强化学习算法，使得能够直接从像素进行鲁棒学习，而无需辅助损失或预训练。该方法利用了计算机视觉任务中常用的输入扰动来转换输入示例，同时正则化价值函数和策略。现有的无模型方法，如软行动者-评论家（SAC），无法有效地从图像像素训练深度网络。然而，添加我们的增强方法显著提高了SAC的性能，使其在DeepMind控制套件上达到最先进的性能，超越了基于模型的方法（Hafner等人，2019；Lee等人，2019；Hafner等人，2018）和最近提出的对比学习（Srinivas等人，2020）。我们的方法，我们称之为DrQ：数据正则化Q，可以与任何无模型强化学习算法结合使用。我们通过将其应用于DQN并显著提高其在Atari 100k基准上的数据效率进一步证明了这一点。",
        "领域": "深度强化学习、计算机视觉、机器人控制",
        "问题": "如何直接从像素进行有效的深度强化学习，而无需辅助损失或预训练",
        "动机": "现有的无模型强化学习方法在直接从图像像素训练深度网络时效率低下，需要一种方法来提高其性能和效率",
        "方法": "提出了一种数据增强技术，通过输入扰动和正则化价值函数及策略，提高无模型强化学习算法的性能",
        "关键词": [
            "数据增强",
            "深度强化学习",
            "无模型学习",
            "图像处理",
            "机器人控制"
        ],
        "涉及的技术概念": {
            "数据增强": "通过输入扰动转换输入示例，以提高模型的泛化能力和鲁棒性",
            "正则化": "用于防止模型过拟合，通过正则化价值函数和策略来优化学习过程",
            "无模型强化学习": "不依赖于环境模型的强化学习方法，直接从经验中学习策略"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 357,
        "title": "Image GANs meet Differentiable Rendering for Inverse Graphics and Interpretable 3D Neural Rendering",
        "html": "https://iclr.cc//virtual/2021/poster/3222",
        "abstract": "Differentiable rendering has paved the way to training neural networks to perform “inverse graphics” tasks such as predicting 3D geometry from monocular photographs. To train high performing models, most of the current approaches rely on multi-view imagery which are not readily available in practice.  Recent Generative Adversarial Networks (GANs) that synthesize images, in contrast, seem to acquire 3D knowledge implicitly during training: object viewpoints can be manipulated by simply manipulating the latent codes. However, these latent codes often lack further physical interpretation and thus GANs cannot easily be inverted to perform explicit 3D reasoning. In this paper, we aim to extract and disentangle 3D knowledge learned by generative models by utilizing differentiable renderers. Key to our approach is to exploit GANs as a multi-view data generator to train an inverse graphics network using an off-the-shelf differentiable renderer, and the trained inverse graphics network as a teacher to disentangle the GAN's latent code into interpretable 3D properties. The entire architecture is trained iteratively using cycle consistency losses. We show that our approach significantly outperforms state-of-the-art inverse graphics networks trained on existing datasets, both quantitatively and via user studies. We further showcase the disentangled GAN as a controllable 3D “neural renderer', complementing traditional graphics renderers.",
        "conference": "ICLR",
        "中文标题": "图像生成对抗网络与可微分渲染相遇：逆向图形学与可解释的3D神经渲染",
        "摘要翻译": "可微分渲染为训练神经网络执行‘逆向图形学’任务（如从单目照片预测3D几何）铺平了道路。为了训练高性能模型，当前大多数方法依赖于多视角图像，这些图像在实践中并不容易获得。相比之下，最近合成图像的生成对抗网络（GANs）似乎在训练过程中隐式地获取了3D知识：通过简单地操作潜在代码就可以操纵物体视角。然而，这些潜在代码往往缺乏进一步的物理解释，因此GANs不易被逆向用于执行显式的3D推理。在本文中，我们旨在通过利用可微分渲染器提取并解耦由生成模型学习的3D知识。我们方法的关键是利用GANs作为多视角数据生成器，使用现成的可微分渲染器训练逆向图形学网络，并将训练好的逆向图形学网络作为教师，将GAN的潜在代码解耦为可解释的3D属性。整个架构使用循环一致性损失迭代训练。我们表明，我们的方法在定量和用户研究方面都显著优于在现有数据集上训练的最先进的逆向图形学网络。我们进一步展示了作为可控3D‘神经渲染器’的解耦GAN，补充了传统的图形渲染器。",
        "领域": "3D重建、生成对抗网络、可微分渲染",
        "问题": "如何从单目照片中预测3D几何，并解耦生成对抗网络中的潜在代码以进行显式的3D推理",
        "动机": "解决当前逆向图形学方法依赖多视角图像的问题，并提高GANs在3D推理中的可解释性",
        "方法": "利用GANs生成多视角数据训练逆向图形学网络，并通过循环一致性损失迭代训练整个架构",
        "关键词": [
            "生成对抗网络",
            "可微分渲染",
            "3D重建",
            "逆向图形学",
            "神经渲染器"
        ],
        "涉及的技术概念": {
            "可微分渲染": "用于训练神经网络执行逆向图形学任务，如从单目照片预测3D几何",
            "生成对抗网络": "用于生成多视角图像数据，隐式学习3D知识",
            "循环一致性损失": "用于迭代训练整个架构，确保逆向图形学网络和GANs之间的一致性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 358,
        "title": "Impact of Representation Learning in Linear Bandits",
        "html": "https://iclr.cc//virtual/2021/poster/2588",
        "abstract": "We study how representation learning can improve the efficiency of bandit problems. We study the setting where we play $T$ linear bandits with dimension $d$ concurrently, and these $T$ bandit tasks share a common $k (\\ll d)$ dimensional linear representation. For the finite-action setting, we present a new algorithm which achieves $\\widetilde{O}(T\\sqrt{kN} + \\sqrt{dkNT})$ regret, where $N$ is the number of rounds we play for each bandit. When $T$ is sufficiently large, our algorithm significantly outperforms the naive algorithm (playing $T$ bandits independently) that achieves $\\widetilde{O}(T\\sqrt{d N})$ regret. We also provide an $\\Omega(T\\sqrt{kN} + \\sqrt{dkNT})$ regret lower bound, showing that our algorithm is minimax-optimal up to poly-logarithmic factors.  Furthermore, we extend our algorithm to the infinite-action setting and obtain a corresponding regret bound which demonstrates the benefit of representation learning in certain regimes. We also present experiments on synthetic and real-world data to illustrate our theoretical findings and demonstrate the effectiveness of our proposed algorithms.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "表征学习在线性Bandit问题中的影响",
        "摘要翻译": "我们研究了表征学习如何提高bandit问题的效率。我们研究了同时进行T个维度为d的线性bandit问题的场景，这些bandit任务共享一个共同的k (<< d)维线性表示。对于有限动作设置，我们提出了一种新的算法，该算法实现了$\\widetilde{O}(T\\sqrt{kN} + \\sqrt{dkNT})$的遗憾值，其中N是我们为每个bandit进行的轮数。当T足够大时，我们的算法明显优于朴素算法（独立地进行T个bandits），后者实现了$\\widetilde{O}(T\\sqrt{d N})$的遗憾值。我们还提供了一个$\\Omega(T\\sqrt{kN} + \\sqrt{dkNT})$的遗憾下界，表明我们的算法在poly-logarithmic因子内是minimax最优的。此外，我们将我们的算法扩展到无限动作设置，并获得相应的遗憾界限，这表明了表征学习在某些情况下的好处。我们还展示了在合成和真实世界数据上的实验，以说明我们的理论发现并证明我们提出的算法的有效性。",
        "领域": "强化学习、 bandit算法、表示学习",
        "问题": "如何在多个bandit任务共享潜在的低维表示的情况下，提高bandit算法的效率和降低遗憾值。",
        "动机": "传统的bandit算法在处理高维数据或多个相关任务时效率较低，而表征学习能够提取共享的低维表示，从而提高算法的泛化能力和效率。",
        "方法": "提出了一种新的bandit算法，利用共享的低维表示来加速学习过程。该算法在有限动作和无限动作设置下都进行了理论分析，并提供了遗憾界限。通过合成和真实世界数据上的实验验证了算法的有效性。",
        "关键词": [
            "表征学习",
            "bandit算法",
            "遗憾界限",
            "多任务学习",
            "线性bandit"
        ],
        "涉及的技术概念": {
            "表征学习": "通过学习数据的潜在表示，将高维数据映射到低维空间，从而提取数据的关键特征。",
            "Bandit算法": "一种在线学习算法，通过在探索和利用之间进行权衡，来最大化累积奖励。"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 359,
        "title": "Implicit Convex Regularizers of CNN Architectures: Convex Optimization of Two- and Three-Layer Networks in Polynomial Time",
        "html": "https://iclr.cc//virtual/2021/poster/3039",
        "abstract": "We study training of Convolutional Neural Networks (CNNs) with ReLU activations and introduce exact convex optimization formulations with a polynomial complexity with respect to the number of data samples, the number of neurons, and data dimension. More specifically, we develop a convex analytic framework utilizing semi-infinite duality to obtain equivalent convex optimization problems for several two- and three-layer CNN architectures. We first prove that two-layer CNNs can be globally optimized via an $\\ell_2$ norm regularized convex program. We then show that multi-layer circular CNN training problems with a single ReLU layer are equivalent to an $\\ell_1$ regularized convex program that encourages sparsity in the spectral domain. We also extend these results to three-layer CNNs with two ReLU layers. Furthermore, we present extensions of our approach to different pooling methods, which elucidates the implicit architectural bias as convex regularizers.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "卷积神经网络架构的隐式凸正则化器：多项式时间内二层和三层网络的凸优化",
        "摘要翻译": "我们研究了带有ReLU激活函数的卷积神经网络（CNN）的训练，并引入了精确的凸优化公式，其复杂度相对于数据样本数量、神经元数量和数据维度是多项式的。更具体地说，我们开发了一个凸分析框架，利用半无限对偶性来获得几个二层和三层CNN架构的等价凸优化问题。我们首先证明，可以通过一个范数正则化的凸程序来全局优化二层CNN。然后，我们表明具有单个ReLU层的多层循环CNN训练问题等价于一个正则化的凸程序，该程序鼓励频谱域中的稀疏性。我们还将这些结果扩展到具有两个ReLU层的三层CNN。此外，我们提出了我们的方法对不同池化方法的扩展，这阐明了作为凸正则化器的隐式架构偏差。",
        "领域": "卷积神经网络、凸优化、模型优化",
        "问题": "如何针对特定的CNN架构，设计有效的凸优化方法，以实现全局最优解，并降低计算复杂度。",
        "动机": "传统的深度学习模型训练通常依赖于非凸优化方法，容易陷入局部最优解。通过将CNN的训练转化为凸优化问题，可以保证找到全局最优解，并提高模型的性能和可解释性。",
        "方法": "利用半无限对偶性构建凸分析框架，将二层和三层CNN的训练问题转化为等价的凸优化问题。针对不同的CNN架构和激活函数，设计了相应的凸正则化器，并证明了其有效性。",
        "关键词": [
            "凸优化",
            "卷积神经网络",
            "ReLU激活函数",
            "正则化",
            "全局优化"
        ],
        "涉及的技术概念": {
            "凸优化": "通过寻找凸函数的最优解来优化模型参数。保证找到全局最优解，避免陷入局部最优。",
            "ReLU激活函数": "一种常用的非线性激活函数，在CNN中引入非线性特性，增强模型的表达能力。"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 360,
        "title": "Implicit Gradient Regularization",
        "html": "https://iclr.cc//virtual/2021/poster/3150",
        "abstract": "Gradient descent can be surprisingly good at optimizing deep neural networks without overfitting and without explicit regularization. We find that the discrete steps of gradient descent implicitly regularize models by penalizing gradient descent trajectories that have large loss gradients. We call this Implicit Gradient Regularization (IGR) and we use backward error analysis to calculate the size of this regularization. We confirm empirically that implicit gradient regularization biases gradient descent toward flat minima, where test errors are small and solutions are robust to noisy parameter perturbations. Furthermore, we demonstrate that the implicit gradient regularization term can be used as an explicit regularizer, allowing us to control this gradient regularization directly. More broadly, our work indicates that backward error analysis is a useful theoretical approach to the perennial question of how learning rate, model size, and parameter regularization interact to determine the properties of overparameterized models optimized with gradient descent.",
        "conference": "ICLR",
        "中文标题": "隐式梯度正则化",
        "摘要翻译": "梯度下降法在优化深度神经网络时，出人意料地表现良好，既不会过拟合，也不需要显式正则化。我们发现，梯度下降的离散步骤通过惩罚具有大损失梯度的梯度下降轨迹，隐式地对模型进行正则化。我们将此称为隐式梯度正则化（IGR），并利用后向误差分析来计算这种正则化的大小。我们通过实验证实，隐式梯度正则化使梯度下降偏向于平坦的最小值，这些最小值的测试误差小且解对参数扰动具有鲁棒性。此外，我们证明了隐式梯度正则化项可以用作显式正则化器，使我们能够直接控制这种梯度正则化。更广泛地说，我们的工作表明，后向误差分析是一种有用的理论方法，用于解决学习率、模型大小和参数正则化如何相互作用以决定用梯度下降优化的过参数化模型特性的长期问题。",
        "领域": "深度学习优化、过参数化模型、梯度下降法",
        "问题": "梯度下降法在优化深度神经网络时如何隐式地进行正则化，以及如何利用这一现象改进模型训练。",
        "动机": "探索梯度下降法在优化深度神经网络时的隐式正则化效应，以及如何利用这一效应提高模型的泛化能力和鲁棒性。",
        "方法": "通过后向误差分析计算隐式梯度正则化的大小，并将其作为显式正则化器应用于模型训练中。",
        "关键词": [
            "隐式梯度正则化",
            "后向误差分析",
            "梯度下降法",
            "过参数化模型",
            "平坦最小值"
        ],
        "涉及的技术概念": {
            "隐式梯度正则化": "梯度下降法在优化过程中隐式地对模型进行正则化，通过惩罚大损失梯度的轨迹来偏向平坦的最小值。",
            "后向误差分析": "用于计算隐式梯度正则化大小的理论方法，帮助理解梯度下降法的正则化效应。",
            "平坦最小值": "梯度下降法优化的目标，具有小的测试误差和对参数扰动的鲁棒性，隐式梯度正则化有助于模型收敛到这类最小值。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 361,
        "title": "Implicit Normalizing Flows",
        "html": "https://iclr.cc//virtual/2021/poster/2983",
        "abstract": "Normalizing flows define a probability distribution by an explicit invertible transformation $\\boldsymbol{\\mathbf{z}}=f(\\boldsymbol{\\mathbf{x}})$. In this work, we present implicit normalizing flows (ImpFlows), which generalize normalizing flows by allowing the mapping to be implicitly defined by the roots of an equation $F(\\boldsymbol{\\mathbf{z}}, \\boldsymbol{\\mathbf{x}})= \\boldsymbol{\\mathbf{0}}$. ImpFlows build on residual flows (ResFlows) with a proper balance between expressiveness and tractability. Through theoretical analysis, we show that the function space of ImpFlow is strictly richer than that of ResFlows. Furthermore, for any ResFlow with a fixed number of blocks, there exists some function that ResFlow has a non-negligible approximation error. However, the function is exactly representable by a single-block ImpFlow. We propose a scalable algorithm to train and draw samples from ImpFlows. Empirically, we evaluate ImpFlow on several classification and density modeling tasks, and ImpFlow outperforms ResFlow with a comparable amount of parameters on all the benchmarks.",
        "conference": "ICLR",
        "中文标题": "隐式归一化流",
        "摘要翻译": "归一化流通过一个明确的可逆变换定义了一个概率分布。在这项工作中，我们提出了隐式归一化流（ImpFlows），它通过允许映射由方程的根隐式定义来推广归一化流。ImpFlows建立在残差流（ResFlows）的基础上，在表达能力和可处理性之间取得了适当的平衡。通过理论分析，我们表明ImpFlow的函数空间严格比ResFlows的更丰富。此外，对于任何具有固定数量块的ResFlow，存在一些函数，ResFlow对这些函数有不可忽略的近似误差。然而，这些函数可以通过单块ImpFlow精确表示。我们提出了一种可扩展的算法来训练ImpFlows并从中抽取样本。实证上，我们在几个分类和密度建模任务上评估了ImpFlow，在所有基准测试中，ImpFlow在参数数量相当的情况下优于ResFlow。",
        "领域": "概率密度估计, 生成模型, 深度学习理论",
        "问题": "如何通过隐式定义的映射来推广归一化流，以在保持可处理性的同时提高表达能力",
        "动机": "现有的归一化流方法在表达能力和可处理性之间存在限制，研究旨在通过隐式定义映射来克服这些限制",
        "方法": "提出隐式归一化流（ImpFlows），允许映射由方程的根隐式定义，建立在残差流（ResFlows）的基础上，提出训练和采样算法",
        "关键词": [
            "隐式归一化流",
            "概率密度估计",
            "生成模型",
            "残差流",
            "深度学习"
        ],
        "涉及的技术概念": {
            "隐式归一化流（ImpFlows）": "通过允许映射由方程的根隐式定义来推广归一化流，提高表达能力",
            "残差流（ResFlows）": "ImpFlows建立在其基础上，在表达能力和可处理性之间取得平衡",
            "概率密度估计": "ImpFlows用于定义概率分布，应用于分类和密度建模任务"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 362,
        "title": "Implicit Under-Parameterization Inhibits Data-Efficient Deep Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2021/poster/3301",
        "abstract": "We identify an implicit under-parameterization phenomenon in value-based deep RL methods that use bootstrapping: when value functions, approximated using deep neural networks, are trained with gradient descent using iterated regression onto target values generated by previous instances of the value network, more gradient updates decrease the expressivity of the current value network. We char- acterize this loss of expressivity via a drop in the rank of the learned value net- work features, and show that this typically corresponds to a performance drop. We demonstrate this phenomenon on Atari and Gym benchmarks, in both offline and online RL settings. We formally analyze this phenomenon and show that it results from a pathological interaction between bootstrapping and gradient-based optimization. We further show that mitigating implicit under-parameterization by controlling rank collapse can improve performance.",
        "conference": "ICLR",
        "中文标题": "隐式欠参数化阻碍数据高效的深度强化学习",
        "摘要翻译": "我们在基于值的深度强化学习方法中发现了一种隐式欠参数化现象：当使用深度神经网络近似值函数，并通过梯度下降法对由值网络先前实例生成的目标值进行迭代回归训练时，更多的梯度更新会降低当前值网络的表达能力。我们通过学习的值网络特征秩的下降来表征这种表达能力的丧失，并表明这通常对应于性能的下降。我们在Atari和Gym基准测试中，在离线和在线强化学习设置下，展示了这一现象。我们正式分析了这一现象，并表明它是由自举和基于梯度的优化之间的病态相互作用引起的。我们进一步表明，通过控制秩崩溃来缓解隐式欠参数化可以提高性能。",
        "领域": "深度强化学习",
        "问题": "深度强化学习中隐式欠参数化现象导致值网络表达能力下降的问题",
        "动机": "研究旨在解决深度强化学习中由于隐式欠参数化导致的性能下降问题",
        "方法": "通过分析值网络特征秩的下降来表征隐式欠参数化现象，并提出控制秩崩溃的方法来缓解这一问题",
        "关键词": [
            "隐式欠参数化",
            "深度强化学习",
            "值网络",
            "梯度下降",
            "秩崩溃"
        ],
        "涉及的技术概念": {
            "隐式欠参数化": "指在深度强化学习中，值网络在训练过程中由于梯度更新导致的表达能力下降现象",
            "值网络": "用于近似强化学习中的值函数，通过深度神经网络实现",
            "秩崩溃": "指值网络特征矩阵的秩在训练过程中下降，导致网络表达能力降低"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 363,
        "title": "Improved Autoregressive Modeling with Distribution Smoothing",
        "html": "https://iclr.cc//virtual/2021/poster/3276",
        "abstract": "While autoregressive models excel at image compression, their sample quality is often lacking. Although not realistic, generated images often have high likelihood according to the model, resembling the case of adversarial examples. Inspired by a successful adversarial defense method, we incorporate randomized smoothing into autoregressive generative modeling. We first model a smoothed version of the data distribution, and then reverse the smoothing process to recover the original data distribution. This procedure drastically improves the sample quality of existing autoregressive models on several synthetic and real-world image datasets while obtaining competitive likelihoods on synthetic datasets.",
        "conference": "ICLR",
        "中文标题": "改进的自回归建模与分布平滑",
        "摘要翻译": "虽然自回归模型在图像压缩方面表现出色，但其生成的样本质量往往不尽如人意。尽管生成的图像并不真实，但根据模型，这些图像往往具有很高的似然性，类似于对抗样本的情况。受到一种成功的对抗防御方法的启发，我们将随机平滑引入自回归生成建模中。我们首先对数据分布的平滑版本进行建模，然后逆转平滑过程以恢复原始数据分布。这一过程极大地提高了现有自回归模型在多个合成和真实世界图像数据集上的样本质量，同时在合成数据集上获得了具有竞争力的似然性。",
        "领域": "图像生成、对抗样本防御、自回归模型",
        "问题": "提高自回归模型生成图像的质量",
        "动机": "解决自回归模型在生成高质量图像方面的不足，尤其是在避免生成高似然但不真实的图像方面。",
        "方法": "引入随机平滑技术到自回归生成建模中，先对数据分布的平滑版本建模，再逆转平滑过程以恢复原始分布。",
        "关键词": [
            "自回归模型",
            "分布平滑",
            "图像生成",
            "对抗防御",
            "样本质量"
        ],
        "涉及的技术概念": {
            "自回归模型": "用于图像生成和压缩的模型，通过预测给定序列中下一个元素的条件分布来生成数据。",
            "随机平滑": "一种对抗防御技术，通过向输入数据添加随机噪声来提高模型的鲁棒性。",
            "数据分布逆转": "在平滑处理后，通过特定方法恢复原始数据分布的技术，以提高生成样本的质量。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 364,
        "title": "Improved Estimation of Concentration Under $\\ell_p$-Norm Distance Metrics Using Half Spaces",
        "html": "https://iclr.cc//virtual/2021/poster/2690",
        "abstract": "Concentration of measure has been argued to be the fundamental cause of adversarial vulnerability. Mahloujifar et al. (2019) presented an empirical way to measure the concentration of a data distribution using samples, and employed it to find lower bounds on intrinsic robustness for several benchmark datasets. However, it remains unclear whether these lower bounds are tight enough to provide a useful approximation for the intrinsic robustness of a dataset. To gain a deeper understanding of the concentration of measure phenomenon, we first extend the Gaussian Isoperimetric Inequality to non-spherical Gaussian measures and arbitrary $\\ell_p$-norms ($p \\geq 2$). We leverage these theoretical insights to design a method that uses half-spaces to estimate the concentration of any empirical dataset under $\\ell_p$-norm distance metrics. Our proposed algorithm is more efficient than Mahloujifar et al. (2019)'s, and experiments on synthetic datasets and image benchmarks demonstrate that it is able to find much tighter intrinsic robustness bounds. These tighter estimates provide further evidence that rules out intrinsic dataset concentration as a possible explanation for the adversarial vulnerability of state-of-the-art classifiers.",
        "conference": "ICLR",
        "中文标题": "使用半空间改进在ℓp范数距离度量下的集中度估计",
        "摘要翻译": "集中度测量被认为是对抗性脆弱性的根本原因。Mahloujifar等人（2019年）提出了一种使用样本测量数据分布集中度的经验方法，并利用它为几个基准数据集找到了内在鲁棒性的下限。然而，这些下限是否足够紧以提供数据集内在鲁棒性的有用近似仍不清楚。为了更深入地理解集中度测量现象，我们首先将高斯等周不等式扩展到非球形高斯测量和任意ℓp范数（p≥2）。我们利用这些理论见解设计了一种方法，使用半空间来估计任何经验数据集在ℓp范数距离度量下的集中度。我们提出的算法比Mahloujifar等人（2019年）的更高效，并且在合成数据集和图像基准上的实验表明，它能够找到更紧的内在鲁棒性界限。这些更紧的估计提供了进一步的证据，排除了内在数据集集中度作为最先进分类器对抗性脆弱性可能解释的原因。",
        "领域": "对抗性机器学习、深度学习理论、鲁棒性分析",
        "问题": "如何更准确地估计数据集在ℓp范数距离度量下的集中度，以提供更紧的内在鲁棒性界限",
        "动机": "深入理解集中度测量现象，排除内在数据集集中度作为对抗性脆弱性的可能解释",
        "方法": "扩展高斯等周不等式到非球形高斯测量和任意ℓp范数，设计使用半空间估计数据集集中度的算法",
        "关键词": [
            "集中度测量",
            "ℓp范数",
            "内在鲁棒性",
            "对抗性脆弱性",
            "半空间"
        ],
        "涉及的技术概念": {
            "高斯等周不等式": "用于描述高斯空间中集合的集中度特性，本文扩展到非球形高斯测量和任意ℓp范数",
            "ℓp范数": "用于定义距离度量，本文中p≥2，用于测量数据点之间的距离",
            "半空间": "用于估计数据集集中度的几何工具，本文设计的方法利用半空间来提高估计效率"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 365,
        "title": "Improve Object Detection with Feature-based Knowledge Distillation: Towards Accurate and Efficient Detectors",
        "html": "https://iclr.cc//virtual/2021/poster/2601",
        "abstract": "Knowledge distillation, in which a student model is trained to mimic a teacher model, has been proved as an effective technique for model compression and model accuracy boosting. However, most knowledge distillation methods, designed for image classification, have failed on more challenging tasks, such as object detection. In this paper, we suggest that the failure of knowledge distillation on object detection is mainly caused by two reasons: (1) the imbalance between pixels of foreground and background and (2) lack of distillation on the relation between different pixels. Observing the above reasons, we propose attention-guided distillation and non-local distillation to address the two problems, respectively.  Attention-guided distillation is proposed to find the crucial pixels of foreground objects with attention mechanism and then make the students take more effort to learn their features. Non-local distillation is proposed to enable students to learn not only the feature of an individual pixel but also the relation between different pixels captured by non-local modules. Experiments show that our methods achieve excellent AP improvements on both one-stage and two-stage, both anchor-based and anchor-free detectors. For example, Faster RCNN (ResNet101 backbone) with our distillation achieves 43.9 AP on COCO2017, which is 4.1 higher than the baseline. Codes have been released on Github.",
        "conference": "ICLR",
        "中文标题": "基于特征的知识蒸馏提升目标检测：迈向精确高效的检测器",
        "摘要翻译": "知识蒸馏技术通过训练学生模型模仿教师模型，已被证明是一种有效的模型压缩和模型精度提升方法。然而，大多数为图像分类设计的知识蒸馏方法在更具挑战性的任务，如目标检测上表现不佳。本文认为，知识蒸馏在目标检测上的失败主要由两个原因造成：（1）前景与背景像素之间的不平衡；（2）缺乏对不同像素间关系的蒸馏。针对上述原因，我们分别提出了注意力引导蒸馏和非局部蒸馏来解决这两个问题。注意力引导蒸馏旨在通过注意力机制找到前景对象的关键像素，然后使学生模型更加努力地学习这些特征。非局部蒸馏则使学生模型不仅学习单个像素的特征，还能学习由非局部模块捕获的不同像素间的关系。实验表明，我们的方法在单阶段和两阶段、基于锚点和无锚点的检测器上均实现了显著的AP提升。例如，采用我们蒸馏方法的Faster RCNN（ResNet101骨干网络）在COCO2017上达到了43.9 AP，比基线高出4.1。代码已在Github上发布。",
        "领域": "目标检测",
        "问题": "解决知识蒸馏在目标检测任务中因前景与背景像素不平衡及缺乏像素间关系蒸馏而表现不佳的问题",
        "动机": "提升知识蒸馏在目标检测任务中的效果，实现模型压缩同时提高检测精度",
        "方法": "提出注意力引导蒸馏和非局部蒸馏，分别解决前景与背景像素不平衡和像素间关系蒸馏不足的问题",
        "关键词": [
            "知识蒸馏",
            "目标检测",
            "注意力机制",
            "非局部模块",
            "模型压缩"
        ],
        "涉及的技术概念": {
            "注意力机制": "用于识别前景对象的关键像素，指导学生模型重点学习这些特征",
            "非局部模块": "捕获不同像素间的关系，使学生模型能够学习到更丰富的特征表示",
            "知识蒸馏": "通过训练学生模型模仿教师模型，实现模型压缩和精度提升的技术"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 366,
        "title": "Improving Adversarial Robustness via Channel-wise Activation Suppressing",
        "html": "https://iclr.cc//virtual/2021/poster/2827",
        "abstract": "The study of adversarial examples and their activations have attracted significant attention for secure and robust learning with deep neural networks (DNNs).  Different from existing works, in this paper, we highlight two new characteristics of adversarial examples from the channel-wise activation perspective:  1) the activation magnitudes of adversarial examples are higher than that of natural examples; and 2) the channels are activated more uniformly by adversarial examples than natural examples. We find that, while the state-of-the-art defense adversarial training has addressed the first issue of high activation magnitude via training on adversarial examples, the second issue of uniform activation remains.  This motivates us to suppress redundant activations from being activated by adversarial perturbations during the adversarial training process, via a Channel-wise Activation Suppressing (CAS) training strategy.  We show that CAS can train a model that inherently suppresses adversarial activations, and can be easily applied to existing defense methods to further improve their robustness. Our work provides a simplebut generic training strategy for robustifying the intermediate layer activations of DNNs.",
        "conference": "ICLR",
        "中文标题": "通过通道级激活抑制提升对抗鲁棒性",
        "摘要翻译": "对抗样本及其激活的研究在深度神经网络（DNNs）的安全和鲁棒学习领域引起了广泛关注。与现有工作不同，本文从通道级激活的角度突出了对抗样本的两个新特征：1）对抗样本的激活幅度高于自然样本；2）对抗样本比自然样本更均匀地激活通道。我们发现，尽管最先进的防御方法——对抗训练通过训练对抗样本解决了高激活幅度的问题，但均匀激活的问题仍然存在。这促使我们在对抗训练过程中通过通道级激活抑制（CAS）训练策略来抑制由对抗扰动引起的冗余激活。我们证明，CAS可以训练一个本质上抑制对抗激活的模型，并且可以轻松应用于现有的防御方法以进一步提高其鲁棒性。我们的工作为强化DNNs中间层激活提供了一个简单但通用的训练策略。",
        "领域": "对抗性机器学习、深度神经网络安全、图像分类",
        "问题": "解决对抗样本在深度神经网络中引起的通道级激活问题，特别是高激活幅度和均匀激活的问题。",
        "动机": "现有的对抗训练方法虽然解决了高激活幅度的问题，但未能解决对抗样本引起的均匀激活问题，这促使研究新的训练策略以进一步提升模型的对抗鲁棒性。",
        "方法": "提出了一种通道级激活抑制（CAS）训练策略，通过在对抗训练过程中抑制冗余激活，训练出能够本质上抑制对抗激活的模型。",
        "关键词": [
            "对抗鲁棒性",
            "通道级激活抑制",
            "对抗训练",
            "深度神经网络安全",
            "激活抑制"
        ],
        "涉及的技术概念": {
            "对抗样本": "在输入数据上添加微小扰动以误导深度神经网络产生错误输出的样本。",
            "通道级激活抑制（CAS）": "一种训练策略，旨在通过抑制由对抗扰动引起的冗余通道激活，提升模型的对抗鲁棒性。",
            "对抗训练": "一种通过在训练过程中引入对抗样本来提高模型对抗鲁棒性的防御方法。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 367,
        "title": "Improving Relational Regularized Autoencoders with Spherical Sliced Fused Gromov Wasserstein",
        "html": "https://iclr.cc//virtual/2021/poster/2980",
        "abstract": "Relational regularized autoencoder (RAE) is a framework to learn the distribution of data by minimizing a reconstruction loss together with a relational regularization on the prior of latent space. A recent attempt to reduce the inner discrepancy between the prior and aggregated posterior distributions is to incorporate sliced fused Gromov-Wasserstein (SFG) between these distributions. That approach has a weakness since it treats every slicing direction similarly, meanwhile several directions are not useful for the discriminative task. To improve the discrepancy and consequently the relational regularization, we propose a new relational discrepancy, named spherical sliced fused Gromov Wasserstein (SSFG), that can find an important area of projections characterized by a von Mises-Fisher distribution. Then, we introduce two variants of SSFG to improve its performance. The first variant, named mixture spherical sliced fused Gromov Wasserstein (MSSFG), replaces the vMF distribution by a mixture of von Mises-Fisher distributions to capture multiple important areas of directions that are far from each other. The second variant, named power spherical sliced fused Gromov Wasserstein (PSSFG), replaces the vMF distribution by a power spherical distribution to improve the sampling time of the vMF distribution in high dimension settings. We then apply the new discrepancies to the RAE framework to achieve its new variants. Finally, we conduct extensive experiments to show that the new autoencoders have favorable performance in learning latent manifold structure, image generation, and reconstruction.",
        "conference": "ICLR",
        "中文标题": "改进关系正则化自编码器：球面切片融合Gromov Wasserstein方法",
        "摘要翻译": "关系正则化自编码器（RAE）是一种通过学习数据分布来最小化重建损失及潜在空间先验上的关系正则化的框架。最近，为了减少先验与聚合后验分布之间的内部差异，有研究尝试在这些分布之间引入切片融合Gromov-Wasserstein（SFG）。然而，该方法存在一个弱点，即它对所有切片方向都一视同仁，而实际上某些方向对于判别任务并无帮助。为了改进这种差异，进而优化关系正则化，我们提出了一种新的关系差异度量，称为球面切片融合Gromov Wasserstein（SSFG），它能够通过von Mises-Fisher分布找到投影的重要区域。接着，我们介绍了两种SSFG的变体以提升其性能。第一种变体称为混合球面切片融合Gromov Wasserstein（MSSFG），它用von Mises-Fisher分布的混合物替代单一分布，以捕捉彼此远离的多个重要方向区域。第二种变体称为幂球面切片融合Gromov Wasserstein（PSSFG），它用幂球面分布替代von Mises-Fisher分布，以在高维设置下改善vMF分布的采样时间。随后，我们将这些新的差异度量应用于RAE框架，以实现其新变体。最后，我们进行了大量实验，证明新的自编码器在学习潜在流形结构、图像生成和重建方面具有优越性能。",
        "领域": "生成模型, 深度学习优化, 图像生成",
        "问题": "减少先验与聚合后验分布之间的内部差异，并优化关系正则化",
        "动机": "现有的切片融合Gromov-Wasserstein方法对所有切片方向同等对待，忽略了某些方向对判别任务的无用性，导致关系正则化效果不佳",
        "方法": "提出球面切片融合Gromov Wasserstein（SSFG）及其两种变体MSSFG和PSSFG，以更有效地捕捉重要投影区域并优化关系正则化",
        "关键词": [
            "关系正则化自编码器",
            "球面切片融合Gromov Wasserstein",
            "von Mises-Fisher分布",
            "潜在流形学习",
            "图像生成"
        ],
        "涉及的技术概念": {
            "关系正则化自编码器（RAE）": "一种通过学习数据分布来最小化重建损失及潜在空间先验上的关系正则化的框架",
            "球面切片融合Gromov Wasserstein（SSFG）": "一种新的关系差异度量，能够通过von Mises-Fisher分布找到投影的重要区域",
            "von Mises-Fisher分布": "用于在球面上定义方向分布的统计分布，SSFG利用它来识别重要的投影方向"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 368,
        "title": "Improving Transformation Invariance in Contrastive Representation Learning",
        "html": "https://iclr.cc//virtual/2021/poster/2855",
        "abstract": "We propose methods to strengthen the invariance properties of representations obtained by contrastive learning. While existing approaches implicitly induce a degree of invariance as representations are learned, we look to more directly enforce invariance in the encoding process. To this end, we first introduce a training objective for contrastive learning that uses a novel regularizer to control how the representation changes under transformation. We show that representations trained with this objective perform better on downstream tasks and are more robust to the introduction of nuisance transformations at test time. Second, we propose a change to how test time representations are generated by introducing a feature averaging approach that combines encodings from multiple transformations of the original input, finding that this leads to across the board performance gains. Finally, we introduce the novel Spirograph dataset to explore our ideas in the context of a differentiable generative process with multiple downstream tasks, showing that our techniques for learning invariance are highly beneficial.",
        "conference": "ICLR",
        "中文标题": "提升对比表示学习中的变换不变性",
        "摘要翻译": "我们提出了增强对比学习获得的表示的不变性属性的方法。虽然现有方法在学习表示时隐式地引入了一定程度的不变性，但我们寻求在编码过程中更直接地强制执行不变性。为此，我们首先为对比学习引入了一个训练目标，该目标使用一种新颖的正则化器来控制表示在变换下的变化。我们展示了使用这一目标训练的表示在下游任务上表现更好，并且在测试时对干扰变换的引入更加鲁棒。其次，我们提出了通过引入一种特征平均方法来改变测试时表示生成的方式，该方法结合了原始输入的多种变换的编码，发现这带来了全面的性能提升。最后，我们引入了新颖的Spirograph数据集，以在一个具有多个下游任务的可微分生成过程的背景下探索我们的想法，展示了我们学习不变性的技术是非常有益的。",
        "领域": "自监督学习、表示学习、计算机视觉",
        "问题": "如何在对比表示学习中更直接地增强表示的不变性属性",
        "动机": "现有方法在学习表示时隐式地引入不变性，但缺乏直接强制执行不变性的机制，影响了表示的质量和鲁棒性",
        "方法": "引入带有新颖正则化器的训练目标控制表示变换；提出特征平均方法结合多变换编码生成测试表示；使用Spirograph数据集验证技术有效性",
        "关键词": [
            "对比学习",
            "表示学习",
            "不变性",
            "特征平均",
            "Spirograph数据集"
        ],
        "涉及的技术概念": {
            "对比学习": "一种自监督学习方法，通过比较正负样本对来学习数据表示",
            "不变性": "表示对输入变换保持不变的能力，是提升模型泛化性和鲁棒性的关键",
            "特征平均": "通过平均多个变换的编码来生成更鲁棒的测试表示，减少单一变换带来的偏差"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 369,
        "title": "Improving VAEs' Robustness to Adversarial Attack",
        "html": "https://iclr.cc//virtual/2021/poster/2585",
        "abstract": "Variational autoencoders (VAEs) have recently been shown to be vulnerable to adversarial attacks, wherein they are fooled into reconstructing a chosen target image. However, how to defend against such attacks remains an open problem. We make significant advances in addressing this issue by introducing methods for producing adversarially robust VAEs. Namely, we first demonstrate that methods proposed to obtain disentangled latent representations produce VAEs that are more robust to these attacks. However, this robustness comes at the cost of reducing the quality of the reconstructions. We ameliorate this by applying disentangling methods to hierarchical VAEs. The resulting models produce high--fidelity autoencoders that are also adversarially robust. We confirm their capabilities on several different datasets and with current state-of-the-art VAE adversarial attacks, and also show that they increase the robustness of downstream tasks to attack.",
        "conference": "ICLR",
        "中文标题": "提升变分自编码器对抗攻击的鲁棒性",
        "摘要翻译": "变分自编码器（VAEs）最近被证明容易受到对抗攻击的影响，在这种攻击下，它们会被欺骗去重建一个选定的目标图像。然而，如何防御此类攻击仍然是一个未解决的问题。我们在解决这一问题上取得了重大进展，通过引入方法来产生对抗性鲁棒的VAEs。具体来说，我们首先证明了提出的用于获得解缠结潜在表示的方法能够产生对这些攻击更为鲁棒的VAEs。然而，这种鲁棒性是以降低重建质量为代价的。我们通过将解缠结方法应用于分层VAEs来改善这一点。所得到的模型产生了既具有高保真度又具有对抗性鲁棒性的自编码器。我们在几个不同的数据集上以及使用当前最先进的VAE对抗攻击确认了它们的能力，并且还表明它们提高了下游任务对攻击的鲁棒性。",
        "领域": "对抗性防御、变分自编码器、深度学习安全",
        "问题": "如何提升变分自编码器（VAEs）对抗对抗攻击的鲁棒性",
        "动机": "变分自编码器（VAEs）在对抗攻击下表现脆弱，需要开发方法来增强其鲁棒性，同时保持或提高重建质量。",
        "方法": "通过引入解缠结潜在表示的方法增强VAEs的对抗鲁棒性，并将这些方法应用于分层VAEs以保持高保真度的重建。",
        "关键词": [
            "变分自编码器",
            "对抗攻击",
            "解缠结表示",
            "分层VAEs",
            "对抗鲁棒性"
        ],
        "涉及的技术概念": {
            "变分自编码器（VAEs）": "一种生成模型，用于学习数据的潜在表示，并能够从这些表示中重建数据。",
            "对抗攻击": "旨在欺骗机器学习模型，使其产生错误输出或行为的恶意输入。",
            "解缠结潜在表示": "一种技术，旨在使潜在空间中的每个维度对应于数据的一个独立且有意义的特征，以提高模型的解释性和鲁棒性。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 370,
        "title": "Improving Zero-Shot Voice Style Transfer via Disentangled Representation Learning",
        "html": "https://iclr.cc//virtual/2021/poster/3306",
        "abstract": "Voice style transfer, also called voice conversion, seeks to modify one speaker's voice to generate speech as if it came from another (target) speaker. Previous works have made progress on voice conversion with parallel training data and pre-known speakers. However, zero-shot voice style transfer, which learns from non-parallel data and generates voices for previously unseen speakers, remains a challenging problem. In this paper we propose a novel zero-shot voice transfer method via disentangled representation learning. The proposed method first encodes speaker-related style and voice content of each input voice into separate low-dimensional embedding spaces, and then transfers to a new voice by combining the source content embedding and target style embedding through a decoder. With information-theoretic guidance, the style and content embedding spaces are representative and (ideally) independent of each other. On real-world datasets, our method outperforms other baselines and obtains state-of-the-art results in terms of transfer accuracy and voice naturalness.",
        "conference": "ICLR",
        "中文标题": "通过解耦表示学习改进零样本语音风格转换",
        "摘要翻译": "语音风格转换，也称为语音转换，旨在修改一个说话者的语音以生成听起来像是来自另一个（目标）说话者的语音。先前的工作在使用并行训练数据和预先已知的说话者进行语音转换方面取得了进展。然而，零样本语音风格转换，即从非并行数据中学习并为之前未见过的说话者生成语音，仍然是一个具有挑战性的问题。在本文中，我们提出了一种通过解耦表示学习的新型零样本语音转换方法。所提出的方法首先将每个输入语音的说话者相关风格和语音内容编码到独立的低维嵌入空间中，然后通过解码器将源内容嵌入和目标风格嵌入结合起来，转换到新的语音。在信息理论的指导下，风格和内容嵌入空间具有代表性并且（理想情况下）彼此独立。在真实世界的数据集上，我们的方法在其他基线方法中表现优异，并在转换准确性和语音自然度方面取得了最先进的结果。",
        "领域": "语音合成、语音转换、零样本学习",
        "问题": "解决在非并行数据和未见过的说话者条件下进行零样本语音风格转换的挑战",
        "动机": "探索如何在没有并行训练数据和未知说话者的情况下，实现高质量的语音风格转换",
        "方法": "通过解耦表示学习，将语音内容与说话者风格分离，并在信息理论指导下进行独立编码和解码",
        "关键词": [
            "零样本学习",
            "语音风格转换",
            "解耦表示学习",
            "信息理论",
            "语音合成"
        ],
        "涉及的技术概念": {
            "解耦表示学习": "将语音中的风格和内容信息分离到独立的嵌入空间，以便于风格转换",
            "零样本学习": "在没有见过目标说话者样本的情况下，实现语音风格转换",
            "信息理论": "用于指导风格和内容嵌入空间的构建，确保它们既具有代表性又相互独立"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 371,
        "title": "Incorporating Symmetry into Deep Dynamics Models for Improved Generalization",
        "html": "https://iclr.cc//virtual/2021/poster/2785",
        "abstract": "Recent work has shown deep learning can accelerate the prediction of physical dynamics relative to numerical solvers. However, limited physical accuracy and an inability to generalize under distributional shift limit its applicability to the real world. We propose to improve accuracy and generalization by incorporating symmetries into convolutional neural networks. Specifically, we employ a variety of methods each tailored to enforce a different symmetry. Our models are both theoretically and experimentally robust to distributional shift by symmetry group transformations and enjoy favorable sample complexity. We demonstrate the advantage of our approach on a variety of physical dynamics including Rayleigh–Bénard convection and real-world ocean currents and temperatures. Compare with image or text applications, our work is a significant step towards applying equivariant neural networks to high-dimensional systems with complex dynamics.",
        "conference": "ICLR",
        "中文标题": "将对称性融入深度动力学模型以提升泛化能力",
        "摘要翻译": "最近的研究表明，深度学习可以加速物理动力学的预测，相较于数值解法。然而，有限的物理准确性和在分布变化下泛化能力的不足限制了其在现实世界中的应用。我们提出通过将对称性融入卷积神经网络来提高准确性和泛化能力。具体来说，我们采用了多种方法，每种方法都针对性地强化不同的对称性。我们的模型在理论上和实验上都能通过对称群变换对分布变化保持鲁棒，并享有有利的样本复杂度。我们在包括Rayleigh–Bénard对流和现实世界中的洋流及温度在内的多种物理动力学上展示了我们方法的优势。与图像或文本应用相比，我们的工作是将等变神经网络应用于具有复杂动力学的高维系统的重要一步。",
        "领域": "物理动力学预测、等变神经网络、高维系统建模",
        "问题": "提高深度学习模型在物理动力学预测中的准确性和在分布变化下的泛化能力",
        "动机": "解决深度学习在物理动力学预测中因有限物理准确性和泛化能力不足而难以应用于现实世界的问题",
        "方法": "通过将对称性融入卷积神经网络，采用多种针对性强化的对称性方法，提高模型的准确性和泛化能力",
        "关键词": [
            "对称性融入",
            "物理动力学预测",
            "等变神经网络",
            "高维系统",
            "泛化能力"
        ],
        "涉及的技术概念": {
            "对称性融入": "将物理系统中的对称性原理融入深度学习模型，以提高模型的物理准确性和泛化能力",
            "等变神经网络": "一种能够保持输入变换下输出相应变换的神经网络，特别适用于处理具有对称性的物理系统",
            "高维系统建模": "指对具有大量自由度和复杂动力学的系统进行建模和预测，是物理动力学预测中的一个挑战"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 372,
        "title": "Incremental few-shot learning via vector quantization in deep embedded space",
        "html": "https://iclr.cc//virtual/2021/poster/2948",
        "abstract": "The capability of incrementally learning new tasks without forgetting old ones is a challenging problem due to catastrophic forgetting. This challenge becomes greater when novel tasks contain very few labelled training samples. Currently, most methods are dedicated to class-incremental learning and rely on sufficient training data to learn additional weights for newly added classes. Those methods cannot be easily extended to incremental regression tasks and could suffer from severe overfitting when learning few-shot novel tasks. In this study, we propose a nonparametric method in deep embedded space to tackle incremental few-shot learning problems. The knowledge about the learned tasks are compressed into a small number of quantized reference vectors. The proposed method learns new tasks sequentially by adding more reference vectors to the model using few-shot samples in each novel task. For classification problems, we employ the nearest neighbor scheme to make classification on sparsely available data and incorporate intra-class variation, less forgetting regularization and calibration of reference vectors to mitigate catastrophic forgetting. In addition, the proposed learning vector quantization (LVQ) in deep embedded space can be customized as a kernel smoother to handle incremental few-shot regression tasks. Experimental results demonstrate that the proposed method outperforms other state-of-the-art methods in incremental learning.",
        "conference": "ICLR",
        "中文标题": "通过深度嵌入空间中的向量量化实现增量式少样本学习",
        "摘要翻译": "由于灾难性遗忘，增量式学习新任务而不遗忘旧任务的能力是一个具有挑战性的问题。当新任务包含非常少的标记训练样本时，这一挑战变得更大。目前，大多数方法致力于类增量学习，并依赖于足够的训练数据来为新添加的类学习额外的权重。这些方法不能轻易扩展到增量回归任务，并且在少样本新任务学习中可能会遭受严重的过拟合。在本研究中，我们提出了一种在深度嵌入空间中的非参数方法来解决增量式少样本学习问题。关于已学习任务的知识被压缩成少量量化的参考向量。所提出的方法通过在每个新任务中使用少样本样本来向模型添加更多参考向量，从而顺序学习新任务。对于分类问题，我们采用最近邻方案对稀疏可用数据进行分类，并结合类内变异、减少遗忘正则化和参考向量校准来减轻灾难性遗忘。此外，所提出的深度嵌入空间中的学习向量量化（LVQ）可以定制为核平滑器来处理增量式少样本回归任务。实验结果表明，所提出的方法在增量学习方面优于其他最先进的方法。",
        "领域": "增量学习、少样本学习、深度嵌入学习",
        "问题": "解决在增量学习过程中，面对少样本新任务时的灾难性遗忘和过拟合问题",
        "动机": "探索一种能够在少样本条件下有效进行增量学习，同时减轻灾难性遗忘的方法",
        "方法": "提出一种在深度嵌入空间中的非参数方法，通过量化参考向量来压缩已学知识，并采用最近邻分类和核平滑器处理分类和回归任务",
        "关键词": [
            "增量学习",
            "少样本学习",
            "向量量化",
            "深度嵌入空间",
            "灾难性遗忘"
        ],
        "涉及的技术概念": {
            "向量量化": "在深度嵌入空间中压缩已学习任务的知识为少量参考向量，用于增量学习",
            "最近邻分类": "用于在少样本条件下对稀疏数据进行分类，结合类内变异减少遗忘",
            "核平滑器": "定制化的学习向量量化方法，用于处理增量式少样本回归任务"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 373,
        "title": "In Defense of Pseudo-Labeling: An Uncertainty-Aware Pseudo-label Selection Framework for Semi-Supervised Learning",
        "html": "https://iclr.cc//virtual/2021/poster/3255",
        "abstract": "The recent research in semi-supervised learning (SSL) is mostly dominated by consistency regularization based methods which achieve strong performance. However, they heavily rely on domain-specific data augmentations, which are not easy to generate for all data modalities. Pseudo-labeling (PL) is a general SSL approach that does not have this constraint but performs relatively poorly in its original formulation. We argue that PL underperforms due to the erroneous high confidence predictions from poorly calibrated models; these predictions generate many incorrect pseudo-labels, leading to noisy training. We propose an uncertainty-aware pseudo-label selection (UPS) framework which improves pseudo labeling accuracy by drastically reducing the amount of noise encountered in the training process. Furthermore, UPS generalizes the pseudo-labeling process, allowing for the creation of negative pseudo-labels; these negative pseudo-labels can be used for multi-label classification as well as negative learning to improve the single-label classification. We achieve strong performance when compared to recent SSL methods on the CIFAR-10 and CIFAR-100 datasets. Also, we demonstrate the versatility of our method on the video dataset UCF-101 and the multi-label dataset Pascal VOC.",
        "conference": "ICLR",
        "中文标题": "为伪标签辩护：一种半监督学习中基于不确定性感知的伪标签选择框架",
        "摘要翻译": "最近半监督学习（SSL）的研究主要由基于一致性正则化的方法主导，这些方法取得了强劲的性能。然而，它们严重依赖于特定领域的数据增强，这对于所有数据模态来说并不容易生成。伪标签（PL）是一种通用的SSL方法，没有这一限制，但在其原始形式中表现相对较差。我们认为PL表现不佳是由于校准不佳的模型产生的高置信度预测错误；这些预测生成了许多不正确的伪标签，导致训练过程中的噪声。我们提出了一种基于不确定性感知的伪标签选择（UPS）框架，通过大幅减少训练过程中遇到的噪声量来提高伪标签的准确性。此外，UPS泛化了伪标签过程，允许创建负伪标签；这些负伪标签可用于多标签分类以及负学习，以改进单标签分类。与最近的SSL方法相比，我们在CIFAR-10和CIFAR-100数据集上取得了强劲的性能。此外，我们在视频数据集UCF-101和多标签数据集Pascal VOC上展示了我们方法的通用性。",
        "领域": "半监督学习、多标签分类、视频分类",
        "问题": "解决伪标签方法在半监督学习中由于模型校准不佳导致的高置信度错误预测和噪声训练问题",
        "动机": "提高伪标签方法的准确性和泛化能力，减少训练过程中的噪声，同时扩展其应用于多标签分类和负学习",
        "方法": "提出一种不确定性感知的伪标签选择（UPS）框架，通过减少噪声和引入负伪标签来改进伪标签的准确性和应用范围",
        "关键词": [
            "伪标签选择",
            "不确定性感知",
            "半监督学习",
            "多标签分类",
            "负学习"
        ],
        "涉及的技术概念": {
            "伪标签（PL）": "一种半监督学习方法，通过模型预测为未标记数据生成标签",
            "不确定性感知": "评估模型预测的置信度，用于筛选高质量的伪标签",
            "负伪标签": "用于表示样本不属于某一类别的伪标签，扩展了伪标签在多标签分类和负学习中的应用"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 374,
        "title": "Individually Fair Gradient Boosting",
        "html": "https://iclr.cc//virtual/2021/poster/2749",
        "abstract": "We consider the task of enforcing individual fairness in gradient boosting. Gradient boosting is a popular method for machine learning from tabular data, which arise often in applications where algorithmic fairness is a concern. At a high level, our approach is a functional gradient descent on a (distributionally) robust loss function that encodes our intuition of algorithmic fairness for the ML task at hand. Unlike prior approaches to individual fairness that only work with smooth ML models, our approach also works with non-smooth models such as decision trees. We show that our algorithm converges globally and generalizes. We also demonstrate the efficacy of our algorithm on three ML problems susceptible to algorithmic bias.",
        "conference": "ICLR",
        "中文标题": "个体公平梯度提升",
        "摘要翻译": "我们考虑在梯度提升中实施个体公平性的任务。梯度提升是一种流行的从表格数据中学习的方法，这些数据经常出现在算法公平性受到关注的应用中。从高层次来看，我们的方法是对一个（分布上）鲁棒的损失函数进行函数梯度下降，该损失函数编码了我们对手头机器学习任务算法公平性的直觉。与之前仅适用于平滑机器学习模型的个体公平性方法不同，我们的方法也适用于非平滑模型，如决策树。我们证明了我们的算法具有全局收敛性和泛化能力。我们还在三个容易受到算法偏差影响的机器学习问题上展示了我们算法的有效性。",
        "领域": "机器学习公平性、梯度提升、决策树",
        "问题": "在梯度提升中实施个体公平性",
        "动机": "解决在机器学习应用中，尤其是在使用非平滑模型如决策树时，如何确保算法公平性的问题。",
        "方法": "采用函数梯度下降方法，在鲁棒的损失函数上进行优化，以编码算法公平性的直觉。",
        "关键词": [
            "个体公平性",
            "梯度提升",
            "决策树",
            "算法公平性",
            "机器学习"
        ],
        "涉及的技术概念": {
            "梯度提升": "一种流行的从表格数据中学习的方法，用于本研究中实施个体公平性。",
            "个体公平性": "研究中的核心目标，确保算法对所有个体公平。",
            "鲁棒的损失函数": "研究中用于编码算法公平性直觉的函数，通过函数梯度下降进行优化。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 375,
        "title": "Individually Fair Rankings",
        "html": "https://iclr.cc//virtual/2021/poster/2627",
        "abstract": "We develop an algorithm to train individually fair learning-to-rank (LTR) models. The proposed approach ensures items from minority groups appear alongside similar items from majority groups. This notion of fair ranking is based on the definition of individual fairness from supervised learning and is more nuanced than prior fair LTR approaches that simply ensure the ranking model provides underrepresented items with a basic level of exposure. The crux of our method is an optimal transport-based regularizer that enforces individual fairness and an efficient algorithm for optimizing the regularizer. We show that our approach leads to certifiably individually fair LTR models and demonstrate the efficacy of our method on ranking tasks subject to demographic biases.",
        "conference": "ICLR",
        "中文标题": "个体公平排名",
        "摘要翻译": "我们开发了一种算法来训练个体公平的学习排名（LTR）模型。所提出的方法确保来自少数群体的项目与来自多数群体的相似项目一起出现。这种公平排名的概念基于监督学习中个体公平的定义，比之前简单的公平LTR方法更为细致，后者仅确保排名模型为代表性不足的项目提供基本的曝光度。我们方法的核心是一个基于最优传输的正则化器，它强制执行个体公平，以及一个优化正则化器的高效算法。我们展示了我们的方法能够产生可证明的个体公平LTR模型，并在受人口统计偏差影响的排名任务上证明了我们方法的有效性。",
        "领域": "学习排名、公平机器学习、算法公平性",
        "问题": "如何在学习排名模型中实现个体公平，确保少数群体项目获得与多数群体相似项目同等的曝光机会。",
        "动机": "解决现有公平LTR方法仅提供基本曝光保障，无法实现更细致的个体公平问题。",
        "方法": "采用基于最优传输的正则化器强制执行个体公平，并开发高效算法优化该正则化器。",
        "关键词": [
            "个体公平",
            "学习排名",
            "最优传输",
            "正则化器",
            "算法公平性"
        ],
        "涉及的技术概念": {
            "个体公平": "基于监督学习中个体公平的定义，确保每个个体在排名中获得公平对待。",
            "最优传输": "用于设计正则化器，强制执行个体公平，确保少数和多数群体项目在排名中的公平分布。",
            "正则化器": "通过优化算法调整，以在模型训练中强制执行个体公平原则。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 376,
        "title": "Inductive Representation Learning in Temporal Networks via Causal Anonymous Walks",
        "html": "https://iclr.cc//virtual/2021/poster/2651",
        "abstract": "Temporal networks serve as abstractions of many real-world dynamic systems. These networks typically evolve according to certain laws, such as the law of triadic closure, which is universal in social networks. Inductive representation learning of temporal networks should be able to capture such laws and further be applied to systems that follow the same laws but have not been unseen during the training stage. Previous works in this area depend on either network node identities or rich edge attributes and typically fail to extract these laws. Here, we propose {\\em Causal Anonymous Walks (CAWs)} to inductively represent a temporal network. CAWs are extracted by temporal random walks and work as automatic retrieval of temporal network motifs to represent network dynamics while avoiding the time-consuming selection and counting of those motifs. CAWs adopt a novel anonymization strategy that replaces node identities with the hitting counts of the nodes based on a set of sampled walks to keep the method inductive, and simultaneously establish the correlation between motifs. We further propose a neural-network model CAW-N to encode CAWs, and pair it with a CAW sampling strategy with constant memory and time cost to support online training and inference. CAW-N is evaluated to predict links over 6 real temporal networks and uniformly outperforms previous SOTA methods by averaged 15\\% AUC gain in the inductive setting. CAW-N also outperforms previous methods in 5 out of the 6 networks in the transductive setting.",
        "conference": "ICLR",
        "中文标题": "通过因果匿名游走的时序网络归纳表示学习",
        "摘要翻译": "时序网络作为许多现实世界动态系统的抽象，通常按照某些规律演化，如社交网络中普遍存在的三元闭包定律。时序网络的归纳表示学习应能捕捉这些规律，并进一步应用于遵循相同规律但在训练阶段未见过的系统。该领域的先前工作依赖于网络节点身份或丰富的边属性，通常无法提取这些规律。在此，我们提出了因果匿名游走（CAWs）来归纳表示时序网络。CAWs通过时序随机游走提取，作为自动检索时序网络模体以表示网络动态的方法，同时避免了这些模体的耗时选择和计数。CAWs采用了一种新颖的匿名化策略，将节点身份替换为基于一组采样游走的节点命中计数，以保持方法的归纳性，并同时建立模体之间的相关性。我们进一步提出了一个神经网络模型CAW-N来编码CAWs，并将其与具有恒定内存和时间成本的CAW采样策略配对，以支持在线训练和推理。CAW-N在6个真实时序网络上进行了链接预测评估，并在归纳设置中平均优于先前的最先进方法15%的AUC增益。在转导设置中，CAW-N在6个网络中的5个上也优于先前的方法。",
        "领域": "时序网络分析, 表示学习, 动态网络建模",
        "问题": "如何在时序网络中归纳学习表示，捕捉网络动态规律并应用于未见过的系统",
        "动机": "解决现有方法依赖节点身份或丰富边属性，难以捕捉和泛化时序网络动态规律的问题",
        "方法": "提出因果匿名游走（CAWs）和神经网络模型CAW-N，通过匿名化策略和恒定成本的采样策略，实现时序网络的归纳表示学习和高效在线处理",
        "关键词": [
            "因果匿名游走",
            "时序网络",
            "归纳表示学习",
            "动态网络建模",
            "链接预测"
        ],
        "涉及的技术概念": {
            "因果匿名游走（CAWs）": "一种通过时序随机游走提取的表示方法，用于自动检索时序网络模体并捕捉网络动态，同时保持归纳性",
            "匿名化策略": "将节点身份替换为基于采样游走的节点命中计数，以保持方法的归纳性并建立模体间相关性",
            "CAW-N模型": "一个神经网络模型，用于编码CAWs，与恒定成本的采样策略配对，支持高效的在线训练和推理"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 377,
        "title": "Influence Estimation for Generative Adversarial Networks",
        "html": "https://iclr.cc//virtual/2021/poster/2970",
        "abstract": "Identifying harmful instances, whose absence in a training dataset improves model performance, is important for building better machine learning models. \nAlthough previous studies have succeeded in estimating harmful instances under supervised settings, they cannot be trivially extended to generative adversarial networks (GANs).\nThis is because previous approaches require that (i) the absence of a training instance directly affects the loss value and that (ii) the change in the loss directly measures the harmfulness of the instance for the performance of a model. \nIn GAN training, however, neither of the requirements is satisfied. \nThis is because, (i) the generator’s loss is not directly affected by the training instances as they are not part of the generator's training steps, and (ii) the values of GAN's losses normally do not capture the generative performance of a model.\nTo this end, (i) we propose an influence estimation method that uses the Jacobian of the gradient of the generator's loss with respect to the discriminator’s parameters (and vice versa) to trace how the absence of an instance in the discriminator’s training affects the generator’s parameters, and (ii) we propose a novel evaluation scheme, in which we assess harmfulness of each training instance on the basis of how GAN evaluation metric (e.g., inception score) is expected to change due to the removal of the instance.\nWe experimentally verified that our influence estimation method correctly inferred the changes in GAN evaluation metrics.\nWe also demonstrated that the removal of the identified harmful instances effectively improved the model’s generative performance with respect to various GAN evaluation metrics.",
        "conference": "ICLR",
        "中文标题": "生成对抗网络的影响估计",
        "摘要翻译": "识别有害实例，即在训练数据集中移除这些实例可以提高模型性能，对于构建更好的机器学习模型非常重要。尽管先前的研究在监督设置下成功估计了有害实例，但它们不能简单地扩展到生成对抗网络（GANs）。这是因为先前的方法要求（i）训练实例的缺失直接影响损失值，以及（ii）损失的变化直接衡量实例对模型性能的有害性。然而，在GAN训练中，这两个要求都不满足。这是因为，（i）生成器的损失不直接受训练实例的影响，因为它们不是生成器训练步骤的一部分，以及（ii）GAN损失的值通常不捕捉模型的生成性能。为此，（i）我们提出了一种影响估计方法，该方法使用生成器损失相对于判别器参数的梯度的雅可比矩阵（反之亦然）来追踪判别器训练中实例的缺失如何影响生成器的参数，以及（ii）我们提出了一种新的评估方案，在该方案中，我们基于GAN评估指标（如初始分数）预期如何因实例的移除而变化来评估每个训练实例的有害性。我们通过实验验证了我们的影响估计方法正确推断出了GAN评估指标的变化。我们还证明了移除已识别的有害实例有效地提高了模型在各种GAN评估指标下的生成性能。",
        "领域": "生成对抗网络、深度学习优化、模型性能评估",
        "问题": "如何在生成对抗网络中有效识别和移除有害训练实例以提高模型性能",
        "动机": "现有方法无法直接应用于GANs，因为GANs的训练机制和性能评估与传统的监督学习不同，需要新的方法来识别有害实例",
        "方法": "提出了一种基于雅可比矩阵的影响估计方法和一个新的评估方案，用于追踪实例移除对生成器参数的影响并评估实例的有害性",
        "关键词": [
            "生成对抗网络",
            "影响估计",
            "有害实例识别",
            "模型性能优化",
            "雅可比矩阵"
        ],
        "涉及的技术概念": {
            "雅可比矩阵": "用于追踪生成器损失相对于判别器参数梯度的变化，以评估实例移除对生成器的影响",
            "GAN评估指标": "如初始分数，用于衡量生成模型的性能，作为评估实例有害性的依据",
            "影响估计方法": "通过分析训练实例移除对模型性能的影响，识别有害实例以优化模型训练"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 378,
        "title": "Influence Functions in Deep Learning Are Fragile",
        "html": "https://iclr.cc//virtual/2021/poster/2841",
        "abstract": "Influence functions approximate the effect of training samples in test-time predictions and have a wide variety of applications in machine learning interpretability and uncertainty estimation. A commonly-used (first-order) influence function can be implemented efficiently as a post-hoc method requiring access only to the gradients and Hessian of the model. For linear models, influence functions are well-defined due to the convexity of the underlying loss function and are generally accurate even across difficult settings where model changes are fairly large such as estimating group influences. Influence functions, however, are not well-understood in the context of deep learning with non-convex loss functions.  In this paper, we provide a comprehensive and large-scale empirical study of successes and failures of influence functions in neural network models trained on datasets such as Iris, MNIST, CIFAR-10 and ImageNet. Through our extensive experiments, we show that the network architecture, its depth and width, as well as the extent of model parameterization and regularization techniques have strong effects in the accuracy of influence functions. In particular, we find that (i) influence estimates are fairly accurate for shallow networks, while for deeper networks the estimates are often erroneous; (ii) for certain network architectures and datasets, training with weight-decay regularization is important to get high-quality influence estimates; and (iii) the accuracy of influence estimates can vary significantly depending on the examined test points. These results suggest that in general influence functions in deep learning are fragile and call for developing improved influence estimation methods to mitigate these issues in non-convex setups.",
        "conference": "ICLR",
        "中文标题": "深度学习中的影响函数是脆弱的",
        "摘要翻译": "影响函数近似于训练样本在测试时预测中的影响，并在机器学习可解释性和不确定性估计中有广泛应用。一种常用的（一阶）影响函数可以作为一种事后方法高效实现，仅需要访问模型的梯度和Hessian矩阵。对于线性模型，由于基础损失函数的凸性，影响函数定义良好，并且即使在模型变化相当大的困难设置下（如估计群体影响）通常也是准确的。然而，在具有非凸损失函数的深度学习背景下，影响函数尚未被充分理解。在本文中，我们对神经网络模型（在Iris、MNIST、CIFAR-10和ImageNet等数据集上训练）中影响函数的成功和失败进行了全面且大规模的实证研究。通过我们的广泛实验，我们发现网络架构、其深度和宽度，以及模型参数化和正则化技术的程度对影响函数的准确性有强烈影响。特别是，我们发现（i）对于浅层网络，影响估计相当准确，而对于更深层的网络，估计往往是错误的；（ii）对于某些网络架构和数据集，使用权重衰减正则化训练对于获得高质量的影响估计很重要；（iii）影响估计的准确性可能因检查的测试点而有显著差异。这些结果表明，深度学习中的影响函数通常是脆弱的，并呼吁开发改进的影响估计方法以缓解非凸设置中的这些问题。",
        "领域": "深度学习可解释性、不确定性估计、神经网络优化",
        "问题": "深度学习模型中影响函数的准确性和可靠性问题",
        "动机": "探索在非凸损失函数的深度学习背景下，影响函数的适用性和准确性",
        "方法": "通过在不同数据集和网络架构上的大规模实证研究，分析影响函数的准确性和影响因素",
        "关键词": [
            "影响函数",
            "深度学习",
            "非凸优化",
            "模型可解释性",
            "不确定性估计"
        ],
        "涉及的技术概念": {
            "影响函数": "用于估计训练样本对模型预测影响的工具，基于模型的梯度和Hessian矩阵",
            "非凸优化": "在深度学习模型中，损失函数通常是非凸的，这使得影响函数的准确估计变得复杂",
            "权重衰减正则化": "一种正则化技术，用于防止模型过拟合，研究发现其对提高影响函数估计的准确性有重要作用"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 379,
        "title": "InfoBERT: Improving Robustness of Language Models from An Information Theoretic Perspective",
        "html": "https://iclr.cc//virtual/2021/poster/3123",
        "abstract": "Large-scale language models such as BERT have achieved state-of-the-art performance across a wide range of NLP tasks. Recent studies, however, show that such BERT-based models are vulnerable facing the threats of textual adversarial attacks. We aim to address this problem from an information-theoretic perspective, and propose InfoBERT, a novel learning framework for robust ﬁne-tuning of pre-trained language models. InfoBERT contains two mutual-information-based regularizers for model training: (i) an Information Bottleneck regularizer, which suppresses noisy mutual information between the input and the feature representation; and (ii) a Robust Feature regularizer, which increases the mutual information between local robust features and global features. We provide a principled way to theoretically analyze and improve the robustness of representation learning for language models in both standard and adversarial training. Extensive experiments demonstrate that InfoBERT achieves state-of-the-art robust accuracy over several adversarial datasets on Natural Language Inference (NLI) and Question Answering (QA) tasks.\nOur code is available at https://github.com/AI-secure/InfoBERT.",
        "conference": "ICLR",
        "中文标题": "InfoBERT：从信息论角度提升语言模型的鲁棒性",
        "摘要翻译": "诸如BERT这样的大规模语言模型已在广泛的自然语言处理任务中实现了最先进的性能。然而，最近的研究表明，这类基于BERT的模型在面对文本对抗攻击的威胁时显得脆弱。我们旨在从信息论的角度解决这一问题，并提出了InfoBERT，一种新颖的学习框架，用于预训练语言模型的鲁棒微调。InfoBERT包含两个基于互信息的正则化器用于模型训练：（i）信息瓶颈正则化器，它抑制输入与特征表示之间的噪声互信息；（ii）鲁棒特征正则化器，它增加局部鲁棒特征与全局特征之间的互信息。我们提供了一种原则性的方法，从理论上分析和改进语言模型在标准和对抗训练中的表示学习鲁棒性。大量实验证明，InfoBERT在自然语言推理（NLI）和问答（QA）任务的多个对抗数据集上实现了最先进的鲁棒准确率。我们的代码可在https://github.com/AI-secure/InfoBERT获取。",
        "领域": "自然语言处理与视觉结合, 对抗性学习, 语言模型鲁棒性",
        "问题": "提高基于BERT的语言模型在面对文本对抗攻击时的鲁棒性",
        "动机": "解决BERT等大规模语言模型在对抗攻击下的脆弱性问题",
        "方法": "提出InfoBERT框架，包含信息瓶颈正则化器和鲁棒特征正则化器，用于抑制噪声互信息和增强特征间的互信息",
        "关键词": [
            "InfoBERT",
            "对抗性学习",
            "信息论",
            "语言模型",
            "鲁棒性"
        ],
        "涉及的技术概念": {
            "信息瓶颈正则化器": "用于抑制输入与特征表示之间的噪声互信息，提高模型的鲁棒性",
            "鲁棒特征正则化器": "增加局部鲁棒特征与全局特征之间的互信息，增强模型对抗攻击的能力",
            "互信息": "衡量两个变量之间相互依赖性的指标，在InfoBERT中用于优化特征表示"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 380,
        "title": "Information Laundering for Model Privacy",
        "html": "https://iclr.cc//virtual/2021/poster/2710",
        "abstract": "In this work, we propose information laundering, a novel framework for enhancing model privacy. Unlike data privacy that concerns the protection of raw data information, model privacy aims to protect an already-learned model that is to be deployed for public use. The private model can be obtained from general learning methods, and its deployment means that it will return a deterministic or random response for a given input query. An information-laundered model consists of probabilistic components that deliberately maneuver the intended input and output for queries of the model, so the model's adversarial acquisition is less likely. Under the proposed framework, we develop an information-theoretic principle to quantify the fundamental tradeoffs between model utility and privacy leakage and derive the optimal design.",
        "conference": "ICLR",
        "中文标题": "信息洗白以增强模型隐私",
        "摘要翻译": "在这项工作中，我们提出了信息洗白，一个增强模型隐私的新框架。与关注保护原始数据信息的数据隐私不同，模型隐私旨在保护一个已经学习完毕并准备公开部署的模型。这个私有模型可以通过一般的学习方法获得，其部署意味着对于给定的输入查询，它将返回一个确定性的或随机的响应。一个经过信息洗白的模型包含概率性组件，这些组件故意操纵模型的输入和输出，从而降低模型被对抗性获取的可能性。在提出的框架下，我们开发了一个信息论原则来量化模型效用和隐私泄露之间的基本权衡，并推导出最优设计。",
        "领域": "模型隐私保护、对抗性机器学习、信息论安全",
        "问题": "如何在模型部署时保护其不被对抗性获取，同时保持模型的实用性。",
        "动机": "现有的隐私保护方法主要关注数据隐私，而对模型隐私的保护研究较少。随着模型部署的普及，保护模型不被恶意利用成为一个重要问题。",
        "方法": "提出信息洗白框架，通过引入概率性组件操纵模型的输入和输出，减少模型被对抗性获取的风险，并基于信息论原则量化效用与隐私的权衡。",
        "关键词": [
            "模型隐私",
            "信息洗白",
            "对抗性获取",
            "信息论",
            "概率性组件"
        ],
        "涉及的技术概念": {
            "信息洗白": "通过引入概率性组件操纵模型的输入和输出，旨在降低模型被对抗性获取的风险。",
            "信息论原则": "用于量化模型效用和隐私泄露之间的权衡，指导最优设计。",
            "对抗性获取": "指攻击者通过查询模型试图获取或重构模型的敏感信息的行为。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 381,
        "title": "Initialization and Regularization of Factorized Neural Layers",
        "html": "https://iclr.cc//virtual/2021/poster/2913",
        "abstract": "Factorized layers—operations parameterized by products of two or more matrices—occur in a variety of deep learning contexts, including compressed model training, certain types of knowledge distillation, and multi-head self-attention architectures. We study how to initialize and regularize deep nets containing such layers, examining two simple, understudied schemes, spectral initialization and Frobenius decay, for improving their performance. The guiding insight is to design optimization routines for these networks that are as close as possible to that of their well-tuned, non-decomposed counterparts; we back this intuition with an analysis of how the initialization and regularization schemes impact training with gradient descent, drawing on modern attempts to understand the interplay of weight-decay and batch-normalization. Empirically, we highlight the benefits of spectral initialization and Frobenius decay across a variety of settings. In model compression, we show that they enable low-rank methods to significantly outperform both unstructured sparsity and tensor methods on the task of training low-memory residual networks; analogs of the schemes also improve the performance of tensor decomposition techniques. For knowledge distillation, Frobenius decay enables a simple, overcomplete baseline that yields a compact model from over-parameterized training without requiring retraining with or pruning a teacher network. Finally, we show how both schemes applied to multi-head attention lead to improved performance on both translation and unsupervised pre-training.",
        "conference": "ICLR",
        "中文标题": "因子化神经层的初始化与正则化",
        "摘要翻译": "因子化层——由两个或多个矩阵乘积参数化的操作——出现在多种深度学习场景中，包括压缩模型训练、某些类型的知识蒸馏以及多头自注意力架构。我们研究了如何初始化和正则化包含此类层的深度网络，考察了两种简单且研究不足的方案：谱初始化和Frobenius衰减，以提高其性能。指导性的见解是设计这些网络的优化程序，使其尽可能接近其经过良好调整的非分解对应物；我们通过分析初始化和正则化方案如何影响梯度下降训练来支持这一直觉，借鉴了现代尝试理解权重衰减和批量归一化之间相互作用的努力。实证上，我们强调了谱初始化和Frobenius衰减在各种设置中的好处。在模型压缩中，我们展示了它们使低秩方法在训练低内存残差网络的任务上显著优于非结构化稀疏性和张量方法；这些方案的类似物也提高了张量分解技术的性能。对于知识蒸馏，Frobenius衰减实现了一个简单的、过完备的基线，它可以从过参数化训练中产生一个紧凑模型，而无需重新训练或修剪教师网络。最后，我们展示了这两种方案应用于多头注意力时，如何在翻译和无监督预训练上带来性能提升。",
        "领域": "模型压缩, 知识蒸馏, 多头自注意力机制",
        "问题": "如何有效地初始化和正则化因子化神经层以提高深度学习模型的性能",
        "动机": "探索因子化层在深度学习中的有效初始化和正则化方法，以提升模型性能，特别是在模型压缩、知识蒸馏和多头自注意力架构中的应用",
        "方法": "研究了谱初始化和Frobenius衰减两种方案，通过分析它们对梯度下降训练的影响，设计接近非分解对应物的优化程序",
        "关键词": [
            "因子化层",
            "谱初始化",
            "Frobenius衰减",
            "模型压缩",
            "知识蒸馏"
        ],
        "涉及的技术概念": {
            "因子化层": "由两个或多个矩阵乘积参数化的操作，用于压缩模型训练、知识蒸馏和多头自注意力架构",
            "谱初始化": "一种初始化方法，旨在通过考虑矩阵的谱性质来改善因子化层的训练",
            "Frobenius衰减": "一种正则化技术，通过惩罚权重矩阵的Frobenius范数来控制模型的复杂度，防止过拟合"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 382,
        "title": "In-N-Out: Pre-Training and Self-Training using Auxiliary Information for Out-of-Distribution Robustness",
        "html": "https://iclr.cc//virtual/2021/poster/2947",
        "abstract": "Consider a prediction setting with few in-distribution labeled examples and many unlabeled examples both in- and out-of-distribution (OOD). The goal is to learn a model which performs well both in-distribution and OOD. In these settings, auxiliary information is often cheaply available for every input. How should we best leverage this auxiliary information for the prediction task? Empirically across three image and time-series datasets, and theoretically in a multi-task linear regression setting, we show that (i) using auxiliary information as input features improves in-distribution error but can hurt OOD error; but (ii) using auxiliary information as outputs of auxiliary pre-training tasks improves OOD error. To get the best of both worlds, we introduce In-N-Out, which first trains a model with auxiliary inputs and uses it to pseudolabel all the in-distribution inputs, then pre-trains a model on OOD auxiliary outputs and fine-tunes this model with the pseudolabels (self-training). We show both theoretically and empirically that In-N-Out outperforms auxiliary inputs or outputs alone on both in-distribution and OOD error.",
        "conference": "ICLR",
        "中文标题": "内外兼修：利用辅助信息进行预训练和自训练以增强分布外鲁棒性",
        "摘要翻译": "考虑一个预测场景，其中分布内的标记样本很少，而分布内外的未标记样本很多。目标是学习一个在分布内和分布外（OOD）都表现良好的模型。在这些情况下，每个输入的辅助信息通常可以廉价获得。我们如何最好地利用这些辅助信息进行预测任务？通过对三个图像和时间序列数据集的实证研究，以及在多任务线性回归设置中的理论分析，我们发现：（i）将辅助信息用作输入特征可以改善分布内误差，但可能损害OOD误差；（ii）将辅助信息用作辅助预训练任务的输出可以改善OOD误差。为了两全其美，我们引入了In-N-Out方法，该方法首先训练一个带有辅助输入的模型，并用它对所有分布内输入进行伪标记，然后在OOD辅助输出上预训练一个模型，并用伪标记微调这个模型（自训练）。我们通过理论和实证表明，In-N-Out在分布内和OOD误差上都优于单独使用辅助输入或输出。",
        "领域": "分布外泛化、自监督学习、多任务学习",
        "问题": "如何在分布内标记样本稀少且存在大量分布内外未标记样本的情况下，学习一个在分布内和分布外都表现良好的模型。",
        "动机": "探索如何有效利用廉价可得的辅助信息，以提升模型在分布内外的泛化能力。",
        "方法": "提出In-N-Out方法，结合辅助信息的输入和输出使用，通过预训练和自训练策略优化模型性能。",
        "关键词": [
            "分布外鲁棒性",
            "辅助信息",
            "预训练",
            "自训练",
            "多任务学习"
        ],
        "涉及的技术概念": {
            "辅助信息": "用于增强模型训练和性能的外部数据或特征，可以以输入或输出的形式被利用。",
            "预训练": "在目标任务之前，利用辅助任务对模型进行初步训练，以提取有用的特征表示。",
            "自训练": "利用模型自身的预测结果（伪标签）来进一步训练模型，通常用于半监督学习场景。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 383,
        "title": "In Search of Lost Domain Generalization",
        "html": "https://iclr.cc//virtual/2021/poster/2998",
        "abstract": "The goal of domain generalization algorithms is to predict well on distributions different from those seen during training.\nWhile a myriad of domain generalization algorithms exist, inconsistencies in experimental conditions---datasets, network architectures, and model selection criteria---render fair comparisons difficult.\nThe goal of this paper is to understand how useful domain generalization algorithms are in realistic settings.\nAs a first step, we realize that model selection is non-trivial for domain generalization tasks, and we argue that algorithms without a model selection criterion remain incomplete.\nNext we implement DomainBed, a testbed for domain generalization including seven benchmarks, fourteen algorithms, and three model selection criteria.\nWhen conducting extensive experiments using DomainBed we find that when carefully implemented and tuned, ERM outperforms the state-of-the-art in terms of average performance.\nFurthermore, no algorithm included in DomainBed outperforms ERM by more than one point when evaluated under the same experimental conditions.\nWe hope that the release of DomainBed, alongside contributions from fellow researchers, will streamline reproducible and rigorous advances in domain generalization.",
        "conference": "ICLR",
        "中文标题": "寻找丢失的领域泛化",
        "摘要翻译": "领域泛化算法的目标是在与训练时不同的分布上进行良好的预测。尽管存在无数的领域泛化算法，但实验条件的不一致性——数据集、网络架构和模型选择标准——使得公平比较变得困难。本文的目标是理解领域泛化算法在现实环境中的实用性。作为第一步，我们意识到模型选择对于领域泛化任务来说并非易事，我们认为没有模型选择标准的算法仍然是不完整的。接下来，我们实现了DomainBed，一个用于领域泛化的测试平台，包括七个基准、十四种算法和三种模型选择标准。在使用DomainBed进行广泛实验时，我们发现，当仔细实现和调整时，ERM在平均性能方面优于最先进的技术。此外，在相同的实验条件下评估时，DomainBed中包含的算法中没有一种能比ERM高出超过一分。我们希望DomainBed的发布，以及来自其他研究人员的贡献，将促进领域泛化方面可重复和严格的进展。",
        "领域": "领域泛化、机器学习基准测试、模型选择",
        "问题": "领域泛化算法在现实环境中的实用性和公平比较的困难",
        "动机": "理解领域泛化算法在现实环境中的实用性，并提供一个公平比较的平台",
        "方法": "实现DomainBed测试平台，包括七个基准、十四种算法和三种模型选择标准，并进行广泛实验",
        "关键词": [
            "领域泛化",
            "模型选择",
            "ERM",
            "DomainBed",
            "基准测试"
        ],
        "涉及的技术概念": {
            "领域泛化": "算法在未见过的数据分布上表现良好的能力",
            "模型选择": "在领域泛化任务中选择最佳模型的过程",
            "ERM": "经验风险最小化，一种在DomainBed测试中表现优异的基线方法"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 384,
        "title": "INT: An Inequality Benchmark for Evaluating Generalization in Theorem Proving",
        "html": "https://iclr.cc//virtual/2021/poster/2689",
        "abstract": "In learning-assisted theorem proving, one of the most critical challenges is to generalize to theorems unlike those seen at training time. In this paper, we introduce INT, an INequality Theorem proving benchmark designed to test agents’ generalization ability. INT is based on a theorem generator, which provides theoretically infinite data and allows us to measure 6 different types of generalization, each reflecting a distinct challenge, characteristic of automated theorem proving. In addition, provides a fast theorem proving environment with sequence-based and graph-based interfaces, conducive to performing learning-based research. We introduce base-lines with architectures including transformers and graph neural networks (GNNs)for INT. Using INT, we find that transformer-based agents achieve stronger test performance for most of the generalization tasks, despite having much larger out-of-distribution generalization gaps than GNNs. We further find that the addition of Monte Carlo Tree Search (MCTS) at test time helps to prove new theorems.",
        "conference": "ICLR",
        "中文标题": "INT：一个用于评估定理证明中泛化能力的不等式基准",
        "摘要翻译": "在学习辅助的定理证明中，最关键的挑战之一是泛化到与训练时所见不同的定理。本文介绍了INT，一个旨在测试代理泛化能力的不等式定理证明基准。INT基于一个定理生成器，该生成器理论上提供无限的数据，并允许我们测量6种不同类型的泛化，每种都反映了自动定理证明中的独特挑战。此外，INT提供了一个快速的定理证明环境，支持基于序列和基于图的接口，有利于进行基于学习的研究。我们为INT介绍了包括变换器和图神经网络（GNNs）在内的基线架构。使用INT，我们发现基于变换器的代理在大多数泛化任务中实现了更强的测试性能，尽管其分布外泛化差距比GNNs大得多。我们进一步发现，在测试时加入蒙特卡洛树搜索（MCTS）有助于证明新定理。",
        "领域": "自动定理证明、机器学习辅助证明、泛化能力评估",
        "问题": "评估和提升学习辅助定理证明系统在面对与训练数据不同的定理时的泛化能力",
        "动机": "为了解决学习辅助定理证明系统在遇到未见过的定理时泛化能力不足的问题，设计一个能够全面评估泛化能力的基准",
        "方法": "开发了一个基于定理生成器的基准INT，支持测量多种泛化类型，并引入了变换器和图神经网络作为基线方法，探索了蒙特卡洛树搜索在提升证明能力上的应用",
        "关键词": [
            "定理证明",
            "泛化能力",
            "不等式基准",
            "变换器",
            "图神经网络"
        ],
        "涉及的技术概念": {
            "定理生成器": "用于生成理论上无限的不等式定理，以测试代理的泛化能力",
            "变换器": "作为基线架构之一，用于处理序列数据，展现出在多数泛化任务中的优越性能",
            "蒙特卡洛树搜索（MCTS）": "在测试时加入，以探索可能的证明路径，帮助证明新定理"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 385,
        "title": "Integrating Categorical Semantics into Unsupervised Domain Translation",
        "html": "https://iclr.cc//virtual/2021/poster/2614",
        "abstract": "While unsupervised domain translation (UDT) has seen a lot of success recently, we argue that mediating its translation via categorical semantic features could broaden its applicability. In particular, we demonstrate that categorical semantics improves the translation between perceptually different domains sharing multiple object categories. We propose a method to learn, in an unsupervised manner, categorical semantic features (such as object labels) that are invariant of the source and target domains. We show that conditioning the style encoder of unsupervised domain translation methods on the learned categorical semantics leads to a translation preserving the digits on MNIST$\\leftrightarrow$SVHN and to a more realistic stylization on Sketches$\\to$Reals.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "将类别语义融入到无监督领域转换中",
        "摘要翻译": "虽然无监督领域转换（UDT）最近取得了很大的成功，但我们认为通过类别语义特征来调节其转换可以拓宽其适用性。 特别是，我们证明了类别语义改进了在共享多个对象类别的感知上不同的域之间的转换。 我们提出了一种以无监督方式学习类别语义特征（例如对象标签）的方法，该方法对于源域和目标域是不变的。 我们表明，将无监督域转换方法的风格编码器以学习到的类别语义为条件，可以实现 MNIST$\\leftrightarrow$SVHN 上保留数字的转换，以及 Sketches$\\to$Reals 上更逼真的风格化。",
        "领域": "图像转换",
        "问题": "如何提高无监督领域转换在感知差异较大但共享多个对象类别的域之间的转换质量和适用性。",
        "动机": "现有的无监督领域转换方法在处理感知差异大的领域，尤其是在多个对象类别共存的情况下，性能会受到限制。 通过引入类别语义作为中间表示，可以更好地保留内容信息，从而提升转换效果。",
        "方法": "提出了一种无监督学习类别语义特征的方法，该特征对于源域和目标域是不变的。 然后，将学习到的类别语义作为条件，整合到无监督域转换方法的风格编码器中，从而指导图像转换过程。",
        "关键词": [
            "无监督领域转换",
            "类别语义",
            "风格编码器",
            "领域不变性",
            "图像风格化"
        ],
        "涉及的技术概念": {
            "无监督领域转换": "一种将图像从一个领域转换到另一个领域的技术，无需配对的训练数据。",
            "类别语义": "表示图像中对象类别的高级语义特征，用于在领域转换过程中保留内容信息。"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 386,
        "title": "Interactive Weak Supervision: Learning Useful Heuristics for Data Labeling",
        "html": "https://iclr.cc//virtual/2021/poster/3093",
        "abstract": "Obtaining large annotated datasets is critical for training successful machine learning models and it is often a bottleneck in practice. Weak supervision offers a promising alternative for producing labeled datasets without ground truth annotations by generating probabilistic labels using multiple noisy heuristics. This process can scale to large datasets and has demonstrated state of the art performance in diverse domains such as healthcare and e-commerce. One practical issue with learning from user-generated heuristics is that their creation requires creativity, foresight, and domain expertise from those who hand-craft them, a process which can be tedious and subjective. We develop the first framework for interactive weak supervision in which a method proposes heuristics and learns from user feedback given on each proposed heuristic. Our experiments demonstrate that only a small number of feedback iterations are needed to train models that achieve highly competitive test set performance without access to ground truth training labels. We conduct user studies, which show that users are able to effectively provide feedback on heuristics and that test set results track the performance of simulated oracles.",
        "conference": "ICLR",
        "中文标题": "交互式弱监督：学习数据标注的有用启发式方法",
        "摘要翻译": "获取大量标注数据集对于训练成功的机器学习模型至关重要，而这在实践中往往是一个瓶颈。弱监督提供了一个有前景的替代方案，它通过使用多个有噪声的启发式方法生成概率标签，从而无需真实标注即可产生标注数据集。这一过程可以扩展到大型数据集，并在医疗健康和电子商务等多个领域展示了最先进的性能。从用户生成的启发式方法学习的一个实际问题是，它们的创建需要手工制作这些方法的人具备创造性、前瞻性和领域专业知识，这一过程可能既繁琐又主观。我们开发了第一个交互式弱监督框架，在该框架中，方法提出启发式方法并从用户对每个提出的启发式方法的反馈中学习。我们的实验表明，只需少量反馈迭代即可训练出模型，这些模型在没有真实训练标签的情况下实现了极具竞争力的测试集性能。我们进行了用户研究，研究表明用户能够有效地提供关于启发式方法的反馈，并且测试集结果跟踪了模拟预言机的性能。",
        "领域": "自然语言处理与视觉结合、数据标注自动化、机器学习模型训练",
        "问题": "如何高效地从用户反馈中学习并生成有用的数据标注启发式方法，以减少对大量真实标注数据的依赖。",
        "动机": "解决在缺乏大量真实标注数据的情况下，如何通过交互式学习用户反馈来优化弱监督方法，提高数据标注的效率和质量。",
        "方法": "开发了一个交互式弱监督框架，该框架通过提出启发式方法并学习用户反馈来优化模型，无需真实标注数据即可实现高性能。",
        "关键词": [
            "交互式弱监督",
            "数据标注",
            "启发式学习",
            "用户反馈",
            "无监督学习"
        ],
        "涉及的技术概念": {
            "弱监督": "一种不依赖真实标注数据，而是通过多个有噪声的启发式方法生成概率标签来训练模型的技术。",
            "交互式学习": "通过用户反馈来优化模型的方法，使得模型能够从用户的交互中学习并改进。",
            "启发式方法": "用于生成数据标注的简化规则或策略，这些方法可能不完全准确，但可以有效地减少标注工作的复杂性。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 387,
        "title": "Interpretable Models for Granger Causality Using Self-explaining Neural Networks",
        "html": "https://iclr.cc//virtual/2021/poster/2605",
        "abstract": "Exploratory analysis of time series data can yield a better understanding of complex dynamical systems. Granger causality is a practical framework for analysing interactions in sequential data, applied in a wide range of domains. In this paper, we propose a novel framework for inferring multivariate Granger causality under nonlinear dynamics based on an extension of self-explaining neural networks. This framework is more interpretable than other neural-network-based techniques for inferring Granger causality, since in addition to relational inference, it also allows detecting signs of Granger-causal effects and inspecting their variability over time. In comprehensive experiments on simulated data, we show that our framework performs on par with several powerful baseline methods at inferring Granger causality and that it achieves better performance at inferring interaction signs. The results suggest that our framework is a viable and more interpretable alternative to sparse-input neural networks for inferring Granger causality.",
        "conference": "ICLR",
        "中文标题": "使用自解释神经网络构建可解释的格兰杰因果关系模型",
        "摘要翻译": "时间序列数据的探索性分析可以更好地理解复杂的动态系统。格兰杰因果关系是分析序列数据中相互作用的实用框架，广泛应用于多个领域。在本文中，我们提出了一种基于自解释神经网络扩展的新框架，用于推断非线性动态下的多元格兰杰因果关系。这一框架比其他基于神经网络的格兰杰因果关系推断技术更具可解释性，因为它不仅允许关系推断，还能检测格兰杰因果效应的迹象并检查其随时间的变化。在模拟数据的综合实验中，我们展示了我们的框架在推断格兰杰因果关系方面与几种强大的基线方法表现相当，并且在推断相互作用迹象方面表现更优。结果表明，我们的框架是推断格兰杰因果关系的一个可行且更具可解释性的替代方案，优于稀疏输入神经网络。",
        "领域": "时间序列分析, 因果关系推断, 神经网络解释性",
        "问题": "如何在非线性动态下推断多元格兰杰因果关系，并提高模型的可解释性",
        "动机": "探索更可解释的神经网络方法，以改进格兰杰因果关系的推断，特别是在检测因果效应迹象和其时间变异性方面",
        "方法": "提出了一种基于自解释神经网络扩展的新框架，用于推断非线性动态下的多元格兰杰因果关系，增强了模型的可解释性",
        "关键词": [
            "格兰杰因果关系",
            "自解释神经网络",
            "非线性动态",
            "时间序列分析",
            "模型可解释性"
        ],
        "涉及的技术概念": {
            "自解释神经网络": "用于构建可解释的格兰杰因果关系模型，增强模型推断过程的透明度和可理解性",
            "格兰杰因果关系": "用于分析时间序列数据中的因果关系，本文中通过非线性动态下的多元推断扩展其应用",
            "非线性动态": "本文研究的核心动态系统特性，框架能够在此类复杂动态下有效推断因果关系"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 388,
        "title": "Interpretable Neural Architecture Search via Bayesian Optimisation with Weisfeiler-Lehman Kernels",
        "html": "https://iclr.cc//virtual/2021/poster/3361",
        "abstract": "Current neural architecture search (NAS) strategies focus only on finding a single, good, architecture. They offer little insight into why a specific network is performing well, or how we should modify the architecture if we want further improvements. We propose a Bayesian optimisation (BO) approach for NAS that combines the Weisfeiler-Lehman graph kernel with a Gaussian process surrogate. Our method not only optimises the architecture in a highly data-efficient manner, but also affords interpretability by discovering useful network features and their corresponding impact on the network performance. Moreover, our method is capable of capturing the topological structures of the architectures and is scalable to large graphs, thus making the high-dimensional and graph-like search spaces amenable to BO. We demonstrate empirically that our surrogate model is capable of identifying useful motifs which can guide the generation of new architectures. We finally show that our method outperforms existing NAS approaches to achieve the state of the art on both closed- and open-domain search spaces.",
        "conference": "ICLR",
        "中文标题": "通过贝叶斯优化与Weisfeiler-Lehman核的可解释神经架构搜索",
        "摘要翻译": "当前的神经架构搜索（NAS）策略仅专注于寻找单一、性能良好的架构。它们对于为什么特定网络表现良好，或者如果我们想要进一步改进应该如何修改架构提供了很少的见解。我们提出了一种结合Weisfeiler-Lehman图核与高斯过程代理的贝叶斯优化（BO）方法用于NAS。我们的方法不仅以高度数据效率的方式优化架构，而且还通过发现有用的网络特征及其对网络性能的相应影响来提供可解释性。此外，我们的方法能够捕捉架构的拓扑结构，并且可扩展到大图，从而使高维和图状的搜索空间适合BO。我们通过实验证明，我们的代理模型能够识别有用的模式，这些模式可以指导新架构的生成。最后，我们展示了我们的方法在封闭和开放域搜索空间上都优于现有的NAS方法，达到了最先进的水平。",
        "领域": "神经架构搜索、贝叶斯优化、图核方法",
        "问题": "当前神经架构搜索方法缺乏解释性，难以指导架构的进一步优化。",
        "动机": "提供一种既能高效优化神经架构又能提供架构性能解释的方法。",
        "方法": "结合Weisfeiler-Lehman图核与高斯过程代理的贝叶斯优化方法。",
        "关键词": [
            "神经架构搜索",
            "贝叶斯优化",
            "Weisfeiler-Lehman核",
            "高斯过程",
            "可解释性"
        ],
        "涉及的技术概念": {
            "贝叶斯优化": "用于高效优化神经架构的搜索过程，结合高斯过程作为代理模型来预测架构性能。",
            "Weisfeiler-Lehman图核": "用于捕捉神经架构的拓扑结构，使贝叶斯优化能够处理高维和图状的搜索空间。",
            "高斯过程代理": "用于建模架构与性能之间的关系，提供对架构性能的预测和不确定性估计。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 389,
        "title": "Interpreting and Boosting Dropout from a Game-Theoretic View",
        "html": "https://iclr.cc//virtual/2021/poster/3349",
        "abstract": "This paper aims to understand and improve the utility of the dropout operation from the perspective of game-theoretical interactions. We prove that dropout can suppress the strength of interactions between input variables of deep neural networks (DNNs). The theoretical proof is also verified by various experiments. Furthermore, we find that such interactions were strongly related to the over-fitting problem in deep learning. So, the utility of dropout can be regarded as decreasing interactions to alleviating the significance of over-fitting. Based on this understanding, we propose the interaction loss to further improve the utility of dropout. Experimental results on various DNNs and datasets have shown that the interaction loss can effectively improve the utility of dropout and boost the performance of DNNs.",
        "conference": "ICLR",
        "中文标题": "从博弈论视角解读和提升Dropout的效果",
        "摘要翻译": "本文旨在从博弈论交互的角度理解和提升dropout操作的效用。我们证明了dropout可以抑制深度神经网络(DNNs)输入变量之间交互的强度。这一理论证明也通过各种实验得到了验证。此外，我们发现这种交互与深度学习中的过拟合问题密切相关。因此，dropout的效用可以被视为通过减少交互来缓解过拟合的重要性。基于这一理解，我们提出了交互损失以进一步提升dropout的效用。在各种DNNs和数据集上的实验结果表明，交互损失能有效提升dropout的效用并增强DNNs的性能。",
        "领域": "深度学习优化、神经网络正则化、过拟合抑制",
        "问题": "如何从博弈论的角度理解和提升dropout操作在深度神经网络中的效用",
        "动机": "探索dropout操作通过抑制输入变量间交互强度来缓解过拟合的机制，并基于此机制进一步提升dropout的效果",
        "方法": "通过理论证明和实验验证dropout抑制输入变量间交互强度的作用，提出交互损失以优化dropout的效用",
        "关键词": [
            "Dropout优化",
            "博弈论交互",
            "过拟合抑制",
            "深度神经网络",
            "交互损失"
        ],
        "涉及的技术概念": {
            "Dropout": "一种在深度学习中用于防止过拟合的正则化技术，通过随机忽略网络中的一部分神经元来减少神经元间的复杂共适应",
            "博弈论交互": "用于分析和理解dropout如何通过减少输入变量间的交互强度来防止过拟合的理论框架",
            "交互损失": "基于对dropout作用机制的新理解提出的损失函数，旨在通过进一步减少不必要的交互来提升dropout的效果和模型性能"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 390,
        "title": "Interpreting Graph Neural Networks for NLP With Differentiable Edge Masking",
        "html": "https://iclr.cc//virtual/2021/poster/2852",
        "abstract": "Graph neural networks (GNNs) have become a popular approach to integrating structural inductive biases into NLP models. However, there has been little work on interpreting them, and specifically on understanding which parts of the graphs (e.g. syntactic trees or co-reference structures) contribute to a prediction. In this work, we introduce a post-hoc method for interpreting the predictions of GNNs which identifies unnecessary edges. Given a trained GNN model, we learn a simple classifier that, for every edge in every layer, predicts if that edge can be dropped. We demonstrate that such a classifier can be trained in a fully differentiable fashion, employing stochastic gates and encouraging sparsity through the expected $L_0$ norm. We use our technique as an attribution method to analyze GNN models for two tasks -- question answering and semantic role labeling -- providing insights into the information flow in these models. We show that we can drop a large proportion of edges without deteriorating the performance of the model, while we can analyse the remaining edges for interpreting model predictions.",
        "conference": "ICLR",
        "中文标题": "通过可微分边缘掩码解释NLP中的图神经网络",
        "摘要翻译": "图神经网络（GNNs）已成为将结构归纳偏置集成到NLP模型中的一种流行方法。然而，关于如何解释它们，特别是理解图的哪些部分（例如句法树或共指结构）对预测有贡献的工作还很少。在这项工作中，我们介绍了一种事后解释GNN预测的方法，该方法识别不必要的边。给定一个训练好的GNN模型，我们学习一个简单的分类器，对于每一层的每一条边，预测该边是否可以被丢弃。我们证明了这样的分类器可以以完全可微分的方式训练，采用随机门并通过期望的L0范数鼓励稀疏性。我们将我们的技术作为一种归因方法，用于分析GNN模型在两个任务——问答和语义角色标注——中的信息流。我们表明，我们可以丢弃大量的边而不降低模型的性能，同时我们可以分析剩余的边以解释模型预测。",
        "领域": "自然语言处理与视觉结合、图神经网络、模型解释性",
        "问题": "如何解释图神经网络在NLP任务中的预测，特别是识别图中哪些部分对预测有贡献。",
        "动机": "当前缺乏对图神经网络在NLP任务中预测的解释性研究，特别是理解图中哪些部分对预测有贡献。",
        "方法": "提出一种事后解释方法，通过训练一个简单的分类器来识别和丢弃不必要的边，采用随机门和L0范数鼓励稀疏性。",
        "关键词": [
            "图神经网络",
            "模型解释性",
            "可微分边缘掩码",
            "自然语言处理",
            "信息流分析"
        ],
        "涉及的技术概念": {
            "图神经网络": "用于集成结构归纳偏置到NLP模型中，捕捉图中的结构信息。",
            "可微分边缘掩码": "通过训练分类器识别和丢弃不必要的边，以提高模型的解释性。",
            "L0范数": "用于鼓励边的稀疏性，帮助识别对预测贡献最大的边。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 391,
        "title": "Interpreting Knowledge Graph Relation Representation from Word Embeddings",
        "html": "https://iclr.cc//virtual/2021/poster/2656",
        "abstract": "Many models learn representations of knowledge graph data by exploiting its low-rank latent structure, encoding known relations between entities and enabling unknown facts to be inferred. To predict whether a relation holds between entities, embeddings are typically compared in the latent space following a relation-specific mapping. Whilst their predictive performance has steadily improved, how such models capture the underlying latent structure of semantic information remains unexplained. Building on recent theoretical understanding of word embeddings, we categorise knowledge graph relations into three types and for each derive explicit requirements of their representations. We show that empirical properties of relation representations and the relative performance of leading knowledge graph representation methods are justified by our analysis.",
        "conference": "ICLR",
        "中文标题": "从词嵌入解读知识图谱关系表示",
        "摘要翻译": "许多模型通过利用知识图谱数据的低秩潜在结构来学习其表示，编码实体之间的已知关系并推断未知事实。为了预测实体之间是否存在某种关系，通常在潜在空间中按照关系特定的映射比较嵌入。尽管这些模型的预测性能稳步提升，但它们如何捕捉语义信息的潜在结构仍然没有得到解释。基于最近对词嵌入的理论理解，我们将知识图谱关系分为三种类型，并为每种类型推导出其表示的明确要求。我们展示了关系表示的经验性质以及领先的知识图谱表示方法的相对性能，我们的分析为此提供了依据。",
        "领域": "知识图谱表示学习",
        "问题": "理解知识图谱关系表示如何捕捉语义信息的潜在结构",
        "动机": "解释知识图谱表示学习方法如何以及为何能够有效预测实体间的关系",
        "方法": "基于词嵌入的理论理解，分类知识图谱关系并推导其表示的明确要求",
        "关键词": [
            "知识图谱",
            "关系表示",
            "词嵌入",
            "语义信息",
            "潜在结构"
        ],
        "涉及的技术概念": {
            "低秩潜在结构": "知识图谱数据的一种表示方式，通过低维空间捕捉实体和关系的主要特征",
            "关系特定映射": "在潜在空间中，根据特定关系调整实体嵌入的比较方式",
            "词嵌入": "将词汇映射到连续向量空间的技术，用于捕捉词汇间的语义关系"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 392,
        "title": "Into the Wild with AudioScope: Unsupervised Audio-Visual Separation of On-Screen Sounds",
        "html": "https://iclr.cc//virtual/2021/poster/3161",
        "abstract": "Recent progress in deep learning has enabled many advances in sound separation and visual scene understanding. However, extracting sound sources which are apparent in natural videos remains an open problem. In this work, we present AudioScope, a novel audio-visual sound separation framework that can be trained without supervision to isolate on-screen sound sources from real in-the-wild videos. Prior audio-visual separation work assumed artificial limitations on the domain of sound classes (e.g., to speech or music), constrained the number of sources, and required strong sound separation or visual segmentation labels. AudioScope overcomes these limitations, operating on an open domain of sounds, with variable numbers of sources, and without labels or prior visual segmentation.  The training procedure for AudioScope uses mixture invariant training (MixIT) to separate synthetic mixtures of mixtures (MoMs) into individual sources, where noisy labels for mixtures are provided by an unsupervised audio-visual coincidence model. Using the noisy labels, along with attention between video and audio features, AudioScope learns to identify audio-visual similarity and to suppress off-screen sounds. We demonstrate the effectiveness of our approach using a dataset of video clips extracted from open-domain YFCC100m video data. This dataset contains a wide diversity of sound classes recorded in unconstrained conditions, making the application of previous methods unsuitable. For evaluation and semi-supervised experiments, we collected human labels for presence of on-screen and off-screen sounds on a small subset of clips.",
        "conference": "ICLR",
        "中文标题": "深入野外与AudioScope：无监督的屏幕声音音频-视觉分离",
        "摘要翻译": "深度学习的最新进展在声音分离和视觉场景理解方面取得了许多进步。然而，从自然视频中提取明显的声音源仍然是一个未解决的问题。在这项工作中，我们提出了AudioScope，一种新颖的音频-视觉声音分离框架，可以在无需监督的情况下训练，以从真实的野外视频中隔离屏幕上的声音源。先前的音频-视觉分离工作假设了对声音类别的领域施加了人为限制（例如，仅限于语音或音乐），限制了源的数量，并需要强大的声音分离或视觉分割标签。AudioScope克服了这些限制，操作于开放的声音领域，具有可变数量的源，且无需标签或先前的视觉分割。AudioScope的训练过程使用混合不变训练（MixIT）将混合物的合成混合物（MoMs）分离为单个源，其中混合物的噪声标签由无监督的音频-视觉巧合模型提供。利用这些噪声标签，以及视频和音频特征之间的注意力，AudioScope学会了识别音频-视觉相似性并抑制屏幕外的声音。我们使用从开放领域YFCC100m视频数据中提取的视频剪辑数据集证明了我们方法的有效性。该数据集包含了在无约束条件下记录的广泛多样的声音类别，使得以前的方法不适用。为了评估和半监督实验，我们在剪辑的一小部分子集上收集了人类对屏幕上和屏幕外声音存在的标签。",
        "领域": "音频-视觉学习, 声音分离, 无监督学习",
        "问题": "从自然视频中无监督地分离屏幕上的声音源",
        "动机": "克服现有音频-视觉分离方法在声音类别、源数量和需要标签方面的限制",
        "方法": "使用混合不变训练（MixIT）和无监督的音频-视觉巧合模型进行训练，结合视频和音频特征的注意力机制",
        "关键词": [
            "音频-视觉分离",
            "无监督学习",
            "混合不变训练",
            "注意力机制",
            "野外视频"
        ],
        "涉及的技术概念": {
            "混合不变训练（MixIT）": "用于将混合物的合成混合物分离为单个源的技术",
            "无监督的音频-视觉巧合模型": "提供混合物噪声标签的模型，用于训练过程中的监督",
            "注意力机制": "用于识别音频-视觉相似性并抑制屏幕外声音的技术"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 393,
        "title": "Intraclass clustering: an implicit learning ability that regularizes DNNs",
        "html": "https://iclr.cc//virtual/2021/poster/2802",
        "abstract": "Several works have shown that the regularization mechanisms underlying deep neural networks' generalization performances are still poorly understood. In this paper, we hypothesize that deep neural networks are regularized through their ability to extract meaningful clusters among the samples of a class. This constitutes an implicit form of regularization, as no explicit training mechanisms or supervision target such behaviour. To support our hypothesis, we design four different measures of intraclass clustering, based on the neuron- and layer-level representations of the training data. We then show that these measures constitute accurate predictors of generalization performance across variations of a large set of hyperparameters (learning rate, batch size, optimizer, weight decay, dropout rate, data augmentation, network depth and width).",
        "conference": "ICLR",
        "中文标题": "类内聚类：一种正则化深度神经网络的隐式学习能力",
        "摘要翻译": "多项研究表明，深度神经网络泛化性能背后的正则化机制仍然知之甚少。在本文中，我们假设深度神经网络通过其在一个类别的样本中提取有意义聚类的能力进行正则化。这构成了一种隐式的正则化形式，因为没有明确的训练机制或监督目标针对这种行为。为了支持我们的假设，我们基于训练数据的神经元和层级表示设计了四种不同的类内聚类度量。然后，我们展示了这些度量构成了泛化性能的准确预测器，跨越了大量超参数（学习率、批量大小、优化器、权重衰减、dropout率、数据增强、网络深度和宽度）的变化。",
        "领域": "深度学习正则化、神经网络泛化、隐式学习机制",
        "问题": "深度神经网络泛化性能背后的正则化机制不明确",
        "动机": "探索深度神经网络通过类内聚类实现隐式正则化的能力",
        "方法": "基于神经元和层级表示设计类内聚类度量，验证其作为泛化性能预测器的有效性",
        "关键词": [
            "类内聚类",
            "隐式正则化",
            "泛化性能",
            "深度神经网络",
            "超参数影响"
        ],
        "涉及的技术概念": {
            "类内聚类": "度量深度神经网络在类别样本中形成有意义聚类的能力，作为隐式正则化的一种形式",
            "隐式正则化": "指深度神经网络在没有明确正则化机制的情况下，通过其内在学习能力实现的泛化性能提升",
            "泛化性能预测器": "通过类内聚类度量预测深度神经网络在不同超参数设置下的泛化能力"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 394,
        "title": "Intrinsic-Extrinsic Convolution and Pooling for Learning on 3D Protein Structures",
        "html": "https://iclr.cc//virtual/2021/poster/2878",
        "abstract": "Proteins perform a large variety of functions in living organisms and thus play a key role in biology. However, commonly used algorithms in protein representation learning were not specifically designed for protein data, and are therefore not able to capture all relevant structural levels of a protein during learning. To fill this gap, we propose two new learning operators, specifically designed to process protein structures. First, we introduce a novel convolution operator that considers the primary, secondary, and tertiary structure of a protein by using $n$-D convolutions defined on both the Euclidean distance, as well as multiple geodesic distances between the atoms in a multi-graph. Second, we introduce a set of hierarchical pooling operators that enable multi-scale protein analysis. We further evaluate the accuracy of our algorithms on common downstream tasks, where we outperform state-of-the-art protein learning algorithms.",
        "conference": "ICLR",
        "中文标题": "内在-外在卷积与池化用于3D蛋白质结构学习",
        "摘要翻译": "蛋白质在生物体中执行多种功能，因此在生物学中扮演着关键角色。然而，蛋白质表示学习中常用的算法并非专门为蛋白质数据设计，因此在学习过程中无法捕捉蛋白质的所有相关结构层次。为了填补这一空白，我们提出了两种新的学习算子，专门设计用于处理蛋白质结构。首先，我们引入了一种新颖的卷积算子，该算子通过使用在欧几里得距离以及多图中原子之间的多个测地距离上定义的n维卷积，考虑了蛋白质的一级、二级和三级结构。其次，我们引入了一组层次化池化算子，支持多尺度蛋白质分析。我们进一步评估了我们的算法在常见下游任务上的准确性，在这些任务中，我们的算法优于最先进的蛋白质学习算法。",
        "领域": "蛋白质结构学习、生物信息学、深度学习",
        "问题": "如何设计专门针对蛋白质结构的学习算法，以捕捉其多层次的复杂结构信息。",
        "动机": "现有的蛋白质表示学习算法未能充分考虑蛋白质的多层次结构信息，限制了学习效果和应用范围。",
        "方法": "提出了一种新的卷积算子，结合欧几里得和测地距离进行多维度卷积，以及一组层次化池化算子，用于多尺度分析。",
        "关键词": [
            "蛋白质结构学习",
            "3D卷积",
            "层次化池化",
            "生物信息学",
            "深度学习"
        ],
        "涉及的技术概念": {
            "n维卷积": "用于处理蛋白质结构的多层次信息，包括一级、二级和三级结构。",
            "测地距离": "在多图中定义原子之间的距离，用于更准确地描述蛋白质的三维结构。",
            "层次化池化": "支持蛋白质的多尺度分析，有助于捕捉不同层次的结构特征。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 395,
        "title": "IOT: Instance-wise Layer Reordering for Transformer Structures",
        "html": "https://iclr.cc//virtual/2021/poster/2891",
        "abstract": "With sequentially stacked self-attention, (optional) encoder-decoder attention, and feed-forward layers, Transformer achieves big success in natural language processing (NLP), and many variants have been proposed. Currently, almost all these models assume that the \\emph{layer order} is fixed and kept the same across data samples. We observe that different data samples actually favor different orders of the layers. Based on this observation, in this work, we break the assumption of the fixed layer order in Transformer and introduce instance-wise layer reordering into model structure. Our Instance-wise Ordered Transformer (IOT) can model variant functions by reordered layers, which enables each sample to select the better one to improve the model performance under the constraint of almost same number of parameters. To achieve this, we introduce a light predictor with negligible parameter and inference cost to decide the most capable and favorable layer order for any input sequence. Experiments on $3$ tasks (neural machine translation, abstractive summarization, and code generation) and $9$ datasets demonstrate consistent improvements of our method. We further show that our method can also be applied to other architectures beyond Transformer. Our code is released at Github\\footnote{\\url{https://github.com/instance-wise-ordered-transformer/IOT}}.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "IOT：针对Transformer结构的实例级层重排序",
        "摘要翻译": "通过顺序堆叠的自注意力、（可选的）编码器-解码器注意力和前馈层，Transformer在自然语言处理（NLP）领域取得了巨大成功，并且已经提出了许多变体。目前，几乎所有模型都假设层顺序是固定的，并且在所有数据样本中保持一致。我们观察到，不同的数据样本实际上偏好不同的层顺序。基于这一观察，在这项工作中，我们打破了Transformer中固定层顺序的假设，并将实例级层重排序引入模型结构。我们的实例级有序Transformer（IOT）可以通过重排序的层来建模变体函数，这使得每个样本能够在几乎相同参数数量的约束下选择更好的层顺序以提高模型性能。为了实现这一点，我们引入了一个参数和推理成本可忽略不计的轻量级预测器，以决定任何输入序列最有能力和最有利的层顺序。在3个任务（神经机器翻译、抽象摘要和代码生成）和9个数据集上的实验证明了我们方法的持续改进。我们进一步表明，我们的方法也可以应用于Transformer之外的其他架构。我们的代码已在Github上发布。",
        "领域": "自然语言处理与视觉结合",
        "问题": "解决Transformer模型中固定层顺序对所有数据样本不适用的问题",
        "动机": "观察到不同数据样本偏好不同的层顺序，旨在通过实例级层重排序提高模型性能",
        "方法": "引入实例级层重排序机制和轻量级预测器，动态决定最优层顺序",
        "关键词": [
            "实例级层重排序",
            "Transformer",
            "自然语言处理",
            "动态结构",
            "轻量级预测器"
        ],
        "涉及的技术概念": {
            "实例级层重排序": "允许模型根据输入数据动态调整层顺序，以提高处理不同样本的效率",
            "轻量级预测器": "用于决定输入序列的最优层顺序，具有可忽略的参数和推理成本",
            "动态结构": "通过重排序层实现模型结构的动态调整，以适应不同数据样本的需求"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 396,
        "title": "IsarStep: a Benchmark for High-level Mathematical Reasoning",
        "html": "https://iclr.cc//virtual/2021/poster/3049",
        "abstract": "A well-defined benchmark is essential for measuring and accelerating research progress of machine learning models. In this paper, we present a benchmark for high-level mathematical reasoning and study the reasoning capabilities of neural sequence-to-sequence models. We build a non-synthetic dataset from the largest repository of proofs written by human experts in a theorem prover. The dataset has a broad coverage of undergraduate and research-level mathematical and computer science theorems. In our defined task, a model is required to fill in a missing intermediate proposition given surrounding proofs. This task provides a starting point for the long-term goal of having machines generate human-readable proofs automatically. Our experiments and analysis reveal that while the task is challenging, neural models can capture non-trivial mathematical reasoning. We further design a hierarchical transformer that outperforms the transformer baseline. ",
        "conference": "ICLR",
        "中文标题": "IsarStep: 高级数学推理的基准",
        "摘要翻译": "一个定义明确的基准对于衡量和加速机器学习模型的研究进展至关重要。在本文中，我们提出了一个用于高级数学推理的基准，并研究了神经序列到序列模型的推理能力。我们从由定理证明器中人类专家编写的最大证明库中构建了一个非合成数据集。该数据集广泛覆盖了本科和研究级的数学和计算机科学定理。在我们定义的任务中，模型需要根据周围的证明填补缺失的中间命题。这项任务为实现机器自动生成人类可读证明的长期目标提供了一个起点。我们的实验和分析表明，尽管任务具有挑战性，但神经模型能够捕捉到非平凡的数学推理。我们进一步设计了一个分层变换器，其性能优于变换器基线。",
        "领域": "自然语言处理与视觉结合、自动定理证明、数学知识表示",
        "问题": "如何构建一个有效的基准来评估和提升机器学习模型在高级数学推理上的能力。",
        "动机": "为了推动机器学习模型在理解和生成高级数学证明方面的能力，需要一个高质量的基准数据集来评估和指导研究。",
        "方法": "从人类专家编写的定理证明库中构建非合成数据集，定义填补缺失中间命题的任务，并设计分层变换器模型以提高性能。",
        "关键词": [
            "数学推理",
            "基准测试",
            "序列到序列模型",
            "定理证明",
            "分层变换器"
        ],
        "涉及的技术概念": {
            "神经序列到序列模型": "用于理解和生成数学证明的模型，能够处理从输入序列到输出序列的映射。",
            "分层变换器": "一种改进的变换器架构，通过层次化处理信息来提高模型在复杂数学推理任务上的表现。",
            "非合成数据集": "从真实世界的数学证明库中构建的数据集，确保了数据的多样性和真实性，有助于模型的泛化能力。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 397,
        "title": "Is Attention Better Than Matrix Decomposition?",
        "html": "https://iclr.cc//virtual/2021/poster/3364",
        "abstract": "As an essential ingredient of modern deep learning, attention mechanism, especially self-attention, plays a vital role in the global correlation discovery. However, is hand-crafted attention irreplaceable when modeling the global context? Our intriguing finding is that self-attention is not better than the matrix decomposition~(MD) model developed 20 years ago regarding the performance and computational cost for encoding the long-distance dependencies. We model the global context issue as a low-rank completion problem and show that its optimization algorithms can help design global information blocks. This paper then proposes a series of Hamburgers, in which we employ the optimization algorithms for solving MDs to factorize the input representations into sub-matrices and reconstruct a low-rank embedding. Hamburgers with different MDs can perform favorably against the popular global context module self-attention when carefully coping with gradients back-propagated through MDs. Comprehensive experiments are conducted in the vision tasks where it is crucial to learn the global context, including semantic segmentation and image generation, demonstrating significant improvements over self-attention and its variants. Code is available at https://github.com/Gsunshine/Enjoy-Hamburger.",
        "conference": "ICLR",
        "中文标题": "注意力机制是否优于矩阵分解？",
        "摘要翻译": "作为现代深度学习的重要组成部分，注意力机制，尤其是自注意力，在全球相关性发现中扮演着关键角色。然而，在建模全局上下文时，手工设计的注意力是否不可替代？我们有趣的发现是，在编码长距离依赖性的性能和计算成本方面，自注意力并不比20年前开发的矩阵分解（MD）模型更优。我们将全局上下文问题建模为一个低秩完成问题，并展示其优化算法可以帮助设计全局信息块。本文随后提出了一系列Hamburgers，其中我们利用解决MDs的优化算法将输入表示分解为子矩阵并重建一个低秩嵌入。当仔细处理通过MDs反向传播的梯度时，具有不同MDs的Hamburgers可以优于流行的全局上下文模块自注意力。在需要学习全局上下文的视觉任务中进行了全面实验，包括语义分割和图像生成，证明了相对于自注意力及其变体的显著改进。代码可在https://github.com/Gsunshine/Enjoy-Hamburger获取。",
        "领域": "语义分割, 图像生成, 全局上下文建模",
        "问题": "探索在全局上下文建模中，自注意力机制是否比矩阵分解更有效。",
        "动机": "研究自注意力机制在全局上下文建模中的效率问题，发现矩阵分解可能提供更优的解决方案。",
        "方法": "提出Hamburgers方法，利用矩阵分解的优化算法分解输入表示并重建低秩嵌入，以替代或补充自注意力机制。",
        "关键词": [
            "自注意力",
            "矩阵分解",
            "全局上下文建模",
            "低秩完成",
            "Hamburgers"
        ],
        "涉及的技术概念": {
            "自注意力": "用于发现输入数据中的全局相关性，但在某些情况下可能不如矩阵分解高效。",
            "矩阵分解": "用于将输入表示分解为子矩阵，以更高效地建模全局上下文。",
            "低秩完成": "将全局上下文问题建模为低秩完成问题，利用优化算法设计全局信息块。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 398,
        "title": "Is Label Smoothing Truly Incompatible with Knowledge Distillation: An Empirical Study",
        "html": "https://iclr.cc//virtual/2021/poster/2869",
        "abstract": "This work aims to empirically clarify a recently discovered perspective that label smoothing is incompatible with knowledge distillation. We begin by introducing the motivation behind on how this incompatibility is raised, i.e., label smoothing erases relative information between teacher logits. We provide a novel connection on how label smoothing affects distributions of semantically similar and dissimilar classes. Then we propose a metric to quantitatively measure the degree of erased information in sample's representation. After that, we study its one-sidedness and imperfection of the incompatibility view through massive analyses, visualizations and comprehensive experiments on Image Classification, Binary Networks, and Neural Machine Translation. Finally, we broadly discuss several circumstances wherein label smoothing will indeed lose its effectiveness.",
        "conference": "ICLR",
        "中文标题": "标签平滑真的与知识蒸馏不兼容吗：一项实证研究",
        "摘要翻译": "本研究旨在通过实证方法澄清最近发现的一个观点，即标签平滑与知识蒸馏不兼容。我们首先介绍了这种不兼容性是如何被提出的动机，即标签平滑抹去了教师逻辑之间的相对信息。我们提供了一个新颖的连接，展示了标签平滑如何影响语义相似和不相似类别的分布。然后，我们提出了一个度量标准，用于定量测量样本表示中被抹去信息的程度。之后，我们通过大量的分析、可视化以及在图像分类、二元网络和神经机器翻译上的全面实验，研究了这种不兼容观点的一面性和不完美性。最后，我们广泛讨论了标签平滑确实会失去其有效性的几种情况。",
        "领域": "深度学习",
        "问题": "标签平滑与知识蒸馏的兼容性问题",
        "动机": "澄清标签平滑与知识蒸馏不兼容的观点，探索标签平滑对知识蒸馏效果的影响",
        "方法": "通过理论分析、提出新的度量标准、大量实验和可视化来研究标签平滑与知识蒸馏的关系",
        "关键词": [
            "标签平滑",
            "知识蒸馏",
            "深度学习",
            "图像分类",
            "神经机器翻译"
        ],
        "涉及的技术概念": {
            "标签平滑": "一种正则化技术，用于防止模型对训练数据过度自信，通过在标签上添加噪声来实现",
            "知识蒸馏": "一种模型压缩技术，通过让小型模型（学生模型）学习大型模型（教师模型）的输出分布来提高小型模型的性能",
            "教师逻辑": "知识蒸馏中教师模型输出的未归一化的预测分数，用于指导学生模型的学习"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 399,
        "title": "Isometric Propagation Network for Generalized Zero-shot Learning",
        "html": "https://iclr.cc//virtual/2021/poster/2709",
        "abstract": "Zero-shot learning (ZSL) aims to classify images of an unseen class only based on a few attributes describing that class but no access to any training sample. A popular strategy is to learn a mapping between the semantic space of class attributes and the visual space of images based on the seen classes and their data. Thus, an unseen class image can be ideally mapped to its corresponding class attributes. The key challenge is how to align the representations in the two spaces. For most ZSL settings, the attributes for each seen/unseen class are only represented by a vector while the seen-class data provide much more information. Thus, the imbalanced supervision from the semantic and the visual space can make the learned mapping easily overfitting to the seen classes. To resolve this problem, we propose Isometric Propagation Network (IPN), which learns to strengthen the relation between classes within each space and align the class dependency in the two spaces. Specifically, IPN learns to propagate the class representations on an auto-generated graph within each space. In contrast to only aligning the resulted static representation, we regularize the two dynamic propagation procedures to be isometric in terms of the two graphs' edge weights per step by minimizing a consistency loss between them. IPN achieves state-of-the-art performance on three popular ZSL benchmarks. To evaluate the generalization capability of IPN, we further build two larger benchmarks with more diverse unseen classes and demonstrate the advantages of IPN on them.",
        "conference": "ICLR",
        "中文标题": "等距传播网络用于广义零样本学习",
        "摘要翻译": "零样本学习（ZSL）旨在仅基于描述未见类别的少量属性，而不需要任何训练样本，对未见类别的图像进行分类。一种流行的策略是基于已见类别及其数据，学习类别属性的语义空间与图像的视觉空间之间的映射。因此，未见类别的图像可以理想地映射到其对应的类别属性。关键挑战是如何对齐这两个空间中的表示。对于大多数ZSL设置，每个已见/未见类别的属性仅由一个向量表示，而已见类别数据提供了更多信息。因此，来自语义和视觉空间的不平衡监督可能使学习到的映射容易过拟合到已见类别。为了解决这个问题，我们提出了等距传播网络（IPN），它学习加强每个空间内类别之间的关系，并在这两个空间中对齐类别依赖性。具体来说，IPN学习在每个空间内自动生成的图上传播类别表示。与仅对齐结果的静态表示不同，我们通过最小化它们之间的一致性损失，规范两个动态传播过程在每一步的两个图的边权重方面是等距的。IPN在三个流行的ZSL基准测试中实现了最先进的性能。为了评估IPN的泛化能力，我们进一步构建了两个具有更多样化未见类别的更大基准测试，并展示了IPN在它们上的优势。",
        "领域": "广义零样本学习",
        "问题": "解决零样本学习中语义空间和视觉空间表示对齐的挑战，避免过拟合到已见类别。",
        "动机": "由于语义空间和视觉空间监督的不平衡，现有方法容易过拟合到已见类别，限制了模型对未见类别的泛化能力。",
        "方法": "提出等距传播网络（IPN），通过在自动生成的图上传播类别表示，并规范两个空间的传播过程在边权重上保持等距，以加强类别间关系并对齐空间依赖性。",
        "关键词": [
            "零样本学习",
            "等距传播",
            "类别依赖性对齐",
            "语义空间",
            "视觉空间"
        ],
        "涉及的技术概念": {
            "等距传播": "IPN中用于在两个空间内传播类别表示并保持传播过程在边权重上等距的技术，以加强类别间关系并对齐空间依赖性。",
            "一致性损失": "用于最小化两个动态传播过程之间差异的损失函数，确保两个空间的传播过程在每一步的边权重上保持等距。",
            "自动生成的图": "IPN中用于表示类别间关系的图结构，通过在图上传播类别表示来加强类别间的关系和对齐空间依赖性。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 400,
        "title": "Isometric Transformation Invariant and Equivariant Graph Convolutional Networks",
        "html": "https://iclr.cc//virtual/2021/poster/3192",
        "abstract": "Graphs are one of the most important data structures for representing pairwise relations between objects. Specifically, a graph embedded in a Euclidean space is essential to solving real problems, such as physical simulations. A crucial requirement for applying graphs in Euclidean spaces to physical simulations is learning and inferring the isometric transformation invariant and equivariant features in a computationally efficient manner. In this paper, we propose a set of transformation invariant and equivariant models based on graph convolutional networks, called IsoGCNs. We demonstrate that the proposed model has a competitive performance compared to state-of-the-art methods on tasks related to geometrical and physical simulation data. Moreover, the proposed model can scale up to graphs with 1M vertices and conduct an inference faster than a conventional finite element analysis, which the existing equivariant models cannot achieve.",
        "conference": "ICLR",
        "中文标题": "等距变换不变与等变的图卷积网络",
        "摘要翻译": "图是表示对象间成对关系的最重要数据结构之一。具体而言，嵌入欧几里得空间中的图对于解决实际问题（如物理模拟）至关重要。将欧几里得空间中的图应用于物理模拟的一个关键要求是以计算高效的方式学习和推断等距变换不变和等变的特征。在本文中，我们提出了一组基于图卷积网络的变换不变和等变模型，称为IsoGCNs。我们证明，在与几何和物理模拟数据相关的任务上，所提出的模型与最先进的方法相比具有竞争性能。此外，所提出的模型可以扩展到具有100万个顶点的图，并且比传统的有限元分析进行推理更快，这是现有等变模型无法实现的。",
        "领域": "图神经网络、物理模拟、几何深度学习",
        "问题": "如何在计算高效的前提下，学习和推断欧几里得空间中图的等距变换不变和等变特征。",
        "动机": "解决物理模拟中图数据结构在欧几里得空间应用的关键需求，即高效学习和推断等距变换不变和等变的特征。",
        "方法": "提出了一组基于图卷积网络的变换不变和等变模型（IsoGCNs），并在几何和物理模拟数据相关任务上验证其性能。",
        "关键词": [
            "图卷积网络",
            "等距变换",
            "物理模拟",
            "几何深度学习",
            "大规模图处理"
        ],
        "涉及的技术概念": {
            "图卷积网络": "用于处理图结构数据的深度学习模型，本文中用于学习和推断图的等距变换不变和等变特征。",
            "等距变换": "保持距离不变的变换，本文中研究的是对这种变换的不变性和等变性。",
            "物理模拟": "通过计算模型模拟物理系统的行为，本文中图结构数据用于此类模拟。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 401,
        "title": "Isotropy in the Contextual Embedding Space: Clusters and Manifolds",
        "html": "https://iclr.cc//virtual/2021/poster/3079",
        "abstract": "The geometric properties of contextual embedding spaces for deep language models such as BERT and ERNIE, have attracted considerable attention in recent years. Investigations on the contextual embeddings demonstrate a strong anisotropic space such that most of the vectors fall within a narrow cone, leading to high cosine similarities.  It is surprising that these LMs are as successful as they are, given that most of their embedding vectors are as similar to one another as they are. In this paper, we argue that the isotropy indeed exists in the space, from a different but more constructive perspective. We identify isolated clusters and low dimensional manifolds in the contextual embedding space, and introduce tools to both qualitatively and quantitatively analyze them. We hope the study in this paper could provide insights towards a better understanding of the deep language models.",
        "conference": "ICLR",
        "中文标题": "上下文嵌入空间中的各向同性：簇与流形",
        "摘要翻译": "近年来，诸如BERT和ERNIE等深度语言模型的上下文嵌入空间的几何特性引起了广泛关注。对上下文嵌入的研究表明，这些空间具有强烈的各向异性，使得大多数向量都落在一个狭窄的锥体内，导致高余弦相似性。令人惊讶的是，尽管这些语言模型的嵌入向量彼此之间非常相似，它们却取得了巨大的成功。在本文中，我们从一个不同但更具建设性的角度出发，认为空间中确实存在各向同性。我们在上下文嵌入空间中识别出了孤立的簇和低维流形，并引入了工具来定性和定量地分析它们。我们希望本文的研究能够为更好地理解深度语言模型提供见解。",
        "领域": "自然语言处理与视觉结合, 语言模型理解, 嵌入空间分析",
        "问题": "探讨深度语言模型的上下文嵌入空间中的各向同性问题",
        "动机": "尽管深度语言模型的嵌入向量在空间中表现出高相似性，这些模型却非常成功，研究旨在从簇和流形的角度解释这一现象",
        "方法": "识别上下文嵌入空间中的孤立簇和低维流形，并开发工具进行定性和定量分析",
        "关键词": [
            "各向同性",
            "上下文嵌入",
            "深度语言模型",
            "簇分析",
            "流形学习"
        ],
        "涉及的技术概念": {
            "各向同性": "在本文中指上下文嵌入空间中向量分布的均匀性，研究其存在性有助于理解语言模型的工作原理",
            "簇分析": "用于识别嵌入空间中的孤立簇，揭示向量分布的局部结构",
            "流形学习": "用于发现嵌入空间中的低维流形结构，帮助理解高维数据的本质维度"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 402,
        "title": "Iterated learning for emergent systematicity in VQA",
        "html": "https://iclr.cc//virtual/2021/poster/3302",
        "abstract": "Although neural module networks have an architectural bias towards compositionality, they require gold standard layouts to generalize systematically in practice. When instead learning layouts and modules jointly, compositionality does not arise automatically and an explicit pressure is necessary for the emergence of layouts exhibiting the right structure. We propose to address this problem using iterated learning, a cognitive science theory of the emergence of compositional languages in nature that has primarily been applied to simple referential games in machine learning. Considering the layouts of module networks as samples from an emergent language, we use iterated learning to encourage the development of structure within this language. We show that the resulting layouts support systematic generalization in neural agents solving the more complex task of visual question-answering. Our regularized iterated learning method can outperform baselines without iterated learning on SHAPES-SyGeT (SHAPES Systematic Generalization Test), a new split of the SHAPES dataset we introduce to evaluate systematic generalization, and on CLOSURE, an extension of CLEVR also designed to test systematic generalization. We demonstrate superior performance in recovering ground-truth compositional program structure with limited supervision on both SHAPES-SyGeT and CLEVR.",
        "conference": "ICLR",
        "中文标题": "迭代学习促进视觉问答中系统性涌现",
        "摘要翻译": "尽管神经模块网络在架构上偏向于组合性，但在实践中它们需要黄金标准布局才能系统地泛化。当同时学习布局和模块时，组合性不会自动出现，必须施加明确的压力才能使布局展现出正确的结构。我们提出使用迭代学习来解决这个问题，这是一种认知科学理论，关于自然界中组合性语言的出现，主要在机器学习中被应用于简单的指称游戏。将模块网络的布局视为从涌现语言中抽取的样本，我们使用迭代学习来鼓励这种语言内部结构的发展。我们表明，由此产生的布局支持神经代理在解决更复杂的视觉问答任务时进行系统性泛化。我们的正则化迭代学习方法在SHAPES-SyGeT（我们引入的SHAPES数据集的新分割，用于评估系统性泛化）和CLOSURE（CLEVR的扩展，同样设计用于测试系统性泛化）上可以优于没有迭代学习的基线。我们在SHAPES-SyGeT和CLEVR上展示了在有限监督下恢复地面真实组合程序结构的优越性能。",
        "领域": "视觉问答、系统性泛化、组合性学习",
        "问题": "神经模块网络在实践中需要黄金标准布局才能系统地泛化，而同时学习布局和模块时组合性不会自动出现。",
        "动机": "通过迭代学习促进神经模块网络布局的系统性结构发展，以支持视觉问答任务中的系统性泛化。",
        "方法": "采用迭代学习方法，将模块网络的布局视为涌现语言的样本，鼓励语言内部结构的发展，以促进系统性泛化。",
        "关键词": [
            "迭代学习",
            "系统性泛化",
            "视觉问答",
            "神经模块网络",
            "组合性学习"
        ],
        "涉及的技术概念": {
            "迭代学习": "一种认知科学理论，应用于机器学习中，通过模拟语言演化的过程来促进组合性结构的涌现。",
            "系统性泛化": "指模型在面对新组合或未见过的输入时，能够基于已有知识进行合理推断的能力。",
            "神经模块网络": "一种具有模块化结构的神经网络，每个模块负责处理特定类型的输入或执行特定功能，通过组合这些模块来完成复杂任务。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 403,
        "title": "Iterative Empirical Game Solving via Single Policy Best Response",
        "html": "https://iclr.cc//virtual/2021/poster/2662",
        "abstract": "Policy-Space Response Oracles (PSRO) is a general algorithmic framework for learning policies in multiagent systems by interleaving empirical game analysis with deep reinforcement learning (DRL).\nAt each iteration, DRL is invoked to train a best response to a mixture of opponent policies.\nThe repeated application of DRL poses an expensive computational burden as we look to apply this algorithm to more complex domains.\nWe introduce two variations of PSRO designed to reduce the amount of simulation required during DRL training.\nBoth algorithms modify how PSRO adds new policies to the empirical game, based on learned responses to a single opponent policy.\nThe first, Mixed-Oracles, transfers knowledge from previous iterations of DRL, requiring training only against the opponent's newest policy.\nThe second, Mixed-Opponents, constructs a pure-strategy opponent by mixing existing strategy's action-value estimates, instead of their policies.\nLearning against a single policy mitigates conflicting experiences on behalf of a learner facing an unobserved distribution of opponents.\nWe empirically demonstrate that these algorithms substantially reduce the amount of simulation during training required by PSRO, while producing equivalent or better solutions to the game.",
        "conference": "ICLR",
        "中文标题": "通过单策略最佳响应进行迭代式经验博弈求解",
        "摘要翻译": "策略空间响应预言（PSRO）是一个通用的算法框架，用于通过将经验博弈分析与深度强化学习（DRL）交替进行来学习多智能体系统中的策略。在每次迭代中，DRL被调用来训练对对手策略混合的最佳响应。随着我们尝试将这一算法应用于更复杂的领域，DRL的重复应用带来了昂贵的计算负担。我们介绍了两种旨在减少DRL训练期间所需模拟量的PSRO变体。这两种算法都基于对单一对手策略的学习响应，修改了PSRO如何向经验博弈添加新策略的方式。第一种算法，混合预言，从DRL的先前迭代中转移知识，仅需要针对对手的最新策略进行训练。第二种算法，混合对手，通过混合现有策略的动作价值估计而不是它们的策略，构建了一个纯策略对手。针对单一策略的学习减轻了学习者面对未观察到的对手分布时的冲突经验。我们通过实验证明，这些算法在产生与PSRO相当或更好的游戏解决方案的同时，显著减少了训练期间所需的模拟量。",
        "领域": "多智能体系统、深度强化学习、博弈论",
        "问题": "减少在多智能体系统中使用深度强化学习进行策略学习时的计算负担",
        "动机": "为了将策略空间响应预言（PSRO）算法应用于更复杂的领域，需要减少其昂贵的计算负担",
        "方法": "介绍了两种PSRO的变体算法：混合预言和混合对手，通过修改策略添加方式和对手构建方法，减少训练期间的模拟量",
        "关键词": [
            "策略空间响应预言",
            "深度强化学习",
            "多智能体系统",
            "博弈论",
            "计算效率"
        ],
        "涉及的技术概念": {
            "策略空间响应预言（PSRO）": "一个通用的算法框架，用于通过交替进行经验博弈分析和深度强化学习来学习多智能体系统中的策略",
            "深度强化学习（DRL）": "用于训练对对手策略混合的最佳响应的技术",
            "混合预言和混合对手": "两种PSRO的变体算法，旨在减少DRL训练期间所需的模拟量"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 404,
        "title": "Kanerva++: Extending the Kanerva Machine With Differentiable, Locally Block Allocated Latent Memory",
        "html": "https://iclr.cc//virtual/2021/poster/2961",
        "abstract": "Episodic and semantic memory are critical components of the human memory model. The theory of complementary learning systems (McClelland et al., 1995) suggests that the compressed representation produced by a serial event (episodic memory) is later restructured to build a more generalized form of reusable knowledge (semantic memory). In this work, we develop a new principled Bayesian memory allocation scheme that bridges the gap between episodic and semantic memory via a hierarchical latent variable model. We take inspiration from traditional heap allocation and extend the idea of locally contiguous memory to the Kanerva Machine, enabling a novel differentiable block allocated latent memory. In contrast to the Kanerva Machine, we simplify the process of memory writing by treating it as a fully feed forward deterministic process, relying on the stochasticity of the read key distribution to disperse information within the memory. We demonstrate that this allocation scheme improves performance in memory conditional image generation, resulting in new state-of-the-art conditional likelihood values on binarized MNIST (≤41.58 nats/image) , binarized Omniglot (≤66.24 nats/image), as well as presenting competitive performance on CIFAR10, DMLab Mazes, Celeb-A and ImageNet32×32.",
        "conference": "ICLR",
        "中文标题": "Kanerva++：通过可微分局部块分配潜在内存扩展Kanerva机器",
        "摘要翻译": "情景记忆和语义记忆是人类记忆模型的关键组成部分。互补学习系统理论（McClelland等人，1995）提出，由连续事件（情景记忆）产生的压缩表示随后被重构以构建更通用的可重用知识形式（语义记忆）。在这项工作中，我们开发了一种新的基于原则的贝叶斯内存分配方案，通过分层潜在变量模型桥接情景记忆和语义记忆之间的差距。我们从传统的堆分配中汲取灵感，并将局部连续内存的概念扩展到Kanerva机器，实现了一种新颖的可微分块分配潜在内存。与Kanerva机器相比，我们通过将内存写入过程视为完全前馈确定性过程来简化它，依赖于读取键分布的随机性来分散内存中的信息。我们证明，这种分配方案在内存条件图像生成中提高了性能，在二值化MNIST（≤41.58 nats/image）、二值化Omniglot（≤66.24 nats/image）上实现了新的最先进条件似然值，同时在CIFAR10、DMLab Mazes、Celeb-A和ImageNet32×32上展示了竞争性能。",
        "领域": "深度学习与记忆模型、图像生成、贝叶斯方法",
        "问题": "如何通过改进内存分配方案来桥接情景记忆和语义记忆，以提高内存条件图像生成的性能。",
        "动机": "受到互补学习系统理论和传统堆分配方法的启发，旨在开发一种新的内存分配方案，以更有效地桥接情景记忆和语义记忆，提升模型在多种数据集上的表现。",
        "方法": "开发了一种基于贝叶斯原则的内存分配方案，扩展了Kanerva机器的概念，引入了可微分局部块分配潜在内存，简化了内存写入过程，依赖于读取键分布的随机性来分散信息。",
        "关键词": [
            "Kanerva机器",
            "贝叶斯内存分配",
            "可微分内存",
            "图像生成",
            "分层潜在变量模型"
        ],
        "涉及的技术概念": {
            "分层潜在变量模型": "用于桥接情景记忆和语义记忆，通过层次化结构捕捉数据的深层特征。",
            "可微分块分配潜在内存": "扩展了Kanerva机器的内存分配机制，允许通过梯度下降优化内存分配，提高内存使用效率。",
            "互补学习系统理论": "提供了理论基础，指导如何通过情景记忆和语义记忆的交互来构建更通用的知识表示。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 405,
        "title": "Knowledge Distillation as Semiparametric Inference",
        "html": "https://iclr.cc//virtual/2021/poster/3318",
        "abstract": "A popular approach to model compression is to train an inexpensive student model to mimic the class probabilities of a highly accurate but cumbersome teacher model. Surprisingly, this two-step knowledge distillation process often leads to higher accuracy than training the student directly on labeled data. To explain and enhance this phenomenon, we cast knowledge distillation as a semiparametric inference problem with the optimal student model as the target, the unknown Bayes class probabilities as nuisance, and the teacher probabilities as a plug-in nuisance estimate.  By adapting modern semiparametric tools, we derive new guarantees for the prediction error of standard distillation and develop two enhancements—cross-fitting and loss correction—to mitigate the impact of teacher overfitting and underfitting on student performance. We validate our findings empirically on both tabular and image data and observe consistent improvements from our knowledge distillation enhancements.",
        "conference": "ICLR",
        "中文标题": "知识蒸馏作为半参数推断",
        "摘要翻译": "模型压缩的一种流行方法是训练一个成本低廉的学生模型来模仿高度准确但笨重的教师模型的类别概率。令人惊讶的是，这种两步知识蒸馏过程往往比直接在标记数据上训练学生模型获得更高的准确率。为了解释和增强这一现象，我们将知识蒸馏视为一个半参数推断问题，其中最优学生模型为目标，未知的贝叶斯类别概率为干扰项，教师概率为插件干扰估计。通过适应现代半参数工具，我们为标准蒸馏的预测误差推导了新的保证，并开发了两种增强方法——交叉拟合和损失校正——以减轻教师过拟合和欠拟合对学生表现的影响。我们在表格和图像数据上实证验证了我们的发现，并观察到我们的知识蒸馏增强方法带来的持续改进。",
        "领域": "模型压缩、知识蒸馏、半参数学习",
        "问题": "如何通过知识蒸馏提高学生模型的准确率，并解释其优于直接训练的现象",
        "动机": "探索知识蒸馏过程中学生模型准确率提升的原因，并提出方法来优化这一过程",
        "方法": "将知识蒸馏视为半参数推断问题，利用现代半参数工具推导预测误差保证，并开发交叉拟合和损失校正两种增强方法",
        "关键词": [
            "知识蒸馏",
            "半参数推断",
            "模型压缩",
            "交叉拟合",
            "损失校正"
        ],
        "涉及的技术概念": {
            "知识蒸馏": "通过训练学生模型模仿教师模型的输出，实现模型压缩和性能提升的技术",
            "半参数推断": "结合参数和非参数方法进行统计推断，用于分析知识蒸馏中的最优学生模型",
            "交叉拟合": "一种减少教师模型过拟合或欠拟合对学生模型性能影响的技术"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 406,
        "title": "Knowledge distillation via softmax regression representation learning",
        "html": "https://iclr.cc//virtual/2021/poster/2531",
        "abstract": "This paper addresses the problem of model compression via knowledge distillation. We advocate for a method that optimizes the output feature of the penultimate layer of the student network and hence is directly related to representation learning. Previous distillation methods which typically impose direct feature matching between the student and the teacher do not take into account the classification problem at hand. On the contrary, our distillation method decouples representation learning and classification and utilizes the teacher's pre-trained classifier to train the student's penultimate layer feature. In particular, for the same input image, we wish the teacher's and student's feature to produce the same output when passed through the teacher's classifier which is achieved with a simple $L_2$ loss. Our method is extremely simple to implement and straightforward to train and is shown to consistently outperform previous state-of-the-art methods over a large set of experimental settings including different (a) network architectures, (b) teacher-student capacities, (c) datasets, and (d) domains. The code will be available at \\url{https://github.com/jingyang2017/KD_SRRL}.",
        "conference": "ICLR",
        "中文标题": "通过Softmax回归表示学习实现知识蒸馏",
        "摘要翻译": "本文探讨了通过知识蒸馏进行模型压缩的问题。我们提出了一种方法，该方法优化了学生网络倒数第二层的输出特征，因此与表示学习直接相关。以往的蒸馏方法通常直接对学生和教师的特征进行匹配，而没有考虑到当前的分类问题。相反，我们的蒸馏方法将表示学习和分类解耦，并利用教师预训练的分类器来训练学生的倒数第二层特征。具体来说，对于相同的输入图像，我们希望当通过教师的分类器时，教师和学生的特征能产生相同的输出，这是通过简单的L2损失实现的。我们的方法实现极其简单，训练直接，并且在包括不同的（a）网络架构，（b）教师-学生能力，（c）数据集，和（d）领域在内的大量实验设置中，始终优于先前的最先进方法。代码将在https://github.com/jingyang2017/KD_SRRL提供。",
        "领域": "模型压缩、知识蒸馏、表示学习",
        "问题": "如何在知识蒸馏过程中更有效地进行模型压缩和表示学习",
        "动机": "解决现有知识蒸馏方法在特征匹配时忽略分类问题，以及表示学习与分类耦合的问题",
        "方法": "通过解耦表示学习和分类，利用教师模型的预训练分类器指导学生模型倒数第二层特征的训练，使用L2损失确保学生和教师特征在通过教师分类器时输出一致",
        "关键词": [
            "知识蒸馏",
            "模型压缩",
            "表示学习",
            "Softmax回归",
            "L2损失"
        ],
        "涉及的技术概念": {
            "知识蒸馏": "一种模型压缩技术，通过训练一个较小的学生模型来模仿较大的教师模型的行为",
            "表示学习": "学习数据的表示形式，以便于后续任务如分类等",
            "L2损失": "用于衡量学生和教师模型特征在通过教师分类器时输出差异的损失函数"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 407,
        "title": "LambdaNetworks: Modeling long-range Interactions without Attention",
        "html": "https://iclr.cc//virtual/2021/poster/3294",
        "abstract": "We present lambda layers -- an alternative framework to self-attention -- for capturing long-range interactions between an input and structured contextual information (e.g. a pixel surrounded by other pixels). Lambda layers capture such interactions by transforming available contexts into linear functions, termed lambdas, and applying these linear functions to each input separately. Similar to linear attention, lambda layers bypass expensive attention maps, but in contrast, they model both content and position-based interactions which enables their application to large structured inputs such as images. The resulting neural network architectures, LambdaNetworks, significantly outperform their convolutional and attentional counterparts on ImageNet classification, COCO object detection and instance segmentation, while being more computationally efficient. Additionally, we design LambdaResNets, a family of hybrid architectures across different scales, that considerably improves the speed-accuracy tradeoff of image classification models. LambdaResNets reach excellent accuracies on ImageNet while being 3.2 - 4.4x faster than the popular EfficientNets on modern machine learning accelerators. In large-scale semi-supervised training with an additional 130M pseudo-labeled images, LambdaResNets achieve up to 86.7% ImageNet accuracy while being 9.5x faster than EfficientNet NoisyStudent and 9x faster than a Vision Transformer with comparable accuracies.",
        "conference": "ICLR",
        "中文标题": "Lambda网络：无需注意力机制的长距离交互建模",
        "摘要翻译": "我们提出了lambda层——一种替代自注意力机制的框架——用于捕获输入与结构化上下文信息（例如被其他像素包围的像素）之间的长距离交互。Lambda层通过将可用上下文转换为线性函数（称为lambdas），并将这些线性函数分别应用于每个输入，来捕获此类交互。与线性注意力类似，lambda层绕过了昂贵的注意力图，但不同的是，它们同时建模了基于内容和位置的交互，这使得它们能够应用于图像等大型结构化输入。由此产生的神经网络架构——Lambda网络，在ImageNet分类、COCO目标检测和实例分割上显著优于其卷积和注意力机制的对应物，同时计算效率更高。此外，我们设计了LambdaResNets，这是一系列跨不同尺度的混合架构，显著改善了图像分类模型的速度-准确度权衡。LambdaResNets在ImageNet上达到了优异的准确度，同时在现代机器学习加速器上比流行的EfficientNets快3.2至4.4倍。在使用额外130M伪标记图像的大规模半监督训练中，LambdaResNets实现了高达86.7%的ImageNet准确度，同时比EfficientNet NoisyStudent快9.5倍，比具有可比准确度的Vision Transformer快9倍。",
        "领域": "图像分类, 目标检测, 实例分割",
        "问题": "如何在无需昂贵注意力机制的情况下，有效捕获长距离交互",
        "动机": "为了在保持计算效率的同时，提高模型在图像分类、目标检测和实例分割任务中的性能",
        "方法": "提出lambda层作为自注意力机制的替代，通过将上下文信息转换为线性函数并分别应用于每个输入，来捕获长距离交互",
        "关键词": [
            "Lambda层",
            "长距离交互",
            "LambdaResNets",
            "图像分类",
            "计算效率"
        ],
        "涉及的技术概念": {
            "Lambda层": "一种替代自注意力机制的框架，通过将上下文信息转换为线性函数来捕获长距离交互",
            "LambdaResNets": "一系列跨不同尺度的混合架构，旨在改善图像分类模型的速度-准确度权衡",
            "半监督训练": "在训练过程中使用伪标记图像来扩展训练数据集，以提高模型的准确度"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 408,
        "title": "Language-Agnostic Representation Learning of Source Code from Structure and Context",
        "html": "https://iclr.cc//virtual/2021/poster/2838",
        "abstract": "Source code (Context) and its parsed abstract syntax tree (AST; Structure) are two complementary representations of the same computer program. Traditionally, designers of machine learning models have relied predominantly either on Structure or Context. We propose a new model, which jointly learns on Context and Structure of source code. In contrast to previous approaches, our model uses only language-agnostic features, i.e., source code and features that can be computed directly from the AST. Besides obtaining state-of-the-art on monolingual code summarization on all five programming languages considered in this work, we propose the first multilingual code summarization model. We show that jointly training on non-parallel data from multiple programming languages improves results on all individual languages, where the strongest gains are on low-resource languages. Remarkably, multilingual training only from Context does not lead to the same improvements, highlighting the benefits of combining Structure and Context for representation learning on code.",
        "conference": "ICLR",
        "中文标题": "源代码结构与上下文无关表示学习",
        "摘要翻译": "源代码（上下文）及其解析的抽象语法树（AST；结构）是同一计算机程序的两种互补表示。传统上，机器学习模型的设计者主要依赖于结构或上下文中的一种。我们提出了一种新模型，该模型联合学习源代码的上下文和结构。与之前的方法相比，我们的模型仅使用与语言无关的特征，即源代码和可以直接从AST计算的特征。除了在本文考虑的所有五种编程语言上获得单语言代码摘要的最新成果外，我们还提出了第一个多语言代码摘要模型。我们展示了在多种编程语言的非并行数据上联合训练可以提高所有单独语言的结果，其中低资源语言的收益最大。值得注意的是，仅从上下文进行的多语言训练不会带来相同的改进，这突出了结合结构和上下文进行代码表示学习的好处。",
        "领域": "自然语言处理与视觉结合、代码表示学习、多语言处理",
        "问题": "如何联合利用源代码的上下文和结构进行有效的代码表示学习，以提升代码摘要的性能，特别是在多语言环境下。",
        "动机": "传统的机器学习模型在处理源代码时，往往只依赖于结构或上下文中的一种，这限制了模型的性能。通过联合学习源代码的上下文和结构，可以提高代码摘要的准确性和泛化能力，尤其是在多语言和低资源语言环境下。",
        "方法": "提出了一种新模型，该模型联合学习源代码的上下文和结构，仅使用与语言无关的特征。通过在多语言非并行数据上进行联合训练，提高了单语言和多语言代码摘要的性能。",
        "关键词": [
            "代码表示学习",
            "多语言代码摘要",
            "抽象语法树",
            "上下文无关特征",
            "联合学习"
        ],
        "涉及的技术概念": {
            "抽象语法树（AST）": "用于表示源代码结构的树状数据结构，模型从中提取与语言无关的特征进行学习。",
            "语言无关特征": "指不依赖于特定编程语言的源代码特征，使得模型能够跨语言学习和应用。",
            "多语言联合训练": "通过在多种编程语言的非并行数据上进行训练，提高模型在单语言和多语言任务上的性能，特别是在低资源语言上的表现。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 409,
        "title": "Large Associative Memory Problem in Neurobiology and Machine Learning",
        "html": "https://iclr.cc//virtual/2021/poster/2695",
        "abstract": "Dense Associative Memories or modern Hopfield networks permit storage and reliable  retrieval of an exponentially large (in the dimension of feature space) number of memories. At the same time, their naive implementation is non-biological, since it seemingly requires the existence of many-body synaptic junctions between the neurons.  We show that these models are effective descriptions of a more microscopic (written in terms of biological degrees of freedom) theory that has additional (hidden) neurons and only requires two-body interactions between them. For this reason our proposed microscopic theory is a valid model of large associative memory with a degree of biological plausibility. The dynamics of our network and its reduced dimensional equivalent both minimize energy (Lyapunov) functions. When certain dynamical variables (hidden neurons) are integrated out from our microscopic theory, one can recover many of the models that were previously discussed in the literature, e.g. the model presented in 'Hopfield Networks is All You Need' paper. We also provide an alternative derivation of the energy function and the update rule proposed in the aforementioned paper and clarify the relationships between various models of this class.",
        "conference": "ICLR",
        "中文标题": "神经生物学与机器学习中的大型联想记忆问题",
        "摘要翻译": "密集联想记忆或现代Hopfield网络允许存储和可靠检索特征空间维度上指数级大量的记忆。然而，它们的简单实现是非生物学的，因为这似乎需要神经元之间存在多体突触连接。我们展示这些模型是对一个更微观（用生物自由度描述）理论的有效描述，该理论具有额外的（隐藏的）神经元，并且仅需要它们之间的二体相互作用。因此，我们提出的微观理论是一个具有生物学合理性的大型联想记忆的有效模型。我们的网络动态及其降维等效都最小化能量（Lyapunov）函数。当某些动态变量（隐藏神经元）从我们的微观理论中积分出来时，可以恢复许多先前在文献中讨论过的模型，例如在'Hopfield Networks is All You Need'论文中提出的模型。我们还提供了上述论文中提出的能量函数和更新规则的另一种推导，并澄清了这类模型中各种模型之间的关系。",
        "领域": "神经网络模型, 联想记忆, 计算神经科学",
        "问题": "如何在保持生物学合理性的同时，实现大型联想记忆的存储和检索",
        "动机": "探索和开发一种既具有生物学合理性又能有效处理大型联想记忆的神经网络模型",
        "方法": "提出一种微观理论，通过引入隐藏神经元和限制于二体相互作用，实现对大型联想记忆的有效描述",
        "关键词": [
            "联想记忆",
            "Hopfield网络",
            "生物合理性",
            "能量函数",
            "神经网络动态"
        ],
        "涉及的技术概念": {
            "密集联想记忆": "允许存储和检索特征空间维度上指数级大量记忆的网络模型",
            "现代Hopfield网络": "一种改进的Hopfield网络，能够更有效地处理联想记忆任务",
            "Lyapunov函数": "用于分析和保证网络动态稳定性的能量函数"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 410,
        "title": "Large Batch Simulation for Deep Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2021/poster/3314",
        "abstract": "We accelerate deep reinforcement learning-based training in visually complex 3D environments by two orders of magnitude over prior work, realizing end-to-end training speeds of over 19,000 frames of experience per second on a single GPU and up to 72,000 frames per second on a single eight-GPU machine. The key idea of our approach is to design a 3D renderer and embodied navigation simulator around the principle of “batch simulation”: accepting and executing large batches of requests simultaneously.  Beyond exposing large amounts of work at once, batch simulation allows implementations to amortize in-memory storage of scene assets, rendering work, data loading, and synchronization costs across many simulation requests, dramatically improving the number of simulated agents per GPU and overall simulation throughput.  To balance DNN inference and training costs with faster simulation, we also build a computationally efficient policy DNN that maintains high task performance, and modify training algorithms to maintain sample efficiency when training with large mini-batches. By combining batch simulation and DNN performance optimizations, we demonstrate that PointGoal navigation agents can be trained in complex 3D environments on a single GPU in 1.5 days to 97% of the accuracy of agents trained on a prior state-of-the-art system using a 64-GPU cluster over three days.  We provide open-source reference implementations of our batch 3D renderer and simulator to facilitate incorporation of these ideas into RL systems.",
        "conference": "ICLR",
        "中文标题": "大规模批量模拟用于深度强化学习",
        "摘要翻译": "我们将在视觉复杂的3D环境中基于深度强化学习的训练速度提高了两个数量级，实现了在单个GPU上每秒超过19,000帧经验的端到端训练速度，以及在单个八GPU机器上每秒高达72,000帧的速度。我们方法的关键思想是围绕“批量模拟”原则设计一个3D渲染器和实体导航模拟器：同时接受并执行大批量请求。除了立即暴露大量工作外，批量模拟还允许实现跨许多模拟请求分摊场景资产的内存存储、渲染工作、数据加载和同步成本，显著提高了每个GPU的模拟代理数量和整体模拟吞吐量。为了平衡DNN推理和训练成本与更快的模拟，我们还构建了一个计算效率高的策略DNN，保持高任务性能，并修改训练算法以在使用大批量训练时保持样本效率。通过结合批量模拟和DNN性能优化，我们证明了PointGoal导航代理可以在复杂的3D环境中在单个GPU上1.5天内训练到97%的准确率，而之前的最先进系统使用64-GPU集群需要三天。我们提供了批量3D渲染器和模拟器的开源参考实现，以促进将这些想法融入RL系统。",
        "领域": "深度强化学习、3D环境模拟、机器人导航",
        "问题": "加速在视觉复杂的3D环境中基于深度强化学习的训练过程",
        "动机": "提高深度强化学习在复杂3D环境中的训练效率，减少计算资源消耗",
        "方法": "设计支持批量模拟的3D渲染器和导航模拟器，优化策略DNN和训练算法以提高效率",
        "关键词": [
            "批量模拟",
            "深度强化学习",
            "3D渲染",
            "策略DNN",
            "训练优化"
        ],
        "涉及的技术概念": {
            "批量模拟": "同时处理大批量模拟请求，提高模拟吞吐量和效率",
            "策略DNN": "高效计算的深度神经网络，用于保持高任务性能",
            "训练算法优化": "修改算法以适应大批量训练，保持样本效率"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 411,
        "title": "Large Scale Image Completion via Co-Modulated Generative Adversarial Networks",
        "html": "https://iclr.cc//virtual/2021/poster/2759",
        "abstract": "Numerous task-specific variants of conditional generative adversarial networks have been developed for image completion. Yet, a serious limitation remains that all existing algorithms tend to fail when handling large-scale missing regions. To overcome this challenge, we propose a generic new approach that bridges the gap between image-conditional and recent modulated unconditional generative architectures via co-modulation of both conditional and stochastic style representations. Also, due to the lack of good quantitative metrics for image completion, we propose the new Paired/Unpaired Inception Discriminative Score (P-IDS/U-IDS), which robustly measures the perceptual fidelity of inpainted images compared to real images via linear separability in a feature space. Experiments demonstrate superior performance in terms of both quality and diversity over state-of-the-art methods in free-form image completion and easy generalization to image-to-image translation. Code is available at https://github.com/zsyzzsoft/co-mod-gan.",
        "conference": "ICLR",
        "中文标题": "通过共调制生成对抗网络进行大规模图像补全",
        "摘要翻译": "针对图像补全任务，已经开发了许多条件生成对抗网络的任务特定变体。然而，一个严重的限制是，所有现有算法在处理大规模缺失区域时往往失败。为了克服这一挑战，我们提出了一种通用的新方法，通过共调制条件和随机风格表示，弥合了图像条件与最近调制的无条件生成架构之间的差距。此外，由于缺乏良好的图像补全定量指标，我们提出了新的配对/非配对初始判别分数（P-IDS/U-IDS），通过特征空间中的线性可分性，稳健地测量修复图像与真实图像之间的感知保真度。实验证明，在自由形式图像补全和轻松泛化到图像到图像转换方面，我们的方法在质量和多样性上都优于最先进的方法。代码可在https://github.com/zsyzzsoft/co-mod-gan获取。",
        "领域": "图像补全、生成对抗网络、图像到图像转换",
        "问题": "现有图像补全算法在处理大规模缺失区域时效果不佳",
        "动机": "克服现有算法在大规模缺失区域图像补全中的限制，提高补全图像的质量和多样性",
        "方法": "提出一种通过共调制条件和随机风格表示的新方法，弥合图像条件与无条件生成架构之间的差距，并引入新的定量指标P-IDS/U-IDS",
        "关键词": [
            "图像补全",
            "生成对抗网络",
            "共调制",
            "P-IDS/U-IDS",
            "图像到图像转换"
        ],
        "涉及的技术概念": {
            "共调制生成对抗网络": "通过同时调制条件和随机风格表示，提高图像补全的质量和多样性",
            "P-IDS/U-IDS": "新的定量指标，用于测量修复图像与真实图像之间的感知保真度",
            "图像到图像转换": "将一种图像转换为另一种图像的任务，本方法在此任务上表现出良好的泛化能力"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 412,
        "title": "Large-width functional asymptotics for deep Gaussian neural networks",
        "html": "https://iclr.cc//virtual/2021/poster/2635",
        "abstract": "In this paper, we consider fully connected feed-forward deep neural networks where weights and biases are independent and identically distributed according to Gaussian distributions. Extending previous results (Matthews et al., 2018a;b;Yang, 2019)  we adopt a function-space perspective, i.e. we look at neural networks as infinite-dimensional random elements on the input space $\\mathbb{R}^I$. Under suitable assumptions on the activation function we show that: i) a network defines a continuous Gaussian process on the input space $\\mathbb{R}^I$; ii) a network with re-scaled weights converges weakly to a continuous Gaussian process in the large-width limit; iii) the limiting Gaussian process has almost surely locally $\\gamma$-Hölder continuous paths, for $0 < \\gamma <1$. Our results contribute to recent theoretical studies on the interplay between infinitely wide deep neural networks and Gaussian processes by establishing weak convergence in function-space with respect to a stronger metric.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "深度高斯神经网络的大宽度泛函渐近性",
        "摘要翻译": "本文研究了全连接前馈深度神经网络，其中权重和偏差根据高斯分布独立同分布。扩展了之前的研究结果 (Matthews et al., 2018a;b;Yang, 2019)，我们采用函数空间视角，即我们将神经网络视为输入空间上的无限维随机元素。在激活函数的适当假设下，我们证明：i) 一个网络在输入空间上定义了一个连续高斯过程；ii) 一个具有重新缩放权重的网络在大宽度极限下弱收敛到一个连续高斯过程；iii) 对于 0 < γ < 1，极限高斯过程几乎肯定具有局部 γ-Hölder 连续路径。我们的结果通过建立关于更强度量的函数空间中的弱收敛性，为最近关于无限宽深度神经网络和高斯过程之间相互作用的理论研究做出了贡献。",
        "领域": "神经网络理论, 高斯过程, 函数空间分析",
        "问题": "研究深度高斯神经网络在大宽度极限下的函数空间行为，并证明其收敛到高斯过程。",
        "动机": "深入理解无限宽深度神经网络与高斯过程之间的关系，为深度学习的理论基础提供支持。",
        "方法": "采用函数空间视角，将神经网络视为无限维随机元素，并利用弱收敛理论证明网络在大宽度极限下收敛到高斯过程。",
        "关键词": [
            "高斯过程",
            "深度神经网络",
            "函数空间",
            "弱收敛",
            "大宽度极限"
        ],
        "涉及的技术概念": {
            "高斯过程": "一种随机过程，其任意有限个点的联合概率分布都是高斯分布。论文中用高斯过程来描述深度神经网络在大宽度极限下的行为。",
            "弱收敛": "概率论中的一种收敛方式，指随机变量序列的分布函数收敛到某个分布函数。论文中用弱收敛来证明深度神经网络在大宽度极限下收敛到高斯过程。"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 413,
        "title": "Latent Convergent Cross Mapping",
        "html": "https://iclr.cc//virtual/2021/poster/2939",
        "abstract": "Discovering causal structures of temporal processes is a major tool of scientific inquiry because it helps us better understand and explain the mechanisms driving a phenomenon of interest, thereby facilitating analysis, reasoning, and synthesis for such systems. \nHowever, accurately inferring causal structures within a phenomenon based on observational data only is still an open problem. Indeed, this type of data usually consists in short time series with missing or noisy values for which causal inference is increasingly difficult. In this work, we propose a method to uncover causal relations in chaotic dynamical systems from short, noisy and sporadic time series (that is, incomplete observations at infrequent and irregular intervals) where the classical convergent cross mapping (CCM) fails. Our method works by learning a Neural ODE latent process modeling the state-space dynamics of the time series and by checking the existence of a continuous map between the resulting processes. We provide theoretical analysis and show empirically that Latent-CCM can reliably uncover the true causal pattern, unlike traditional methods.",
        "conference": "ICLR",
        "中文标题": "潜在收敛交叉映射",
        "摘要翻译": "发现时间过程的因果结构是科学探究的主要工具，因为它帮助我们更好地理解和解释驱动感兴趣现象的机制，从而促进对此类系统的分析、推理和综合。然而，仅基于观测数据准确推断现象内的因果结构仍然是一个未解决的问题。实际上，这类数据通常由具有缺失或噪声值的短时间序列组成，因果推断变得越来越困难。在这项工作中，我们提出了一种方法，用于从短、噪声和零星的时间序列（即在罕见和不规则间隔的不完整观测）中揭示混沌动力系统中的因果关系，其中经典的收敛交叉映射（CCM）失败。我们的方法通过学习一个神经ODE潜在过程来建模时间序列的状态空间动态，并通过检查结果过程之间是否存在连续映射来工作。我们提供了理论分析，并实证表明，与传统方法不同，Latent-CCM可以可靠地揭示真实的因果模式。",
        "领域": "时间序列分析、因果推断、混沌动力系统",
        "问题": "从短、噪声和零星的时间序列中准确推断混沌动力系统中的因果关系",
        "动机": "解决在观测数据有限且质量不高的情况下，传统因果推断方法难以准确揭示混沌动力系统中因果关系的问题",
        "方法": "通过学习神经ODE潜在过程建模时间序列的状态空间动态，并检查过程间是否存在连续映射来揭示因果关系",
        "关键词": [
            "因果推断",
            "混沌动力系统",
            "神经ODE",
            "时间序列分析",
            "潜在过程"
        ],
        "涉及的技术概念": {
            "神经ODE": "用于建模时间序列的状态空间动态，捕捉系统的连续时间演化",
            "收敛交叉映射（CCM）": "传统方法，用于检测时间序列间的因果关系，但在短、噪声和零星数据上效果有限",
            "潜在过程": "通过学习数据的内在表示，揭示隐藏在观测数据之下的动态结构和因果关系"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 414,
        "title": "Latent Skill Planning for Exploration and Transfer",
        "html": "https://iclr.cc//virtual/2021/poster/3027",
        "abstract": "To quickly solve new tasks in complex environments, intelligent agents need to build up reusable knowledge. For example, a learned world model captures knowledge about the environment that applies to new tasks. Similarly, skills capture general behaviors that can apply to new tasks. In this paper, we investigate how these two approaches can be integrated into a single reinforcement learning agent. Specifically, we leverage the idea of partial amortization for fast adaptation at test time. For this, actions are produced by a policy that is learned over time while the skills it conditions on are chosen using online planning. We demonstrate the benefits of our design decisions across a suite of challenging locomotion tasks and demonstrate improved sample efficiency in single tasks as well as in transfer from one task to another, as compared to competitive baselines. Videos are available at: https://sites.google.com/view/latent-skill-planning/",
        "conference": "ICLR",
        "中文标题": "潜在技能规划用于探索与迁移",
        "摘要翻译": "为了在复杂环境中快速解决新任务，智能代理需要积累可重用的知识。例如，一个学习到的世界模型捕捉了适用于新任务的环境知识。同样，技能捕捉了可以应用于新任务的通用行为。在本文中，我们研究了如何将这两种方法整合到一个单一的强化学习代理中。具体来说，我们利用部分分摊的思想在测试时快速适应。为此，动作由一个随时间学习的策略产生，而它所基于的技能则通过在线规划选择。我们通过一系列具有挑战性的运动任务展示了我们设计决策的优势，并展示了在单个任务中以及从一个任务迁移到另一个任务时的样本效率提高，与竞争基线相比。视频可在以下网址获取：https://sites.google.com/view/latent-skill-planning/",
        "领域": "强化学习、机器人控制、技能迁移",
        "问题": "如何在强化学习代理中整合世界模型和技能学习，以提高在新任务中的适应性和效率",
        "动机": "探索如何通过结合世界模型和技能学习，使智能代理能够更有效地在复杂环境中学习和迁移知识",
        "方法": "利用部分分摊的思想进行快速适应，通过在线规划选择技能，同时学习产生动作的策略",
        "关键词": [
            "潜在技能规划",
            "强化学习",
            "技能迁移",
            "在线规划",
            "世界模型"
        ],
        "涉及的技术概念": {
            "部分分摊": "用于在测试时快速适应，通过分摊计算成本来提高效率",
            "在线规划": "用于动态选择技能，以适应不断变化的任务需求",
            "世界模型": "捕捉环境知识，使代理能够理解和预测环境动态"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 415,
        "title": "Layer-adaptive Sparsity for the Magnitude-based Pruning",
        "html": "https://iclr.cc//virtual/2021/poster/3108",
        "abstract": "Recent discoveries on neural network pruning reveal that, with a carefully chosen layerwise sparsity, a simple magnitude-based pruning achieves state-of-the-art tradeoff between sparsity and performance. However, without a clear consensus on ``how to choose,'' the layerwise sparsities are mostly selected algorithm-by-algorithm, often resorting to handcrafted heuristics or an extensive hyperparameter search. To fill this gap, we propose a novel importance score for global pruning, coined layer-adaptive magnitude-based pruning (LAMP) score; the score is a rescaled version of weight magnitude that incorporates the model-level $\\ell_2$ distortion incurred by pruning, and does not require any hyperparameter tuning or heavy computation.\nUnder various image classification setups, LAMP consistently outperforms popular existing schemes for layerwise sparsity selection.\nFurthermore, we observe that LAMP continues to outperform baselines even in weight-rewinding setups, while the connectivity-oriented layerwise sparsity (the strongest baseline overall) performs worse than a simple global magnitude-based pruning in this case. Code: https://github.com/jaeho-lee/layer-adaptive-sparsity",
        "conference": "ICLR",
        "success": true,
        "中文标题": "基于幅度的剪枝中的层自适应稀疏性",
        "摘要翻译": "最近关于神经网络剪枝的研究发现，通过精心选择的逐层稀疏度，简单的基于幅度的剪枝可以在稀疏性和性能之间达到最先进的权衡。然而，由于缺乏关于‘如何选择’的明确共识，逐层稀疏度大多是算法间各自选择的，常常依赖于手工启发式或广泛的超参数搜索。为了填补这一空白，我们提出了一种新的全局剪枝重要性评分，称为层自适应基于幅度的剪枝（LAMP）评分；该评分是权重幅度的重新缩放版本，包含了剪枝引起的模型级ℓ2失真，并且不需要任何超参数调整或大量计算。在各种图像分类设置下，LAMP始终优于现有的逐层稀疏度选择方案。此外，我们观察到，即使在权重重绕设置中，LAMP仍然优于基线，而面向连接的逐层稀疏度（总体上最强的基线）在这种情况下比简单的全局基于幅度的剪枝表现更差。代码：https://github.com/jaeho-lee/layer-adaptive-sparsity",
        "领域": "神经网络剪枝",
        "问题": "如何在没有明确共识的情况下选择逐层稀疏度，以实现剪枝后的最优性能与稀疏性平衡",
        "动机": "填补现有剪枝方法在逐层稀疏度选择上的空白，减少对手工启发式或超参数搜索的依赖",
        "方法": "提出了一种新的全局剪枝重要性评分——层自适应基于幅度的剪枝（LAMP）评分，该评分通过重新缩放权重幅度并考虑模型级ℓ2失真，无需超参数调整或大量计算",
        "关键词": [
            "神经网络剪枝",
            "层自适应稀疏性",
            "LAMP评分",
            "全局剪枝",
            "图像分类"
        ],
        "涉及的技术概念": {
            "层自适应稀疏性": "在神经网络剪枝中，根据不同层的特点自适应地选择稀疏度，以优化剪枝效果",
            "LAMP评分": "一种新的全局剪枝重要性评分，通过重新缩放权重幅度并考虑模型级ℓ2失真，无需超参数调整或大量计算",
            "模型级ℓ2失真": "剪枝操作对模型整体性能的影响度量，LAMP评分通过考虑这一因素来优化剪枝策略"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 416,
        "title": "LEAF: A Learnable Frontend for Audio Classification",
        "html": "https://iclr.cc//virtual/2021/poster/2668",
        "abstract": "Mel-filterbanks are fixed, engineered audio features which emulate human perception and have been used through the history of audio understanding up to today. However, their undeniable qualities are counterbalanced by the fundamental limitations of handmade representations. In this work we show that we can train a single learnable frontend that outperforms mel-filterbanks on a wide range of audio signals, including speech, music, audio events and animal sounds, providing a general-purpose learned frontend for audio classification. To do so, we introduce a new principled, lightweight, fully learnable architecture that can be used as a drop-in replacement of mel-filterbanks. Our system learns all operations of audio features extraction, from filtering to pooling, compression and normalization, and can be integrated into any neural network at a negligible parameter cost. We perform multi-task training on eight diverse audio classification tasks, and show consistent improvements of our model over mel-filterbanks and previous learnable alternatives. Moreover, our system outperforms the current state-of-the-art learnable frontend on Audioset, with orders of magnitude fewer parameters.",
        "conference": "ICLR",
        "中文标题": "LEAF：一种可学习的音频分类前端",
        "摘要翻译": "梅尔滤波器组是固定的、工程化的音频特征，它们模拟了人类的感知，并且从音频理解的历史一直使用到今天。然而，它们不可否认的优点被手工制作表示的基本局限性所抵消。在这项工作中，我们展示了我们可以训练一个单一的可学习前端，其在广泛的音频信号上优于梅尔滤波器组，包括语音、音乐、音频事件和动物声音，为音频分类提供了一个通用的学习前端。为此，我们引入了一种新的、有原则的、轻量级的、完全可学习的架构，可以作为梅尔滤波器组的即插即用替代品。我们的系统学习了音频特征提取的所有操作，从滤波到池化、压缩和归一化，并且可以以可忽略的参数成本集成到任何神经网络中。我们在八个不同的音频分类任务上进行了多任务训练，并展示了我们的模型相对于梅尔滤波器组和以前的可学习替代方案的持续改进。此外，我们的系统在Audioset上以数量级更少的参数优于当前最先进的可学习前端。",
        "领域": "音频信号处理, 深度学习, 音频分类",
        "问题": "解决手工制作的音频特征（如梅尔滤波器组）在音频分类任务中的基本局限性问题。",
        "动机": "开发一种能够超越传统手工制作音频特征性能的可学习前端，以提供更通用的音频分类解决方案。",
        "方法": "引入一种新的、完全可学习的轻量级架构，该架构能够学习音频特征提取的所有操作，并可以作为梅尔滤波器组的替代品。",
        "关键词": [
            "可学习前端",
            "音频分类",
            "梅尔滤波器组",
            "轻量级架构",
            "多任务训练"
        ],
        "涉及的技术概念": {
            "可学习前端": "一种可以替代传统固定音频特征提取方法的架构，能够通过训练学习最优的音频特征提取策略。",
            "梅尔滤波器组": "传统的固定音频特征提取方法，模拟人类听觉系统的频率感知特性。",
            "多任务训练": "在多个相关任务上同时训练模型，以提高模型的泛化能力和性能。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 417,
        "title": "Learnable Embedding sizes for Recommender Systems",
        "html": "https://iclr.cc//virtual/2021/poster/3372",
        "abstract": "The embedding-based representation learning is commonly used in deep learning recommendation models to map the raw sparse features to dense vectors. The traditional embedding manner that assigns a uniform size to all features has two issues. First, the numerous features inevitably lead to a gigantic embedding table that causes a high memory usage cost. Second, it is likely to cause the over-fitting problem for those features that do not require too large representation capacity. Existing works that try to address the problem always cause a significant drop in recommendation performance or suffers from the limitation of unaffordable training time cost. In this paper, we proposed a novel approach, named PEP (short for Plug-in Embedding Pruning), to reduce the size of the embedding table while avoiding the drop of recommendation accuracy. PEP prunes embedding parameter where the pruning threshold(s) can be adaptively learned from data. Therefore we can automatically obtain a mixed-dimension embedding-scheme by pruning redundant parameters for each feature. PEP is a general framework that can plug in various base recommendation models. Extensive experiments demonstrate it can efficiently cut down embedding parameters and boost the base model's performance. Specifically, it achieves strong recommendation performance while reducing 97-99% parameters. As for the computation cost, PEP only brings an additional 20-30% time cost compare with base models. ",
        "conference": "ICLR",
        "中文标题": "可学习嵌入尺寸的推荐系统",
        "摘要翻译": "基于嵌入的表示学习在深度学习推荐模型中常用，用于将原始的稀疏特征映射到密集向量。传统的嵌入方式为所有特征分配统一尺寸，存在两个问题。首先，大量的特征不可避免地导致巨大的嵌入表，从而引起高内存使用成本。其次，对于那些不需要太大表示能力的特征，很可能导致过拟合问题。现有尝试解决这一问题的研究总是导致推荐性能显著下降或承受不起的训练时间成本。在本文中，我们提出了一种名为PEP（插件嵌入剪枝的简称）的新方法，以减少嵌入表的大小，同时避免推荐准确性的下降。PEP剪枝嵌入参数，其中剪枝阈值可以从数据中自适应学习。因此，我们可以通过为每个特征剪枝冗余参数来自动获得混合维度的嵌入方案。PEP是一个通用框架，可以插入各种基础推荐模型。大量实验证明，它可以有效减少嵌入参数并提升基础模型的性能。具体来说，它在减少97-99%参数的同时实现了强大的推荐性能。至于计算成本，PEP仅比基础模型带来额外20-30%的时间成本。",
        "领域": "推荐系统、深度学习、特征表示学习",
        "问题": "传统嵌入方式中统一尺寸分配导致的高内存成本和过拟合问题",
        "动机": "解决传统嵌入方式在推荐系统中导致的高内存使用和过拟合问题，同时保持或提升推荐性能",
        "方法": "提出了一种名为PEP（插件嵌入剪枝）的方法，通过自适应学习剪枝阈值来减少嵌入表的大小，同时避免推荐准确性的下降",
        "关键词": [
            "推荐系统",
            "嵌入剪枝",
            "混合维度嵌入",
            "深度学习",
            "参数优化"
        ],
        "涉及的技术概念": {
            "嵌入剪枝": "通过剪枝冗余参数减少嵌入表的大小，同时保持或提升模型性能",
            "混合维度嵌入": "为每个特征自动获得适合的嵌入维度，解决统一尺寸分配的问题",
            "自适应学习阈值": "从数据中自适应学习剪枝阈值，优化嵌入参数的剪枝过程"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 418,
        "title": "Learning Accurate Entropy Model with Global Reference for Image Compression",
        "html": "https://iclr.cc//virtual/2021/poster/2829",
        "abstract": "In recent deep image compression neural networks, the entropy model plays a critical role in estimating the prior distribution of deep image encodings. Existing methods combine hyperprior with local context in the entropy estimation function. This greatly limits their performance due to the absence of a global vision. In this work, we propose a novel Global Reference Model for image compression to effectively leverage both the local and the global context information, leading to an enhanced compression rate. The proposed method scans decoded latents and then finds the most relevant latent to assist the distribution estimating of the current latent. A by-product of this work is the innovation of a mean-shifting GDN module that further improves the performance. Experimental results demonstrate that the proposed model outperforms the rate-distortion performance of most of the state-of-the-art methods in the industry.",
        "conference": "ICLR",
        "中文标题": "学习具有全局参考的精确熵模型用于图像压缩",
        "摘要翻译": "在最近的深度图像压缩神经网络中，熵模型在估计深度图像编码的先验分布方面起着关键作用。现有方法在熵估计函数中将超先验与局部上下文结合。由于缺乏全局视野，这大大限制了它们的性能。在这项工作中，我们提出了一种新颖的全局参考模型用于图像压缩，以有效利用局部和全局上下文信息，从而提高压缩率。所提出的方法扫描解码后的潜在变量，然后找到最相关的潜在变量以协助当前潜在变量的分布估计。这项工作的一个副产品是创新了一个均值偏移GDN模块，进一步提高了性能。实验结果表明，所提出的模型在率失真性能上优于行业中大多数最先进的方法。",
        "领域": "图像压缩、深度学习、熵模型优化",
        "问题": "现有图像压缩方法在熵估计中缺乏全局视野，限制了压缩性能。",
        "动机": "通过结合局部和全局上下文信息，提高图像压缩的效率和性能。",
        "方法": "提出一种全局参考模型，通过扫描解码后的潜在变量并利用最相关的潜在变量来协助分布估计，同时创新均值偏移GDN模块以进一步提升性能。",
        "关键词": [
            "图像压缩",
            "熵模型",
            "全局参考",
            "均值偏移GDN",
            "率失真性能"
        ],
        "涉及的技术概念": {
            "熵模型": "用于估计深度图像编码的先验分布，是深度图像压缩中的关键组成部分。",
            "全局参考模型": "提出的新模型，通过利用全局上下文信息来改进熵估计，从而提高压缩率。",
            "均值偏移GDN模块": "创新的模块，通过调整潜在变量的均值来进一步提升图像压缩的性能。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 419,
        "title": "Learning advanced mathematical computations from examples",
        "html": "https://iclr.cc//virtual/2021/poster/3219",
        "abstract": "Using transformers over large generated datasets, we train models to learn mathematical properties of differential systems, such as local stability, behavior at infinity and controllability. We achieve near perfect prediction of qualitative characteristics, and good approximations of numerical features of the system. This demonstrates that neural networks can learn to perform complex computations, grounded in advanced theory, from examples, without built-in mathematical knowledge.",
        "conference": "ICLR",
        "中文标题": "通过示例学习高级数学计算",
        "摘要翻译": "通过在大型生成的数据集上使用变换器，我们训练模型以学习微分系统的数学特性，如局部稳定性、无穷远点行为和可控性。我们实现了对系统定性特征的近乎完美预测，以及对系统数值特征的良好近似。这表明神经网络可以通过示例学习执行基于高级理论的复杂计算，而无需内置数学知识。",
        "领域": "自然语言处理与视觉结合、深度学习在数学建模中的应用、自动定理证明",
        "问题": "如何使神经网络在没有内置数学知识的情况下，通过学习示例来理解和预测微分系统的复杂数学特性。",
        "动机": "探索神经网络是否能够通过学习示例来掌握高级数学计算，从而扩展其在数学理论和应用中的使用范围。",
        "方法": "使用变换器模型在大型生成的数学数据集上进行训练，以学习微分系统的数学特性。",
        "关键词": [
            "变换器",
            "微分系统",
            "数学特性学习",
            "神经网络",
            "高级数学计算"
        ],
        "涉及的技术概念": {
            "变换器": "用于处理和学习大型生成数据集中的数学特性，是模型的核心架构。",
            "微分系统": "研究的数学对象，模型需要学习其局部稳定性、无穷远点行为和可控性等特性。",
            "数学特性学习": "指神经网络通过学习示例来理解和预测微分系统的复杂数学特性的过程。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 420,
        "title": "Learning a Latent Search Space for Routing Problems using Variational Autoencoders",
        "html": "https://iclr.cc//virtual/2021/poster/3009",
        "abstract": "Methods for automatically learning to solve routing problems are rapidly improving in performance. While most of these methods excel at generating solutions quickly, they are unable to effectively utilize longer run times because they lack a sophisticated search component. We present a learning-based optimization approach that allows a guided search in the distribution of high-quality solutions for a problem instance. More precisely, our method uses a conditional variational autoencoder that learns to map points in a continuous (latent) search space to high-quality, instance-specific routing problem solutions. The learned space can then be searched by any unconstrained continuous optimization method. We show that even using a standard differential evolution search strategy our approach is able to outperform existing purely machine learning based approaches. ",
        "conference": "ICLR",
        "中文标题": "利用变分自编码器学习路由问题的潜在搜索空间",
        "摘要翻译": "自动学习解决路由问题的方法在性能上正在迅速提高。虽然这些方法大多擅长快速生成解决方案，但由于缺乏复杂的搜索组件，它们无法有效利用更长的运行时间。我们提出了一种基于学习的优化方法，该方法允许在问题实例的高质量解决方案分布中进行引导搜索。更准确地说，我们的方法使用了一个条件变分自编码器，该编码器学习将连续（潜在）搜索空间中的点映射到高质量、特定于实例的路由问题解决方案。然后，可以通过任何无约束的连续优化方法搜索学习到的空间。我们表明，即使使用标准的差分进化搜索策略，我们的方法也能够超越现有的纯基于机器学习的方法。",
        "领域": "机器学习优化、路由问题求解、变分自编码器应用",
        "问题": "如何有效利用更长的运行时间以生成高质量的路由问题解决方案",
        "动机": "现有的自动学习方法在快速生成解决方案方面表现优异，但在利用更长的运行时间以进行深入搜索方面存在不足，因此需要一种能够引导搜索高质量解决方案的方法。",
        "方法": "使用条件变分自编码器学习将连续潜在搜索空间中的点映射到高质量、特定于实例的路由问题解决方案，并通过无约束的连续优化方法进行搜索。",
        "关键词": [
            "变分自编码器",
            "路由问题",
            "机器学习优化",
            "连续搜索空间",
            "差分进化"
        ],
        "涉及的技术概念": {
            "条件变分自编码器": "用于学习将连续潜在搜索空间中的点映射到高质量、特定于实例的路由问题解决方案的技术。",
            "连续搜索空间": "一个连续的空间，通过学习可以映射到高质量解决方案的点，使得搜索过程更加高效和灵活。",
            "差分进化": "一种无约束的连续优化方法，用于在学习的潜在搜索空间中寻找高质量解决方案。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 421,
        "title": "Learning a Latent Simplex in Input Sparsity Time",
        "html": "https://iclr.cc//virtual/2021/poster/2553",
        "abstract": "We consider the problem of learning a latent $k$-vertex simplex $K\\in\\mathbb{R}^d$, given $\\mathbf{A}\\in\\mathbb{R}^{d\\times n}$, which can be viewed as $n$ data points that are formed by randomly perturbing some latent points in $K$, possibly beyond $K$. A large class of latent variable models, such as adversarial clustering, mixed membership stochastic block models, and topic models can be cast in this view of learning a latent simplex. Bhattacharyya and Kannan (SODA 2020) give an algorithm for learning such a $k$-vertex latent simplex in time roughly $O(k\\cdot\\text{nnz}(\\mathbf{A}))$, where $\\text{nnz}(\\mathbf{A})$ is the number of non-zeros in $\\mathbf{A}$. We show that the dependence on $k$ in the running time is unnecessary given a natural assumption about the mass of the top $k$ singular values of $\\mathbf{A}$, which holds in many of these applications. Further, we show this assumption is necessary, as otherwise an algorithm for learning a latent simplex would imply a better low rank approximation algorithm than what is known. \n\nWe obtain a spectral low-rank approximation to $\\mathbf{A}$ in input-sparsity time and show that the column space thus obtained has small $\\sin\\Theta$ (angular) distance to the right top-$k$ singular space of $\\mathbf{A}$. Our algorithm then selects $k$ points in the low-rank  subspace with the largest inner product (in absolute value) with $k$ carefully chosen random vectors. By working in the low-rank subspace, we avoid reading the entire matrix in each iteration and thus circumvent the $\\Theta(k\\cdot\\text{nnz}(\\mathbf{A}))$ running time.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "在输入稀疏时间内学习潜在单纯形",
        "摘要翻译": "我们考虑学习一个潜在的 $k$ 顶点单纯形 $K\\in\\mathbb{R}^d$ 的问题，给定 $\\\\mathbf{A}\\\\in\\\\mathbb{R}^{d\\\\times n}$，它可以被看作是由随机扰动 $K$ 中某些潜在点形成的 $n$ 个数据点，可能超出 $K$。一大类潜在变量模型，如对抗聚类、混合成员随机块模型和主题模型，都可以用学习潜在单纯形的视角来表示。Bhattacharyya 和 Kannan (SODA 2020) 提出了一个算法，用于在大约 $O(k\\\\cdot\\\\text{nnz}(\\\\mathbf{A}))$ 的时间内学习这样的 $k$ 顶点潜在单纯形，其中 $\\\\text{nnz}(\\\\mathbf{A})$ 是 $\\\\mathbf{A}$ 中非零元素的数量。我们表明，如果对 $\\\\mathbf{A}$ 的前 $k$ 个奇异值的质量做出一个自然的假设（这在许多应用中都成立），则运行时间对 $k$ 的依赖是不必要的。此外，我们证明了这种假设是必要的，否则，学习潜在单纯形的算法将意味着比已知的更好的低秩逼近算法。\\n\\n我们在输入稀疏时间内获得 $\\\\mathbf{A}$ 的谱低秩逼近，并表明由此获得的列空间与 $\\\\mathbf{A}$ 的右前 $k$ 个奇异空间具有较小的 $\\\\sin\\\\Theta$（角度）距离。然后，我们的算法在低秩子空间中选择 $k$ 个点，这些点与 $k$ 个精心选择的随机向量具有最大的内积（绝对值）。通过在低秩子空间中工作，我们避免了在每次迭代中读取整个矩阵，从而避免了 $\\\\Theta(k\\\\cdot\\\\text{nnz}(\\\\mathbf{A}))$ 的运行时间。",
        "领域": "降维, 矩阵分解, 谱方法",
        "问题": "如何高效地学习一个潜在的k顶点单纯形，尤其是在数据稀疏的情况下，降低算法的时间复杂度。",
        "动机": "现有的学习潜在单纯形的算法在时间复杂度上对顶点数量k有依赖性，这在实际应用中可能成为瓶颈。该研究旨在消除这种依赖性，提高算法效率。",
        "方法": "提出了一种基于谱低秩逼近的算法，通过在输入稀疏时间内获得低秩逼近，并在该子空间中选择关键点，从而避免了对整个矩阵的重复读取，降低了时间复杂度。",
        "关键词": [
            "潜在单纯形",
            "低秩逼近",
            "谱方法",
            "输入稀疏性",
            "奇异值分解"
        ],
        "涉及的技术概念": {
            "谱低秩逼近": "一种利用矩阵的奇异值分解进行降维的技术，用于在低维空间中保留矩阵的主要信息。",
            "奇异值": "矩阵奇异值分解后得到的特征值，代表了矩阵在对应特征向量方向上的能量或重要性。"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 422,
        "title": "Learning A Minimax Optimizer: A Pilot Study",
        "html": "https://iclr.cc//virtual/2021/poster/2542",
        "abstract": "Solving continuous minimax optimization is of extensive practical interest, yet notoriously unstable and difficult. This paper introduces the learning to optimize(L2O) methodology to the minimax problems for the first time and addresses its accompanying unique challenges. We first present Twin-L2O, the first dedicated minimax L2O method consisting of two LSTMs for updating min and max variables separately. The decoupled design is found to facilitate learning, particularly when the min and max variables are highly asymmetric. Empirical experiments on a variety of minimax problems corroborate the effectiveness of Twin-L2O. We then discuss a crucial concern of Twin-L2O, i.e., its inevitably limited generalizability to unseen optimizees. To address this issue, we present two complementary strategies. Our first solution, Enhanced Twin-L2O, is empirically applicable for general minimax problems, by improving L2O training via leveraging curriculum learning. Our second alternative, called Safeguarded Twin-L2O, is a preliminary theoretical exploration stating that under some strong assumptions, it is possible to theoretically establish the convergence of Twin-L2O. We benchmark our algorithms on several testbed problems and compare against state-of-the-art minimax solvers. The code is available at:  https://github.com/VITA-Group/L2O-Minimax.",
        "conference": "ICLR",
        "中文标题": "学习极小极大优化器：一项初步研究",
        "摘要翻译": "解决连续极小极大优化问题具有广泛的实用价值，但因其极其不稳定和困难而闻名。本文首次将学习优化（L2O）方法引入极小极大问题，并解决了伴随而来的独特挑战。我们首先提出了Twin-L2O，这是首个专门用于极小极大问题的L2O方法，由两个LSTM组成，分别用于更新最小和最大变量。研究发现，解耦设计有助于学习，特别是当最小和最大变量高度不对称时。在各种极小极大问题上的实证实验证实了Twin-L2O的有效性。然后，我们讨论了Twin-L2O的一个关键问题，即其对未见优化问题的有限泛化能力。为了解决这个问题，我们提出了两种互补的策略。我们的第一个解决方案，增强型Twin-L2O，通过利用课程学习改进L2O训练，适用于一般的极小极大问题。我们的第二个替代方案，称为保护型Twin-L2O，是一项初步的理论探索，表明在某些强假设下，理论上可以建立Twin-L2O的收敛性。我们在几个测试问题上对我们的算法进行了基准测试，并与最先进的极小极大求解器进行了比较。代码可在https://github.com/VITA-Group/L2O-Minimax获取。",
        "领域": "优化算法、深度学习、连续优化",
        "问题": "解决连续极小极大优化问题的不稳定性和困难",
        "动机": "探索学习优化方法在极小极大问题中的应用，解决其特有的挑战",
        "方法": "提出Twin-L2O方法，使用两个LSTM分别更新最小和最大变量，并通过增强型和保护型策略提高泛化能力和理论保证",
        "关键词": [
            "极小极大优化",
            "学习优化",
            "LSTM",
            "课程学习",
            "收敛性理论"
        ],
        "涉及的技术概念": {
            "Twin-L2O": "专门用于极小极大问题的L2O方法，由两个LSTM组成，分别更新最小和最大变量",
            "课程学习": "用于改进L2O训练的策略，通过逐步增加难度来提高模型的泛化能力",
            "收敛性理论": "在特定假设下，理论上证明Twin-L2O方法的收敛性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 423,
        "title": "Learning and Evaluating Representations for Deep One-Class Classification",
        "html": "https://iclr.cc//virtual/2021/poster/3244",
        "abstract": "We present a two-stage framework for deep one-class classification. We first learn self-supervised  representations from one-class data, and then build one-class classifiers on learned representations. The framework not only allows to learn better representations, but also permits building one-class classifiers that are faithful to the target task. We argue that classifiers inspired by the statistical perspective in generative or discriminative models are more effective than existing approaches, such as a normality score from a surrogate classifier. We thoroughly evaluate different self-supervised representation learning algorithms under the proposed framework for one-class classification. Moreover, we present a novel distribution-augmented contrastive learning that extends training distributions via data augmentation to obstruct the uniformity of contrastive representations. In experiments, we demonstrate state-of-the-art performance on visual domain one-class classification benchmarks, including novelty and anomaly detection. Finally, we present visual explanations, confirming that the decision-making process of deep one-class classifiers is intuitive to humans. The code is available at https://github.com/google-research/deep_representation_one_class.\n",
        "conference": "ICLR",
        "中文标题": "深度一类分类的表示学习与评估",
        "摘要翻译": "我们提出了一个两阶段的深度一类分类框架。首先，我们从一类数据中学习自监督表示，然后在学习到的表示上构建一类分类器。该框架不仅能够学习到更好的表示，还能够构建忠实于目标任务的一类分类器。我们认为，受到生成或判别模型中统计视角启发的分类器比现有方法（如来自替代分类器的正态性评分）更有效。我们在提出的框架下彻底评估了不同自监督表示学习算法在一类分类中的应用。此外，我们提出了一种新颖的分布增强对比学习，通过数据增强扩展训练分布，以阻碍对比表示的统一性。在实验中，我们在视觉领域的一类分类基准测试中展示了最先进的性能，包括新颖性和异常检测。最后，我们提供了视觉解释，确认深度一类分类器的决策过程对人类来说是直观的。代码可在https://github.com/google-research/deep_representation_one_class获取。",
        "领域": "异常检测、一类分类、自监督学习",
        "问题": "如何在一类分类任务中学习更有效的表示并构建更忠实的分类器",
        "动机": "现有的一类分类方法（如正态性评分）可能不如基于统计视角的生成或判别模型有效，因此需要开发更有效的表示学习和分类器构建方法",
        "方法": "提出两阶段框架：首先通过自监督学习从一类数据中学习表示，然后基于这些表示构建一类分类器；引入分布增强对比学习以提升表示质量",
        "关键词": [
            "一类分类",
            "自监督学习",
            "对比学习",
            "异常检测",
            "表示学习"
        ],
        "涉及的技术概念": {
            "自监督表示学习": "从一类数据中学习表示，无需外部标签，为后续分类器构建提供基础",
            "分布增强对比学习": "通过数据增强扩展训练分布，防止对比学习中的表示过于统一，提升表示质量",
            "一类分类器": "专门设计用于处理仅有一类样本的分类任务，旨在识别与训练样本显著不同的新样本"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 424,
        "title": "Learning Associative Inference Using Fast Weight Memory",
        "html": "https://iclr.cc//virtual/2021/poster/2988",
        "abstract": "Humans can quickly associate stimuli to solve problems in novel contexts. Our novel neural network model learns state representations of facts that can be composed to perform such associative inference. To this end, we augment the LSTM model with an associative memory, dubbed \\textit{Fast Weight Memory} (FWM). Through differentiable operations at every step of a given input sequence, the LSTM \\textit{updates and maintains} compositional associations stored in the rapidly changing FWM weights. Our model is trained end-to-end by gradient descent and yields excellent performance on compositional language reasoning problems, meta-reinforcement-learning for POMDPs, and small-scale word-level language modelling.",
        "conference": "ICLR",
        "中文标题": "使用快速权重记忆学习关联推理",
        "摘要翻译": "人类能够快速关联刺激以解决新情境中的问题。我们新颖的神经网络模型学习事实的状态表示，这些表示可以被组合以执行此类关联推理。为此，我们为LSTM模型增加了一个称为快速权重记忆（FWM）的关联记忆。通过在给定输入序列的每一步进行可微分操作，LSTM更新并维护存储在快速变化的FWM权重中的组合关联。我们的模型通过梯度下降进行端到端训练，并在组合语言推理问题、POMDPs的元强化学习以及小规模词级语言建模方面表现出色。",
        "领域": "自然语言处理与视觉结合, 元强化学习, 语言建模",
        "问题": "如何快速关联刺激以解决新情境中的问题",
        "动机": "开发一种能够模仿人类快速关联刺激能力的神经网络模型，以解决新情境中的问题",
        "方法": "通过为LSTM模型增加快速权重记忆（FWM），并在输入序列的每一步进行可微分操作，更新和维护组合关联",
        "关键词": [
            "快速权重记忆",
            "关联推理",
            "LSTM",
            "元强化学习",
            "语言建模"
        ],
        "涉及的技术概念": {
            "快速权重记忆（FWM）": "一种关联记忆，用于存储和快速更新组合关联",
            "LSTM": "长短期记忆网络，用于学习序列数据的长期依赖关系",
            "梯度下降": "用于训练模型的优化算法，通过最小化损失函数来调整模型参数"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 425,
        "title": "Learning-based Support Estimation in Sublinear Time",
        "html": "https://iclr.cc//virtual/2021/poster/2622",
        "abstract": "We consider the  problem of estimating the number of distinct elements in a large data set (or, equivalently, the support size of the distribution induced by the data set) from a random sample of its elements. The problem occurs in many applications, including biology, genomics, computer systems and linguistics. A line of research spanning the last decade resulted in algorithms that estimate the support up to $ \\pm \\varepsilon n$ from a sample of size $O(\\log^2(1/\\varepsilon) \\cdot n/\\log n)$, where $n$ is the data set size.  Unfortunately, this bound is known to be tight, limiting further improvements to the complexity of this problem. In this paper we consider estimation algorithms augmented with a machine-learning-based predictor that, given any element, returns an estimation of  its frequency.  We show that if the predictor is correct up to a constant approximation factor, then the sample complexity can be reduced significantly,  to\n$$ \\ \\log (1/\\varepsilon) \\cdot n^{1-\\Theta(1/\\log(1/\\varepsilon))}. $$\nWe evaluate the proposed algorithms on a collection of data sets, using the neural-network based estimators from {Hsu et al, ICLR'19} as predictors. Our experiments  demonstrate substantial (up to 3x) improvements in the estimation accuracy compared to the state of the art algorithm.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "亚线性时间中基于学习的支持度估计",
        "摘要翻译": "我们考虑从大数据集的随机样本中估计不同元素数量（或者等价地，由数据集引起的支持度大小）的问题。 这个问题出现在许多应用中，包括生物学、基因组学、计算机系统和语言学。 过去十年的一系列研究产生了这样的算法：从大小为$O(log^2(1/\\\\varepsilon) \\\\cdot n/log n)$的样本中，将支持度估计到$ \\\\pm \\\\varepsilon n$，其中n是数据集大小。 不幸的是，已知这个界限是紧的，限制了对这个问题复杂性的进一步改进。 在本文中，我们考虑使用基于机器学习的预测器增强的估计算法，该预测器在给定任何元素时，返回对其频率的估计。 我们表明，如果预测器在恒定近似因子内是正确的，那么样本复杂度可以显着降低到 $ \\\\log (1/\\\\varepsilon) \\\\cdot n^{1-\\\\Theta(1/log(1/\\\\varepsilon))}$。我们在一系列数据集上评估了所提出的算法，使用来自{Hsu et al, ICLR'19}的基于神经网络的估计器作为预测器。 我们的实验表明，与最先进的算法相比，估计精度有了显着提高（高达3倍）。",
        "领域": "数据挖掘, 算法优化, 机器学习",
        "问题": "在大数据集中，如何高效地估计不同元素的数量（支持度大小），尤其是在亚线性时间内完成估计。",
        "动机": "传统算法在估计大数据集中不同元素数量时存在复杂度瓶颈，难以进一步提升效率。因此，研究动机在于利用机器学习技术来降低样本复杂度，从而显著提高估计效率。",
        "方法": "利用基于机器学习的预测器来估计元素的频率，并结合该预测信息来改进支持度估计算法。具体来说，如果预测器的准确度达到一定的要求，则可以显著降低样本复杂度。",
        "关键词": [
            "支持度估计",
            "亚线性时间",
            "机器学习预测器",
            "样本复杂度",
            "频率估计"
        ],
        "涉及的技术概念": {
            "支持度估计": "估计数据集中不同元素的数量，是数据分析和挖掘中的一个基本问题。",
            "亚线性时间": "算法运行时间低于线性时间，通常意味着算法不需要读取整个输入数据就能得到结果，适用于处理大规模数据集。"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 426,
        "title": "Learning Better Structured Representations Using Low-rank Adaptive Label Smoothing",
        "html": "https://iclr.cc//virtual/2021/poster/3097",
        "abstract": "Training with soft targets instead of hard targets has been shown to improve performance and calibration of deep neural networks. Label smoothing is a popular way of computing soft targets, where one-hot encoding of a class is smoothed with a uniform distribution. Owing to its simplicity, label smoothing has found wide-spread use for training deep neural networks on a wide variety of tasks, ranging from image and text classification to machine translation and semantic parsing. Complementing recent empirical justification for label smoothing, we obtain PAC-Bayesian generalization bounds for label smoothing and show that the generalization error depends on the choice of the noise (smoothing) distribution. Then we propose low-rank adaptive label smoothing (LORAS): a simple yet novel method for training with learned soft targets that generalizes label smoothing and adapts to the latent structure of the label space in structured prediction tasks. Specifically, we evaluate our method on semantic parsing tasks and show that training with appropriately smoothed soft targets can significantly improve accuracy and model calibration, especially in low-resource settings. Used in conjunction with pre-trained sequence-to-sequence models, our method achieves state of the art performance on four semantic parsing data sets. LORAS can be used with any model, improves performance and implicit model calibration  without increasing the number of model parameters, and can be scaled to problems with large label spaces containing tens of thousands of labels.",
        "conference": "ICLR",
        "中文标题": "学习更好的结构化表示：使用低秩自适应标签平滑",
        "摘要翻译": "使用软目标而非硬目标进行训练已被证明可以提高深度神经网络的性能和校准度。标签平滑是一种计算软目标的流行方法，其中类的独热编码通过均匀分布进行平滑。由于其简单性，标签平滑已被广泛用于训练深度神经网络，涵盖从图像和文本分类到机器翻译和语义解析等多种任务。作为对标签平滑近期实证研究的补充，我们获得了标签平滑的PAC-贝叶斯泛化界限，并表明泛化误差取决于噪声（平滑）分布的选择。然后，我们提出了低秩自适应标签平滑（LORAS）：一种简单而新颖的方法，用于通过学习的软目标进行训练，该方法推广了标签平滑并适应于结构化预测任务中标签空间的潜在结构。具体来说，我们在语义解析任务上评估了我们的方法，并表明使用适当平滑的软目标进行训练可以显著提高准确性和模型校准度，特别是在资源匮乏的情况下。与预训练的序列到序列模型结合使用时，我们的方法在四个语义解析数据集上实现了最先进的性能。LORAS可以与任何模型一起使用，提高性能和隐式模型校准，而不增加模型参数的数量，并且可以扩展到包含数万个标签的大标签空间问题。",
        "领域": "语义解析、模型校准、结构化预测",
        "问题": "如何通过改进标签平滑方法来提高深度神经网络在结构化预测任务中的性能和校准度",
        "动机": "探索标签平滑方法的理论基础，并提出一种能够适应标签空间潜在结构的改进方法，以提高模型在结构化预测任务中的表现",
        "方法": "提出低秩自适应标签平滑（LORAS）方法，该方法通过学习软目标来推广标签平滑，并适应标签空间的潜在结构",
        "关键词": [
            "标签平滑",
            "低秩自适应",
            "语义解析",
            "模型校准",
            "结构化预测"
        ],
        "涉及的技术概念": {
            "标签平滑": "一种通过均匀分布平滑独热编码来计算软目标的技术，用于提高模型的性能和校准度",
            "低秩自适应标签平滑（LORAS）": "一种改进的标签平滑方法，通过学习软目标并适应标签空间的潜在结构，以提高结构化预测任务的性能",
            "PAC-贝叶斯泛化界限": "用于分析标签平滑方法泛化能力的理论框架，表明泛化误差与噪声分布的选择有关"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 427,
        "title": "Learning continuous-time PDEs from sparse data with graph neural networks",
        "html": "https://iclr.cc//virtual/2021/poster/3028",
        "abstract": "The behavior of many dynamical systems follow complex, yet still unknown partial differential equations (PDEs). While several machine learning methods have been proposed to learn PDEs directly from data, previous methods are limited to discrete-time approximations or make the limiting assumption of the observations arriving at regular grids. We propose a general continuous-time differential model for dynamical systems whose governing equations are parameterized by message passing graph neural networks. The model admits arbitrary space and time discretizations, which removes constraints on the locations of observation points and time intervals between the observations. The model is trained with continuous-time adjoint method enabling efficient neural PDE inference. We demonstrate the model's ability to work with unstructured grids, arbitrary time steps, and noisy observations. We compare our method with existing approaches on several well-known physical systems that involve first and higher-order PDEs with state-of-the-art predictive performance.",
        "conference": "ICLR",
        "中文标题": "利用图神经网络从稀疏数据中学习连续时间偏微分方程",
        "摘要翻译": "许多动力系统的行为遵循复杂但尚未知的偏微分方程（PDEs）。虽然已经提出了几种机器学习方法直接从数据中学习PDEs，但先前的方法仅限于离散时间近似或做出观测点位于规则网格上的限制性假设。我们提出了一个通用的连续时间微分模型，用于动力系统，其控制方程由消息传递图神经网络参数化。该模型允许任意的空间和时间离散化，从而消除了对观测点位置和观测间时间间隔的限制。该模型通过连续时间伴随方法进行训练，实现了高效的神经PDE推理。我们展示了该模型在处理非结构化网格、任意时间步长和噪声观测方面的能力。我们在几个涉及一阶和高阶PDEs的著名物理系统上，与现有方法进行了比较，展示了最先进的预测性能。",
        "领域": "偏微分方程学习、图神经网络、动力系统建模",
        "问题": "如何从稀疏且不规则的数据中学习连续时间偏微分方程",
        "动机": "克服现有方法在离散时间近似和规则网格观测上的限制，提供更灵活和通用的PDE学习框架",
        "方法": "提出了一种基于消息传递图神经网络的连续时间微分模型，采用连续时间伴随方法进行训练",
        "关键词": [
            "连续时间PDEs",
            "图神经网络",
            "稀疏数据",
            "非结构化网格",
            "伴随方法"
        ],
        "涉及的技术概念": {
            "消息传递图神经网络": "用于参数化动力系统的控制方程，允许模型处理非结构化数据",
            "连续时间伴随方法": "用于高效训练模型，优化神经PDE推理过程",
            "非结构化网格": "模型能够处理的数据类型之一，展示了模型在任意空间离散化下的灵活性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 428,
        "title": "Learning Cross-Domain Correspondence for Control with Dynamics Cycle-Consistency",
        "html": "https://iclr.cc//virtual/2021/poster/2817",
        "abstract": "At the heart of many robotics problems is the challenge of learning correspondences across domains. For instance, imitation learning requires obtaining correspondence between humans and robots; sim-to-real requires correspondence between physics simulators and real hardware; transfer learning requires correspondences between different robot environments. In this paper, we propose to learn correspondence across such domains emphasizing on differing modalities (vision and internal state), physics parameters (mass and friction), and morphologies (number of limbs). Importantly, correspondences are learned using unpaired and randomly collected data from the two domains. We propose dynamics cycles that align dynamic robotic behavior across two domains using a cycle consistency constraint. Once this correspondence is found, we can directly transfer the policy trained on one domain to the other, without needing any additional fine-tuning on the second domain. We perform experiments across a variety of problem domains, both in simulation and on real robots. Our framework is able to align uncalibrated monocular video of a real robot arm to dynamic state-action trajectories of a simulated arm without paired data. Video demonstrations of our results are available at: https://sites.google.com/view/cycledynamics .",
        "conference": "ICLR",
        "中文标题": "学习跨域对应关系以实现动态周期一致性的控制",
        "摘要翻译": "许多机器人问题的核心在于学习跨域对应关系的挑战。例如，模仿学习需要获取人类与机器人之间的对应关系；仿真到现实需要物理模拟器与真实硬件之间的对应关系；迁移学习则需要不同机器人环境之间的对应关系。在本文中，我们提出学习跨域对应关系，重点关注不同的模态（视觉和内部状态）、物理参数（质量和摩擦）以及形态（肢体数量）。重要的是，这些对应关系是利用两个域中未配对和随机收集的数据学习的。我们提出了动态周期，利用周期一致性约束来对齐两个域之间的动态机器人行为。一旦找到这种对应关系，我们就可以直接将在一个域上训练的策略转移到另一个域，而无需在第二个域上进行任何额外的微调。我们在仿真和真实机器人上进行了各种问题域的实验。我们的框架能够将真实机器人手臂的未校准单目视频与模拟手臂的动态状态-动作轨迹对齐，而无需配对数据。我们的结果视频演示可在以下网址查看：https://sites.google.com/view/cycledynamics。",
        "领域": "机器人学习、跨域迁移、模仿学习",
        "问题": "学习跨域对应关系以实现策略的直接迁移，无需额外微调",
        "动机": "解决机器人学习中的跨域对应问题，如模仿学习、仿真到现实和迁移学习中的对应关系建立",
        "方法": "提出动态周期方法，利用周期一致性约束对齐不同域之间的动态行为，实现策略的直接迁移",
        "关键词": [
            "跨域对应",
            "动态周期一致性",
            "策略迁移",
            "模仿学习",
            "仿真到现实"
        ],
        "涉及的技术概念": {
            "动态周期一致性": "利用周期一致性约束对齐两个域之间的动态机器人行为，确保策略的有效迁移",
            "未配对数据学习": "使用两个域中未配对和随机收集的数据学习对应关系，提高方法的适用性",
            "策略直接迁移": "在找到对应关系后，无需额外微调即可将策略从一个域迁移到另一个域，简化了迁移学习过程"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 429,
        "title": "Learning Deep Features in Instrumental Variable Regression",
        "html": "https://iclr.cc//virtual/2021/poster/2995",
        "abstract": "Instrumental variable (IV) regression is a standard strategy for learning causal relationships between confounded treatment and outcome variables from observational data by using an instrumental variable, which affects the outcome only through the treatment. In classical IV regression, learning proceeds in two stages: stage 1 performs linear regression from the instrument to the treatment; and stage 2 performs linear regression from the treatment to the outcome, conditioned on the instrument. We propose a novel method, deep feature instrumental variable regression (DFIV), to address the case where relations between instruments, treatments, and outcomes may be nonlinear. In this case, deep neural nets are trained to define informative nonlinear features on the instruments and treatments. We propose an alternating training regime for these features to ensure good end-to-end performance when composing stages 1 and 2, thus obtaining highly flexible feature maps in a computationally efficient manner.\nDFIV outperforms recent state-of-the-art methods on challenging IV benchmarks, including settings involving high dimensional image data. DFIV also exhibits competitive performance in off-policy policy evaluation for reinforcement learning, which can be understood as an IV regression task.",
        "conference": "ICLR",
        "中文标题": "学习工具变量回归中的深度特征",
        "摘要翻译": "工具变量（IV）回归是一种标准策略，用于通过使用仅通过治疗影响结果的工具变量，从观察数据中学习混淆治疗和结果变量之间的因果关系。在经典的工具变量回归中，学习分为两个阶段进行：第一阶段执行从工具到治疗的线性回归；第二阶段执行从治疗到结果的线性回归，以工具为条件。我们提出了一种新方法，深度特征工具变量回归（DFIV），以解决工具、治疗和结果之间关系可能为非线性的情况。在这种情况下，深度神经网络被训练来定义工具和治疗上的信息非线性特征。我们提出了这些特征的交替训练方案，以确保在组合第一阶段和第二阶段时具有良好的端到端性能，从而以计算高效的方式获得高度灵活的特征映射。DFIV在具有挑战性的IV基准测试中优于最近的最先进方法，包括涉及高维图像数据的设置。DFIV在强化学习的离策略策略评估中也表现出竞争性能，这可以被理解为一个IV回归任务。",
        "领域": "因果推断、强化学习、非线性回归",
        "问题": "解决工具变量回归中工具、治疗和结果之间可能存在非线性关系的问题",
        "动机": "为了在非线性关系存在的情况下，更有效地从观察数据中学习因果关系",
        "方法": "提出深度特征工具变量回归（DFIV）方法，通过训练深度神经网络定义非线性特征，并采用交替训练方案优化特征映射",
        "关键词": [
            "工具变量回归",
            "深度特征",
            "非线性关系",
            "强化学习",
            "因果推断"
        ],
        "涉及的技术概念": {
            "工具变量回归": "一种用于从观察数据中学习因果关系的方法，通过使用仅通过治疗影响结果的工具变量",
            "深度特征": "通过深度神经网络训练得到的非线性特征，用于捕捉工具和治疗之间的复杂关系",
            "交替训练方案": "一种训练策略，用于优化深度神经网络的特征映射，确保端到端性能"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 430,
        "title": "Learning Energy-Based Generative Models via Coarse-to-Fine Expanding and Sampling",
        "html": "https://iclr.cc//virtual/2021/poster/2704",
        "abstract": "Energy-based models (EBMs) parametrized by neural networks can be trained by Markov chain Monte Carlo (MCMC) sampling-based maximum likelihood estimation. Despite the recent significant success of EBMs in data generation, the current approaches to train EBMs can be unstable and sometimes may have difficulty synthesizing diverse and high-fidelity images. In this paper, we propose to train EBMs via a multistage coarse-to-fine expanding and sampling strategy, namely CF-EBM. To improve the learning procedure, we propose an effective net architecture and advocate applying smooth activations. The resulting approach is computationally efficient and achieves the best performance on image generation amongst EBMs and the spectral normalization GAN. Furthermore, we provide a recipe for being the first successful EBM to synthesize $512\\times512$-pixel images and also improve out-of-distribution detection. In the end, we effortlessly generalize CF-EBM to the one-sided unsupervised image-to-image translation and beat baseline methods with the model size and the training budget largely reduced. In parallel, we present a gradient-based discriminative saliency method to interpret the translation dynamics which align with human behavior explicitly.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "通过从粗到细的扩展与采样学习基于能量的生成模型",
        "摘要翻译": "基于神经网络参数化的能量模型（EBMs）可以通过基于马尔可夫链蒙特卡洛（MCMC）采样的最大似然估计进行训练。尽管EBMs在数据生成方面最近取得了显著成功，但当前训练EBMs的方法可能不稳定，有时可能难以合成多样化和高保真度的图像。在本文中，我们提出通过多阶段从粗到细的扩展与采样策略（即CF-EBM）来训练EBMs。为了改进学习过程，我们提出了一个有效的网络架构，并提倡应用平滑激活函数。所得到的方法计算效率高，并在图像生成方面达到了EBMs和谱归一化GAN中的最佳性能。此外，我们提供了一个配方，成为第一个成功合成512×512像素图像的EBM，并改进了分布外检测。最后，我们轻松地将CF-EBM推广到单侧无监督图像到图像翻译，并在模型大小和训练预算大幅减少的情况下击败了基线方法。同时，我们提出了一种基于梯度的判别性显著性方法来解释翻译动态，这些动态与人类行为明确对齐。",
        "领域": "图像生成",
        "问题": "当前训练基于能量的模型（EBMs）的方法不稳定，难以合成多样化和高保真度的图像",
        "动机": "改进EBMs的训练过程，提高图像生成的多样性和保真度",
        "方法": "提出多阶段从粗到细的扩展与采样策略（CF-EBM），包括有效的网络架构和平滑激活函数的应用",
        "关键词": [
            "基于能量的模型",
            "图像生成",
            "从粗到细采样",
            "无监督图像翻译",
            "判别性显著性方法"
        ],
        "涉及的技术概念": {
            "能量模型（EBMs）": "一种生成模型，通过能量函数定义数据的概率分布，用于数据生成",
            "马尔可夫链蒙特卡洛（MCMC）采样": "一种用于从复杂概率分布中采样的技术，用于训练EBMs",
            "谱归一化GAN": "一种生成对抗网络（GAN）的变体，通过谱归一化稳定训练过程"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 431,
        "title": "Learning Energy-Based Models by Diffusion Recovery Likelihood",
        "html": "https://iclr.cc//virtual/2021/poster/3238",
        "abstract": "While energy-based models (EBMs) exhibit a number of desirable properties, training and sampling on high-dimensional datasets remains challenging. Inspired by recent progress on diffusion probabilistic models, we present a diffusion recovery likelihood method to tractably learn and sample from a sequence of EBMs trained on increasingly noisy versions of a dataset. Each EBM is trained with recovery likelihood,  which maximizes the conditional probability of the data at a certain noise level given their noisy versions at a higher noise level. Optimizing recovery likelihood is more tractable than marginal likelihood, as sampling from the conditional distributions is much easier than sampling from the marginal distributions. After training, synthesized images can be generated by the sampling process that initializes from Gaussian white noise distribution and progressively samples the conditional distributions at decreasingly lower noise levels.  Our method generates high fidelity samples on various image datasets. On unconditional CIFAR-10 our method achieves FID 9.58 and inception score 8.30, superior to the majority of GANs. Moreover, we demonstrate that unlike previous work on EBMs, our long-run MCMC samples from the conditional distributions do not diverge and still represent realistic images, allowing us to accurately estimate the normalized density of data even for high-dimensional datasets. Our implementation is available at \\url{https://github.com/ruiqigao/recovery_likelihood}.\n",
        "conference": "ICLR",
        "中文标题": "通过扩散恢复似然学习能量基模型",
        "摘要翻译": "尽管能量基模型（EBMs）展现了一系列理想的特性，但在高维数据集上的训练和采样仍然具有挑战性。受到扩散概率模型最新进展的启发，我们提出了一种扩散恢复似然方法，能够从一系列在数据集的逐渐噪声化版本上训练的EBMs中进行可追踪的学习和采样。每个EBM都通过恢复似然进行训练，这最大化了一定噪声水平下数据给定更高噪声水平下其噪声版本的条件概率。优化恢复似然比边际似然更易于处理，因为从条件分布中采样比从边际分布中采样要容易得多。训练后，可以通过从高斯白噪声分布初始化并逐步在逐渐降低的噪声水平下采样条件分布的采样过程来生成合成图像。我们的方法在各种图像数据集上生成了高保真度的样本。在无条件CIFAR-10上，我们的方法实现了FID 9.58和初始分数8.30，优于大多数GANs。此外，我们证明，与之前关于EBMs的工作不同，我们从条件分布中获得的长运行MCMC样本不会发散，并且仍然代表真实的图像，这使得我们能够准确估计即使是高维数据集的数据的归一化密度。我们的实现可在https://github.com/ruiqigao/recovery_likelihood获取。",
        "领域": "生成模型, 图像合成, 概率模型",
        "问题": "在高维数据集上训练和采样能量基模型的挑战",
        "动机": "解决能量基模型在高维数据上训练和采样的困难，提高样本生成的质量和效率",
        "方法": "提出扩散恢复似然方法，通过在一系列逐渐噪声化的数据集版本上训练EBMs，并利用恢复似然优化条件概率",
        "关键词": [
            "能量基模型",
            "扩散恢复似然",
            "高维数据",
            "图像合成",
            "MCMC采样"
        ],
        "涉及的技术概念": {
            "能量基模型": "一种通过能量函数定义的概率模型，用于数据建模和生成",
            "扩散恢复似然": "一种优化方法，通过最大化给定更高噪声水平下数据的条件概率来训练模型",
            "MCMC采样": "马尔可夫链蒙特卡罗方法，用于从概率分布中采样，本研究中用于生成图像样本和估计数据密度"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 432,
        "title": "Learning explanations that are hard to vary",
        "html": "https://iclr.cc//virtual/2021/poster/2721",
        "abstract": "In this paper, we investigate the principle that good explanations are hard to vary in the context of deep learning.\nWe show that averaging gradients across examples -- akin to a logical OR of patterns -- can favor memorization and `patchwork' solutions that sew together different strategies, instead of identifying invariances.\nTo inspect this, we first formalize a notion of consistency for minima of the loss surface, which measures to what extent a minimum appears only when examples are pooled.\nWe then propose and experimentally validate a simple alternative algorithm based on a logical AND, that focuses on invariances and prevents memorization in a set of real-world tasks. \nFinally, using a synthetic dataset with a clear distinction between invariant and spurious mechanisms, we dissect learning signals and compare this approach to well-established regularizers.",
        "conference": "ICLR",
        "中文标题": "学习难以变化的解释",
        "摘要翻译": "在本文中，我们研究了在深度学习背景下，好的解释难以变化的原则。我们展示了跨示例平均梯度——类似于模式的逻辑OR——可以倾向于记忆和‘拼凑’解决方案，这些解决方案将不同的策略缝合在一起，而不是识别不变性。为了检查这一点，我们首先形式化了损失表面最小值的一致性概念，这衡量了一个最小值仅在示例被汇集时出现的程度。然后，我们提出并通过实验验证了一个基于逻辑AND的简单替代算法，该算法专注于不变性并在一系列现实世界任务中防止记忆。最后，使用一个清晰区分不变性和虚假机制的合成数据集，我们剖析了学习信号，并将这种方法与已建立的规范化器进行了比较。",
        "领域": "深度学习理论、模型解释性、不变性学习",
        "问题": "深度学习模型中解释的稳定性和不变性问题",
        "动机": "探索深度学习模型中解释的稳定性，避免模型通过记忆和拼凑解决方案来学习，而是识别和利用数据中的不变性。",
        "方法": "提出了一种基于逻辑AND的算法，通过形式化损失表面最小值的一致性概念，专注于识别数据中的不变性，防止记忆。",
        "关键词": [
            "解释稳定性",
            "不变性学习",
            "深度学习理论",
            "模型解释性",
            "梯度平均"
        ],
        "涉及的技术概念": {
            "梯度平均": "在多个示例上平均梯度，类似于逻辑OR操作，可能导致模型记忆和拼凑解决方案。",
            "损失表面最小值的一致性": "衡量损失函数的最小值在示例汇集时出现的程度，用于评估模型的解释稳定性。",
            "逻辑AND算法": "提出的新算法，专注于识别数据中的不变性，防止模型通过记忆学习。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 433,
        "title": "Learning from Demonstration with Weakly Supervised Disentanglement",
        "html": "https://iclr.cc//virtual/2021/poster/3178",
        "abstract": "Robotic manipulation tasks, such as wiping with a soft sponge, require control from multiple rich sensory modalities. Human-robot interaction, aimed at teach- ing robots, is difficult in this setting as there is potential for mismatch between human and machine comprehension of the rich data streams. We treat the task of interpretable learning from demonstration as an optimisation problem over a probabilistic generative model. To account for the high-dimensionality of the data, a high-capacity neural network is chosen to represent the model. The latent variables in this model are explicitly aligned with high-level notions and concepts that are manifested in a set of demonstrations. We show that such alignment is best achieved through the use of labels from the end user, in an appropriately restricted vocabulary, in contrast to the conventional approach of the designer picking a prior over the latent variables. Our approach is evaluated in the context of two table-top robot manipulation tasks performed by a PR2 robot – that of dabbing liquids with a sponge (forcefully pressing a sponge and moving it along a surface) and pouring between different containers. The robot provides visual information, arm joint positions and arm joint efforts. We have made videos of the tasks and data available - see supplementary materials at: https://sites.google.com/view/weak-label-lfd.",
        "conference": "ICLR",
        "中文标题": "从演示中学习：基于弱监督解缠的方法",
        "摘要翻译": "机器人操作任务，如使用软海绵擦拭，需要从多种丰富的感官模态中进行控制。旨在教导机器人的人机交互在这一背景下显得尤为困难，因为人类和机器对丰富数据流的理解可能存在不匹配。我们将可解释的从演示中学习任务视为概率生成模型上的优化问题。为了处理数据的高维度，我们选择了一个高容量的神经网络来表示模型。该模型中的潜在变量与演示中表现出的高级概念和观念明确对齐。我们表明，与设计师选择潜在变量先验的传统方法相比，通过使用来自最终用户的标签（在适当限制的词汇表中）可以最好地实现这种对齐。我们的方法在两个由PR2机器人执行的桌面机器人操作任务中进行了评估——用海绵蘸取液体（用力按压海绵并沿表面移动）和在不同容器之间倒液体。机器人提供了视觉信息、手臂关节位置和手臂关节努力。我们已经制作了任务和数据的视频——参见补充材料：https://sites.google.com/view/weak-label-lfd。",
        "领域": "机器人操作学习、人机交互、概率生成模型",
        "问题": "解决在丰富感官模态下，人机交互中人类和机器对数据流理解不匹配的问题，以及如何从演示中学习可解释的机器人操作任务。",
        "动机": "研究动机是为了提高机器人在复杂操作任务中的学习效率和可解释性，特别是在需要从多种感官模态中理解和执行任务时。",
        "方法": "采用概率生成模型作为优化问题的框架，使用高容量神经网络处理高维数据，并通过最终用户提供的标签实现潜在变量与高级概念的对齐。",
        "关键词": [
            "弱监督学习",
            "概率生成模型",
            "机器人操作",
            "人机交互",
            "解缠表示"
        ],
        "涉及的技术概念": {
            "概率生成模型": "用于从演示中学习可解释的机器人操作任务的框架，通过优化问题实现。",
            "高容量神经网络": "用于处理高维度数据，表示概率生成模型中的复杂关系。",
            "弱监督解缠": "通过最终用户提供的有限标签，实现潜在变量与高级概念的对齐，提高学习的可解释性和效率。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 434,
        "title": "Learning from others' mistakes: Avoiding dataset biases without modeling them",
        "html": "https://iclr.cc//virtual/2021/poster/3089",
        "abstract": "State-of-the-art natural language processing (NLP) models often learn to model dataset biases and surface form correlations instead of features that target the intended underlying task. Previous work has demonstrated effective methods to circumvent these issues when knowledge of the bias is available. We consider cases where the bias issues may not be explicitly identified, and show a method for training models that learn to ignore these problematic correlations. Our approach relies on the observation that models with limited capacity primarily learn to exploit biases in the dataset. We can leverage the errors of such limited capacity models to train a more robust model in a product of experts, thus bypassing the need to hand-craft a biased model. We show the effectiveness of this method to retain improvements in out-of-distribution settings even if no particular bias is targeted by the biased model.",
        "conference": "ICLR",
        "中文标题": "从他人的错误中学习：无需建模即可避免数据集偏差",
        "摘要翻译": "最先进的自然语言处理（NLP）模型常常学习建模数据集偏差和表面形式相关性，而非针对预期底层任务的特征。先前的工作已经展示了在偏差知识可用时规避这些问题的有效方法。我们考虑那些偏差问题可能未被明确识别的情况，并展示了一种训练模型的方法，使其学会忽略这些有问题的相关性。我们的方法基于一个观察：容量有限的模型主要学习利用数据集中的偏差。我们可以利用这些有限容量模型的错误来训练一个更鲁棒的模型，作为专家产品的形式，从而绕过需要手工制作一个有偏差模型的需求。我们展示了这种方法在保留分布外设置中改进效果的有效性，即使有偏差模型没有针对任何特定偏差。",
        "领域": "自然语言处理与视觉结合",
        "问题": "解决NLP模型学习数据集偏差而非任务特征的问题",
        "动机": "在偏差未被明确识别的情况下，训练模型忽略有问题的相关性",
        "方法": "利用有限容量模型的错误训练更鲁棒的模型，作为专家产品的形式",
        "关键词": [
            "数据集偏差",
            "自然语言处理",
            "模型鲁棒性"
        ],
        "涉及的技术概念": {
            "有限容量模型": "容量有限的模型主要学习利用数据集中的偏差",
            "专家产品": "通过结合多个模型的预测来提高整体性能的技术",
            "分布外设置": "模型在训练数据分布之外的数据上的表现"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 435,
        "title": "Learning from Protein Structure with Geometric Vector Perceptrons",
        "html": "https://iclr.cc//virtual/2021/poster/3102",
        "abstract": "Learning on 3D structures of large biomolecules is emerging as a distinct area in machine learning, but there has yet to emerge a unifying network architecture that simultaneously leverages the geometric and relational aspects of the problem domain. To address this gap, we introduce geometric vector perceptrons, which extend standard dense layers to operate on collections of Euclidean vectors. Graph neural networks equipped with such layers are able to perform both geometric and relational reasoning on efficient representations of macromolecules. We demonstrate our approach on two important problems in learning from protein structure: model quality assessment and computational protein design. Our approach improves over existing classes of architectures on both problems, including state-of-the-art convolutional neural networks and graph neural networks. We release our code at https://github.com/drorlab/gvp.",
        "conference": "ICLR",
        "中文标题": "从蛋白质结构中学习：几何向量感知器的应用",
        "摘要翻译": "学习大型生物分子的3D结构正在成为机器学习中的一个独特领域，但目前尚未出现一种能够同时利用问题领域的几何和关系方面的统一网络架构。为了填补这一空白，我们引入了几何向量感知器，它扩展了标准密集层以操作欧几里得向量的集合。配备此类层的图神经网络能够在高效表示的大分子上进行几何和关系推理。我们在两个重要的蛋白质结构学习问题上展示了我们的方法：模型质量评估和计算蛋白质设计。我们的方法在这两个问题上都优于现有类别的架构，包括最先进的卷积神经网络和图神经网络。我们在https://github.com/drorlab/gvp上发布了我们的代码。",
        "领域": "蛋白质结构预测, 计算蛋白质设计, 生物分子3D结构学习",
        "问题": "缺乏能够同时利用生物分子3D结构的几何和关系方面的统一网络架构",
        "动机": "填补在生物分子3D结构学习中同时利用几何和关系方面的网络架构的空白",
        "方法": "引入几何向量感知器扩展标准密集层，以操作欧几里得向量的集合，并结合图神经网络进行几何和关系推理",
        "关键词": [
            "几何向量感知器",
            "图神经网络",
            "蛋白质结构预测",
            "计算蛋白质设计",
            "3D结构学习"
        ],
        "涉及的技术概念": {
            "几何向量感知器": "扩展标准密集层以操作欧几里得向量的集合，用于处理生物分子的3D结构",
            "图神经网络": "用于在高效表示的大分子上进行几何和关系推理",
            "欧几里得向量": "表示生物分子3D结构中的几何信息，是几何向量感知器处理的基本单位"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 436,
        "title": "Learning Generalizable Visual Representations via Interactive Gameplay",
        "html": "https://iclr.cc//virtual/2021/poster/2685",
        "abstract": "A growing body of research suggests that embodied gameplay, prevalent not just in human cultures but across a variety of animal species including turtles and ravens, is critical in developing the neural flexibility for creative problem solving, decision making, and socialization. Comparatively little is known regarding the impact of embodied gameplay upon artificial agents. While recent work has produced agents proficient in abstract games, these environments are far removed the real world and thus these agents can provide little insight into the advantages of embodied play. Hiding games, such as hide-and-seek, played universally, provide a rich ground for studying the impact of embodied gameplay on representation learning in the context of perspective taking, secret keeping, and false belief understanding. Here we are the first to show that embodied adversarial reinforcement learning agents playing Cache, a variant of hide-and-seek, in a high fidelity, interactive, environment, learn generalizable representations of their observations encoding information such as object permanence, free space, and containment. Moving closer to biologically motivated learning strategies, our agents' representations, enhanced by intentionality and memory, are developed through interaction and play. These results serve as a model for studying how facets of vision develop through interaction, provide an experimental framework for assessing what is learned by artificial agents, and demonstrates the value of moving from large, static, datasets towards experiential, interactive, representation learning.",
        "conference": "ICLR",
        "中文标题": "通过互动游戏学习可泛化的视觉表示",
        "摘要翻译": "越来越多的研究表明，不仅人类文化中普遍存在的实体游戏，而且在包括海龟和乌鸦在内的多种动物物种中，对于发展创造性问题解决、决策制定和社会化的神经灵活性至关重要。相比之下，关于实体游戏对人工代理影响的研究知之甚少。尽管最近的工作已经产生了精通抽象游戏的代理，但这些环境与现实世界相去甚远，因此这些代理几乎无法提供关于实体游戏优势的见解。躲藏游戏，如普遍玩耍的捉迷藏，为研究实体游戏在视角采取、秘密保持和错误信念理解背景下对表示学习的影响提供了丰富的土壤。在这里，我们首次展示了在高保真、互动环境中玩Cache（捉迷藏的一种变体）的实体对抗性强化学习代理，学习了其观察的可泛化表示，编码了诸如物体永久性、自由空间和包含性等信息。更接近生物学动机的学习策略，我们的代理的表示，通过意图和记忆增强，是通过互动和游戏发展起来的。这些结果作为研究视觉方面如何通过互动发展的模型，提供了一个评估人工代理学习内容的实验框架，并展示了从大型静态数据集向经验性、互动性表示学习转变的价值。",
        "领域": "强化学习与视觉表示学习",
        "问题": "研究实体游戏对人工代理视觉表示学习的影响",
        "动机": "探索实体游戏如何促进人工代理学习可泛化的视觉表示，以更接近生物学习策略",
        "方法": "使用实体对抗性强化学习代理在互动环境中玩Cache游戏，学习可泛化的视觉表示",
        "关键词": [
            "实体游戏",
            "强化学习",
            "视觉表示学习",
            "互动学习",
            "可泛化表示"
        ],
        "涉及的技术概念": {
            "实体对抗性强化学习": "在互动环境中通过对抗性游戏学习，增强代理的视觉表示能力",
            "可泛化视觉表示": "代理通过游戏学习到的能够泛化到新情境的视觉信息编码",
            "互动学习框架": "通过代理与环境的互动，发展出更接近生物学习策略的视觉表示"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 437,
        "title": "Learning Hyperbolic Representations of Topological Features",
        "html": "https://iclr.cc//virtual/2021/poster/3113",
        "abstract": "Learning task-specific representations of persistence diagrams is an important problem in topological data analysis and machine learning. However, current state of the art methods are restricted in terms of their expressivity as they are focused on Euclidean representations. Persistence diagrams often contain features of infinite persistence (i.e., essential features) and Euclidean spaces shrink their importance relative to non-essential features because they cannot assign infinite distance to finite points. To deal with this issue, we propose a method to learn representations of persistence diagrams on hyperbolic spaces, more specifically on the Poincare ball. By representing features of infinite persistence infinitesimally close to the boundary of the ball, their distance to non-essential features approaches infinity, thereby their relative importance is preserved. This is achieved without utilizing extremely high values for the learnable parameters, thus the representation can be fed into downstream optimization methods and trained efficiently in an end-to-end fashion. We present experimental results on graph and image classification tasks and show that the performance of our method is on par with or exceeds the performance of other state of the art methods.\n",
        "conference": "ICLR",
        "中文标题": "学习拓扑特征的超几何表示",
        "摘要翻译": "学习持久性图的任务特定表示是拓扑数据分析和机器学习中的一个重要问题。然而，当前最先进的方法在表达能力上受到限制，因为它们主要集中在欧几里得表示上。持久性图通常包含无限持久性的特征（即本质特征），而欧几里得空间会缩小这些特征相对于非本质特征的重要性，因为它们无法为有限点分配无限距离。为了解决这个问题，我们提出了一种在超几何空间，更具体地说是在庞加莱球上学习持久性图表示的方法。通过将无限持久性的特征表示为接近球边界无限小的点，它们与非本质特征的距离接近无限，从而保持了它们的相对重要性。这不需要为可学习参数使用极高的值，因此表示可以被输入到下游优化方法中，并以端到端的方式高效训练。我们在图和图像分类任务上展示了实验结果，并表明我们的方法的性能与其他最先进方法的性能相当或更好。",
        "领域": "拓扑数据分析、图分类、图像分类",
        "问题": "解决持久性图中无限持久性特征在欧几里得表示中重要性被缩小的问题",
        "动机": "为了保持持久性图中无限持久性特征相对于非本质特征的重要性，提出在超几何空间学习表示的方法",
        "方法": "在庞加莱球上学习持久性图的表示，通过将无限持久性特征表示为接近球边界无限小的点，保持其与非本质特征的无限距离",
        "关键词": [
            "持久性图",
            "超几何空间",
            "庞加莱球",
            "图分类",
            "图像分类"
        ],
        "涉及的技术概念": {
            "持久性图": "用于表示拓扑数据分析中特征的持久性，是论文研究的核心对象",
            "超几何空间": "论文中用于学习持久性图表示的空间，能够更好地表示无限持久性特征",
            "庞加莱球": "超几何空间的一种具体实现，用于在有限区域内表示无限距离的特征"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 438,
        "title": "Learning Incompressible Fluid Dynamics from Scratch - Towards Fast, Differentiable Fluid Models that Generalize",
        "html": "https://iclr.cc//virtual/2021/poster/3004",
        "abstract": "Fast and stable fluid simulations are an essential prerequisite for applications ranging from computer-generated imagery to computer-aided design in research and development. However, solving the partial differential equations of incompressible fluids is a challenging task and traditional numerical approximation schemes come at high computational costs. Recent deep learning based approaches promise vast speed-ups but do not generalize to new fluid domains, require fluid simulation data for training, or rely on complex pipelines that outsource major parts of the fluid simulation to traditional methods.\n\nIn this work, we propose a novel physics-constrained training approach that generalizes to new fluid domains, requires no fluid simulation data, and allows convolutional neural networks to map a fluid state from time-point t to a subsequent state at time t+dt in a single forward pass. This simplifies the pipeline to train and evaluate neural fluid models. After training, the framework yields models that are capable of fast fluid simulations and can handle various fluid phenomena including the Magnus effect and Kármán vortex streets. We present an interactive real-time demo to show the speed and generalization capabilities of our trained models. Moreover, the trained neural networks are efficient differentiable fluid solvers as they offer a differentiable update step to advance the fluid simulation in time. We exploit this fact in a proof-of-concept optimal control experiment. Our models significantly outperform a recent differentiable fluid solver in terms of computational speed and accuracy.",
        "conference": "ICLR",
        "中文标题": "从零开始学习不可压缩流体动力学——迈向快速、可微分且具有泛化能力的流体模型",
        "摘要翻译": "快速且稳定的流体模拟是从计算机生成图像到研发中的计算机辅助设计等应用的基本前提。然而，解决不可压缩流体的偏微分方程是一项具有挑战性的任务，传统的数值近似方案计算成本高昂。最近基于深度学习的方法承诺大幅提速，但无法泛化到新的流体领域，需要流体模拟数据进行训练，或依赖于将流体模拟的主要部分外包给传统方法的复杂流程。在这项工作中，我们提出了一种新颖的物理约束训练方法，该方法能够泛化到新的流体领域，不需要流体模拟数据，并允许卷积神经网络在单次前向传递中将流体状态从时间点t映射到后续时间点t+dt的状态。这简化了训练和评估神经流体模型的流程。训练后，该框架产生的模型能够进行快速流体模拟，并能处理包括马格努斯效应和卡门涡街在内的各种流体现象。我们展示了一个交互式实时演示，以展示我们训练模型的速度和泛化能力。此外，训练好的神经网络是高效的可微分流体求解器，因为它们提供了一个可微分的更新步骤来推进流体模拟。我们在概念验证的最优控制实验中利用了这一事实。我们的模型在计算速度和准确性方面显著优于最近的可微分流体求解器。",
        "领域": "流体模拟、深度学习应用、计算机辅助设计",
        "问题": "解决传统流体模拟方法计算成本高、泛化能力差的问题",
        "动机": "开发一种能够快速、准确模拟流体行为且具有良好泛化能力的模型，以支持广泛的应用场景",
        "方法": "提出一种物理约束的训练方法，使用卷积神经网络直接从流体状态预测下一时间点的状态，无需传统流体模拟数据",
        "关键词": [
            "流体模拟",
            "深度学习",
            "物理约束训练",
            "可微分求解器",
            "泛化能力"
        ],
        "涉及的技术概念": {
            "物理约束训练": "在训练过程中引入物理定律作为约束，确保模型预测符合物理规律",
            "卷积神经网络": "用于直接从流体状态预测下一时间点的状态，实现快速模拟",
            "可微分流体求解器": "提供可微分的更新步骤，支持基于梯度的优化和控制应用"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 439,
        "title": "Learning Invariant Representations for Reinforcement Learning without Reconstruction",
        "html": "https://iclr.cc//virtual/2021/poster/2863",
        "abstract": "We study how representation learning can accelerate reinforcement learning from rich observations, such as images, without relying either on domain knowledge or pixel-reconstruction. Our goal is to learn representations that provide for effective downstream control and invariance to task-irrelevant details. Bisimulation metrics quantify behavioral similarity between states in continuous MDPs, which we propose using to learn robust latent representations which encode only the task-relevant information from observations. Our method trains encoders such that distances in latent space equal bisimulation distances in state space. We demonstrate the effectiveness of our method at disregarding task-irrelevant information using modified visual MuJoCo tasks, where the background is replaced with moving distractors and natural videos, while achieving SOTA performance. We also test a first-person highway driving task where our method learns invariance to clouds, weather, and time of day. Finally, we provide generalization results drawn from properties of bisimulation metrics, and links to causal inference.",
        "conference": "ICLR",
        "中文标题": "无需重构的强化学习不变表示学习",
        "摘要翻译": "我们研究了表示学习如何在不依赖领域知识或像素重构的情况下，从丰富的观察（如图像）中加速强化学习。我们的目标是学习能够为下游控制提供有效支持且对任务无关细节保持不变的表示。双仿真度量量化了连续马尔可夫决策过程中状态之间的行为相似性，我们提出利用它来学习仅编码观察中任务相关信息的鲁棒潜在表示。我们的方法训练编码器，使得潜在空间中的距离等于状态空间中的双仿真距离。我们通过在视觉MuJoCo任务中替换背景为移动干扰物和自然视频，同时达到最先进性能，展示了我们方法在忽略任务无关信息方面的有效性。我们还测试了一个第一人称高速公路驾驶任务，其中我们的方法学习了对云、天气和一天中时间的不变性。最后，我们提供了从双仿真度量的性质中得出的泛化结果，以及与因果推断的联系。",
        "领域": "强化学习、表示学习、视觉控制",
        "问题": "如何在不依赖领域知识或像素重构的情况下，从丰富的观察中学习对任务无关细节不变的表示，以加速强化学习。",
        "动机": "为了加速从丰富观察（如图像）中进行的强化学习，同时减少对领域知识或像素重构的依赖，学习能够忽略任务无关细节的表示。",
        "方法": "利用双仿真度量学习仅编码任务相关信息的鲁棒潜在表示，训练编码器使潜在空间距离等于状态空间的双仿真距离。",
        "关键词": [
            "强化学习",
            "表示学习",
            "双仿真度量",
            "视觉控制",
            "不变性"
        ],
        "涉及的技术概念": {
            "双仿真度量": "用于量化连续马尔可夫决策过程中状态之间的行为相似性，指导学习仅编码任务相关信息的潜在表示。",
            "潜在表示": "通过编码器学习得到的低维表示，旨在捕捉对下游控制有效且对任务无关细节不变的信息。",
            "视觉控制": "应用在视觉输入（如图像）上的控制任务，本研究中通过忽略背景变化等任务无关信息来提高性能。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 440,
        "title": "Learning Long-term Visual Dynamics with Region Proposal Interaction Networks",
        "html": "https://iclr.cc//virtual/2021/poster/2767",
        "abstract": "Learning long-term dynamics models is the key to understanding physical common sense. Most existing approaches on learning dynamics from visual input sidestep long-term predictions by resorting to rapid re-planning with short-term models. This not only requires such models to be super accurate but also limits them only to tasks where an agent can continuously obtain feedback and take action at each step until completion. In this paper, we aim to leverage the ideas from success stories in visual recognition tasks to build object representations that can capture inter-object and object-environment interactions over a long range. To this end, we propose Region Proposal Interaction Networks (RPIN), which reason about each object's trajectory in a latent region-proposal feature space. Thanks to the simple yet effective object representation, our approach outperforms prior methods by a significant margin both in terms of prediction quality and their ability to plan for downstream tasks, and also generalize well to novel environments. Code, pre-trained models, and more visualization results are available at https://haozhi.io/RPIN.",
        "conference": "ICLR",
        "中文标题": "学习长期视觉动态与区域提议交互网络",
        "摘要翻译": "学习长期动态模型是理解物理常识的关键。大多数现有的从视觉输入学习动态的方法通过依赖短期模型进行快速重新规划来回避长期预测。这不仅要求这些模型极其精确，而且将它们限制在那些代理可以持续获得反馈并在每一步采取行动直到完成的任务上。在本文中，我们旨在利用视觉识别任务成功案例中的思想，构建能够捕捉长时间范围内对象间及对象与环境间交互的对象表示。为此，我们提出了区域提议交互网络（RPIN），它在潜在的区域提议特征空间中推理每个对象的轨迹。得益于简单而有效的对象表示，我们的方法在预测质量和为下游任务规划的能力方面均显著优于先前的方法，并且在新环境中也表现出良好的泛化能力。代码、预训练模型及更多可视化结果可在https://haozhi.io/RPIN获取。",
        "领域": "视觉动态预测, 对象交互建模, 长期视觉理解",
        "问题": "如何从视觉输入中学习长期动态模型，以理解和预测对象间及对象与环境的交互。",
        "动机": "现有的视觉动态学习方法主要依赖短期模型和快速重新规划，限制了在需要长期预测和理解的任务中的应用。",
        "方法": "提出区域提议交互网络（RPIN），在潜在的区域提议特征空间中推理每个对象的轨迹，以捕捉长期的对象间及对象与环境间的交互。",
        "关键词": [
            "长期视觉动态",
            "区域提议交互网络",
            "对象交互建模",
            "视觉预测",
            "物理常识理解"
        ],
        "涉及的技术概念": {
            "区域提议交互网络（RPIN）": "一种在潜在的区域提议特征空间中推理对象轨迹的网络结构，用于捕捉长期的对象间及对象与环境间的交互。",
            "长期动态模型": "旨在理解和预测长时间范围内对象及环境变化的模型，关键于物理常识的理解。",
            "对象表示": "在视觉任务中用于表示和推理对象及其交互的方式，本文中通过简单的表示实现了有效的长期预测。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 441,
        "title": "Learning Manifold Patch-Based Representations of Man-Made Shapes",
        "html": "https://iclr.cc//virtual/2021/poster/2959",
        "abstract": "Choosing the right representation for geometry is crucial for making 3D models compatible with existing applications. Focusing on piecewise-smooth man-made shapes, we propose a new representation that is usable in conventional CAD modeling pipelines and can also be learned by deep neural networks. We demonstrate its benefits by applying it to the task of sketch-based modeling. Given a raster image, our system infers a set of parametric surfaces that realize the input in 3D. To capture piecewise smooth geometry, we learn a special shape representation: a deformable parametric template composed of Coons patches. Naively training such a system, however, is hampered by non-manifold artifacts in the parametric shapes and by a lack of data. To address this, we introduce loss functions that bias the network to output non-self-intersecting shapes and implement them as part of a fully self-supervised system, automatically generating both shape templates and synthetic training data. We develop a testbed for sketch-based modeling, demonstrate shape interpolation, and provide comparison to related work.",
        "conference": "ICLR",
        "中文标题": "学习基于流形块的人造形状表示",
        "摘要翻译": "为几何选择正确的表示方法对于使3D模型与现有应用兼容至关重要。针对分段光滑的人造形状，我们提出了一种新的表示方法，该方法既可用于传统的CAD建模流程，也可被深度神经网络学习。我们通过将其应用于基于草图的建模任务来展示其优势。给定一个光栅图像，我们的系统推断出一组参数化曲面，以在3D中实现输入。为了捕捉分段光滑的几何形状，我们学习了一种特殊的形状表示：由Coons块组成的可变形参数化模板。然而，天真地训练这样的系统会受到参数化形状中的非流形伪影和缺乏数据的阻碍。为了解决这个问题，我们引入了损失函数，这些函数偏向于网络输出非自相交的形状，并将它们作为完全自监督系统的一部分实现，自动生成形状模板和合成训练数据。我们开发了一个基于草图的建模测试平台，展示了形状插值，并提供了与相关工作的比较。",
        "领域": "三维重建、深度学习与几何处理、计算机辅助设计",
        "问题": "如何为分段光滑的人造形状开发一种既适用于传统CAD建模流程又能被深度神经网络学习的表示方法。",
        "动机": "为了使3D模型更好地兼容现有应用，并解决在参数化形状中存在的非流形伪影和缺乏数据的问题。",
        "方法": "提出了一种由Coons块组成的可变形参数化模板作为形状表示，引入了偏向于非自相交形状输出的损失函数，并实现了一个完全自监督的系统来自动生成形状模板和合成训练数据。",
        "关键词": [
            "人造形状表示",
            "Coons块",
            "自监督学习",
            "基于草图的建模",
            "参数化曲面"
        ],
        "涉及的技术概念": {
            "Coons块": "用于构建可变形参数化模板的基本单元，能够捕捉分段光滑的几何形状。",
            "自监督学习": "系统自动生成训练数据和形状模板，减少了对大量标注数据的依赖。",
            "非流形伪影": "在参数化形状中出现的几何不一致性问题，通过特定的损失函数来避免。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 442,
        "title": "Learning Mesh-Based Simulation with Graph Networks",
        "html": "https://iclr.cc//virtual/2021/poster/2837",
        "abstract": "Mesh-based simulations are central to modeling complex physical systems in many disciplines across science and engineering. Mesh representations support powerful numerical integration methods and their resolution can be adapted to strike favorable trade-offs between accuracy and efficiency. However, high-dimensional scientific simulations are very expensive to run, and solvers and parameters must often be tuned individually to each system studied.\nHere we introduce MeshGraphNets, a framework for learning mesh-based simulations using graph neural networks. Our model can be trained to pass messages on a mesh graph and to adapt the mesh discretization during forward simulation. Our results show it can accurately predict the dynamics of a wide range of physical systems, including aerodynamics, structural mechanics, and cloth. The model's adaptivity supports learning resolution-independent dynamics and can scale to more complex state spaces at test time. Our method is also highly efficient, running 1-2 orders of magnitude faster than the simulation on which it is trained. Our approach broadens the range of problems on which neural network simulators can operate and promises to improve the efficiency of complex, scientific modeling tasks.",
        "conference": "ICLR",
        "中文标题": "基于图网络的网格模拟学习",
        "摘要翻译": "基于网格的模拟是科学和工程中许多学科建模复杂物理系统的核心。网格表示支持强大的数值积分方法，其分辨率可以调整以在准确性和效率之间取得有利的平衡。然而，高维科学模拟运行成本非常高，求解器和参数通常需要针对每个研究的系统单独调整。我们在此介绍MeshGraphNets，一个使用图神经网络学习基于网格模拟的框架。我们的模型可以训练来在网格图上传递消息，并在前向模拟过程中调整网格离散化。我们的结果表明，它能够准确预测包括空气动力学、结构力学和布料在内的广泛物理系统的动态。该模型的自适应性支持学习分辨率无关的动态，并且可以在测试时扩展到更复杂的状态空间。我们的方法也非常高效，运行速度比训练它的模拟快1-2个数量级。我们的方法拓宽了神经网络模拟器可以操作的问题范围，并有望提高复杂科学建模任务的效率。",
        "领域": "计算物理模拟、图神经网络、科学计算",
        "问题": "高维科学模拟运行成本高，求解器和参数需要针对每个系统单独调整的问题",
        "动机": "提高复杂物理系统模拟的效率和适应性，减少对单独调整求解器和参数的依赖",
        "方法": "使用图神经网络框架MeshGraphNets学习网格上的消息传递和网格离散化调整，以预测物理系统的动态",
        "关键词": [
            "MeshGraphNets",
            "图神经网络",
            "物理系统模拟",
            "网格离散化",
            "科学计算"
        ],
        "涉及的技术概念": {
            "图神经网络": "用于在网格图上传递消息和调整网格离散化，以学习物理系统的动态",
            "网格离散化": "在模拟过程中调整网格的分辨率，以平衡准确性和效率",
            "科学计算": "应用于包括空气动力学、结构力学和布料在内的复杂物理系统模拟"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 443,
        "title": "Learning Neural Event Functions for Ordinary Differential Equations",
        "html": "https://iclr.cc//virtual/2021/poster/2743",
        "abstract": "The existing Neural ODE formulation relies on an explicit knowledge of the termination time. We extend Neural ODEs to implicitly defined termination criteria modeled by neural event functions, which can be chained together and differentiated through. Neural Event ODEs are capable of modeling discrete and instantaneous changes in a continuous-time system, without prior knowledge of when these changes should occur or how many such changes should exist. We test our approach in modeling hybrid discrete- and continuous- systems such as switching dynamical systems and collision in multi-body systems, and we propose simulation-based training of point processes with applications in discrete control.",
        "conference": "ICLR",
        "中文标题": "学习神经事件函数用于常微分方程",
        "摘要翻译": "现有的神经ODE（常微分方程）公式依赖于终止时间的明确知识。我们扩展了神经ODE，使其包含由神经事件函数建模的隐式定义的终止标准，这些函数可以链式连接并通过微分处理。神经事件ODE能够在连续时间系统中建模离散和瞬时变化，而无需预先知道这些变化何时发生或应存在多少此类变化。我们在建模混合离散和连续系统（如切换动力系统和多体系统中的碰撞）中测试了我们的方法，并提出了基于模拟的点过程训练，应用于离散控制中。",
        "领域": "动态系统建模",
        "问题": "扩展神经ODE以处理隐式定义的终止标准和离散瞬时变化",
        "动机": "现有的神经ODE需要明确的终止时间知识，限制了其在需要处理未知时间和数量的离散变化的系统中的应用。",
        "方法": "引入神经事件函数来建模隐式终止标准，支持链式连接和微分处理，无需预先知道变化的时间和数量。",
        "关键词": [
            "神经ODE",
            "神经事件函数",
            "动态系统建模",
            "离散控制",
            "点过程训练"
        ],
        "涉及的技术概念": {
            "神经ODE": "一种使用神经网络来参数化和解决常微分方程的方法，允许通过反向传播进行端到端训练。",
            "神经事件函数": "用于建模隐式终止标准的神经网络，能够识别和处理系统中的离散和瞬时变化。",
            "点过程训练": "一种基于模拟的训练方法，特别适用于处理具有离散事件和连续动态的复杂系统。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 444,
        "title": "Learning Neural Generative Dynamics for Molecular Conformation Generation",
        "html": "https://iclr.cc//virtual/2021/poster/2628",
        "abstract": "We study how to generate molecule conformations (i.e., 3D structures) from a molecular graph. Traditional methods, such as molecular dynamics, sample conformations via computationally expensive simulations. Recently, machine learning methods have shown great potential by training on a large collection of conformation data. Challenges arise from the limited model capacity for capturing complex distributions of conformations and the difficulty in modeling long-range dependencies between atoms. Inspired by the recent progress in deep generative models, in this paper, we propose a novel probabilistic framework to generate valid and diverse conformations given a molecular graph. We propose a method combining the advantages of both flow-based and energy-based models, enjoying: (1) a high model capacity to estimate the multimodal conformation distribution; (2) explicitly capturing the complex long-range dependencies between atoms in the observation space. Extensive experiments demonstrate the superior performance of the proposed method on several benchmarks, including conformation generation and distance modeling tasks, with a significant improvement over existing generative models for molecular conformation sampling.",
        "conference": "ICLR",
        "中文标题": "学习神经生成动力学用于分子构象生成",
        "摘要翻译": "我们研究如何从分子图中生成分子构象（即3D结构）。传统方法，如分子动力学，通过计算昂贵的模拟来采样构象。最近，机器学习方法通过在大量构象数据上训练显示出了巨大的潜力。挑战来自于有限的模型能力以捕捉构象的复杂分布以及建模原子间长程依赖性的困难。受到深度生成模型最新进展的启发，本文中，我们提出了一种新的概率框架，以在给定分子图的情况下生成有效且多样的构象。我们提出了一种结合基于流和基于能量的模型优点的方法，享有：（1）高模型能力以估计多模态构象分布；（2）明确捕捉观察空间中原子间复杂的长程依赖性。大量实验证明了所提方法在几个基准测试上的优越性能，包括构象生成和距离建模任务，相较于现有的分子构象采样生成模型有显著改进。",
        "领域": "分子构象生成、深度学习在化学中的应用、3D结构预测",
        "问题": "如何高效生成分子构象并捕捉其复杂分布及原子间的长程依赖性",
        "动机": "传统分子构象生成方法计算成本高，机器学习方法虽显示出潜力，但在模型能力和长程依赖性建模方面存在挑战",
        "方法": "结合基于流和基于能量的模型的概率框架，以提高模型能力和长程依赖性建模",
        "关键词": [
            "分子构象生成",
            "深度生成模型",
            "基于流的模型",
            "基于能量的模型",
            "长程依赖性"
        ],
        "涉及的技术概念": {
            "基于流的模型": "用于估计多模态构象分布，提高模型能力",
            "基于能量的模型": "用于明确捕捉原子间的长程依赖性",
            "深度生成模型": "作为整个概率框架的基础，用于生成有效且多样的分子构象"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 445,
        "title": "Learning N:M  Fine-grained Structured Sparse Neural Networks From Scratch",
        "html": "https://iclr.cc//virtual/2021/poster/3174",
        "abstract": "Sparsity in Deep Neural Networks (DNNs) has been widely studied to compress and accelerate the models on resource-constrained environments. It can be generally categorized into unstructured fine-grained sparsity that zeroes out multiple individual weights distributed across the neural network, and structured coarse-grained sparsity which prunes blocks of sub-networks of a neural network. Fine-grained sparsity can achieve a high compression ratio but is not hardware friendly and hence receives limited speed gains. On the other hand, coarse-grained sparsity cannot simultaneously achieve both apparent acceleration on modern GPUs and\ndecent performance. In this paper, we are the first to study training from scratch an N:M fine-grained structured sparse network, which can maintain the advantages of both unstructured fine-grained sparsity and structured coarse-grained sparsity simultaneously on specifically designed GPUs. Specifically, a 2 : 4 sparse network could achieve 2× speed-up without performance drop on Nvidia A100 GPUs. Furthermore, we propose a novel and effective ingredient, sparse-refined straight-through estimator (SR-STE), to alleviate the negative influence of the approximated gradients computed by vanilla STE during optimization. We also define a metric, Sparse Architecture Divergence (SAD), to measure the sparse network’s topology change during the training process. Finally, We justify SR-STE’s advantages with SAD and demonstrate the effectiveness of SR-STE by performing\ncomprehensive experiments on various tasks. Anonymous code and model will be at available at https://github.com/anonymous-NM-sparsity/NM-sparsity.",
        "conference": "ICLR",
        "中文标题": "从零开始学习N:M细粒度结构化稀疏神经网络",
        "摘要翻译": "深度神经网络（DNNs）中的稀疏性已被广泛研究，以在资源受限的环境中压缩和加速模型。它通常可以分为非结构化细粒度稀疏性，即零化分布在神经网络中的多个单独权重，以及结构化粗粒度稀疏性，即修剪神经网络的子网络块。细粒度稀疏性可以实现高压缩比，但对硬件不友好，因此速度提升有限。另一方面，粗粒度稀疏性无法在现代GPU上同时实现明显的加速和良好的性能。在本文中，我们首次研究了从零开始训练N:M细粒度结构化稀疏网络，该网络可以在专门设计的GPU上同时保持非结构化细粒度稀疏性和结构化粗粒度稀疏性的优势。具体来说，一个2:4的稀疏网络可以在Nvidia A100 GPU上实现2倍的加速而不会降低性能。此外，我们提出了一种新颖且有效的成分，稀疏精炼直通估计器（SR-STE），以减轻在优化过程中由普通STE计算的近似梯度的负面影响。我们还定义了一个度量标准，稀疏架构差异（SAD），以衡量训练过程中稀疏网络的拓扑变化。最后，我们通过在各种任务上进行全面实验，证明了SR-STE的优势和有效性。匿名代码和模型将在https://github.com/anonymous-NM-sparsity/NM-sparsity上提供。",
        "领域": "模型压缩与加速、稀疏神经网络、GPU优化",
        "问题": "如何在保持神经网络性能的同时，实现高效的模型压缩和加速。",
        "动机": "研究动机是为了解决现有稀疏方法在硬件友好性和性能之间难以平衡的问题，探索一种既能保持高压缩比又能实现明显加速的稀疏神经网络训练方法。",
        "方法": "提出了一种从零开始训练N:M细粒度结构化稀疏网络的方法，并引入了稀疏精炼直通估计器（SR-STE）来优化训练过程，同时定义了稀疏架构差异（SAD）来监控网络拓扑变化。",
        "关键词": [
            "稀疏神经网络",
            "模型压缩",
            "GPU加速",
            "细粒度稀疏性",
            "结构化稀疏性"
        ],
        "涉及的技术概念": {
            "N:M细粒度结构化稀疏网络": "一种新型的稀疏网络结构，旨在同时实现高压缩比和硬件友好的加速。",
            "稀疏精炼直通估计器（SR-STE）": "用于优化过程中减轻近似梯度负面影响的技术，提高训练效率和模型性能。",
            "稀疏架构差异（SAD）": "用于量化训练过程中稀疏网络拓扑变化的度量标准，帮助理解和优化网络结构。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 446,
        "title": "Learning Parametrised Graph Shift Operators",
        "html": "https://iclr.cc//virtual/2021/poster/2932",
        "abstract": "In many domains data is currently represented as graphs and therefore, the graph representation of this data becomes increasingly important in machine learning. Network data is, implicitly or explicitly, always represented using a graph shift operator (GSO) with the most common choices being the adjacency, Laplacian matrices and their normalisations. In this paper, a novel parametrised GSO (PGSO) is proposed, where specific parameter values result in the most commonly used GSOs and message-passing operators in graph neural network (GNN) frameworks. The PGSO is suggested as a replacement of the standard GSOs that are used in state-of-the-art GNN architectures and the optimisation of the PGSO parameters is seamlessly included in the model training. It is proved that the PGSO has real eigenvalues and a set of real eigenvectors independent of the parameter values and spectral bounds on the PGSO are derived. PGSO parameters are shown to adapt to the sparsity of the graph structure in a study on stochastic blockmodel networks, where they are found to automatically replicate the GSO regularisation found in the literature. On several real-world datasets the accuracy of state-of-the-art GNN architectures is improved by the inclusion of the PGSO in both node- and graph-classification tasks. ",
        "conference": "ICLR",
        "中文标题": "学习参数化图移位算子",
        "摘要翻译": "在许多领域，数据目前被表示为图，因此，这种数据的图表示在机器学习中变得越来越重要。网络数据，无论是隐式还是显式，总是使用图移位算子（GSO）来表示，最常见的选择是邻接矩阵、拉普拉斯矩阵及其归一化。本文提出了一种新颖的参数化GSO（PGSO），其中特定的参数值可以产生图神经网络（GNN）框架中最常用的GSO和消息传递算子。PGSO被建议作为最先进GNN架构中使用的标准GSO的替代品，并且PGSO参数的优化被无缝地包括在模型训练中。证明了PGSO具有实特征值和一组与参数值无关的实特征向量，并推导了PGSO的谱界。在对随机块模型网络的研究中，PGSO参数显示出能够适应图结构的稀疏性，在那里它们被发现自动复制了文献中的GSO正则化。在几个真实世界的数据集上，通过在节点和图分类任务中包含PGSO，最先进GNN架构的准确性得到了提高。",
        "领域": "图神经网络、图表示学习、网络数据分析",
        "问题": "如何优化图神经网络中的图移位算子以提高模型性能",
        "动机": "现有的图移位算子在表示网络数据时存在局限性，需要一种更灵活、可优化的参数化图移位算子来提升图神经网络的性能。",
        "方法": "提出了一种参数化图移位算子（PGSO），通过优化其参数来替代传统的图移位算子，并在模型训练中无缝集成参数优化过程。",
        "关键词": [
            "参数化图移位算子",
            "图神经网络",
            "图表示学习",
            "网络数据分析",
            "模型优化"
        ],
        "涉及的技术概念": {
            "参数化图移位算子（PGSO）": "一种新颖的图移位算子，通过参数化来灵活表示图数据，能够适应不同的图结构和任务需求。",
            "图神经网络（GNN）": "一种专门用于处理图结构数据的神经网络，通过消息传递机制在图节点之间传播信息。",
            "谱界": "对图移位算子特征值的界限进行理论分析，确保PGSO的稳定性和性能。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 447,
        "title": "Learning perturbation sets for robust machine learning",
        "html": "https://iclr.cc//virtual/2021/poster/2570",
        "abstract": "Although much progress has been made towards robust deep learning, a significant gap in robustness remains between real-world perturbations and more narrowly defined sets typically studied in adversarial defenses. In this paper, we aim to bridge this gap by learning perturbation sets from data, in order to characterize real-world effects for robust training and evaluation. Specifically, we use a conditional generator that defines the perturbation set over a constrained region of the latent space. We formulate desirable properties that measure the quality of a learned perturbation set, and theoretically prove that a conditional variational autoencoder naturally satisfies these criteria. Using this framework, our approach can generate a variety of perturbations at different complexities and scales, ranging from baseline spatial transformations, through common image corruptions, to lighting variations. We measure the quality of our learned perturbation sets both quantitatively and qualitatively, finding that our models are capable of producing a diverse set of meaningful perturbations beyond the limited data seen during training. Finally, we leverage our learned perturbation sets to train models which are empirically and certifiably robust to adversarial image corruptions and adversarial lighting variations, while improving generalization on non-adversarial data. All code and configuration files for reproducing the experiments as well as pretrained model weights can be found at https://github.com/locuslab/perturbation_learning. ",
        "conference": "ICLR",
        "中文标题": "学习扰动集以实现鲁棒机器学习",
        "摘要翻译": "尽管在鲁棒深度学习方面已取得很大进展，但现实世界中的扰动与对抗防御中通常研究的更狭义定义的集合之间仍存在显著的鲁棒性差距。在本文中，我们旨在通过学习数据中的扰动集来弥合这一差距，以表征现实世界效应用于鲁棒训练和评估。具体来说，我们使用一个条件生成器，该生成器在潜在空间的受限区域内定义扰动集。我们制定了衡量学习扰动集质量的理想属性，并从理论上证明条件变分自编码器自然满足这些标准。利用这一框架，我们的方法可以在不同复杂度和规模上生成各种扰动，从基线空间变换，到常见的图像损坏，再到光照变化。我们定量和定性地测量了学习扰动集的质量，发现我们的模型能够产生超出训练期间所见有限数据的多样化且有意义的扰动集。最后，我们利用学习到的扰动集来训练模型，这些模型在经验上和可证明地对对抗性图像损坏和对抗性光照变化具有鲁棒性，同时提高了在非对抗性数据上的泛化能力。所有用于重现实验的代码和配置文件以及预训练模型权重都可以在https://github.com/locuslab/perturbation_learning找到。",
        "领域": "对抗性防御、图像鲁棒性、深度学习安全",
        "问题": "如何通过学习数据中的扰动集来弥合现实世界扰动与对抗防御中研究的狭义扰动集之间的鲁棒性差距",
        "动机": "为了表征现实世界效应用于鲁棒训练和评估，提高模型对对抗性图像损坏和光照变化的鲁棒性，同时改善在非对抗性数据上的泛化能力",
        "方法": "使用条件生成器在潜在空间的受限区域内定义扰动集，并通过条件变分自编码器满足理想属性标准，生成多样化的扰动集",
        "关键词": [
            "扰动集学习",
            "对抗性防御",
            "条件变分自编码器",
            "图像鲁棒性",
            "深度学习安全"
        ],
        "涉及的技术概念": {
            "条件生成器": "在潜在空间的受限区域内定义扰动集，用于生成多样化的扰动",
            "条件变分自编码器": "用于满足学习扰动集的理想属性标准，能够生成超出训练数据的扰动",
            "对抗性图像损坏": "模型需要抵抗的一种扰动类型，通过学习扰动集来提高模型对此类扰动的鲁棒性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 448,
        "title": "Learning Reasoning Paths over Semantic Graphs for Video-grounded Dialogues",
        "html": "https://iclr.cc//virtual/2021/poster/3106",
        "abstract": "Compared to traditional visual question answering, video-grounded dialogues require additional reasoning over dialogue context to answer questions in a multi-turn setting. Previous approaches to video-grounded dialogues mostly use dialogue context as a simple text input without modelling the inherent information flows at the turn level. In this paper, we propose a novel framework of Reasoning Paths in Dialogue Context (PDC). PDC model discovers information flows among dialogue turns through a semantic graph constructed based on lexical components in each question and answer. PDC model then learns to predict reasoning paths over this semantic graph. Our path prediction model predicts a path from the current turn through past dialogue turns that contain additional visual cues to answer the current question. Our reasoning model sequentially processes both visual and textual information through this reasoning path and the propagated features are used to generate the answer. Our experimental results demonstrate the effectiveness of our method and provide additional insights on how models use semantic dependencies in a dialogue context to retrieve visual cues.",
        "conference": "ICLR",
        "中文标题": "基于语义图的视频对话推理路径学习",
        "摘要翻译": "与传统视觉问答相比，视频对话需要在多轮对话环境中对对话上下文进行额外推理以回答问题。以往的视频对话方法大多将对话上下文作为简单的文本输入，而没有在轮次级别上建模内在的信息流。本文中，我们提出了一种新颖的对话上下文推理路径（PDC）框架。PDC模型通过基于每个问题和答案中的词汇成分构建的语义图，发现对话轮次之间的信息流。PDC模型随后学习预测这个语义图上的推理路径。我们的路径预测模型预测一条从当前轮次通过包含额外视觉线索的过去对话轮次的路径，以回答当前问题。我们的推理模型通过这条推理路径顺序处理视觉和文本信息，传播的特征用于生成答案。我们的实验结果证明了我们方法的有效性，并提供了关于模型如何利用对话上下文中的语义依赖来检索视觉线索的额外见解。",
        "领域": "视频理解与对话系统、多模态学习、语义推理",
        "问题": "如何在多轮视频对话中有效推理对话上下文以回答问题",
        "动机": "解决传统方法未能建模对话轮次间信息流的问题，提升视频对话系统的推理能力",
        "方法": "构建基于词汇成分的语义图，预测并利用推理路径顺序处理视觉和文本信息",
        "关键词": [
            "视频对话",
            "语义推理",
            "多模态学习",
            "信息流建模",
            "路径预测"
        ],
        "涉及的技术概念": {
            "语义图": "基于对话中的词汇成分构建，用于表示和发现对话轮次间的信息流",
            "推理路径": "预测的路径，指导模型从当前问题回溯到包含相关视觉线索的历史对话轮次",
            "多模态特征传播": "通过推理路径顺序整合视觉和文本信息，用于生成最终答案"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 449,
        "title": "Learning Robust State Abstractions for Hidden-Parameter Block MDPs",
        "html": "https://iclr.cc//virtual/2021/poster/2847",
        "abstract": "Many control tasks exhibit similar dynamics that can be modeled as having common latent structure. Hidden-Parameter Markov Decision Processes (HiP-MDPs) explicitly model this structure to improve sample efficiency in multi-task settings.\nHowever, this setting makes strong assumptions on the observability of the state that limit its application in real-world scenarios with rich observation spaces.  In this work, we leverage ideas of common structure from the HiP-MDP setting, and extend it to enable robust state abstractions inspired by Block MDPs. We  derive instantiations of this new framework for  both multi-task reinforcement learning (MTRL) and  meta-reinforcement learning (Meta-RL) settings. Further, we provide transfer and generalization bounds based on task and state similarity, along with sample complexity bounds that depend on the aggregate number of samples across tasks, rather than the number of tasks, a significant improvement over prior work. To further demonstrate efficacy of the proposed method, we empirically compare and show improvement over multi-task and meta-reinforcement learning baselines.",
        "conference": "ICLR",
        "中文标题": "学习隐藏参数块MDP的鲁棒状态抽象",
        "摘要翻译": "许多控制任务展现出可以被建模为具有共同潜在结构的相似动态。隐藏参数马尔可夫决策过程（HiP-MDPs）明确地建模了这种结构，以提高多任务设置中的样本效率。然而，这种设置对状态的可观测性做出了强有力的假设，限制了其在具有丰富观察空间的现实世界场景中的应用。在这项工作中，我们利用了HiP-MDP设置中的共同结构思想，并扩展它以实现受块MDP启发的鲁棒状态抽象。我们为多任务强化学习（MTRL）和元强化学习（Meta-RL）设置推导了这一新框架的实例。此外，我们提供了基于任务和状态相似性的转移和泛化界限，以及依赖于跨任务样本总数的样本复杂度界限，这比之前的工作有了显著改进。为了进一步证明所提出方法的有效性，我们进行了实证比较，并显示了对多任务和元强化学习基线的改进。",
        "领域": "强化学习, 多任务学习, 元学习",
        "问题": "如何在具有丰富观察空间的现实世界场景中，利用共同潜在结构提高多任务强化学习和元强化学习的样本效率和泛化能力。",
        "动机": "现有的HiP-MDPs在多任务设置中虽然能提高样本效率，但对状态的可观测性假设限制了其在现实世界中的应用。",
        "方法": "结合HiP-MDPs的共同结构思想和块MDPs的鲁棒状态抽象，为多任务强化学习和元强化学习提供新的框架，并基于任务和状态相似性提供理论保证。",
        "关键词": [
            "隐藏参数MDP",
            "状态抽象",
            "多任务强化学习",
            "元强化学习",
            "样本效率"
        ],
        "涉及的技术概念": {
            "隐藏参数马尔可夫决策过程（HiP-MDPs）": "一种明确建模任务间共同潜在结构以提高多任务样本效率的框架。",
            "块MDPs": "一种通过状态抽象来简化观察空间的方法，本文受其启发扩展了HiP-MDPs。",
            "样本复杂度界限": "本文提出的理论保证之一，表明样本效率依赖于跨任务样本总数而非任务数量。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 450,
        "title": "Learning Safe Multi-agent Control with Decentralized Neural Barrier Certificates",
        "html": "https://iclr.cc//virtual/2021/poster/2820",
        "abstract": "We study the multi-agent safe control problem where agents should avoid collisions to static obstacles and collisions with each other while reaching their goals. Our core idea is to learn the multi-agent control policy jointly with  learning the control barrier functions as safety certificates. We propose a new joint-learning framework that can be implemented in a decentralized fashion, which can adapt to an arbitrarily large number of agents. Building upon this framework, we further improve the scalability by  incorporating neural network architectures  that are invariant to the quantity and permutation of neighboring agents. In addition, we propose a new spontaneous policy refinement method to further enforce the certificate condition during testing. We provide extensive experiments to demonstrate that our method significantly outperforms other leading multi-agent control approaches in terms of maintaining safety and completing original tasks. Our approach also shows substantial generalization capability in that the control policy can be trained with 8 agents in one scenario, while being used on other scenarios with up to 1024 agents in complex multi-agent environments and dynamics. Videos and source code can be found at https://realm.mit.edu/blog/learning-safe-multi-agent-control-decentralized-neural-barrier-certificates.",
        "conference": "ICLR",
        "中文标题": "学习具有分散神经屏障证书的安全多智能体控制",
        "摘要翻译": "我们研究了多智能体安全控制问题，其中智能体在达到目标的同时应避免与静态障碍物及彼此之间的碰撞。我们的核心思想是联合学习多智能体控制策略与控制屏障函数作为安全证书。我们提出了一个新的联合学习框架，可以以分散的方式实现，能够适应任意数量的智能体。基于这一框架，我们通过引入对邻近智能体数量和排列不变的神经网络架构，进一步提高了可扩展性。此外，我们提出了一种新的自发策略细化方法，以在测试期间进一步加强证书条件。我们提供了大量实验，证明我们的方法在保持安全性和完成原始任务方面显著优于其他领先的多智能体控制方法。我们的方法还显示出强大的泛化能力，即控制策略可以在一个场景中用8个智能体训练，而在其他场景中用于多达1024个智能体的复杂多智能体环境和动态中。视频和源代码可以在https://realm.mit.edu/blog/learning-safe-multi-agent-control-decentralized-neural-barrier-certificates找到。",
        "领域": "多智能体系统、安全控制、分散学习",
        "问题": "解决多智能体在避免与静态障碍物及彼此碰撞的同时达到目标的安全控制问题",
        "动机": "研究动机是为了开发一种能够确保多智能体在复杂环境中安全交互的控制方法，同时保持高度的可扩展性和泛化能力",
        "方法": "提出了一种联合学习多智能体控制策略与控制屏障函数的框架，采用分散式实现和神经网络架构以提高可扩展性，并引入自发策略细化方法加强安全证书条件",
        "关键词": [
            "多智能体控制",
            "安全证书",
            "分散学习",
            "神经网络",
            "泛化能力"
        ],
        "涉及的技术概念": {
            "控制屏障函数": "作为安全证书，用于确保智能体在达到目标的同时避免碰撞",
            "分散学习框架": "允许框架适应任意数量的智能体，提高方法的可扩展性",
            "神经网络架构": "设计为对邻近智能体数量和排列不变，以进一步提高方法的可扩展性和适应性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 451,
        "title": "Learning Structural Edits via Incremental Tree Transformations",
        "html": "https://iclr.cc//virtual/2021/poster/3205",
        "abstract": "While most neural generative models generate outputs in a single pass, the human creative process is usually one of iterative building and refinement. Recent work has proposed models of editing processes, but these mostly focus on editing sequential data and/or only model a single editing pass. In this paper, we present a generic model for incremental editing of structured data (i.e. ''structural edits''). Particularly, we focus on tree-structured data, taking abstract syntax trees of computer programs as our canonical example. Our editor learns to iteratively generate tree edits (e.g. deleting or adding a subtree) and applies them to the partially edited data, thereby the entire editing process can be formulated as consecutive, incremental tree transformations. To show the unique benefits of modeling tree edits directly, we further propose a novel edit encoder for learning to represent edits, as well as an imitation learning method that allows the editor to be more robust. We evaluate our proposed editor on two source code edit datasets, where results show that, with the proposed edit encoder, our editor significantly improves accuracy over previous approaches that generate the edited program directly in one pass. Finally, we demonstrate that training our editor to imitate experts and correct its mistakes dynamically can further improve its performance.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "通过增量树变换学习结构编辑",
        "摘要翻译": "虽然大多数神经生成模型通过单次传递生成输出，但人类的创作过程通常是迭代构建和精炼的。最近的工作提出了编辑过程的模型，但这些模型主要关注于编辑序列数据和/或仅模拟单次编辑传递。在本文中，我们提出了一个用于结构化数据（即“结构编辑”）增量编辑的通用模型。特别地，我们关注于树形结构数据，以计算机程序的抽象语法树作为我们的典型例子。我们的编辑器学习迭代生成树编辑（例如删除或添加子树）并将其应用于部分编辑的数据，从而整个编辑过程可以表述为连续的、增量的树变换。为了展示直接建模树编辑的独特优势，我们进一步提出了一种新颖的编辑编码器用于学习表示编辑，以及一种模仿学习方法，使编辑器更加健壮。我们在两个源代码编辑数据集上评估了我们提出的编辑器，结果显示，通过提出的编辑编码器，我们的编辑器在准确性上显著优于之前直接单次传递生成编辑程序的方法。最后，我们证明了训练我们的编辑器模仿专家并动态纠正其错误可以进一步提高其性能。",
        "领域": "程序合成与编辑",
        "问题": "如何有效地对结构化数据（特别是树形结构数据）进行增量编辑",
        "动机": "模拟人类创作过程中的迭代构建和精炼过程，提高结构化数据编辑的准确性和效率",
        "方法": "提出了一种通用模型，通过增量树变换进行结构编辑，包括一个新颖的编辑编码器和模仿学习方法",
        "关键词": [
            "结构编辑",
            "增量树变换",
            "编辑编码器",
            "模仿学习",
            "程序合成"
        ],
        "涉及的技术概念": {
            "增量树变换": "将整个编辑过程表述为连续的、增量的树变换，以提高编辑的准确性和效率",
            "编辑编码器": "一种新颖的编码器，用于学习表示编辑，帮助模型更好地理解和生成编辑操作",
            "模仿学习": "通过模仿专家的编辑行为并动态纠正错误，提高编辑器的性能和健壮性"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 452,
        "title": "Learning Subgoal Representations with Slow Dynamics",
        "html": "https://iclr.cc//virtual/2021/poster/3356",
        "abstract": "In goal-conditioned Hierarchical Reinforcement Learning (HRL), a high-level policy periodically sets subgoals for a low-level policy, and the low-level policy is trained to reach those subgoals. A proper subgoal representation function, which abstracts a state space to a latent subgoal space, is crucial for effective goal-conditioned HRL, since different low-level behaviors are induced by reaching subgoals in the compressed representation space. Observing that the high-level agent operates at an abstract temporal scale, we propose a slowness objective to effectively learn the subgoal representation (i.e., the high-level action space). We provide a theoretical grounding for the slowness objective. That is, selecting slow features as the subgoal space can achieve efficient hierarchical exploration. As a result of better exploration ability, our approach significantly outperforms state-of-the-art HRL and exploration methods on a number of benchmark continuous-control tasks. Thanks to the generality of the proposed subgoal representation learning method, empirical results also demonstrate that the learned representation and corresponding low-level policies can be transferred between distinct tasks.",
        "conference": "ICLR",
        "中文标题": "学习具有慢动态特性的子目标表示",
        "摘要翻译": "在目标条件的层次强化学习（HRL）中，高层策略定期为低层策略设定子目标，而低层策略被训练以达到这些子目标。一个合适的子目标表示函数，它将状态空间抽象为潜在的子目标空间，对于有效的目标条件HRL至关重要，因为通过达到压缩表示空间中的子目标，可以诱导出不同的低层行为。观察到高层代理在抽象的时间尺度上操作，我们提出了一个慢动态目标来有效地学习子目标表示（即高层动作空间）。我们为慢动态目标提供了理论基础。即，选择慢特征作为子目标空间可以实现高效的层次探索。由于更好的探索能力，我们的方法在一系列基准连续控制任务上显著优于最先进的HRL和探索方法。得益于所提出的子目标表示学习方法的通用性，实证结果还表明，学习到的表示和相应的低层策略可以在不同的任务之间转移。",
        "领域": "层次强化学习、连续控制任务、探索方法",
        "问题": "如何在层次强化学习中有效地学习和表示子目标，以促进高效的层次探索和任务间的知识转移。",
        "动机": "为了解决层次强化学习中子目标表示的有效性问题，以及如何通过慢动态特性来优化高层策略的动作空间，从而提高探索效率和任务间的泛化能力。",
        "方法": "提出了一种慢动态目标来学习子目标表示，该方法通过选择慢特征作为子目标空间，以实现高效的层次探索，并在连续控制任务上验证了其有效性。",
        "关键词": [
            "层次强化学习",
            "子目标表示",
            "慢动态特性",
            "连续控制",
            "探索方法"
        ],
        "涉及的技术概念": {
            "层次强化学习（HRL）": "一种将复杂任务分解为子任务或子目标的强化学习方法，通过高层策略和低层策略的协同工作来提高学习效率和性能。",
            "子目标表示": "将状态空间抽象为潜在的子目标空间，用于指导低层策略的行为，是实现有效层次强化学习的关键。",
            "慢动态特性": "一种选择慢变化特征作为子目标空间的方法，旨在通过减少高层策略的动作空间变化频率来提高探索效率和任务间的泛化能力。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 453,
        "title": "Learning Task Decomposition with Ordered Memory Policy Network",
        "html": "https://iclr.cc//virtual/2021/poster/2974",
        "abstract": "Many complex real-world tasks are composed of several levels of subtasks. Humans leverage these hierarchical structures to accelerate the learning process and achieve better generalization. In this work, we study the inductive bias and propose Ordered Memory Policy Network (OMPN) to discover subtask hierarchy by learning from demonstration. The discovered subtask hierarchy could be used to perform task decomposition, recovering the subtask boundaries in an unstructured demonstration. Experiments on Craft and Dial demonstrate that our model can achieve higher task decomposition performance under both unsupervised and weakly supervised settings, comparing with strong baselines. OMPN can also be directly applied to partially observable environments and still achieve higher task decomposition performance. Our visualization further confirms that the subtask hierarchy can emerge in our model 1.",
        "conference": "ICLR",
        "中文标题": "学习任务分解的有序记忆策略网络",
        "摘要翻译": "许多复杂的现实世界任务由多个层次的子任务组成。人类利用这些层次结构来加速学习过程并实现更好的泛化。在这项工作中，我们研究了归纳偏差，并提出了有序记忆策略网络（OMPN），通过学习示范来发现子任务层次结构。发现的子任务层次结构可用于执行任务分解，恢复非结构化示范中的子任务边界。在Craft和Dial上的实验表明，与强大的基线相比，我们的模型可以在无监督和弱监督设置下实现更高的任务分解性能。OMPN也可以直接应用于部分可观察的环境，并且仍然实现更高的任务分解性能。我们的可视化进一步证实了子任务层次结构可以在我们的模型中显现。",
        "领域": "强化学习、任务分解、层次化学习",
        "问题": "如何从示范中学习并发现子任务的层次结构，以进行有效的任务分解。",
        "动机": "利用人类示范中的层次结构信息，加速学习过程并提高模型的泛化能力。",
        "方法": "提出了有序记忆策略网络（OMPN），通过学习示范来发现子任务层次结构，并用于任务分解。",
        "关键词": [
            "任务分解",
            "有序记忆策略网络",
            "层次化学习",
            "强化学习",
            "示范学习"
        ],
        "涉及的技术概念": {
            "有序记忆策略网络（OMPN）": "用于从示范中学习并发现子任务层次结构的网络模型。",
            "任务分解": "将复杂任务分解为更小、更易管理的子任务的过程。",
            "层次化学习": "通过识别和利用任务中的层次结构来加速学习和提高泛化能力的方法。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 454,
        "title": "Learning Task-General Representations with Generative Neuro-Symbolic Modeling",
        "html": "https://iclr.cc//virtual/2021/poster/3058",
        "abstract": "People can learn rich, general-purpose conceptual representations from only raw perceptual inputs. Current machine learning approaches fall well short of these human standards, although different modeling traditions often have complementary strengths. Symbolic models can capture the compositional and causal knowledge that enables flexible generalization, but they struggle to learn from raw inputs, relying on strong abstractions and simplifying assumptions. Neural network models can learn directly from raw data, but they struggle to capture compositional and causal structure and typically must retrain to tackle new tasks. We bring together these two traditions to learn generative models of concepts that capture rich compositional and causal structure, while learning from raw data. We develop a generative neuro-symbolic (GNS) model of handwritten character concepts that uses the control flow of a probabilistic program, coupled with symbolic stroke primitives and a symbolic image renderer, to represent the causal and compositional processes by which characters are formed. The distributions of parts (strokes), and correlations between parts, are modeled with neural network subroutines, allowing the model to learn directly from raw data and express nonparametric statistical relationships. We apply our model to the Omniglot challenge of human-level concept learning, using a background set of alphabets to learn an expressive prior distribution over character drawings. In a subsequent evaluation, our GNS model uses probabilistic inference to learn rich conceptual representations from a single training image that generalize to 4 unique tasks, succeeding where previous work has fallen short.",
        "conference": "ICLR",
        "中文标题": "通过生成性神经符号建模学习任务通用表示",
        "摘要翻译": "人们能够仅从原始感知输入中学习到丰富、通用的概念表示。当前的机器学习方法远未达到这些人类标准，尽管不同的建模传统往往具有互补的优势。符号模型能够捕捉到支持灵活泛化的组合性和因果性知识，但它们难以从原始输入中学习，依赖于强抽象和简化假设。神经网络模型可以直接从原始数据中学习，但它们难以捕捉组合性和因果性结构，通常需要重新训练以应对新任务。我们将这两种传统结合起来，学习能够捕捉丰富组合性和因果性结构的概念生成模型，同时从原始数据中学习。我们开发了一个手写字符概念的生成性神经符号（GNS）模型，该模型使用概率程序的控制流，结合符号笔画基元和符号图像渲染器，来表示字符形成的因果和组合过程。部分（笔画）的分布以及部分之间的相关性，通过神经网络子程序建模，使模型能够直接从原始数据中学习并表达非参数统计关系。我们将我们的模型应用于人类水平概念学习的Omniglot挑战，使用一组背景字母表来学习字符绘制的表达性先验分布。在随后的评估中，我们的GNS模型使用概率推断从单个训练图像中学习丰富的概念表示，这些表示能够泛化到4个独特任务，在先前工作失败的地方取得了成功。",
        "领域": "概念学习、神经符号系统、手写字符识别",
        "问题": "如何从原始数据中学习到既具有组合性和因果性结构，又能够直接应用于多种任务的通用概念表示。",
        "动机": "结合符号模型和神经网络模型的优势，开发能够直接从原始数据中学习并捕捉丰富组合性和因果性结构的概念生成模型。",
        "方法": "开发生成性神经符号（GNS）模型，结合概率程序控制流、符号笔画基元和符号图像渲染器，以及神经网络子程序来建模笔画分布和相关性。",
        "关键词": [
            "生成性神经符号建模",
            "概念学习",
            "Omniglot挑战",
            "概率推断",
            "组合性结构"
        ],
        "涉及的技术概念": {
            "生成性神经符号（GNS）模型": "结合符号模型和神经网络模型的优势，直接从原始数据中学习并捕捉组合性和因果性结构的概念生成模型。",
            "概率程序控制流": "用于表示字符形成的因果和组合过程，使模型能够进行灵活的泛化。",
            "符号笔画基元和符号图像渲染器": "用于具体表示字符的组成部分和生成字符图像，支持模型从原始数据中学习。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 455,
        "title": "Learning the Pareto Front with Hypernetworks",
        "html": "https://iclr.cc//virtual/2021/poster/2593",
        "abstract": "Multi-objective optimization (MOO) problems are prevalent in machine learning. These problems have a set of optimal solutions, called the Pareto front, where each point on the front represents a different trade-off between possibly conflicting objectives. Recent MOO methods can target a specific desired ray in loss space however, most approaches still face two grave limitations: (i) A separate model has to be trained for each point on the front; and (ii) The exact trade-off must be known before the optimization process. Here, we tackle the problem of learning the entire Pareto front, with the capability of selecting a desired operating point on the front after training. We call this new setup Pareto-Front Learning (PFL).\n\nWe describe an approach to PFL implemented using HyperNetworks, which we term Pareto HyperNetworks (PHNs). PHN learns the entire Pareto front simultaneously using a single hypernetwork, which receives as input a desired preference vector and returns a Pareto-optimal model whose loss vector is in the desired ray. The unified model is runtime efficient compared to training multiple models and generalizes to new operating points not used during training. We evaluate our method on a wide set of problems, from multi-task regression and classification to fairness. PHNs learn the entire Pareto front at roughly the same time as learning a single point on the front and at the same time reach a better solution set. PFL opens the door to new applications where models are selected based on preferences that are only available at run time.",
        "conference": "ICLR",
        "中文标题": "使用超网络学习帕累托前沿",
        "摘要翻译": "多目标优化（MOO）问题在机器学习中普遍存在。这些问题有一组最优解，称为帕累托前沿，前沿上的每个点代表了可能冲突目标之间的不同权衡。最近的MOO方法可以针对损失空间中的特定期望射线，然而，大多数方法仍面临两个严重限制：（i）必须为前沿上的每个点单独训练一个模型；（ii）优化过程之前必须知道确切的权衡。在这里，我们解决了学习整个帕累托前沿的问题，能够在训练后选择前沿上的期望操作点。我们称这种新设置为帕累托前沿学习（PFL）。我们描述了一种使用超网络实现的PFL方法，我们称之为帕累托超网络（PHNs）。PHN使用单个超网络同时学习整个帕累托前沿，该网络接收期望的偏好向量作为输入，并返回一个帕累托最优模型，其损失向量位于期望的射线上。与训练多个模型相比，统一模型在运行时效率更高，并且可以推广到训练期间未使用的新操作点。我们在广泛的问题集上评估了我们的方法，从多任务回归和分类到公平性。PHNs学习整个帕累托前沿的时间大约与学习前沿上的单个点相同，并且同时达到更好的解集。PFL为基于仅在运行时可用的偏好选择模型的新应用打开了大门。",
        "领域": "多目标优化、超网络应用、机器学习模型优化",
        "问题": "解决多目标优化中需要为帕累托前沿上的每个点单独训练模型以及优化前必须知道确切权衡的问题。",
        "动机": "开发一种能够学习整个帕累托前沿并能在训练后根据运行时可用的偏好选择操作点的方法。",
        "方法": "使用超网络（HyperNetworks）实现帕累托前沿学习（PFL），通过单个超网络同时学习整个帕累托前沿，根据输入的偏好向量返回帕累托最优模型。",
        "关键词": [
            "多目标优化",
            "帕累托前沿",
            "超网络",
            "机器学习",
            "模型优化"
        ],
        "涉及的技术概念": {
            "帕累托前沿": "在多目标优化问题中，表示所有最优解的集合，每个解代表不同目标之间的权衡。",
            "超网络": "一种生成其他网络的网络，用于同时学习多个模型或配置，提高效率和灵活性。",
            "偏好向量": "在多目标优化中，表示决策者对各个目标偏好的向量，用于指导模型生成特定权衡的解。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 456,
        "title": "Learning to Deceive Knowledge Graph Augmented Models via Targeted Perturbation",
        "html": "https://iclr.cc//virtual/2021/poster/2769",
        "abstract": "Knowledge graphs (KGs) have helped neural models improve performance on various knowledge-intensive tasks, like question answering and item recommendation. By using attention over the KG, such KG-augmented models can also 'explain' which KG information was most relevant for making a given prediction. In this paper, we question whether these models are really behaving as we expect. We show that, through a reinforcement learning policy (or even simple heuristics), one can produce deceptively perturbed KGs, which maintain the downstream performance of the original KG while significantly deviating from the original KG's semantics and structure. Our findings raise doubts about KG-augmented models' ability to reason about KG information and give sensible explanations.",
        "conference": "ICLR",
        "中文标题": "学习通过目标扰动欺骗知识图谱增强模型",
        "摘要翻译": "知识图谱（KGs）已帮助神经模型在多种知识密集型任务上提高性能，如问答和物品推荐。通过使用对知识图谱的注意力机制，这类知识图谱增强模型还能‘解释’哪些知识图谱信息对做出特定预测最为相关。在本文中，我们质疑这些模型是否真的如我们所期望的那样行为。我们展示，通过强化学习策略（或甚至简单的启发式方法），可以产生欺骗性的扰动知识图谱，这些知识图谱在保持原始知识图谱下游性能的同时，显著偏离原始知识图谱的语义和结构。我们的发现对知识图谱增强模型推理知识图谱信息和提供合理解释的能力提出了质疑。",
        "领域": "知识图谱增强学习、模型解释性、对抗性攻击",
        "问题": "知识图谱增强模型是否真的能够如预期那样利用知识图谱信息进行推理和解释。",
        "动机": "质疑知识图谱增强模型在实际应用中是否能够正确利用知识图谱信息，以及其解释的可靠性。",
        "方法": "通过强化学习策略或简单启发式方法生成欺骗性的扰动知识图谱，测试模型性能。",
        "关键词": [
            "知识图谱增强",
            "对抗性攻击",
            "模型解释性",
            "强化学习",
            "注意力机制"
        ],
        "涉及的技术概念": {
            "知识图谱增强": "通过整合知识图谱信息来提升神经模型在知识密集型任务上的性能。",
            "对抗性攻击": "通过特定设计的输入扰动来测试模型的鲁棒性和可靠性。",
            "注意力机制": "用于识别和解释知识图谱中哪些信息对模型预测最为关键的技术。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 457,
        "title": "Learning to Generate 3D Shapes with Generative Cellular Automata",
        "html": "https://iclr.cc//virtual/2021/poster/2914",
        "abstract": "In this work, we present a probabilistic 3D generative model, named Generative Cellular Automata, which is able to produce diverse and high quality shapes. We formulate the shape generation process as sampling from the transition kernel of a Markov chain, where the sampling chain eventually evolves to the full shape of the learned distribution. The transition kernel employs the local update rules of cellular automata, effectively reducing the search space in a high-resolution 3D grid space by exploiting the connectivity and sparsity of 3D shapes. Our progressive generation only focuses on the sparse set of occupied voxels and their neighborhood, thus enables the utilization of an expressive sparse convolutional network. We propose an effective training scheme to obtain the local homogeneous rule of generative cellular automata with sequences that are slightly different from the sampling chain but converge to the full shapes in the training data. Extensive experiments on probabilistic shape completion and shape generation demonstrate that our method achieves competitive performance against recent methods.",
        "conference": "ICLR",
        "中文标题": "学习使用生成细胞自动机生成3D形状",
        "摘要翻译": "在这项工作中，我们提出了一种名为生成细胞自动机的概率3D生成模型，该模型能够产生多样化和高质量的3D形状。我们将形状生成过程表述为从马尔可夫链的转移核中采样，其中采样链最终演化为学习分布的全形状。转移核采用细胞自动机的局部更新规则，通过利用3D形状的连通性和稀疏性，有效地减少了在高分辨率3D网格空间中的搜索空间。我们的渐进生成仅关注稀疏的占据体素及其邻域，从而使得能够利用表达性稀疏卷积网络。我们提出了一种有效的训练方案，以获取生成细胞自动机的局部同质规则，这些规则的序列与采样链略有不同，但在训练数据中收敛于全形状。在概率形状完成和形状生成方面的广泛实验表明，我们的方法相对于最近的方法实现了竞争性的性能。",
        "领域": "3D形状生成、概率生成模型、稀疏卷积网络",
        "问题": "如何高效地在高分辨率3D网格空间中生成多样化和高质量的3D形状",
        "动机": "探索利用细胞自动机的局部更新规则和稀疏性，以更高效的方式生成3D形状，减少计算资源的消耗",
        "方法": "采用生成细胞自动机模型，结合马尔可夫链采样和稀疏卷积网络，通过局部同质规则渐进生成3D形状",
        "关键词": [
            "生成细胞自动机",
            "3D形状生成",
            "稀疏卷积网络",
            "马尔可夫链",
            "概率生成模型"
        ],
        "涉及的技术概念": {
            "生成细胞自动机": "一种概率3D生成模型，利用细胞自动机的局部更新规则生成3D形状",
            "马尔可夫链转移核": "用于从学习分布中采样形状，通过转移核的演化生成全形状",
            "稀疏卷积网络": "在渐进生成过程中，仅处理稀疏的占据体素及其邻域，提高计算效率"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 458,
        "title": "Learning to live with Dale's principle: ANNs with separate excitatory and inhibitory units",
        "html": "https://iclr.cc//virtual/2021/poster/3014",
        "abstract": " The units in artificial neural networks (ANNs) can be thought of as abstractions of biological neurons, and ANNs are increasingly used in neuroscience research. However, there are many important differences between ANN units and real neurons. One of the most notable is the absence of Dale's principle, which ensures that biological neurons are either exclusively excitatory or inhibitory. Dale's principle is typically left out of ANNs because its inclusion impairs learning. This is problematic, because one of the great advantages of ANNs for neuroscience research is their ability to learn complicated, realistic tasks. Here, by taking inspiration from feedforward inhibitory interneurons in the brain we show that we can develop ANNs with separate populations of excitatory and inhibitory units that learn just as well as standard ANNs. We call these networks Dale's ANNs (DANNs). We present two insights that enable DANNs to learn well: (1) DANNs are related to normalization schemes, and can be initialized such that the inhibition centres and standardizes the excitatory activity, (2) updates to inhibitory neuron parameters should be scaled using corrections based on the Fisher Information matrix. These results demonstrate how ANNs that respect Dale's principle can be built without sacrificing learning performance, which is important for future work using ANNs as models of the brain. The results may also have interesting implications for how inhibitory plasticity in the real brain operates.",
        "conference": "ICLR",
        "中文标题": "学会与戴尔原则共存：具有独立兴奋和抑制单元的人工神经网络",
        "摘要翻译": "人工神经网络（ANNs）中的单元可以被视为生物神经元的抽象，ANNs越来越多地被用于神经科学研究。然而，ANN单元与真实神经元之间存在许多重要差异。其中最显著的一点是缺乏戴尔原则，该原则确保生物神经元要么完全是兴奋性的，要么完全是抑制性的。戴尔原则通常被排除在ANNs之外，因为它的包含会损害学习。这是有问题的，因为ANNs用于神经科学研究的一个巨大优势是它们能够学习复杂的、现实的任务。在这里，通过从大脑中的前馈抑制性中间神经元获得灵感，我们展示了我们可以开发具有独立兴奋和抑制单元群的ANNs，这些网络学习效果与标准ANNs一样好。我们称这些网络为戴尔ANNs（DANNs）。我们提出了两个使DANNs能够良好学习的见解：（1）DANNs与归一化方案相关，并且可以初始化使得抑制中心化和标准化兴奋性活动，（2）抑制性神经元参数的更新应使用基于费舍尔信息矩阵的修正进行缩放。这些结果表明，如何在不牺牲学习性能的情况下构建尊重戴尔原则的ANNs，这对于未来使用ANNs作为大脑模型的工作非常重要。这些结果也可能对真实大脑中抑制性可塑性的运作方式有有趣的启示。",
        "领域": "神经网络模型、神经科学研究、机器学习",
        "问题": "如何在人工神经网络中实现戴尔原则而不损害其学习能力",
        "动机": "为了更准确地模拟生物神经元的特性，同时保持人工神经网络的学习能力",
        "方法": "通过从大脑中的前馈抑制性中间神经元获得灵感，开发具有独立兴奋和抑制单元群的ANNs，并采用基于费舍尔信息矩阵的参数更新策略",
        "关键词": [
            "戴尔原则",
            "人工神经网络",
            "抑制性神经元",
            "费舍尔信息矩阵",
            "神经科学研究"
        ],
        "涉及的技术概念": {
            "戴尔原则": "确保生物神经元要么完全是兴奋性的，要么完全是抑制性的原则，用于提高ANNs对生物神经元的模拟准确性",
            "费舍尔信息矩阵": "用于缩放抑制性神经元参数更新的修正，以优化网络的学习性能",
            "前馈抑制性中间神经元": "从大脑中获得的灵感，用于开发具有独立兴奋和抑制单元群的ANNs"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 459,
        "title": "Learning to Make Decisions via Submodular Regularization",
        "html": "https://iclr.cc//virtual/2021/poster/3298",
        "abstract": "Many sequential decision making tasks can be viewed as combinatorial optimization problems over a large number of actions. When the cost of evaluating an action is high, even a greedy algorithm, which iteratively picks the best action given the history, is prohibitive to run. In this paper, we aim to learn a greedy heuristic for sequentially selecting actions as a surrogate for invoking the expensive oracle when evaluating an action. In particular, we focus on a class of combinatorial problems that can be solved via submodular maximization (either directly on the objective function or via submodular surrogates). We introduce a data-driven optimization framework based on the submodular-norm loss, a novel loss function that encourages the resulting objective to exhibit diminishing returns. Our framework outputs a surrogate objective that is efficient to train, approximately submodular, and can be made permutation-invariant. The latter two properties allow us to prove strong approximation guarantees for the learned greedy heuristic. Furthermore, we show that our model can be easily integrated with modern deep imitation learning pipelines for sequential prediction tasks. We demonstrate the performance of our algorithm on a variety of batched and sequential optimization tasks, including set cover, active learning, and Bayesian optimization for protein engineering.",
        "conference": "ICLR",
        "中文标题": "通过子模正则化学习决策",
        "摘要翻译": "许多顺序决策任务可以被视为对大量动作的组合优化问题。当评估一个动作的成本很高时，即使是贪婪算法——即根据历史迭代选择最佳动作——也难以运行。在本文中，我们的目标是学习一个贪婪启发式方法，用于顺序选择动作，作为评估动作时调用昂贵预测器的替代。特别是，我们关注一类可以通过子模最大化（直接在目标函数上或通过子模替代）解决的组合问题。我们引入了一个基于子模范数损失的数据驱动优化框架，这是一种新颖的损失函数，鼓励结果目标表现出递减回报。我们的框架输出一个替代目标，该目标训练效率高，近似子模，并且可以做到排列不变。后两个属性使我们能够为学习到的贪婪启发式方法提供强有力的近似保证。此外，我们展示了我们的模型可以轻松集成到现代深度模仿学习管道中，用于顺序预测任务。我们在多种批量和顺序优化任务上展示了我们算法的性能，包括集合覆盖、主动学习和蛋白质工程的贝叶斯优化。",
        "领域": "组合优化、主动学习、贝叶斯优化",
        "问题": "在高成本动作评估环境下，如何有效学习一个贪婪启发式方法以替代昂贵的预测器调用。",
        "动机": "解决在高成本动作评估环境下，传统贪婪算法运行成本过高的问题。",
        "方法": "引入基于子模范数损失的数据驱动优化框架，学习一个高效训练、近似子模且排列不变的替代目标。",
        "关键词": [
            "子模正则化",
            "贪婪启发式",
            "组合优化",
            "主动学习",
            "贝叶斯优化"
        ],
        "涉及的技术概念": {
            "子模最大化": "用于解决一类组合优化问题，通过子模性质确保目标函数的递减回报。",
            "子模范数损失": "一种新颖的损失函数，用于鼓励学习到的目标函数表现出子模性质。",
            "排列不变性": "确保学习到的目标函数对输入动作的顺序不敏感，从而提供更强的近似保证。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 460,
        "title": "Learning to Reach Goals via Iterated Supervised Learning",
        "html": "https://iclr.cc//virtual/2021/poster/2574",
        "abstract": "Current reinforcement learning (RL) algorithms can be brittle and difficult to use, especially when learning goal-reaching behaviors from sparse rewards. Although supervised imitation learning provides a simple and stable alternative, it requires access to demonstrations from a human supervisor. In this paper, we study RL algorithms that use imitation learning to acquire goal reaching policies from scratch, without the need for expert demonstrations or a value function. In lieu of demonstrations, we leverage the property that any trajectory is a successful demonstration for reaching the final state in that same trajectory. We propose a simple algorithm in which an agent continually relabels and imitates the trajectories it generates to progressively learn goal-reaching behaviors from scratch. Each iteration, the agent collects new trajectories using the latest policy, and maximizes the likelihood of the actions along these trajectories under the goal that was actually reached, so as to improve the policy. We formally show that this iterated supervised learning procedure optimizes a bound on the RL objective, derive performance bounds of the learned policy, and empirically demonstrate improved goal-reaching performance and robustness over current RL algorithms in several benchmark tasks. ",
        "conference": "ICLR",
        "中文标题": "通过迭代监督学习实现目标达成",
        "摘要翻译": "当前的强化学习（RL）算法可能脆弱且难以使用，尤其是在从稀疏奖励中学习达成目标的行为时。尽管监督模仿学习提供了一个简单且稳定的替代方案，但它需要访问来自人类监督者的演示。在本文中，我们研究了使用模仿学习从零开始获取达成目标策略的RL算法，无需专家演示或价值函数。代替演示，我们利用任何轨迹都是达成该轨迹最终状态的成功演示这一特性。我们提出了一个简单的算法，其中代理不断重新标记并模仿其生成的轨迹，从而逐步从零开始学习达成目标的行为。每次迭代，代理使用最新策略收集新轨迹，并在实际达成的目标下最大化这些轨迹上动作的可能性，以改进策略。我们正式展示了这种迭代监督学习过程优化了RL目标的界限，推导了学习策略的性能界限，并通过实验证明在几个基准任务中，与当前RL算法相比，达成目标的性能和鲁棒性有所提高。",
        "领域": "强化学习",
        "问题": "如何从稀疏奖励中有效学习达成目标的行为",
        "动机": "解决当前强化学习算法在从稀疏奖励中学习达成目标行为时的脆弱性和难以使用的问题",
        "方法": "提出一种迭代监督学习算法，代理通过不断重新标记和模仿自身生成的轨迹来学习达成目标的行为",
        "关键词": [
            "迭代监督学习",
            "目标达成",
            "强化学习"
        ],
        "涉及的技术概念": {
            "迭代监督学习": "通过不断重新标记和模仿自身生成的轨迹来学习达成目标的行为",
            "稀疏奖励": "在强化学习中，奖励信号不频繁或难以获得的情况",
            "策略改进": "通过最大化轨迹上动作的可能性来改进代理的策略"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 461,
        "title": "Learning to Recombine and Resample Data For Compositional Generalization",
        "html": "https://iclr.cc//virtual/2021/poster/2687",
        "abstract": "Flexible neural sequence models outperform grammar- and automaton-based counterparts on a variety of tasks. However, neural models perform poorly in settings requiring compositional generalization beyond the training data—particularly to rare or unseen subsequences. Past work has found symbolic scaffolding (e.g. grammars or automata) essential in these settings. We describe R&R, a learned data augmentation scheme that enables a large category of compositional generalizations without appeal to latent symbolic structure. R&R has two components: recombination of original training examples via a prototype-based generative model and resampling of generated examples to encourage extrapolation. Training an ordinary neural sequence model on a dataset augmented with recombined and resampled examples significantly improves generalization in two language processing problems—instruction following (SCAN) and morphological analysis (SIGMORPHON 2018)—where R&R enables learning of new constructions and tenses from as few as eight initial examples.",
        "conference": "ICLR",
        "中文标题": "学习重组和重采样数据以实现组合泛化",
        "摘要翻译": "灵活的神经序列模型在各种任务上表现优于基于语法和自动机的模型。然而，在需要超越训练数据的组合泛化——特别是对罕见或未见过的子序列——神经模型表现不佳。过去的工作发现，在这些情况下，符号支架（如语法或自动机）是必不可少的。我们描述了R&R，一种学习到的数据增强方案，它能够在不需要潜在符号结构的情况下实现一大类组合泛化。R&R有两个组成部分：通过基于原型的生成模型重组原始训练示例，以及重采样生成的示例以鼓励外推。在一个通过重组和重采样示例增强的数据集上训练普通的神经序列模型，在两种语言处理问题——指令跟随（SCAN）和形态分析（SIGMORPHON 2018）——中显著提高了泛化能力，其中R&R能够从仅八个初始示例中学习新的结构和时态。",
        "领域": "自然语言处理与视觉结合, 序列模型, 数据增强",
        "问题": "神经序列模型在需要组合泛化的情况下表现不佳，特别是在处理罕见或未见过的子序列时。",
        "动机": "探索一种不依赖于潜在符号结构的数据增强方法，以提高神经序列模型在组合泛化任务上的表现。",
        "方法": "采用R&R数据增强方案，包括通过基于原型的生成模型重组原始训练示例和重采样生成的示例以鼓励外推。",
        "关键词": [
            "组合泛化",
            "数据增强",
            "神经序列模型",
            "原型生成模型",
            "外推"
        ],
        "涉及的技术概念": {
            "R&R数据增强方案": "一种学习到的数据增强方法，通过重组和重采样训练数据来提高模型的组合泛化能力。",
            "基于原型的生成模型": "用于重组原始训练示例的模型，通过原型来生成新的数据示例。",
            "外推": "通过重采样生成的示例来鼓励模型学习超出原始数据分布的模式。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 462,
        "title": "Learning to Represent Action Values as a Hypergraph on the Action Vertices",
        "html": "https://iclr.cc//virtual/2021/poster/2731",
        "abstract": "Action-value estimation is a critical component of many reinforcement learning (RL) methods whereby sample complexity relies heavily on how fast a good estimator for action value can be learned. By viewing this problem through the lens of representation learning, good representations of both state and action can facilitate action-value estimation. While advances in deep learning have seamlessly driven progress in learning state representations, given the specificity of the notion of agency to RL, little attention has been paid to learning action representations. We conjecture that leveraging the combinatorial structure of multi-dimensional action spaces is a key ingredient for learning good representations of action. To test this, we set forth the action hypergraph networks framework---a class of functions for learning action representations in multi-dimensional discrete action spaces with a structural inductive bias. Using this framework we realise an agent class based on a combination with deep Q-networks, which we dub hypergraph Q-networks. We show the effectiveness of our approach on a myriad of domains: illustrative prediction problems under minimal confounding effects, Atari 2600 games, and discretised physical control benchmarks.",
        "conference": "ICLR",
        "中文标题": "学习将动作值表示为动作顶点上的超图",
        "摘要翻译": "动作值估计是许多强化学习（RL）方法的关键组成部分，样本复杂度在很大程度上依赖于学习动作值良好估计器的速度。通过从表示学习的角度看待这个问题，良好的状态和动作表示可以促进动作值的估计。尽管深度学习的进步无缝推动了状态表示学习的进展，但由于代理概念对RL的特殊性，学习动作表示的研究很少受到关注。我们推测，利用多维动作空间的组合结构是学习良好动作表示的关键因素。为了验证这一点，我们提出了动作超图网络框架——一类用于在多维离散动作空间中学习动作表示的函数，具有结构归纳偏置。利用这一框架，我们实现了一个基于深度Q网络组合的代理类，我们称之为超图Q网络。我们在多种领域展示了我们方法的有效性：在最小混杂效应下的说明性预测问题、Atari 2600游戏以及离散化的物理控制基准。",
        "领域": "强化学习、动作表示学习、多智能体系统",
        "问题": "如何在多维离散动作空间中有效地学习和表示动作值",
        "动机": "由于代理概念对强化学习的特殊性，动作表示学习的研究较少，而良好的动作表示可以显著提高动作值估计的效率",
        "方法": "提出动作超图网络框架，结合深度Q网络，用于在多维离散动作空间中学习动作表示",
        "关键词": [
            "动作表示学习",
            "超图网络",
            "强化学习",
            "深度Q网络",
            "多维动作空间"
        ],
        "涉及的技术概念": {
            "动作超图网络": "用于在多维离散动作空间中学习动作表示的框架，具有结构归纳偏置",
            "深度Q网络": "结合动作超图网络实现的代理类，用于动作值估计",
            "结构归纳偏置": "在动作表示学习中引入的先验知识，帮助模型更好地泛化"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 463,
        "title": "Learning to Sample with Local and Global Contexts  in Experience Replay Buffer",
        "html": "https://iclr.cc//virtual/2021/poster/3138",
        "abstract": "Experience replay, which enables the agents to remember and reuse experience from the past, has played a significant role in the success of off-policy reinforcement learning (RL). To utilize the experience replay efficiently, the existing sampling methods allow selecting out more meaningful experiences by imposing priorities on them based on certain metrics (e.g. TD-error). However, they may result in sampling highly biased, redundant transitions since they compute the sampling rate for each transition independently, without consideration of its importance in relation to other transitions. In this paper, we aim to address the issue by proposing a new learning-based sampling method that can compute the relative importance of transition. To this end, we design a novel permutation-equivariant neural architecture that takes contexts from not only features of each transition (local) but also those of others (global) as inputs. We validate our framework, which we refer to as Neural Experience Replay Sampler (NERS), on multiple benchmark tasks for both continuous and discrete control tasks and show that it can significantly improve the performance of various off-policy RL methods. Further analysis confirms that the improvements of the sample efficiency indeed are due to sampling diverse and meaningful transitions by NERS that considers both local and global contexts. ",
        "conference": "ICLR",
        "中文标题": "在经验回放缓冲区中学习利用局部与全局上下文进行采样",
        "摘要翻译": "经验回放使智能体能够记住并重用过去的经验，在离策略强化学习（RL）的成功中发挥了重要作用。为了高效利用经验回放，现有的采样方法通过基于某些指标（如TD误差）对经验赋予优先级，从而选择出更有意义的经验。然而，这些方法可能会因为独立计算每个转移的采样率，而不考虑其相对于其他转移的重要性，导致采样出高度偏差、冗余的转移。本文旨在通过提出一种新的基于学习的采样方法来解决这一问题，该方法能够计算转移的相对重要性。为此，我们设计了一种新颖的置换等变神经架构，该架构不仅将每个转移的特征（局部）作为输入，还将其他转移的特征（全局）作为输入。我们在多个基准任务上验证了我们的框架——我们称之为神经经验回放采样器（NERS），包括连续和离散控制任务，并表明它可以显著提高各种离策略RL方法的性能。进一步的分析证实，样本效率的提高确实是由于NERS考虑了局部和全局上下文，从而采样出了多样且有意义的转移。",
        "领域": "强化学习、经验回放、样本效率优化",
        "问题": "现有经验回放采样方法因独立计算每个转移的采样率，不考虑转移间的相对重要性，导致采样偏差和冗余。",
        "动机": "提高经验回放的效率，通过考虑转移间的相对重要性，减少采样偏差和冗余，从而提升强化学习算法的性能。",
        "方法": "提出一种基于学习的采样方法NERS，设计置换等变神经架构，同时考虑局部（单个转移特征）和全局（其他转移特征）上下文来计算转移的相对重要性。",
        "关键词": [
            "经验回放",
            "采样方法",
            "强化学习",
            "置换等变",
            "神经架构"
        ],
        "涉及的技术概念": {
            "经验回放": "一种技术，允许强化学习智能体记住并重用过去的经验，以提高学习效率和稳定性。",
            "置换等变神经架构": "一种神经网络设计，能够处理输入的顺序不变性，适用于需要考虑多个输入间关系的任务。",
            "TD误差": "时间差分误差，用于衡量当前状态值函数估计与下一个状态值函数估计之间的差异，常用于优先级经验回放中确定转移的重要性。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 464,
        "title": "Learning to Set Waypoints for Audio-Visual Navigation",
        "html": "https://iclr.cc//virtual/2021/poster/2814",
        "abstract": "In audio-visual navigation, an agent intelligently travels through a complex, unmapped 3D environment using both sights and sounds to find a sound source (e.g., a phone ringing in another room). Existing models learn to act at a fixed granularity of agent motion and rely on simple recurrent aggregations of the audio observations. We introduce a reinforcement learning approach to audio-visual navigation with two key novel elements: 1) waypoints that are dynamically set and learned end-to-end within the navigation policy, and 2) an acoustic memory that provides a structured, spatially grounded record of what the agent has heard as it moves. Both new ideas capitalize on the synergy of audio and visual data for revealing the geometry of an unmapped space. We demonstrate our approach on two challenging datasets of real-world 3D scenes, Replica and Matterport3D. Our model improves the state of the art by a substantial margin, and our experiments reveal that learning the links between sights, sounds, and space is essential for audio-visual navigation.",
        "conference": "ICLR",
        "中文标题": "学习为视听导航设置路径点",
        "摘要翻译": "在视听导航中，智能体通过视觉和听觉在复杂、未映射的3D环境中智能移动，以寻找声源（例如，另一个房间中响起的电话铃声）。现有模型学习以固定的智能体运动粒度行动，并依赖于对音频观察的简单循环聚合。我们引入了一种强化学习方法到视听导航中，该方法包含两个关键的新元素：1）在导航策略中动态设置并端到端学习的路径点，以及2）一个声学记忆，它提供了智能体移动时所听到内容的结构化、空间基础记录。这两个新想法都利用了音频和视觉数据的协同作用，以揭示未映射空间的几何结构。我们在两个具有挑战性的真实世界3D场景数据集Replica和Matterport3D上展示了我们的方法。我们的模型大幅提高了现有技术水平，并且我们的实验揭示了学习视觉、听觉和空间之间的联系对于视听导航至关重要。",
        "领域": "视听导航、强化学习、3D环境理解",
        "问题": "如何在复杂、未映射的3D环境中，通过结合视觉和听觉信息，有效地导航至声源位置。",
        "动机": "现有方法在视听导航中依赖于固定的运动粒度和简单的音频观察聚合，限制了导航的效率和准确性。",
        "方法": "提出了一种结合动态路径点设置和端到端学习的强化学习方法，以及一个结构化声学记忆系统，以优化视听导航策略。",
        "关键词": [
            "视听导航",
            "强化学习",
            "路径点设置",
            "声学记忆",
            "3D环境理解"
        ],
        "涉及的技术概念": {
            "动态路径点": "在导航策略中动态设置并学习的路径点，用于指导智能体在3D环境中的移动。",
            "声学记忆": "一个结构化、空间基础的系统，记录智能体在移动过程中所听到的声音，帮助理解环境布局。",
            "强化学习": "用于训练智能体在复杂环境中做出决策的方法，通过奖励机制优化导航策略。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 465,
        "title": "Learning Value Functions in Deep Policy Gradients using Residual Variance",
        "html": "https://iclr.cc//virtual/2021/poster/3319",
        "abstract": "Policy gradient algorithms have proven to be successful in diverse decision making and control tasks. However, these methods suffer from high sample complexity and instability issues. In this paper, we address these challenges by providing a different approach for training the critic in the actor-critic framework. Our work builds on recent studies indicating that traditional actor-critic algorithms do not succeed in fitting the true value function, calling for the need to identify a better objective for the critic. In our method, the critic uses a new state-value (resp. state-action-value) function approximation that learns the value of the states (resp. state-action pairs) relative to their mean value rather than the absolute value as in conventional actor-critic. We prove the theoretical consistency of the new gradient estimator and observe dramatic empirical improvement across a variety of continuous control tasks and algorithms. Furthermore, we validate our method in tasks with sparse rewards, where we provide experimental evidence and theoretical insights.",
        "conference": "ICLR",
        "中文标题": "在深度策略梯度中使用残差方差学习价值函数",
        "摘要翻译": "策略梯度算法已在多样化的决策制定和控制任务中证明是成功的。然而，这些方法存在高样本复杂性和不稳定性问题。在本文中，我们通过为演员-评论家框架中的评论家提供一种不同的训练方法来解决这些挑战。我们的工作基于最近的研究，这些研究表明传统的演员-评论家算法未能成功拟合真实的价值函数，因此需要为评论家确定一个更好的目标。在我们的方法中，评论家使用一种新的状态价值（或状态-动作价值）函数近似，学习状态（或状态-动作对）相对于其平均值的价值，而不是像传统演员-评论家那样学习绝对值。我们证明了新梯度估计器的理论一致性，并在各种连续控制任务和算法中观察到了显著的实证改进。此外，我们在奖励稀疏的任务中验证了我们的方法，提供了实验证据和理论见解。",
        "领域": "强化学习、连续控制、稀疏奖励任务",
        "问题": "解决策略梯度算法中的高样本复杂性和不稳定性问题",
        "动机": "传统演员-评论家算法未能成功拟合真实的价值函数，需要为评论家确定一个更好的目标",
        "方法": "提出一种新的状态价值（或状态-动作价值）函数近似方法，学习状态（或状态-动作对）相对于其平均值的价值",
        "关键词": [
            "策略梯度",
            "演员-评论家",
            "残差方差",
            "连续控制",
            "稀疏奖励"
        ],
        "涉及的技术概念": {
            "策略梯度": "一种直接优化策略以最大化预期回报的强化学习方法",
            "演员-评论家": "结合了价值函数近似（评论家）和策略优化（演员）的强化学习框架",
            "残差方差": "用于衡量状态或状态-动作对价值相对于其平均值的波动，作为新的学习目标"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 466,
        "title": "Learning 'What-if' Explanations for Sequential Decision-Making",
        "html": "https://iclr.cc//virtual/2021/poster/2854",
        "abstract": "Building interpretable parameterizations of real-world decision-making on the basis of demonstrated behavior--i.e. trajectories of observations and actions made by an expert maximizing some unknown reward function--is essential for introspecting and auditing policies in different institutions. In this paper, we propose learning explanations of expert decisions by modeling their reward function in terms of preferences with respect to ``'what if'' outcomes: Given the current history of observations, what would happen if we took a particular action? To learn these cost-benefit tradeoffs associated with the expert's actions, we integrate counterfactual reasoning into batch inverse reinforcement learning. This offers a principled way of defining reward functions and explaining expert behavior, and also satisfies the constraints of real-world decision-making---where active experimentation is often impossible (e.g. in healthcare). Additionally, by estimating the effects of different actions, counterfactuals readily tackle the off-policy nature of policy evaluation in the batch setting, and can naturally accommodate settings where the expert policies depend on histories of observations rather than just current states. Through illustrative experiments in both real and simulated medical environments, we highlight the effectiveness of our batch, counterfactual inverse reinforcement learning approach in recovering accurate and interpretable descriptions of behavior.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "学习顺序决策的‘假设’解释",
        "摘要翻译": "基于展示的行为——即专家在最大化某个未知奖励函数时做出的观察和行动的轨迹——构建现实世界决策的可解释参数化，对于在不同机构中内省和审计政策至关重要。在本文中，我们提出通过学习专家决策的解释，通过将他们的奖励函数建模为相对于‘假设’结果的偏好：给定当前的观察历史，如果我们采取特定的行动会发生什么？为了学习与专家行动相关的成本效益权衡，我们将反事实推理集成到批量逆强化学习中。这为定义奖励函数和解释专家行为提供了一种原则性的方法，并且也满足了现实世界决策的约束——在这些情况下，主动实验往往是不可能的（例如在医疗保健领域）。此外，通过估计不同行动的效果，反事实推理轻松应对了批量设置中政策评估的非政策性质，并且可以自然地适应专家政策依赖于观察历史而不仅仅是当前状态的设置。通过在真实和模拟的医疗环境中的说明性实验，我们强调了我们的批量、反事实逆强化学习方法在恢复准确且可解释的行为描述方面的有效性。",
        "领域": "逆强化学习",
        "问题": "如何基于专家的行为轨迹构建可解释的决策模型",
        "动机": "为了内省和审计不同机构中的政策，需要构建现实世界决策的可解释参数化",
        "方法": "将反事实推理集成到批量逆强化学习中，以学习专家决策的解释",
        "关键词": [
            "逆强化学习",
            "反事实推理",
            "决策解释",
            "批量学习",
            "医疗决策"
        ],
        "涉及的技术概念": {
            "逆强化学习": "用于从专家的行为轨迹中学习奖励函数的技术",
            "反事实推理": "用于估计采取不同行动可能结果的技术，帮助理解专家决策",
            "批量学习": "在无法进行主动实验的环境中，从固定数据集学习的方法"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 467,
        "title": "Learning What To Do by Simulating the Past",
        "html": "https://iclr.cc//virtual/2021/poster/2954",
        "abstract": "Since reward functions are hard to specify, recent work has focused on learning policies from human feedback. However, such approaches are impeded by the expense of acquiring such feedback. Recent work proposed that agents have access to a source of information that is effectively free: in any environment that humans have acted in, the state will already be optimized for human preferences, and thus an agent can extract information about what humans want from the state. Such learning is possible in principle, but requires simulating all possible past trajectories that could have led to the observed state. This is feasible in gridworlds, but how do we scale it to complex tasks? In this work, we show that by combining a learned feature encoder with learned inverse models, we can enable agents to simulate human actions backwards in time to infer what they must have done. The resulting algorithm is able to reproduce a specific skill in MuJoCo environments given a single state sampled from the optimal policy for that skill.",
        "conference": "ICLR",
        "中文标题": "通过模拟过去学习该做什么",
        "摘要翻译": "由于奖励函数难以指定，最近的研究集中在从人类反馈中学习策略。然而，这种方法因获取反馈的高成本而受到阻碍。最近的研究提出，代理可以访问一种几乎免费的信息源：在任何人类活动过的环境中，状态已经被优化以适应人类偏好，因此代理可以从状态中提取关于人类需求的信息。这种学习在理论上是可行的，但需要模拟所有可能导致观察状态的过去轨迹。这在网格世界中是可行的，但我们如何将其扩展到复杂任务中？在这项工作中，我们展示了通过将学习到的特征编码器与学习的逆模型相结合，可以使代理模拟人类在时间上的反向行动，以推断他们必须做了什么。所得到的算法能够在MuJoCo环境中复制特定技能，给定从该技能的最优策略中采样的单一状态。",
        "领域": "强化学习、人机交互、机器人学习",
        "问题": "如何在不依赖昂贵的人类反馈的情况下，学习适应人类偏好的策略",
        "动机": "减少从人类反馈中学习策略的成本，利用环境中已有的状态信息来推断人类偏好",
        "方法": "结合学习到的特征编码器和逆模型，模拟人类过去的行动以推断其偏好",
        "关键词": [
            "强化学习",
            "逆模型",
            "人类偏好",
            "MuJoCo",
            "策略学习"
        ],
        "涉及的技术概念": {
            "逆模型": "用于模拟人类过去的行动，以推断导致当前状态的行为",
            "特征编码器": "用于从环境中提取有用的特征信息，帮助理解人类偏好",
            "MuJoCo": "一个物理模拟环境，用于测试和验证算法在复杂任务中的表现"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 468,
        "title": "Learning with AMIGo: Adversarially Motivated Intrinsic Goals",
        "html": "https://iclr.cc//virtual/2021/poster/2781",
        "abstract": "A key challenge for reinforcement learning (RL) consists of learning in environments with sparse extrinsic rewards. In contrast to current RL methods, humans are able to learn new skills with little or no reward by using various forms of intrinsic motivation. We propose AMIGo, a novel agent incorporating -- as form of meta-learning -- a goal-generating teacher that proposes Adversarially Motivated Intrinsic Goals to train a goal-conditioned 'student' policy in the absence of (or alongside) environment reward. Specifically, through a simple but effective 'constructively adversarial' objective, the teacher learns to propose increasingly challenging -- yet achievable -- goals that allow the student to learn general skills for acting in a new environment, independent of the task to be solved. We show that our method generates a natural curriculum of self-proposed goals which ultimately allows the agent to solve challenging procedurally-generated tasks where other forms of intrinsic motivation and state-of-the-art RL methods fail.",
        "conference": "ICLR",
        "中文标题": "与AMIGo共学：对抗性驱动的内在目标",
        "摘要翻译": "强化学习（RL）面临的一个关键挑战是在稀疏外在奖励的环境中学习。与当前的RL方法不同，人类能够通过使用各种形式的内在动机，在几乎没有奖励的情况下学习新技能。我们提出了AMIGo，这是一种新颖的智能体，它作为一种元学习形式，包含了一个目标生成的教师，该教师提出对抗性驱动的内在目标，以在没有（或同时有）环境奖励的情况下训练一个目标条件的'学生'策略。具体来说，通过一个简单但有效的'建设性对抗'目标，教师学会提出越来越具有挑战性——但可实现——的目标，这些目标使学生能够学习在新环境中行动的一般技能，独立于要解决的任务。我们展示了我们的方法生成了一个自然的自提议目标课程，最终使智能体能够解决其他形式的内在动机和最先进的RL方法无法解决的具有挑战性的程序生成任务。",
        "领域": "强化学习、元学习、程序生成任务",
        "问题": "在稀疏外在奖励的环境中学习新技能",
        "动机": "通过内在动机模仿人类学习新技能的能力，解决强化学习在稀疏奖励环境中的学习效率问题",
        "方法": "提出AMIGo智能体，通过对抗性驱动的内在目标生成教师，训练目标条件的学生策略",
        "关键词": [
            "强化学习",
            "内在动机",
            "对抗性学习",
            "元学习",
            "程序生成任务"
        ],
        "涉及的技术概念": {
            "对抗性驱动的内在目标": "教师智能体生成的目标，旨在通过对抗性学习机制提高学生策略的学习效率和泛化能力",
            "目标条件的学生策略": "一种能够根据特定目标调整其行为的策略，通过学习实现教师提出的目标来获得技能",
            "建设性对抗目标": "一种设计目标的方法，确保目标既具有挑战性又能够实现，以促进学生策略的有效学习"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 469,
        "title": "Learning with Feature-Dependent Label Noise: A Progressive Approach",
        "html": "https://iclr.cc//virtual/2021/poster/2708",
        "abstract": "Label noise is frequently observed in real-world large-scale datasets. The noise is introduced due to a variety of reasons; it is heterogeneous and feature-dependent. Most existing approaches to handling noisy labels fall into two categories: they either assume an ideal feature-independent noise, or remain heuristic without theoretical guarantees. In this paper, we propose to target a new family of feature-dependent label noise, which is much more general than commonly used i.i.d. label noise and encompasses a broad spectrum of noise patterns. Focusing on this general noise family, we propose a progressive label correction algorithm that iteratively corrects labels and refines the model. We provide theoretical guarantees showing that for a wide variety of (unknown) noise patterns, a classifier trained with this strategy converges to be consistent with the Bayes classifier. In experiments, our method outperforms SOTA baselines and is robust to various noise types and levels.",
        "conference": "ICLR",
        "中文标题": "特征依赖标签噪声下的学习：一种渐进式方法",
        "摘要翻译": "在现实世界的大规模数据集中，标签噪声经常被观察到。这种噪声由于多种原因被引入；它是异质的且依赖于特征的。大多数现有的处理噪声标签的方法分为两类：它们要么假设一个理想的特征独立噪声，要么保持启发式而没有理论保证。在本文中，我们提出针对一种新的特征依赖标签噪声家族，这比常用的独立同分布标签噪声更为普遍，并包含广泛的噪声模式。针对这一普遍的噪声家族，我们提出了一种渐进式标签校正算法，该算法迭代地校正标签并优化模型。我们提供了理论保证，表明对于多种（未知）噪声模式，使用这一策略训练的分类器将收敛到与贝叶斯分类器一致。在实验中，我们的方法优于最先进的基线，并且对各种噪声类型和水平都具有鲁棒性。",
        "领域": "机器学习噪声鲁棒性、深度学习理论、数据清洗与预处理",
        "问题": "如何处理现实世界数据集中普遍存在的特征依赖标签噪声问题",
        "动机": "现有的噪声标签处理方法大多假设噪声与特征无关或缺乏理论保证，无法有效处理更普遍的特征依赖噪声",
        "方法": "提出一种渐进式标签校正算法，通过迭代校正标签和优化模型来处理特征依赖噪声",
        "关键词": [
            "特征依赖噪声",
            "渐进式校正",
            "标签噪声鲁棒性",
            "贝叶斯分类器一致性",
            "噪声模式多样性"
        ],
        "涉及的技术概念": {
            "特征依赖标签噪声": "指噪声的分布依赖于数据的特征，比独立同分布噪声更普遍和复杂",
            "渐进式标签校正算法": "通过迭代过程校正噪声标签并优化模型性能的方法",
            "贝叶斯分类器一致性": "算法保证在多种噪声模式下，训练的分类器将收敛到与最优贝叶斯分类器一致"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 470,
        "title": "Learning with Instance-Dependent Label Noise: A Sample Sieve Approach",
        "html": "https://iclr.cc//virtual/2021/poster/2755",
        "abstract": "Human-annotated labels are often prone to noise, and the presence of such noise will degrade the performance of the resulting deep neural network (DNN) models. Much of the literature (with several recent exceptions) of learning with noisy labels focuses on the case when the label noise is independent of features. Practically, annotations errors tend to be instance-dependent and often depend on the difficulty levels of recognizing a certain task. Applying existing results from instance-independent settings would require a significant amount of estimation of noise rates. Therefore, providing theoretically rigorous solutions for learning with instance-dependent label noise remains a challenge. In this paper, we propose CORES$^{2}$ (COnfidence REgularized Sample Sieve), which progressively sieves out corrupted examples. The implementation of CORES$^{2}$  does not require specifying noise rates and yet we are able to provide theoretical guarantees of CORES$^{2}$ in filtering out the corrupted examples. This high-quality sample sieve allows us to treat clean examples and the corrupted ones separately in training a DNN solution, and such a separation is shown to be advantageous in the instance-dependent noise setting. We demonstrate the performance of CORES$^{2}$ on CIFAR10 and CIFAR100 datasets with synthetic instance-dependent label noise and Clothing1M with real-world human noise. As of independent interests, our sample sieve provides a generic machinery for anatomizing noisy datasets and provides a flexible interface for various robust training techniques to further improve the performance. Code is available at https://github.com/UCSC-REAL/cores.",
        "conference": "ICLR",
        "中文标题": "学习实例依赖标签噪声：一种样本筛选方法",
        "摘要翻译": "人工标注的标签往往容易受到噪声的影响，这种噪声的存在会降低最终深度神经网络（DNN）模型的性能。大量关于带噪声标签学习的文献（除了一些最近的例外）集中在标签噪声与特征无关的情况下。实际上，标注错误往往是实例依赖的，并且常常依赖于识别特定任务的难度级别。应用来自实例无关设置的现有结果将需要大量的噪声率估计。因此，为实例依赖标签噪声学习提供理论严谨的解决方案仍然是一个挑战。在本文中，我们提出了CORES$^{2}$（置信度正则化样本筛选），它逐步筛选出被污染的样本。CORES$^{2}$的实现不需要指定噪声率，但我们能够提供CORES$^{2}$在过滤被污染样本方面的理论保证。这种高质量的样本筛选使我们能够在训练DNN解决方案时分别处理干净样本和被污染的样本，并且这种分离在实例依赖噪声设置中显示出优势。我们在带有合成实例依赖标签噪声的CIFAR10和CIFAR100数据集以及带有真实世界人类噪声的Clothing1M上展示了CORES$^{2}$的性能。作为独立兴趣，我们的样本筛选提供了一种通用的机制来解剖噪声数据集，并为各种鲁棒训练技术提供了灵活的接口，以进一步提高性能。代码可在https://github.com/UCSC-REAL/cores获取。",
        "领域": "深度学习噪声鲁棒性、计算机视觉数据清洗、实例依赖噪声处理",
        "问题": "解决实例依赖标签噪声对深度神经网络性能的影响问题",
        "动机": "实例依赖的标签噪声在实际应用中普遍存在，但现有方法大多假设噪声与实例无关，这限制了它们在现实场景中的应用效果。",
        "方法": "提出CORES$^{2}$方法，通过置信度正则化逐步筛选出被污染的样本，无需预先指定噪声率，并在训练中分别处理干净和被污染的样本。",
        "关键词": [
            "实例依赖噪声",
            "样本筛选",
            "置信度正则化",
            "深度神经网络",
            "噪声鲁棒性"
        ],
        "涉及的技术概念": {
            "实例依赖标签噪声": "指标签噪声与数据实例的特征或识别难度相关，不同于传统假设中噪声与实例无关的情况。",
            "置信度正则化": "通过正则化技术调整模型对样本预测的置信度，用于区分干净样本和被污染样本。",
            "样本筛选": "一种逐步识别和分离被污染样本的技术，旨在提高模型在噪声数据上的鲁棒性和性能。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 471,
        "title": "Lifelong Learning of Compositional Structures",
        "html": "https://iclr.cc//virtual/2021/poster/2733",
        "abstract": "A hallmark of human intelligence is the ability to construct self-contained chunks of knowledge and adequately reuse them in novel combinations for solving different yet structurally related problems. Learning such compositional structures has been a significant challenge for artificial systems, due to the combinatorial nature of the underlying search problem. To date, research into compositional learning has largely proceeded separately from work on lifelong or continual learning. We integrate these two lines of work to present a general-purpose framework for lifelong learning of compositional structures that can be used for solving a stream of related tasks. Our framework separates the learning process into two broad stages: learning how to best combine existing components in order to assimilate a novel problem, and learning how to adapt the set of existing components to accommodate the new problem. This separation explicitly handles the trade-off between the stability required to remember how to solve earlier tasks and the flexibility required to solve new tasks, as we show empirically in an extensive evaluation.",
        "conference": "ICLR",
        "中文标题": "终身学习组合结构",
        "摘要翻译": "人类智能的一个标志是能够构建自包含的知识块，并在解决不同但结构相关的问题时，适当地在新组合中重用它们。对于人工系统来说，由于底层搜索问题的组合性质，学习这样的组合结构一直是一个重大挑战。迄今为止，组合学习的研究与终身或持续学习的工作基本上是分开进行的。我们将这两条工作线整合起来，提出了一个用于终身学习组合结构的通用框架，该框架可用于解决一系列相关任务。我们的框架将学习过程分为两个主要阶段：学习如何最佳组合现有组件以吸收新问题，以及学习如何调整现有组件集以适应新问题。正如我们在广泛评估中所展示的那样，这种分离明确处理了记住如何解决早期任务所需的稳定性与解决新任务所需的灵活性之间的权衡。",
        "领域": "终身学习、组合学习、持续学习",
        "问题": "如何在人工系统中实现终身学习组合结构，以解决一系列相关任务",
        "动机": "整合组合学习与终身学习的研究，以解决人工系统在学习组合结构和适应新任务方面的挑战",
        "方法": "提出一个两阶段学习框架，第一阶段学习如何组合现有组件吸收新问题，第二阶段学习如何调整组件集以适应新问题",
        "关键词": [
            "终身学习",
            "组合结构",
            "持续学习",
            "知识重用",
            "任务适应性"
        ],
        "涉及的技术概念": {
            "组合学习": "学习如何构建和重用自包含的知识块以解决结构相关的问题",
            "终身学习": "系统在整个生命周期内持续学习新任务而不忘记旧任务的能力",
            "稳定性与灵活性权衡": "在记住如何解决早期任务和适应新任务之间找到平衡的关键挑战"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 472,
        "title": "LiftPool: Bidirectional ConvNet Pooling",
        "html": "https://iclr.cc//virtual/2021/poster/3154",
        "abstract": "Pooling is a critical operation in convolutional neural networks for increasing receptive fields and improving robustness to input variations. Most existing pooling operations downsample the feature maps,  which is a lossy process.   Moreover, they are not invertible: upsampling a downscaled feature map can not recover the lost information in the downsampling.  By adopting the philosophy of the classical Lifting Scheme from signal processing, we propose LiftPool for bidirectional pooling layers, including LiftDownPool and LiftUpPool.  LiftDownPool decomposes a feature map into various downsized sub-bands,  each of which contains information with different frequencies. As the pooling function in LiftDownPool is perfectly invertible, by performing LiftDownPool backward, a corresponding up-pooling layer LiftUpPool is able to generate a refined upsampled feature map using the detail subbands, which is useful for image-to-image translation challenges.  Experiments show the proposed methods achieve better results on image classification and semantic segmentation,  using various backbones. Moreover, LiftDownPool offers better robustness to input corruptions and perturbations.",
        "conference": "ICLR",
        "中文标题": "LiftPool：双向卷积网络池化",
        "摘要翻译": "池化是卷积神经网络中用于增大感受野和提高对输入变化鲁棒性的关键操作。大多数现有的池化操作会对特征图进行下采样，这是一个有损的过程。此外，它们是不可逆的：对下采样后的特征图进行上采样无法恢复在下采样过程中丢失的信息。通过采用信号处理中经典提升方案的哲学，我们提出了用于双向池化层的LiftPool，包括LiftDownPool和LiftUpPool。LiftDownPool将特征图分解为各种尺寸缩小的子带，每个子带包含不同频率的信息。由于LiftDownPool中的池化函数是完全可逆的，通过反向执行LiftDownPool，相应的上池化层LiftUpPool能够使用细节子带生成一个精细化的上采样特征图，这对于图像到图像的转换挑战非常有用。实验表明，所提出的方法在使用各种骨干网络时，在图像分类和语义分割上取得了更好的结果。此外，LiftDownPool对输入损坏和扰动提供了更好的鲁棒性。",
        "领域": "图像分类, 语义分割, 图像到图像转换",
        "问题": "解决现有池化操作中的信息丢失和不可逆性问题",
        "动机": "提高卷积神经网络中池化操作的信息保留能力和可逆性，以改善图像分类和语义分割的性能",
        "方法": "采用信号处理中的提升方案哲学，设计双向池化层LiftPool，包括下池化层LiftDownPool和上池化层LiftUpPool，实现特征图的可逆分解与重构",
        "关键词": [
            "双向池化",
            "提升方案",
            "图像分类",
            "语义分割",
            "图像到图像转换"
        ],
        "涉及的技术概念": {
            "LiftDownPool": "下池化层，将特征图分解为不同频率的子带，保留更多信息",
            "LiftUpPool": "上池化层，利用LiftDownPool的子带信息进行特征图的上采样和重构",
            "提升方案": "信号处理中的一种技术，用于实现信号的可逆分解与重构，被应用于设计双向池化层"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 473,
        "title": "Linear Convergent Decentralized Optimization with Compression",
        "html": "https://iclr.cc//virtual/2021/poster/2693",
        "abstract": "Communication compression has become a key strategy to speed up distributed optimization. However, existing decentralized algorithms with compression mainly focus on compressing DGD-type algorithms. They are unsatisfactory in terms of convergence rate, stability, and the capability to handle heterogeneous data. Motivated by primal-dual algorithms, this paper proposes the first \\underline{L}in\\underline{EA}r convergent \\underline{D}ecentralized algorithm with compression, LEAD. Our theory describes the coupled dynamics of the inexact primal and dual update as well as compression error, and we provide the first consensus error bound in such settings without assuming bounded gradients. Experiments on convex problems validate our theoretical analysis, and empirical study on deep neural nets shows that LEAD is applicable to non-convex problems.",
        "conference": "ICLR",
        "中文标题": "线性收敛的压缩去中心化优化",
        "摘要翻译": "通信压缩已成为加速分布式优化的关键策略。然而，现有的带有压缩的去中心化算法主要集中于压缩DGD类型算法。它们在收敛速度、稳定性以及处理异构数据的能力方面不尽如人意。受原始对偶算法的启发，本文提出了第一个带有压缩的线性收敛去中心化算法LEAD。我们的理论描述了不精确的原始和双重更新以及压缩误差的耦合动态，并且我们首次在这样的设置下提供了共识误差界限，而无需假设梯度有界。在凸问题上的实验验证了我们的理论分析，而在深度神经网络上的实证研究表明LEAD适用于非凸问题。",
        "领域": "分布式优化、去中心化学习、通信压缩",
        "问题": "解决现有带有压缩的去中心化算法在收敛速度、稳定性和处理异构数据能力方面的不足",
        "动机": "受原始对偶算法的启发，开发一种线性收敛的去中心化优化算法，以克服现有方法的局限性",
        "方法": "提出LEAD算法，通过理论分析不精确的原始和双重更新及压缩误差的耦合动态，并在实验中验证其有效性",
        "关键词": [
            "去中心化优化",
            "通信压缩",
            "线性收敛",
            "原始对偶算法",
            "异构数据处理"
        ],
        "涉及的技术概念": {
            "原始对偶算法": "用于开发LEAD算法的基础，旨在优化分布式系统中的问题",
            "通信压缩": "减少分布式优化中的通信开销，提高效率",
            "共识误差界限": "在无需假设梯度有界的情况下，首次提供了共识误差的理论界限"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 474,
        "title": "Linear Last-iterate Convergence in Constrained Saddle-point Optimization",
        "html": "https://iclr.cc//virtual/2021/poster/3218",
        "abstract": "Optimistic Gradient Descent Ascent (OGDA) and Optimistic Multiplicative Weights Update (OMWU) for saddle-point optimization have received growing attention due to their favorable last-iterate convergence. However, their behaviors for simple bilinear games over the probability simplex are still not fully understood --- previous analysis lacks explicit convergence rates, only applies to an exponentially small learning rate, or requires additional assumptions such as the uniqueness of the optimal solution.\n\nIn this work, we significantly expand the understanding of last-iterate convergence for OGDA and OMWU in the constrained setting. Specifically, for OMWU in bilinear games over the simplex, we show that when the equilibrium is unique, linear last-iterate convergence is achievable with a constant learning rate, which improves the result of (Daskalakis & Panageas, 2019) under the same assumption. We then significantly extend the results to more general objectives and feasible sets for the projected OGDA algorithm, by introducing a sufficient condition under which OGDA exhibits concrete last-iterate convergence rates with a constant learning rate. We show that bilinear games over any polytope satisfy this condition and OGDA converges exponentially fast even without the unique equilibrium assumption. Our condition also holds for strongly-convex-strongly-concave functions, recovering the result of (Hsieh et al., 2019). Finally, we provide experimental results to further support our theory. ",
        "conference": "ICLR",
        "中文标题": "约束鞍点优化中的线性最后迭代收敛",
        "摘要翻译": "乐观梯度下降上升法（OGDA）和乐观乘法权重更新法（OMWU）在鞍点优化中因其良好的最后迭代收敛性而受到越来越多的关注。然而，对于概率单纯形上的简单双线性游戏，它们的行为仍未完全理解——之前的分析缺乏明确的收敛速率，仅适用于指数级小的学习率，或需要额外的假设，如最优解的唯一性。在这项工作中，我们显著扩展了对OGDA和OMWU在约束设置下最后迭代收敛的理解。具体来说，对于单纯形上的双线性游戏中的OMWU，我们展示了当均衡唯一时，使用恒定学习率可以实现线性最后迭代收敛，这改进了（Daskalakis & Panageas, 2019）在相同假设下的结果。然后，我们通过引入一个充分条件，将结果显著扩展到投影OGDA算法的更一般目标和可行集上，在该条件下OGDA表现出具体的最后迭代收敛速率与恒定学习率。我们展示了任何多面体上的双线性游戏都满足这一条件，并且OGDA即使在没有唯一均衡假设的情况下也能指数级快速收敛。我们的条件也适用于强凸-强凹函数，恢复了（Hsieh et al., 2019）的结果。最后，我们提供了实验结果以进一步支持我们的理论。",
        "领域": "优化算法、博弈论、机器学习",
        "问题": "理解并改进OGDA和OMWU在约束鞍点优化中的最后迭代收敛行为",
        "动机": "现有分析对OGDA和OMWU在简单双线性游戏中的行为理解不足，缺乏明确的收敛速率或需要强假设",
        "方法": "通过引入充分条件，扩展OGDA和OMWU在更一般目标和可行集上的最后迭代收敛理论，并进行实验验证",
        "关键词": [
            "乐观梯度下降上升法",
            "乐观乘法权重更新法",
            "最后迭代收敛",
            "双线性游戏",
            "强凸-强凹函数"
        ],
        "涉及的技术概念": {
            "乐观梯度下降上升法（OGDA）": "一种用于鞍点优化的算法，通过结合当前和过去的梯度信息来更新参数，以实现更好的收敛性能",
            "乐观乘法权重更新法（OMWU）": "一种在博弈论和优化中使用的算法，通过乐观地更新权重来寻找均衡点",
            "最后迭代收敛": "指优化算法在迭代过程中的最后一步达到收敛状态的性质，与平均收敛或遍历收敛相对"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 475,
        "title": "Linear Mode Connectivity in Multitask and Continual Learning",
        "html": "https://iclr.cc//virtual/2021/poster/2876",
        "abstract": "Continual (sequential) training and multitask (simultaneous) training are often attempting to solve the same overall objective: to find a solution that performs well on all considered tasks. The main difference is in the training regimes, where continual learning can only have access to one task at a time, which for neural networks typically leads to catastrophic forgetting. That is, the solution found for a subsequent task does not perform well on the previous ones anymore. \n    However, the relationship between the different minima that the two training regimes arrive at is not well understood. What sets them apart? Is there a local structure that could explain the difference in performance achieved by the two different schemes? \n    Motivated by recent work showing that different minima of the same task are typically connected by very simple curves of low error, we investigate whether multitask and continual solutions are similarly connected. We empirically find that indeed such connectivity can be reliably achieved and, more interestingly, it can be done by a linear path, conditioned on having the same initialization for both. We thoroughly analyze this observation and discuss its significance for the continual learning process.\n    Furthermore, we exploit this finding to propose an effective algorithm that constrains the sequentially learned minima to behave as the multitask solution.  We show that our method outperforms several state of the art continual learning algorithms on various vision benchmarks.",
        "conference": "ICLR",
        "中文标题": "多任务与持续学习中的线性模式连接性",
        "摘要翻译": "持续（顺序）训练和多任务（同时）训练通常试图解决相同的总体目标：找到一个在所有考虑的任务上表现良好的解决方案。主要区别在于训练机制，持续学习一次只能访问一个任务，这对于神经网络通常会导致灾难性遗忘。也就是说，为后续任务找到的解决方案在之前的任务上不再表现良好。然而，两种训练机制达到的不同最小值之间的关系尚不明确。是什么使它们不同？是否存在可以解释两种不同方案实现性能差异的局部结构？受到最近工作的启发，该工作表明同一任务的不同最小值通常通过非常简单的低误差曲线连接，我们调查多任务和持续解决方案是否类似地连接。我们实证发现，确实可以实现这种连接性，更有趣的是，它可以通过线性路径实现，条件是两者具有相同的初始化。我们全面分析了这一观察结果，并讨论了它对持续学习过程的意义。此外，我们利用这一发现提出了一种有效的算法，该算法约束顺序学习的最小值表现得像多任务解决方案。我们展示了我们的方法在各种视觉基准上优于几种最先进的持续学习算法。",
        "领域": "持续学习, 多任务学习, 神经网络优化",
        "问题": "探索多任务学习和持续学习解决方案之间的连接性及其对灾难性遗忘的影响",
        "动机": "理解多任务和持续学习解决方案之间的差异，并探索如何通过线性路径连接它们以减少灾难性遗忘",
        "方法": "通过实证研究验证多任务和持续学习解决方案可以通过线性路径连接，并基于此提出一种新算法以优化持续学习过程",
        "关键词": [
            "持续学习",
            "多任务学习",
            "线性连接性",
            "灾难性遗忘",
            "神经网络优化"
        ],
        "涉及的技术概念": {
            "线性模式连接性": "研究多任务和持续学习解决方案之间是否存在简单的线性路径连接",
            "灾难性遗忘": "神经网络在持续学习过程中忘记之前学习任务的现象",
            "初始化条件": "确保多任务和持续学习解决方案具有相同的初始化条件，以便研究它们之间的连接性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 476,
        "title": "Lipschitz Recurrent Neural Networks",
        "html": "https://iclr.cc//virtual/2021/poster/3112",
        "abstract": "Viewing recurrent neural networks (RNNs) as continuous-time dynamical systems, we propose a recurrent unit that describes the hidden state's evolution with two parts: a well-understood linear component plus a Lipschitz nonlinearity. This particular functional form facilitates stability analysis of the long-term behavior of the recurrent unit using tools from nonlinear systems theory. In turn, this enables architectural design decisions before experimentation. Sufficient conditions for global stability of the recurrent unit are obtained, motivating a novel scheme for constructing hidden-to-hidden matrices. Our experiments demonstrate that the Lipschitz RNN can outperform existing recurrent units on a range of benchmark tasks, including computer vision, language modeling and speech prediction tasks. Finally, through Hessian-based analysis we demonstrate that our Lipschitz recurrent unit is more robust with respect to input and parameter perturbations as compared to other continuous-time RNNs.",
        "conference": "ICLR",
        "中文标题": "Lipschitz循环神经网络",
        "摘要翻译": "将循环神经网络（RNNs）视为连续时间动态系统，我们提出了一种循环单元，该单元通过两部分描述隐藏状态的演化：一个易于理解的线性组件加上一个Lipschitz非线性。这种特定的函数形式便于使用非线性系统理论的工具对循环单元的长期行为进行稳定性分析。这反过来使得在实验之前进行架构设计决策成为可能。我们获得了循环单元全局稳定性的充分条件，激发了一种构建隐藏到隐藏矩阵的新方案。我们的实验表明，Lipschitz RNN在一系列基准任务上可以超越现有的循环单元，包括计算机视觉、语言建模和语音预测任务。最后，通过基于Hessian的分析，我们证明了与其他连续时间RNN相比，我们的Lipschitz循环单元在输入和参数扰动方面更加稳健。",
        "领域": "循环神经网络优化、语言建模、语音识别",
        "问题": "如何设计一个更稳定和鲁棒的循环神经网络单元",
        "动机": "为了解决现有循环神经网络在长期行为稳定性和对输入及参数扰动的鲁棒性方面的问题",
        "方法": "提出了一种结合线性组件和Lipschitz非线性的循环单元，利用非线性系统理论进行稳定性分析，并通过实验验证其性能",
        "关键词": [
            "Lipschitz非线性",
            "稳定性分析",
            "循环神经网络优化",
            "语言建模",
            "语音识别"
        ],
        "涉及的技术概念": {
            "Lipschitz非线性": "用于描述隐藏状态演化的非线性部分，保证系统的稳定性和可预测性",
            "稳定性分析": "利用非线性系统理论的工具分析循环单元的长期行为，确保其稳定性",
            "Hessian-based分析": "通过Hessian矩阵分析循环单元对输入和参数扰动的鲁棒性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 477,
        "title": "Local Convergence Analysis of Gradient Descent Ascent with Finite Timescale Separation",
        "html": "https://iclr.cc//virtual/2021/poster/3036",
        "abstract": "We study the role that a finite timescale separation parameter $\\tau$ has on gradient descent-ascent in non-convex, non-concave zero-sum games where the learning rate of player 1 is denoted by $\\gamma_1$ and the learning rate of player 2 is defined to be $\\gamma_2=\\tau\\gamma_1$. We provide a non-asymptotic construction of the finite timescale separation parameter $\\tau^{\\ast}$ such that gradient descent-ascent locally converges to  $x^{\\ast}$ for all $\\tau \\in (\\tau^{\\ast}, \\infty)$ if and only if it is a strict local minmax equilibrium. Moreover, we provide explicit local convergence rates given the finite timescale separation. The convergence results we present are complemented by a non-convergence result: given a critical point $x^{\\ast}$ that is not a strict local minmax equilibrium, we present a non-asymptotic construction of a finite timescale separation $\\tau_{0}$ such that gradient descent-ascent with timescale separation $\\tau\\in (\\tau_0, \\infty)$ does not converge to $x^{\\ast}$. Finally, we extend the results to gradient penalty regularization methods for generative adversarial networks and empirically demonstrate on CIFAR-10 and CelebA the significant impact timescale separation has on training performance. ",
        "conference": "ICLR",
        "中文标题": "梯度下降上升法有限时间尺度分离的局部收敛性分析",
        "摘要翻译": "我们研究了在非凸、非凹零和博弈中，有限时间尺度分离参数τ对梯度下降上升法的作用，其中玩家1的学习率记为γ1，玩家2的学习率定义为γ2=τγ1。我们提供了有限时间尺度分离参数τ*的非渐近构造，使得梯度下降上升法局部收敛到x*对于所有τ∈(τ*,∞)当且仅当它是一个严格的局部最小最大均衡。此外，我们给出了给定有限时间尺度分离的显式局部收敛率。我们提出的收敛结果由一个不收敛结果补充：给定一个不是严格局部最小最大均衡的临界点x*，我们提出了一个有限时间尺度分离τ0的非渐近构造，使得具有时间尺度分离τ∈(τ0,∞)的梯度下降上升法不收敛到x*。最后，我们将结果扩展到生成对抗网络的梯度惩罚正则化方法，并在CIFAR-10和CelebA上实证展示了时间尺度分离对训练性能的显著影响。",
        "领域": "生成对抗网络、优化算法、博弈论",
        "问题": "在非凸、非凹零和博弈中，有限时间尺度分离参数τ如何影响梯度下降上升法的局部收敛性",
        "动机": "研究梯度下降上升法在特定条件下的收敛性，以优化生成对抗网络等应用的训练过程",
        "方法": "通过非渐近构造有限时间尺度分离参数τ*，分析梯度下降上升法的局部收敛性，并扩展到梯度惩罚正则化方法",
        "关键词": [
            "梯度下降上升法",
            "时间尺度分离",
            "局部收敛性",
            "生成对抗网络",
            "优化算法"
        ],
        "涉及的技术概念": {
            "梯度下降上升法": "一种用于解决零和博弈中优化问题的算法，通过交替执行梯度下降和上升来更新玩家策略",
            "时间尺度分离": "指不同玩家学习率的比例关系，影响算法的收敛行为和性能",
            "局部最小最大均衡": "博弈论中的一种均衡概念，表示在局部范围内玩家无法单方面改善自己的策略"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 478,
        "title": "Locally Free Weight Sharing for Network Width Search",
        "html": "https://iclr.cc//virtual/2021/poster/2839",
        "abstract": "Searching for network width is an effective way to slim deep neural networks with hardware budgets. With this aim, a one-shot supernet is usually leveraged as a performance evaluator to rank the performance \\wrt~different width. Nevertheless, current methods mainly follow a manually fixed weight sharing pattern, which is limited to distinguish the performance gap of different width. In this paper, to better evaluate each width, we propose a locally free weight sharing strategy (CafeNet) accordingly. In CafeNet, weights are more freely shared, and each width is jointly indicated by its base channels and free channels, where free channels are supposed to locate freely in a local zone to better represent each width. Besides, we propose to further reduce the search space by leveraging our introduced FLOPs-sensitive bins. As a result, our CafeNet can be trained stochastically and get optimized within a min-min strategy. Extensive experiments on ImageNet, CIFAR-10, CelebA and MS COCO dataset have verified our superiority comparing to other state-of-the-art baselines. For example, our method can further boost the benchmark NAS network EfficientNet-B0 by 0.41\\% via searching its width more delicately.",
        "conference": "ICLR",
        "中文标题": "局部自由权重共享用于网络宽度搜索",
        "摘要翻译": "搜索网络宽度是一种在硬件预算下精简深度神经网络的有效方法。为此，通常使用一次性超级网络作为性能评估器，以对不同宽度下的性能进行排名。然而，当前的方法主要遵循手动固定的权重共享模式，这限制了区分不同宽度性能差距的能力。在本文中，为了更好地评估每个宽度，我们相应地提出了一种局部自由权重共享策略（CafeNet）。在CafeNet中，权重更自由地共享，每个宽度由其基础通道和自由通道共同指示，其中自由通道被假定在局部区域内自由定位，以更好地代表每个宽度。此外，我们提出通过利用我们引入的FLOPs敏感箱来进一步减少搜索空间。因此，我们的CafeNet可以随机训练，并在最小-最小策略内进行优化。在ImageNet、CIFAR-10、CelebA和MS COCO数据集上的大量实验验证了我们相对于其他最先进基线的优越性。例如，我们的方法可以通过更精细地搜索其宽度，进一步将基准NAS网络EfficientNet-B0提升0.41%。",
        "领域": "神经网络架构搜索",
        "问题": "如何更有效地评估和搜索深度神经网络的最优宽度配置",
        "动机": "当前固定权重共享模式限制了不同网络宽度性能的准确评估，需要一种更自由和灵活的权重共享策略来提升性能评估的准确性",
        "方法": "提出局部自由权重共享策略（CafeNet），通过基础通道和自由通道的组合来表示网络宽度，并利用FLOPs敏感箱减少搜索空间",
        "关键词": [
            "网络宽度搜索",
            "权重共享",
            "神经网络架构搜索",
            "性能评估",
            "FLOPs敏感箱"
        ],
        "涉及的技术概念": {
            "局部自由权重共享": "在CafeNet中，权重在局部区域内自由共享，以更灵活地表示不同网络宽度",
            "FLOPs敏感箱": "用于减少搜索空间的技术，通过考虑计算量（FLOPs）来优化网络宽度的搜索过程",
            "最小-最小策略": "一种优化策略，用于在训练过程中同时最小化网络宽度和性能损失"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 479,
        "title": "Local Search Algorithms for Rank-Constrained Convex Optimization",
        "html": "https://iclr.cc//virtual/2021/poster/3273",
        "abstract": "We propose greedy and local search algorithms for rank-constrained convex optimization, namely solving $\\underset{\\mathrm{rank}(A)\\leq r^*}{\\min}\\, R(A)$ given a convex function $R:\\mathbb{R}^{m\\times n}\\rightarrow \\mathbb{R}$ and a parameter $r^*$. These algorithms consist of repeating two steps: (a) adding a new rank-1 matrix to $A$ and (b) enforcing the rank constraint on $A$. We refine and improve the theoretical analysis of Shalev-Shwartz et al. (2011), and show that if the rank-restricted condition number of $R$ is $\\kappa$, a solution $A$ with rank $O(r^*\\cdot \\min\\{\\kappa \\log \\frac{R(\\mathbf{0})-R(A^*)}{\\epsilon}, \\kappa^2\\})$ and $R(A) \\leq R(A^*) + \\epsilon$ can be recovered, where $A^*$ is the optimal solution. This significantly generalizes associated results on sparse convex optimization, as well as rank-constrained convex optimization for smooth functions. We then introduce new practical variants of these algorithms that have superior runtime and recover better solutions in practice. We demonstrate the versatility of these methods on a wide range of applications involving matrix completion and robust principal component analysis.\n",
        "conference": "ICLR",
        "success": true,
        "中文标题": "秩约束凸优化的局部搜索算法",
        "摘要翻译": "我们提出了用于秩约束凸优化的贪婪和局部搜索算法，即在给定凸函数 $R: \\\\mathbb{R}^{m\\\\times n}\\\\rightarrow \\\\mathbb{R}$ 和参数 $r^*$ 的情况下，求解 $\\\\underset{\\\\mathrm{rank}(A)\\\\leq r^*}{\\\\min}\\, R(A)$。这些算法包括重复两个步骤：（a）向 $A$ 添加一个新的秩为 1 的矩阵，以及（b）对 $A$ 强制执行秩约束。我们改进和提升了 Shalev-Shwartz 等人（2011）的理论分析，并表明如果 $R$ 的秩约束条件数为 $\\\\kappa$，则可以恢复秩为 $O(r^*\\\\cdot \\\\min{\\\\kappa \\\\log \\\\frac{R(\\\\mathbf{0})-R(A^*)}{\\\\epsilon}, \\\\kappa^2})$ 且 $R(A) \\\\leq R(A^*) + \\\\epsilon$ 的解 $A$，其中 $A^*$ 是最优解。这大大推广了关于稀疏凸优化以及光滑函数的秩约束凸优化的相关结果。然后，我们介绍了这些算法的新的实用变体，这些变体具有优越的运行时间和在实践中恢复更好的解决方案。我们在涉及矩阵补全和鲁棒主成分分析的广泛应用中展示了这些方法的多功能性。",
        "领域": "优化算法、矩阵分解、鲁棒主成分分析",
        "问题": "如何在秩约束下高效求解凸优化问题。",
        "动机": "现有方法在处理大规模秩约束凸优化问题时效率较低，且理论保证不足。",
        "方法": "提出贪婪和局部搜索算法，通过迭代添加秩一矩阵和强制秩约束来求解问题，并改进了理论分析，提供了更强的性能保证。",
        "关键词": [
            "秩约束优化",
            "局部搜索",
            "矩阵补全",
            "鲁棒主成分分析",
            "凸优化"
        ],
        "涉及的技术概念": {
            "秩约束": "限制解矩阵的秩，用于降低问题复杂度并挖掘数据中的低秩结构。",
            "凸优化": "利用凸函数的性质，保证算法能够找到全局最优解或近似最优解。"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 480,
        "title": "Long Live the Lottery: The Existence of Winning Tickets in Lifelong Learning",
        "html": "https://iclr.cc//virtual/2021/poster/3031",
        "abstract": "The lottery ticket hypothesis states that a highly sparsified sub-network can be trained in isolation, given the appropriate weight initialization. This paper extends that hypothesis from one-shot task learning, and demonstrates for the first time that such extremely compact and independently trainable sub-networks can be also identified in the lifelong learning scenario, which we call lifelong tickets. We show that the resulting lifelong ticket can further be leveraged to improve the performance of learning over continual tasks. However, it is highly non-trivial to conduct network pruning in the lifelong setting. Two critical roadblocks arise: i) As many tasks now arrive sequentially, finding tickets in a greedy weight pruning fashion will inevitably suffer from the intrinsic bias, that the earlier emerging tasks impact more; ii) As lifelong learning is consistently challenged by catastrophic forgetting, the compact network capacity of tickets might amplify the risk of forgetting. In view of those, we introduce two pruning options, e.g., top-down and bottom-up, for finding lifelong tickets. Compared to the top-down pruning that extends vanilla (iterative) pruning over sequential tasks, we show that the bottom-up one, which can dynamically shrink and (re-)expand model capacity, effectively avoids the undesirable excessive pruning in the early stage. We additionally introduce lottery teaching that further overcomes forgetting via knowledge distillation aided by external unlabeled data. Unifying those ingredients, we demonstrate the existence of very competitive lifelong tickets, e.g., achieving 3-8% of the dense model size with even higher accuracy, compared to strong class-incremental learning baselines on CIFAR-10/CIFAR-100/Tiny-ImageNet datasets. Codes available at https://github.com/VITA-Group/Lifelong-Learning-LTH.",
        "conference": "ICLR",
        "中文标题": "彩票长存：终身学习中的中奖彩票存在性",
        "摘要翻译": "彩票假设指出，在适当的权重初始化下，可以独立训练一个高度稀疏的子网络。本文将该假设从一次性任务学习扩展到终身学习场景，并首次证明在这种场景下也能识别出极其紧凑且可独立训练的子网络，我们称之为终身彩票。我们展示，由此产生的终身彩票可以进一步利用来提高连续任务学习的性能。然而，在终身学习设置中进行网络剪枝是非常不平凡的。出现了两个关键障碍：i) 由于许多任务现在按顺序到达，以贪婪的权重剪枝方式寻找彩票将不可避免地受到内在偏见的影响，即早期出现的任务影响更大；ii) 由于终身学习一直受到灾难性遗忘的挑战，彩票的紧凑网络容量可能会放大遗忘的风险。鉴于这些，我们引入了两种剪枝选项，例如自上而下和自下而上，用于寻找终身彩票。与在顺序任务上扩展普通（迭代）剪枝的自上而下剪枝相比，我们展示了自下而上的剪枝，可以动态收缩和（重新）扩展模型容量，有效避免了早期阶段不希望的过度剪枝。我们还引入了彩票教学，通过外部未标记数据辅助的知识蒸馏进一步克服遗忘。统一这些要素，我们证明了非常具有竞争力的终身彩票的存在，例如，在CIFAR-10/CIFAR-100/Tiny-ImageNet数据集上，与强大的类增量学习基线相比，实现了密集模型大小的3-8%，甚至更高的准确率。代码可在https://github.com/VITA-Group/Lifelong-Learning-LTH获取。",
        "领域": "终身学习、网络剪枝、知识蒸馏",
        "问题": "如何在终身学习场景中识别和利用高度稀疏且可独立训练的子网络（终身彩票）以提高连续任务学习的性能。",
        "动机": "探索在终身学习环境中应用彩票假设的可能性，解决网络剪枝和灾难性遗忘带来的挑战。",
        "方法": "引入自上而下和自下而上两种剪枝选项寻找终身彩票，并通过彩票教学利用知识蒸馏克服遗忘。",
        "关键词": [
            "终身学习",
            "网络剪枝",
            "彩票假设",
            "知识蒸馏",
            "灾难性遗忘"
        ],
        "涉及的技术概念": {
            "彩票假设": "指在适当的权重初始化下，可以独立训练一个高度稀疏的子网络。",
            "终身彩票": "在终身学习场景中识别出的极其紧凑且可独立训练的子网络。",
            "知识蒸馏": "通过外部未标记数据辅助的技术，用于克服终身学习中的遗忘问题。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 481,
        "title": "Long Range Arena : A Benchmark for Efficient Transformers ",
        "html": "https://iclr.cc//virtual/2021/poster/3225",
        "abstract": "Transformers do not scale very well to long sequence lengths largely because of quadratic self-attention complexity. In the recent months, a wide spectrum of efficient, fast Transformers have been proposed to tackle this problem, more often than not claiming superior or comparable model quality to vanilla Transformer models. To this date, there is no well-established consensus on how to evaluate this class of models. Moreover, inconsistent benchmarking on a wide spectrum of tasks and datasets makes it difficult to assess relative model quality amongst many models. This paper proposes a systematic and unified benchmark, Long Range Arena, specifically focused on evaluating model quality under long-context scenarios. Our benchmark is a suite of tasks consisting of sequences ranging from $1K$ to $16K$ tokens, encompassing a wide range of data types and modalities such as text, natural, synthetic images, and mathematical expressions requiring similarity, structural, and visual-spatial reasoning. We systematically evaluate ten well-established long-range Transformer models (Reformers, Linformers, Linear Transformers, Sinkhorn Transformers, Performers, Synthesizers, Sparse Transformers, and Longformers) on our newly proposed benchmark suite. Long Range Arena paves the way towards better understanding this class of efficient Transformer models, facilitates more research in this direction, and presents new challenging tasks to tackle.",
        "conference": "ICLR",
        "中文标题": "长距离竞技场：高效Transformer模型的基准测试",
        "摘要翻译": "Transformer模型在处理长序列时表现不佳，主要是因为其自注意力机制的二次复杂度。最近几个月，为了解决这一问题，提出了多种高效、快速的Transformer模型，这些模型往往声称其模型质量优于或等同于传统的Transformer模型。然而，到目前为止，如何评估这类模型尚未形成广泛共识。此外，在广泛的任务和数据集上进行的不一致的基准测试使得评估众多模型之间的相对质量变得困难。本文提出了一个系统且统一的基准测试——长距离竞技场，专门用于评估长上下文场景下的模型质量。我们的基准测试包含一系列任务，这些任务的序列长度从1K到16K个标记不等，涵盖了广泛的数据类型和模态，如文本、自然和合成图像，以及需要相似性、结构和视觉空间推理的数学表达式。我们系统地评估了十种成熟的长距离Transformer模型（包括Reformers、Linformers、Linear Transformers、Sinkhorn Transformers、Performers、Synthesizers、Sparse Transformers和Longformers）在我们新提出的基准测试套件上的表现。长距离竞技场为更好地理解这类高效Transformer模型铺平了道路，促进了这一方向的更多研究，并提出了新的挑战性任务。",
        "领域": "自然语言处理与视觉结合",
        "问题": "评估和比较高效Transformer模型在长序列处理上的性能",
        "动机": "解决长序列处理中Transformer模型性能评估缺乏统一标准的问题",
        "方法": "提出一个包含多种任务和数据类型的统一基准测试套件，系统地评估多种高效Transformer模型",
        "关键词": [
            "长序列处理",
            "Transformer模型",
            "基准测试"
        ],
        "涉及的技术概念": {
            "自注意力机制": "Transformer模型中的核心机制，用于捕捉序列中不同位置间的依赖关系",
            "高效Transformer模型": "针对传统Transformer模型在长序列处理上的不足进行优化的模型",
            "长距离竞技场": "本文提出的用于评估长序列处理模型性能的统一基准测试套件"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 482,
        "title": "Long-tailed Recognition by Routing Diverse Distribution-Aware Experts",
        "html": "https://iclr.cc//virtual/2021/poster/3018",
        "abstract": "Natural data are often long-tail distributed over semantic classes. Existing recognition methods tend to focus on gaining performance on tail classes, often at the expense of losing performance on head classes and with increased classifier variance. The low tail performance manifests itself in large inter-class confusion and high classifier variance. We aim to reduce both the bias and the variance of a long-tailed classifier by RoutIng Diverse Experts (RIDE), consisting of three components: 1) a shared architecture for multiple classifiers (experts); 2) a distribution-aware diversity loss that encourages more diverse decisions for classes with fewer training instances; and 3) an expert routing module that dynamically assigns more ambiguous instances to additional experts.  With on-par computational complexity, RIDE significantly outperforms the state-of-the-art methods by 5% to 7% on all the benchmarks including CIFAR100-LT, ImageNet-LT, and iNaturalist 2018. RIDE is also a universal framework that can be applied to different backbone networks and integrated into various long-tailed algorithms and training mechanisms for consistent performance gains. Our code is publicly available at https://github.com/frank-xwang/RIDE-LongTailRecognition.",
        "conference": "ICLR",
        "中文标题": "通过路由多样化分布感知专家的长尾识别",
        "摘要翻译": "自然数据通常在语义类别上呈现长尾分布。现有的识别方法往往侧重于提高尾部类别的性能，但这常常以牺牲头部类别的性能和增加分类器方差为代价。尾部性能低下表现为较大的类间混淆和较高的分类器方差。我们旨在通过路由多样化专家（RIDE）来减少长尾分类器的偏差和方差，RIDE包含三个组成部分：1）一个用于多个分类器（专家）的共享架构；2）一个分布感知的多样性损失，鼓励对训练实例较少的类别做出更多样化的决策；3）一个专家路由模块，动态地将更模糊的实例分配给额外的专家。在计算复杂度相当的情况下，RIDE在所有基准测试（包括CIFAR100-LT、ImageNet-LT和iNaturalist 2018）上显著优于最先进的方法，提高了5%到7%。RIDE也是一个通用框架，可以应用于不同的骨干网络，并集成到各种长尾算法和训练机制中，以获得一致的性能提升。我们的代码公开在https://github.com/frank-xwang/RIDE-LongTailRecognition。",
        "领域": "长尾识别、图像分类、深度学习",
        "问题": "解决长尾分布数据中尾部类别识别性能低下和分类器方差高的问题",
        "动机": "减少长尾分类器的偏差和方差，提高尾部类别的识别性能而不牺牲头部类别的性能",
        "方法": "采用共享架构的多分类器系统，结合分布感知的多样性损失和动态专家路由模块",
        "关键词": [
            "长尾识别",
            "分布感知",
            "专家路由",
            "多样性损失",
            "动态分配"
        ],
        "涉及的技术概念": {
            "共享架构": "用于多个分类器的共享架构，旨在提高模型的效率和性能",
            "分布感知的多样性损失": "鼓励模型对训练实例较少的类别做出更多样化的决策，以减少偏差",
            "专家路由模块": "动态地将更模糊的实例分配给额外的专家，以减少分类器的方差"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 483,
        "title": "Long-tail learning via logit adjustment",
        "html": "https://iclr.cc//virtual/2021/poster/2675",
        "abstract": "Real-world classification problems typically exhibit an imbalanced or long-tailed label distribution, wherein many labels have only a few associated samples. This poses a challenge for generalisation on such labels, and also  makes naive learning biased towards dominant labels. In this paper,  we present a statistical framework that unifies and generalises several recent proposals to cope with these challenges. Our framework revisits the classic idea of logit adjustment based on the label frequencies, which encourages a large relative margin between logits of rare positive versus dominant negative labels. This yields two techniques  for long-tail learning, where such adjustment is either applied post-hoc to a trained model, or enforced in the loss during training. These techniques are statistically grounded, and practically effective on four real-world datasets with long-tailed label distributions. ",
        "conference": "ICLR",
        "中文标题": "通过逻辑调整进行长尾学习",
        "摘要翻译": "现实世界中的分类问题通常表现出不平衡或长尾的标签分布，其中许多标签只有少量相关样本。这对这些标签的泛化提出了挑战，同时也使得朴素学习偏向于主导标签。在本文中，我们提出了一个统计框架，该框架统一并概括了几种最近提出的应对这些挑战的方案。我们的框架重新审视了基于标签频率的逻辑调整的经典思想，这鼓励了罕见正标签与主导负标签之间的逻辑相对较大的边际。这产生了两种长尾学习的技术，其中这种调整要么在训练后应用于训练好的模型，要么在训练期间通过损失强制执行。这些技术在统计上有依据，并且在四个具有长尾标签分布的真实世界数据集上实际有效。",
        "领域": "长尾学习、不平衡分类、深度学习",
        "问题": "解决在长尾标签分布下的分类问题，提高模型对罕见标签的泛化能力。",
        "动机": "现实世界中的分类问题往往存在标签分布不平衡的情况，导致模型偏向于主导标签，难以有效识别罕见标签。",
        "方法": "提出一个统计框架，通过逻辑调整技术，在训练后或训练过程中调整模型，以改善对罕见标签的分类性能。",
        "关键词": [
            "长尾学习",
            "逻辑调整",
            "不平衡分类",
            "统计框架",
            "标签分布"
        ],
        "涉及的技术概念": {
            "逻辑调整": "基于标签频率调整模型的输出逻辑，以改善对罕见标签的分类性能。",
            "长尾学习": "处理标签分布极不平衡的分类问题，特别是那些有许多罕见标签的情况。",
            "统计框架": "提供一个统一的方法来理解和实施针对长尾学习问题的解决方案。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 484,
        "title": "Loss Function Discovery for Object Detection via Convergence-Simulation Driven Search",
        "html": "https://iclr.cc//virtual/2021/poster/2832",
        "abstract": "Designing proper loss functions for vision tasks has been a long-standing research direction to advance the capability of existing models. For object detection, the well-established classification and regression loss functions have been carefully designed by considering diverse learning challenges (e.g. class imbalance, hard negative samples, and scale variances). Inspired by the recent progress in network architecture search, it is interesting to explore the possibility of discovering new loss function formulations via directly searching the primitive operation combinations. So that the learned losses not only fit for diverse object detection challenges to alleviate huge human efforts, but also have better alignment with evaluation metric and good mathematical convergence property. Beyond the previous auto-loss works on face recognition and image classification, our work makes the first attempt to discover new loss functions for the challenging object detection from primitive operation levels and finds the searched losses are insightful. We propose an effective convergence-simulation driven evolutionary search algorithm, called CSE-Autoloss, for speeding up the search progress by regularizing the mathematical rationality of loss candidates via two progressive convergence simulation modules: convergence property verification and model optimization simulation. CSE-Autoloss involves the search space (i.e. 21 mathematical operators, 3 constant-type inputs, and 3 variable-type inputs) that cover a wide range of the possible variants of existing losses and discovers best-searched loss function combination within a short time (around 1.5 wall-clock days with 20x speedup in comparison to the vanilla evolutionary algorithm). We conduct extensive evaluations of loss function search on popular detectors and validate the good generalization capability of searched losses across diverse architectures and various datasets. Our experiments show that the best-discovered loss function combinations outperform default combinations (Cross-entropy/Focal loss for classification and L1 loss for regression) by 1.1% and 0.8% in terms of mAP for two-stage and one-stage detectors on COCO respectively. Our searched losses are available at https://github.com/PerdonLiu/CSE-Autoloss.",
        "conference": "ICLR",
        "中文标题": "通过收敛模拟驱动搜索实现目标检测的损失函数发现",
        "摘要翻译": "为视觉任务设计合适的损失函数一直是提升现有模型能力的一个长期研究方向。对于目标检测，已建立的分类和回归损失函数通过考虑多样化的学习挑战（如类别不平衡、难负样本和尺度变化）被精心设计。受到网络架构搜索最新进展的启发，探索通过直接搜索原始操作组合来发现新的损失函数公式的可能性变得有趣。这样学习到的损失不仅适合多样化的目标检测挑战以减轻大量人力投入，而且与评估指标有更好的对齐和良好的数学收敛性。与之前在人脸识别和图像分类上的自动损失工作不同，我们的工作首次尝试从原始操作层面为具有挑战性的目标检测发现新的损失函数，并发现搜索到的损失具有洞察力。我们提出了一种有效的收敛模拟驱动进化搜索算法，称为CSE-Autoloss，通过两个渐进式收敛模拟模块（收敛性验证和模型优化模拟）来规范化损失候选者的数学合理性，从而加速搜索进程。CSE-Autoloss涉及的搜索空间（即21个数学运算符、3个常量类型输入和3个变量类型输入）覆盖了现有损失可能变体的广泛范围，并在短时间内（约1.5个日历日，与原始进化算法相比速度提升20倍）发现了最佳搜索的损失函数组合。我们在流行的检测器上对损失函数搜索进行了广泛评估，并验证了搜索到的损失在不同架构和各种数据集上的良好泛化能力。我们的实验表明，对于COCO数据集上的两阶段和一阶段检测器，最佳发现的损失函数组合在mAP方面分别比默认组合（分类的交叉熵/焦点损失和回归的L1损失）高出1.1%和0.8%。我们搜索到的损失可在https://github.com/PerdonLiu/CSE-Autoloss获取。",
        "领域": "目标检测",
        "问题": "如何自动发现适合目标检测任务的高效损失函数，以替代人工设计的损失函数",
        "动机": "减少人工设计损失函数的工作量，同时提高损失函数与评估指标的对齐和数学收敛性",
        "方法": "提出一种收敛模拟驱动的进化搜索算法（CSE-Autoloss），通过规范化损失候选者的数学合理性来加速搜索进程",
        "关键词": [
            "损失函数搜索",
            "目标检测",
            "进化算法",
            "收敛模拟",
            "自动机器学习"
        ],
        "涉及的技术概念": {
            "收敛模拟驱动搜索": "通过模拟损失函数的收敛行为来指导搜索过程，确保发现的损失函数具有良好的数学收敛性",
            "进化算法": "用于在广泛的搜索空间中高效探索和优化损失函数组合",
            "损失函数组合": "通过组合不同的数学运算符和输入类型，构建新的损失函数以适应目标检测的多样化挑战"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 485,
        "title": "Lossless Compression of Structured Convolutional Models via Lifting",
        "html": "https://iclr.cc//virtual/2021/poster/2929",
        "abstract": "Lifting is an efficient technique to scale up graphical models generalized to relational domains by exploiting the underlying symmetries. Concurrently, neural models are continuously expanding from grid-like tensor data into structured representations, such as various attributed graphs and relational databases. To address the irregular structure of the data, the models typically extrapolate on the idea of convolution, effectively introducing parameter sharing in their, dynamically unfolded, computation graphs. The computation graphs themselves then reflect the symmetries of the underlying data, similarly to the lifted graphical models. Inspired by lifting, we introduce a simple and efficient technique to detect the symmetries and compress the neural models without loss of any information. We demonstrate through experiments that such compression can lead to significant speedups of structured convolutional models, such as various Graph Neural Networks, across various tasks, such as molecule classification and knowledge-base completion.",
        "conference": "ICLR",
        "中文标题": "通过提升实现结构化卷积模型的无损压缩",
        "摘要翻译": "提升是一种高效的技术，通过利用底层对称性来扩展推广到关系领域的图形模型。同时，神经网络模型正不断从网格状张量数据扩展到结构化表示，如各种属性图和关系数据库。为了处理数据的不规则结构，这些模型通常基于卷积的概念进行外推，有效地在其动态展开的计算图中引入参数共享。计算图本身随后反映了底层数据的对称性，类似于提升的图形模型。受提升的启发，我们引入了一种简单而高效的技术来检测对称性并无损压缩神经网络模型。我们通过实验证明，这种压缩可以显著加速结构化卷积模型，如各种图神经网络，在多种任务中的表现，如分子分类和知识库完成。",
        "领域": "图神经网络、知识库完成、分子分类",
        "问题": "如何高效无损地压缩结构化卷积模型以加速其性能",
        "动机": "为了处理结构化数据的不规则性并提升模型效率，研究如何利用数据的对称性进行无损压缩",
        "方法": "引入基于提升的技术来检测数据的对称性并无损压缩神经网络模型",
        "关键词": [
            "无损压缩",
            "结构化卷积模型",
            "图神经网络",
            "对称性检测",
            "参数共享"
        ],
        "涉及的技术概念": {
            "提升": "一种利用底层对称性扩展图形模型的技术，用于无损压缩神经网络模型",
            "结构化卷积模型": "处理不规则结构化数据的神经网络模型，通过卷积概念外推实现参数共享",
            "对称性检测": "识别数据中的对称模式以优化模型压缩和性能的技术"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 486,
        "title": "LowKey: Leveraging Adversarial Attacks to Protect Social Media Users from Facial Recognition",
        "html": "https://iclr.cc//virtual/2021/poster/3088",
        "abstract": "Facial recognition systems are increasingly deployed by private corporations, government agencies, and contractors for consumer services and mass surveillance programs alike.  These systems are typically built by scraping social media profiles for user images.  Adversarial perturbations have been proposed for bypassing facial recognition systems.  However, existing methods fail on full-scale systems and commercial APIs.  We develop our own adversarial filter that accounts for the entire image processing pipeline and is demonstrably effective against industrial-grade pipelines that include face detection and large scale databases.  Additionally, we release an easy-to-use webtool that significantly degrades the accuracy of Amazon Rekognition and the Microsoft Azure Face Recognition API, reducing the accuracy of each to below 1%.",
        "conference": "ICLR",
        "中文标题": "LowKey：利用对抗性攻击保护社交媒体用户免受面部识别",
        "摘要翻译": "面部识别系统越来越多地被私营公司、政府机构和承包商用于消费者服务和大规模监控项目。这些系统通常通过抓取社交媒体上的用户图像来构建。对抗性扰动已被提出用于绕过面部识别系统。然而，现有方法在全面系统和商业API上失败。我们开发了自己的对抗性过滤器，考虑了整个图像处理流程，并证明对包括面部检测和大规模数据库在内的工业级流程有效。此外，我们发布了一个易于使用的网络工具，显著降低了Amazon Rekognition和Microsoft Azure面部识别API的准确率，将各自的准确率降至1%以下。",
        "领域": "人脸识别安全、对抗性机器学习、隐私保护技术",
        "问题": "现有对抗性扰动方法无法有效对抗工业级面部识别系统",
        "动机": "保护社交媒体用户免受未经同意的面部识别和数据收集",
        "方法": "开发了一种考虑整个图像处理流程的对抗性过滤器，并创建了一个易于使用的网络工具",
        "关键词": [
            "对抗性攻击",
            "面部识别",
            "隐私保护",
            "社交媒体安全",
            "工业级系统"
        ],
        "涉及的技术概念": {
            "对抗性扰动": "用于生成能够欺骗面部识别系统的微小图像修改",
            "图像处理流程": "指从原始图像到面部识别系统处理的完整步骤，对抗性过滤器需要适应这一流程",
            "工业级面部识别系统": "指商业部署的大规模面部识别系统，如Amazon Rekognition和Microsoft Azure Face API"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 487,
        "title": "MALI: A memory efficient and reverse accurate integrator for Neural ODEs",
        "html": "https://iclr.cc//virtual/2021/poster/2945",
        "abstract": "Neural ordinary differential equations (Neural ODEs) are a new family of deep-learning models with continuous depth. However, the numerical estimation of the gradient in the continuous case is not well solved: existing implementations of the adjoint method suffer from inaccuracy in reverse-time trajectory, while the naive method and the adaptive checkpoint adjoint method (ACA) have a memory cost that grows with integration time. In this project, based on the asynchronous leapfrog (ALF) solver, we propose the Memory-efficient ALF Integrator (MALI), which has a constant memory cost $w.r.t$ integration time similar to the adjoint method, and guarantees accuracy in reverse-time trajectory (hence accuracy in gradient estimation). We validate MALI in various tasks: on image recognition tasks, to our knowledge, MALI is the first to enable feasible training of a Neural ODE on ImageNet and outperform a well-tuned ResNet, while existing methods fail due to either heavy memory burden or inaccuracy; for time series modeling, MALI significantly outperforms the adjoint method; and for continuous generative models, MALI achieves new state-of-the-art performance. We provide a pypi package: https://jzkay12.github.io/TorchDiffEqPack",
        "conference": "ICLR",
        "中文标题": "MALI：一种内存高效且反向精确的神经ODE积分器",
        "摘要翻译": "神经普通微分方程（Neural ODEs）是一种具有连续深度的新型深度学习模型家族。然而，连续情况下梯度的数值估计问题尚未得到很好解决：现有的伴随方法实现存在反向时间轨迹不准确的问题，而朴素方法和自适应检查点伴随方法（ACA）的内存成本随着积分时间的增长而增加。在本项目中，基于异步跳跃（ALF）求解器，我们提出了内存高效的ALF积分器（MALI），它具有与伴随方法相似的关于积分时间的恒定内存成本，并保证了反向时间轨迹的准确性（从而保证了梯度估计的准确性）。我们在各种任务中验证了MALI：在图像识别任务中，据我们所知，MALI首次实现了在ImageNet上可行地训练神经ODE并超越了经过良好调整的ResNet，而现有方法由于沉重的内存负担或不准确性而失败；对于时间序列建模，MALI显著优于伴随方法；对于连续生成模型，MALI实现了新的最先进性能。我们提供了一个pypi包：https://jzkay12.github.io/TorchDiffEqPack",
        "领域": "深度学习优化、时间序列建模、连续生成模型",
        "问题": "解决神经ODE在连续深度模型训练中梯度估计的内存效率和准确性不足的问题",
        "动机": "提高神经ODE在训练过程中的内存效率和梯度估计的准确性，以支持更广泛的应用场景",
        "方法": "基于异步跳跃（ALF）求解器，开发了一种内存高效的ALF积分器（MALI），实现了恒定内存成本和反向时间轨迹的准确性",
        "关键词": [
            "神经ODE",
            "内存效率",
            "梯度估计",
            "异步跳跃求解器",
            "图像识别"
        ],
        "涉及的技术概念": {
            "神经ODE": "一种具有连续深度的深度学习模型，通过普通微分方程描述数据的动态变化",
            "伴随方法": "用于计算梯度的一种数值方法，但在反向时间轨迹上存在不准确的问题",
            "异步跳跃求解器（ALF）": "一种数值求解器，用于高效准确地模拟动态系统的行为，是MALI方法的基础"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 488,
        "title": "Mapping the Timescale Organization of Neural Language Models",
        "html": "https://iclr.cc//virtual/2021/poster/3232",
        "abstract": "In the human brain, sequences of language input are processed within a distributed and hierarchical architecture, in which higher stages of processing encode contextual information over longer timescales. In contrast, in recurrent neural networks which perform natural language processing, we know little about how the multiple timescales of contextual information are functionally organized. Therefore, we applied tools developed in neuroscience to map the “processing timescales” of individual units within a word-level LSTM language model. This timescale-mapping method assigned long timescales to units previously found to track long-range syntactic dependencies. Additionally, the mapping revealed a small subset of the network (less than 15% of units) with long timescales and whose function had not previously been explored. We next probed the functional organization of the network by examining the relationship between the processing timescale of units and their network connectivity. We identified two classes of long-timescale units: “controller” units composed a densely interconnected subnetwork and strongly projected to the rest of the network, while “integrator” units showed the longest timescales in the network, and expressed projection profiles closer to the mean projection profile. Ablating integrator and controller units affected model performance at different positions within a sentence, suggesting distinctive functions of these two sets of units. Finally, we tested the generalization of these results to a character-level LSTM model and models with different architectures. In summary, we demonstrated a model-free technique for mapping the timescale organization in recurrent neural networks, and we applied this method to reveal the timescale and functional organization of neural language models",
        "conference": "ICLR",
        "中文标题": "映射神经语言模型的时间尺度组织",
        "摘要翻译": "在人脑中，语言输入的序列是在一个分布式和层次化的架构中处理的，其中更高阶段的处理在更长的时间尺度上编码上下文信息。相比之下，在执行自然语言处理的循环神经网络中，我们对上下文信息的多个时间尺度如何功能性地组织知之甚少。因此，我们应用了神经科学中开发的工具来映射单词级LSTM语言模型中各个单元的“处理时间尺度”。这种时间尺度映射方法将长时间尺度分配给先前发现跟踪长距离句法依赖的单元。此外，映射揭示了一个网络的小子集（少于15%的单元）具有长时间尺度，其功能先前未被探索。我们接下来通过检查单元的处理时间尺度与其网络连接性之间的关系来探测网络的功能组织。我们识别了两类长时间尺度单元：“控制器”单元构成了一个密集互连的子网络，并强烈投射到网络的其余部分，而“整合器”单元显示出网络中最长的时间尺度，并表达了接近平均投射轮廓的投射轮廓。消融整合器和控制器单元影响了模型在句子不同位置的表现，表明这两组单元的独特功能。最后，我们测试了这些结果在字符级LSTM模型和具有不同架构的模型中的泛化性。总之，我们展示了一种无模型技术来映射循环神经网络中的时间尺度组织，并应用这种方法揭示了神经语言模型的时间尺度和功能组织。",
        "领域": "自然语言处理与视觉结合, 神经网络模型分析, 语言模型理解",
        "问题": "理解循环神经网络中上下文信息的时间尺度如何功能性地组织",
        "动机": "探索神经语言模型中时间尺度的功能组织，以更好地理解其处理语言的方式",
        "方法": "应用神经科学中的工具映射LSTM语言模型中单元的处理时间尺度，分析其功能组织和网络连接性",
        "关键词": [
            "时间尺度映射",
            "LSTM语言模型",
            "功能组织",
            "神经网络分析",
            "上下文处理"
        ],
        "涉及的技术概念": {
            "时间尺度映射": "用于识别和分类神经网络单元处理信息的时间尺度，揭示不同单元的功能特性",
            "LSTM语言模型": "一种循环神经网络，用于处理和生成自然语言，能够捕捉长距离依赖关系",
            "功能组织": "分析神经网络中不同单元如何协同工作以处理信息，揭示其内部结构和动态"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 489,
        "title": "MARS: Markov Molecular Sampling for Multi-objective Drug Discovery",
        "html": "https://iclr.cc//virtual/2021/poster/3352",
        "abstract": "Searching for novel molecules with desired chemical properties is crucial in drug discovery. Existing work focuses on developing neural models to generate either molecular sequences or chemical graphs. However, it remains a big challenge to find novel and diverse compounds satisfying several properties. In this paper, we propose MARS, a method for multi-objective drug molecule discovery. MARS is based on the idea of generating the chemical candidates by iteratively editing fragments of molecular graphs. To search for high-quality candidates, it employs Markov chain Monte Carlo sampling (MCMC) on molecules with an annealing scheme and an adaptive proposal. To further improve sample efficiency, MARS uses a graph neural network (GNN) to represent and select candidate edits, where the GNN is trained on-the-fly with samples from MCMC. Experiments show that MARS achieves state-of-the-art performance in various multi-objective settings where molecular bio-activity, drug-likeness, and synthesizability are considered. Remarkably, in the most challenging setting where all four objectives are simultaneously optimized, our approach outperforms previous methods significantly in comprehensive evaluations. The code is available at https://github.com/yutxie/mars.",
        "conference": "ICLR",
        "中文标题": "MARS：用于多目标药物发现的马尔可夫分子采样",
        "摘要翻译": "寻找具有所需化学性质的新分子在药物发现中至关重要。现有工作主要集中在开发神经模型以生成分子序列或化学图。然而，找到满足多种性质的新颖且多样化的化合物仍然是一个巨大的挑战。在本文中，我们提出了MARS，一种用于多目标药物分子发现的方法。MARS基于通过迭代编辑分子图的片段来生成化学候选物的想法。为了寻找高质量的候选物，它采用了带有退火方案和自适应提议的马尔可夫链蒙特卡洛采样（MCMC）对分子进行采样。为了进一步提高采样效率，MARS使用图神经网络（GNN）来表示和选择候选编辑，其中GNN通过MCMC的样本进行即时训练。实验表明，在考虑分子生物活性、药物相似性和可合成性的各种多目标设置中，MARS实现了最先进的性能。值得注意的是，在所有四个目标同时优化的最具挑战性的设置中，我们的方法在综合评估中显著优于以前的方法。代码可在https://github.com/yutxie/mars获取。",
        "领域": "药物分子设计、化学信息学、图神经网络应用",
        "问题": "如何在药物发现中高效地生成满足多种化学性质要求的新颖且多样化的分子。",
        "动机": "解决现有方法在生成满足多种化学性质要求的新颖且多样化分子方面的不足。",
        "方法": "提出MARS方法，结合马尔可夫链蒙特卡洛采样和图神经网络，通过迭代编辑分子图片段来生成候选分子。",
        "关键词": [
            "多目标药物发现",
            "马尔可夫链蒙特卡洛采样",
            "图神经网络",
            "分子编辑",
            "化学性质优化"
        ],
        "涉及的技术概念": {
            "马尔可夫链蒙特卡洛采样（MCMC）": "用于在分子空间中高效搜索满足多种化学性质要求的候选分子。",
            "图神经网络（GNN）": "用于表示和选择分子图的编辑操作，提高分子生成的效率和多样性。",
            "退火方案和自适应提议": "优化MCMC采样过程，提高在高维分子空间中的搜索效率和质量。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 490,
        "title": "Mastering Atari with Discrete World Models",
        "html": "https://iclr.cc//virtual/2021/poster/2742",
        "abstract": "Intelligent agents need to generalize from past experience to achieve goals in complex environments. World models facilitate such generalization and allow learning behaviors from imagined outcomes to increase sample-efficiency. While learning world models from image inputs has recently become feasible for some tasks, modeling Atari games accurately enough to derive successful behaviors has remained an open challenge for many years. We introduce DreamerV2, a reinforcement learning agent that learns behaviors purely from predictions in the compact latent space of a powerful world model. The world model uses discrete representations and is trained separately from the policy. DreamerV2 constitutes the first agent that achieves human-level performance on the Atari benchmark of 55 tasks by learning behaviors inside a separately trained world model. With the same computational budget and wall-clock time, Dreamer V2 reaches 200M frames and exceeds the final performance of the top single-GPU agents IQN and Rainbow.",
        "conference": "ICLR",
        "中文标题": "掌握离散世界模型的Atari游戏",
        "摘要翻译": "智能代理需要从过去的经验中泛化，以在复杂环境中实现目标。世界模型促进了这种泛化，并允许从想象中的结果学习行为，以提高样本效率。虽然从图像输入学习世界模型最近对某些任务变得可行，但多年来，对Atari游戏进行足够准确的建模以推导出成功行为仍然是一个开放的挑战。我们介绍了DreamerV2，一个强化学习代理，它纯粹从强大世界模型的紧凑潜在空间的预测中学习行为。世界模型使用离散表示，并与策略分开训练。DreamerV2是第一个通过在单独训练的世界模型中学习行为，在55个任务的Atari基准测试中达到人类水平性能的代理。在相同的计算预算和挂钟时间下，DreamerV2达到了200M帧，并超过了顶级单GPU代理IQN和Rainbow的最终性能。",
        "领域": "强化学习、游戏AI、世界模型",
        "问题": "如何在Atari游戏中通过世界模型学习达到人类水平的性能",
        "动机": "解决从图像输入准确建模Atari游戏并从中学习成功行为的长期挑战",
        "方法": "开发DreamerV2代理，利用离散表示的世界模型在潜在空间中预测学习行为",
        "关键词": [
            "强化学习",
            "世界模型",
            "Atari游戏",
            "离散表示",
            "样本效率"
        ],
        "涉及的技术概念": {
            "离散表示": "世界模型采用离散而非连续的表示方式，有助于更有效地捕捉和预测游戏状态",
            "世界模型": "用于从过去的经验中泛化，预测未来状态，从而在潜在空间中学习行为",
            "强化学习代理": "DreamerV2通过在世界模型的潜在空间中预测来学习行为，实现高效样本利用"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 491,
        "title": "Mathematical Reasoning via Self-supervised Skip-tree Training",
        "html": "https://iclr.cc//virtual/2021/poster/3055",
        "abstract": "We demonstrate that self-supervised language modeling applied to mathematical formulas enables logical reasoning. To measure the logical reasoning abilities of language models, we formulate several evaluation (downstream) tasks, such as inferring types, suggesting missing assumptions and completing equalities. For training language models for formal mathematics, we propose a novel skip-tree task. We find that models trained on the skip-tree task show surprisingly strong mathematical reasoning abilities, and outperform models trained on standard skip-sequence tasks. We also analyze the models' ability to formulate new conjectures by measuring how often the predictions are provable and useful in other proofs.",
        "conference": "ICLR",
        "中文标题": "通过自监督跳跃树训练实现数学推理",
        "摘要翻译": "我们证明，将自监督语言建模应用于数学公式能够实现逻辑推理。为了衡量语言模型的逻辑推理能力，我们制定了几个评估（下游）任务，如推断类型、建议缺失假设和完成等式。为了训练用于形式数学的语言模型，我们提出了一种新颖的跳跃树任务。我们发现，经过跳跃树任务训练的模型显示出惊人的强大数学推理能力，并且优于经过标准跳跃序列任务训练的模型。我们还通过测量预测在其他证明中可证明和有用的频率，分析了模型制定新猜想的能力。",
        "领域": "自然语言处理与数学结合、逻辑推理、形式数学",
        "问题": "如何通过自监督学习提升语言模型在数学公式上的逻辑推理能力",
        "动机": "探索自监督语言模型在数学逻辑推理中的应用潜力，特别是在形式数学领域",
        "方法": "提出一种新颖的跳跃树任务来训练语言模型，以增强其在数学公式上的逻辑推理能力",
        "关键词": [
            "自监督学习",
            "数学推理",
            "跳跃树任务",
            "语言模型",
            "逻辑推理"
        ],
        "涉及的技术概念": {
            "自监督语言建模": "应用于数学公式，使模型能够进行逻辑推理",
            "跳跃树任务": "一种新颖的训练任务，旨在提升模型在数学推理上的表现",
            "逻辑推理能力评估": "通过下游任务如推断类型、建议缺失假设和完成等式来评估模型的逻辑推理能力"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 492,
        "title": "Measuring Massive Multitask Language Understanding",
        "html": "https://iclr.cc//virtual/2021/poster/2962",
        "abstract": "We propose a new test to measure a text model's multitask accuracy. The test covers 57 tasks including elementary mathematics, US history, computer science, law, and more. To attain high accuracy on this test, models must possess extensive world knowledge and problem solving ability. We find that while most recent models have near random-chance accuracy, the very largest GPT-3 model improves over random chance by almost 20 percentage points on average. However, on every one of the 57 tasks, the best models still need substantial improvements before they can reach expert-level accuracy. Models also have lopsided performance and frequently do not know when they are wrong. Worse, they still have near-random accuracy on some socially important subjects such as morality and law. By comprehensively evaluating the breadth and depth of a model's academic and professional understanding, our test can be used to analyze models across many tasks and to identify important shortcomings.",
        "conference": "ICLR",
        "中文标题": "测量大规模多任务语言理解",
        "摘要翻译": "我们提出了一种新的测试方法来衡量文本模型的多任务准确性。该测试涵盖了57个任务，包括基础数学、美国历史、计算机科学、法律等。要在这一测试中获得高准确率，模型必须具备广泛的世界知识和问题解决能力。我们发现，尽管大多数最新模型的准确率接近随机概率，但最大的GPT-3模型平均比随机概率提高了近20个百分点。然而，在这57个任务的每一个上，最佳模型仍需要大幅改进才能达到专家级准确率。模型的表现也不均衡，经常不知道自己在何时出错。更糟糕的是，它们在一些社会重要主题如道德和法律上的准确率仍接近随机。通过全面评估模型在学术和专业理解上的广度和深度，我们的测试可用于分析模型在多项任务上的表现，并识别重要缺陷。",
        "领域": "自然语言处理与视觉结合",
        "问题": "衡量文本模型在多任务上的准确性和理解能力",
        "动机": "为了评估和提升文本模型在广泛任务中的表现，识别其在关键领域的不足",
        "方法": "提出了一种涵盖57个不同领域任务的新测试方法，用于全面评估模型的多任务准确性和理解能力",
        "关键词": [
            "多任务学习",
            "语言理解",
            "模型评估",
            "GPT-3",
            "准确性测试"
        ],
        "涉及的技术概念": {
            "多任务准确性": "衡量模型在多个不同任务上的表现，反映其广泛适用性和理解能力",
            "世界知识": "模型需要具备的广泛背景知识，以理解和解决跨领域的任务",
            "问题解决能力": "模型应用其知识解决具体问题的能力，是评估其性能的关键指标"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 493,
        "title": "MELR: Meta-Learning via Modeling Episode-Level Relationships for Few-Shot Learning",
        "html": "https://iclr.cc//virtual/2021/poster/3256",
        "abstract": "Most recent few-shot learning (FSL) approaches are based on episodic training whereby each episode samples few training instances (shots) per class to imitate the test condition. However, this strict adhering to test condition has a negative side effect, that is, the trained model is susceptible to the poor sampling of few shots. In this work, for the first time, this problem is addressed by exploiting inter-episode relationships. Specifically, a novel meta-learning via modeling episode-level relationships (MELR) framework is proposed. By sampling two episodes containing the same set of classes for meta-training, MELR is designed to ensure that the meta-learned model is robust against the presence of poorly-sampled shots in the meta-test stage. This is achieved through two key components: (1) a Cross-Episode Attention Module (CEAM) to improve the ability of alleviating the effects of poorly-sampled shots, and (2) a Cross-Episode Consistency Regularization (CECR) to enforce that the two classifiers learned from the two episodes are consistent even when there are unrepresentative instances. Extensive experiments for non-transductive standard FSL on two benchmarks show that our MELR achieves 1.0%-5.0% improvements over the baseline (i.e., ProtoNet) used for FSL in our model and outperforms the latest competitors under the same settings.",
        "conference": "ICLR",
        "中文标题": "MELR：通过建模片段级关系进行元学习的小样本学习",
        "摘要翻译": "最近的小样本学习（FSL）方法大多基于片段式训练，每个片段从每个类别中采样少量训练实例（shots）以模拟测试条件。然而，这种严格遵循测试条件的做法有一个负面效应，即训练模型容易受到少量样本采样不佳的影响。在这项工作中，首次通过利用片段间关系来解决这一问题。具体来说，提出了一种新颖的通过建模片段级关系（MELR）的元学习框架。通过在元训练中采样包含相同类别集的两个片段，MELR旨在确保元学习模型在元测试阶段对采样不佳的shots具有鲁棒性。这通过两个关键组件实现：（1）跨片段注意力模块（CEAM）以提高减轻采样不佳shots影响的能力，（2）跨片段一致性正则化（CECR）以强制从两个片段学习到的两个分类器即使在存在非代表性实例时也保持一致。在两个基准上的非传导标准FSL的大量实验表明，我们的MELR比用于FSL的基线（即ProtoNet）提高了1.0%-5.0%，并在相同设置下优于最新的竞争对手。",
        "领域": "小样本学习、元学习、计算机视觉",
        "问题": "解决小样本学习中模型对采样不佳的少量训练实例敏感的问题",
        "动机": "通过利用片段间关系，提高模型在元测试阶段对采样不佳的少量训练实例的鲁棒性",
        "方法": "提出MELR框架，包含跨片段注意力模块（CEAM）和跨片段一致性正则化（CECR）两个关键组件",
        "关键词": [
            "小样本学习",
            "元学习",
            "片段级关系",
            "跨片段注意力",
            "一致性正则化"
        ],
        "涉及的技术概念": {
            "跨片段注意力模块（CEAM）": "用于提高模型减轻采样不佳shots影响的能力",
            "跨片段一致性正则化（CECR）": "强制从两个片段学习到的分类器在存在非代表性实例时保持一致",
            "片段级关系建模": "通过建模片段间关系来提高模型对采样不佳shots的鲁棒性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 494,
        "title": "Memory Optimization for Deep Networks",
        "html": "https://iclr.cc//virtual/2021/poster/3341",
        "abstract": "Deep learning is slowly, but steadily, hitting a memory bottleneck. While the tensor computation in top-of-the-line GPUs increased by $32\\times$ over the last five years, the total available memory only grew by $2.5\\times$. This prevents researchers from exploring larger architectures, as training large networks requires more memory for storing intermediate outputs. In this paper, we present MONeT, an automatic framework that minimizes both the memory footprint and computational overhead of deep networks. MONeT jointly optimizes the checkpointing schedule and the implementation of various operators. MONeT is able to outperform all prior hand-tuned operations as well as automated checkpointing. MONeT reduces the overall memory requirement by $3\\times$ for various PyTorch models, with a 9-16$\\%$ overhead in computation. For the same computation cost, MONeT requires 1.2-1.8$\\times$ less memory than current state-of-the-art automated checkpointing frameworks. Our code will be made publicly available upon acceptance.",
        "conference": "ICLR",
        "中文标题": "深度网络的内存优化",
        "摘要翻译": "深度学习正缓慢但稳步地遇到内存瓶颈。虽然顶级GPU中的张量计算在过去五年中增长了32倍，但总可用内存仅增长了2.5倍。这阻碍了研究人员探索更大的架构，因为训练大型网络需要更多内存来存储中间输出。在本文中，我们提出了MONeT，一个自动框架，旨在最小化深度网络的内存占用和计算开销。MONeT联合优化了检查点调度和各种算子的实现。MONeT能够超越所有先前手动调优的操作以及自动检查点。MONeT为各种PyTorch模型减少了3倍的整体内存需求，计算开销增加了9-16%。在相同的计算成本下，MONeT需要比当前最先进的自动检查点框架少1.2-1.8倍的内存。我们的代码将在接受后公开提供。",
        "领域": "深度学习优化、自动机器学习、计算资源管理",
        "问题": "解决深度学习训练过程中内存占用过高的问题",
        "动机": "由于GPU内存增长速度远低于计算能力的提升，限制了大型深度学习模型的训练和探索",
        "方法": "提出了MONeT框架，通过联合优化检查点调度和算子实现，自动减少内存占用和计算开销",
        "关键词": [
            "内存优化",
            "深度学习",
            "自动框架",
            "检查点调度",
            "算子优化"
        ],
        "涉及的技术概念": {
            "检查点调度": "在训练过程中智能地保存和恢复模型状态，以减少内存使用",
            "算子优化": "改进深度学习模型中各个操作的实现，以提高计算效率和减少内存占用",
            "自动框架": "MONeT框架能够自动进行内存和计算的优化，无需人工干预"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 495,
        "title": "Meta Back-Translation",
        "html": "https://iclr.cc//virtual/2021/poster/2541",
        "abstract": "Back-translation is an effective strategy to improve the performance of Neural Machine Translation~(NMT) by generating pseudo-parallel data. However, several recent works have found that better translation quality in the pseudo-parallel data does not necessarily lead to a better final translation model, while lower-quality but diverse data often yields stronger results instead.\nIn this paper we propose a new way to generate pseudo-parallel data for back-translation that directly optimizes the final model performance.  Specifically, we propose a meta-learning framework where the back-translation model learns to match the forward-translation model's gradients on the development data with those on the pseudo-parallel data. In our evaluations in both the standard datasets WMT En-De'14 and WMT En-Fr'14, as well as a multilingual translation setting, our method leads to significant improvements over strong baselines. ",
        "conference": "ICLR",
        "中文标题": "元反向翻译",
        "摘要翻译": "反向翻译是一种通过生成伪平行数据来提高神经机器翻译（NMT）性能的有效策略。然而，最近的几项工作发现，伪平行数据中更好的翻译质量并不一定导致更好的最终翻译模型，而质量较低但多样化的数据往往能产生更强的结果。在本文中，我们提出了一种新的生成伪平行数据的方法，该方法直接优化最终模型的性能。具体来说，我们提出了一个元学习框架，其中反向翻译模型学习在开发数据上与伪平行数据上的前向翻译模型的梯度相匹配。在我们对标准数据集WMT En-De'14和WMT En-Fr'14以及多语言翻译设置的评估中，我们的方法相对于强基线带来了显著的改进。",
        "领域": "神经机器翻译、元学习、多语言处理",
        "问题": "如何生成更有效的伪平行数据以优化神经机器翻译模型的性能",
        "动机": "解决伪平行数据质量与模型性能之间不一致的问题，通过优化数据生成过程直接提升翻译模型的表现",
        "方法": "提出一个元学习框架，使反向翻译模型能够学习匹配前向翻译模型在开发数据和伪平行数据上的梯度",
        "关键词": [
            "反向翻译",
            "元学习",
            "伪平行数据",
            "神经机器翻译",
            "多语言处理"
        ],
        "涉及的技术概念": {
            "反向翻译": "一种通过将目标语言翻译回源语言来生成伪平行数据的技术，用于增强神经机器翻译模型的训练",
            "元学习": "一种学习如何学习的方法，使模型能够快速适应新任务，本文中用于优化反向翻译过程",
            "伪平行数据": "通过反向翻译等方法生成的非真实平行数据，用于扩充训练数据集以提高模型性能"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 496,
        "title": "Meta-GMVAE: Mixture of Gaussian VAE for Unsupervised Meta-Learning",
        "html": "https://iclr.cc//virtual/2021/poster/3317",
        "abstract": "Unsupervised learning aims to learn meaningful representations from unlabeled data which can captures its intrinsic structure, that can be transferred to downstream tasks. Meta-learning, whose objective is to learn to generalize across tasks such that the learned model can rapidly adapt to a novel task, shares the spirit of unsupervised learning in that the both seek to learn more effective and efficient learning procedure than learning from scratch. The fundamental difference of the two is that the most meta-learning approaches are supervised, assuming full access to the labels. However, acquiring labeled dataset for meta-training not only is costly as it requires human efforts in labeling but also limits its applications to pre-defined task distributions. In this paper, we propose a principled unsupervised meta-learning model, namely Meta-GMVAE, based on Variational Autoencoder (VAE) and set-level variational inference. Moreover, we introduce a mixture of Gaussian (GMM) prior, assuming that each modality represents each class-concept in a randomly sampled episode, which we optimize with Expectation-Maximization (EM). Then, the learned model can be used for downstream few-shot classification tasks, where we obtain task-specific parameters by performing semi-supervised EM on the latent representations of the support and query set, and predict labels of the query set by computing aggregated posteriors. We validate our model on Omniglot and Mini-ImageNet datasets by evaluating its performance on downstream few-shot classification tasks. The results show that our model obtain impressive performance gains over existing unsupervised meta-learning baselines, even outperforming supervised MAML on a certain setting.",
        "conference": "ICLR",
        "中文标题": "Meta-GMVAE：用于无监督元学习的高斯混合变分自编码器",
        "摘要翻译": "无监督学习旨在从未标记的数据中学习有意义的表示，这些表示能够捕捉其内在结构，并可以迁移到下游任务中。元学习的目标是学习跨任务泛化，使得学习到的模型能够快速适应新任务，这与无监督学习的精神相契合，因为两者都寻求比从零开始学习更有效和高效的学习过程。两者的根本区别在于，大多数元学习方法是有监督的，假设可以完全访问标签。然而，获取用于元训练的标记数据集不仅成本高昂，因为它需要人工标注，而且将其应用限制在预定义的任务分布上。在本文中，我们提出了一种基于变分自编码器（VAE）和集合级变分推理的原则性无监督元学习模型，即Meta-GMVAE。此外，我们引入了高斯混合（GMM）先验，假设每个模态代表随机采样情节中的每个类概念，我们使用期望最大化（EM）对其进行优化。然后，学习到的模型可以用于下游的少样本分类任务，其中我们通过对支持和查询集的潜在表示执行半监督EM来获得任务特定参数，并通过计算聚合后验来预测查询集的标签。我们在Omniglot和Mini-ImageNet数据集上验证了我们的模型，通过评估其在下游少样本分类任务上的性能。结果表明，我们的模型在现有无监督元学习基线上获得了令人印象深刻的性能提升，甚至在某些设置上超过了有监督的MAML。",
        "领域": "无监督学习、元学习、少样本学习",
        "问题": "如何在无监督的情况下进行有效的元学习，以快速适应新任务",
        "动机": "减少对标记数据的依赖，扩展元学习应用到更广泛的任务分布",
        "方法": "基于变分自编码器和集合级变分推理，引入高斯混合先验，使用期望最大化算法优化",
        "关键词": [
            "无监督元学习",
            "高斯混合变分自编码器",
            "少样本分类"
        ],
        "涉及的技术概念": {
            "变分自编码器（VAE）": "用于学习数据的潜在表示，支持无监督学习",
            "高斯混合模型（GMM）": "作为先验分布，帮助模型捕捉数据中的多模态结构",
            "期望最大化（EM）": "用于优化高斯混合模型的参数，实现有效的模型训练"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 497,
        "title": "Meta-Learning of Structured Task Distributions in Humans and Machines",
        "html": "https://iclr.cc//virtual/2021/poster/3064",
        "abstract": "In recent years, meta-learning, in which a model is trained on a family of tasks (i.e. a task distribution), has emerged as an approach to training neural networks to perform tasks that were previously assumed to require structured representations, making strides toward closing the gap between humans and machines. However, we argue that evaluating meta-learning remains a challenge, and can miss whether meta-learning actually uses the structure embedded within the tasks. These meta-learners might therefore still be significantly different from humans learners. To demonstrate this difference, we first define a new meta-reinforcement learning task in which a structured task distribution is generated using a compositional grammar. We then introduce a novel approach to constructing a 'null task distribution' with the same statistical complexity as this structured task distribution but without the explicit rule-based structure used to generate the structured task. We train a standard meta-learning agent, a recurrent network trained with model-free reinforcement learning, and compare it with human performance across the two task distributions. We find a double dissociation in which humans do better in the structured task distribution whereas agents do better in the null task distribution -- despite comparable statistical complexity. This work highlights that multiple strategies can achieve reasonable meta-test performance, and that careful construction of control task distributions is a valuable way to understand which strategies meta-learners acquire, and how they might differ from humans. ",
        "conference": "ICLR",
        "中文标题": "人类与机器中结构化任务分布的元学习",
        "摘要翻译": "近年来，元学习——即在一个任务族（即任务分布）上训练模型——已成为一种训练神经网络执行那些以前被认为需要结构化表示的任务的方法，从而在缩小人类与机器之间的差距方面取得了进展。然而，我们认为评估元学习仍然是一个挑战，并且可能会忽略元学习是否真正利用了任务中嵌入的结构。因此，这些元学习者可能仍然与人类学习者有显著不同。为了证明这种差异，我们首先定义了一个新的元强化学习任务，其中使用组合语法生成一个结构化任务分布。然后，我们介绍了一种新颖的方法来构建一个'空任务分布'，该分布具有与结构化任务分布相同的统计复杂性，但没有用于生成结构化任务的明确的基于规则的结构。我们训练了一个标准的元学习代理，一个通过无模型强化学习训练的循环网络，并将其与人类在两个任务分布上的表现进行比较。我们发现了一个双重分离现象：人类在结构化任务分布中表现更好，而代理在空任务分布中表现更好——尽管统计复杂性相当。这项工作强调，多种策略可以实现合理的元测试性能，并且精心构建控制任务分布是理解元学习者获取哪些策略以及它们可能与人类有何不同的宝贵方法。",
        "领域": "元学习、强化学习、认知建模",
        "问题": "评估元学习是否真正利用了任务中嵌入的结构，以及元学习代理与人类学习者在处理结构化任务分布时的差异。",
        "动机": "探讨元学习代理与人类学习者在处理结构化任务分布时的表现差异，以理解元学习是否真正利用了任务的结构。",
        "方法": "定义了一个新的元强化学习任务，使用组合语法生成结构化任务分布，并构建一个统计复杂性相同但无明确规则结构的'空任务分布'，比较人类和元学习代理的表现。",
        "关键词": [
            "元学习",
            "强化学习",
            "结构化任务分布",
            "人类与机器比较",
            "认知建模"
        ],
        "涉及的技术概念": {
            "元学习": "在多个任务上训练模型，使其能够快速适应新任务的技术。",
            "强化学习": "通过奖励机制学习最优行为策略的机器学习方法。",
            "结构化任务分布": "通过明确的规则或语法生成的任务集合，具有一定的内在结构。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 498,
        "title": "Meta-learning Symmetries by Reparameterization",
        "html": "https://iclr.cc//virtual/2021/poster/2607",
        "abstract": "Many successful deep learning architectures are equivariant to certain transformations in order to conserve parameters and improve generalization: most famously, convolution layers are equivariant to shifts of the input. This approach only works when practitioners know the symmetries of the task and can manually construct an architecture with the corresponding equivariances. Our goal is an approach for learning equivariances from data, without needing to design custom task-specific architectures. We present a method for learning and encoding equivariances into networks by learning corresponding parameter sharing patterns from data. Our method can provably represent equivariance-inducing parameter sharing for any finite group of symmetry transformations. Our experiments suggest that it can automatically learn to encode equivariances to common transformations used in image processing tasks.",
        "conference": "ICLR",
        "中文标题": "通过重参数化进行对称性的元学习",
        "摘要翻译": "许多成功的深度学习架构对某些变换具有等变性，以节省参数并提高泛化能力：最著名的是，卷积层对输入的平移具有等变性。这种方法仅在实践者知道任务的对称性并能手动构建具有相应等变性的架构时有效。我们的目标是提出一种从数据中学习等变性的方法，而无需设计特定于任务的自定义架构。我们提出了一种方法，通过从数据中学习相应的参数共享模式，将等变性学习和编码到网络中。我们的方法可以证明地表示任何有限对称变换群的等变性诱导参数共享。我们的实验表明，它可以自动学习编码图像处理任务中常用变换的等变性。",
        "领域": "深度学习架构设计、图像处理、对称性学习",
        "问题": "如何从数据中自动学习等变性，而无需手动设计具有特定等变性的网络架构",
        "动机": "减少对任务对称性先验知识的依赖，自动学习并编码等变性到网络中",
        "方法": "通过从数据中学习参数共享模式，自动编码等变性到网络架构中",
        "关键词": [
            "元学习",
            "对称性学习",
            "参数共享",
            "等变性",
            "深度学习架构"
        ],
        "涉及的技术概念": {
            "等变性": "网络对输入变换的响应特性，使得输出以可预测的方式随输入变换而变化",
            "参数共享": "在网络的不同部分使用相同的参数，以减少模型复杂度和提高泛化能力",
            "有限对称变换群": "描述了一组有限的对称变换操作，网络通过学习这些变换的等变性来提高性能"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 499,
        "title": "Meta-learning with negative learning rates",
        "html": "https://iclr.cc//virtual/2021/poster/3183",
        "abstract": "Deep learning models require a large amount of data to perform well. When data is scarce for a target task, we can transfer the knowledge gained by training on similar tasks to quickly learn the target. A successful approach is meta-learning, or 'learning to learn' a distribution of tasks, where 'learning' is represented by an outer loop, and 'to learn' by an inner loop of gradient descent. However, a number of recent empirical studies argue that the inner loop is unnecessary and more simple models work equally well or even better. We study the performance of MAML as a function of the learning rate of the inner loop, where zero learning rate implies that there is no inner loop. Using random matrix theory and exact solutions of linear models, we calculate an algebraic expression for the test loss of MAML applied to mixed linear regression and nonlinear regression with overparameterized models. Surprisingly, while the optimal learning rate for adaptation is positive, we find that the optimal learning rate for training is always negative, a setting that has never been considered before. Therefore, not only does the performance increase by decreasing the learning rate to zero, as suggested by recent work, but it can be increased even further by decreasing the learning rate to negative\nvalues. These results help clarify under what circumstances meta-learning performs best.",
        "conference": "ICLR",
        "中文标题": "负学习率下的元学习",
        "摘要翻译": "深度学习模型需要大量数据才能表现良好。当目标任务的数据稀缺时，我们可以通过训练相似任务获得的知识来快速学习目标任务。一种成功的方法是元学习，或称‘学习如何学习’一系列任务，其中‘学习’由外循环表示，‘如何学习’由梯度下降的内循环表示。然而，最近的一些实证研究认为内循环是不必要的，更简单的模型表现同样好甚至更好。我们研究了MAML（模型无关的元学习）性能作为内循环学习率的函数，其中零学习率意味着没有内循环。利用随机矩阵理论和线性模型的精确解，我们计算了MAML应用于混合线性回归和过参数化模型的非线性回归的测试损失的代数表达式。令人惊讶的是，虽然适应的最佳学习率是正的，但我们发现训练的最佳学习率总是负的，这是一个以前从未考虑过的设置。因此，不仅通过将学习率降低到零可以提高性能，正如最近的工作所建议的那样，而且通过将学习率降低到负值可以进一步提高性能。这些结果有助于澄清在什么情况下元学习表现最佳。",
        "领域": "元学习、深度学习优化、迁移学习",
        "问题": "研究在数据稀缺情况下，如何通过元学习优化模型性能，特别是探索内循环学习率对模型性能的影响。",
        "动机": "探索元学习中内循环学习率的作用，特别是在数据稀缺的情况下，如何通过调整学习率（包括负学习率）来优化模型性能。",
        "方法": "使用随机矩阵理论和线性模型的精确解，分析MAML在混合线性回归和过参数化模型的非线性回归中的性能，特别关注内循环学习率的影响。",
        "关键词": [
            "元学习",
            "负学习率",
            "MAML",
            "过参数化模型",
            "混合线性回归"
        ],
        "涉及的技术概念": {
            "元学习": "一种‘学习如何学习’的方法，旨在通过训练一系列任务来提高模型在新任务上的学习效率和性能。",
            "MAML": "模型无关的元学习，一种元学习算法，通过梯度下降在多个任务上进行训练，以快速适应新任务。",
            "负学习率": "在训练过程中使用负值的学习率，这在传统深度学习中不常见，但在本研究中发现可以进一步提高元学习的性能。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 500,
        "title": "Meta-Learning with Neural Tangent Kernels",
        "html": "https://iclr.cc//virtual/2021/poster/2848",
        "abstract": "Model Agnostic Meta-Learning (MAML) has emerged as a standard framework for meta-learning, where a meta-model is learned with the ability of fast adapting to new tasks. However, as a double-looped optimization problem, MAML needs to differentiate through the whole inner-loop optimization path for every outer-loop training step, which may lead to both computational inefficiency and sub-optimal solutions. In this paper, we generalize MAML to allow meta-learning to be defined in function spaces, and propose the first meta-learning paradigm in the Reproducing Kernel Hilbert Space (RKHS) induced by the meta-model's Neural Tangent Kernel (NTK). Within this paradigm, we introduce two meta-learning algorithms in the RKHS, which no longer need a sub-optimal iterative inner-loop adaptation as in the MAML framework. We achieve this goal by 1) replacing the adaptation with a fast-adaptive regularizer in the RKHS; and 2) solving the adaptation analytically based on the NTK theory. Extensive experimental studies demonstrate advantages of our paradigm in both efficiency and quality of solutions compared to related meta-learning algorithms. Another interesting feature of our proposed methods is that they are demonstrated to be more robust to adversarial attacks and out-of-distribution adaptation than popular baselines, as demonstrated in our experiments.",
        "conference": "ICLR",
        "中文标题": "基于神经正切核的元学习",
        "摘要翻译": "模型无关的元学习（MAML）已成为元学习的标准框架，其中元模型具有快速适应新任务的能力。然而，作为一个双循环优化问题，MAML需要在每个外循环训练步骤中通过整个内循环优化路径进行微分，这可能导致计算效率低下和次优解。在本文中，我们将MAML推广到允许在函数空间中定义元学习，并提出了由元模型的神经正切核（NTK）诱导的再生核希尔伯特空间（RKHS）中的第一个元学习范式。在这一范式中，我们在RKHS中引入了两种元学习算法，它们不再需要像MAML框架中那样进行次优的迭代内循环适应。我们通过以下方式实现这一目标：1）在RKHS中用快速自适应正则化器替换适应；2）基于NTK理论解析地解决适应问题。广泛的实验研究表明，与相关的元学习算法相比，我们的范式在解决方案的效率和质量上都具有优势。我们提出的方法的另一个有趣特点是，实验证明它们比流行的基线方法对对抗性攻击和分布外适应更具鲁棒性。",
        "领域": "元学习",
        "问题": "解决MAML框架中计算效率低下和次优解的问题",
        "动机": "提高元学习算法的效率和解决方案的质量，同时增强对对抗性攻击和分布外适应的鲁棒性",
        "方法": "在由神经正切核诱导的再生核希尔伯特空间中定义元学习，并引入两种不需要迭代内循环适应的算法",
        "关键词": [
            "元学习",
            "神经正切核",
            "再生核希尔伯特空间",
            "快速自适应正则化器",
            "对抗性鲁棒性"
        ],
        "涉及的技术概念": {
            "神经正切核（NTK）": "用于诱导再生核希尔伯特空间，支持在函数空间中进行元学习",
            "再生核希尔伯特空间（RKHS）": "提供了一个数学框架，使得元学习可以在函数空间中进行",
            "快速自适应正则化器": "替换了传统MAML中的迭代内循环适应，提高了计算效率和解决方案的质量"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 501,
        "title": "MetaNorm: Learning to Normalize Few-Shot Batches Across Domains",
        "html": "https://iclr.cc//virtual/2021/poster/3313",
        "abstract": "Batch normalization plays a crucial role when training deep neural networks. However, batch statistics become unstable with small batch sizes and are unreliable in the presence of distribution shifts. We propose MetaNorm, a simple yet effective meta-learning normalization. It tackles the aforementioned issues in a unified way by leveraging the meta-learning setting and learns to infer adaptive statistics for batch normalization. MetaNorm is generic, flexible and model-agnostic, making it a simple plug-and-play module that is seamlessly embedded into existing meta-learning approaches. It can be efficiently implemented by lightweight hypernetworks with low computational cost. We verify its effectiveness by extensive evaluation on representative tasks suffering from the small batch and domain shift problems: few-shot learning and domain generalization. We further introduce an even more challenging setting: few-shot domain generalization. Results demonstrate that MetaNorm consistently achieves better, or at least competitive, accuracy compared to existing batch normalization methods.  ",
        "conference": "ICLR",
        "中文标题": "MetaNorm：跨领域小批量归一化的学习",
        "摘要翻译": "批量归一化在训练深度神经网络时扮演着关键角色。然而，在小批量大小下，批量统计变得不稳定，并且在存在分布偏移时不可靠。我们提出了MetaNorm，一种简单而有效的元学习归一化方法。它通过利用元学习设置，以一种统一的方式解决了上述问题，并学习推断用于批量归一化的自适应统计量。MetaNorm是通用的、灵活的且与模型无关的，使其成为一个简单的即插即用模块，可以无缝嵌入现有的元学习方法中。它可以通过计算成本低的轻量级超网络高效实现。我们通过在代表性任务上的广泛评估验证了其有效性，这些任务受到小批量和领域偏移问题的困扰：少样本学习和领域泛化。我们进一步引入了一个更具挑战性的设置：少样本领域泛化。结果表明，与现有的批量归一化方法相比，MetaNorm始终能够达到更好或至少具有竞争力的准确率。",
        "领域": "元学习、少样本学习、领域泛化",
        "问题": "解决在小批量大小和分布偏移情况下批量归一化统计量不稳定和不可靠的问题",
        "动机": "为了提高在少样本学习和领域泛化等任务中深度神经网络的训练效果和泛化能力",
        "方法": "提出MetaNorm，一种基于元学习的归一化方法，通过学习自适应统计量来改进批量归一化",
        "关键词": [
            "元学习",
            "批量归一化",
            "少样本学习",
            "领域泛化",
            "超网络"
        ],
        "涉及的技术概念": {
            "元学习": "用于学习如何学习，使模型能够快速适应新任务",
            "批量归一化": "一种用于加速深度神经网络训练的技术，通过规范化每一层的输入",
            "超网络": "一种生成其他网络参数的网络，用于高效实现MetaNorm"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 502,
        "title": "MiCE: Mixture of Contrastive Experts for Unsupervised Image Clustering",
        "html": "https://iclr.cc//virtual/2021/poster/2882",
        "abstract": "We present Mixture of Contrastive Experts (MiCE), a unified probabilistic clustering framework that simultaneously exploits the discriminative representations learned by contrastive learning and the semantic structures captured by a latent mixture model. Motivated by the mixture of experts, MiCE employs a gating function to partition an unlabeled dataset into subsets according to the latent semantics and multiple experts to discriminate distinct subsets of instances assigned to them in a contrastive learning manner. To solve the nontrivial inference and learning problems caused by the latent variables, we further develop a scalable variant of the Expectation-Maximization (EM) algorithm for MiCE and provide proof of the convergence. Empirically, we evaluate the clustering performance of MiCE on four widely adopted natural image datasets. MiCE achieves significantly better results than various previous methods and a strong contrastive learning baseline.",
        "conference": "ICLR",
        "中文标题": "MiCE：用于无监督图像聚类的对比专家混合",
        "摘要翻译": "我们提出了对比专家混合（MiCE），这是一个统一的概率聚类框架，它同时利用了对比学习学到的判别性表示和潜在混合模型捕获的语义结构。受到专家混合的启发，MiCE采用一个门控函数根据潜在语义将未标记的数据集划分为子集，并采用多个专家以对比学习的方式区分分配给它们的实例的不同子集。为了解决由潜在变量引起的非平凡推理和学习问题，我们进一步为MiCE开发了一个可扩展的期望最大化（EM）算法变体，并提供了收敛性证明。实证上，我们在四个广泛采用的自然图像数据集上评估了MiCE的聚类性能。MiCE取得了比各种先前方法和一个强大的对比学习基线显著更好的结果。",
        "领域": "无监督学习、图像聚类、对比学习",
        "问题": "如何在无监督图像聚类中同时利用对比学习的判别性表示和潜在混合模型的语义结构",
        "动机": "为了更有效地进行无监督图像聚类，结合对比学习的判别能力和潜在混合模型对语义结构的捕捉能力",
        "方法": "提出了一种统一的概率聚类框架MiCE，结合了门控函数和多个专家进行对比学习，并开发了一个可扩展的EM算法变体来解决潜在变量带来的问题",
        "关键词": [
            "无监督图像聚类",
            "对比学习",
            "专家混合",
            "期望最大化算法",
            "潜在语义"
        ],
        "涉及的技术概念": {
            "对比学习": "用于学习判别性表示，帮助区分不同的图像实例",
            "专家混合": "通过门控函数和多个专家模型，根据潜在语义划分和区分实例",
            "期望最大化算法": "用于解决模型中的潜在变量问题，优化模型参数并保证收敛"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 503,
        "title": "Mind the Gap when Conditioning Amortised Inference in Sequential Latent-Variable Models",
        "html": "https://iclr.cc//virtual/2021/poster/2610",
        "abstract": "Amortised inference enables scalable learning of sequential latent-variable models (LVMs) with the evidence lower bound (ELBO). In this setting, variational posteriors are often only partially conditioned. While the true posteriors depend, e.g., on the entire sequence of observations, approximate posteriors are only informed by past observations. This mimics the Bayesian filter---a mixture of smoothing posteriors. Yet, we show that the ELBO objective forces partially-conditioned amortised posteriors to approximate products of smoothing posteriors instead. Consequently, the learned generative model is compromised. We demonstrate these theoretical findings in three scenarios: traffic flow, handwritten digits, and aerial vehicle dynamics. Using fully-conditioned approximate posteriors, performance improves in terms of generative modelling and multi-step prediction.",
        "conference": "ICLR",
        "中文标题": "注意条件化摊销推断在序列潜在变量模型中的差距",
        "摘要翻译": "摊销推断使得利用证据下界（ELBO）可扩展地学习序列潜在变量模型（LVMs）成为可能。在这一设置下，变分后验往往只是部分条件化的。虽然真实的后验依赖于整个观测序列，近似后验却仅由过去的观测信息决定。这模仿了贝叶斯滤波器——一种平滑后验的混合。然而，我们表明，ELBO目标迫使部分条件化的摊销后验去近似平滑后验的乘积。因此，学习到的生成模型受到了影响。我们在三种场景中展示了这些理论发现：交通流量、手写数字和飞行器动力学。使用完全条件化的近似后验，生成建模和多步预测的性能得到了提升。",
        "领域": "序列潜在变量模型、变分推断、生成模型",
        "问题": "部分条件化的摊销推断在序列潜在变量模型中导致的后验近似问题",
        "动机": "研究部分条件化的摊销推断如何影响序列潜在变量模型的学习效果，以及如何通过完全条件化的近似后验提升模型性能",
        "方法": "通过理论分析和在交通流量、手写数字及飞行器动力学三种场景下的实验，比较部分条件化和完全条件化近似后验对模型性能的影响",
        "关键词": [
            "摊销推断",
            "序列潜在变量模型",
            "变分推断",
            "生成模型",
            "多步预测"
        ],
        "涉及的技术概念": {
            "摊销推断": "一种通过共享参数来高效近似后验分布的技术，用于可扩展地学习潜在变量模型",
            "序列潜在变量模型": "一类处理序列数据的生成模型，其中潜在变量序列生成观测序列",
            "变分推断": "一种近似推断方法，通过优化变分下界来近似难以计算的后验分布"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 504,
        "title": "Mind the Pad -- CNNs Can Develop Blind Spots",
        "html": "https://iclr.cc//virtual/2021/poster/3295",
        "abstract": "We show how feature maps in convolutional networks are susceptible to spatial bias. Due to a combination of architectural choices, the activation at certain locations is systematically elevated or weakened. The major source of this bias is the padding mechanism. Depending on several aspects of convolution arithmetic, this mechanism can apply the padding unevenly, leading to asymmetries in the learned weights. We demonstrate how such bias can be detrimental to certain tasks such as small object detection: the activation is suppressed if the stimulus lies in the impacted area, leading to blind spots and misdetection. We explore alternative padding methods and propose solutions for analyzing and mitigating spatial bias.\n",
        "conference": "ICLR",
        "中文标题": "注意填充——卷积神经网络可能产生盲点",
        "摘要翻译": "我们展示了卷积网络中的特征图如何容易受到空间偏差的影响。由于架构选择的组合，某些位置的激活被系统地提升或削弱。这种偏差的主要来源是填充机制。根据卷积算术的几个方面，这种机制可能不均匀地应用填充，导致学习到的权重不对称。我们证明了这种偏差如何对某些任务（如小物体检测）有害：如果刺激位于受影响区域，激活会被抑制，导致盲点和误检测。我们探索了替代的填充方法，并提出了分析和减轻空间偏差的解决方案。",
        "领域": "小物体检测",
        "问题": "卷积神经网络中由于填充机制导致的空间偏差问题",
        "动机": "解决卷积神经网络中因填充机制引起的空间偏差，特别是在小物体检测任务中导致的激活抑制和误检测问题",
        "方法": "探索替代的填充方法，并提出分析和减轻空间偏差的解决方案",
        "关键词": [
            "卷积神经网络",
            "空间偏差",
            "填充机制",
            "小物体检测",
            "激活抑制"
        ],
        "涉及的技术概念": {
            "特征图": "卷积网络中用于表示输入数据的空间特征",
            "填充机制": "在卷积操作中用于处理边界像素的技术，可能导致空间偏差",
            "激活抑制": "由于空间偏差，某些区域的激活被削弱，影响模型性能"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 505,
        "title": "Minimum Width for Universal Approximation",
        "html": "https://iclr.cc//virtual/2021/poster/2920",
        "abstract": "The universal approximation property of width-bounded networks has been studied as a dual of classical universal approximation results on depth-bounded networks. However, the critical width enabling the universal approximation has not been exactly characterized in terms of the input dimension $d_x$ and the output dimension $d_y$. In this work, we provide the first definitive result in this direction for networks using the ReLU activation functions: The minimum width required for the universal approximation of the $L^p$ functions is exactly $\\max\\{d_x+1,d_y\\}$. We also prove that the same conclusion does not hold for the uniform approximation with ReLU, but does hold with an additional threshold activation function. Our proof technique can be also used to derive a tighter upper bound on the minimum width required for the universal approximation using networks with general activation functions.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "通用逼近的最小宽度",
        "摘要翻译": "宽度受限网络的通用逼近性质已被研究为深度受限网络上经典通用逼近结果的对偶。然而，实现通用逼近的关键宽度尚未根据输入维度dx和输出维度dy进行精确表征。在这项工作中，我们为使用ReLU激活函数的网络提供了这方面的第一个明确结果：L^p函数通用逼近所需的最小宽度恰好是max{dx+1, dy}。我们还证明了相同的结论不适用于ReLU的均匀逼近，但适用于附加的阈值激活函数。我们的证明技术也可用于推导使用具有通用激活函数的网络进行通用逼近所需的最小宽度的更严格上限。",
        "领域": "神经网络理论, 函数逼近, 激活函数研究",
        "问题": "确定ReLU激活函数网络实现通用逼近所需的最小宽度，并研究该结论在不同逼近方式下的适用性。",
        "动机": "理解宽度受限网络的通用逼近能力，并精确表征实现通用逼近所需的最小宽度，对于设计高效的神经网络架构具有重要意义。",
        "方法": "理论分析和证明，结合ReLU激活函数的特性，推导L^p函数通用逼近所需的最小宽度，并推广到其他激活函数。",
        "关键词": [
            "通用逼近",
            "最小宽度",
            "ReLU激活函数",
            "L^p函数",
            "阈值激活函数"
        ],
        "涉及的技术概念": {
            "通用逼近": "神经网络逼近任意连续函数的能力，是深度学习理论的基础。",
            "ReLU激活函数": "一种常用的非线性激活函数，因其简单高效而被广泛应用。"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 506,
        "title": "Mirostat: A Neural Text Decoding Algorithm That Directly Controls Perplexity",
        "html": "https://iclr.cc//virtual/2021/poster/2700",
        "abstract": "Neural text decoding algorithms strongly influence the quality of texts generated using language models, but popular algorithms like top-k, top-p (nucleus), and temperature-based sampling may yield texts that have objectionable repetition or incoherence. Although these methods generate high-quality text after ad hoc parameter tuning that depends on the language model and the length of generated text, not much is known about the control they provide over the statistics of the output. This is important, however, since recent reports show that humans prefer when perplexity is neither too much nor too little and since we experimentally show that cross-entropy (log of perplexity) has a near-linear relation with repetition. First, we provide a theoretical analysis of perplexity in top-k, top-p, and temperature sampling, under Zipfian statistics. Then, we use this analysis to design a feedback-based adaptive top-k text decoding algorithm called mirostat that generates text (of any length) with a predetermined target value of perplexity without any tuning. Experiments show that for low values of k and p, perplexity drops significantly with generated text length and leads to excessive repetitions (the boredom trap). Contrarily, for large values of k and p, perplexity increases with generated text length and leads to incoherence (confusion trap). Mirostat avoids both traps. Specifically, we show that setting target perplexity value beyond a threshold yields negligible sentence-level repetitions. Experiments with\nhuman raters for fluency, coherence, and quality further verify our findings.",
        "conference": "ICLR",
        "中文标题": "Mirostat：一种直接控制困惑度的神经文本解码算法",
        "摘要翻译": "神经文本解码算法极大地影响了使用语言模型生成的文本质量，但流行的算法如top-k、top-p（核心）和基于温度的采样可能会产生具有不可接受的重复或不连贯的文本。尽管这些方法在经过依赖于语言模型和生成文本长度的临时参数调整后能生成高质量文本，但人们对它们对输出统计量的控制知之甚少。这一点很重要，因为最近的报告显示，人类偏好困惑度既不太高也不太低的情况，并且我们通过实验表明，交叉熵（困惑度的对数）与重复性有近乎线性的关系。首先，我们在Zipf统计下对top-k、top-p和温度采样中的困惑度进行了理论分析。然后，我们利用这一分析设计了一种基于反馈的自适应top-k文本解码算法，称为mirostat，它能在不进行任何调整的情况下生成具有预定目标困惑度值的文本（长度不限）。实验表明，对于k和p的低值，困惑度随着生成文本长度的增加而显著下降，导致过度重复（无聊陷阱）。相反，对于k和p的高值，困惑度随着生成文本长度的增加而增加，导致不连贯（混乱陷阱）。Mirostat避免了这两种陷阱。具体来说，我们展示了将目标困惑度值设定在阈值以上可以忽略不计句子级别的重复。针对流畅性、连贯性和质量的人类评分者实验进一步验证了我们的发现。",
        "领域": "自然语言处理与视觉结合、文本生成、语言模型优化",
        "问题": "解决神经文本解码算法在生成文本时可能产生的重复或不连贯问题",
        "动机": "探索如何通过控制困惑度来提升生成文本的质量和人类偏好",
        "方法": "设计了一种基于反馈的自适应top-k文本解码算法mirostat，直接控制生成文本的困惑度",
        "关键词": [
            "文本解码",
            "困惑度控制",
            "自适应算法",
            "语言模型",
            "文本生成"
        ],
        "涉及的技术概念": {
            "困惑度": "用于衡量语言模型预测文本序列的不确定性，mirostat算法直接控制此值以优化文本生成质量",
            "自适应top-k采样": "一种动态调整k值的采样方法，旨在避免生成文本时的重复或不连贯问题",
            "Zipfian统计": "用于分析文本中单词频率分布的统计模型，支持mirostat算法的理论分析"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 507,
        "title": "Mixed-Features Vectors and Subspace Splitting",
        "html": "https://iclr.cc//virtual/2021/poster/2525",
        "abstract": "Motivated by metagenomics, recommender systems, dictionary learning, and related problems, this paper introduces subspace splitting(SS): the task of clustering the entries of what we call amixed-features vector, that is, a vector whose subsets of coordinates agree with a collection of subspaces. We derive precise identifiability conditions under which SS is well-posed, thus providing the first fundamental theory for this problem. We also propose the first three practical SS algorithms, each with advantages and disadvantages: a random sampling method , a projection-based greedy heuristic , and an alternating Lloyd-type algorithm ; all allow noise, outliers, and missing data. Our extensive experiments outline the performance of our algorithms, and in lack of other SS algorithms, for reference we compare against methods for tightly related problems, like robust matched subspace detection and maximum feasible subsystem, which are special simpler cases of SS.",
        "conference": "ICLR",
        "中文标题": "混合特征向量与子空间分割",
        "摘要翻译": "受到元基因组学、推荐系统、字典学习及相关问题的启发，本文介绍了子空间分割(SS)任务：即对我们所称的混合特征向量的条目进行聚类，该向量的坐标子集与一组子空间一致。我们推导了SS问题适定的精确可识别性条件，从而为该问题提供了第一个基本理论。我们还提出了前三个实用的SS算法，每种算法都有其优缺点：随机抽样方法、基于投影的贪婪启发式算法和交替Lloyd型算法；所有这些算法都允许噪声、异常值和缺失数据。我们的大量实验概述了我们算法的性能，并且由于缺乏其他SS算法，作为参考，我们将其与紧密相关问题的解决方法进行比较，如鲁棒匹配子空间检测和最大可行子系统，这些都是SS的特殊简化案例。",
        "领域": "子空间聚类、特征提取、数据挖掘",
        "问题": "如何对混合特征向量的条目进行有效聚类，这些向量的坐标子集与一组子空间一致。",
        "动机": "为了解决元基因组学、推荐系统、字典学习等领域中混合特征向量聚类的问题。",
        "方法": "提出了三种子空间分割算法：随机抽样方法、基于投影的贪婪启发式算法和交替Lloyd型算法。",
        "关键词": [
            "子空间分割",
            "混合特征向量",
            "聚类算法",
            "可识别性条件",
            "噪声容忍"
        ],
        "涉及的技术概念": {
            "子空间分割(SS)": "任务是对混合特征向量的条目进行聚类，这些向量的坐标子集与一组子空间一致。",
            "可识别性条件": "确保子空间分割问题适定的条件，为问题提供了理论基础。",
            "交替Lloyd型算法": "一种用于子空间分割的算法，允许噪声、异常值和缺失数据的存在。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 508,
        "title": "MixKD: Towards Efficient Distillation of Large-scale Language Models",
        "html": "https://iclr.cc//virtual/2021/poster/2554",
        "abstract": "Large-scale language models have recently demonstrated impressive empirical performance. Nevertheless, the improved results are attained at the price of bigger models, more power consumption, and slower inference, which hinder their applicability to low-resource (both memory and computation) platforms. Knowledge distillation (KD) has been demonstrated as an effective framework for compressing such big models. However, large-scale neural network systems are prone to memorize training instances, and thus tend to make inconsistent predictions when the data distribution is altered slightly. Moreover, the student model has few opportunities to request useful information from the teacher model when there is limited task-specific data available. To address these issues, we propose MixKD, a data-agnostic distillation framework that leverages mixup, a simple yet efficient data augmentation approach, to endow the resulting model with stronger generalization ability. Concretely, in addition to the original training examples, the student model is encouraged to mimic the teacher's behavior on the linear interpolation of example pairs as well. We prove from a theoretical perspective that under reasonable conditions MixKD gives rise to a smaller gap between the generalization error and the empirical error. To verify its effectiveness, we conduct experiments on the GLUE benchmark, where MixKD consistently leads to significant gains over the standard KD training, and outperforms several competitive baselines. Experiments under a limited-data setting and ablation studies further demonstrate the advantages of the proposed approach.",
        "conference": "ICLR",
        "中文标题": "MixKD：迈向大规模语言模型高效蒸馏",
        "摘要翻译": "大规模语言模型最近展示了令人印象深刻的实证性能。然而，这些改进的结果是以更大的模型、更多的功耗和更慢的推理速度为代价的，这阻碍了它们在资源有限（包括内存和计算）平台上的适用性。知识蒸馏（KD）已被证明是压缩这类大模型的有效框架。然而，大规模神经网络系统容易记住训练实例，因此在数据分布稍有改变时往往会产生不一致的预测。此外，当特定任务的数据有限时，学生模型很少有机会从教师模型中请求有用信息。为了解决这些问题，我们提出了MixKD，一个数据无关的蒸馏框架，它利用mixup这一简单而高效的数据增强方法，赋予结果模型更强的泛化能力。具体来说，除了原始的训练例子外，还鼓励学生模型模仿教师模型在例子对的线性插值上的行为。我们从理论角度证明，在合理条件下，MixKD能够减小泛化误差和经验误差之间的差距。为了验证其有效性，我们在GLUE基准上进行了实验，MixKD在标准KD训练基础上持续带来显著增益，并优于几个竞争基线。在有限数据设置下的实验和消融研究进一步证明了所提出方法的优势。",
        "领域": "自然语言处理与视觉结合",
        "问题": "大规模语言模型在资源有限平台上的适用性问题",
        "动机": "提高大规模语言模型在资源有限平台上的适用性和泛化能力",
        "方法": "提出MixKD框架，利用mixup数据增强方法进行知识蒸馏",
        "关键词": [
            "知识蒸馏",
            "数据增强",
            "泛化能力"
        ],
        "涉及的技术概念": {
            "知识蒸馏": "用于压缩大规模语言模型，通过教师模型指导学生模型学习",
            "mixup": "一种数据增强方法，通过线性插值生成新的训练样本，增强模型的泛化能力",
            "泛化误差": "衡量模型在未见数据上表现与训练数据上表现差异的指标，MixKD旨在减小这一差距"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 509,
        "title": "MODALS: Modality-agnostic Automated Data Augmentation in the Latent Space",
        "html": "https://iclr.cc//virtual/2021/poster/2589",
        "abstract": "Data augmentation is an efficient way to expand a training dataset by creating additional artificial data. While data augmentation is found to be effective in improving the generalization capabilities of models for various machine learning tasks, the underlying augmentation methods are usually manually designed and carefully evaluated for each data modality separately, like image processing functions for image data and word-replacing rules for text data. In this work, we propose an automated data augmentation approach called MODALS (Modality-agnostic Automated Data Augmentation in the Latent Space) to augment data for any modality in a generic way. MODALS exploits automated data augmentation to fine-tune four universal data transformation operations in the latent space to adapt the transform to data of different modalities. Through comprehensive experiments, we demonstrate the effectiveness of MODALS on multiple datasets for text, tabular, time-series and image modalities.",
        "conference": "ICLR",
        "中文标题": "MODALS：潜在空间中的模态无关自动化数据增强",
        "摘要翻译": "数据增强是一种通过创建额外人工数据来扩展训练数据集的有效方法。虽然数据增强被发现能有效提高模型在各种机器学习任务中的泛化能力，但基础的增强方法通常是手动设计并针对每种数据模态单独仔细评估的，如图像数据的图像处理功能和文本数据的单词替换规则。在这项工作中，我们提出了一种名为MODALS（潜在空间中的模态无关自动化数据增强）的自动化数据增强方法，以通用方式为任何模态的数据进行增强。MODALS利用自动化数据增强来微调潜在空间中的四种通用数据转换操作，以适应不同模态的数据。通过全面的实验，我们在文本、表格、时间序列和图像模态的多个数据集上证明了MODALS的有效性。",
        "领域": "数据增强、多模态学习、自动化机器学习",
        "问题": "如何设计一种能够适用于不同数据模态的自动化数据增强方法",
        "动机": "现有的数据增强方法通常需要针对每种数据模态手动设计和评估，缺乏通用性和自动化",
        "方法": "提出MODALS方法，通过在潜在空间中微调四种通用数据转换操作，实现模态无关的自动化数据增强",
        "关键词": [
            "数据增强",
            "模态无关",
            "潜在空间",
            "自动化机器学习",
            "多模态学习"
        ],
        "涉及的技术概念": {
            "潜在空间": "用于表示数据的低维空间，MODALS在此空间中执行数据转换操作",
            "自动化数据增强": "MODALS自动调整数据增强策略，无需手动设计",
            "模态无关": "MODALS设计用于处理多种数据模态，如文本、图像、时间序列等"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 510,
        "title": "Model-based micro-data reinforcement learning: what are the crucial model properties and which model to choose?",
        "html": "https://iclr.cc//virtual/2021/poster/2884",
        "abstract": "We contribute to micro-data model-based reinforcement learning (MBRL) by rigorously comparing popular generative models using a fixed (random shooting) control agent. We find that on an environment that requires multimodal posterior predictives, mixture density nets outperform all other models by a large margin. When multimodality is not required, our surprising finding is that we do not need probabilistic posterior predictives: deterministic models are on par, in fact they consistently (although non-significantly) outperform their probabilistic counterparts. We also found that heteroscedasticity at training time, perhaps acting as a regularizer, improves predictions at longer horizons. At the methodological side, we design metrics and an experimental protocol which can be used to evaluate the various models, predicting their asymptotic performance when using them on the control problem. Using this framework, we improve the state-of-the-art sample complexity of MBRL on Acrobot by two to four folds, using an aggressive training schedule which is outside of the hyperparameter interval usually considered.",
        "conference": "ICLR",
        "中文标题": "基于模型的微数据强化学习：关键模型属性是什么以及如何选择模型？",
        "摘要翻译": "我们通过使用固定的（随机射击）控制代理严格比较流行的生成模型，为基于微数据的模型强化学习（MBRL）做出了贡献。我们发现，在一个需要多模态后验预测的环境中，混合密度网络以较大优势优于所有其他模型。当不需要多模态时，我们的惊人发现是我们不需要概率后验预测：确定性模型与之相当，事实上它们一致（虽然不显著）优于其概率对应物。我们还发现，训练时的异方差性，可能作为一种正则化器，改善了较长视野下的预测。在方法方面，我们设计了指标和实验协议，可用于评估各种模型，预测它们在控制问题上的渐近性能。使用这个框架，我们通过采用通常考虑的超参数区间之外的激进训练计划，将MBRL在Acrobot上的最新样本复杂度提高了两到四倍。",
        "领域": "强化学习、生成模型、控制策略",
        "问题": "在基于模型的强化学习中，如何选择最适合的生成模型以提高样本复杂度和控制性能。",
        "动机": "探索在基于模型的强化学习中，不同生成模型对控制性能的影响，特别是在需要多模态后验预测和不需要的情况下的表现差异。",
        "方法": "通过固定控制代理比较不同生成模型的表现，设计评估指标和实验协议，预测模型的渐近性能，并采用激进训练计划提高样本复杂度。",
        "关键词": [
            "模型强化学习",
            "混合密度网络",
            "异方差性",
            "样本复杂度",
            "控制策略"
        ],
        "涉及的技术概念": {
            "混合密度网络": "用于在需要多模态后验预测的环境中生成预测，显著优于其他模型。",
            "异方差性": "在训练时可能作为正则化器，改善模型在较长预测视野下的表现。",
            "样本复杂度": "通过激进训练计划显著提高，展示了在Acrobot任务上的性能提升。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 511,
        "title": "Model-Based Offline Planning",
        "html": "https://iclr.cc//virtual/2021/poster/3240",
        "abstract": "Offline learning is a key part of making reinforcement learning (RL) useable in real systems. Offline RL looks at scenarios where there is data from a system's operation, but no direct access to the system when learning a policy. Recent work on training RL policies from offline data has shown results both with model-free policies learned directly from the data, or with planning on top of learnt models of the data. Model-free policies tend to be more performant, but are more opaque, harder to command externally, and less easy to integrate into larger systems. We propose an offline learner that generates a model that can be used to control the system directly through planning. This allows us to have easily controllable policies directly from data, without ever interacting with the system. We show the performance of our algorithm, Model-Based Offline Planning (MBOP) on a series of robotics-inspired tasks, and demonstrate its ability leverage planning to respect environmental constraints. We are able to find near-optimal polices for certain simulated systems from as little as 50 seconds of real-time system interaction, and create zero-shot goal-conditioned policies on a series of environments.",
        "conference": "ICLR",
        "中文标题": "基于模型的离线规划",
        "摘要翻译": "离线学习是使强化学习（RL）在实际系统中可用的关键部分。离线RL研究的是有系统操作数据但在学习策略时无法直接访问系统的场景。最近关于从离线数据训练RL策略的工作显示，无论是直接从数据学习无模型策略，还是在学习的数据模型上进行规划，都取得了成果。无模型策略往往表现更好，但更不透明，更难从外部控制，也更难集成到更大的系统中。我们提出了一种离线学习器，它生成一个可以通过规划直接控制系统使用的模型。这使我们能够直接从数据中获得易于控制的策略，而无需与系统交互。我们在一系列受机器人启发的任务上展示了我们的算法——基于模型的离线规划（MBOP）的性能，并证明了其利用规划尊重环境约束的能力。我们能够从仅50秒的实时系统交互中为某些模拟系统找到接近最优的策略，并在一系列环境中创建零样本目标条件策略。",
        "领域": "强化学习、机器人控制、策略优化",
        "问题": "如何在无法直接访问系统的情况下，从离线数据中学习有效的控制策略",
        "动机": "解决无模型策略在透明性、可控性和系统集成方面的不足",
        "方法": "提出一种基于模型的离线规划方法（MBOP），通过生成可用于直接规划控制的模型，实现从数据中学习易于控制的策略",
        "关键词": [
            "离线强化学习",
            "模型预测控制",
            "机器人任务",
            "策略优化",
            "零样本学习"
        ],
        "涉及的技术概念": {
            "离线强化学习": "在无法直接与环境交互的情况下，从历史数据中学习策略的方法",
            "模型预测控制": "利用系统模型进行未来状态预测和动作规划的控制策略",
            "零样本学习": "在训练阶段未见过的任务或目标条件下，能够直接执行策略的能力"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 512,
        "title": "Model-Based Visual Planning with Self-Supervised Functional Distances",
        "html": "https://iclr.cc//virtual/2021/poster/2599",
        "abstract": "A generalist robot must be able to complete a variety of tasks in its environment. One appealing way to specify each task is in terms of a goal observation. However, learning goal-reaching policies with reinforcement learning remains a challenging problem, particularly when hand-engineered reward functions are not available. Learned dynamics models are a promising approach for learning about the environment without rewards or task-directed data, but planning to reach goals with such a model requires a notion of functional similarity between observations and goal states. We present a self-supervised method for model-based visual goal reaching, which uses both a visual dynamics model as well as a dynamical distance function learned using model-free reinforcement learning. Our approach learns entirely using offline, unlabeled data, making it practical to scale to large and diverse datasets. In our experiments, we find that our method can successfully learn models that perform a variety of tasks at test-time, moving objects amid distractors with a simulated robotic arm and even learning to open and close a drawer using a real-world robot. In comparisons, we find that this approach substantially outperforms both model-free and model-based prior methods.",
        "conference": "ICLR",
        "中文标题": "基于模型的视觉规划与自监督功能距离",
        "摘要翻译": "一个通用机器人必须能够在其环境中完成各种任务。指定每个任务的一种吸引人的方式是通过目标观察。然而，使用强化学习学习达到目标的策略仍然是一个具有挑战性的问题，特别是当没有手工设计的奖励函数时。学习到的动态模型是一种无需奖励或任务导向数据即可了解环境的有前途的方法，但使用这样的模型规划达到目标需要观察和目标状态之间的功能相似性概念。我们提出了一种基于模型的视觉目标达成的自监督方法，该方法既使用视觉动态模型，也使用通过无模型强化学习学习到的动态距离函数。我们的方法完全使用离线、未标记的数据进行学习，使其能够实际扩展到大型和多样化的数据集。在我们的实验中，我们发现我们的方法可以成功学习执行各种任务的模型，在模拟机器人手臂中在干扰物中移动物体，甚至学习使用真实世界机器人打开和关闭抽屉。在比较中，我们发现这种方法显著优于无模型和基于模型的先前方法。",
        "领域": "机器人视觉控制、自监督学习、动态模型规划",
        "问题": "如何在缺乏手工设计奖励函数的情况下，通过学习动态模型和功能距离来实现视觉目标达成。",
        "动机": "解决在无奖励或任务导向数据情况下，通用机器人学习完成多样化任务的问题。",
        "方法": "结合视觉动态模型和通过无模型强化学习学习到的动态距离函数，进行自监督学习。",
        "关键词": [
            "视觉规划",
            "自监督学习",
            "动态距离函数",
            "机器人控制",
            "强化学习"
        ],
        "涉及的技术概念": {
            "视觉动态模型": "用于预测环境状态变化的模型，支持在没有明确奖励的情况下进行规划。",
            "动态距离函数": "通过无模型强化学习学习，衡量观察与目标状态之间的功能相似性，指导策略学习。",
            "自监督学习": "利用未标记数据进行学习的方法，减少对人工标注的依赖，提高模型的泛化能力。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 513,
        "title": "Modeling the Second Player in Distributionally Robust Optimization",
        "html": "https://iclr.cc//virtual/2021/poster/3201",
        "abstract": "Distributionally robust optimization (DRO) provides a framework for training machine learning models that are able to perform well on a collection of related data distributions (the 'uncertainty set'). This is done by solving a min-max game: the model is trained to minimize its maximum expected loss among all distributions in the uncertainty set. While careful design of the uncertainty set is critical to the success of the DRO procedure, previous work has been limited to relatively simple alternatives that keep the min-max optimization problem exactly tractable, such as $f$-divergence balls. In this paper, we argue instead for the use of neural generative models to characterize the worst-case distribution, allowing for more flexible and problem-specific selection of the uncertainty set. However, while simple conceptually, this approach poses a number of implementation and optimization challenges. To circumvent these issues, we propose a relaxation of the KL-constrained inner maximization objective that makes the DRO problem more amenable to gradient-based optimization of large scale generative models, and develop model selection heuristics to guide hyper-parameter search. On both toy settings and realistic NLP tasks, we find that the proposed approach yields models that are more robust than comparable baselines.",
        "conference": "ICLR",
        "中文标题": "在分布鲁棒优化中对第二玩家建模",
        "摘要翻译": "分布鲁棒优化（DRO）提供了一个框架，用于训练能够在相关数据分布集合（'不确定性集'）上表现良好的机器学习模型。这是通过解决一个最小-最大游戏来实现的：模型被训练以最小化其在不确定性集中所有分布上的最大期望损失。虽然不确定性集的精心设计对DRO过程的成功至关重要，但之前的工作仅限于保持最小-最大优化问题完全可处理的相对简单的替代方案，如$f$-散度球。在本文中，我们主张使用神经生成模型来表征最坏情况分布，从而允许更灵活和问题特定的不确定性集选择。然而，尽管概念上简单，这种方法带来了一系列实现和优化挑战。为了规避这些问题，我们提出了一个KL约束内最大化目标的松弛，使得DRO问题更适合于基于梯度的大规模生成模型优化，并开发了模型选择启发式方法来指导超参数搜索。在玩具设置和现实的NLP任务上，我们发现所提出的方法产生的模型比可比基线更鲁棒。",
        "领域": "机器学习优化、自然语言处理、生成模型",
        "问题": "如何在分布鲁棒优化中更灵活和问题特定地选择不确定性集",
        "动机": "提高机器学习模型在不确定性集上的鲁棒性，通过更灵活的不确定性集选择来适应不同的问题",
        "方法": "使用神经生成模型来表征最坏情况分布，并提出KL约束内最大化目标的松弛以优化大规模生成模型",
        "关键词": [
            "分布鲁棒优化",
            "神经生成模型",
            "KL约束",
            "模型选择",
            "梯度优化"
        ],
        "涉及的技术概念": {
            "分布鲁棒优化": "一种训练机器学习模型的方法，旨在最小化在最坏情况分布下的期望损失",
            "神经生成模型": "用于表征不确定性集中的最坏情况分布，提供更灵活和问题特定的选择",
            "KL约束": "用于松弛内最大化目标，使得优化问题更适合于基于梯度的方法"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 514,
        "title": "Modelling Hierarchical Structure between Dialogue Policy and Natural Language Generator with Option Framework for Task-oriented Dialogue System",
        "html": "https://iclr.cc//virtual/2021/poster/2720",
        "abstract": "Designing task-oriented dialogue systems is a challenging research topic, since it needs not only to generate utterances fulfilling user requests but also to guarantee the comprehensibility. Many previous works trained end-to-end (E2E) models with supervised learning (SL), however, the bias in annotated system utterances remains as a bottleneck. Reinforcement learning (RL) deals with the problem through using non-differentiable evaluation metrics (e.g., the success rate) as rewards. Nonetheless, existing works with RL showed that the comprehensibility of generated system utterances could be corrupted when improving the performance on fulfilling user requests. In our work, we (1) propose modelling the hierarchical structure between dialogue policy and natural language generator (NLG) with the option framework, called HDNO, where the latent dialogue act is applied to avoid designing specific dialogue act representations; (2) train HDNO via hierarchical reinforcement learning (HRL), as well as suggest the asynchronous updates between dialogue policy and NLG during training to theoretically guarantee their convergence to a local maximizer; and (3) propose using a discriminator modelled with language models as an additional reward to further improve the comprehensibility. We test HDNO on MultiWoz 2.0 and MultiWoz 2.1, the datasets on multi-domain dialogues, in comparison with word-level E2E model trained with RL, LaRL and HDSA, showing improvements on the performance evaluated by automatic evaluation metrics and human evaluation. Finally, we demonstrate the semantic meanings of latent dialogue acts to show the explanability for HDNO.",
        "conference": "ICLR",
        "中文标题": "面向任务型对话系统的对话策略与自然语言生成器间层次结构建模——基于选项框架",
        "摘要翻译": "设计任务型对话系统是一个具有挑战性的研究课题，因为它不仅需要生成满足用户请求的话语，还需要保证话语的可理解性。许多先前的工作通过监督学习（SL）训练端到端（E2E）模型，然而，标注系统话语中的偏差仍然是一个瓶颈。强化学习（RL）通过使用不可微分的评估指标（如成功率）作为奖励来解决这个问题。尽管如此，现有的RL研究表明，在提高满足用户请求的性能时，生成系统话语的可理解性可能会受到损害。在我们的工作中，我们（1）提出了使用选项框架建模对话策略与自然语言生成器（NLG）之间的层次结构，称为HDNO，其中应用潜在对话行为以避免设计特定的对话行为表示；（2）通过层次强化学习（HRL）训练HDNO，并建议在训练期间对话策略和NLG之间进行异步更新，以理论上保证它们收敛到局部最大值；（3）提出使用语言模型建模的判别器作为额外奖励，以进一步提高可理解性。我们在多领域对话数据集MultiWoz 2.0和MultiWoz 2.1上测试HDNO，与通过RL训练的单词级E2E模型、LaRL和HDSA进行比较，显示出在自动评估指标和人类评估中性能的提升。最后，我们展示了潜在对话行为的语义含义，以显示HDNO的可解释性。",
        "领域": "任务型对话系统、自然语言生成、强化学习",
        "问题": "解决任务型对话系统中在提高满足用户请求性能的同时保持生成话语的可理解性问题",
        "动机": "现有的任务型对话系统在提高满足用户请求的性能时，可能会损害生成话语的可理解性，本研究旨在通过层次结构和强化学习解决这一问题",
        "方法": "提出HDNO模型，使用选项框架建模对话策略与自然语言生成器之间的层次结构，通过层次强化学习训练，并引入语言模型判别器作为额外奖励",
        "关键词": [
            "任务型对话系统",
            "层次强化学习",
            "自然语言生成",
            "选项框架",
            "可理解性"
        ],
        "涉及的技术概念": {
            "选项框架": "用于建模对话策略与自然语言生成器之间的层次结构，避免设计特定的对话行为表示",
            "层次强化学习": "用于训练HDNO模型，通过异步更新对话策略和自然语言生成器，保证它们收敛到局部最大值",
            "语言模型判别器": "作为额外奖励，用于提高生成系统话语的可理解性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 515,
        "title": "Model Patching: Closing the Subgroup Performance Gap with Data Augmentation",
        "html": "https://iclr.cc//virtual/2021/poster/2873",
        "abstract": "Classifiers in machine learning are often brittle when deployed. Particularly concerning are models with inconsistent performance on specific subgroups of a class, e.g., exhibiting disparities in skin cancer classification in the presence or absence of a spurious bandage. To mitigate these performance differences, we introduce model patching, a two-stage framework for improving robustness that encourages the model to be invariant to subgroup differences, and focus on class information shared by subgroups. Model patching first models subgroup features within a class and learns semantic transformations between them, and then trains a classifier with data augmentations that deliberately manipulate subgroup features. We instantiate model patching with CAMEL, which (1) uses a CycleGAN to learn the intra-class, inter-subgroup augmentations, and (2) balances subgroup performance using a theoretically-motivated subgroup consistency regularizer, accompanied by a new robust objective. We demonstrate CAMEL’s effectiveness on 3 benchmark datasets, with reductions in robust error of up to 33% relative to the best baseline. Lastly, CAMEL successfully patches a model that fails due to spurious features on a real-world skin cancer dataset.",
        "conference": "ICLR",
        "中文标题": "模型修补：通过数据增强缩小子群性能差距",
        "摘要翻译": "机器学习中的分类器在部署时往往表现脆弱。尤其令人担忧的是模型在类的特定子群上表现不一致，例如，在存在或不存在虚假绷带的情况下，皮肤癌分类中表现出差异。为了减轻这些性能差异，我们引入了模型修补，这是一个两阶段的框架，旨在提高鲁棒性，鼓励模型对子群差异保持不变，并专注于子群共享的类别信息。模型修补首先建模类内的子群特征，并学习它们之间的语义转换，然后通过故意操纵子群特征的数据增强来训练分类器。我们用CAMEL实例化模型修补，它（1）使用CycleGAN学习类内、子群间的增强，（2）使用理论上动机的子群一致性正则化器平衡子群性能，并伴随一个新的鲁棒目标。我们在3个基准数据集上展示了CAMEL的有效性，相对于最佳基线，鲁棒误差减少了高达33%。最后，CAMEL成功修补了一个由于真实世界皮肤癌数据集上的虚假特征而失败的模型。",
        "领域": "图像分类",
        "问题": "解决机器学习分类器在特定子群上表现不一致的问题",
        "动机": "提高模型对子群差异的鲁棒性，确保分类器在所有子群上表现一致",
        "方法": "采用两阶段框架，包括学习子群间语义转换和使用数据增强训练分类器",
        "关键词": [
            "模型修补",
            "数据增强",
            "子群一致性",
            "CycleGAN",
            "鲁棒性"
        ],
        "涉及的技术概念": {
            "模型修补": "一个两阶段框架，旨在通过数据增强提高模型在特定子群上的鲁棒性",
            "CycleGAN": "用于学习类内、子群间的语义转换，生成数据增强样本",
            "子群一致性正则化器": "用于平衡不同子群的性能，提高模型的整体鲁棒性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 516,
        "title": "Molecule Optimization by Explainable Evolution",
        "html": "https://iclr.cc//virtual/2021/poster/3099",
        "abstract": "Optimizing molecules for desired properties is a fundamental yet challenging task in chemistry, material science, and drug discovery. This paper develops a novel algorithm for optimizing molecular properties via an Expectation-Maximization (EM) like explainable evolutionary process. The algorithm is designed to mimic human experts in the process of searching for desirable molecules and alternate between two stages: the first stage on explainable local search which identifies rationales, i.e., critical subgraph patterns accounting for desired molecular properties, and the second stage on molecule completion which explores the larger space of molecules containing good rationales. We test our approach against various baselines on a real-world multi-property optimization task where each method is given the same number of queries to the property oracle. We show that our evolution-by-explanation algorithm is 79% better than the best baseline in terms of a generic metric combining aspects such as success rate, novelty, and diversity. Human expert evaluation on optimized molecules shows that 60% of top molecules obtained from our methods are deemed successful. ",
        "conference": "ICLR",
        "中文标题": "通过可解释进化进行分子优化",
        "摘要翻译": "优化分子以获得所需属性是化学、材料科学和药物发现领域中一项基础但具有挑战性的任务。本文开发了一种新颖的算法，通过类似期望最大化（EM）的可解释进化过程来优化分子属性。该算法旨在模仿人类专家在寻找理想分子过程中的行为，并在两个阶段之间交替进行：第一阶段是可解释的局部搜索，识别出关键子图模式，即解释所需分子属性的基本原理；第二阶段是分子完成，探索包含良好基本原理的更大分子空间。我们在一个真实世界的多属性优化任务上测试了我们的方法，与各种基线方法相比，每种方法都给予相同次数的属性查询。结果表明，我们的通过解释进化算法在结合成功率、新颖性和多样性等方面的通用指标上比最佳基线方法高出79%。人类专家对我们方法获得的优化分子进行评估，结果显示60%的顶级分子被认为是成功的。",
        "领域": "药物发现、材料科学、化学信息学",
        "问题": "如何有效地优化分子以获得所需的化学属性",
        "动机": "开发一种能够模仿人类专家行为、高效优化分子属性的算法",
        "方法": "采用类似期望最大化（EM）的可解释进化过程，交替进行可解释的局部搜索和分子完成",
        "关键词": [
            "分子优化",
            "可解释进化",
            "期望最大化",
            "子图模式",
            "多属性优化"
        ],
        "涉及的技术概念": {
            "可解释进化": "模仿人类专家行为，通过进化过程优化分子属性",
            "期望最大化（EM）": "用于交替进行局部搜索和分子完成，优化分子属性",
            "关键子图模式": "识别出解释分子属性的基本原理，指导分子优化过程"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 517,
        "title": "MONGOOSE: A Learnable LSH Framework for Efficient Neural Network Training",
        "html": "https://iclr.cc//virtual/2021/poster/3277",
        "abstract": "Recent advances by practitioners in the deep learning community have breathed new life into Locality Sensitive Hashing (LSH), using it to reduce memory and time bottlenecks in neural network (NN) training. However, while LSH has sub-linear guarantees for approximate near-neighbor search in theory, it is known to have inefficient query time in practice due to its use of random hash functions. Moreover, when model parameters are changing, LSH suffers from update overhead. This work is motivated by an observation that model parameters evolve slowly, such that the changes do not always require an LSH update to maintain performance. This phenomenon points to the potential for a reduction in update time and allows for a modified learnable version of data-dependent LSH to improve query time at a low cost. We use the above insights to build MONGOOSE, an end-to-end LSH framework for efficient NN training. In particular, MONGOOSE is equipped with a scheduling algorithm to adaptively perform LSH updates with provable guarantees and learnable hash functions to improve query efficiency. Empirically, we validate MONGOOSE on large-scale deep learning models for recommendation systems and language modeling. We find that it achieves up to 8% better accuracy compared to previous LSH approaches, with $6.5 \\times$ speed-up and $6\\times$ reduction in memory usage.",
        "conference": "ICLR",
        "中文标题": "MONGOOSE：一种可学习的LSH框架用于高效神经网络训练",
        "摘要翻译": "深度学习社区的最新进展为局部敏感哈希（LSH）注入了新的活力，利用它来减少神经网络（NN）训练中的内存和时间瓶颈。然而，尽管LSH在理论上具有近似最近邻搜索的亚线性保证，但由于其使用随机哈希函数，在实践中查询时间效率低下。此外，当模型参数发生变化时，LSH会遭受更新开销的困扰。这项工作的动机来自于一个观察，即模型参数变化缓慢，因此这些变化并不总是需要LSH更新来维持性能。这一现象指出了减少更新时间的潜力，并允许修改后的可学习版本的数据依赖LSH以低成本提高查询时间。我们利用上述见解构建了MONGOOSE，一个用于高效NN训练的端到端LSH框架。特别是，MONGOOSE配备了一个调度算法，以自适应地执行具有可证明保证的LSH更新，以及可学习的哈希函数以提高查询效率。实证上，我们在推荐系统和语言建模的大规模深度学习模型上验证了MONGOOSE。我们发现，与之前的LSH方法相比，它实现了高达8%的准确率提升，速度提升了6.5倍，内存使用减少了6倍。",
        "领域": "推荐系统、语言建模、神经网络优化",
        "问题": "解决局部敏感哈希（LSH）在神经网络训练中因使用随机哈希函数导致的查询效率低下和更新开销大的问题",
        "动机": "观察到模型参数变化缓慢，不需要频繁更新LSH即可维持性能，从而减少更新时间和提高查询效率",
        "方法": "开发了一个名为MONGOOSE的端到端LSH框架，包括自适应调度算法进行LSH更新和可学习的哈希函数以提高查询效率",
        "关键词": [
            "局部敏感哈希",
            "神经网络训练",
            "推荐系统",
            "语言建模",
            "可学习哈希"
        ],
        "涉及的技术概念": {
            "局部敏感哈希": "用于近似最近邻搜索的技术，以减少神经网络训练中的内存和时间瓶颈",
            "可学习哈希函数": "通过训练优化的哈希函数，以提高查询效率和减少更新开销",
            "调度算法": "自适应地决定何时更新LSH，以平衡性能和计算开销"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 518,
        "title": "Monotonic Kronecker-Factored Lattice",
        "html": "https://iclr.cc//virtual/2021/poster/2667",
        "abstract": "It is computationally challenging to learn flexible monotonic functions that guarantee model behavior and provide interpretability beyond a few input features, and in a time where minimizing resource use is increasingly important, we must be able to learn such models that are still efficient. In this paper we show how to effectively and efficiently learn such functions using Kronecker-Factored Lattice ($\\mathrm{KFL}$), an efficient reparameterization of flexible monotonic lattice regression via Kronecker product. Both computational and storage costs scale linearly in the number of input features, which is a significant improvement over existing methods that grow exponentially. We also show that we can still properly enforce monotonicity and other shape constraints. The $\\mathrm{KFL}$ function class consists of products of piecewise-linear functions, and the size of the function class can be further increased through ensembling. We prove that the function class of an ensemble of $M$ base $\\mathrm{KFL}$ models strictly increases as $M$ increases up to a certain threshold. Beyond this threshold, every multilinear interpolated lattice function can be expressed. Our experimental results demonstrate that $\\mathrm{KFL}$ trains faster with fewer parameters while still achieving accuracy and evaluation speeds comparable to or better than the baseline methods and preserving monotonicity guarantees on the learned model.",
        "conference": "ICLR",
        "中文标题": "单调克罗内克分解格",
        "摘要翻译": "学习既灵活又单调的函数在计算上具有挑战性，这些函数能够保证模型行为并提供超越少数输入特征的可解释性。在资源使用最小化日益重要的今天，我们必须能够学习这些仍然高效的模型。本文展示了如何通过克罗内克分解格（KFL）有效且高效地学习这些函数，KFL是通过克罗内克积对灵活单调格回归的高效重新参数化。计算和存储成本在输入特征数量上呈线性增长，这比现有方法呈指数级增长有显著改进。我们还展示了我们仍然可以正确实施单调性和其他形状约束。KFL函数类由分段线性函数的乘积组成，函数类的大小可以通过集成进一步增加。我们证明，当M增加到某个阈值时，M个基础KFL模型集成函数类的严格增加。超过这个阈值，可以表达所有多线性插值格函数。我们的实验结果表明，KFL训练速度更快，参数更少，同时仍然达到与基线方法相当或更好的准确性和评估速度，并在学习模型上保持单调性保证。",
        "领域": "机器学习优化",
        "问题": "如何在保证模型单调性和可解释性的同时，高效学习灵活的函数",
        "动机": "在资源使用最小化日益重要的背景下，需要开发既高效又能保证模型行为和学习可解释性的方法",
        "方法": "使用克罗内克分解格（KFL）作为灵活单调格回归的高效重新参数化方法，通过克罗内克积实现",
        "关键词": [
            "克罗内克分解格",
            "单调性保证",
            "高效学习"
        ],
        "涉及的技术概念": {
            "克罗内克分解格（KFL）": "通过克罗内克积对灵活单调格回归进行高效重新参数化的方法",
            "单调性约束": "确保模型输出随输入单调递增或递减的约束条件",
            "集成学习": "通过组合多个基础模型来增加函数类的表达能力和准确性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 519,
        "title": "Monte-Carlo Planning and Learning with Language Action Value Estimates",
        "html": "https://iclr.cc//virtual/2021/poster/3128",
        "abstract": "Interactive Fiction (IF) games provide a useful testbed for language-based reinforcement learning agents, posing significant challenges of natural language understanding, commonsense reasoning, and non-myopic planning in the combinatorial search space. Agents based on standard planning algorithms struggle to play IF games due to the massive search space of language actions. Thus, language-grounded planning is a key ability of such agents, since inferring the consequence of language action based on semantic understanding can drastically improve search. In this paper, we introduce Monte-Carlo planning with Language Action Value Estimates (MC-LAVE) that combines a Monte-Carlo tree search with language-driven exploration. MC-LAVE invests more search effort into semantically promising language actions using locally optimistic language value estimates, yielding a significant reduction in the effective search space of language actions. We then present a reinforcement learning approach via MC-LAVE, which alternates between MC-LAVE planning and supervised learning of the self-generated language actions. In the experiments, we demonstrate that our method achieves new high scores in various IF games.",
        "conference": "ICLR",
        "中文标题": "基于语言动作价值估计的蒙特卡洛规划与学习",
        "摘要翻译": "交互式小说（IF）游戏为基于语言的强化学习代理提供了一个有用的测试平台，提出了自然语言理解、常识推理以及在组合搜索空间中进行非近视规划的重大挑战。基于标准规划算法的代理由于语言动作的巨大搜索空间而难以玩IF游戏。因此，语言基础的规划是这类代理的关键能力，因为基于语义理解推断语言动作的后果可以极大地改善搜索。在本文中，我们介绍了结合蒙特卡洛树搜索与语言驱动探索的基于语言动作价值估计的蒙特卡洛规划（MC-LAVE）。MC-LAVE利用局部乐观的语言价值估计，将更多的搜索努力投入到语义上有希望的语言动作中，从而显著减少了语言动作的有效搜索空间。然后，我们提出了一种通过MC-LAVE的强化学习方法，该方法在MC-LAVE规划与自生成语言动作的监督学习之间交替进行。在实验中，我们证明了我们的方法在各种IF游戏中实现了新的高分。",
        "领域": "自然语言处理与视觉结合、强化学习、游戏AI",
        "问题": "解决在交互式小说游戏中，由于语言动作的巨大搜索空间导致的规划难题",
        "动机": "通过结合语义理解和蒙特卡洛规划，提高代理在交互式小说游戏中的表现",
        "方法": "结合蒙特卡洛树搜索与语言驱动探索的MC-LAVE方法，以及通过MC-LAVE的强化学习方法",
        "关键词": [
            "蒙特卡洛规划",
            "语言动作价值估计",
            "交互式小说游戏",
            "强化学习",
            "语义理解"
        ],
        "涉及的技术概念": {
            "蒙特卡洛树搜索": "用于在巨大的语言动作搜索空间中进行有效规划的技术",
            "语言动作价值估计": "评估语言动作的语义价值，以指导搜索方向",
            "强化学习": "通过奖励信号优化代理行为的学习方法"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 520,
        "title": "MoPro: Webly Supervised Learning with Momentum Prototypes",
        "html": "https://iclr.cc//virtual/2021/poster/2567",
        "abstract": "We propose a webly-supervised representation learning method that does not suffer from the annotation unscalability of supervised learning, nor the computation unscalability of self-supervised learning. Most existing works on webly-supervised representation learning adopt a vanilla supervised learning method without accounting for the prevalent noise in the training data, whereas most prior methods in learning with label noise are less effective for real-world large-scale noisy data. We propose momentum prototypes (MoPro), a simple contrastive learning method that achieves online label noise correction, out-of-distribution sample removal, and representation learning. MoPro achieves state-of-the-art performance on WebVision, a weakly-labeled noisy dataset. MoPro also shows superior performance when the pretrained model is transferred to down-stream image classification and detection tasks. It outperforms the ImageNet supervised pretrained model by +10.5 on 1-shot classification on VOC, and outperforms the best self-supervised pretrained model by +17.3 when finetuned on 1% of ImageNet labeled samples. Furthermore, MoPro is more robust to distribution shifts. Code and pretrained models are available at https://github.com/salesforce/MoPro.",
        "conference": "ICLR",
        "中文标题": "MoPro：基于动量原型的网络监督学习",
        "摘要翻译": "我们提出了一种网络监督表示学习方法，该方法既不受监督学习中标注不可扩展性的限制，也不受自监督学习中计算不可扩展性的限制。大多数现有的网络监督表示学习工作采用普通的监督学习方法，而没有考虑到训练数据中普遍存在的噪声，而大多数先前处理标签噪声的方法对于现实世界的大规模噪声数据效果不佳。我们提出了动量原型（MoPro），这是一种简单的对比学习方法，实现了在线标签噪声校正、分布外样本移除和表示学习。MoPro在WebVision（一个弱标记的噪声数据集）上实现了最先进的性能。当预训练模型迁移到下游图像分类和检测任务时，MoPro也显示出卓越的性能。在VOC的1-shot分类上，它比ImageNet监督预训练模型高出10.5分，在ImageNet标记样本的1%上进行微调时，比最佳自监督预训练模型高出17.3分。此外，MoPro对分布变化更加鲁棒。代码和预训练模型可在https://github.com/salesforce/MoPro获取。",
        "领域": "弱监督学习、图像分类、目标检测",
        "问题": "解决网络监督学习中由于数据噪声和标注不可扩展性导致的表示学习效果不佳的问题",
        "动机": "开发一种能够有效处理大规模噪声数据并实现高质量表示学习的方法",
        "方法": "提出动量原型（MoPro）方法，通过对比学习实现在线标签噪声校正、分布外样本移除和表示学习",
        "关键词": [
            "动量原型",
            "对比学习",
            "网络监督学习",
            "噪声校正",
            "表示学习"
        ],
        "涉及的技术概念": {
            "动量原型": "用于在线校正标签噪声和移除分布外样本的技术，通过对比学习优化表示学习过程",
            "对比学习": "一种通过比较正负样本来学习数据表示的方法，MoPro中用于提升模型的表示能力",
            "表示学习": "学习数据的有用表示，MoPro通过优化这一过程来提高模型在下游任务中的性能"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 521,
        "title": "More or Less: When and How to Build Convolutional Neural Network Ensembles",
        "html": "https://iclr.cc//virtual/2021/poster/3286",
        "abstract": "Convolutional neural networks are utilized to solve increasingly more complex problems and with more data. As a  result, researchers and practitioners seek to scale the representational power of such models by adding more parameters. However, increasing parameters requires additional critical resources in terms of memory and compute,  leading to increased training and inference cost. Thus a consistent challenge is to obtain as high as possible accuracy within a parameter budget. As neural network designers navigate this complex landscape, they are guided by conventional wisdom that is informed from past empirical studies. We identify a critical part of this design space that is not well-understood: How to decide between the alternatives of expanding a single convolutional network model or increasing the number of networks in the form of an ensemble. We study this question in detail across various network architectures and data sets. We build an extensive experimental framework that captures numerous angles of the possible design space in terms of how a new set of parameters can be used in a model.  We consider a holistic set of metrics such as training time, inference time, and memory usage. The framework provides a robust assessment by making sure it controls for the number of parameters. Contrary to conventional wisdom, we show that when we perform a holistic and robust assessment, we uncover a wide design space, where ensembles provide better accuracy, train faster, and deploy at speed comparable to single convolutional networks with the same total number of parameters. ",
        "conference": "ICLR",
        "中文标题": "多或少：何时以及如何构建卷积神经网络集成",
        "摘要翻译": "卷积神经网络被用来解决日益复杂的问题和处理更多的数据。因此，研究人员和实践者试图通过增加更多参数来扩展此类模型的表示能力。然而，增加参数需要额外的关键资源，包括内存和计算能力，导致训练和推理成本增加。因此，一个持续的挑战是在参数预算内获得尽可能高的准确性。当神经网络设计者在这个复杂的领域中导航时，他们受到来自过去实证研究的传统智慧的指导。我们识别了这个设计空间中一个未被充分理解的关键部分：如何在扩展单个卷积网络模型或增加集成中网络数量之间做出决定。我们在各种网络架构和数据集上详细研究了这个问题。我们构建了一个广泛的实验框架，从如何使用一组新参数的角度捕捉了可能的设计空间的多个方面。我们考虑了一整套指标，如训练时间、推理时间和内存使用。通过确保控制参数数量，该框架提供了稳健的评估。与传统智慧相反，我们表明，当我们进行全面的稳健评估时，我们发现了一个广阔的设计空间，其中集成提供了更好的准确性，训练更快，并且部署速度与具有相同总参数数量的单个卷积网络相当。",
        "领域": "深度学习模型优化、卷积神经网络、模型集成",
        "问题": "在有限的参数预算下，如何选择扩展单个卷积神经网络或构建网络集成以获得最佳性能",
        "动机": "探索在参数数量相同的情况下，扩展单个网络与构建网络集成之间的性能差异，以指导更高效的模型设计",
        "方法": "构建一个广泛的实验框架，比较不同网络架构和数据集上扩展单个网络与构建集成的性能，包括训练时间、推理时间和内存使用等指标",
        "关键词": [
            "卷积神经网络",
            "模型集成",
            "参数优化",
            "性能评估",
            "设计空间探索"
        ],
        "涉及的技术概念": {
            "卷积神经网络": "用于图像识别和处理的深度学习模型，通过卷积操作提取特征",
            "模型集成": "通过组合多个模型的预测来提高整体性能的技术",
            "参数优化": "在有限的资源下调整模型参数以达到最佳性能的过程"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 522,
        "title": "MoVie: Revisiting Modulated Convolutions for Visual Counting and Beyond",
        "html": "https://iclr.cc//virtual/2021/poster/3071",
        "abstract": "This paper focuses on visual counting, which aims to predict the number of occurrences given a natural image and a query (e.g. a question or a category). Unlike most prior works that use explicit, symbolic models which can be computationally expensive and limited in generalization, we propose a simple and effective alternative by revisiting modulated convolutions that fuse the query and the image locally. Following the design of residual bottleneck, we call our method MoVie, short for Modulated conVolutional bottlenecks. Notably, MoVie reasons implicitly and holistically and only needs a single forward-pass during inference. Nevertheless, MoVie showcases strong performance for counting: 1) advancing the state-of-the-art on counting-specific VQA tasks while being more efficient; 2) outperforming prior-art on difficult benchmarks like COCO for common object counting; 3) helped us secure the first place of 2020 VQA challenge when integrated as a module for ‘number’ related questions in generic VQA models. Finally, we show evidence that modulated convolutions such as MoVie can serve as a general mechanism for reasoning tasks beyond counting.",
        "conference": "ICLR",
        "中文标题": "MoVie：重新审视调制卷积在视觉计数及其他领域的应用",
        "摘要翻译": "本文聚焦于视觉计数，其目标是在给定自然图像和查询（如问题或类别）的情况下预测出现的次数。与大多数先前工作使用显式、符号化模型（这些模型可能计算成本高且泛化能力有限）不同，我们提出了一种简单有效的替代方案，通过重新审视调制卷积，将查询和图像局部融合。遵循残差瓶颈的设计，我们称我们的方法为MoVie，即调制卷积瓶颈的简称。值得注意的是，MoVie隐式且整体地进行推理，在推理过程中仅需单次前向传播。尽管如此，MoVie在计数方面展示了强大的性能：1）在计数特定的视觉问答任务上推进了最先进的技术，同时更加高效；2）在如COCO这样的困难基准测试中，对于常见对象计数，超越了先前的最新技术；3）当作为通用视觉问答模型中‘数字’相关问题的模块集成时，帮助我们获得了2020年视觉问答挑战赛的第一名。最后，我们展示了证据，表明如MoVie这样的调制卷积可以作为超越计数的推理任务的一般机制。",
        "领域": "视觉问答、对象计数、图像理解",
        "问题": "如何高效且准确地进行视觉计数，特别是在自然图像和特定查询条件下。",
        "动机": "解决现有显式、符号化模型在视觉计数任务中计算成本高和泛化能力有限的问题。",
        "方法": "提出了一种基于调制卷积的简单有效方法MoVie，通过局部融合查询和图像信息，实现隐式和整体推理。",
        "关键词": [
            "视觉计数",
            "调制卷积",
            "视觉问答",
            "对象计数",
            "推理任务"
        ],
        "涉及的技术概念": {
            "调制卷积": "用于局部融合查询和图像信息的技术，提高模型的推理效率和准确性。",
            "残差瓶颈": "作为MoVie方法的设计基础，帮助模型更有效地进行信息传递和特征提取。",
            "隐式推理": "MoVie方法的核心特点，允许模型通过单次前向传播完成复杂的推理任务。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 523,
        "title": "Multi-Class Uncertainty Calibration via Mutual Information Maximization-based Binning",
        "html": "https://iclr.cc//virtual/2021/poster/2923",
        "abstract": "Post-hoc multi-class calibration is a common approach for providing high-quality confidence estimates of deep neural network predictions. Recent work has shown that widely used scaling methods underestimate their calibration error, while alternative Histogram Binning (HB) methods often fail to preserve classification accuracy. When classes have small prior probabilities, HB also faces the issue of severe sample-inefficiency after the conversion into K one-vs-rest class-wise calibration problems. The goal of this paper is to resolve the identified issues of HB in order to provide calibrated confidence estimates using only a small holdout calibration dataset for bin optimization while preserving multi-class ranking accuracy. From an information-theoretic perspective, we derive the I-Max concept for binning, which maximizes the mutual information between labels and quantized logits. This concept mitigates potential loss in ranking performance due to lossy quantization, and by disentangling the optimization of bin edges and representatives allows simultaneous improvement of ranking and calibration performance. To improve the sample efficiency and estimates from a small calibration set, we propose a shared class-wise (sCW) calibration strategy, sharing one calibrator among similar classes (e.g., with similar class priors) so that the training sets of their class-wise calibration problems can be merged to train the single calibrator. The combination of sCW and I-Max binning outperforms the state of the art calibration methods on various evaluation metrics across different benchmark datasets and models, using a small calibration set (e.g., 1k samples for ImageNet).",
        "conference": "ICLR",
        "中文标题": "基于互信息最大化分箱的多类不确定性校准",
        "摘要翻译": "事后多类校准是一种常见的方法，用于提供深度神经网络预测的高质量置信度估计。最近的研究表明，广泛使用的缩放方法低估了其校准误差，而替代的直方图分箱（HB）方法往往无法保持分类准确性。当类别的先验概率较小时，HB在转换为K个一对多类别校准问题后还面临着样本效率严重不足的问题。本文的目标是解决HB的这些问题，以便仅使用一个小的保留校准数据集进行分箱优化，同时保持多类排名准确性，从而提供校准的置信度估计。从信息论的角度出发，我们推导出了用于分箱的I-Max概念，该概念最大化标签和量化逻辑之间的互信息。这一概念减轻了由于有损量化可能导致的排名性能损失，并通过解耦分箱边缘和代表的优化，允许同时改进排名和校准性能。为了提高小校准集的样本效率和估计，我们提出了一种共享类别（sCW）校准策略，即在相似类别（例如，具有相似类别先验）之间共享一个校准器，以便它们的类别校准问题的训练集可以合并来训练单个校准器。sCW和I-Max分箱的组合在不同基准数据集和模型上的各种评估指标上优于最先进的校准方法，使用小的校准集（例如，ImageNet的1k样本）。",
        "领域": "深度学习模型校准、多类分类、置信度估计",
        "问题": "解决直方图分箱方法在多类校准中的样本效率低下和分类准确性保持问题",
        "动机": "为了提高深度神经网络预测置信度估计的准确性和效率，特别是在类别先验概率较小的情况下",
        "方法": "提出I-Max分箱概念以最大化互信息，并采用共享类别校准策略提高样本效率",
        "关键词": [
            "多类校准",
            "互信息最大化",
            "直方图分箱",
            "共享类别校准",
            "置信度估计"
        ],
        "涉及的技术概念": {
            "I-Max分箱": "通过最大化标签和量化逻辑之间的互信息来优化分箱过程，以减少量化带来的信息损失",
            "共享类别校准策略（sCW）": "在相似类别间共享校准器，合并训练集以提高样本效率和校准性能",
            "互信息": "用于衡量标签和量化逻辑之间共享信息的量，是I-Max分箱优化的核心指标"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 524,
        "title": "Multi-Level Local SGD: Distributed SGD for Heterogeneous Hierarchical Networks",
        "html": "https://iclr.cc//virtual/2021/poster/3195",
        "abstract": "We propose Multi-Level Local SGD, a distributed stochastic gradient method for learning a smooth, non-convex objective in a multi-level communication network with heterogeneous workers. Our network model consists of a set of disjoint sub-networks, with a single hub and multiple workers; further, workers may have different operating rates. The hubs exchange information with one another via a connected, but not necessarily complete communication network. In our algorithm, sub-networks execute a distributed SGD algorithm, using a hub-and-spoke paradigm, and the hubs periodically average their models with neighboring hubs. We first provide a unified mathematical framework that describes the Multi-Level Local SGD algorithm. We then present a theoretical analysis of the algorithm; our analysis shows the dependence of the convergence error on the worker node heterogeneity, hub network topology, and the number of local, sub-network, and global iterations. We illustrate the effectiveness of our algorithm in a multi-level network with slow workers via simulation-based experiments.",
        "conference": "ICLR",
        "中文标题": "多级本地SGD：面向异构层次网络的分布式SGD",
        "摘要翻译": "我们提出了多级本地SGD，一种用于在多级通信网络中学习平滑、非凸目标的分布式随机梯度方法，该网络具有异构的工作节点。我们的网络模型由一组不相交的子网络组成，每个子网络有一个中心节点和多个工作节点；此外，工作节点可能具有不同的操作速率。中心节点通过一个连通但不一定是完全的通信网络相互交换信息。在我们的算法中，子网络使用中心辐射模式执行分布式SGD算法，中心节点定期与相邻中心节点平均其模型。我们首先提供了一个统一的数学框架来描述多级本地SGD算法。然后，我们提出了算法的理论分析；我们的分析显示了收敛误差对工作节点异构性、中心网络拓扑以及本地、子网络和全局迭代次数的依赖性。我们通过基于模拟的实验，在一个具有慢速工作节点的多级网络中说明了我们算法的有效性。",
        "领域": "分布式学习、优化算法、网络通信",
        "问题": "解决在多级异构网络中高效执行分布式随机梯度下降（SGD）的问题。",
        "动机": "研究动机是为了在多级异构网络中实现更高效的分布式学习，特别是在工作节点操作速率不同的情况下。",
        "方法": "采用多级本地SGD算法，结合中心辐射模式和周期性的模型平均，以适应异构网络环境。",
        "关键词": [
            "分布式SGD",
            "异构网络",
            "多级通信",
            "模型平均",
            "收敛分析"
        ],
        "涉及的技术概念": {
            "分布式SGD": "在多级网络中执行随机梯度下降，以分布式方式优化目标函数。",
            "中心辐射模式": "子网络中的中心节点与工作节点之间的通信模式，用于协调分布式计算。",
            "模型平均": "中心节点定期与相邻中心节点交换并平均模型参数，以减少通信开销和提高模型一致性。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 525,
        "title": "MultiModalQA: complex question answering over text, tables and images",
        "html": "https://iclr.cc//virtual/2021/poster/2538",
        "abstract": "When answering complex questions, people can seamlessly combine information from visual, textual and tabular sources. \nWhile interest in models that reason over multiple pieces of evidence has surged in recent years, there has been relatively little work on question answering models that reason across multiple modalities.\nIn this paper, we present MultiModalQA (MMQA): a challenging question answering dataset that requires joint reasoning over text, tables and images. \nWe create MMQA using a new framework for generating complex multi-modal questions at scale, harvesting tables from Wikipedia, and attaching images and text paragraphs using entities that appear in each table. We then define a formal language that allows us to take questions that can be answered from a single modality, and combine them to generate cross-modal questions. Last, crowdsourcing workers take these automatically generated questions and rephrase them into more fluent language.\nWe create 29,918 questions through this procedure, and empirically demonstrate the necessity of a multi-modal multi-hop approach to solve our task: our multi-hop model, ImplicitDecomp, achieves an average F1 of 51.7  over cross-modal questions, substantially outperforming a strong baseline that achieves 38.2 F1, but still lags significantly behind human performance, which is at 90.1 F1.",
        "conference": "ICLR",
        "中文标题": "MultiModalQA：基于文本、表格和图像的复杂问答",
        "摘要翻译": "在回答复杂问题时，人们可以无缝地结合来自视觉、文本和表格来源的信息。尽管近年来对能够推理多证据的模型的兴趣激增，但在跨模态问答模型方面的研究相对较少。在本文中，我们提出了MultiModalQA（MMQA）：一个需要联合推理文本、表格和图像的具有挑战性的问答数据集。我们使用一个新的框架来大规模生成复杂的多模态问题，从维基百科中收集表格，并使用每个表格中出现的实体附加图像和文本段落。然后，我们定义了一种形式语言，使我们能够将可以从单一模态回答的问题结合起来，生成跨模态问题。最后，众包工作者将这些自动生成的问题重新表述为更流畅的语言。通过这一过程，我们创建了29,918个问题，并通过实证证明了解决我们的任务需要多模态多跳方法：我们的多跳模型ImplicitDecomp在跨模态问题上实现了51.7的平均F1分数，显著优于仅达到38.2 F1分数的强基线，但仍显著落后于人类表现的90.1 F1分数。",
        "领域": "多模态学习、问答系统、跨模态推理",
        "问题": "开发一个能够跨文本、表格和图像模态进行复杂问答的系统",
        "动机": "解决现有问答系统在多模态联合推理方面的不足，提升模型处理跨模态复杂问题的能力",
        "方法": "提出MultiModalQA数据集，采用新框架生成复杂多模态问题，结合众包工作者的重新表述，开发多跳模型ImplicitDecomp进行跨模态推理",
        "关键词": [
            "多模态学习",
            "问答系统",
            "跨模态推理",
            "多跳模型",
            "数据集构建"
        ],
        "涉及的技术概念": {
            "多模态学习": "结合文本、表格和图像等多种数据模态进行联合学习和推理",
            "问答系统": "设计能够理解和回答复杂问题的系统，特别是在多模态环境下",
            "跨模态推理": "在不同数据模态之间进行信息整合和推理，以回答需要多模态信息的问题"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 526,
        "title": "Multiplicative Filter Networks",
        "html": "https://iclr.cc//virtual/2021/poster/3198",
        "abstract": "Although deep networks are typically used to approximate functions over high dimensional inputs, recent work has increased interest in neural networks as function approximators for low-dimensional-but-complex functions, such as representing images as a function of pixel coordinates, solving differential equations, or representing signed distance fields or neural radiance fields.  Key to these recent successes has been the use of new elements such as sinusoidal nonlinearities, or Fourier features in positional encodings, which vastly outperform simple ReLU networks.  In this paper, we propose and empirically demonstrate that an arguably simpler class of function approximators can work just as well for such problems: multiplicative filter networks.  In these networks, we avoid traditional compositional depth altogether, and simply multiply together (linear functions of) sinusoidal or Gabor wavelet functions applied to the input.  This representation has the notable advantage that the entire function can simply be viewed as a linear function approximator over an exponential number of Fourier or Gabor basis functions, respectively.  Despite this simplicity, when compared to recent approaches that use Fourier features with ReLU networks or sinusoidal activation networks, we show that these multiplicative filter networks largely outperform or match the performance of these recent approaches on the domains highlighted in these past works.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "乘法滤波器网络",
        "摘要翻译": "尽管深度网络通常用于近似高维输入的函数，但最近的研究增加了对神经网络作为低维但复杂函数近似器的兴趣，例如将图像表示为像素坐标的函数、求解微分方程或表示有符号距离场或神经辐射场。这些最近成功的关键在于使用了新的元素，如正弦非线性或位置编码中的傅里叶特征，这些元素大大优于简单的ReLU网络。在本文中，我们提出并实证证明，对于这类问题，一类可以说更简单的函数近似器可以同样有效：乘法滤波器网络。在这些网络中，我们完全避免了传统的组合深度，而只是将应用于输入的正弦或Gabor小波函数（的线性函数）相乘。这种表示法有一个显著的优点，即整个函数可以简单地被视为分别基于指数数量的傅里叶或Gabor基函数的线性函数近似器。尽管这种简单性，与最近使用傅里叶特征与ReLU网络或正弦激活网络的方法相比，我们表明这些乘法滤波器网络在很大程度上优于或匹配了过去工作中强调的领域上这些最近方法的性能。",
        "领域": "神经网络函数近似",
        "问题": "如何有效地近似低维但复杂的函数",
        "动机": "探索比现有方法更简单且有效的神经网络结构，用于近似低维复杂函数",
        "方法": "提出乘法滤波器网络，通过将正弦或Gabor小波函数的线性函数相乘来近似函数，避免传统组合深度",
        "关键词": [
            "乘法滤波器网络",
            "函数近似",
            "神经网络",
            "傅里叶特征",
            "Gabor小波"
        ],
        "涉及的技术概念": {
            "乘法滤波器网络": "一种新型的神经网络结构，通过乘法操作组合正弦或Gabor小波函数的线性函数来近似复杂函数",
            "傅里叶特征": "用于位置编码的特征，能够提升神经网络对高频信息的捕捉能力",
            "Gabor小波": "一种在空间和频率域都有良好局部化特性的小波，用于提取图像的局部特征"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 527,
        "title": "Multi-Prize Lottery Ticket Hypothesis: Finding Accurate Binary Neural Networks by Pruning A Randomly Weighted Network",
        "html": "https://iclr.cc//virtual/2021/poster/3050",
        "abstract": "Recently, Frankle & Carbin (2019) demonstrated that randomly-initialized dense networks contain subnetworks that once found can be trained to reach test accuracy comparable to the trained dense network. However, finding these high performing trainable subnetworks is expensive, requiring iterative process of training and pruning weights. In this paper, we propose (and prove) a stronger Multi-Prize Lottery Ticket Hypothesis:\n\nA sufficiently over-parameterized neural network with random weights contains several subnetworks (winning tickets) that (a) have comparable accuracy to a dense target network with learned weights (prize 1), (b) do not require any further training to achieve prize 1 (prize 2), and (c) is robust to extreme forms of quantization (i.e., binary weights and/or activation) (prize 3).\n\nThis provides a new paradigm for learning compact yet highly accurate binary neural networks simply by pruning and quantizing randomly weighted full precision neural networks. We also propose an algorithm for finding multi-prize tickets (MPTs) and test it by performing a series of experiments on CIFAR-10 and ImageNet datasets. Empirical results indicate that as models grow deeper and wider, multi-prize tickets start to reach similar (and sometimes even higher) test accuracy compared to their significantly larger and full-precision counterparts that have been weight-trained. Without ever updating the weight values, our MPTs-1/32 not only set new binary weight network state-of-the-art (SOTA) Top-1 accuracy -- 94.8% on CIFAR-10 and 74.03% on ImageNet -- but also outperform their full-precision counterparts by 1.78% and 0.76%, respectively. Further, our MPT-1/1 achieves SOTA Top-1 accuracy (91.9%) for binary neural networks on CIFAR-10. Code and pre-trained models are available at: https://github.com/chrundle/biprop.",
        "conference": "ICLR",
        "中文标题": "多奖彩票假设：通过修剪随机加权网络寻找精确的二进制神经网络",
        "摘要翻译": "最近，Frankle & Carbin（2019年）证明了随机初始化的密集网络包含子网络，这些子网络一旦被发现，可以通过训练达到与训练后的密集网络相当的测试准确率。然而，寻找这些高性能的可训练子网络成本高昂，需要迭代的训练和权重修剪过程。在本文中，我们提出（并证明）了一个更强的多奖彩票假设：一个足够过参数化的随机权重神经网络包含多个子网络（中奖彩票），这些子网络（a）具有与学习权重的密集目标网络相当的准确率（奖1），（b）不需要任何进一步的训练即可达到奖1（奖2），以及（c）对极端形式的量化（即二进制权重和/或激活）具有鲁棒性（奖3）。这为学习紧凑而高度精确的二进制神经网络提供了一个新的范式，只需通过修剪和量化随机加权的全精度神经网络即可实现。我们还提出了一种寻找多奖彩票（MPTs）的算法，并通过在CIFAR-10和ImageNet数据集上进行一系列实验来测试它。实证结果表明，随着模型变得越来越深和宽，多奖彩票开始达到与它们显著更大且全精度的对应物相似的（有时甚至更高的）测试准确率，这些对应物已经进行了权重训练。在不更新权重值的情况下，我们的MPTs-1/32不仅设置了新的二进制权重网络最先进（SOTA）Top-1准确率——在CIFAR-10上为94.8%，在ImageNet上为74.03%——而且还分别比它们的全精度对应物高出1.78%和0.76%。此外，我们的MPT-1/1在CIFAR-10上为二进制神经网络实现了SOTA Top-1准确率（91.9%）。代码和预训练模型可在以下网址获取：https://github.com/chrundle/biprop。",
        "领域": "神经网络修剪、二进制神经网络、模型压缩",
        "问题": "如何高效地找到在随机初始化的神经网络中存在的、无需进一步训练即可达到高准确率的子网络，并使其对极端量化具有鲁棒性。",
        "动机": "减少寻找高性能神经网络子网络的成本，同时保持或提高模型的准确率和鲁棒性。",
        "方法": "提出并证明了多奖彩票假设，开发了一种算法来寻找满足特定条件的子网络（多奖彩票），并通过实验验证了这些子网络在二进制神经网络中的有效性。",
        "关键词": [
            "多奖彩票假设",
            "二进制神经网络",
            "神经网络修剪",
            "模型压缩",
            "随机权重"
        ],
        "涉及的技术概念": {
            "多奖彩票假设": "提出了一种新的假设，认为随机初始化的神经网络中存在多个高性能的子网络，这些子网络无需进一步训练即可达到高准确率，并对极端量化具有鲁棒性。",
            "二进制神经网络": "一种权重和激活被量化为二进制的神经网络，旨在减少模型大小和计算成本。",
            "神经网络修剪": "通过移除神经网络中不重要的连接或节点来减少模型大小和计算成本的技术。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 528,
        "title": "Multi-resolution modeling of a discrete stochastic process identifies causes of cancer",
        "html": "https://iclr.cc//virtual/2021/poster/3170",
        "abstract": "Detection of cancer-causing mutations within the vast and mostly unexplored human genome is a major challenge. Doing so requires modeling the background mutation rate, a highly non-stationary stochastic process, across regions of interest varying in size from one to millions of positions. Here, we present the split-Poisson-Gamma (SPG) distribution, an extension of the classical Poisson-Gamma formulation, to model a discrete stochastic process at multiple resolutions. We demonstrate that the probability model has a closed-form posterior, enabling efficient and accurate linear-time prediction over any length scale after the parameters of the model have been inferred a single time. We apply our framework to model mutation rates in tumors and show that model parameters can be accurately inferred from high-dimensional epigenetic data using a convolutional neural network, Gaussian process, and maximum-likelihood estimation. Our method is both more accurate and more efficient than existing models over a large range of length scales. We demonstrate the usefulness of multi-resolution modeling by detecting genomic elements that drive tumor emergence and are of vastly differing sizes.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "离散随机过程的多分辨率建模识别癌症成因",
        "摘要翻译": "在广阔且大部分未被探索的人类基因组中检测致癌突变是一项重大挑战。这需要对背景突变率进行建模，这是一个高度非平稳的随机过程，涉及从一到数百万个位置大小不等的感兴趣区域。在此，我们提出了分裂泊松-伽马（SPG）分布，作为经典泊松-伽马公式的扩展，用于在多个分辨率下建模离散随机过程。我们证明了该概率模型具有封闭形式的后验，使得在模型参数被推断一次后，能够在任何长度尺度上进行高效且准确的线性时间预测。我们应用我们的框架来建模肿瘤中的突变率，并展示模型参数可以通过卷积神经网络、高斯过程和最大似然估计从高维表观遗传数据中准确推断。我们的方法在广泛的长度尺度上比现有模型更准确、更高效。通过检测驱动肿瘤出现且大小差异巨大的基因组元素，我们展示了多分辨率建模的实用性。",
        "领域": "基因组学数据分析",
        "问题": "如何在广阔的人类基因组中高效准确地检测致癌突变",
        "动机": "解决在高度非平稳的随机过程中建模背景突变率的挑战，以识别致癌突变",
        "方法": "提出分裂泊松-伽马（SPG）分布，结合卷积神经网络、高斯过程和最大似然估计，进行多分辨率建模",
        "关键词": [
            "多分辨率建模",
            "分裂泊松-伽马分布",
            "致癌突变检测",
            "卷积神经网络",
            "高斯过程"
        ],
        "涉及的技术概念": {
            "分裂泊松-伽马分布": "用于在多个分辨率下建模离散随机过程的扩展泊松-伽马公式",
            "卷积神经网络": "用于从高维表观遗传数据中准确推断模型参数",
            "高斯过程": "与卷积神经网络和最大似然估计结合，用于模型参数的准确推断"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 529,
        "title": "Multiscale Score Matching for Out-of-Distribution Detection",
        "html": "https://iclr.cc//virtual/2021/poster/3214",
        "abstract": "We present a new methodology for detecting out-of-distribution (OOD) images by utilizing norms of the score estimates at multiple noise scales. A score is defined to be the gradient of the log density with respect to the input data. Our methodology is completely unsupervised and follows a straight forward training scheme. First, we train a deep network to estimate scores for $L$ levels of noise. Once trained, we calculate the noisy score estimates for $N$ in-distribution samples and take the L2-norms across the input dimensions (resulting in an $N$x$L$ matrix). Then we train an auxiliary model (such as a Gaussian Mixture Model) to learn the in-distribution spatial regions in this $L$-dimensional space. This auxiliary model can now be used to identify points that reside outside the learned space. Despite its simplicity, our experiments show that this methodology significantly outperforms the state-of-the-art in detecting out-of-distribution images. For example, our method can effectively separate CIFAR-10 (inlier) and SVHN (OOD) images, a setting which has been previously shown to be difficult for deep likelihood models.",
        "conference": "ICLR",
        "中文标题": "多尺度评分匹配用于分布外检测",
        "摘要翻译": "我们提出了一种新方法，通过利用多个噪声尺度下评分估计的范数来检测分布外（OOD）图像。评分定义为输入数据相对于对数密度的梯度。我们的方法完全无监督，并遵循简单的训练方案。首先，我们训练一个深度网络来估计$L$个噪声水平的评分。训练完成后，我们计算$N$个分布内样本的噪声评分估计，并在输入维度上取L2范数（结果为一个$N$x$L$矩阵）。然后，我们训练一个辅助模型（如高斯混合模型）来学习这个$L$维空间中的分布内空间区域。这个辅助模型现在可以用来识别位于学习空间之外的点。尽管方法简单，我们的实验表明，这种方法在检测分布外图像方面显著优于现有技术。例如，我们的方法可以有效地分离CIFAR-10（内点）和SVHN（OOD）图像，这一设置在之前已被证明对深度似然模型来说是困难的。",
        "领域": "异常检测、图像分类、深度学习",
        "问题": "如何有效检测分布外图像",
        "动机": "解决深度似然模型在检测分布外图像方面的困难",
        "方法": "利用多尺度评分估计的范数训练深度网络和辅助模型进行分布外检测",
        "关键词": [
            "多尺度评分匹配",
            "分布外检测",
            "无监督学习",
            "高斯混合模型",
            "深度网络"
        ],
        "涉及的技术概念": {
            "评分估计": "定义为输入数据相对于对数密度的梯度，用于检测分布外图像",
            "L2范数": "在多尺度评分估计中用于衡量输入维度的差异",
            "高斯混合模型": "作为辅助模型，用于学习分布内样本在多维空间中的分布"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 530,
        "title": "Multi-Time Attention Networks for Irregularly Sampled Time Series",
        "html": "https://iclr.cc//virtual/2021/poster/2703",
        "abstract": "Irregular sampling occurs in many time series modeling applications where it presents a significant challenge to standard deep learning models. This work is motivated by the analysis of physiological time series data in electronic health records, which are sparse, irregularly sampled, and multivariate. In this paper, we propose a new deep learning framework for this setting that we call Multi-Time Attention Networks. Multi-Time Attention Networks learn an embedding of continuous time values and use an attention mechanism to produce a fixed-length representation of a time series containing a variable number of observations. We investigate the performance of this framework on interpolation and classification tasks using multiple datasets. Our results show that the proposed approach performs as well or better than a range of baseline and recently proposed models while offering significantly faster training times than current state-of-the-art methods.",
        "conference": "ICLR",
        "中文标题": "多时间注意力网络用于不规则采样时间序列",
        "摘要翻译": "不规则采样出现在许多时间序列建模应用中，这对标准的深度学习模型构成了重大挑战。这项工作的动机来自于对电子健康记录中生理时间序列数据的分析，这些数据是稀疏的、不规则采样的、多变量的。在本文中，我们提出了一种新的深度学习框架，我们称之为多时间注意力网络。多时间注意力网络学习连续时间值的嵌入，并使用注意力机制生成包含可变数量观测值的时间序列的固定长度表示。我们使用多个数据集研究了该框架在插值和分类任务上的性能。我们的结果表明，所提出的方法在性能上与一系列基线模型和最近提出的模型相当或更好，同时提供了比当前最先进方法显著更快的训练时间。",
        "领域": "时间序列分析、医疗健康数据分析、深度学习模型优化",
        "问题": "解决不规则采样时间序列数据的建模和分析问题",
        "动机": "分析电子健康记录中稀疏、不规则采样和多变量的生理时间序列数据",
        "方法": "提出多时间注意力网络，通过学习连续时间值的嵌入和使用注意力机制，生成时间序列的固定长度表示",
        "关键词": [
            "不规则采样时间序列",
            "多时间注意力网络",
            "电子健康记录",
            "深度学习",
            "注意力机制"
        ],
        "涉及的技术概念": {
            "多时间注意力网络": "一种新的深度学习框架，用于处理不规则采样时间序列数据",
            "注意力机制": "用于生成时间序列的固定长度表示，提高模型对重要时间点的关注",
            "连续时间值嵌入": "学习时间值的连续表示，以处理不规则采样数据"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 531,
        "title": "Multi-timescale Representation Learning in LSTM Language Models",
        "html": "https://iclr.cc//virtual/2021/poster/3095",
        "abstract": "Language models must capture statistical dependencies between words at timescales ranging from very short to very long. Earlier work has demonstrated that dependencies in natural language tend to decay with distance between words according to a power law. However, it is unclear how this knowledge can be used for analyzing or designing neural network language models. In this work, we derived a theory for how the memory gating mechanism in long short-term memory (LSTM) language models can capture power law decay. We found that unit timescales within an LSTM, which are determined by the forget gate bias, should follow an Inverse Gamma distribution. Experiments then showed that LSTM language models trained on natural English text learn to approximate this theoretical distribution. Further, we found that explicitly imposing the theoretical distribution upon the model during training yielded better language model perplexity overall, with particular improvements for predicting low-frequency (rare) words. Moreover, the explicit multi-timescale model selectively routes information about different types of words through units with different timescales, potentially improving model interpretability. These results demonstrate the importance of careful, theoretically-motivated analysis of memory and timescale in language models.",
        "conference": "ICLR",
        "中文标题": "LSTM语言模型中的多时间尺度表示学习",
        "摘要翻译": "语言模型必须捕捉从非常短到非常长的时间尺度上单词之间的统计依赖关系。早期工作表明，自然语言中的依赖关系倾向于按照幂律随单词之间的距离衰减。然而，如何利用这一知识来分析或设计神经网络语言模型尚不明确。在这项工作中，我们推导了一个理论，说明长短期记忆（LSTM）语言模型中的记忆门控机制如何捕捉幂律衰减。我们发现，LSTM内部单元的时间尺度（由遗忘门偏置决定）应遵循逆伽马分布。实验表明，在自然英语文本上训练的LSTM语言模型学会了近似这一理论分布。此外，我们发现，在训练过程中明确施加理论分布可以提高语言模型的整体困惑度，特别是在预测低频（罕见）单词方面有所改进。此外，明确的多时间尺度模型选择性地通过具有不同时间尺度的单元路由关于不同类型单词的信息，可能提高模型的可解释性。这些结果证明了在语言模型中对记忆和时间尺度进行仔细、理论驱动的分析的重要性。",
        "领域": "自然语言处理与视觉结合, 语言模型优化, 深度学习理论分析",
        "问题": "如何分析和设计神经网络语言模型以捕捉自然语言中随距离按幂律衰减的统计依赖关系",
        "动机": "探索LSTM语言模型中记忆门控机制捕捉幂律衰减的理论基础，以提高模型性能和可解释性",
        "方法": "推导LSTM中单元时间尺度应遵循逆伽马分布的理论，并在实验中验证该理论分布对模型性能的影响",
        "关键词": [
            "LSTM语言模型",
            "多时间尺度表示",
            "幂律衰减",
            "逆伽马分布",
            "模型可解释性"
        ],
        "涉及的技术概念": {
            "记忆门控机制": "LSTM中用于控制信息保留和遗忘的机制，本研究探讨其如何捕捉幂律衰减",
            "逆伽马分布": "本研究理论推导出的LSTM单元时间尺度应遵循的分布，用于优化模型性能",
            "模型困惑度": "评估语言模型性能的指标，本研究通过优化时间尺度分布降低了困惑度"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 532,
        "title": "Multivariate Probabilistic Time Series Forecasting via Conditioned Normalizing Flows",
        "html": "https://iclr.cc//virtual/2021/poster/3117",
        "abstract": "Time series forecasting is often fundamental to scientific and engineering problems and enables decision making. With ever increasing data set sizes, a trivial solution to scale up predictions is to assume independence between interacting time series. However, modeling statistical dependencies can improve accuracy and enable analysis of interaction effects. Deep learning methods are well suited for this problem, but multi-variate models often assume a simple parametric distribution and do not scale to high dimensions. In this work we model the multi-variate temporal dynamics of time series via an autoregressive deep learning model, where the data distribution  is represented by a conditioned normalizing flow. This combination retains the power of autoregressive models, such as good performance in extrapolation into the future, with the flexibility of flows as a general purpose high-dimensional distribution model, while remaining computationally tractable. We show that it improves over the state-of-the-art for standard metrics on many real-world data sets with several thousand interacting time-series.",
        "conference": "ICLR",
        "中文标题": "通过条件归一化流进行多变量概率时间序列预测",
        "摘要翻译": "时间序列预测通常是科学和工程问题的基础，能够支持决策制定。随着数据集规模的不断增加，扩大预测规模的一个简单解决方案是假设相互影响的时间序列之间独立。然而，建模统计依赖性可以提高准确性并实现交互效应的分析。深度学习方法非常适合这个问题，但多变量模型通常假设一个简单的参数分布，并且无法扩展到高维度。在这项工作中，我们通过自回归深度学习模型对时间序列的多变量时间动态进行建模，其中数据分布由条件归一化流表示。这种组合保留了自回归模型的优势，如对未来外推的良好性能，以及流作为一种通用高维分布模型的灵活性，同时保持计算上的可处理性。我们证明，在许多具有数千个相互影响时间序列的真实世界数据集上，它在标准指标上优于现有技术。",
        "领域": "时间序列预测、深度学习、概率模型",
        "问题": "如何在多变量时间序列预测中有效建模统计依赖性和扩展到高维度的问题。",
        "动机": "提高多变量时间序列预测的准确性，并分析时间序列间的交互效应。",
        "方法": "采用自回归深度学习模型结合条件归一化流来建模多变量时间序列的动态分布。",
        "关键词": [
            "多变量时间序列",
            "概率预测",
            "条件归一化流",
            "自回归模型",
            "深度学习"
        ],
        "涉及的技术概念": {
            "条件归一化流": "用于表示数据分布，提供高维分布的灵活建模能力。",
            "自回归模型": "用于捕捉时间序列的时间动态，保持对未来外推的良好性能。",
            "深度学习": "用于构建模型框架，处理大规模和多变量时间序列数据。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 533,
        "title": "Mutual Information State Intrinsic Control",
        "html": "https://iclr.cc//virtual/2021/poster/2723",
        "abstract": "Reinforcement learning has been shown to be highly successful at many challenging tasks. However, success heavily relies on well-shaped rewards. Intrinsically motivated RL attempts to remove this constraint by defining an intrinsic reward function. Motivated by the self-consciousness concept in psychology, we make a natural assumption that the agent knows what constitutes itself, and propose a new intrinsic objective that encourages the agent to have maximum control on the environment. We mathematically formalize this reward as the mutual information between the agent state and the surrounding state under the current agent policy. With this new intrinsic motivation, we are able to outperform previous methods, including being able to complete the pick-and-place task for the first time without using any task reward. A video showing experimental results is available at https://youtu.be/AUCwc9RThpk.",
        "conference": "ICLR",
        "中文标题": "互信息状态内在控制",
        "摘要翻译": "强化学习已被证明在许多具有挑战性的任务中非常成功。然而，成功很大程度上依赖于良好塑造的奖励。内在动机的强化学习试图通过定义一个内在奖励函数来消除这一限制。受到心理学中自我意识概念的启发，我们做了一个自然的假设，即智能体知道什么构成了它自己，并提出了一个新的内在目标，鼓励智能体对环境有最大的控制。我们将这一奖励数学形式化为当前智能体策略下智能体状态与周围状态之间的互信息。有了这种新的内在动机，我们能够超越以前的方法，包括首次在不使用任何任务奖励的情况下完成拾取和放置任务。展示实验结果的视频可在https://youtu.be/AUCwc9RThpk观看。",
        "领域": "强化学习、机器人控制、自主智能体",
        "问题": "如何在不依赖外部奖励的情况下，通过内在动机提高智能体对环境的控制能力",
        "动机": "受到心理学中自我意识概念的启发，探索智能体如何通过内在奖励自我激励，以增强对环境的控制",
        "方法": "提出一个新的内在目标，基于智能体状态与周围状态之间的互信息来定义内在奖励，以鼓励智能体对环境有最大的控制",
        "关键词": [
            "内在动机",
            "互信息",
            "强化学习",
            "自主控制",
            "拾取放置任务"
        ],
        "涉及的技术概念": {
            "互信息": "用于量化智能体状态与周围状态之间的统计依赖性，作为内在奖励的基础",
            "内在奖励函数": "替代外部奖励，激励智能体探索和学习，不依赖于任务特定的奖励设计",
            "自主智能体": "能够通过内在动机自我激励，独立于外部奖励进行学习和适应的智能体"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 534,
        "title": "My Body is a Cage: the Role of Morphology in Graph-Based Incompatible Control",
        "html": "https://iclr.cc//virtual/2021/poster/2942",
        "abstract": "Multitask Reinforcement Learning is a promising way to obtain models with better performance, generalisation, data efficiency, and robustness. Most existing work is limited to compatible settings, where the state and action space dimensions are the same across tasks. Graph Neural Networks (GNN) are one way to address incompatible environments, because they can process graphs of arbitrary size. They also allow practitioners to inject biases encoded in the structure of the input graph. Existing work in graph-based continuous control uses the physical morphology of the agent to construct the input graph, i.e., encoding limb features as node labels and using edges to connect the nodes if their corresponded limbs are physically connected.\nIn this work, we present a series of ablations on existing methods that show that morphological information encoded in the graph does not improve their performance. Motivated by the hypothesis that any benefits GNNs extract from the graph structure are outweighed by difficulties they create for message passing, we also propose Amorpheus, a transformer-based approach. Further results show that, while Amorpheus ignores the morphological information that GNNs encode, it nonetheless substantially outperforms GNN-based methods.",
        "conference": "ICLR",
        "中文标题": "我的身体是一个笼子：形态学在图基不兼容控制中的作用",
        "摘要翻译": "多任务强化学习是一种有前景的方法，可以获得具有更好性能、泛化能力、数据效率和鲁棒性的模型。大多数现有工作局限于兼容设置，其中状态和动作空间的维度在各个任务中是相同的。图神经网络（GNN）是解决不兼容环境的一种方式，因为它们可以处理任意大小的图。它们还允许从业者注入编码在输入图结构中的偏见。在图基连续控制的现有工作中，使用代理的物理形态来构建输入图，即，将肢体特征编码为节点标签，并使用边来连接节点，如果它们对应的肢体在物理上是连接的。在这项工作中，我们对现有方法进行了一系列的消融研究，表明图中编码的形态信息并没有提高它们的性能。基于GNN从图结构中提取的任何好处都被它们为消息传递创造的困难所抵消的假设，我们还提出了Amorpheus，一种基于变压器的方法。进一步的结果显示，虽然Amorpheus忽略了GNN编码的形态信息，但它仍然大大优于基于GNN的方法。",
        "领域": "多任务强化学习, 图神经网络, 连续控制",
        "问题": "解决在多任务强化学习中，由于状态和动作空间维度不同导致的不兼容问题",
        "动机": "探索形态学信息在图基不兼容控制中的实际效用，并提出更有效的解决方案",
        "方法": "通过消融研究评估形态信息的作用，并提出基于变压器的Amorpheus方法",
        "关键词": [
            "多任务强化学习",
            "图神经网络",
            "连续控制",
            "形态学",
            "变压器"
        ],
        "涉及的技术概念": {
            "图神经网络（GNN）": "用于处理任意大小的图，解决不兼容环境中的问题",
            "消融研究": "用于评估形态信息在图基控制中的实际效用",
            "变压器（Transformer）": "提出的Amorpheus方法基于此技术，用于提高性能而不依赖形态信息"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 535,
        "title": "NAS-Bench-ASR: Reproducible Neural Architecture Search for Speech Recognition",
        "html": "https://iclr.cc//virtual/2021/poster/3034",
        "abstract": "Powered by innovations in novel architecture design, noise tolerance techniques and increasing model capacity, Automatic Speech Recognition (ASR) has made giant strides in reducing word-error-rate over the past decade. ASR models are often trained with tens of thousand hours of high quality speech data to produce state-of-the-art (SOTA) results. Industry-scale ASR model training thus remains computationally heavy and time-consuming, and consequently has attracted little attention in adopting automatic techniques. On the other hand, Neural Architecture Search (NAS) has gained a lot of interest in the recent years thanks to its successes in discovering efficient architectures, often outperforming handcrafted alternatives. However, by changing the standard training process into a bi-level optimisation problem, NAS approaches often require significantly more time and computational power compared to single-model training, and at the same time increase complexity of the overall process. As a result, NAS has been predominately applied to problems which do not require as extensive training as ASR, and even then reproducibility of NAS algorithms is often problematic. Lately, a number of benchmark datasets has been introduced to address reproducibility issues by pro- viding NAS researchers with information about performance of different models obtained through exhaustive evaluation. However, these datasets focus mainly on computer vision and NLP tasks and thus suffer from limited coverage of application domains. In order to increase diversity in the existing NAS benchmarks, and at the same time provide systematic study of the effects of architectural choices for ASR, we release NAS-Bench-ASR – the first NAS benchmark for ASR models. The dataset consists of 8, 242 unique models trained on the TIMIT audio dataset for three different target epochs, and each starting from three different initializations. The dataset also includes runtime measurements of all the models on a diverse set of hardware platforms. Lastly, we show that identified good cell structures in our search space for TIMIT transfer well to a much larger LibriSpeech dataset.",
        "conference": "ICLR",
        "中文标题": "NAS-Bench-ASR：语音识别中可复现的神经架构搜索",
        "摘要翻译": "得益于新颖架构设计、噪声容忍技术以及模型容量的增加，自动语音识别（ASR）在过去十年中在降低词错误率方面取得了巨大进步。ASR模型通常需要数万小时的高质量语音数据进行训练，以产生最先进（SOTA）的结果。因此，工业级ASR模型的训练仍然计算量大且耗时，因此在采用自动化技术方面鲜有关注。另一方面，神经架构搜索（NAS）近年来因其在发现高效架构方面的成功而备受关注，这些架构往往优于手工设计的替代方案。然而，通过将标准训练过程转变为双层优化问题，NAS方法通常需要比单模型训练更多的时间和计算能力，同时增加了整个过程的复杂性。因此，NAS主要应用于不需要像ASR那样广泛训练的问题，即便如此，NAS算法的可复现性也常常存在问题。最近，一些基准数据集的引入通过为NAS研究人员提供通过详尽评估获得的不同模型性能信息，解决了可复现性问题。然而，这些数据集主要集中在计算机视觉和自然语言处理任务上，因此在应用领域的覆盖面上存在限制。为了增加现有NAS基准的多样性，同时为ASR的架构选择效果提供系统研究，我们发布了NAS-Bench-ASR——第一个用于ASR模型的NAS基准。该数据集包含8,242个在TIMIT音频数据集上训练的独特模型，针对三个不同的目标时期，每个时期从三个不同的初始化开始。数据集还包括所有模型在多种硬件平台上的运行时测量。最后，我们展示了在我们的搜索空间中对TIMIT识别良好的单元结构能够很好地迁移到更大的LibriSpeech数据集上。",
        "领域": "语音识别、神经架构搜索、自动语音识别",
        "问题": "解决自动语音识别（ASR）模型训练中神经架构搜索（NAS）的可复现性和效率问题",
        "动机": "为了增加NAS在ASR领域的应用，提供系统研究架构选择对ASR性能影响的方法",
        "方法": "发布NAS-Bench-ASR基准数据集，包含8,242个独特模型在TIMIT数据集上的训练结果和运行时测量，展示良好单元结构的迁移能力",
        "关键词": [
            "神经架构搜索",
            "自动语音识别",
            "可复现性",
            "基准数据集",
            "迁移学习"
        ],
        "涉及的技术概念": {
            "神经架构搜索（NAS）": "一种自动化设计神经网络架构的技术，用于发现高效架构",
            "自动语音识别（ASR）": "将人类语音转换为文本的技术，本研究中通过NAS优化其模型架构",
            "迁移学习": "将在TIMIT数据集上识别出的良好单元结构应用于更大的LibriSpeech数据集，验证其泛化能力"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 536,
        "title": "NBDT: Neural-Backed Decision Tree",
        "html": "https://iclr.cc//virtual/2021/poster/3310",
        "abstract": "Machine learning applications such as finance and medicine demand accurate and justifiable predictions, barring most deep learning methods from use. In response, previous work combines decision trees with deep learning, yielding models that (1) sacrifice interpretability for accuracy or (2) sacrifice accuracy for interpretability. We forgo this dilemma by jointly improving accuracy and interpretability using Neural-Backed Decision Trees (NBDTs). NBDTs replace a neural network's final linear layer with a differentiable sequence of decisions and a surrogate loss. This forces the model to learn high-level concepts and lessens reliance on highly-uncertain decisions, yielding (1) accuracy: NBDTs match or outperform modern neural networks on CIFAR, ImageNet and better generalize to unseen classes by up to 16%. Furthermore, our surrogate loss improves the original model's accuracy by up to 2%. NBDTs also afford (2) interpretability: improving human trustby clearly identifying model mistakes and assisting in dataset debugging. Code and pretrained NBDTs are at https://github.com/alvinwan/neural-backed-decision-trees.",
        "conference": "ICLR",
        "中文标题": "NBDT：神经支持决策树",
        "摘要翻译": "在金融和医学等机器学习应用领域，需要准确且可证明的预测，这使得大多数深度学习方法无法使用。为此，先前的工作将决策树与深度学习结合，产生的模型要么（1）为了准确性牺牲可解释性，要么（2）为了可解释性牺牲准确性。我们通过使用神经支持决策树（NBDT）共同提高准确性和可解释性，避免了这一困境。NBDTs用可微分的决策序列和替代损失替换了神经网络的最终线性层。这迫使模型学习高级概念，并减少对高度不确定决策的依赖，从而实现了（1）准确性：NBDTs在CIFAR、ImageNet上与现代神经网络相匹敌或超越，并且对未见类别的泛化能力提高了多达16%。此外，我们的替代损失将原始模型的准确性提高了多达2%。NBDTs还提供了（2）可解释性：通过明确识别模型错误和辅助数据集调试，提高了人类的信任度。代码和预训练的NBDTs可在https://github.com/alvinwan/neural-backed-decision-trees找到。",
        "领域": "深度学习与决策树结合、模型可解释性、图像分类",
        "问题": "如何在保持深度学习模型高准确性的同时，提高其可解释性。",
        "动机": "解决深度学习模型在需要准确且可解释预测的应用领域（如金融和医学）中的适用性问题。",
        "方法": "通过将神经网络的最终线性层替换为可微分的决策序列和替代损失，共同提高模型的准确性和可解释性。",
        "关键词": [
            "神经支持决策树",
            "模型可解释性",
            "深度学习",
            "决策树",
            "替代损失"
        ],
        "涉及的技术概念": {
            "神经支持决策树": "一种结合神经网络和决策树的模型，旨在同时提高准确性和可解释性。",
            "替代损失": "用于替换原始模型损失函数的损失，旨在优化模型训练过程，提高准确性。",
            "可微分决策序列": "一种允许模型通过可微分操作进行决策的技术，使得模型能够学习高级概念并减少对不确定决策的依赖。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 537,
        "title": "Nearest Neighbor Machine Translation",
        "html": "https://iclr.cc//virtual/2021/poster/2532",
        "abstract": "We introduce $k$-nearest-neighbor machine translation ($k$NN-MT), which predicts tokens with a nearest-neighbor classifier over a large datastore of cached examples, using representations from a neural translation model for similarity search. This approach requires no additional training and scales to give the decoder direct access to billions of examples at test time, resulting in a highly expressive model that consistently improves performance across many settings. Simply adding nearest-neighbor search improves a state-of-the-art German-English translation model by 1.5 BLEU. $k$NN-MT allows a single model to be adapted to diverse domains by using a domain-specific datastore, improving results by an average of 9.2 BLEU over zero-shot transfer, and achieving new state-of-the-art results---without training on these domains. A massively multilingual model can also be specialized for particular language pairs, with improvements of 3 BLEU for translating from English into German and Chinese. Qualitatively, $k$NN-MT is easily interpretable; it combines source and target context to retrieve highly relevant examples.",
        "conference": "ICLR",
        "中文标题": "最近邻机器翻译",
        "摘要翻译": "我们介绍了$k$-最近邻机器翻译（$k$NN-MT），它通过一个大型缓存示例数据存储上的最近邻分类器来预测标记，使用神经翻译模型的表示进行相似性搜索。这种方法不需要额外的训练，并且可以扩展，使解码器在测试时直接访问数十亿个示例，从而形成一个高度表达性的模型，在许多设置中持续提高性能。简单地添加最近邻搜索，就能将最先进的德英翻译模型的性能提高1.5 BLEU。$k$NN-MT允许通过使用特定领域的数据存储来使单个模型适应不同的领域，比零样本转移平均提高9.2 BLEU，并在这些领域上无需训练即可达到新的最先进结果。一个大规模的多语言模型也可以专门用于特定的语言对，将英语翻译成德语和中文的性能提高3 BLEU。从质量上讲，$k$NN-MT易于解释；它结合了源和目标上下文来检索高度相关的示例。",
        "领域": "机器翻译、自然语言处理、多语言处理",
        "问题": "提高机器翻译的性能和适应性，特别是在多语言和特定领域翻译任务中。",
        "动机": "探索一种无需额外训练即可提高翻译模型性能的方法，并使其能够适应不同的领域和语言对。",
        "方法": "使用最近邻分类器和大规模缓存示例数据存储进行相似性搜索，以预测翻译标记。",
        "关键词": [
            "最近邻机器翻译",
            "多语言翻译",
            "领域适应",
            "BLEU提升",
            "无需训练"
        ],
        "涉及的技术概念": {
            "最近邻分类器": "用于在大型数据存储中查找与当前翻译任务最相似的示例，以预测翻译标记。",
            "神经翻译模型表示": "用于计算相似性搜索的表示，使得模型能够找到与当前上下文最相关的翻译示例。",
            "大规模数据存储": "存储数十亿个翻译示例，使模型在测试时能够直接访问这些示例，从而提高翻译的准确性和适应性。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 538,
        "title": "Negative Data Augmentation ",
        "html": "https://iclr.cc//virtual/2021/poster/2546",
        "abstract": "Data augmentation is often used to enlarge datasets with synthetic samples generated in accordance with the underlying data distribution. To enable a wider range of augmentations, we explore negative data augmentation strategies (NDA) that intentionally create out-of-distribution samples. We show that such negative out-of-distribution samples provide information on the support of the data distribution,  and can be leveraged for generative modeling and representation learning. We introduce a new GAN training objective where we use NDA as an additional source of synthetic data for the discriminator. We prove that under suitable conditions, optimizing the resulting objective still recovers the true data distribution but can directly bias the generator towards avoiding samples that lack the desired structure. Empirically, models trained with our method achieve improved conditional/unconditional image generation along with improved anomaly detection capabilities. Further, we incorporate the same negative data augmentation strategy in a contrastive learning framework for self-supervised representation learning on images and videos, achieving improved performance on downstream image classification, object detection, and action recognition tasks. These results suggest that prior knowledge on what does not constitute valid data is an effective form of weak supervision across a range of unsupervised learning tasks.",
        "conference": "ICLR",
        "中文标题": "负数据增强",
        "摘要翻译": "数据增强通常用于通过根据底层数据分布生成的合成样本来扩大数据集。为了启用更广泛的增强方法，我们探索了故意创建分布外样本的负数据增强策略（NDA）。我们展示了这种负的分布外样本提供了关于数据分布支持的信息，并且可以用于生成建模和表示学习。我们引入了一个新的GAN训练目标，其中我们使用NDA作为判别器的额外合成数据来源。我们证明，在适当的条件下，优化所得目标仍然可以恢复真实的数据分布，但可以直接使生成器偏向于避免缺乏所需结构的样本。实证上，使用我们的方法训练的模型在条件/无条件图像生成以及异常检测能力方面实现了改进。此外，我们在对比学习框架中采用了相同的负数据增强策略，用于图像和视频的自监督表示学习，在下游图像分类、目标检测和动作识别任务上实现了性能提升。这些结果表明，关于什么不构成有效数据的先验知识是一种有效的弱监督形式，适用于一系列无监督学习任务。",
        "领域": "生成对抗网络、自监督学习、异常检测",
        "问题": "如何利用负数据增强策略（NDA）来改进生成建模和表示学习的效果",
        "动机": "探索通过故意创建分布外样本的负数据增强策略，以提供关于数据分布支持的信息，并利用这些信息改进生成建模和表示学习的效果",
        "方法": "引入了一个新的GAN训练目标，使用NDA作为判别器的额外合成数据来源，并在对比学习框架中采用相同的负数据增强策略进行自监督表示学习",
        "关键词": [
            "负数据增强",
            "生成对抗网络",
            "自监督学习",
            "异常检测",
            "对比学习"
        ],
        "涉及的技术概念": {
            "负数据增强（NDA）": "故意创建分布外样本的策略，用于提供关于数据分布支持的信息",
            "生成对抗网络（GAN）": "用于生成建模的框架，通过判别器和生成器的对抗训练来恢复真实的数据分布",
            "对比学习": "一种自监督学习方法，通过比较正负样本来学习有效的表示"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 539,
        "title": "NeMo: Neural Mesh Models of Contrastive Features for Robust 3D Pose Estimation",
        "html": "https://iclr.cc//virtual/2021/poster/3073",
        "abstract": "3D pose estimation is a challenging but important task in computer vision. In this work, we show that standard deep learning approaches to 3D pose estimation are not robust to partial occlusion. Inspired by the robustness of generative vision models to partial occlusion, we propose to integrate deep neural networks with 3D generative representations of objects into a unified neural architecture that we term NeMo. In particular, NeMo learns a generative model of neural feature activations at each vertex on a dense 3D mesh. Using differentiable rendering we estimate the 3D object pose by minimizing the reconstruction error between NeMo and the feature representation of the target image. To avoid local optima in the reconstruction loss, we train the feature extractor to maximize the distance between the individual feature representations on the mesh using contrastive learning. Our extensive experiments on PASCAL3D+, occluded-PASCAL3D+ and ObjectNet3D show that NeMo is much more robust to partial occlusion compared to standard deep networks, while retaining competitive performance on non-occluded data. Interestingly, our experiments also show that NeMo performs reasonably well even when the mesh representation only crudely approximates the true object geometry with a cuboid, hence revealing that the detailed 3D geometry is not needed for accurate 3D pose estimation.",
        "conference": "ICLR",
        "中文标题": "NeMo：基于对比特征的神经网格模型用于鲁棒的三维姿态估计",
        "摘要翻译": "三维姿态估计是计算机视觉中一项具有挑战性但重要的任务。在这项工作中，我们发现标准的深度学习方法在三维姿态估计中对部分遮挡不够鲁棒。受到生成视觉模型对部分遮挡鲁棒性的启发，我们提出将深度神经网络与物体的三维生成表示整合到一个统一的神经架构中，我们称之为NeMo。具体来说，NeMo学习在密集的三维网格上每个顶点的神经特征激活的生成模型。通过可微分渲染，我们通过最小化NeMo与目标图像特征表示之间的重建误差来估计三维物体姿态。为了避免重建损失中的局部最优，我们训练特征提取器以通过对比学习最大化网格上各个特征表示之间的距离。我们在PASCAL3D+、遮挡-PASCAL3D+和ObjectNet3D上的大量实验表明，与标准的深度网络相比，NeMo对部分遮挡更加鲁棒，同时在非遮挡数据上保持竞争性能。有趣的是，我们的实验还显示，即使网格表示仅用长方体粗略近似真实物体几何，NeMo也表现相当好，从而揭示了详细的3D几何对于准确的三维姿态估计不是必需的。",
        "领域": "三维姿态估计",
        "问题": "解决三维姿态估计在部分遮挡情况下的鲁棒性问题",
        "动机": "标准深度学习方法在三维姿态估计中对部分遮挡不够鲁棒，受到生成视觉模型对部分遮挡鲁棒性的启发，提出整合深度神经网络与三维生成表示的方法",
        "方法": "提出NeMo架构，学习三维网格上每个顶点的神经特征激活的生成模型，通过可微分渲染和对比学习优化特征表示，以估计三维姿态",
        "关键词": [
            "三维姿态估计",
            "神经网格模型",
            "对比学习",
            "可微分渲染",
            "部分遮挡鲁棒性"
        ],
        "涉及的技术概念": {
            "神经网格模型": "在密集的三维网格上学习神经特征激活的生成模型，用于表示物体的三维结构",
            "可微分渲染": "用于通过最小化重建误差来估计三维物体姿态的技术，使得梯度可以通过渲染过程反向传播",
            "对比学习": "训练特征提取器以最大化不同特征表示之间的距离，避免重建损失中的局部最优"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 540,
        "title": "Net-DNF: Effective Deep Modeling of Tabular Data",
        "html": "https://iclr.cc//virtual/2021/poster/2539",
        "abstract": "A challenging open question in deep learning is how to handle tabular data. Unlike domains such as image and natural language processing, where deep architectures prevail, there is still no widely accepted neural architecture that dominates tabular data. As a step toward bridging this gap, we present Net-DNF a novel generic architecture whose inductive bias elicits models whose structure corresponds to logical Boolean formulas in disjunctive normal form (DNF) over affine soft-threshold decision terms. Net-DNFs also promote localized decisions that are taken over small subsets of the features. We present an extensive experiments showing that Net-DNFs significantly and consistently outperform fully connected networks over tabular data. With relatively few hyperparameters, Net-DNFs open the door to practical end-to-end handling of tabular data using neural networks. We present ablation studies, which justify the design choices of Net-DNF including the inductive bias elements, namely, Boolean formulation, locality, and feature selection. \n",
        "conference": "ICLR",
        "中文标题": "Net-DNF：表格数据的有效深度建模",
        "摘要翻译": "深度学习中的一个具有挑战性的开放问题是如何处理表格数据。与图像和自然语言处理等领域不同，在这些领域中深度架构占主导地位，但目前还没有广泛接受的神经架构在表格数据上占据主导地位。为了缩小这一差距，我们提出了Net-DNF，这是一种新颖的通用架构，其归纳偏差引出的模型结构对应于在仿射软阈值决策项上的析取范式（DNF）逻辑布尔公式。Net-DNF还促进了在特征的小子集上做出的局部决策。我们进行了广泛的实验，显示Net-DNF在表格数据上显著且一致地优于全连接网络。Net-DNF具有相对较少的超参数，为使用神经网络进行表格数据的实用端到端处理打开了大门。我们提出了消融研究，这些研究证明了Net-DNF的设计选择，包括归纳偏差元素，即布尔公式、局部性和特征选择。",
        "领域": "深度学习与表格数据处理、神经网络架构设计、特征选择与局部决策",
        "问题": "如何有效地使用深度学习方法处理表格数据，并设计出优于全连接网络的神经架构。",
        "动机": "当前深度学习在图像和自然语言处理等领域取得了显著成功，但在表格数据处理上缺乏广泛接受的神经架构，Net-DNF旨在填补这一空白。",
        "方法": "提出了一种新颖的通用架构Net-DNF，其模型结构对应于在仿射软阈值决策项上的析取范式（DNF）逻辑布尔公式，并促进在特征的小子集上做出的局部决策。",
        "关键词": [
            "表格数据",
            "Net-DNF",
            "深度建模",
            "布尔公式",
            "特征选择"
        ],
        "涉及的技术概念": {
            "析取范式（DNF）": "一种逻辑布尔公式的表达形式，Net-DNF利用其在仿射软阈值决策项上的应用来构建模型结构。",
            "仿射软阈值决策项": "Net-DNF中用于构建模型的基础决策单元，支持局部决策和特征选择。",
            "归纳偏差": "Net-DNF设计中的核心概念，包括布尔公式、局部性和特征选择，指导模型学习表格数据的有效表示。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 541,
        "title": "Network Pruning That Matters:  A Case Study on Retraining Variants",
        "html": "https://iclr.cc//virtual/2021/poster/2991",
        "abstract": "Network pruning is an effective method to reduce the computational expense of over-parameterized neural networks for deployment on low-resource systems. Recent state-of-the-art techniques for retraining pruned networks such as weight rewinding and learning rate rewinding have been shown to outperform the traditional fine-tuning technique in recovering the lost accuracy (Renda et al., 2020), but so far it is unclear what accounts for such performance. In this work, we conduct extensive experiments to verify and analyze the uncanny effectiveness of learning rate rewinding. We find that the reason behind the success of learning rate rewinding is the usage of a large learning rate. Similar phenomenon can be observed in other learning rate schedules that involve large learning rates, e.g., the 1-cycle learning rate schedule (Smith et al., 2019). By leveraging the right learning rate schedule in retraining, we demonstrate a counter-intuitive phenomenon in that randomly pruned networks could even achieve better performance than methodically pruned networks (fine-tuned with the conventional approach). Our results emphasize the cruciality of the learning rate schedule in pruned network retraining - a detail often overlooked by practitioners during the implementation of network pruning. ",
        "conference": "ICLR",
        "中文标题": "网络剪枝的重要性：关于重新训练变体的案例研究",
        "摘要翻译": "网络剪枝是一种有效的方法，用于减少过度参数化神经网络在低资源系统上部署时的计算开销。最近的先进技术，如权重回退和学习率回退，在恢复丢失的准确性方面已被证明优于传统的微调技术（Renda等人，2020年），但到目前为止，尚不清楚是什么导致了这种性能。在这项工作中，我们进行了广泛的实验来验证和分析学习率回退的不可思议的有效性。我们发现，学习率回退成功的原因在于使用了较大的学习率。类似的现象可以在其他涉及大学习率的学习率调度中观察到，例如1周期学习率调度（Smith等人，2019年）。通过在重新训练中利用正确的学习率调度，我们展示了一个反直觉的现象，即随机剪枝的网络甚至可以比方法性剪枝的网络（使用传统方法微调）获得更好的性能。我们的结果强调了学习率调度在剪枝网络重新训练中的关键性——这一细节在实施网络剪枝时常常被从业者忽视。",
        "领域": "神经网络优化",
        "问题": "如何有效恢复剪枝后神经网络的性能",
        "动机": "探索学习率调度在剪枝网络重新训练中的作用，以提高模型性能",
        "方法": "通过实验分析学习率回退的有效性，并比较不同学习率调度策略对剪枝网络性能的影响",
        "关键词": [
            "网络剪枝",
            "学习率调度",
            "模型优化"
        ],
        "涉及的技术概念": {
            "学习率回退": "在重新训练剪枝网络时，使用较大的学习率以恢复模型性能的技术",
            "1周期学习率调度": "一种学习率调度策略，涉及在训练过程中动态调整学习率，包括使用较大的学习率",
            "权重回退": "在重新训练剪枝网络时，将权重重置到剪枝前的状态，以帮助恢复模型性能的技术"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 542,
        "title": "Neural Approximate Sufficient Statistics for Implicit Models",
        "html": "https://iclr.cc//virtual/2021/poster/3267",
        "abstract": "We consider the fundamental problem of how to automatically construct summary statistics for implicit generative models where the evaluation of the likelihood function is intractable but sampling data from the model is possible. The idea is to frame the task of constructing sufficient statistics as learning mutual information maximizing representations of the data with the help of deep neural networks. The infomax learning procedure does not need to estimate any density or density ratio. We apply our approach to both traditional approximate Bayesian computation and recent neural likelihood methods, boosting their performance on a range of tasks. ",
        "conference": "ICLR",
        "success": true,
        "中文标题": "隐式模型的神经近似充分统计量",
        "摘要翻译": "我们考虑了一个基本问题：如何为隐式生成模型自动构建摘要统计量，这些模型的似然函数评估难以处理，但可以从模型中采样数据。我们的想法是将构建充分统计量的任务框架化为借助深度神经网络学习数据的互信息最大化表示。这种信息最大化学习过程不需要估计任何密度或密度比。我们将我们的方法应用于传统的近似贝叶斯计算和最近的神经似然方法，在一系列任务中提升了它们的性能。",
        "领域": "生成模型",
        "问题": "如何为隐式生成模型自动构建摘要统计量",
        "动机": "解决隐式生成模型中似然函数评估难以处理的问题，通过自动构建摘要统计量来提升模型性能",
        "方法": "利用深度神经网络学习数据的互信息最大化表示，无需估计密度或密度比",
        "关键词": [
            "隐式生成模型",
            "摘要统计量",
            "互信息最大化",
            "深度神经网络",
            "近似贝叶斯计算"
        ],
        "涉及的技术概念": {
            "隐式生成模型": "一种生成模型，其似然函数难以直接评估，但可以从中采样数据",
            "互信息最大化": "一种学习表示的方法，旨在最大化数据表示与目标变量之间的互信息",
            "深度神经网络": "用于学习数据表示的强大工具，能够捕捉数据中的复杂模式"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 543,
        "title": "Neural Architecture Search on ImageNet in Four GPU Hours: A Theoretically Inspired Perspective",
        "html": "https://iclr.cc//virtual/2021/poster/2816",
        "abstract": "Neural Architecture Search (NAS) has been explosively studied to automate the discovery of top-performer neural networks. Current works require heavy training of supernet or intensive architecture evaluations, thus suffering from heavy resource consumption and often incurring search bias due to truncated training or approximations. Can we select the best neural architectures without involving any training and eliminate a drastic portion of the search cost? \n\nWe provide an affirmative answer, by proposing a novel framework called \\textit{training-free neural architecture search} ($\\textbf{TE-NAS}$). TE-NAS ranks architectures by analyzing the spectrum of the neural tangent kernel (NTK), and the number of linear regions in the input space. Both are motivated by recent theory advances in deep networks, and can be computed without any training. We show that: (1) these two measurements imply the $\\textit{trainability}$ and $\\textit{expressivity}$ of a neural network; and (2) they strongly correlate with the network's actual test accuracy. Further on, we design a pruning-based NAS mechanism to achieve a more flexible and superior trade-off between the trainability and expressivity during the search. In NAS-Bench-201 and DARTS search spaces, TE-NAS completes high-quality search but only costs $\\textbf{0.5}$ and $\\textbf{4}$ GPU hours with one 1080Ti on CIFAR-10 and ImageNet, respectively. We hope our work to inspire more attempts in bridging between the theoretic findings of deep networks and practical impacts in real NAS applications.",
        "conference": "ICLR",
        "中文标题": "四GPU小时内在ImageNet上进行的神经架构搜索：理论启发的视角",
        "摘要翻译": "神经架构搜索（NAS）已被广泛研究以自动化发现性能最优的神经网络。当前的工作需要大量训练超级网络或密集的架构评估，因此遭受资源消耗大和由于截断训练或近似而常常引入搜索偏差的问题。我们能否在不涉及任何训练的情况下选择最佳的神经架构，并消除大部分搜索成本？我们通过提出一个名为\textit{免训练神经架构搜索}（\textbf{TE-NAS}）的新框架给出了肯定的答案。TE-NAS通过分析神经切线核（NTK）的谱和输入空间中线性区域的数量来排名架构。这两者都受到深度学习网络最新理论进展的启发，并且可以在不进行任何训练的情况下计算。我们表明：（1）这两个测量指标暗示了神经网络的\textit{可训练性}和\textit{表达能力}；（2）它们与网络的实际测试准确度有很强的相关性。此外，我们设计了一种基于剪枝的NAS机制，以在搜索过程中实现可训练性和表达能力之间更灵活和优越的权衡。在NAS-Bench-201和DARTS搜索空间中，TE-NAS完成了高质量的搜索，但在CIFAR-10和ImageNet上分别仅消耗\textbf{0.5}和\textbf{4} GPU小时（使用一块1080Ti显卡）。我们希望我们的工作能够激发更多尝试，将深度学习网络的理论发现与实际NAS应用中的影响联系起来。",
        "领域": "神经架构搜索、深度学习优化、自动化机器学习",
        "问题": "如何在减少资源消耗和避免搜索偏差的同时，高效自动化地发现最优神经网络架构",
        "动机": "解决当前神经架构搜索方法中资源消耗大和搜索偏差的问题，通过理论启发的方法实现高效架构搜索",
        "方法": "提出免训练神经架构搜索（TE-NAS）框架，利用神经切线核谱和线性区域数量作为架构评估指标，结合剪枝机制优化搜索过程",
        "关键词": [
            "神经架构搜索",
            "免训练评估",
            "神经切线核",
            "线性区域",
            "剪枝机制"
        ],
        "涉及的技术概念": {
            "神经切线核（NTK）": "用于评估神经网络的可训练性，无需实际训练即可预测网络性能",
            "线性区域数量": "衡量神经网络的表达能力，反映网络对输入空间的划分能力",
            "剪枝机制": "在搜索过程中动态调整架构，优化可训练性和表达能力的平衡"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 544,
        "title": "Neural Attention Distillation: Erasing Backdoor Triggers from Deep Neural Networks",
        "html": "https://iclr.cc//virtual/2021/poster/2760",
        "abstract": "Deep neural networks (DNNs) are known vulnerable to backdoor attacks, a training time attack that injects a trigger pattern into a small proportion of training data so as to control the model's prediction at the test time. Backdoor attacks are notably dangerous since they do not affect the model's performance on clean examples, yet can fool the model to make the incorrect prediction whenever the trigger pattern appears during testing. In this paper, we propose a novel defense framework Neural Attention Distillation (NAD) to erase backdoor triggers from backdoored DNNs. NAD utilizes a teacher network to guide the finetuning of the backdoored student network on a small clean subset of data such that the intermediate-layer attention of the student network aligns with that of the teacher network. The teacher network can be obtained by an independent finetuning process on the same clean subset. We empirically show, against 6 state-of-the-art backdoor attacks,  NAD can effectively erase the backdoor triggers using only 5\\% clean training data without causing obvious performance degradation on clean examples. Our code is available at https://github.com/bboylyg/NAD.",
        "conference": "ICLR",
        "中文标题": "神经注意力蒸馏：从深度神经网络中消除后门触发器",
        "摘要翻译": "深度神经网络（DNNs）已知易受后门攻击，这是一种在训练时将触发器模式注入一小部分训练数据中，以便在测试时控制模型预测的攻击。后门攻击特别危险，因为它们不影响模型在干净样本上的性能，却能在测试时触发器模式出现时欺骗模型做出错误预测。本文提出了一种新颖的防御框架——神经注意力蒸馏（NAD），用于从被后门攻击的DNNs中消除后门触发器。NAD利用教师网络指导被后门攻击的学生网络在一小部分干净数据上的微调，使学生网络的中间层注意力与教师网络对齐。教师网络可以通过在同一干净子集上的独立微调过程获得。我们实证表明，针对6种最先进的后门攻击，NAD仅使用5%的干净训练数据即可有效消除后门触发器，而不会对干净样本造成明显的性能下降。我们的代码可在https://github.com/bboylyg/NAD获取。",
        "领域": "深度学习安全、后门攻击防御、神经网络鲁棒性",
        "问题": "如何从深度神经网络中有效消除后门触发器，而不影响模型在干净数据上的性能。",
        "动机": "后门攻击对深度神经网络的安全性构成严重威胁，需要开发有效的防御机制来消除这些攻击，同时保持模型在未受攻击数据上的性能。",
        "方法": "提出神经注意力蒸馏（NAD）框架，通过教师网络指导学生网络的微调，使其注意力与教师网络对齐，从而消除后门触发器。",
        "关键词": [
            "后门攻击防御",
            "神经注意力蒸馏",
            "深度神经网络安全",
            "微调策略",
            "注意力机制"
        ],
        "涉及的技术概念": {
            "神经注意力蒸馏（NAD）": "一种防御框架，通过教师网络指导学生网络的微调，消除后门触发器。",
            "后门攻击": "一种训练时攻击，通过在训练数据中注入触发器模式来控制模型在测试时的预测。",
            "注意力机制": "在NAD中用于对齐学生网络和教师网络的中间层注意力，帮助消除后门触发器。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 545,
        "title": "Neural Delay Differential Equations",
        "html": "https://iclr.cc//virtual/2021/poster/3120",
        "abstract": "<p>Neural Ordinary Differential Equations (NODEs), a framework of continuous-depth neural networks, have been widely\r\n    applied, showing exceptional efficacy in coping with some representative datasets. Recently, an augmented framework\r\n    has been successfully developed for conquering some limitations emergent in application of the original framework.\r\n    Here we propose a new class of continuous-depth neural networks with delay, named as Neural Delay Differential\r\n    Equations (NDDEs), and, for computing the corresponding gradients, we use the adjoint sensitivity method to obtain\r\n    the delayed dynamics of the adjoint. Since the differential equations with delays are usually seen as dynamical\r\n    systems of infinite dimension possessing more fruitful dynamics, the NDDEs, compared to the NODEs, own a stronger\r\n    capacity of nonlinear representations. Indeed, we analytically validate that the NDDEs are of universal\r\n    approximators, and further articulate an extension of the NDDEs, where the initial function of the NDDEs is supposed\r\n    to satisfy ODEs. More importantly, we use several illustrative examples to demonstrate the outstanding capacities of\r\n    the NDDEs and the NDDEs with ODEs' initial value. More precisely, (1) we successfully model the delayed dynamics\r\n    where the trajectories in the lower-dimensional phase space could be mutually intersected, while the traditional\r\n    NODEs without any argumentation are not directly applicable for such modeling, and (2) we achieve lower loss and\r\n    higher accuracy not only for the data produced synthetically by complex models but also for the real-world image\r\n    datasets, i.e., CIFAR10, MNIST and SVHN. Our results on the NDDEs reveal that appropriately articulating the\r\n    elements of dynamical systems into the network design is truly beneficial to promoting the network performance.\r\n</p>",
        "conference": "ICLR",
        "中文标题": "神经延迟微分方程",
        "摘要翻译": "神经普通微分方程（NODEs）作为一种连续深度神经网络的框架，已被广泛应用，并在处理一些代表性数据集时显示出卓越的效能。最近，一个增强框架被成功开发出来，以克服原始框架在应用中出现的一些限制。在此，我们提出了一类新的带有延迟的连续深度神经网络，命名为神经延迟微分方程（NDDEs），并且，为了计算相应的梯度，我们使用伴随灵敏度方法来获得伴随的延迟动态。由于带有延迟的微分方程通常被视为具有更丰富动态的无限维动力系统，与NODEs相比，NDDEs拥有更强的非线性表示能力。事实上，我们分析验证了NDDEs是通用逼近器，并进一步阐述了NDDEs的一个扩展，其中NDDEs的初始函数假设满足ODEs。更重要的是，我们使用几个示例性例子来展示NDDEs和具有ODEs初始值的NDDEs的出色能力。更准确地说，（1）我们成功地建模了延迟动态，其中低维相空间中的轨迹可以相互交叉，而没有任何增强的传统NODEs不直接适用于此类建模；（2）我们不仅对于由复杂模型合成的数据，而且对于真实世界的图像数据集，即CIFAR10、MNIST和SVHN，实现了更低的损失和更高的准确度。我们在NDDEs上的结果表明，适当地将动力系统的元素融入网络设计中，确实有利于提升网络性能。",
        "领域": "连续深度神经网络、动力系统建模、图像识别",
        "问题": "克服神经普通微分方程（NODEs）在处理延迟动态和复杂数据集时的限制",
        "动机": "探索和开发能够更有效处理延迟动态和复杂数据集的连续深度神经网络框架",
        "方法": "提出神经延迟微分方程（NDDEs）框架，使用伴随灵敏度方法计算梯度，并通过理论分析和实验验证其性能",
        "关键词": [
            "神经延迟微分方程",
            "伴随灵敏度方法",
            "通用逼近器",
            "动力系统建模",
            "图像识别"
        ],
        "涉及的技术概念": {
            "神经延迟微分方程（NDDEs）": "一类新的带有延迟的连续深度神经网络，用于增强非线性表示能力和处理延迟动态",
            "伴随灵敏度方法": "用于计算NDDEs的梯度，获得伴随的延迟动态",
            "通用逼近器": "分析验证NDDEs能够逼近任何连续函数，证明其强大的表示能力"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 546,
        "title": "Neural gradients are near-lognormal: improved quantized  and sparse training",
        "html": "https://iclr.cc//virtual/2021/poster/2716",
        "abstract": "While training can mostly be accelerated by reducing the time needed to propagate neural gradients (loss gradients with respect to the intermediate neural layer outputs) back throughout the model, most previous works focus on the quantization/pruning of weights and activations. These methods are often not applicable to neural gradients, which have very different statistical properties. Distinguished from weights and activations, we find that the distribution of neural gradients is approximately lognormal. Considering this, we suggest two closed-form analytical methods to reduce the computational and memory burdens of neural gradients. The first method optimizes the floating-point format and scale of the gradients. The second method accurately sets sparsity thresholds for gradient pruning.  Each method achieves state-of-the-art results on ImageNet. To the best of our knowledge, this paper is the first to (1) quantize the gradients to 6-bit floating-point formats, or (2) achieve up to 85% gradient sparsity --- in each case without accuracy degradation.\nReference implementation accompanies the paper in the supplementary material.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "神经梯度接近对数正态分布：改进的量化与稀疏训练",
        "摘要翻译": "虽然通过减少传播神经梯度（即损失梯度相对于中间神经层输出的梯度）所需的时间可以大幅加速训练过程，但大多数先前的工作集中在权重和激活的量化/剪枝上。这些方法通常不适用于神经梯度，因为神经梯度具有非常不同的统计特性。与权重和激活不同，我们发现神经梯度的分布近似于对数正态。考虑到这一点，我们提出了两种闭式解析方法来减少神经梯度的计算和内存负担。第一种方法优化了梯度的浮点格式和比例。第二种方法准确设置了梯度剪枝的稀疏阈值。每种方法都在ImageNet上取得了最先进的结果。据我们所知，本文是第一个（1）将梯度量化为6位浮点格式，或（2）实现高达85%的梯度稀疏度——在每种情况下都没有准确度下降的研究。参考实现随论文的补充材料一同提供。",
        "领域": "深度学习优化",
        "问题": "减少神经梯度传播的计算和内存负担",
        "动机": "神经梯度具有与权重和激活不同的统计特性，需要专门的方法来优化其处理",
        "方法": "提出两种基于神经梯度对数正态分布特性的闭式解析方法，分别优化梯度的浮点格式和比例，以及准确设置梯度剪枝的稀疏阈值",
        "关键词": [
            "神经梯度",
            "对数正态分布",
            "量化训练",
            "梯度稀疏化",
            "深度学习优化"
        ],
        "涉及的技术概念": {
            "神经梯度": "损失梯度相对于中间神经层输出的梯度，用于反向传播中的参数更新",
            "对数正态分布": "神经梯度的统计分布特性，为优化梯度处理提供了理论基础",
            "梯度稀疏化": "通过剪枝减少梯度中的非零元素，降低计算和内存需求的技术"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 547,
        "title": "Neural Jump Ordinary Differential Equations: Consistent Continuous-Time Prediction and Filtering",
        "html": "https://iclr.cc//virtual/2021/poster/3339",
        "abstract": "Combinations of neural ODEs with recurrent neural networks (RNN), like GRU-ODE-Bayes or ODE-RNN are well suited to model irregularly observed time series. While those models outperform existing discrete-time approaches, no theoretical guarantees for their predictive capabilities are available. Assuming that the irregularly-sampled time series data originates from a continuous stochastic process, the $L^2$-optimal online prediction is the conditional expectation given the currently available information. We introduce the Neural Jump ODE (NJ-ODE) that provides a data-driven approach to learn, continuously in time, the conditional expectation of a stochastic process. Our approach models the conditional expectation between two observations with a neural ODE and jumps whenever a new observation is made. We define a novel training framework, which allows us to prove theoretical guarantees for the first time. In particular, we show that the output of our model converges to the $L^2$-optimal prediction. This can be interpreted as solution to a special filtering problem. We provide experiments showing that the theoretical results also hold empirically. Moreover, we experimentally show that our model outperforms the baselines in more complex learning tasks and give comparisons on real-world datasets.",
        "conference": "ICLR",
        "中文标题": "神经跳跃常微分方程：一致的连续时间预测与滤波",
        "摘要翻译": "将神经常微分方程（ODE）与循环神经网络（RNN）结合，如GRU-ODE-Bayes或ODE-RNN，非常适合建模不规则观测的时间序列。虽然这些模型优于现有的离散时间方法，但它们的预测能力缺乏理论保证。假设不规则采样的时间序列数据源自连续随机过程，$L^2$-最优在线预测是在给定当前可用信息条件下的条件期望。我们引入了神经跳跃常微分方程（NJ-ODE），它提供了一种数据驱动的方法，以连续时间学习随机过程的条件期望。我们的方法在两个观测之间使用神经ODE建模条件期望，并在有新观测时跳跃。我们定义了一个新的训练框架，首次允许我们证明理论保证。特别是，我们展示了我们模型的输出收敛于$L^2$-最优预测。这可以被解释为一个特殊滤波问题的解决方案。我们提供的实验表明，理论结果在实证中也成立。此外，我们通过实验展示了我们的模型在更复杂的学习任务中优于基线，并在真实世界数据集上进行了比较。",
        "领域": "时间序列预测, 随机过程建模, 深度学习与微分方程结合",
        "问题": "如何在不规则观测的时间序列数据中，提供理论保证的连续时间预测与滤波",
        "动机": "解决现有结合神经ODE和RNN的模型在预测能力上缺乏理论保证的问题，提供一种能够学习随机过程条件期望的数据驱动方法",
        "方法": "引入神经跳跃常微分方程（NJ-ODE），在两个观测之间使用神经ODE建模条件期望，并在有新观测时跳跃，定义新的训练框架以证明理论保证",
        "关键词": [
            "神经跳跃常微分方程",
            "时间序列预测",
            "随机过程",
            "条件期望",
            "滤波问题"
        ],
        "涉及的技术概念": {
            "神经ODE": "用于建模两个观测之间的条件期望，提供连续时间预测",
            "条件期望": "作为$L^2$-最优在线预测的核心，模型学习的目标",
            "滤波问题": "模型输出收敛于$L^2$-最优预测，被视为解决特殊滤波问题的方案"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 548,
        "title": "Neural Learning of One-of-Many Solutions for Combinatorial Problems in Structured Output Spaces",
        "html": "https://iclr.cc//virtual/2021/poster/2941",
        "abstract": "Recent research has proposed neural architectures for solving combinatorial problems in structured output spaces. In many such problems, there may exist multiple solutions for a given input, e.g. a partially filled Sudoku puzzle may have many completions satisfying all constraints. Further, we are often interested in finding any 'one' of the possible solutions, without any preference between them. Existing approaches completely ignore this solution multiplicity. In this paper, we argue that being oblivious to the presence of multiple solutions can severely hamper their training ability. Our contribution is two-fold. First, we formally define the task of learning one-of-many solutions for combinatorial problems in structured output spaces, which is applicable for solving several problems of interest such as N-Queens, and Sudoku. Second, we present a generic learning framework that adapts an existing prediction network for a combinatorial problem to handle solution multiplicity. Our framework uses a selection module, whose goal is to dynamically determine, for every input, the solution that is most effective for training the network parameters in any given learning iteration. We propose an RL based approach to jointly train the selection module with the prediction network. Experiments on three different domains, and using two different prediction networks,  demonstrate that our framework significantly improves the accuracy in our setting, obtaining up to 21 pt gain over the baselines.\n",
        "conference": "ICLR",
        "中文标题": "结构化输出空间中组合问题多解之一的神经学习",
        "摘要翻译": "最近的研究提出了用于解决结构化输出空间中组合问题的神经架构。在许多此类问题中，对于给定的输入可能存在多个解，例如，部分填写的数独谜题可能有许多满足所有约束的完成方式。此外，我们通常对找到可能的解中的'一个'感兴趣，而不对它们之间有任何偏好。现有的方法完全忽略了解的多重性。在本文中，我们认为忽视多解的存在会严重削弱它们的训练能力。我们的贡献有两方面。首先，我们正式定义了在结构化输出空间中学习组合问题多解之一的任务，这适用于解决几个感兴趣的问题，如N皇后和数独。其次，我们提出了一个通用的学习框架，该框架调整了现有的组合问题预测网络以处理解的多重性。我们的框架使用了一个选择模块，其目标是动态地为每个输入确定在任何给定的学习迭代中最有效训练网络参数的解。我们提出了一种基于强化学习的方法来联合训练选择模块与预测网络。在三个不同领域的实验，以及使用两种不同的预测网络，证明了我们的框架在我们的设置中显著提高了准确性，比基线获得了高达21个百分点的增益。",
        "领域": "组合优化、结构化预测、强化学习",
        "问题": "解决结构化输出空间中组合问题存在多个解时，现有方法忽视解的多重性，影响训练效果的问题。",
        "动机": "认识到忽视多解的存在会严重削弱神经架构的训练能力，提出一种能够处理解的多重性的学习框架。",
        "方法": "提出了一个通用的学习框架，包括一个选择模块，用于动态选择最有效训练网络参数的解，并采用基于强化学习的方法联合训练选择模块与预测网络。",
        "关键词": [
            "组合优化",
            "结构化预测",
            "强化学习",
            "多解学习",
            "神经架构"
        ],
        "涉及的技术概念": {
            "结构化输出空间": "指输出具有特定结构或约束的问题空间，如数独或N皇后问题，其中解必须满足一系列预定义的规则。",
            "选择模块": "框架中的组件，负责动态选择对于当前训练迭代最有效的解，以优化网络参数。",
            "强化学习": "用于联合训练选择模块和预测网络的方法，通过奖励机制指导选择模块做出最优决策。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 549,
        "title": "Neurally Augmented ALISTA",
        "html": "https://iclr.cc//virtual/2021/poster/3179",
        "abstract": " It is well-established that many iterative sparse reconstruction algorithms can be unrolled to yield a learnable neural network for improved empirical performance. A prime example is learned ISTA (LISTA) where weights, step sizes and thresholds are learned from training data. Recently, Analytic LISTA (ALISTA) has been introduced, combining the strong empirical performance of a fully learned approach like LISTA, while retaining theoretical guarantees of classical compressed sensing algorithms and significantly reducing the number of parameters to learn. However, these parameters are trained to work in expectation, often leading to suboptimal reconstruction of individual targets.  In this work we therefore introduce Neurally Augmented ALISTA, in which an LSTM network is used to compute step sizes and thresholds individually for each target vector during reconstruction. This adaptive approach is theoretically motivated by revisiting the recovery guarantees of ALISTA. We show that our approach further improves empirical performance in sparse reconstruction, in particular outperforming existing algorithms by an increasing margin as the compression ratio becomes more challenging.",
        "conference": "ICLR",
        "中文标题": "神经增强的ALISTA",
        "摘要翻译": "众所周知，许多迭代稀疏重建算法可以被展开以产生一个可学习的神经网络，从而提高实证性能。一个典型的例子是学习型ISTA（LISTA），其中权重、步长和阈值是从训练数据中学习得到的。最近，分析型LISTA（ALISTA）被提出，它结合了像LISTA这样的完全学习方法强大的实证性能，同时保留了经典压缩感知算法的理论保证，并显著减少了需要学习的参数数量。然而，这些参数是针对期望值进行训练的，常常导致对单个目标的重建不够理想。因此，在这项工作中，我们引入了神经增强的ALISTA，其中使用LSTM网络在重建过程中为每个目标向量单独计算步长和阈值。这种自适应方法的理论动机是通过重新审视ALISTA的恢复保证。我们表明，我们的方法进一步提高了稀疏重建的实证性能，特别是在压缩比变得更加具有挑战性时，以越来越大的优势超越现有算法。",
        "领域": "稀疏重建、压缩感知、深度学习优化",
        "问题": "提高稀疏重建算法对单个目标的重建质量",
        "动机": "解决ALISTA算法在针对期望值训练参数时对单个目标重建不够理想的问题",
        "方法": "引入LSTM网络为每个目标向量单独计算步长和阈值，实现自适应重建",
        "关键词": [
            "稀疏重建",
            "ALISTA",
            "LSTM",
            "压缩感知",
            "深度学习"
        ],
        "涉及的技术概念": {
            "LISTA": "学习型ISTA，通过从训练数据中学习权重、步长和阈值来提高稀疏重建的实证性能",
            "ALISTA": "分析型LISTA，结合了学习型方法的实证性能和经典压缩感知算法的理论保证，减少了需要学习的参数数量",
            "LSTM网络": "用于在神经增强的ALISTA中为每个目标向量单独计算步长和阈值，实现自适应重建"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 550,
        "title": "Neural Mechanics: Symmetry and Broken Conservation Laws in Deep Learning Dynamics",
        "html": "https://iclr.cc//virtual/2021/poster/2715",
        "abstract": "Understanding the dynamics of neural network parameters during training is one of the key challenges in building a theoretical foundation for deep learning. A central obstacle is that the motion of a network in high-dimensional parameter space undergoes discrete finite steps along complex stochastic gradients derived from real-world datasets. We circumvent this obstacle through a unifying theoretical framework based on intrinsic symmetries embedded in a network's architecture that are present for any dataset. We show that any such symmetry imposes stringent geometric constraints on gradients and Hessians, leading to an associated conservation law in the continuous-time limit of stochastic gradient descent (SGD), akin to Noether's theorem in physics. We further show that finite learning rates used in practice can actually break these symmetry induced conservation laws. We apply tools from finite difference methods to derive modified gradient flow, a differential equation that better approximates the numerical trajectory taken by SGD at finite learning rates. We combine modified gradient flow with our framework of symmetries to derive exact integral expressions for the dynamics of certain parameter combinations. We empirically validate our analytic expressions for learning dynamics on VGG-16 trained on Tiny ImageNet. Overall, by exploiting symmetry, our work demonstrates that we can analytically describe the learning dynamics of various parameter combinations at finite learning rates and batch sizes for state of the art architectures trained on any dataset.",
        "conference": "ICLR",
        "中文标题": "神经力学：深度学习动力学中的对称性与守恒定律破缺",
        "摘要翻译": "理解神经网络参数在训练过程中的动态变化是构建深度学习理论基础的关键挑战之一。一个核心障碍是网络在高维参数空间中的运动沿着从现实世界数据集导出的复杂随机梯度进行离散的有限步骤。我们通过一个基于网络架构中固有对称性的统一理论框架绕过了这一障碍，这些对称性对于任何数据集都存在。我们表明，任何这样的对称性都对梯度和Hessian施加了严格的几何约束，导致在随机梯度下降（SGD）的连续时间极限中出现相关的守恒定律，类似于物理学中的诺特定理。我们进一步表明，实践中使用的有限学习率实际上可以打破这些由对称性诱导的守恒定律。我们应用有限差分方法的工具来推导修正梯度流，这是一个微分方程，能更好地近似SGD在有限学习率下采取的数值轨迹。我们将修正梯度流与我们的对称性框架结合起来，推导出某些参数组合动态的精确积分表达式。我们在VGG-16上对Tiny ImageNet的训练中实证验证了我们关于学习动态的解析表达式。总的来说，通过利用对称性，我们的工作表明，我们可以在有限学习率和批量大小下，对任何数据集上训练的最先进架构的各种参数组合的学习动态进行解析描述。",
        "领域": "深度学习理论、神经网络动力学、优化算法",
        "问题": "理解神经网络参数在训练过程中的动态变化及其理论基础",
        "动机": "构建深度学习的理论基础，特别是理解神经网络参数在训练过程中的动态变化",
        "方法": "基于网络架构中固有对称性的统一理论框架，结合修正梯度流和对称性框架，推导参数组合动态的精确积分表达式",
        "关键词": [
            "神经力学",
            "对称性",
            "守恒定律",
            "随机梯度下降",
            "修正梯度流"
        ],
        "涉及的技术概念": {
            "对称性": "网络架构中固有的对称性，对梯度和Hessian施加严格的几何约束，导致守恒定律的出现",
            "修正梯度流": "一个微分方程，能更好地近似随机梯度下降在有限学习率下采取的数值轨迹",
            "守恒定律": "在随机梯度下降的连续时间极限中出现的定律，类似于物理学中的诺特定理"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 551,
        "title": "Neural Networks for Learning Counterfactual G-Invariances from Single Environments",
        "html": "https://iclr.cc//virtual/2021/poster/3239",
        "abstract": "Despite —or maybe because of— their astonishing capacity to fit data, neural networks are believed to have difficulties extrapolating beyond training data distribution. This work shows that, for extrapolations based on finite transformation groups, a model’s inability to extrapolate is unrelated to its capacity. Rather, the shortcoming is inherited from a learning hypothesis: Examples not explicitly observed with infinitely many training examples have underspecified outcomes in the learner’s model. In order to endow neural networks with the ability to extrapolate over group transformations, we introduce a learning framework counterfactually-guided by the learning hypothesis that any group invariance to (known) transformation groups is mandatory even without evidence, unless the learner deems it inconsistent with the training data. Unlike existing invariance-driven methods for (counterfactual) extrapolations, this framework allows extrapolations from a single environment. Finally, we introduce sequence and image extrapolation tasks that validate our framework and showcase the shortcomings of traditional approaches.",
        "conference": "ICLR",
        "中文标题": "从单一环境中学习反事实G不变性的神经网络",
        "摘要翻译": "尽管——或者可能是因为——神经网络具有惊人的数据拟合能力，人们普遍认为它们在训练数据分布之外进行外推存在困难。这项工作表明，对于基于有限变换群的外推，模型的外推能力与其容量无关。相反，这一缺陷源自一个学习假设：在无限多训练样本中未明确观察到的示例在学习者的模型中具有未指定的结果。为了赋予神经网络在群变换上进行外推的能力，我们引入了一个反事实指导的学习框架，该框架基于学习假设，即任何对（已知）变换群的群不变性都是强制性的，即使没有证据，除非学习者认为它与训练数据不一致。与现有的（反事实）外推的不变性驱动方法不同，该框架允许从单一环境进行外推。最后，我们引入了序列和图像外推任务，验证了我们的框架并展示了传统方法的不足。",
        "领域": "深度学习理论、群不变性学习、外推方法",
        "问题": "神经网络在训练数据分布之外进行外推的困难",
        "动机": "探索神经网络外推能力的限制，并提出一种新的学习框架以克服这些限制",
        "方法": "引入一个反事实指导的学习框架，强制实施群不变性，即使在没有直接证据的情况下，除非与训练数据不一致",
        "关键词": [
            "群不变性",
            "反事实学习",
            "外推方法",
            "神经网络",
            "学习框架"
        ],
        "涉及的技术概念": {
            "群不变性": "在论文中用于描述模型对特定变换群的不变性，是外推能力的关键",
            "反事实学习": "一种学习框架，通过假设未观察到的数据应遵循的规则来指导模型学习",
            "外推方法": "论文提出的技术，使模型能够在训练数据分布之外进行预测"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 552,
        "title": "Neural networks with late-phase weights",
        "html": "https://iclr.cc//virtual/2021/poster/2930",
        "abstract": "The largely successful method of training neural networks is to learn their weights using some variant of stochastic gradient descent (SGD). Here, we show that the solutions found by SGD can be further improved by ensembling a subset of the weights in late stages of learning. At the end of learning, we obtain back a single model by taking a spatial average in weight space. To avoid incurring increased computational costs, we investigate a family of low-dimensional late-phase weight models which interact multiplicatively with the remaining parameters. Our results show that augmenting standard models with late-phase weights improves generalization in established benchmarks such as CIFAR-10/100, ImageNet and enwik8. These findings are complemented with a theoretical analysis of a noisy quadratic problem which provides a simplified picture of the late phases of neural network learning.",
        "conference": "ICLR",
        "中文标题": "具有晚期阶段权重的神经网络",
        "摘要翻译": "训练神经网络的主要成功方法是使用随机梯度下降（SGD）的某种变体来学习其权重。在这里，我们展示了通过在学习后期阶段集成一部分权重，可以进一步改进SGD找到的解决方案。在学习结束时，我们通过在权重空间中进行空间平均来获得单一模型。为了避免增加计算成本，我们研究了一系列低维晚期阶段权重模型，这些模型与剩余参数以乘法方式交互。我们的结果表明，在CIFAR-10/100、ImageNet和enwik8等已建立的基准测试中，通过增加标准模型的晚期阶段权重可以改善泛化能力。这些发现辅以一个关于噪声二次问题的理论分析，该分析提供了神经网络学习晚期阶段的简化图景。",
        "领域": "深度学习优化、神经网络训练、模型泛化",
        "问题": "如何通过改进神经网络训练过程中的权重更新策略来提升模型的泛化能力",
        "动机": "探索在神经网络训练的晚期阶段通过集成和优化权重来进一步提高模型性能的方法",
        "方法": "研究低维晚期阶段权重模型与剩余参数的乘法交互，以及在权重空间中进行空间平均以获得单一模型",
        "关键词": [
            "晚期阶段权重",
            "模型泛化",
            "随机梯度下降",
            "权重空间平均",
            "低维模型"
        ],
        "涉及的技术概念": {
            "随机梯度下降（SGD）": "用于训练神经网络的主要优化方法，通过迭代更新权重以最小化损失函数",
            "晚期阶段权重": "在训练后期阶段集成的权重，旨在进一步优化模型性能",
            "权重空间平均": "在训练结束时对权重进行空间平均，以获得单一且更稳定的模型"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 553,
        "title": "Neural ODE Processes",
        "html": "https://iclr.cc//virtual/2021/poster/2925",
        "abstract": "Neural Ordinary Differential Equations (NODEs) use a neural network to model the instantaneous rate of change in the state of a system. However, despite their apparent suitability for dynamics-governed time-series, NODEs present a few disadvantages. First, they are unable to adapt to incoming data-points, a fundamental requirement for real-time applications imposed by the natural direction of time. Second, time-series are often composed of a sparse set of measurements that could be explained by many possible underlying dynamics. NODEs do not capture this uncertainty. In contrast, Neural Processes (NPs) are a new class of stochastic processes providing uncertainty estimation and fast data-adaptation, but lack an explicit treatment of the flow of time. To address these problems, we introduce Neural ODE Processes (NDPs), a new class of stochastic processes determined by a distribution over Neural ODEs. By maintaining an adaptive data-dependent distribution over the underlying ODE, we show that our model can successfully capture the dynamics of low-dimensional systems from just a few data-points. At the same time, we demonstrate that NDPs scale up to challenging high-dimensional time-series with unknown latent dynamics such as rotating MNIST digits. ",
        "conference": "ICLR",
        "中文标题": "神经ODE过程",
        "摘要翻译": "神经普通微分方程（NODEs）使用神经网络来模拟系统状态的瞬时变化率。然而，尽管它们表面上适合由动力学主导的时间序列，NODEs存在一些缺点。首先，它们无法适应传入的数据点，这是实时应用对时间自然方向的基本要求。其次，时间序列通常由一组稀疏的测量组成，这些测量可能由许多可能的潜在动力学解释。NODEs没有捕捉到这种不确定性。相比之下，神经过程（NPs）是一类新的随机过程，提供了不确定性估计和快速数据适应，但缺乏对时间流动的明确处理。为了解决这些问题，我们引入了神经ODE过程（NDPs），这是一类由神经ODE分布决定的新的随机过程。通过维持对底层ODE的自适应数据依赖分布，我们展示了我们的模型可以从仅有的几个数据点成功捕捉低维系统的动力学。同时，我们证明了NDPs可以扩展到具有未知潜在动力学的挑战性高维时间序列，如旋转的MNIST数字。",
        "领域": "时间序列分析、随机过程建模、动态系统学习",
        "问题": "解决神经普通微分方程（NODEs）在实时应用中的适应性不足和无法捕捉时间序列潜在动力学不确定性的问题。",
        "动机": "结合神经过程（NPs）的不确定性估计和快速数据适应能力与神经普通微分方程（NODEs）对时间流动的处理，以更好地模拟动态系统。",
        "方法": "引入神经ODE过程（NDPs），通过维持对底层ODE的自适应数据依赖分布，捕捉系统动力学并适应高维时间序列。",
        "关键词": [
            "神经ODE过程",
            "随机过程",
            "时间序列分析",
            "动态系统学习",
            "不确定性估计"
        ],
        "涉及的技术概念": {
            "神经普通微分方程（NODEs）": "使用神经网络模拟系统状态的瞬时变化率，用于动态系统建模。",
            "神经过程（NPs）": "一类提供不确定性估计和快速数据适应的随机过程，用于处理时间序列数据。",
            "神经ODE过程（NDPs）": "结合NODEs和NPs的新方法，通过分布神经ODE来捕捉系统动力学并适应数据变化。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 554,
        "title": "Neural Pruning via Growing Regularization",
        "html": "https://iclr.cc//virtual/2021/poster/2526",
        "abstract": "Regularization has long been utilized to learn sparsity in deep neural network pruning. However, its role is mainly explored in the small penalty strength regime. In this work, we extend its application to a new scenario where the regularization grows large gradually to tackle two central problems of pruning: pruning schedule and weight importance scoring. (1) The former topic is newly brought up in this work, which we find critical to the pruning performance while receives little research attention. Specifically, we propose an L2 regularization variant with rising penalty factors and show it can bring significant accuracy gains compared with its one-shot counterpart, even when the same weights are removed. (2) The growing penalty scheme also brings us an approach to exploit the Hessian information for more accurate pruning without knowing their specific values, thus not bothered by the common Hessian approximation problems. Empirically, the proposed algorithms are easy to implement and scalable to large datasets and networks in both structured and unstructured pruning. Their effectiveness is demonstrated with modern deep neural networks on the CIFAR and ImageNet datasets, achieving competitive results compared to many state-of-the-art algorithms. Our code and trained models are publicly available at https://github.com/mingsun-tse/regularization-pruning.",
        "conference": "ICLR",
        "中文标题": "通过增长正则化进行神经剪枝",
        "摘要翻译": "正则化长期以来被用于学习深度神经网络剪枝中的稀疏性。然而，其作用主要在小惩罚强度范围内被探索。在这项工作中，我们将其应用扩展到一个新场景，其中正则化逐渐增大，以解决剪枝的两个核心问题：剪枝计划和权重重要性评分。（1）前者是本工作中新提出的，我们发现这对剪枝性能至关重要，但研究关注较少。具体来说，我们提出了一种惩罚因子递增的L2正则化变体，并显示即使移除相同的权重，与一次性剪枝相比，它能带来显著的准确性提升。（2）增长的惩罚方案还为我们提供了一种方法，可以利用Hessian信息进行更准确的剪枝，而无需知道其具体值，因此不受常见的Hessian近似问题困扰。实证上，所提出的算法易于实现，并可扩展到大型数据集和网络中的结构化和非结构化剪枝。它们的有效性在现代深度神经网络在CIFAR和ImageNet数据集上得到了证明，与许多最先进的算法相比，取得了竞争性的结果。我们的代码和训练模型可在https://github.com/mingsun-tse/regularization-pruning公开获取。",
        "领域": "深度神经网络剪枝",
        "问题": "解决剪枝计划和权重重要性评分的问题",
        "动机": "探索正则化在剪枝中的新应用，特别是在逐渐增大惩罚强度的场景下，以提高剪枝性能和准确性",
        "方法": "提出一种惩罚因子递增的L2正则化变体，利用Hessian信息进行更准确的剪枝",
        "关键词": [
            "神经剪枝",
            "增长正则化",
            "L2正则化",
            "Hessian信息",
            "剪枝计划"
        ],
        "涉及的技术概念": {
            "L2正则化": "用于学习深度神经网络剪枝中的稀疏性，本工作中提出惩罚因子递增的变体以提高剪枝性能",
            "Hessian信息": "用于更准确地进行剪枝，无需知道具体值，避免常见的Hessian近似问题",
            "剪枝计划": "本工作中新提出的概念，指剪枝过程中权重移除的顺序和策略，对剪枝性能至关重要"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 555,
        "title": "Neural representation and generation for RNA secondary structures",
        "html": "https://iclr.cc//virtual/2021/poster/3086",
        "abstract": "Our work is concerned with the generation and targeted design of RNA, a type of genetic macromolecule that can adopt complex structures which influence their cellular activities and functions. The design of large scale and complex biological structures spurs dedicated graph-based deep generative modeling techniques, which represents a key but underappreciated aspect of computational drug discovery. In this work, we investigate the principles behind representing and generating different RNA structural modalities, and propose a flexible framework to jointly embed and generate these molecular structures along with their sequence in a meaningful latent space. Equipped with a deep understanding of RNA molecular structures, our most sophisticated encoding and decoding methods operate on the molecular graph as well as the junction tree hierarchy, integrating strong inductive bias about RNA structural regularity and folding mechanism such that high structural validity, stability and diversity of generated RNAs are achieved. Also, we seek to adequately organize the latent space of RNA molecular embeddings with regard to the interaction with proteins, and targeted optimization is used to navigate in this latent space to search for desired novel RNA molecules.",
        "conference": "ICLR",
        "中文标题": "RNA二级结构的神经表示与生成",
        "摘要翻译": "我们的工作关注于RNA的生成与定向设计，RNA是一种可以形成复杂结构从而影响其细胞活动和功能的遗传大分子。大规模和复杂生物结构的设计推动了基于图的深度生成建模技术的发展，这是计算药物发现中一个关键但未被充分认识的方面。在这项工作中，我们研究了表示和生成不同RNA结构模态背后的原理，并提出了一个灵活的框架，在一个有意义的潜在空间中共同嵌入和生成这些分子结构及其序列。凭借对RNA分子结构的深入理解，我们最复杂的编码和解码方法在分子图和连接树层次上操作，整合了关于RNA结构规律性和折叠机制的强归纳偏差，从而实现了生成RNA的高结构有效性、稳定性和多样性。此外，我们寻求根据与蛋白质的相互作用充分组织RNA分子嵌入的潜在空间，并使用定向优化在这个潜在空间中导航以寻找所需的新型RNA分子。",
        "领域": "生物信息学、深度学习、药物发现",
        "问题": "如何有效地表示和生成具有高结构有效性、稳定性和多样性的RNA分子结构",
        "动机": "推动基于图的深度生成建模技术在计算药物发现中的应用，特别是在RNA分子设计和优化方面",
        "方法": "提出了一个灵活的框架，结合分子图和连接树层次的编码和解码方法，整合RNA结构规律性和折叠机制的强归纳偏差，以及使用定向优化在潜在空间中导航",
        "关键词": [
            "RNA二级结构",
            "深度生成模型",
            "分子图",
            "连接树",
            "潜在空间优化"
        ],
        "涉及的技术概念": {
            "分子图": "用于表示RNA分子结构，作为编码和解码的基础",
            "连接树层次": "用于捕捉RNA分子的高层次结构特征，增强模型的结构生成能力",
            "潜在空间优化": "用于在嵌入的潜在空间中定向搜索和优化，以发现具有特定性质的新型RNA分子"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 556,
        "title": "Neural Spatio-Temporal Point Processes",
        "html": "https://iclr.cc//virtual/2021/poster/2747",
        "abstract": "We propose a new class of parameterizations for spatio-temporal point processes which leverage Neural ODEs as a computational method and enable flexible, high-fidelity models of discrete events that are localized in continuous time and space. Central to our approach is a combination of continuous-time neural networks with two novel neural architectures, \\ie, Jump and Attentive Continuous-time Normalizing Flows. This approach allows us to learn complex distributions for both the spatial and temporal domain and to condition non-trivially on the observed event history. We validate our models on data sets from a wide variety of contexts such as seismology, epidemiology, urban mobility, and neuroscience.",
        "conference": "ICLR",
        "中文标题": "神经时空点过程",
        "摘要翻译": "我们提出了一类新的时空点过程参数化方法，该方法利用神经常微分方程作为计算手段，能够灵活、高保真地建模在连续时间和空间中局部化的离散事件。我们方法的核心是将连续时间神经网络与两种新颖的神经架构——即跳跃和注意力连续时间归一化流——相结合。这种方法使我们能够学习时空域的复杂分布，并在观察到的历史事件上进行非平凡的调节。我们在来自地震学、流行病学、城市流动性和神经科学等多种背景的数据集上验证了我们的模型。",
        "领域": "时空数据分析, 深度学习模型, 事件预测",
        "问题": "如何在连续时间和空间中灵活且高保真地建模离散事件",
        "动机": "开发一种能够学习复杂时空分布并基于历史事件进行预测的新方法",
        "方法": "结合连续时间神经网络与跳跃和注意力连续时间归一化流，利用神经常微分方程进行建模",
        "关键词": [
            "神经时空点过程",
            "神经常微分方程",
            "连续时间归一化流",
            "事件预测",
            "深度学习"
        ],
        "涉及的技术概念": {
            "神经常微分方程": "作为计算手段，用于灵活、高保真地建模离散事件",
            "连续时间归一化流": "用于学习时空域的复杂分布",
            "注意力机制": "在连续时间归一化流中用于增强模型对重要事件的关注"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 557,
        "title": "Neural Synthesis of Binaural Speech From Mono Audio",
        "html": "https://iclr.cc//virtual/2021/poster/2964",
        "abstract": "We present a neural rendering approach for binaural sound synthesis that can produce realistic and spatially accurate binaural sound in realtime. The network takes, as input, a single-channel audio source and synthesizes, as output, two-channel binaural sound, conditioned on the relative position and orientation of the listener with respect to the source. We investigate deficiencies of the l2-loss on raw waveforms in a theoretical analysis and introduce an improved loss that overcomes these limitations. In an empirical evaluation, we establish that our approach is the first to generate spatially accurate waveform outputs (as measured by real recordings) and outperforms existing approaches by a considerable margin, both quantitatively and in a perceptual study. Dataset and code are available online.",
        "conference": "ICLR",
        "中文标题": "从单声道音频神经合成双耳语音",
        "摘要翻译": "我们提出了一种用于双耳声音合成的神经渲染方法，能够实时产生真实且空间精确的双耳声音。该网络以单声道音频源作为输入，合成双声道双耳声音作为输出，条件是基于听者相对于声源的相对位置和方向。我们在理论分析中探讨了原始波形上l2损失的不足，并引入了一种改进的损失函数以克服这些限制。在实证评估中，我们证实了我们的方法是首个能够生成空间精确波形输出（以真实录音为测量标准）的方法，并且在定量和感知研究上均以较大优势超越了现有方法。数据集和代码已在线提供。",
        "领域": "语音合成, 音频处理, 神经网络应用",
        "问题": "如何从单声道音频实时合成真实且空间精确的双耳声音",
        "动机": "解决现有方法在双耳声音合成中空间精确度和实时性上的不足",
        "方法": "采用神经网络渲染方法，结合改进的损失函数，从单声道音频合成双耳声音",
        "关键词": [
            "双耳声音合成",
            "神经渲染",
            "实时音频处理",
            "空间音频",
            "损失函数优化"
        ],
        "涉及的技术概念": {
            "神经渲染": "用于从单声道音频合成双耳声音的技术，通过神经网络实现",
            "l2损失": "原始波形上的损失函数，用于衡量合成声音与真实声音的差异",
            "改进的损失函数": "克服了l2损失在双耳声音合成中的限制，提高了合成声音的空间精确度"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 558,
        "title": "Neural Thompson Sampling",
        "html": "https://iclr.cc//virtual/2021/poster/2714",
        "abstract": "Thompson Sampling (TS) is one of the most effective algorithms for solving contextual multi-armed bandit problems. In this paper, we propose a new algorithm, called Neural Thompson Sampling, which adapts deep neural networks for both exploration and exploitation. At the core of our algorithm is a novel posterior distribution of the reward, where its mean is the neural network approximator, and its variance is built upon the neural tangent features of the corresponding neural network. We prove that, provided the underlying reward function is bounded, the proposed algorithm is guaranteed to achieve a cumulative regret of $O(T^{1/2})$, which matches the regret of other contextual bandit algorithms in terms of total round number $T$. Experimental comparisons with other benchmark bandit algorithms on various data sets corroborate our theory.",
        "conference": "ICLR",
        "中文标题": "神经汤普森采样",
        "摘要翻译": "汤普森采样（TS）是解决上下文多臂老虎机问题最有效的算法之一。在本文中，我们提出了一种新算法，称为神经汤普森采样，该算法采用深度神经网络进行探索和利用。我们算法的核心是一个新颖的奖励后验分布，其均值是神经网络近似器，其方差建立在相应神经网络的神经切线特征上。我们证明，只要潜在的奖励函数是有界的，所提出的算法就能保证实现$O(T^{1/2})$的累积遗憾，这在总轮数$T$方面与其他上下文老虎机算法的遗憾相匹配。在各种数据集上与其他基准老虎机算法的实验比较证实了我们的理论。",
        "领域": "强化学习、多臂老虎机问题、深度学习",
        "问题": "如何在上下文多臂老虎机问题中有效地进行探索和利用",
        "动机": "提高在上下文多臂老虎机问题中的决策效率，通过结合深度神经网络来优化探索和利用的平衡",
        "方法": "提出神经汤普森采样算法，利用深度神经网络构建奖励的后验分布，其中均值由神经网络近似器表示，方差基于神经切线特征",
        "关键词": [
            "神经汤普森采样",
            "上下文多臂老虎机",
            "深度神经网络",
            "探索与利用",
            "累积遗憾"
        ],
        "涉及的技术概念": {
            "汤普森采样": "一种用于解决多臂老虎机问题的算法，通过随机采样来选择动作，以平衡探索和利用",
            "深度神经网络": "用于近似奖励函数，作为算法中奖励后验分布的均值部分",
            "神经切线特征": "用于构建奖励后验分布的方差部分，反映了神经网络在参数空间的局部线性行为"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 559,
        "title": "Neural Topic Model via Optimal Transport",
        "html": "https://iclr.cc//virtual/2021/poster/3340",
        "abstract": "Recently, Neural Topic Models (NTMs) inspired by variational autoencoders have obtained increasingly research interest due to their promising results on text analysis. However, it is usually hard for existing NTMs to achieve good document representation and coherent/diverse topics at the same time. Moreover, they often degrade their performance severely on short documents. The requirement of reparameterisation could also comprise their training quality and model flexibility. To address these shortcomings, we present a new neural topic model via the theory of optimal transport (OT). Specifically, we propose to learn the topic distribution of a document by directly minimising its OT distance to the document's word distributions. Importantly, the cost matrix of the OT distance models the weights between topics and words, which is constructed by the distances between topics and words in an embedding space. Our proposed model can be trained efficiently with a differentiable loss. Extensive experiments show that our framework significantly outperforms the state-of-the-art NTMs on discovering more coherent and diverse topics and deriving better document representations for both regular and short texts.",
        "conference": "ICLR",
        "中文标题": "基于最优传输的神经主题模型",
        "摘要翻译": "最近，受变分自编码器启发的神经主题模型（NTMs）因其在文本分析上的优异表现而获得了越来越多的研究关注。然而，现有的NTMs通常难以同时实现良好的文档表示和连贯/多样化的主题。此外，它们在短文本上的表现往往严重下降。重新参数化的要求也可能影响其训练质量和模型灵活性。为了解决这些不足，我们通过最优传输（OT）理论提出了一种新的神经主题模型。具体来说，我们建议通过直接最小化文档的主题分布与其词分布之间的OT距离来学习文档的主题分布。重要的是，OT距离的成本矩阵模拟了主题与词之间的权重，这是通过在嵌入空间中主题与词之间的距离构建的。我们提出的模型可以通过可微分的损失函数高效训练。大量实验表明，我们的框架在发现更连贯和多样化的主题以及为常规和短文本生成更好的文档表示方面显著优于最先进的NTMs。",
        "领域": "自然语言处理与视觉结合、文本挖掘、深度学习模型优化",
        "问题": "解决现有神经主题模型在文档表示和主题连贯性/多样性上的不足，以及在短文本上性能下降的问题。",
        "动机": "提高神经主题模型在文档表示和主题发现上的性能，特别是在短文本上的表现，同时提升模型的训练质量和灵活性。",
        "方法": "通过最优传输理论直接最小化文档主题分布与词分布之间的距离，利用嵌入空间中主题与词的距离构建成本矩阵，并通过可微分损失函数高效训练模型。",
        "关键词": [
            "神经主题模型",
            "最优传输",
            "文本分析",
            "短文本处理",
            "文档表示"
        ],
        "涉及的技术概念": {
            "最优传输（OT）": "用于直接最小化文档主题分布与词分布之间的距离，构建主题与词之间的权重。",
            "嵌入空间": "用于计算主题与词之间的距离，构建OT距离的成本矩阵。",
            "可微分损失函数": "用于高效训练模型，优化文档的主题分布学习。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 560,
        "title": "New Bounds For Distributed Mean Estimation and Variance Reduction",
        "html": "https://iclr.cc//virtual/2021/poster/3360",
        "abstract": " We consider the problem of distributed mean estimation (DME), in which $n$ machines are each given a local $d$-dimensional vector $\\mathbf x_v \\in \\mathbb R^d$, and must cooperate to estimate the mean of their inputs $\\mathbf \\mu = \\frac 1n\\sum_{v = 1}^n \\mathbf x_v$, while minimizing total communication cost. DME is a fundamental construct in distributed machine learning, and there has been considerable work on variants of this problem, especially in the context of distributed variance reduction for stochastic gradients in parallel SGD. Previous work typically assumes an upper bound on the norm of the input vectors, and achieves an error bound in terms of this norm. However, in many real applications, the input vectors are concentrated around the correct output $\\mathbf \\mu$, but $\\mathbf \\mu$ itself has large norm. In such cases, previous output error bounds perform poorly. \n            In this paper, we show that output error bounds need not depend on input norm. We provide a method of quantization which allows distributed mean estimation to be performed with solution quality dependent only on the distance between inputs, not on input norm, and show an analogous result for distributed variance reduction. The technique is based on a new connection with lattice theory. We also provide lower bounds showing that the communication to error trade-off of our algorithms is asymptotically optimal. As the lattices achieving optimal bounds under $\\ell_2$-norm can be computationally impractical, we also present an extension which leverages  easy-to-use cubic lattices, and is loose only up to a logarithmic factor in $d$. We show experimentally that our method yields practical improvements for common applications, relative to prior approaches.  ",
        "conference": "ICLR",
        "中文标题": "分布式均值估计与方差缩减的新界限",
        "摘要翻译": "我们考虑分布式均值估计（DME）问题，其中每台机器给定一个本地d维向量x_v ∈ R^d，必须合作估计它们输入的均值μ = (1/n)∑_{v=1}^n x_v，同时最小化总通信成本。DME是分布式机器学习中的基本构建块，已有大量工作研究此问题的变体，特别是在并行SGD中用于随机梯度分布式方差缩减的背景下。以往的工作通常假设输入向量的范数有一个上限，并根据这个范数实现误差界限。然而，在许多实际应用中，输入向量集中在正确输出μ附近，但μ本身的范数很大。在这种情况下，以往的输出误差界限表现不佳。本文中，我们展示了输出误差界限不需要依赖于输入范数。我们提供了一种量化方法，使得分布式均值估计的解决方案质量仅依赖于输入之间的距离，而不是输入范数，并展示了分布式方差缩减的类似结果。该技术基于与格理论的新联系。我们还提供了下界，显示我们算法的通信与误差权衡是渐进最优的。由于在ℓ2范数下实现最优界限的格可能在计算上不切实际，我们还提出了一个扩展，利用易于使用的立方格，并且仅在d中对数因子范围内宽松。我们通过实验表明，相对于先前的方法，我们的方法为常见应用带来了实际的改进。",
        "领域": "分布式机器学习, 均值估计, 方差缩减",
        "问题": "在输入向量集中在正确输出附近但输出本身范数较大的情况下，如何不依赖于输入范数实现分布式均值估计和方差缩减的误差界限。",
        "动机": "解决在输入向量集中在正确输出附近但输出本身范数较大的情况下，现有方法误差界限表现不佳的问题。",
        "方法": "提出一种量化方法，基于与格理论的新联系，使得解决方案质量仅依赖于输入之间的距离，而不是输入范数，并展示了分布式方差缩减的类似结果。",
        "关键词": [
            "分布式均值估计",
            "方差缩减",
            "格理论",
            "量化方法",
            "通信成本"
        ],
        "涉及的技术概念": {
            "分布式均值估计": "在分布式系统中合作估计输入向量的均值，同时最小化通信成本。",
            "方差缩减": "减少随机梯度下降中梯度的方差，以加速收敛。",
            "格理论": "用于开发新的量化方法，使得解决方案质量不依赖于输入范数。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 561,
        "title": "No Cost Likelihood Manipulation at Test Time for Making Better Mistakes in Deep Networks",
        "html": "https://iclr.cc//virtual/2021/poster/3041",
        "abstract": "There has been increasing interest in building deep hierarchy-aware classifiers that aim to quantify and reduce the severity of mistakes, and not just reduce the number of errors. The idea is to exploit the label hierarchy (e.g., the WordNet ontology) and consider graph distances as a proxy for mistake severity. Surprisingly, on examining mistake-severity distributions of the top-1 prediction, we find that current state-of-the-art hierarchy-aware deep classifiers do not always show practical improvement over the standard cross-entropy baseline in making better mistakes. The reason for the reduction in average mistake-severity can be attributed to the increase in low-severity mistakes, which may also explain the noticeable drop in their accuracy. To this end, we use the classical Conditional Risk Minimization (CRM) framework for hierarchy-aware classification. Given a cost matrix and a reliable estimate of likelihoods (obtained from a trained network), CRM simply amends mistakes at inference time; it needs no extra hyperparameters and requires adding just a few lines of code to the standard cross-entropy baseline. It significantly outperforms the state-of-the-art and consistently obtains large reductions in the average hierarchical distance of top-$k$ predictions across datasets, with very little loss in accuracy. CRM, because of its simplicity, can be used with any off-the-shelf trained model that provides reliable likelihood estimates.",
        "conference": "ICLR",
        "中文标题": "在测试时无成本地操纵似然性以使深度网络犯更好的错误",
        "摘要翻译": "近年来，越来越多的研究关注于构建深度层次感知分类器，这些分类器旨在量化和减少错误的严重性，而不仅仅是减少错误的数量。其思想是利用标签层次结构（例如WordNet本体论）并将图距离作为错误严重性的代理。令人惊讶的是，在检查top-1预测的错误严重性分布时，我们发现当前最先进的层次感知深度分类器在犯更好的错误方面并不总是显示出比标准交叉熵基线更实际的改进。平均错误严重性降低的原因可以归因于低严重性错误的增加，这也可能解释了它们准确性的显著下降。为此，我们使用经典的条件风险最小化（CRM）框架进行层次感知分类。给定一个成本矩阵和从训练网络获得的可靠似然估计，CRM在推理时简单地修正错误；它不需要额外的超参数，并且只需要在标准交叉熵基线中添加几行代码。它显著优于最先进的技术，并在数据集上一致地实现了top-$k$预测的平均层次距离的大幅减少，准确性损失非常小。由于其简单性，CRM可以与任何提供可靠似然估计的现成训练模型一起使用。",
        "领域": "层次感知分类、深度学习优化、错误分析",
        "问题": "如何在不显著降低准确性的情况下，减少深度分类器在层次结构标签上的错误严重性。",
        "动机": "当前层次感知深度分类器在减少错误严重性方面并不总是优于标准交叉熵基线，且可能导致准确性下降，因此需要一种更有效的方法来优化错误严重性。",
        "方法": "使用条件风险最小化（CRM）框架，在推理时根据成本矩阵和可靠似然估计修正错误，无需额外超参数或复杂修改。",
        "关键词": [
            "层次感知分类",
            "条件风险最小化",
            "错误严重性",
            "似然估计",
            "深度网络优化"
        ],
        "涉及的技术概念": {
            "层次感知分类": "利用标签层次结构（如WordNet）来量化和减少分类错误的严重性，而不仅仅是错误数量。",
            "条件风险最小化（CRM）": "一种在给定成本矩阵和可靠似然估计的情况下，在推理时修正错误的框架，旨在减少错误的平均严重性。",
            "似然估计": "从训练网络获得的输出概率，用于在CRM框架中评估和修正预测错误。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 562,
        "title": "Noise against noise: stochastic label noise helps combat inherent label noise",
        "html": "https://iclr.cc//virtual/2021/poster/2606",
        "abstract": "The noise in stochastic gradient descent (SGD) provides a crucial implicit regularization effect, previously studied in optimization by analyzing the dynamics of parameter updates. In this paper, we are interested in learning with noisy labels, where we have a collection of samples with potential mislabeling. We show that a previously rarely discussed SGD noise, induced by stochastic label noise (SLN), mitigates the effects of inherent label noise. In contrast, the common SGD noise directly applied to model parameters does not. We formalize the differences and connections of SGD noise variants, showing that SLN induces SGD noise dependent on the sharpness of output landscape and the confidence of output probability, which may help escape from sharp minima and prevent overconfidence. SLN not only improves generalization in its simplest form but also boosts popular robust training methods, including sample selection and label correction. Specifically, we present an enhanced algorithm by applying SLN to label correction. Our code is released.",
        "conference": "ICLR",
        "中文标题": "噪声对抗噪声：随机标签噪声有助于对抗固有标签噪声",
        "摘要翻译": "随机梯度下降（SGD）中的噪声提供了一种关键的隐式正则化效果，之前通过分析参数更新的动态在优化中进行了研究。在本文中，我们对带有噪声标签的学习感兴趣，其中我们有一组可能存在错误标记的样本。我们展示了一种之前很少讨论的SGD噪声，由随机标签噪声（SLN）引起，可以减轻固有标签噪声的影响。相比之下，直接应用于模型参数的常见SGD噪声则不能。我们形式化了SGD噪声变体的差异和联系，表明SLN诱导的SGD噪声依赖于输出景观的锐度和输出概率的置信度，这可能有助于逃离尖锐的最小值并防止过度自信。SLN不仅在其最简单的形式中提高了泛化能力，而且还增强了包括样本选择和标签校正在内的流行鲁棒训练方法。具体来说，我们通过将SLN应用于标签校正，提出了一种增强算法。我们的代码已发布。",
        "领域": "深度学习正则化、噪声标签学习、鲁棒训练方法",
        "问题": "如何在存在固有标签噪声的情况下，利用随机标签噪声（SLN）提高模型的泛化能力和鲁棒性。",
        "动机": "研究动机是探索和利用SGD中的随机标签噪声（SLN）作为一种隐式正则化手段，以减轻固有标签噪声对模型训练的影响，并提高模型的泛化能力。",
        "方法": "通过分析SGD噪声变体的差异和联系，特别是SLN诱导的噪声，研究其对输出景观锐度和输出概率置信度的依赖性，提出将SLN应用于标签校正的增强算法。",
        "关键词": [
            "随机标签噪声",
            "隐式正则化",
            "鲁棒训练",
            "标签校正",
            "泛化能力"
        ],
        "涉及的技术概念": {
            "随机梯度下降（SGD）": "一种优化算法，用于最小化损失函数，其噪声被认为具有隐式正则化效果。",
            "随机标签噪声（SLN）": "由随机选择的标签引起的SGD噪声，能够减轻固有标签噪声的影响。",
            "标签校正": "一种鲁棒训练方法，通过修正错误的标签来提高模型的训练效果和泛化能力。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 563,
        "title": "Noise or Signal: The Role of Image Backgrounds in Object Recognition",
        "html": "https://iclr.cc//virtual/2021/poster/2857",
        "abstract": "We assess the tendency of state-of-the-art object recognition models to depend on signals from image backgrounds. We create a toolkit for disentangling foreground and background signal on ImageNet images, and find that (a) models can achieve non-trivial accuracy by relying on the background alone, (b) models often misclassify images even in the presence of correctly classified foregrounds--up to 88% of the time with adversarially chosen backgrounds, and (c) more accurate models tend to depend on backgrounds less. Our analysis of backgrounds brings us closer to understanding which correlations machine learning models use, and how they determine models' out of distribution performance.\n",
        "conference": "ICLR",
        "中文标题": "噪声还是信号：图像背景在物体识别中的作用",
        "摘要翻译": "我们评估了最先进的物体识别模型依赖图像背景信号的倾向。我们创建了一个工具包，用于在ImageNet图像上分离前景和背景信号，并发现（a）模型仅依靠背景就能达到非平凡的准确率，（b）模型经常在正确分类的前景存在的情况下错误分类图像——在对抗性选择的背景下，错误率高达88%，（c）更准确的模型倾向于较少依赖背景。我们对背景的分析使我们更接近于理解机器学习模型使用哪些相关性，以及它们如何决定模型的分布外性能。",
        "领域": "物体识别、深度学习模型分析、对抗性机器学习",
        "问题": "评估物体识别模型对图像背景信号的依赖程度及其对模型性能的影响",
        "动机": "理解物体识别模型在分类时对背景信号的依赖程度，以及这种依赖如何影响模型的准确性和鲁棒性",
        "方法": "创建工具包分离图像的前景和背景信号，通过实验分析模型在不同背景条件下的表现",
        "关键词": [
            "物体识别",
            "背景信号",
            "对抗性背景",
            "模型分析",
            "分布外性能"
        ],
        "涉及的技术概念": {
            "前景和背景信号分离": "用于分析模型对背景信号的依赖程度，通过技术手段分离图像的前景和背景",
            "对抗性选择的背景": "通过特定方法选择的背景，用于测试模型在极端条件下的表现和鲁棒性",
            "分布外性能": "指模型在训练数据分布之外的测试数据上的表现，用于评估模型的泛化能力"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 564,
        "title": "No MCMC for me: Amortized sampling for fast and stable training of energy-based models",
        "html": "https://iclr.cc//virtual/2021/poster/2597",
        "abstract": "Energy-Based Models (EBMs) present a flexible and appealing way to represent uncertainty. Despite recent advances, training EBMs on high-dimensional data remains a challenging problem as the state-of-the-art approaches are costly, unstable, and require considerable tuning and domain expertise to apply successfully. In this work, we present a simple method for training EBMs at scale which uses an entropy-regularized generator to amortize the MCMC sampling typically used in EBM training. We improve upon prior MCMC-based entropy regularization methods with a fast variational approximation. We demonstrate the effectiveness of our approach by using it to train tractable likelihood models. Next, we apply our estimator to the recently proposed Joint Energy Model (JEM), where we match the original performance with faster and stable training. This allows us to extend JEM models to semi-supervised classification on tabular data from a variety of continuous domains.",
        "conference": "ICLR",
        "中文标题": "无需MCMC：通过摊销采样实现基于能量模型的快速稳定训练",
        "摘要翻译": "基于能量的模型（EBMs）提供了一种灵活且吸引人的不确定性表示方法。尽管最近有所进展，但在高维数据上训练EBMs仍然是一个具有挑战性的问题，因为最先进的方法成本高昂、不稳定，并且需要大量的调整和领域专业知识才能成功应用。在这项工作中，我们提出了一种简单的方法，用于大规模训练EBMs，该方法使用熵正则化生成器来摊销通常用于EBM训练的MCMC采样。我们通过快速的变分近似改进了先前基于MCMC的熵正则化方法。我们通过使用它来训练可处理的似然模型来证明我们方法的有效性。接着，我们将我们的估计器应用于最近提出的联合能量模型（JEM），在那里我们以更快和更稳定的训练匹配了原始性能。这使我们能够将JEM模型扩展到来自各种连续领域的表格数据的半监督分类。",
        "领域": "生成模型、半监督学习、变分方法",
        "问题": "解决在高维数据上训练基于能量模型（EBMs）时的高成本、不稳定性和需要大量调整的问题",
        "动机": "为了提供一种更高效、更稳定的方法来训练EBMs，减少对MCMC采样的依赖，降低训练成本和提高模型性能",
        "方法": "使用熵正则化生成器摊销MCMC采样，并通过快速的变分近似改进熵正则化方法",
        "关键词": [
            "基于能量的模型",
            "熵正则化",
            "变分近似",
            "半监督分类",
            "摊销采样"
        ],
        "涉及的技术概念": {
            "基于能量的模型（EBMs）": "提供了一种灵活且吸引人的不确定性表示方法，用于捕捉数据的概率分布",
            "熵正则化生成器": "用于摊销MCMC采样，减少训练过程中的计算成本和提高稳定性",
            "变分近似": "一种快速近似方法，用于改进熵正则化，提高训练效率和模型性能"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 565,
        "title": "Non-asymptotic Confidence Intervals of Off-policy Evaluation:  Primal and Dual Bounds ",
        "html": "https://iclr.cc//virtual/2021/poster/2875",
        "abstract": "Off-policy evaluation (OPE) is the task of estimating the expected reward of a given policy based on offline data previously collected under different policies. Therefore, OPE is a key step in applying reinforcement learning to real-world domains such as medical treatment, where interactive data collection is expensive or even unsafe. As the observed data tends to be noisy and limited, it is essential to provide rigorous  uncertainty quantification, not just a point estimation, when applying OPE to make high stakes decisions. This work considers the problem of constructing non-asymptotic confidence intervals in infinite-horizon  off-policy evaluation, which remains a challenging open question. We develop a practical algorithm through a primal-dual optimization-based approach, which leverages the kernel Bellman loss (KBL) of Feng et al. 2019 and a new  martingale concentration inequality of KBL applicable to time-dependent data with unknown mixing conditions. Our algorithm makes  minimum assumptions on the data and the function class of the Q-function,  and works for the behavior-agnostic settings where the data is collected under a mix of arbitrary unknown behavior policies.  We present empirical results that clearly demonstrate the advantages of our approach over existing methods.\n",
        "conference": "ICLR",
        "success": true,
        "中文标题": "非策略评估的非渐近置信区间：原始与对偶边界",
        "摘要翻译": "非策略评估（OPE）的任务是基于先前在不同策略下收集的离线数据来估计给定策略的预期奖励。因此，OPE是将强化学习应用于现实世界领域（如医疗治疗）的关键步骤，在这些领域中，交互式数据收集既昂贵又不安全。由于观察到的数据往往是嘈杂和有限的，在应用OPE做出高风险决策时，提供严格的不确定性量化而不仅仅是点估计至关重要。这项工作考虑了在无限视野非策略评估中构建非渐近置信区间的问题，这仍然是一个具有挑战性的开放性问题。我们通过一种基于原始-对偶优化的方法开发了一个实用算法，该方法利用了Feng等人2019年的核贝尔曼损失（KBL）和适用于具有未知混合条件的时间依赖数据的KBL新鞅集中不等式。我们的算法对数据和Q函数的函数类做出最小假设，并适用于行为不可知设置，其中数据是在任意未知行为策略的混合下收集的。我们提供的实证结果清楚地展示了我们的方法相对于现有方法的优势。",
        "领域": "强化学习",
        "问题": "在无限视野非策略评估中构建非渐近置信区间",
        "动机": "为高风险决策提供严格的不确定性量化，而不仅仅是点估计",
        "方法": "基于原始-对偶优化的方法，利用核贝尔曼损失（KBL）和新鞅集中不等式",
        "关键词": [
            "非策略评估",
            "置信区间",
            "强化学习",
            "核贝尔曼损失",
            "原始-对偶优化"
        ],
        "涉及的技术概念": {
            "核贝尔曼损失（KBL）": "用于评估策略性能的损失函数，基于核方法",
            "鞅集中不等式": "用于处理时间依赖数据，提供统计保证",
            "原始-对偶优化": "用于构建置信区间的优化框架，平衡原始问题和对偶问题"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 566,
        "title": "Nonseparable Symplectic Neural Networks",
        "html": "https://iclr.cc//virtual/2021/poster/3136",
        "abstract": "Predicting the behaviors of Hamiltonian systems has been drawing increasing attention in scientific machine learning. However, the vast majority of the literature was focused on predicting separable Hamiltonian systems with their kinematic and potential energy terms being explicitly decoupled, while building data-driven paradigms to predict nonseparable Hamiltonian systems that are ubiquitous in fluid dynamics and quantum mechanics were rarely explored. The main computational challenge lies in the effective embedding of symplectic priors to describe the inherently coupled evolution of position and momentum, which typically exhibits intricate dynamics. To solve the problem, we propose a novel neural network architecture, Nonseparable Symplectic Neural Networks (NSSNNs), to uncover and embed the symplectic structure of a nonseparable Hamiltonian system from limited observation data. The enabling mechanics of our approach is an augmented symplectic time integrator to decouple the position and momentum energy terms and facilitate their evolution. We demonstrated the efficacy and versatility of our method by predicting a wide range of Hamiltonian systems, both separable and nonseparable, including chaotic vortical flows. We showed the unique computational merits of our approach to yield long-term, accurate, and robust predictions for large-scale Hamiltonian systems by rigorously enforcing symplectomorphism.",
        "conference": "ICLR",
        "中文标题": "不可分离辛神经网络",
        "摘要翻译": "预测哈密顿系统的行为在科学机器学习中引起了越来越多的关注。然而，绝大多数文献都集中在预测可分离的哈密顿系统上，这些系统的动能和势能项被明确解耦，而构建数据驱动范式来预测在流体动力学和量子力学中普遍存在的不可分离哈密顿系统却鲜有探索。主要的计算挑战在于有效嵌入辛先验来描述位置和动量固有的耦合演化，这通常表现出复杂的动力学。为了解决这个问题，我们提出了一种新颖的神经网络架构——不可分离辛神经网络（NSSNNs），以从有限的观测数据中发现并嵌入不可分离哈密顿系统的辛结构。我们方法的关键机制是一个增强的辛时间积分器，用于解耦位置和动量能量项并促进它们的演化。我们通过预测包括混沌涡流在内的广泛哈密顿系统（可分离和不可分离）来证明了我们方法的有效性和多功能性。我们展示了我们的方法在严格强制辛同胚的情况下，为大规模哈密顿系统产生长期、准确和鲁棒的预测的独特计算优势。",
        "领域": "科学机器学习、流体动力学模拟、量子力学预测",
        "问题": "如何有效预测不可分离哈密顿系统的行为",
        "动机": "解决在流体动力学和量子力学中普遍存在的不可分离哈密顿系统预测的挑战",
        "方法": "提出不可分离辛神经网络（NSSNNs）架构，利用增强的辛时间积分器解耦位置和动量能量项",
        "关键词": [
            "不可分离哈密顿系统",
            "辛神经网络",
            "科学机器学习",
            "流体动力学",
            "量子力学"
        ],
        "涉及的技术概念": {
            "辛先验": "用于描述位置和动量固有耦合演化的先验知识",
            "辛时间积分器": "增强的积分器，用于解耦位置和动量能量项并促进它们的演化",
            "辛同胚": "严格强制的方法，确保大规模哈密顿系统长期、准确和鲁棒的预测"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 567,
        "title": "not-MIWAE: Deep Generative Modelling with Missing not at Random Data",
        "html": "https://iclr.cc//virtual/2021/poster/2776",
        "abstract": "When a missing process depends on the missing values themselves, it needs to be explicitly modelled and taken into account while doing likelihood-based inference. We present an approach for building and fitting deep latent variable models (DLVMs) in cases where the missing process is dependent on the missing data. Specifically, a deep neural network enables us to flexibly model the conditional distribution of the missingness pattern given the data. This allows for incorporating prior information about the type of missingness (e.g.~self-censoring) into the model. Our inference technique, based on importance-weighted variational inference, involves maximising a lower bound of the joint likelihood. Stochastic gradients of the bound are obtained by using the reparameterisation trick both in latent space and data space. We show on various kinds of data sets and missingness patterns that explicitly modelling the missing process can be invaluable.",
        "conference": "ICLR",
        "中文标题": "非MIWAE：基于非随机缺失数据的深度生成建模",
        "摘要翻译": "当缺失过程依赖于缺失值本身时，在进行基于似然的推断时需要明确建模并考虑这一过程。我们提出了一种在缺失过程依赖于缺失数据的情况下构建和拟合深度潜变量模型（DLVMs）的方法。具体而言，深度神经网络使我们能够灵活地建模给定数据下缺失模式的条件分布。这允许将关于缺失类型（例如自我审查）的先验信息纳入模型中。我们的推断技术基于重要性加权变分推断，涉及联合似然下界的最大化。通过潜在空间和数据空间中的重新参数化技巧获得边界的随机梯度。我们在各种数据集和缺失模式上展示，明确建模缺失过程可能是非常宝贵的。",
        "领域": "缺失数据处理、深度生成模型、变分推断",
        "问题": "在缺失数据依赖于缺失值本身的情况下，如何构建和拟合深度潜变量模型。",
        "动机": "解决在缺失过程依赖于缺失数据时，传统方法无法有效建模和推断的问题。",
        "方法": "使用深度神经网络灵活建模缺失模式的条件分布，并基于重要性加权变分推断最大化联合似然下界。",
        "关键词": [
            "非随机缺失数据",
            "深度潜变量模型",
            "重要性加权变分推断",
            "重新参数化技巧",
            "缺失过程建模"
        ],
        "涉及的技术概念": {
            "深度潜变量模型（DLVMs）": "用于在缺失数据情况下进行复杂数据建模的深度生成模型。",
            "重要性加权变分推断": "一种变分推断方法，通过重要性采样提高推断的准确性。",
            "重新参数化技巧": "在变分自编码器中用于使随机变量可微分的技术，便于梯度下降优化。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 568,
        "title": "NOVAS: Non-convex Optimization via Adaptive Stochastic Search for End-to-end Learning and Control",
        "html": "https://iclr.cc//virtual/2021/poster/3070",
        "abstract": "In this work we propose the use of adaptive stochastic search as a building block for general, non-convex optimization operations within deep neural network architectures. Specifically, for an objective function located at some layer in the network and parameterized by some network parameters, we employ adaptive stochastic search to perform optimization over its output. This operation is differentiable and does not obstruct the passing of gradients during backpropagation, thus enabling us to incorporate it as a component in end-to-end learning. We study the proposed optimization module's properties and benchmark it against two existing alternatives on a synthetic energy-based structured prediction task, and further showcase its use in stochastic optimal control applications.",
        "conference": "ICLR",
        "中文标题": "NOVAS：通过自适应随机搜索进行非凸优化以实现端到端学习与控制",
        "摘要翻译": "在这项工作中，我们提出使用自适应随机搜索作为深度神经网络架构中一般非凸优化操作的构建块。具体来说，对于位于网络中某一层并由某些网络参数化的目标函数，我们采用自适应随机搜索来对其输出进行优化。这一操作是可微的，并且不会阻碍反向传播过程中梯度的传递，从而使我们能够将其作为端到端学习的一个组成部分。我们研究了所提出的优化模块的特性，并在一个基于能量的结构化预测合成任务上对其与两种现有替代方案进行了基准测试，并进一步展示了其在随机最优控制应用中的使用。",
        "领域": "深度学习优化方法, 结构化预测, 随机最优控制",
        "问题": "在深度神经网络中实现非凸优化操作的端到端学习",
        "动机": "探索一种能够在深度神经网络中有效进行非凸优化，同时不影响梯度传递的方法，以支持更广泛的端到端学习应用。",
        "方法": "采用自适应随机搜索作为网络中的优化模块，确保操作的微分性和梯度传递的顺畅性。",
        "关键词": [
            "自适应随机搜索",
            "非凸优化",
            "端到端学习",
            "结构化预测",
            "随机最优控制"
        ],
        "涉及的技术概念": {
            "自适应随机搜索": "用于在深度神经网络中进行非凸优化的技术，能够适应性地调整搜索策略以提高优化效率。",
            "非凸优化": "在目标函数非凸的情况下进行的优化操作，本研究中通过自适应随机搜索实现。",
            "端到端学习": "一种学习范式，通过将优化模块集成到神经网络中，实现从输入到输出的直接学习。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 569,
        "title": "Off-Dynamics Reinforcement Learning: Training for Transfer with Domain Classifiers",
        "html": "https://iclr.cc//virtual/2021/poster/2818",
        "abstract": "We propose a simple, practical, and intuitive approach for domain adaptation in reinforcement learning. Our approach stems from the idea that the agent's experience in the source domain should look similar to its experience in the target domain. Building off of a probabilistic view of RL, we achieve this goal by compensating for the difference in dynamics by modifying the reward function. This modified reward function is simple to estimate by learning auxiliary classifiers that distinguish source-domain transitions from target-domain transitions. Intuitively, the agent is penalized for transitions that would indicate that the agent is interacting with the source domain, rather than the target domain. Formally, we prove that applying our method in the source domain is guaranteed to obtain a near-optimal policy for the target domain, provided that the source and target domains satisfy a lightweight assumption. Our approach is applicable to domains with continuous states and actions and does not require learning an explicit model of the dynamics. On discrete and continuous control tasks, we illustrate the mechanics of our approach and demonstrate its scalability to high-dimensional~tasks.",
        "conference": "ICLR",
        "中文标题": "非动态强化学习：利用领域分类器进行迁移训练",
        "摘要翻译": "我们提出了一种简单、实用且直观的强化学习领域适应方法。我们的方法源于这样一种理念：智能体在源领域的经验应与其在目标领域的经验相似。基于强化学习的概率视角，我们通过修改奖励函数来补偿动态差异，从而实现这一目标。这种修改后的奖励函数通过学习区分源领域转换与目标领域转换的辅助分类器来简单估计。直观地说，智能体会因为那些表明其正在与源领域而非目标领域交互的转换而受到惩罚。形式上，我们证明了在源领域应用我们的方法可以保证为目标领域获得一个接近最优的策略，前提是源领域和目标领域满足一个轻量级的假设。我们的方法适用于具有连续状态和动作的领域，并且不需要学习动态的显式模型。在离散和连续控制任务上，我们展示了我们方法的机制，并证明了其在高维任务中的可扩展性。",
        "领域": "强化学习、领域适应、连续控制",
        "问题": "解决强化学习中的领域适应问题，即在源领域训练的智能体如何有效地迁移到目标领域。",
        "动机": "研究动机是为了让智能体在源领域的经验能够有效地迁移到目标领域，从而减少在目标领域重新训练的需要。",
        "方法": "通过修改奖励函数来补偿源领域和目标领域之间的动态差异，利用辅助分类器区分不同领域的转换，从而指导智能体学习。",
        "关键词": [
            "强化学习",
            "领域适应",
            "奖励修改",
            "连续控制",
            "高维任务"
        ],
        "涉及的技术概念": {
            "领域适应": "在强化学习中，指智能体将从源领域学到的知识迁移到目标领域的能力。",
            "奖励修改": "通过调整奖励函数来补偿不同领域间的动态差异，促进知识迁移。",
            "辅助分类器": "用于区分源领域和目标领域的转换，帮助智能体识别和适应目标领域的动态特性。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 570,
        "title": "Offline Model-Based Optimization via Normalized Maximum Likelihood Estimation",
        "html": "https://iclr.cc//virtual/2021/poster/2793",
        "abstract": "In this work we consider data-driven optimization problems where one must maximize a function given only queries at a fixed set of points. This problem setting emerges in many domains where function evaluation is a complex and expensive process, such as in the design of materials, vehicles, or neural network architectures. Because the available data typically only covers a small manifold of the possible space of inputs, a principal challenge is to be able to construct algorithms that can reason about uncertainty and out-of-distribution values, since a naive optimizer can easily exploit an estimated model to return adversarial inputs. We propose to tackle the MBO problem by leveraging the normalized maximum-likelihood (NML) estimator, which provides a principled approach to handling uncertainty and out-of-distribution inputs. While in the standard formulation NML is intractable, we propose a tractable approximation that allows us to scale our method to high-capacity neural network models. We demonstrate that our method can effectively optimize high-dimensional design problems in a variety of disciplines such as chemistry, biology, and materials engineering.",
        "conference": "ICLR",
        "中文标题": "基于归一化最大似然估计的离线模型优化",
        "摘要翻译": "在这项工作中，我们考虑了数据驱动的优化问题，其中必须仅通过在一组固定点上的查询来最大化一个函数。这一问题设置在多个领域中出现，其中函数评估是一个复杂且昂贵的过程，例如在材料、车辆或神经网络架构的设计中。由于可用数据通常仅覆盖可能输入空间的一小部分，一个主要挑战是能够构建能够推理不确定性和分布外值的算法，因为一个简单的优化器可以轻易利用估计模型返回对抗性输入。我们提出通过利用归一化最大似然（NML）估计器来解决MBO问题，这为处理不确定性和分布外输入提供了一种原则性方法。虽然在标准公式中NML是难以处理的，但我们提出了一种可处理的近似方法，使我们能够将我们的方法扩展到高容量神经网络模型。我们证明了我们的方法可以有效地优化化学、生物学和材料工程等多个学科中的高维设计问题。",
        "领域": "神经网络架构优化、材料设计优化、生物工程优化",
        "问题": "在数据有限且函数评估成本高的条件下，如何有效优化高维设计问题",
        "动机": "解决在数据覆盖有限的情况下，优化算法容易受到对抗性输入影响的问题",
        "方法": "利用归一化最大似然估计器处理不确定性和分布外输入，并提出其可处理的近似方法以适应高容量神经网络模型",
        "关键词": [
            "归一化最大似然估计",
            "高维优化",
            "神经网络模型",
            "材料设计",
            "生物工程"
        ],
        "涉及的技术概念": {
            "归一化最大似然估计": "用于处理不确定性和分布外输入的原则性方法",
            "高容量神经网络模型": "能够处理复杂和高维数据的模型",
            "对抗性输入": "优化器可能利用估计模型生成的、可能导致模型性能下降的输入"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 571,
        "title": "On Data-Augmentation and Consistency-Based Semi-Supervised Learning",
        "html": "https://iclr.cc//virtual/2021/poster/3176",
        "abstract": "Recently proposed consistency-based Semi-Supervised Learning (SSL) methods such as the Pi-model, temporal ensembling, the mean teacher, or the virtual adversarial training, achieve the state of the art results in several SSL tasks. These methods can typically reach performances that are comparable to their fully supervised counterparts while using only a fraction of labelled examples. Despite these methodological advances, the understanding of these methods is still relatively limited. To make progress, we analyse (variations of) the Pi-model in settings where analytically tractable results can be obtained. We establish links with Manifold Tangent Classifiers and demonstrate that the quality of the perturbations is key to obtaining reasonable SSL performances. Furthermore, we propose a simple extension of the Hidden Manifold Model that naturally incorporates data-augmentation schemes and offers a tractable framework for understanding SSL methods.",
        "conference": "ICLR",
        "中文标题": "论数据增强与基于一致性的半监督学习",
        "摘要翻译": "最近提出的基于一致性的半监督学习（SSL）方法，如Pi模型、时间集成、平均教师或虚拟对抗训练，在多个SSL任务中取得了最先进的结果。这些方法通常仅使用一小部分标记示例就能达到与全监督方法相媲美的性能。尽管方法学上取得了这些进展，对这些方法的理解仍然相对有限。为了取得进展，我们在可分析处理的环境中分析了Pi模型（及其变体）。我们建立了与流形切线分类器的联系，并证明了扰动的质量对于获得合理的SSL性能至关重要。此外，我们提出了一个简单的隐藏流形模型扩展，该扩展自然地融入了数据增强方案，并提供了一个可处理的框架来理解SSL方法。",
        "领域": "半监督学习、数据增强、模型泛化",
        "问题": "如何提高半监督学习方法的性能和理解其工作机制",
        "动机": "尽管基于一致性的半监督学习方法在性能上取得了显著成果，但其工作机制的理解仍然有限，需要更深入的分析和理论支持",
        "方法": "分析Pi模型及其变体，建立与流形切线分类器的联系，提出隐藏流形模型的扩展以融入数据增强方案",
        "关键词": [
            "半监督学习",
            "数据增强",
            "一致性训练",
            "Pi模型",
            "隐藏流形模型"
        ],
        "涉及的技术概念": {
            "Pi模型": "一种基于一致性的半监督学习方法，通过在不同时间点对同一输入施加扰动并最小化预测差异来训练模型",
            "流形切线分类器": "一种分类器，假设数据位于低维流形上，通过利用流形的几何性质来提高分类性能",
            "隐藏流形模型": "一个理论框架，用于模拟和理解数据在潜在空间中的分布，以及如何通过数据增强和半监督学习方法来提高模型性能"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 572,
        "title": "On Dyadic Fairness: Exploring and Mitigating Bias in Graph Connections",
        "html": "https://iclr.cc//virtual/2021/poster/3241",
        "abstract": "Disparate impact has raised serious concerns in machine learning applications and its societal impacts. In response to the need of mitigating discrimination, fairness has been regarded as a crucial property in algorithmic design. In this work, we study the problem of disparate impact on graph-structured data. Specifically, we focus on dyadic fairness, which articulates a fairness concept that a predictive relationship between two instances should be independent of the sensitive attributes. Based on this, we theoretically relate the graph connections to dyadic fairness on link predictive scores in learning graph neural networks, and reveal that regulating weights on existing edges in a graph contributes to dyadic fairness conditionally. Subsequently, we propose our algorithm, \\textbf{FairAdj}, to empirically learn a fair adjacency matrix with proper graph structural constraints for fair link prediction, and in the meanwhile preserve predictive accuracy as much as possible. Empirical validation demonstrates that our method delivers effective dyadic fairness in terms of various statistics, and at the same time enjoys a favorable fairness-utility tradeoff.",
        "conference": "ICLR",
        "中文标题": "关于二元公平性：探索并缓解图连接中的偏见",
        "摘要翻译": "差异影响在机器学习应用及其社会影响中引发了严重关切。为应对减轻歧视的需求，公平性被视为算法设计中的一个关键属性。在这项工作中，我们研究了图结构数据上的差异影响问题。具体而言，我们专注于二元公平性，这一概念阐述了两个实例之间的预测关系应独立于敏感属性的公平性原则。基于此，我们从理论上将图连接与学习图神经网络中的链接预测分数的二元公平性联系起来，并揭示了在图中调节现有边的权重有条件地促进二元公平性。随后，我们提出了我们的算法FairAdj，通过适当的图结构约束经验性地学习一个公平的邻接矩阵，用于公平的链接预测，同时尽可能保留预测准确性。实证验证表明，我们的方法在各种统计量上实现了有效的二元公平性，同时享有良好的公平性与效用性权衡。",
        "领域": "图神经网络、公平性学习、链接预测",
        "问题": "解决图结构数据中的差异影响问题，确保链接预测的公平性",
        "动机": "为了减轻机器学习中的歧视，确保算法设计的公平性",
        "方法": "提出FairAdj算法，通过调节图中边的权重和引入图结构约束，学习公平的邻接矩阵",
        "关键词": [
            "二元公平性",
            "图神经网络",
            "链接预测",
            "公平性学习",
            "邻接矩阵"
        ],
        "涉及的技术概念": {
            "二元公平性": "阐述了两个实例之间的预测关系应独立于敏感属性的公平性原则",
            "图神经网络": "用于处理图结构数据的深度学习模型",
            "邻接矩阵": "表示图中顶点之间连接关系的矩阵，FairAdj算法通过学习公平的邻接矩阵来实现公平的链接预测"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 573,
        "title": "One Network Fits All? Modular versus Monolithic Task Formulations in Neural Networks",
        "html": "https://iclr.cc//virtual/2021/poster/3253",
        "abstract": "Can deep learning solve multiple, very different tasks simultaneously? We investigate how the representations of the underlying tasks affect the ability of a single neural network to learn them jointly. We present theoretical and empirical findings that a single neural network is capable of simultaneously learning multiple tasks from a combined data set, for a variety of methods for representing tasks---for example, when the distinct tasks are encoded by well-separated clusters or decision trees over some task-code attributes. Indeed, more strongly, we present a novel analysis that shows that families of simple programming-like constructs for the codes encoding the tasks are learnable by two-layer neural networks with standard training. We study more generally how the complexity of learning such combined tasks grows with the complexity of the task codes; we find that learning many tasks can be provably hard, even though the individual tasks are easy to learn. We provide empirical support for the usefulness of the learning bounds by training networks on clusters, decision trees, and SQL-style aggregation.",
        "conference": "ICLR",
        "中文标题": "一个网络适应所有？神经网络中的模块化与整体化任务表述",
        "摘要翻译": "深度学习能否同时解决多个非常不同的任务？我们研究了底层任务的表示如何影响单个神经网络联合学习它们的能力。我们提出了理论和实证发现，表明单个神经网络能够从组合数据集中同时学习多个任务，适用于多种任务表示方法——例如，当不同的任务通过良好分离的集群或基于某些任务代码属性的决策树编码时。实际上，更强烈的是，我们提出了一种新颖的分析，表明编码任务的类似简单编程构造的家族可以通过具有标准训练的两层神经网络学习。我们更广泛地研究了学习这种组合任务的复杂性如何随着任务代码的复杂性增长；我们发现学习许多任务可能被证明是困难的，尽管个别任务容易学习。我们通过训练网络在集群、决策树和SQL风格的聚合上，为学习界限的有用性提供了实证支持。",
        "领域": "多任务学习、神经网络架构、深度学习理论",
        "问题": "探讨单个神经网络能否同时学习多个不同任务，以及任务表示如何影响联合学习的效果。",
        "动机": "研究多任务学习的潜力，探索神经网络在处理多样化任务时的能力和限制。",
        "方法": "通过理论和实证分析，研究不同任务表示方法对神经网络联合学习能力的影响，包括集群、决策树和SQL风格聚合等方法。",
        "关键词": [
            "多任务学习",
            "神经网络",
            "任务表示",
            "学习界限",
            "联合学习"
        ],
        "涉及的技术概念": {
            "任务表示": "研究中使用的方法来编码和区分不同的任务，如集群、决策树等。",
            "两层神经网络": "论文中用于学习任务编码的简单神经网络架构。",
            "学习界限": "论文中提出的理论分析，探讨了学习多任务复杂性与任务代码复杂性之间的关系。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 574,
        "title": "On Fast Adversarial Robustness Adaptation in Model-Agnostic Meta-Learning",
        "html": "https://iclr.cc//virtual/2021/poster/2906",
        "abstract": "Model-agnostic meta-learning (MAML) has emerged as one of the most successful meta-learning techniques in few-shot learning. It enables us to learn a $\\textit{meta-initialization}$ of model parameters (that we call $\\textit{meta-model}$) to rapidly adapt to new tasks using a small amount of labeled training data. Despite the generalization power of the meta-model, it remains elusive that how $\\textit{adversarial robustness}$ can be maintained by MAML in few-shot learning. In addition to generalization, robustness is also desired for a meta-model to defend adversarial examples (attacks). Toward promoting adversarial robustness in MAML, we first study $\\textit{when}$ a robustness-promoting regularization should be incorporated, given the fact that MAML adopts a bi-level (fine-tuning vs. meta-update) learning procedure. We show that robustifying the meta-update stage is sufficient to make robustness adapted to the task-specific fine-tuning stage even if the latter uses a standard training protocol. We also make additional justification on the acquired robustness adaptation by peering into the interpretability of neurons' activation maps. Furthermore, we investigate $\\textit{how}$ robust regularization can $\\textit{efficiently}$ be designed in MAML. We propose a general but easily-optimized robustness-regularized meta-learning framework, which allows the use of unlabeled data augmentation, fast adversarial attack generation, and computationally-light fine-tuning. In particular, we for the first time show that the auxiliary contrastive learning task can enhance the adversarial robustness of MAML. Finally, extensive experiments are conducted to demonstrate the effectiveness of our proposed methods in robust few-shot learning.",
        "conference": "ICLR",
        "中文标题": "关于模型无关元学习中快速对抗鲁棒性适应的研究",
        "摘要翻译": "模型无关元学习（MAML）已成为小样本学习中最成功的元学习技术之一。它使我们能够学习模型参数的元初始化（我们称之为元模型），以利用少量标记训练数据快速适应新任务。尽管元模型具有泛化能力，但MAML在小样本学习中如何保持对抗鲁棒性仍然不明确。除了泛化能力，元模型还需要鲁棒性来防御对抗性示例（攻击）。为了在MAML中提升对抗鲁棒性，我们首先研究了在MAML采用双层（微调与元更新）学习过程的情况下，何时应纳入促进鲁棒性的正则化。我们表明，即使在任务特定微调阶段使用标准训练协议，鲁棒化元更新阶段也足以使鲁棒性适应任务特定微调阶段。我们还通过观察神经元激活图的可解释性，对获得的鲁棒性适应进行了额外的合理性证明。此外，我们研究了如何在MAML中高效设计鲁棒正则化。我们提出了一个通用但易于优化的鲁棒性正则化元学习框架，该框架允许使用未标记数据增强、快速对抗攻击生成和计算量轻的微调。特别是，我们首次展示了辅助对比学习任务可以增强MAML的对抗鲁棒性。最后，进行了大量实验以证明我们提出的方法在鲁棒小样本学习中的有效性。",
        "领域": "小样本学习",
        "问题": "如何在模型无关元学习（MAML）中保持和提升对抗鲁棒性",
        "动机": "研究MAML在小样本学习中保持对抗鲁棒性的方法，以防御对抗性示例攻击",
        "方法": "提出了一个鲁棒性正则化元学习框架，包括鲁棒化元更新阶段、使用未标记数据增强、快速对抗攻击生成和计算量轻的微调，以及利用辅助对比学习任务增强对抗鲁棒性",
        "关键词": [
            "模型无关元学习",
            "对抗鲁棒性",
            "小样本学习",
            "正则化",
            "对比学习"
        ],
        "涉及的技术概念": {
            "模型无关元学习（MAML）": "一种元学习技术，通过学习模型参数的元初始化来快速适应新任务",
            "对抗鲁棒性": "模型防御对抗性示例攻击的能力，是本研究的主要关注点",
            "正则化": "在MAML中用于提升对抗鲁棒性的技术手段，特别是在元更新阶段的应用"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 575,
        "title": "On Graph Neural Networks versus Graph-Augmented MLPs",
        "html": "https://iclr.cc//virtual/2021/poster/3074",
        "abstract": "From the perspectives of expressive power and learning, this work compares multi-layer Graph Neural Networks (GNNs) with a simplified alternative that we call Graph-Augmented Multi-Layer Perceptrons (GA-MLPs), which first augments node features with certain multi-hop operators on the graph and then applies learnable node-wise functions. From the perspective of graph isomorphism testing, we show both theoretically and numerically that GA-MLPs with suitable operators can distinguish almost all non-isomorphic graphs, just like the Weisfeiler-Lehman (WL) test and GNNs. However, by viewing them as node-level functions and examining the equivalence classes they induce on rooted graphs, we prove a separation in expressive power between GA-MLPs and GNNs that grows exponentially in depth. In particular, unlike GNNs, GA-MLPs are unable to count the number of attributed walks. We also demonstrate via community detection experiments that GA-MLPs can be limited by their choice of operator family, whereas GNNs have higher flexibility in learning.",
        "conference": "ICLR",
        "中文标题": "图神经网络与图增强多层感知器的比较研究",
        "摘要翻译": "本研究从表达能力和学习能力的角度，比较了多层图神经网络（GNNs）与我们称为图增强多层感知器（GA-MLPs）的简化替代方案。GA-MLPs首先通过图上的某些多跳算子增强节点特征，然后应用可学习的节点级函数。从图同构测试的角度，我们理论上和数值上证明了，具有适当算子的GA-MLPs可以区分几乎所有非同构图，就像Weisfeiler-Lehman（WL）测试和GNNs一样。然而，通过将它们视为节点级函数并检查它们在根图上诱导的等价类，我们证明了GA-MLPs和GNNs在表达能力上的分离随着深度的增加呈指数级增长。特别是，与GNNs不同，GA-MLPs无法计算属性行走的数量。我们还通过社区检测实验证明，GA-MLPs可能受到其算子家族选择的限制，而GNNs在学习上具有更高的灵活性。",
        "领域": "图神经网络、图表示学习、社区检测",
        "问题": "比较图神经网络（GNNs）和图增强多层感知器（GA-MLPs）在表达能力和学习能力上的差异",
        "动机": "探索图神经网络简化替代方案的可行性及其在图数据处理中的表现",
        "方法": "通过理论分析和数值实验比较GNNs和GA-MLPs的表达能力和学习能力，特别是在图同构测试和社区检测任务上的表现",
        "关键词": [
            "图神经网络",
            "图增强多层感知器",
            "图同构测试",
            "社区检测",
            "表达能力"
        ],
        "涉及的技术概念": {
            "图神经网络（GNNs）": "用于处理图结构数据的深度学习模型，能够捕捉图中节点和边的复杂关系",
            "图增强多层感知器（GA-MLPs）": "一种简化的图数据处理方法，通过多跳算子增强节点特征后应用节点级函数",
            "Weisfeiler-Lehman（WL）测试": "一种用于图同构测试的经典算法，能够区分大多数非同构图"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 576,
        "title": "On InstaHide, Phase Retrieval, and Sparse Matrix Factorization",
        "html": "https://iclr.cc//virtual/2021/poster/2969",
        "abstract": "In this work, we examine the security of InstaHide, a scheme recently proposed by \\cite{hsla20} for preserving the security of private datasets in the context of distributed learning. To generate a synthetic training example to be shared among the distributed learners, InstaHide takes a convex combination of private feature vectors and randomly flips the sign of each entry of the resulting vector with probability 1/2. A salient question is whether this scheme is secure in any provable sense, perhaps under a plausible complexity-theoretic assumption. \n\nThe answer to this turns out to be quite subtle and closely related to the average-case complexity of a multi-task, missing-data version of the classic problem of phase retrieval that is interesting in its own right. Motivated by this connection, under the standard distributional assumption that the public/private feature vectors are isotropic Gaussian, we design an algorithm that can actually recover a private vector using only the public vectors and a sequence of synthetic vectors generated by InstaHide.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "关于 InstaHide、相位恢复和稀疏矩阵分解",
        "摘要翻译": "在这项工作中，我们研究了 InstaHide 的安全性，InstaHide 是 \\cite{hsla20} 最近提出的，用于在分布式学习环境中保护私有数据集的安全性的方案。为了生成一个在分布式学习者之间共享的合成训练样本，InstaHide 采用私有特征向量的凸组合，并以 1/2 的概率随机翻转结果向量的每个条目的符号。一个突出的问题是，这种方案是否在任何可证明的意义上是安全的，也许是在一个合理的复杂性理论假设下。\\n\\n事实证明，这个问题的答案非常微妙，并且与相位恢复经典问题的多任务、缺失数据版本的平均情况复杂性密切相关，这个问题本身就很有趣。受此连接的启发，在公共/私有特征向量是各向同性高斯分布的标准分布假设下，我们设计了一种算法，该算法实际上仅使用公共向量和 InstaHide 生成的一系列合成向量来恢复私有向量。",
        "领域": "联邦学习安全, 隐私保护, 密码学",
        "问题": "评估并攻破 InstaHide 方案在分布式学习中保护隐私的能力，以及在特定假设下恢复私有数据的可行性。",
        "动机": "InstaHide 是一种新兴的隐私保护方案，旨在保护分布式学习中的私有数据集。研究其安全性对于理解此类方案的局限性以及开发更强大的隐私保护机制至关重要。",
        "方法": "通过分析 InstaHide 的合成数据生成过程与相位恢复问题的联系，设计了一种在特定分布假设下能够仅利用公开数据和合成数据来恢复私有向量的算法。 通过算法攻破来评估安全性。",
        "关键词": [
            "InstaHide",
            "隐私保护",
            "分布式学习",
            "相位恢复",
            "安全性"
        ],
        "涉及的技术概念": {
            "InstaHide": "一种用于在分布式学习中保护私有数据的方案，通过凸组合私有特征向量并随机翻转符号来生成合成数据。",
            "相位恢复": "一个经典问题，旨在从其傅里叶变换的幅度中恢复信号。论文将其与 InstaHide 的安全性联系起来，表明攻击者可能通过类似相位恢复的方法来恢复私有数据。"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 577,
        "title": "On Learning Universal Representations Across Languages",
        "html": "https://iclr.cc//virtual/2021/poster/2921",
        "abstract": "Recent studies have demonstrated the overwhelming advantage of cross-lingual pre-trained models (PTMs), such as multilingual BERT and XLM, on cross-lingual NLP tasks. However, existing approaches essentially capture the co-occurrence among tokens through involving the masked language model (MLM) objective with token-level cross entropy. In this work, we extend these approaches to learn sentence-level representations and show the effectiveness on cross-lingual understanding and generation. Specifically, we propose a Hierarchical Contrastive Learning (HiCTL) method to (1) learn universal representations for parallel sentences distributed in one or multiple languages and (2) distinguish the semantically-related words from a shared cross-lingual vocabulary for each sentence. We conduct evaluations on two challenging cross-lingual tasks, XTREME and machine translation. Experimental results show that the HiCTL outperforms the state-of-the-art XLM-R by an absolute gain of 4.2% accuracy on the XTREME benchmark as well as achieves substantial improvements on both of the high resource and low-resource English$\\rightarrow$X translation tasks over strong baselines.",
        "conference": "ICLR",
        "中文标题": "关于跨语言学习通用表示的研究",
        "摘要翻译": "最近的研究已经证明了跨语言预训练模型（如多语言BERT和XLM）在跨语言自然语言处理任务中的巨大优势。然而，现有的方法主要通过结合掩码语言模型（MLM）目标和词级交叉熵来捕获标记之间的共现关系。在这项工作中，我们扩展了这些方法以学习句子级表示，并展示了在跨语言理解和生成上的有效性。具体来说，我们提出了一种分层对比学习（HiCTL）方法，以（1）学习分布在一个或多个语言中的平行句子的通用表示，以及（2）从共享的跨语言词汇中为每个句子区分语义相关的词。我们在两个具有挑战性的跨语言任务XTREME和机器翻译上进行了评估。实验结果表明，HiCTL在XTREME基准测试上的准确率绝对提升了4.2%，同时在高低资源英语→X翻译任务上均比强基线有显著提升。",
        "领域": "跨语言自然语言处理、机器翻译、预训练模型",
        "问题": "如何学习跨语言的通用句子级表示以提高跨语言理解和生成任务的性能",
        "动机": "现有的跨语言预训练模型主要关注词级表示，缺乏对句子级通用表示的有效学习",
        "方法": "提出分层对比学习（HiCTL）方法，学习平行句子的通用表示并区分语义相关的词",
        "关键词": [
            "跨语言学习",
            "分层对比学习",
            "句子级表示",
            "机器翻译",
            "预训练模型"
        ],
        "涉及的技术概念": {
            "分层对比学习（HiCTL）": "用于学习跨语言句子级通用表示的方法，通过对比学习区分语义相关的词",
            "掩码语言模型（MLM）": "预训练模型中的一种技术，通过预测被掩码的单词来学习语言表示",
            "跨语言词汇": "共享于多种语言之间的词汇集合，用于支持跨语言理解和生成任务"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 578,
        "title": "Online Adversarial Purification based on Self-supervised Learning",
        "html": "https://iclr.cc//virtual/2021/poster/2996",
        "abstract": "Deep neural networks are known to be vulnerable to adversarial examples, where a perturbation in the input space leads to an amplified shift in the latent network representation. In this paper, we combine canonical supervised learning with self-supervised representation learning, and present Self-supervised Online Adversarial Purification (SOAP), a novel defense strategy that uses a self-supervised loss to purify adversarial examples at test-time. Our approach leverages the label-independent nature of self-supervised signals and counters the adversarial perturbation with respect to the self-supervised tasks. SOAP yields competitive robust accuracy against state-of-the-art adversarial training and purification methods, with considerably less training complexity. In addition, our approach is robust even when adversaries are given the knowledge of the purification defense strategy. To the best of our knowledge, our paper is the first that generalizes the idea of using self-supervised signals to perform online test-time purification.",
        "conference": "ICLR",
        "中文标题": "基于自监督学习的在线对抗净化",
        "摘要翻译": "众所周知，深度神经网络容易受到对抗性例子的影响，输入空间的微小扰动会导致潜在网络表示的显著变化。本文结合了规范的监督学习和自监督表示学习，提出了一种新颖的防御策略——自监督在线对抗净化（SOAP），该策略利用自监督损失在测试时净化对抗性例子。我们的方法利用了自监督信号与标签无关的特性，并针对自监督任务对抗扰动进行抵抗。SOAP在对抗最先进的对抗训练和净化方法时，提供了具有竞争力的鲁棒准确性，且训练复杂度显著降低。此外，即使攻击者知晓净化防御策略，我们的方法仍然保持鲁棒性。据我们所知，本文是首次将利用自监督信号进行在线测试时净化的思想推广开来。",
        "领域": "对抗性防御、自监督学习、深度神经网络安全",
        "问题": "深度神经网络对对抗性例子的脆弱性问题",
        "动机": "提高深度神经网络对抗对抗性攻击的鲁棒性，同时降低训练复杂度",
        "方法": "结合监督学习和自监督学习，利用自监督损失在测试时净化对抗性例子",
        "关键词": [
            "对抗性净化",
            "自监督学习",
            "在线防御",
            "深度神经网络",
            "鲁棒性"
        ],
        "涉及的技术概念": {
            "自监督学习": "用于学习数据表示而不依赖于人工标注的技术，在本研究中用于提供标签无关的信号以净化对抗性扰动",
            "对抗性净化": "在测试时识别并修正对抗性扰动，以恢复原始输入的技术",
            "鲁棒性": "模型在面对输入扰动时保持性能的能力，本研究通过自监督信号增强模型的鲁棒性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 579,
        "title": "On Position Embeddings in BERT",
        "html": "https://iclr.cc//virtual/2021/poster/3249",
        "abstract": "Various Position Embeddings (PEs) have been proposed in Transformer based architectures~(e.g. BERT) to model word order. These are empirically-driven and perform well, but no formal framework exists to systematically study them. To address this, we present three properties of PEs that capture word distance in vector space:  translation invariance, monotonicity, and  symmetry. These properties formally capture the behaviour of PEs and allow us to reinterpret sinusoidal PEs in a principled way.\nMoreover, we propose a new probing test (called `identical word probing') and  mathematical  indicators to quantitatively detect the general  attention patterns with respect to the above properties. An empirical evaluation of seven PEs (and their combinations) for classification (GLUE) and span prediction (SQuAD) shows that: (1) both  classification and span prediction benefit from  translation invariance and local monotonicity, while symmetry slightly decreases performance;\n(2) The fully-learnable absolute PE performs better in classification, while relative PEs perform better in span prediction.  We contribute the first formal and quantitative analysis of desiderata for PEs, and  a principled discussion about their correlation to the performance of typical downstream tasks.",
        "conference": "ICLR",
        "中文标题": "论BERT中的位置嵌入",
        "摘要翻译": "在基于Transformer的架构（如BERT）中，已经提出了各种位置嵌入（PEs）来建模词序。这些方法基于经验驱动且表现良好，但缺乏一个系统的形式化框架来研究它们。为了解决这一问题，我们提出了PEs的三个属性，这些属性在向量空间中捕捉词距离：平移不变性、单调性和对称性。这些属性形式化地捕捉了PEs的行为，并允许我们以原则性的方式重新解释正弦PEs。此外，我们提出了一种新的探测测试（称为‘相同词探测’）和数学指标，以定量检测与上述属性相关的一般注意力模式。对七种PEs（及其组合）在分类（GLUE）和跨度预测（SQuAD）任务上的实证评估表明：（1）分类和跨度预测都受益于平移不变性和局部单调性，而对称性略微降低性能；（2）完全可学习的绝对PE在分类任务中表现更好，而相对PEs在跨度预测任务中表现更好。我们首次对PEs的需求进行了形式和定量分析，并就它们与典型下游任务性能的相关性进行了原则性讨论。",
        "领域": "自然语言处理与视觉结合, 文本分类, 序列标注",
        "问题": "系统地研究和评估Transformer架构中各种位置嵌入（PEs）的性能和属性",
        "动机": "缺乏一个形式化框架来系统地研究位置嵌入（PEs）的行为和其对下游任务性能的影响",
        "方法": "提出PEs的三个形式化属性（平移不变性、单调性和对称性），并开发新的探测测试和数学指标来定量评估PEs的性能",
        "关键词": [
            "位置嵌入",
            "Transformer",
            "文本分类",
            "跨度预测",
            "注意力模式"
        ],
        "涉及的技术概念": {
            "平移不变性": "PEs在向量空间中捕捉词距离的属性，确保模型对词的位置变化具有鲁棒性",
            "单调性": "PEs确保词序在向量空间中得到正确反映的属性，有助于模型理解词序信息",
            "对称性": "PEs在处理对称词序时的属性，研究发现略微降低模型性能"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 580,
        "title": "On Self-Supervised Image Representations for GAN Evaluation",
        "html": "https://iclr.cc//virtual/2021/poster/3329",
        "abstract": "The embeddings from CNNs pretrained on Imagenet classification are de-facto standard image representations for assessing GANs via FID, Precision and Recall measures. Despite broad previous criticism of their usage for non-Imagenet domains, these embeddings are still the top choice in most of the GAN literature.\n\nIn this paper, we advocate the usage of the state-of-the-art self-supervised representations to evaluate GANs on the established non-Imagenet benchmarks. These representations, typically obtained via contrastive learning, are shown to provide better transfer to new tasks and domains, therefore, can serve as more universal embeddings of natural images. With extensive comparison of the recent GANs on the common datasets, we show that self-supervised representations produce a more reasonable ranking of models in terms of FID/Precision/Recall, while the ranking with classification-pretrained embeddings often can be misleading.",
        "conference": "ICLR",
        "中文标题": "关于自监督图像表示在GAN评估中的应用",
        "摘要翻译": "在ImageNet分类任务上预训练的CNN模型的嵌入特征，通过FID、精确度和召回率等指标评估GAN模型时，已成为事实上的标准图像表示。尽管之前对于其在非ImageNet领域使用的广泛批评，这些嵌入特征在大多数GAN文献中仍然是首选。本文主张使用最先进的自监督表示来评估在已建立的非ImageNet基准上的GAN。这些通常通过对比学习获得的自监督表示，已被证明能更好地迁移到新任务和领域，因此可以作为更通用的自然图像嵌入。通过对常见数据集上最近的GAN模型进行广泛比较，我们表明自监督表示在FID/精确度/召回率方面产生了更合理的模型排名，而使用分类预训练嵌入的排名往往可能产生误导。",
        "领域": "生成对抗网络评估、自监督学习、图像表示学习",
        "问题": "如何更准确地评估生成对抗网络（GAN）在非ImageNet数据集上的性能",
        "动机": "现有的基于ImageNet预训练CNN的嵌入特征在评估GAN时存在局限性，尤其是在非ImageNet领域，这促使研究者寻找更通用的图像表示方法。",
        "方法": "采用最先进的自监督学习获得的图像表示来评估GAN，通过对比学习提高表示的通用性和迁移能力。",
        "关键词": [
            "自监督学习",
            "生成对抗网络评估",
            "图像表示",
            "对比学习",
            "FID"
        ],
        "涉及的技术概念": {
            "自监督表示": "通过自监督学习获得的图像表示，无需大量标注数据即可学习有效的特征表示，适用于多种任务和领域。",
            "对比学习": "一种自监督学习方法，通过比较正负样本对来学习表示，能够提高模型的泛化能力和迁移性。",
            "FID": "Frechet Inception Distance，一种评估GAN生成图像质量的指标，通过比较生成图像和真实图像在特征空间中的分布距离来衡量。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 581,
        "title": "On Statistical Bias In Active Learning: How and When to Fix It",
        "html": "https://iclr.cc//virtual/2021/poster/3037",
        "abstract": "Active learning is a powerful tool when labelling data is expensive, but it introduces a bias because the training data no longer follows the population distribution. We formalize this bias and investigate the situations in which it can be harmful and sometimes even helpful. We further introduce novel corrective weights to remove bias when doing so is beneficial. Through this, our work not only provides a useful mechanism that can improve the active learning approach, but also an explanation for the empirical successes of various existing approaches which ignore this bias. In particular, we show that this bias can be actively helpful when training overparameterized models---like neural networks---with relatively modest dataset sizes.",
        "conference": "ICLR",
        "中文标题": "论主动学习中的统计偏差：如何及何时修正",
        "摘要翻译": "主动学习在数据标注成本高昂时是一种强大的工具，但它引入了一种偏差，因为训练数据不再遵循总体分布。我们形式化了这种偏差，并研究了在哪些情况下它可能有害，有时甚至有益。我们进一步引入了新颖的校正权重，以在有益时消除偏差。通过这项工作，我们不仅提供了一种可以改进主动学习方法的实用机制，而且还解释了各种忽视这种偏差的现有方法在实证上成功的原因。特别是，我们展示了这种偏差在训练过参数化模型（如神经网络）时，在相对较小的数据集规模下，可以主动有益。",
        "领域": "机器学习",
        "问题": "主动学习引入的统计偏差问题及其影响",
        "动机": "研究主动学习中统计偏差的性质，探索其在特定情况下的利弊，并提出修正方法",
        "方法": "形式化统计偏差，研究其影响条件，引入校正权重进行偏差修正",
        "关键词": [
            "主动学习",
            "统计偏差",
            "过参数化模型",
            "校正权重",
            "神经网络"
        ],
        "涉及的技术概念": {
            "主动学习": "一种机器学习方法，通过选择最有信息量的样本进行标注，以减少标注成本",
            "统计偏差": "由于训练数据与总体分布不一致而引入的系统性误差",
            "校正权重": "用于调整样本权重以减少或消除统计偏差的技术"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 582,
        "title": "On the Bottleneck of Graph Neural Networks and its Practical Implications",
        "html": "https://iclr.cc//virtual/2021/poster/2575",
        "abstract": "Since the proposal of the graph neural network (GNN) by Gori et al. (2005) and Scarselli et al. (2008), one of the major problems in training GNNs was their struggle to propagate information between distant nodes in the graph.\nWe propose a new explanation for this problem: GNNs are susceptible to a bottleneck when aggregating messages across a long path. This bottleneck causes the over-squashing of exponentially growing information into fixed-size vectors.\nAs a result, GNNs fail to propagate messages originating from distant nodes and perform poorly when the prediction task depends on long-range interaction.\nIn this paper, we highlight the inherent problem of over-squashing in GNNs:\nwe demonstrate that the bottleneck hinders popular GNNs from fitting long-range signals in the training data;\nwe further show that GNNs that absorb incoming edges equally, such as GCN and GIN, are more susceptible to over-squashing than GAT and GGNN;\nfinally, we show that prior work, which extensively tuned GNN models of long-range problems, suffers from over-squashing, and that breaking the bottleneck improves their state-of-the-art results without any tuning or additional weights. \nOur code is available at https://github.com/tech-srl/bottleneck/ .",
        "conference": "ICLR",
        "中文标题": "论图神经网络的瓶颈及其实际影响",
        "摘要翻译": "自从Gori等人（2005年）和Scarselli等人（2008年）提出图神经网络（GNN）以来，训练GNN的一个主要问题是它们在图中远距离节点之间传播信息的困难。我们为这个问题提出了一个新的解释：GNN在聚合长路径上的消息时容易遇到瓶颈。这个瓶颈导致指数增长的信息被过度压缩到固定大小的向量中。结果，GNN无法传播来自远距离节点的消息，并且在预测任务依赖于长距离交互时表现不佳。在本文中，我们强调了GNN中固有的过度压缩问题：我们证明了瓶颈阻碍了流行的GNN拟合训练数据中的长距离信号；我们进一步表明，像GCN和GIN这样平等吸收入边的GNN比GAT和GGNN更容易受到过度压缩的影响；最后，我们展示了先前的工作，这些工作广泛调整了GNN模型以解决长距离问题，却遭受了过度压缩的困扰，而打破瓶颈无需任何调整或额外权重就能改进它们的最先进结果。我们的代码可在https://github.com/tech-srl/bottleneck/获取。",
        "领域": "图神经网络、长距离依赖建模、图表示学习",
        "问题": "图神经网络在远距离节点间信息传播中的瓶颈问题",
        "动机": "解决图神经网络在处理长距离依赖时的信息过度压缩问题，提升模型性能",
        "方法": "分析并提出GNN中的信息传播瓶颈问题，通过实验比较不同GNN架构对过度压缩的敏感性，并提出解决方案",
        "关键词": [
            "图神经网络",
            "信息传播瓶颈",
            "长距离依赖",
            "过度压缩",
            "模型优化"
        ],
        "涉及的技术概念": {
            "过度压缩": "指GNN在聚合长路径信息时，将大量信息压缩到固定大小的向量中，导致信息丢失的现象",
            "图卷积网络（GCN）": "一种基础的图神经网络架构，平等处理所有入边信息，容易受到过度压缩的影响",
            "图注意力网络（GAT）": "通过引入注意力机制来动态调整节点间信息的重要性，减少过度压缩的影响"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 583,
        "title": "On the Critical Role of Conventions in Adaptive Human-AI Collaboration",
        "html": "https://iclr.cc//virtual/2021/poster/2573",
        "abstract": "Humans can quickly adapt to new partners in collaborative tasks (e.g. playing basketball), because they understand which fundamental skills of the task (e.g. how to dribble, how to shoot) carry over across new partners. Humans can also quickly adapt to similar tasks with the same partners by carrying over conventions that they have developed (e.g. raising hand signals pass the ball), without learning to coordinate from scratch. To collaborate seamlessly with humans, AI agents should adapt quickly to new partners and new tasks as well. However, current approaches have not attempted to distinguish between the complexities intrinsic to a task and the conventions used by a partner, and more generally there has been little focus on leveraging conventions for adapting to new settings. In this work, we propose a learning framework that teases apart rule-dependent representation from convention-dependent representation in a principled way. We show that, under some assumptions, our rule-dependent representation is a sufficient statistic of the distribution over best-response strategies across partners. Using this separation of representations, our agents are able to adapt quickly to new partners, and to coordinate with old partners on new tasks in a zero-shot manner. We experimentally validate our approach on three collaborative tasks varying in complexity: a contextual multi-armed bandit, a block placing task, and the card game Hanabi.",
        "conference": "ICLR",
        "中文标题": "论惯例在自适应人机协作中的关键作用",
        "摘要翻译": "人类能够迅速适应协作任务中的新伙伴（例如打篮球），因为他们理解任务的哪些基本技能（例如如何运球、如何投篮）可以跨越新伙伴而延续。人类也能通过延续已发展的惯例（例如举手示意传球），迅速适应与相同伙伴的类似任务，而无需从头学习协调。为了与人类无缝协作，AI代理也应能快速适应新伙伴和新任务。然而，当前的方法尚未尝试区分任务固有的复杂性和伙伴使用的惯例，更广泛地说，很少有研究关注利用惯例来适应新环境。在这项工作中，我们提出了一个学习框架，以原则性的方式区分规则依赖的表示和惯例依赖的表示。我们表明，在某些假设下，我们的规则依赖表示是跨伙伴最佳响应策略分布的充分统计量。利用这种表示的分离，我们的代理能够快速适应新伙伴，并以零样本方式与旧伙伴在新任务上协调。我们在三个复杂度不同的协作任务上实验验证了我们的方法：上下文多臂老虎机、积木放置任务和纸牌游戏Hanabi。",
        "领域": "人机协作、自适应学习、多智能体系统",
        "问题": "如何使AI代理能够快速适应新的人类伙伴和新任务，以实现无缝协作。",
        "动机": "当前AI代理在适应新伙伴和新任务时，未能有效区分任务固有复杂性和伙伴使用的惯例，限制了协作的效率和灵活性。",
        "方法": "提出一个学习框架，区分规则依赖和惯例依赖的表示，利用这种分离实现快速适应和零样本协调。",
        "关键词": [
            "人机协作",
            "自适应学习",
            "惯例依赖表示",
            "零样本协调",
            "Hanabi游戏"
        ],
        "涉及的技术概念": {
            "规则依赖表示": "区分任务固有规则的学习表示，用于跨伙伴适应。",
            "惯例依赖表示": "捕捉伙伴特定惯例的学习表示，用于快速适应新伙伴。",
            "零样本协调": "在没有预先训练的情况下，代理能够与伙伴在新任务上有效协作的能力。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 584,
        "title": "On the Curse of Memory in Recurrent Neural Networks: Approximation and Optimization Analysis",
        "html": "https://iclr.cc//virtual/2021/poster/3345",
        "abstract": "We study the approximation properties and optimization dynamics of recurrent neural networks (RNNs) when applied to learn input-output relationships in temporal data. We consider the simple but representative setting of using continuous-time linear RNNs to learn from data generated by linear relationships. Mathematically, the latter can be understood as a sequence of linear functionals.  We prove a universal approximation theorem of such linear functionals and characterize the approximation rate.  Moreover, we perform a fine-grained dynamical analysis of training linear RNNs by gradient methods.  A unifying theme uncovered is the non-trivial effect of memory, a notion that can be made precise in our framework, on both approximation and optimization: when there is long-term memory in the target, it takes a large number of neurons to approximate it. Moreover, the training process will suffer from slow downs.  In particular, both of these effects become exponentially more pronounced with increasing memory - a phenomenon we call the “curse of memory”.  These analyses represent a basic step towards a concrete mathematical understanding of new phenomenons that may arise in learning temporal relationships using recurrent architectures.",
        "conference": "ICLR",
        "中文标题": "论循环神经网络中的记忆诅咒：逼近与优化分析",
        "摘要翻译": "我们研究了循环神经网络（RNNs）在应用于学习时序数据中的输入-输出关系时的逼近性质和优化动态。我们考虑了一个简单但具有代表性的设置，即使用连续时间线性RNNs从由线性关系生成的数据中学习。从数学上讲，后者可以被理解为一序列的线性泛函。我们证明了这类线性泛函的通用逼近定理，并描述了逼近速率。此外，我们对通过梯度方法训练线性RNNs进行了细致的动态分析。揭示的一个统一主题是记忆对逼近和优化的非平凡影响，这一概念在我们的框架中可以精确化：当目标中存在长期记忆时，需要大量神经元来逼近它。此外，训练过程将遭受减速。特别是，这两种效应随着记忆的增加而呈指数级加剧——我们称之为“记忆诅咒”。这些分析代表了对使用循环架构学习时序关系时可能出现的新现象进行具体数学理解的基本步骤。",
        "领域": "时序数据分析、循环神经网络、机器学习理论",
        "问题": "循环神经网络在处理具有长期记忆的时序数据时的逼近能力和优化效率问题",
        "动机": "探索循环神经网络在学习时序关系时的基本数学性质，特别是记忆对模型性能的影响",
        "方法": "通过理论分析和数学证明，研究线性RNNs的逼近能力和梯度训练的动态特性",
        "关键词": [
            "循环神经网络",
            "记忆诅咒",
            "逼近理论",
            "优化动态",
            "时序数据"
        ],
        "涉及的技术概念": {
            "循环神经网络": "用于处理时序数据的神经网络架构，能够捕捉时间序列中的动态模式",
            "记忆诅咒": "描述随着记忆长度的增加，RNNs在逼近和优化方面面临的指数级困难",
            "梯度方法": "用于训练神经网络的优化技术，通过计算损失函数的梯度来更新网络参数"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 585,
        "title": "On the Dynamics of Training Attention Models",
        "html": "https://iclr.cc//virtual/2021/poster/2692",
        "abstract": "The attention mechanism has been widely used in deep neural networks as a model component. By now, it has become a critical building block in many state-of-the-art natural language models. Despite its great success established empirically, the working mechanism of attention has not been investigated at a sufficient theoretical depth to date. In this paper, we set up a simple text classification task and study the dynamics of training a simple attention-based classification model using gradient descent. In this setting, we show that, for the discriminative words that the model should attend to, a persisting identity exists relating its embedding and the inner product of its key and the query. This allows us to prove that training must converge to attending to the discriminative words when the attention output is classified by a linear classifier. Experiments are performed, which validate our theoretical analysis and provide further insights.",
        "conference": "ICLR",
        "中文标题": "注意力模型训练动态研究",
        "摘要翻译": "注意力机制已被广泛用作深度神经网络中的一个模型组件。迄今为止，它已成为许多最先进自然语言模型中的关键构建块。尽管其在经验上取得了巨大成功，但迄今为止，注意力机制的工作机制尚未在足够的理论深度上进行研究。在本文中，我们建立了一个简单的文本分类任务，并研究了使用梯度下降训练一个简单的基于注意力的分类模型的动态。在此设置中，我们表明，对于模型应该关注的判别性单词，存在一个持久的身份，将其嵌入与其键和查询的内积联系起来。这使我们能够证明，当注意力输出由线性分类器分类时，训练必须收敛于关注判别性单词。进行了实验，验证了我们的理论分析并提供了进一步的见解。",
        "领域": "自然语言处理与视觉结合, 文本分类, 注意力机制",
        "问题": "研究注意力机制在训练过程中的动态行为及其理论依据",
        "动机": "尽管注意力机制在经验上取得了成功，但其工作机制缺乏足够的理论深度研究，本文旨在填补这一空白",
        "方法": "通过建立一个简单的文本分类任务，研究基于注意力的分类模型在梯度下降训练过程中的动态行为，并进行实验验证",
        "关键词": [
            "注意力机制",
            "训练动态",
            "文本分类",
            "梯度下降",
            "理论分析"
        ],
        "涉及的技术概念": {
            "注意力机制": "用于提升模型对输入数据中重要部分的关注，是本文研究的核心对象",
            "梯度下降": "用于训练注意力模型的优化方法，本文研究了其训练动态",
            "线性分类器": "用于分类注意力模型的输出，本文证明了在特定条件下训练会收敛于关注判别性单词"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 586,
        "title": "On the geometry of generalization and memorization in deep neural networks",
        "html": "https://iclr.cc//virtual/2021/poster/2866",
        "abstract": "Understanding how large neural networks avoid memorizing training data is key to explaining their high generalization performance. To examine the structure of when and where memorization occurs in a deep network, we use a recently developed replica-based mean field theoretic geometric analysis method. We find that all layers preferentially learn from examples which share features, and link this behavior to generalization performance. Memorization predominately occurs in the deeper layers, due to decreasing object manifolds’ radius and dimension, whereas early layers are minimally affected. This predicts that generalization can be restored by reverting the final few layer weights to earlier epochs before significant memorization occurred, which is confirmed by the experiments. Additionally, by studying generalization under different model sizes, we reveal the connection between the double descent phenomenon and the underlying model geometry. Finally, analytical analysis shows that networks avoid memorization early in training because close to initialization, the gradient contribution from permuted examples are small. These findings provide quantitative evidence for the structure of memorization across layers of a deep neural network, the drivers for such structure, and its connection to manifold geometric properties.\n",
        "conference": "ICLR",
        "中文标题": "深度神经网络中泛化与记忆的几何学研究",
        "摘要翻译": "理解大型神经网络如何避免记忆训练数据是解释其高泛化性能的关键。为了研究深度网络中记忆发生的结构和时机，我们采用了一种最近开发的基于复制品的平均场理论几何分析方法。我们发现，所有层都优先从共享特征的示例中学习，并将这种行为与泛化性能联系起来。记忆主要发生在更深层，这是由于对象流形的半径和维度减小，而早期层受到的影响最小。这预测了通过将最后几层的权重恢复到显著记忆发生之前的早期时期，可以恢复泛化性能，实验证实了这一点。此外，通过研究不同模型大小下的泛化，我们揭示了双下降现象与底层模型几何之间的联系。最后，分析分析表明，网络在训练早期避免记忆是因为接近初始化时，来自置换示例的梯度贡献较小。这些发现为深度神经网络各层记忆的结构、这种结构的驱动因素及其与流形几何特性的联系提供了定量证据。",
        "领域": "深度学习理论、神经网络优化、机器学习几何学",
        "问题": "研究深度神经网络如何避免记忆训练数据以实现高泛化性能。",
        "动机": "探索深度神经网络中记忆发生的结构和时机，以理解其高泛化性能的机制。",
        "方法": "采用基于复制品的平均场理论几何分析方法，研究网络各层的学习行为和记忆结构。",
        "关键词": [
            "泛化性能",
            "记忆结构",
            "几何分析",
            "双下降现象",
            "流形几何"
        ],
        "涉及的技术概念": {
            "复制品方法": "用于分析深度神经网络中记忆和泛化行为的平均场理论方法。",
            "对象流形": "描述网络中数据表示的几何结构，影响记忆和泛化的发生。",
            "双下降现象": "模型性能随复杂度增加先提高后下降再提高的现象，与模型几何结构相关。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 587,
        "title": "On the Impossibility of Global Convergence in Multi-Loss Optimization",
        "html": "https://iclr.cc//virtual/2021/poster/2794",
        "abstract": "Under mild regularity conditions, gradient-based methods converge globally to a critical point in the single-loss setting. This is known to break down for vanilla gradient descent when moving to multi-loss optimization, but can we hope to build some algorithm with global guarantees? We negatively resolve this open problem by proving that desirable convergence properties cannot simultaneously hold for any algorithm. Our result has more to do with the existence of games with no satisfactory outcomes, than with algorithms per se. More explicitly we construct a two-player game with zero-sum interactions whose losses are both coercive and analytic, but whose only simultaneous critical point is a strict maximum. Any 'reasonable' algorithm, defined to avoid strict maxima, will therefore fail to converge. This is fundamentally different from single losses, where coercivity implies existence of a global minimum.  Moreover, we prove that a wide range of existing gradient-based methods almost surely have bounded but non-convergent iterates in a constructed zero-sum game for suitably small learning rates. It nonetheless remains an open question whether such behavior can arise in high-dimensional games of interest to ML practitioners, such as GANs or multi-agent RL.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "多损失优化中全局收敛的不可能性",
        "摘要翻译": "在温和的正则条件下，基于梯度的方法在单损失设置中全局收敛到一个临界点。已知当转向多损失优化时，对于普通的梯度下降法来说这一点会失效，但我们是否能希望构建某种具有全局保证的算法呢？我们通过证明任何算法都不能同时拥有理想的收敛性质，负面地解决了这个开放性问题。我们的结果更多地与存在没有满意结果的博弈有关，而不是算法本身。更明确地说，我们构建了一个具有零和交互的双玩家博弈，其损失既是强制的又是解析的，但其唯一的同步临界点是一个严格的极大值。因此，任何定义为避免严格极大值的‘合理’算法都将无法收敛。这与单损失情况根本不同，在单损失情况下，强制性意味着存在全局最小值。此外，我们证明了在构造的零和博弈中，对于适当小的学习率，广泛的现有基于梯度的方法几乎肯定有界但不收敛的迭代。然而，这种行为是否会在机器学习从业者感兴趣的高维博弈中出现，如GANs或多智能体RL，仍然是一个开放性问题。",
        "领域": "优化理论",
        "问题": "多损失优化中全局收敛的不可能性",
        "动机": "探索在多损失优化中是否存在算法能够实现全局收敛",
        "方法": "通过构建一个具有特定性质的双玩家零和博弈，证明在多损失优化中全局收敛的不可能性",
        "关键词": [
            "多损失优化",
            "全局收敛",
            "梯度下降",
            "零和博弈",
            "机器学习"
        ],
        "涉及的技术概念": {
            "多损失优化": "研究在多个损失函数同时存在的情况下优化算法的行为",
            "全局收敛": "算法能够在整个定义域内收敛到最优解的性质",
            "零和博弈": "一种博弈论模型，其中一方的收益等于另一方的损失"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 588,
        "title": "On the mapping between Hopfield networks and Restricted Boltzmann Machines",
        "html": "https://iclr.cc//virtual/2021/poster/3045",
        "abstract": "Hopfield networks (HNs) and Restricted Boltzmann Machines (RBMs) are two important models at the interface of statistical physics, machine learning, and neuroscience. Recently, there has been interest in the relationship between HNs and RBMs, due to their similarity under the statistical mechanics formalism. An exact mapping between HNs and RBMs has been previously noted for the special case of orthogonal (“uncorrelated”) encoded patterns. We present here an exact mapping in the case of correlated pattern HNs, which are more broadly applicable to existing datasets. Specifically, we show that any HN with $N$ binary variables and $p<N$ potentially correlated binary patterns can be transformed into an RBM with $N$ binary visible variables and $p$ gaussian hidden variables. We outline the conditions under which the reverse mapping exists, and conduct experiments on the MNIST dataset which suggest the mapping provides a useful initialization to the RBM weights. We discuss extensions, the potential importance of this correspondence for the training of RBMs, and for understanding the performance of feature extraction methods which utilize RBMs.",
        "conference": "ICLR",
        "中文标题": "关于Hopfield网络与受限玻尔兹曼机之间的映射关系",
        "摘要翻译": "Hopfield网络（HNs）和受限玻尔兹曼机（RBMs）是统计物理学、机器学习和神经科学交界处的两个重要模型。最近，由于它们在统计力学形式下的相似性，HNs和RBMs之间的关系引起了人们的兴趣。之前已经注意到，在正交（“不相关”）编码模式的特殊情况下，HNs和RBMs之间存在精确的映射关系。我们在此提出了一种在相关模式HNs情况下的精确映射，这更广泛适用于现有数据集。具体来说，我们展示了任何具有$N$个二元变量和$p<N$个可能相关的二元模式的HN都可以转化为具有$N$个二元可见变量和$p$个高斯隐藏变量的RBM。我们概述了反向映射存在的条件，并在MNIST数据集上进行了实验，这些实验表明该映射为RBM权重提供了有用的初始化。我们讨论了扩展，这种对应关系对于RBMs训练的重要性，以及对于理解利用RBMs的特征提取方法性能的潜在重要性。",
        "领域": "神经网络理论、机器学习模型、统计物理与机器学习交叉研究",
        "问题": "探索Hopfield网络与受限玻尔兹曼机在相关模式下的精确映射关系及其应用。",
        "动机": "研究Hopfield网络与受限玻尔兹曼机之间的映射关系，以促进对这两种模型在统计力学形式下相似性的理解，并探索这种关系在模型训练和特征提取中的应用。",
        "方法": "提出并验证了一种在相关模式Hopfield网络与受限玻尔兹曼机之间的精确映射方法，包括理论推导和MNIST数据集上的实验验证。",
        "关键词": [
            "Hopfield网络",
            "受限玻尔兹曼机",
            "统计力学",
            "模型映射",
            "特征提取"
        ],
        "涉及的技术概念": {
            "Hopfield网络": "一种全连接的递归神经网络，用于存储和检索模式，基于能量最小化原理。",
            "受限玻尔兹曼机": "一种生成式随机神经网络，由可见层和隐藏层组成，用于学习数据的概率分布。",
            "统计力学形式": "用于描述和分析Hopfield网络和受限玻尔兹曼机在统计力学框架下的行为和性质。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 589,
        "title": "On the Origin of Implicit Regularization in Stochastic Gradient Descent",
        "html": "https://iclr.cc//virtual/2021/poster/3157",
        "abstract": "For infinitesimal learning rates, stochastic gradient descent (SGD) follows the path of gradient flow on the full batch loss function. However moderately large learning rates can achieve higher test accuracies, and this generalization benefit is not explained by convergence bounds, since the learning rate which maximizes test accuracy is often larger than the learning rate which minimizes training loss. To interpret this phenomenon we prove that for SGD with random shuffling, the mean SGD iterate also stays close to the path of gradient flow if the learning rate is small and finite, but on a modified loss. This modified loss is composed of the original loss function and an implicit regularizer, which penalizes the norms of the minibatch gradients. Under mild assumptions, when the batch size is small the scale of the implicit regularization term is proportional to the ratio of the learning rate to the batch size. We verify empirically that explicitly including the implicit regularizer in the loss can enhance the test accuracy when the learning rate is small.",
        "conference": "ICLR",
        "中文标题": "论随机梯度下降中隐式正则化的起源",
        "摘要翻译": "对于极小的学习率，随机梯度下降（SGD）遵循全批量损失函数上的梯度流路径。然而，适度大的学习率可以获得更高的测试准确率，并且这种泛化益处无法通过收敛界限来解释，因为最大化测试准确率的学习率通常大于最小化训练损失的学习率。为了解释这一现象，我们证明了对于随机洗牌的SGD，如果学习率小而有限，平均SGD迭代也会保持在梯度流的路径附近，但是是在一个修改后的损失上。这个修改后的损失由原始损失函数和一个隐式正则化器组成，后者惩罚了小批量梯度的范数。在温和的假设下，当批量大小较小时，隐式正则化项的规模与学习率与批量大小的比率成正比。我们通过实验验证，当学习率较小时，显式地在损失中包含隐式正则化器可以提高测试准确率。",
        "领域": "优化算法、深度学习理论、机器学习",
        "问题": "解释随机梯度下降（SGD）中适度大的学习率为何能提高测试准确率，而这一现象无法通过传统的收敛理论解释。",
        "动机": "研究随机梯度下降中隐式正则化的起源及其对模型泛化能力的影响，以解释为何适度大的学习率能带来更好的测试性能。",
        "方法": "通过理论分析和实验验证，证明了SGD在有限学习率下会隐式地引入一个正则化项，该正则化项与小批量梯度的范数有关，并探讨了其对模型泛化能力的影响。",
        "关键词": [
            "随机梯度下降",
            "隐式正则化",
            "学习率",
            "泛化能力",
            "优化算法"
        ],
        "涉及的技术概念": {
            "随机梯度下降（SGD）": "一种常用的优化算法，用于最小化损失函数，特别是在大规模数据集上训练深度学习模型时。",
            "隐式正则化": "指优化算法在训练过程中自动引入的正则化效应，有助于提高模型的泛化能力，而无需显式地在损失函数中添加正则化项。",
            "梯度流": "描述了在连续时间极限下，梯度下降算法动态的数学概念，用于分析优化算法的行为。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 590,
        "title": "On the role of planning in model-based deep reinforcement learning",
        "html": "https://iclr.cc//virtual/2021/poster/3187",
        "abstract": "Model-based planning is often thought to be necessary for deep, careful reasoning and generalization in artificial agents. While recent successes of model-based reinforcement learning (MBRL) with deep function approximation have strengthened this hypothesis, the resulting diversity of model-based methods has also made it difficult to track which components drive success and why. In this paper, we seek to disentangle the contributions of recent methods by focusing on three questions: (1) How does planning benefit MBRL agents? (2) Within planning, what choices drive performance? (3) To what extent does planning improve generalization? To answer these questions, we study the performance of MuZero (Schrittwieser et al., 2019), a state-of-the-art MBRL algorithm with strong connections and overlapping components with many other MBRL algorithms. We perform a number of interventions and ablations of MuZero across a wide range of environments, including control tasks, Atari, and 9x9 Go. Our results suggest the following: (1) Planning is most useful in the learning process, both for policy updates and for providing a more useful data distribution. (2) Using shallow trees with simple Monte-Carlo rollouts is as performant as more complex methods, except in the most difficult reasoning tasks. (3) Planning alone is insufficient to drive strong generalization. These results indicate where and how to utilize planning in reinforcement learning settings, and highlight a number of open questions for future MBRL research.",
        "conference": "ICLR",
        "中文标题": "论规划在基于模型的深度强化学习中的作用",
        "摘要翻译": "在人工代理中，基于模型的规划常被认为是进行深度、细致推理和泛化的必要条件。虽然近期基于模型的强化学习（MBRL）与深度函数逼近的成功加强了这一假设，但由此产生的基于模型的方法多样性也使得难以追踪哪些组件推动了成功及其原因。在本文中，我们试图通过关注三个问题来梳理近期方法的贡献：（1）规划如何使MBRL代理受益？（2）在规划中，哪些选择驱动性能？（3）规划在多大程度上改善了泛化？为了回答这些问题，我们研究了MuZero（Schrittwieser等人，2019年）的性能，这是一种与许多其他MBRL算法有强连接和重叠组件的最先进MBRL算法。我们在包括控制任务、Atari和9x9围棋在内的广泛环境中对MuZero进行了多项干预和消融研究。我们的结果表明：（1）规划在学习过程中最为有用，既用于策略更新，也用于提供更有用的数据分布。（2）使用浅树与简单的蒙特卡洛滚动在大多数情况下与更复杂的方法性能相当，除了在最困难的推理任务中。（3）仅靠规划不足以推动强泛化。这些结果指出了在强化学习设置中何处及如何利用规划，并突出了未来MBRL研究中的若干开放问题。",
        "领域": "强化学习、基于模型的强化学习、深度强化学习",
        "问题": "理解规划在基于模型的深度强化学习中的作用及其对性能和泛化的影响",
        "动机": "探索规划在MBRL中的具体贡献，以指导未来研究和应用中的规划策略选择",
        "方法": "通过对MuZero算法在不同环境下的干预和消融研究，分析规划的作用和效果",
        "关键词": [
            "基于模型的强化学习",
            "规划",
            "MuZero",
            "泛化",
            "性能分析"
        ],
        "涉及的技术概念": {
            "基于模型的强化学习（MBRL）": "一种强化学习方法，通过学习环境模型来预测状态转换和奖励，以辅助决策",
            "MuZero算法": "一种结合了模型学习和规划的先进MBRL算法，能够在未知环境中通过内部模型进行预测和规划",
            "蒙特卡洛滚动": "一种规划技术，通过模拟从当前状态开始的多个随机路径来评估行动的价值"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 591,
        "title": "On the Stability of Fine-tuning BERT: Misconceptions, Explanations, and Strong Baselines",
        "html": "https://iclr.cc//virtual/2021/poster/2558",
        "abstract": "Fine-tuning pre-trained transformer-based language models such as BERT has become a common practice dominating leaderboards across various NLP benchmarks. Despite the strong empirical performance of fine-tuned models, fine-tuning is an unstable process: training the same model with multiple random seeds can result in a large variance of the task performance. Previous literature (Devlin et al., 2019; Lee et al., 2020; Dodge et al., 2020) identified two potential reasons for the observed instability: catastrophic forgetting and small size of the fine-tuning datasets. In this paper, we show that both hypotheses fail to explain the fine-tuning instability. We analyze BERT, RoBERTa, and ALBERT, fine-tuned on commonly used datasets from the GLUE benchmark, and show that the observed instability is caused by optimization difficulties that lead to vanishing gradients. Additionally, we show that the remaining variance of the downstream task performance can be attributed to differences in generalization where fine-tuned models with the same training loss exhibit noticeably different test performance. Based on our analysis, we present a simple but strong baseline that makes fine-tuning BERT-based models significantly more stable than the previously proposed approaches. Code to reproduce our results is available online: https://github.com/uds-lsv/bert-stable-fine-tuning.",
        "conference": "ICLR",
        "中文标题": "关于微调BERT的稳定性：误解、解释与强基线",
        "摘要翻译": "微调预训练的基于Transformer的语言模型，如BERT，已成为主导各种NLP基准排行榜的常见做法。尽管微调模型具有强大的实证性能，但微调是一个不稳定的过程：使用多个随机种子训练同一模型可能导致任务性能的巨大差异。先前的研究（Devlin等人，2019；Lee等人，2020；Dodge等人，2020）确定了观察到的不稳定性的两个潜在原因：灾难性遗忘和微调数据集的小规模。在本文中，我们展示了这两个假设都无法解释微调的不稳定性。我们分析了BERT、RoBERTa和ALBERT，在GLUE基准常用数据集上进行了微调，并表明观察到的不稳定性是由导致梯度消失的优化困难引起的。此外，我们表明下游任务性能的剩余差异可以归因于泛化能力的差异，其中具有相同训练损失的微调模型在测试性能上表现出明显不同。基于我们的分析，我们提出了一个简单但强大的基线，使得基于BERT的模型微调比之前提出的方法显著更稳定。重现我们结果的代码可在网上获取：https://github.com/uds-lsv/bert-stable-fine-tuning。",
        "领域": "自然语言处理与预训练模型微调",
        "问题": "解决预训练语言模型微调过程中的不稳定性问题",
        "动机": "探索并解释BERT等预训练模型微调过程中性能不稳定的原因，并提出更稳定的微调方法",
        "方法": "通过分析BERT、RoBERTa和ALBERT在GLUE基准上的微调过程，识别导致不稳定的优化困难，并提出一种新的基线方法以提高微调稳定性",
        "关键词": [
            "BERT微调",
            "模型稳定性",
            "梯度消失",
            "优化困难",
            "泛化能力"
        ],
        "涉及的技术概念": {
            "灾难性遗忘": "在微调过程中，模型可能会忘记预训练阶段学习到的知识，导致性能下降",
            "梯度消失": "在深度神经网络训练过程中，梯度可能会变得非常小，导致模型参数更新缓慢或停止，影响训练效果",
            "泛化能力": "模型在未见数据上的表现能力，微调过程中相同训练损失下模型可能表现出不同的测试性能"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 592,
        "title": "On the Theory of Implicit Deep Learning: Global Convergence with Implicit Layers",
        "html": "https://iclr.cc//virtual/2021/poster/2935",
        "abstract": "A deep equilibrium model uses implicit layers, which are implicitly defined through an equilibrium point of an infinite sequence of computation. It avoids any explicit computation of the infinite sequence by finding an equilibrium point directly via root-finding and by computing gradients via implicit differentiation. In this paper, we analyze the gradient dynamics of deep equilibrium models with nonlinearity only on weight matrices and non-convex objective functions of weights for regression and classification. Despite non-convexity, convergence to global optimum at a linear rate is guaranteed without any assumption on the width of the models, allowing the width to be smaller than the output dimension and the number of data points. Moreover, we prove a relation between the gradient dynamics of the deep implicit layer and the dynamics of trust region Newton method of a shallow explicit layer. This mathematically proven relation along with our numerical observation suggests the importance of understanding implicit bias of implicit layers and an open problem on the topic. Our proofs deal with implicit layers, weight tying and nonlinearity on weights, and differ from those in the related literature.\n\n",
        "conference": "ICLR",
        "中文标题": "隐式深度学习理论探讨：隐式层的全局收敛性",
        "摘要翻译": "深度平衡模型采用隐式层，这些隐式层通过无限计算序列的平衡点隐式定义。它通过直接寻找平衡点（通过根查找）和通过隐式微分计算梯度，避免了无限序列的任何显式计算。在本文中，我们分析了深度平衡模型的梯度动态，其中仅在权重矩阵上应用非线性，并对回归和分类的权重使用非凸目标函数。尽管存在非凸性，我们保证了在没有对模型宽度做任何假设的情况下，以线性速率收敛到全局最优，允许宽度小于输出维度和数据点的数量。此外，我们证明了深度隐式层的梯度动态与浅显式层的信任域牛顿法动态之间的关系。这一数学证明的关系以及我们的数值观察表明，理解隐式层的隐式偏差和该主题上的开放问题的重要性。我们的证明处理了隐式层、权重绑定和权重的非线性，与相关文献中的证明不同。",
        "领域": "深度学习理论、优化算法、隐式模型",
        "问题": "探讨深度平衡模型在非凸目标函数下的全局收敛性问题",
        "动机": "研究隐式层在深度学习中的理论性质，特别是在非凸优化条件下的全局收敛性",
        "方法": "通过分析深度平衡模型的梯度动态，结合隐式微分和根查找技术，研究其在回归和分类任务中的表现",
        "关键词": [
            "深度平衡模型",
            "隐式层",
            "全局收敛",
            "非凸优化",
            "隐式微分"
        ],
        "涉及的技术概念": {
            "隐式层": "通过无限计算序列的平衡点隐式定义的层，避免了显式计算无限序列",
            "隐式微分": "用于计算隐式层梯度的方法，直接通过平衡点求解",
            "非凸优化": "在非凸目标函数下研究模型的优化行为，保证全局收敛性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 593,
        "title": "On the Transfer of Disentangled Representations in Realistic Settings",
        "html": "https://iclr.cc//virtual/2021/poster/2681",
        "abstract": "Learning meaningful representations that disentangle the underlying structure of the data generating process is considered to be of key importance in machine learning. While disentangled representations were found to be useful for diverse tasks such as abstract reasoning and fair classification, their scalability and real-world impact remain questionable.\nWe introduce a new high-resolution dataset with 1M simulated images and over 1,800 annotated real-world images of the same setup. In contrast to previous work, this new dataset exhibits correlations, a complex underlying structure, and allows to evaluate transfer to unseen simulated and real-world settings where the encoder i) remains in distribution or ii) is out of distribution.\nWe propose new architectures in order to scale disentangled representation learning to realistic high-resolution settings and conduct a large-scale empirical study of disentangled representations on this dataset. We observe that disentanglement is a good predictor for out-of-distribution (OOD) task performance.",
        "conference": "ICLR",
        "中文标题": "论在现实环境中解耦表示的迁移",
        "摘要翻译": "学习能够解耦数据生成过程潜在结构的有意义表示，在机器学习中被认为是至关重要的。虽然解耦表示被发现对于抽象推理和公平分类等多种任务有用，但其可扩展性和现实世界的影响仍然存疑。我们引入了一个新的高分辨率数据集，包含100万张模拟图像和超过1800张相同设置的注释真实世界图像。与之前的工作相比，这个新数据集展示了相关性、复杂的潜在结构，并允许评估在编码器i)保持在分布内或ii)超出分布的情况下，向未见过的模拟和真实世界环境的迁移。我们提出了新的架构，以便将解耦表示学习扩展到现实的高分辨率环境，并在这个数据集上进行了解耦表示的大规模实证研究。我们观察到，解耦是超出分布（OOD）任务性能的良好预测指标。",
        "领域": "表示学习、计算机视觉、迁移学习",
        "问题": "解耦表示在现实环境中的可扩展性和实际应用效果问题",
        "动机": "探索解耦表示在复杂现实环境中的有效性和迁移能力",
        "方法": "引入高分辨率数据集，提出新架构进行大规模实证研究",
        "关键词": [
            "解耦表示",
            "高分辨率数据集",
            "迁移学习",
            "超出分布性能",
            "表示学习"
        ],
        "涉及的技术概念": {
            "解耦表示": "指能够分离数据生成过程中不同因素的表示，有助于提高模型的解释性和泛化能力",
            "超出分布（OOD）": "指模型在处理与训练数据分布不同的数据时的性能，解耦表示被证明能有效预测OOD性能",
            "高分辨率数据集": "新引入的数据集包含高分辨率图像，旨在支持解耦表示在现实环境中的研究和应用"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 594,
        "title": "On the Universality of Rotation Equivariant Point Cloud Networks",
        "html": "https://iclr.cc//virtual/2021/poster/3011",
        "abstract": "Learning functions on point clouds has applications in many fields, including computer vision, computer graphics, physics, and chemistry. Recently, there has been a growing interest in neural architectures that are invariant or equivariant to all three shape-preserving transformations of point clouds: translation, rotation, and permutation. In this paper, we present a first study of the approximation power of these architectures. We first derive two sufficient conditions for an equivariant architecture to have the universal approximation property, based on a novel characterization of the space of equivariant polynomials. We then use these conditions to show that two recently suggested models, Tensor field Networks and SE3-Transformers, are universal, and for devising two other novel universal architectures.",
        "conference": "ICLR",
        "中文标题": "论旋转等变点云网络的普遍性",
        "摘要翻译": "学习点云上的函数在计算机视觉、计算机图形学、物理学和化学等多个领域都有应用。最近，对于能够对所有三种保持形状的点云变换（平移、旋转和排列）保持不变或等变的神经架构的兴趣日益增长。在本文中，我们首次对这些架构的近似能力进行了研究。我们首先基于对等变多项式空间的新颖描述，推导出两个充分条件，以确保一个等变架构具有普遍近似性质。然后，我们利用这些条件证明了两个最近提出的模型——张量场网络和SE3变换器——是普遍的，并且用于设计另外两个新颖的普遍架构。",
        "领域": "点云处理、三维视觉、几何深度学习",
        "问题": "研究点云网络中旋转等变架构的普遍近似能力",
        "动机": "探索和证明点云处理中旋转等变神经网络的普遍近似性质，以推动其在多个领域的应用",
        "方法": "基于对等变多项式空间的新描述，推导普遍近似性质的充分条件，并应用于现有和新型架构的分析与设计",
        "关键词": [
            "旋转等变",
            "点云网络",
            "普遍近似",
            "张量场网络",
            "SE3变换器"
        ],
        "涉及的技术概念": {
            "旋转等变": "指网络对输入点云的旋转操作具有等变性，即旋转输入会导致输出以可预测的方式变化",
            "普遍近似性质": "指网络能够以任意精度近似任何给定的函数，是衡量网络表达能力的重要指标",
            "等变多项式空间": "由满足特定等变性质的多项式构成的空间，为分析和设计等变网络提供了理论基础"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 595,
        "title": "On the Universality of the Double Descent Peak in Ridgeless Regression",
        "html": "https://iclr.cc//virtual/2021/poster/2611",
        "abstract": "We prove a non-asymptotic distribution-independent lower bound for the expected mean squared generalization error caused by label noise in ridgeless linear regression. Our lower bound generalizes a similar known result to the overparameterized (interpolating) regime. In contrast to most previous works, our analysis applies to a broad class of input distributions with almost surely full-rank feature matrices, which allows us to cover various types of deterministic or random feature maps. Our lower bound is asymptotically sharp and implies that in the presence of label noise, ridgeless linear regression does not perform well around the interpolation threshold for any of these feature maps. We analyze the imposed assumptions in detail and provide a theory for analytic (random) feature maps. Using this theory, we can show that our assumptions are satisfied for input distributions with a (Lebesgue) density and feature maps given by random deep neural networks with analytic activation functions like sigmoid, tanh, softplus or GELU. As further examples, we show that feature maps from random Fourier features and polynomial kernels also satisfy our assumptions. We complement our theory with further experimental and analytic results.",
        "conference": "ICLR",
        "中文标题": "关于无脊回归中双下降峰普遍性的研究",
        "摘要翻译": "我们证明了在无脊线性回归中，由标签噪声引起的期望均方泛化误差的非渐近、分布无关的下界。我们的下界将类似已知结果推广到了过参数化（插值）区域。与大多数先前的工作不同，我们的分析适用于一类广泛的输入分布，这些分布的特征矩阵几乎肯定是满秩的，这使得我们能够覆盖各种类型的确定性或随机特征映射。我们的下界在渐近意义上是尖锐的，并且意味着在存在标签噪声的情况下，对于任何这些特征映射，无脊线性回归在插值阈值附近表现不佳。我们详细分析了所施加的假设，并为解析（随机）特征映射提供了理论。利用这一理论，我们可以证明，对于具有（Lebesgue）密度的输入分布和由具有解析激活函数（如sigmoid、tanh、softplus或GELU）的随机深度神经网络给出的特征映射，我们的假设是满足的。作为进一步的例子，我们展示了来自随机傅里叶特征和多项式核的特征映射也满足我们的假设。我们用进一步的实验和解析结果补充了我们的理论。",
        "领域": "机器学习理论、回归分析、神经网络",
        "问题": "研究无脊线性回归在过参数化区域中由标签噪声引起的泛化误差下界",
        "动机": "探索在存在标签噪声的情况下，无脊线性回归在插值阈值附近的性能表现，以及不同特征映射对这一性能的影响",
        "方法": "通过非渐近、分布无关的分析方法，推广已知结果到过参数化区域，并详细分析假设条件，为解析特征映射提供理论支持",
        "关键词": [
            "无脊回归",
            "泛化误差",
            "过参数化",
            "标签噪声",
            "特征映射"
        ],
        "涉及的技术概念": {
            "无脊线性回归": "一种不包含正则化项的线性回归方法，用于研究过参数化模型的行为",
            "泛化误差": "模型在未见数据上的表现与训练数据上表现的差异，用于衡量模型的泛化能力",
            "特征映射": "将输入数据转换到高维空间的函数，用于增强模型的表达能力或实现非线性分离"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 596,
        "title": "OPAL: Offline Primitive Discovery for Accelerating Offline Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2021/poster/3234",
        "abstract": "Reinforcement learning (RL) has achieved impressive performance in a variety of online settings in which an agent’s ability to query the environment for transitions and rewards is effectively unlimited. However, in many practical applications, the situation is reversed:  an agent may have access to large amounts of undirected offline experience data, while access to the online environment is severely limited. In this work, we focus on this offline setting. Our main insight is that, when presented with offline data composed of a variety of behaviors, an effective way to leverage this data is to extract a continuous space of recurring and temporally extended primitive behaviors before using these primitives for downstream task learning.  Primitives extracted in this way serve two purposes:  they delineate the behaviors that are supported by the data from those that are not, making them useful for avoiding distributional shift in offline RL; and they provide a degree of temporal abstraction, which reduces the effective horizon yielding better learning in theory, and improved offline RL in practice. In addition to benefiting offline policy optimization, we show that performing offline primitive learning in this way can also be leveraged for improving few-shot imitation learning as well as exploration and transfer in online RL on a variety of benchmark domains. Visualizations and code are available at https://sites.google.com/view/opal-iclr",
        "conference": "ICLR",
        "中文标题": "OPAL：离线原始行为发现以加速离线强化学习",
        "摘要翻译": "强化学习（RL）在多种在线设置中展现了令人印象深刻的性能，其中智能体查询环境以获取状态转移和奖励的能力实际上是无限的。然而，在许多实际应用中，情况恰恰相反：智能体可能拥有大量无导向的离线经验数据，而对在线环境的访问则受到严格限制。在这项工作中，我们专注于这种离线设置。我们的主要见解是，当面对由各种行为组成的离线数据时，利用这些数据的一个有效方法是在将这些原始行为用于下游任务学习之前，提取一个连续的、重复的且时间上延展的原始行为空间。以这种方式提取的原始行为有两个目的：它们划定了数据支持的行为与不支持的行为之间的界限，这对于避免离线RL中的分布偏移非常有用；并且它们提供了一定程度的时间抽象，这在理论上减少了有效视野，从而实现了更好的学习，在实践中也改善了离线RL。除了有利于离线策略优化外，我们还展示了以这种方式进行离线原始行为学习也可以用于改善少量样本模仿学习以及在多种基准领域中的在线RL的探索和迁移。可视化和代码可在https://sites.google.com/view/opal-iclr获取。",
        "领域": "离线强化学习、模仿学习、探索与迁移学习",
        "问题": "如何在离线数据中发现和利用原始行为以加速和改善离线强化学习的效果",
        "动机": "解决在离线设置中，智能体无法频繁与环境交互时，如何有效利用大量离线数据来提升学习效率和性能的问题",
        "方法": "通过提取连续空间中的重复和时间上延展的原始行为，利用这些原始行为进行下游任务学习，以避免分布偏移并提供时间抽象",
        "关键词": [
            "离线强化学习",
            "原始行为发现",
            "时间抽象",
            "分布偏移",
            "模仿学习"
        ],
        "涉及的技术概念": {
            "离线强化学习": "在无法频繁与环境交互的情况下，利用离线数据进行强化学习的技术",
            "原始行为发现": "从离线数据中提取重复且时间上延展的行为模式，用于下游任务学习",
            "时间抽象": "通过原始行为提供的时间抽象，减少有效视野，从而在理论上实现更好的学习效果"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 597,
        "title": "Open Question Answering over Tables and Text",
        "html": "https://iclr.cc//virtual/2021/poster/2617",
        "abstract": "In open question answering (QA), the answer to a question is produced by retrieving and then analyzing documents that might contain answers to the question.  Most open QA systems have considered only retrieving information from unstructured text.  Here we consider for the first time open QA over {\\em both} tabular and textual data and present a new large-scale dataset \\emph{Open Table-and-Text Question Answering} (OTT-QA) to evaluate performance on this task. Most questions in OTT-QA require multi-hop inference across tabular data and unstructured text, and the evidence required to answer a question can be distributed in different ways over these two types of input, making evidence retrieval challenging---our baseline model using an iterative retriever and BERT-based reader achieves an exact match score less than 10\\%. We then propose two novel techniques to address the challenge of retrieving and aggregating evidence for OTT-QA. The first technique is to use ``early fusion'' to group multiple highly relevant tabular and textual units into a fused block, which provides more context for the retriever to search for.  The second technique is to use a cross-block reader to model the cross-dependency between multiple retrieved evidence with global-local sparse attention. Combining these two techniques improves the score significantly, to above 27\\%.",
        "conference": "ICLR",
        "中文标题": "开放性问题解答：表格与文本的结合",
        "摘要翻译": "在开放性问题解答（QA）中，问题的答案是通过检索并分析可能包含答案的文档来产生的。大多数开放QA系统仅考虑从非结构化文本中检索信息。本文首次考虑了同时从表格和文本数据中进行开放QA，并提出了一个新的大规模数据集《开放表格与文本问题解答》（OTT-QA）来评估此任务的性能。OTT-QA中的大多数问题需要在表格数据和非结构化文本之间进行多跳推理，且回答问题的证据可能以不同方式分布在这两种类型的输入中，这使得证据检索具有挑战性——我们使用迭代检索器和基于BERT的阅读器的基线模型实现的精确匹配分数不到10%。然后，我们提出了两种新技术来解决OTT-QA中检索和聚合证据的挑战。第一种技术是使用“早期融合”将多个高度相关的表格和文本单元分组到一个融合块中，这为检索器提供了更多的上下文来搜索。第二种技术是使用跨块阅读器通过全局-局部稀疏注意力来建模多个检索证据之间的跨依赖关系。结合这两种技术，分数显著提高，达到27%以上。",
        "领域": "自然语言处理与视觉结合、信息检索、多模态学习",
        "问题": "如何有效地从表格和文本数据中检索和聚合信息以回答开放性问题",
        "动机": "解决现有开放QA系统仅从非结构化文本中检索信息的局限性，探索表格和文本数据结合的开放QA任务",
        "方法": "提出早期融合技术和跨块阅读器，结合迭代检索器和基于BERT的阅读器，优化证据检索和聚合过程",
        "关键词": [
            "开放性问题解答",
            "表格与文本",
            "多跳推理",
            "早期融合",
            "跨块阅读器"
        ],
        "涉及的技术概念": {
            "早期融合": "将多个高度相关的表格和文本单元分组到一个融合块中，为检索器提供更多上下文",
            "跨块阅读器": "通过全局-局部稀疏注意力建模多个检索证据之间的跨依赖关系",
            "多跳推理": "在表格数据和非结构化文本之间进行多次推理以回答问题"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 598,
        "title": "Optimal Conversion of Conventional Artificial Neural Networks to Spiking Neural Networks",
        "html": "https://iclr.cc//virtual/2021/poster/2644",
        "abstract": "Spiking neural networks (SNNs) are biology-inspired artificial neural networks (ANNs) that comprise of spiking neurons to process asynchronous discrete signals. While more efficient in power consumption and inference speed on the neuromorphic hardware, SNNs are usually difficult to train directly from scratch with spikes due to the discreteness. As an alternative, many efforts have been devoted to converting conventional ANNs into SNNs by copying the weights from ANNs and adjusting the spiking threshold potential of neurons in SNNs. Researchers have designed new SNN architectures and conversion algorithms to diminish the conversion error. However, an effective conversion should address the difference between the SNN and ANN architectures with an efficient approximation of the loss function, which is missing in the field. In this work, we analyze the conversion error by recursive reduction to layer-wise summation and propose a novel strategic pipeline that transfers the weights to the target SNN by combining threshold balance and soft-reset mechanisms. This pipeline enables almost no accuracy loss between the converted SNNs and conventional ANNs with only $\\sim1/10$ of the typical SNN simulation time. Our method is promising to get implanted onto embedded platforms with better support of SNNs with limited energy and memory. Codes are available at https://github.com/Jackn0/snn_optimal_conversion_pipeline.",
        "conference": "ICLR",
        "中文标题": "传统人工神经网络到脉冲神经网络的最优转换",
        "摘要翻译": "脉冲神经网络（SNNs）是受生物学启发的人工神经网络（ANNs），由脉冲神经元组成，用于处理异步离散信号。尽管在神经形态硬件上功耗和推理速度更为高效，但由于离散性，SNNs通常难以直接从脉冲开始训练。作为替代方案，许多努力致力于通过复制ANNs的权重并调整SNNs中神经元的脉冲阈值电位，将传统ANNs转换为SNNs。研究人员设计了新的SNN架构和转换算法以减少转换误差。然而，有效的转换应通过高效近似损失函数来解决SNN和ANN架构之间的差异，这一领域尚存不足。在这项工作中，我们通过递归减少到逐层求和来分析转换误差，并提出了一种新颖的策略管道，该管道通过结合阈值平衡和软重置机制将权重转移到目标SNN。这一管道使得转换后的SNNs与传统ANNs之间的准确度损失几乎为零，且仅需典型SNN模拟时间的约1/10。我们的方法有望植入到嵌入式平台上，更好地支持能量和内存有限的SNNs。代码可在https://github.com/Jackn0/snn_optimal_conversion_pipeline获取。",
        "领域": "神经形态计算、脉冲神经网络、深度学习优化",
        "问题": "如何高效且准确地将传统人工神经网络转换为脉冲神经网络",
        "动机": "解决脉冲神经网络直接训练困难的问题，通过转换方法利用现有ANN的优势",
        "方法": "通过分析转换误差并提出结合阈值平衡和软重置机制的策略管道，实现高效转换",
        "关键词": [
            "脉冲神经网络",
            "神经网络转换",
            "阈值平衡",
            "软重置机制",
            "神经形态硬件"
        ],
        "涉及的技术概念": {
            "脉冲神经网络（SNNs）": "受生物学启发的神经网络，使用脉冲神经元处理异步离散信号，适合神经形态硬件",
            "阈值平衡": "调整神经元的脉冲阈值电位，以减少转换误差",
            "软重置机制": "在神经元发放脉冲后不完全重置其电位，以保持信息连续性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 599,
        "title": "Optimal Rates for Averaged Stochastic Gradient Descent under Neural Tangent Kernel Regime",
        "html": "https://iclr.cc//virtual/2021/poster/2592",
        "abstract": "We analyze the convergence of the averaged stochastic gradient descent for overparameterized two-layer neural networks for regression problems. It was recently found that a neural tangent kernel (NTK) plays an important role in showing the global convergence of gradient-based methods under the NTK regime, where the learning dynamics for overparameterized neural networks can be almost characterized by that for the associated reproducing kernel Hilbert space (RKHS). However, there is still room for a convergence rate analysis in the NTK regime. In this study, we show that the averaged stochastic gradient descent can achieve the minimax optimal convergence rate, with the global convergence guarantee, by exploiting the complexities of the target function and the RKHS associated with the NTK. Moreover, we show that the target function specified by the NTK of a ReLU network can be learned at the optimal convergence rate through a smooth approximation of a ReLU network under certain conditions.",
        "conference": "ICLR",
        "中文标题": "神经正切核机制下平均随机梯度下降的最优速率",
        "摘要翻译": "我们分析了用于回归问题的过参数化两层神经网络的平均随机梯度下降的收敛性。最近发现，神经正切核（NTK）在显示基于梯度的方法在NTK机制下的全局收敛性中起着重要作用，其中过参数化神经网络的学习动态几乎可以通过相关的再生核希尔伯特空间（RKHS）来表征。然而，在NTK机制下，收敛速率分析仍有研究空间。在本研究中，我们通过利用目标函数和与NTK相关的RKHS的复杂性，展示了平均随机梯度下降可以在保证全局收敛性的情况下达到极小极大最优收敛速率。此外，我们表明，在某些条件下，通过ReLU网络的平滑近似，可以以最优收敛速率学习由ReLU网络的NTK指定的目标函数。",
        "领域": "深度学习理论、神经网络优化、回归分析",
        "问题": "在神经正切核（NTK）机制下，分析平均随机梯度下降（ASGD）的收敛速率，并证明其可以达到极小极大最优收敛速率。",
        "动机": "尽管NTK在理解过参数化神经网络的全局收敛性方面取得了进展，但在NTK机制下的收敛速率分析尚未充分探索，本研究旨在填补这一空白。",
        "方法": "通过分析目标函数和与NTK相关的RKHS的复杂性，证明了ASGD在NTK机制下可以达到极小极大最优收敛速率，并通过ReLU网络的平滑近似实现了目标函数的最优学习。",
        "关键词": [
            "神经正切核",
            "平均随机梯度下降",
            "过参数化神经网络",
            "收敛速率",
            "再生核希尔伯特空间"
        ],
        "涉及的技术概念": {
            "神经正切核（NTK）": "用于描述过参数化神经网络在训练初期动态的核函数，本研究利用NTK证明了梯度下降方法的全局收敛性。",
            "平均随机梯度下降（ASGD）": "一种优化算法，通过平均随机梯度下降的迭代步骤来加速收敛，本研究证明了其在NTK机制下的最优收敛速率。",
            "再生核希尔伯特空间（RKHS）": "与NTK相关的函数空间，本研究通过分析RKHS的复杂性，展示了ASGD的收敛行为。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 600,
        "title": "Optimal Regularization can Mitigate Double Descent",
        "html": "https://iclr.cc//virtual/2021/poster/2540",
        "abstract": "Recent empirical and theoretical studies have shown that many learning algorithms -- from linear regression to neural networks -- can have test performance that is non-monotonic in quantities such the sample size and model size. This striking phenomenon, often referred to as 'double descent', has raised questions of if we need to re-think our current understanding of generalization. In this work, we study whether the double-descent phenomenon can be avoided by using optimal regularization. Theoretically, we prove that for certain linear regression models with isotropic data distribution, optimally-tuned $\\ell_2$ regularization achieves monotonic test performance as we grow either the sample size or the model size.\nWe also demonstrate empirically that optimally-tuned $\\ell_2$ regularization can mitigate double descent for more general models, including neural networks.\nOur results suggest that it may also be informative to study the test risk scalings of various algorithms in the context of appropriately tuned regularization.",
        "conference": "ICLR",
        "中文标题": "最优正则化可以缓解双下降现象",
        "摘要翻译": "近期的实证和理论研究显示，许多学习算法——从线性回归到神经网络——在样本量和模型大小等量上的测试性能可以是非单调的。这一引人注目的现象，常被称为‘双下降’，引发了关于我们是否需要重新思考当前对泛化理解的疑问。在本研究中，我们探讨了是否可以通过使用最优正则化来避免双下降现象。理论上，我们证明了对于某些具有各向同性数据分布的线性回归模型，最优调整的ℓ2正则化能够在样本量或模型大小增长时实现单调的测试性能。我们还通过实证表明，最优调整的ℓ2正则化可以缓解更一般模型（包括神经网络）的双下降现象。我们的结果表明，在适当调整正则化的背景下研究各种算法的测试风险缩放也可能是有益的。",
        "领域": "机器学习理论、深度学习优化、正则化技术",
        "问题": "探讨最优正则化是否可以避免学习算法中的双下降现象",
        "动机": "理解并解决学习算法在样本量和模型大小增加时测试性能非单调变化的问题",
        "方法": "理论证明和实证分析结合，研究最优ℓ2正则化对双下降现象的影响",
        "关键词": [
            "双下降现象",
            "最优正则化",
            "ℓ2正则化",
            "测试性能",
            "泛化能力"
        ],
        "涉及的技术概念": {
            "双下降现象": "描述学习算法在样本量或模型大小增加时测试性能先下降后上升的现象",
            "ℓ2正则化": "一种通过在损失函数中添加权重向量的ℓ2范数平方项来防止过拟合的技术",
            "泛化能力": "模型在未见数据上的表现能力，是衡量学习算法好坏的重要标准"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 601,
        "title": "Optimism in Reinforcement Learning with Generalized Linear Function Approximation",
        "html": "https://iclr.cc//virtual/2021/poster/2563",
        "abstract": "We design a new provably efficient algorithm for episodic reinforcement learning with generalized linear function approximation. We analyze the algorithm under a new expressivity assumption that we call ``optimistic closure,'' which is strictly weaker than assumptions from prior analyses for the linear setting. With optimistic closure, we prove that our algorithm enjoys a regret bound of $\\widetilde{O}\\left(H\\sqrt{d^3 T}\\right)$ where $H$ is the horizon, $d$ is the dimensionality of the state-action features and $T$ is the number of episodes. This is the first statistically and computationally efficient algorithm for reinforcement learning with generalized linear functions.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "基于广义线性函数逼近的强化学习中的乐观性",
        "摘要翻译": "我们设计了一种新的、可证明有效的算法，用于基于广义线性函数逼近的情景强化学习。我们在一种新的表达性假设下分析该算法，我们称之为“乐观闭包”，它严格弱于先前对线性设置进行分析的假设。利用乐观闭包，我们证明我们的算法享有$\\widetilde{O}\\left(H\\sqrt{d^3 T}\\right)$的遗憾界，其中H是horizon，d是状态-动作特征的维度，T是episode的数量。这是第一个用于广义线性函数强化学习的统计和计算上高效的算法。",
        "领域": "强化学习, 函数逼近, 理论分析",
        "问题": "如何在广义线性函数逼近的情况下，设计一种在统计和计算上都高效的强化学习算法，并提供理论保证。",
        "动机": "现有的强化学习算法在处理广义线性函数逼近时，要么效率不高，要么需要过强的假设，因此需要设计一种新的算法，能够在更弱的假设下实现统计和计算上的高效性。",
        "方法": "设计了一种新的基于乐观闭包假设的强化学习算法，该算法利用广义线性函数逼近来学习策略，并通过理论分析证明了其遗憾界。",
        "关键词": [
            "强化学习",
            "广义线性函数逼近",
            "乐观闭包",
            "遗憾界",
            "高效算法"
        ],
        "涉及的技术概念": {
            "强化学习": "一种通过与环境交互来学习最优策略的机器学习方法。",
            "广义线性函数逼近": "使用广义线性函数来近似值函数或策略，以解决状态空间过大带来的维度灾难问题。"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 602,
        "title": "Optimizing Memory Placement using Evolutionary Graph Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2021/poster/2625",
        "abstract": "For deep neural network accelerators, memory movement is both energetically expensive and can bound computation. Therefore, optimal mapping of tensors to memory hierarchies is critical to performance. The growing complexity of neural networks calls for automated memory mapping instead of manual heuristic approaches; yet the search space of neural network computational graphs have previously been prohibitively large. We introduce Evolutionary Graph Reinforcement Learning (EGRL), a method designed for large search spaces, that combines graph neural networks, reinforcement learning, and evolutionary search. A set of fast, stateless policies guide the evolutionary search to improve its sample-efficiency. We train and validate our approach directly on the Intel NNP-I chip for inference. EGRL outperforms policy-gradient, evolutionary search and dynamic programming baselines on BERT, ResNet-101 and ResNet-50. We additionally achieve 28-78% speed-up compared to the native NNP-I compiler on all three workloads.  ",
        "conference": "ICLR",
        "中文标题": "利用进化图强化学习优化内存布局",
        "摘要翻译": "对于深度神经网络加速器而言，内存移动不仅能耗高，还可能限制计算性能。因此，将张量最优映射到内存层次结构对性能至关重要。神经网络日益增长的复杂性要求采用自动化的内存映射方法，而非手动启发式方法；然而，神经网络计算图的搜索空间之前一直大得令人望而却步。我们介绍了进化图强化学习（EGRL），这是一种专为大搜索空间设计的方法，它结合了图神经网络、强化学习和进化搜索。一组快速、无状态的策略指导进化搜索，以提高其样本效率。我们直接在英特尔NNP-I芯片上进行推理训练和验证我们的方法。EGRL在BERT、ResNet-101和ResNet-50上优于策略梯度、进化搜索和动态编程基线。此外，与原生NNP-I编译器相比，我们在所有三个工作负载上实现了28-78%的速度提升。",
        "领域": "神经网络加速器优化、内存管理自动化、高性能计算",
        "问题": "如何高效自动化地将神经网络中的张量映射到内存层次结构，以减少内存移动的能耗并提升计算性能。",
        "动机": "随着神经网络复杂度的增加，传统手动启发式方法难以应对大规模内存映射的搜索空间，需要开发自动化且高效的解决方案。",
        "方法": "结合图神经网络、强化学习和进化搜索，提出进化图强化学习（EGRL）方法，利用快速无状态策略指导进化搜索，提高样本效率。",
        "关键词": [
            "进化图强化学习",
            "内存映射优化",
            "神经网络加速器",
            "自动化内存管理",
            "高性能计算"
        ],
        "涉及的技术概念": {
            "图神经网络": "用于处理神经网络计算图的结构信息，帮助模型理解数据间的复杂关系。",
            "强化学习": "通过奖励机制优化内存映射策略，以实现性能最大化。",
            "进化搜索": "在大规模搜索空间中高效寻找最优解的策略，通过模拟自然选择过程优化解决方案。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 603,
        "title": "Orthogonalizing Convolutional Layers with the Cayley Transform",
        "html": "https://iclr.cc//virtual/2021/poster/3293",
        "abstract": "Recent work has highlighted several advantages of enforcing orthogonality in the weight layers of deep networks, such as maintaining the stability of activations, preserving gradient norms, and enhancing adversarial robustness by enforcing low Lipschitz constants. Although numerous methods exist for enforcing the orthogonality of fully-connected layers, those for convolutional layers are more heuristic in nature, often focusing on penalty methods or limited classes of convolutions. In this work, we propose and evaluate an alternative approach to directly parameterize convolutional layers that are constrained to be orthogonal. Specifically, we propose to apply the Cayley transform to a skew-symmetric convolution in the Fourier domain, so that the inverse convolution needed by the Cayley transform can be computed efficiently. We compare our method to previous Lipschitz-constrained and orthogonal convolutional layers and show that it indeed preserves orthogonality to a high degree even for large convolutions. Applied to the problem of certified adversarial robustness, we show that networks incorporating the layer outperform existing deterministic methods for certified defense against $\\ell_2$-norm-bounded adversaries, while scaling to larger architectures than previously investigated. Code is available at https://github.com/locuslab/orthogonal-convolutions.",
        "conference": "ICLR",
        "中文标题": "使用凯莱变换正交化卷积层",
        "摘要翻译": "最近的研究强调了在深度网络的权重层中实施正交性的几个优势，例如保持激活的稳定性、保留梯度范数以及通过实施低Lipschitz常数增强对抗鲁棒性。尽管存在许多方法来实施全连接层的正交性，但卷积层的方法更为启发式，通常侧重于惩罚方法或有限类别的卷积。在这项工作中，我们提出并评估了一种直接参数化被约束为正交的卷积层的替代方法。具体来说，我们建议在傅里叶域中对斜对称卷积应用凯莱变换，以便可以高效地计算凯莱变换所需的逆卷积。我们将我们的方法与之前的Lipschitz约束和正交卷积层进行比较，并表明即使对于大型卷积，它确实能在很大程度上保持正交性。应用于认证对抗鲁棒性问题时，我们展示了包含该层的网络在认证防御ℓ2范数有界对手方面优于现有的确定性方法，同时扩展到比以前研究的更大的架构。代码可在https://github.com/locuslab/orthogonal-convolutions获取。",
        "领域": "对抗性防御、卷积神经网络、深度学习优化",
        "问题": "如何在卷积层中有效实施正交性约束，以提高网络的稳定性和对抗鲁棒性",
        "动机": "探索一种更有效的方法来直接参数化正交卷积层，以克服现有方法的启发式局限性和计算效率问题",
        "方法": "在傅里叶域中应用凯莱变换于斜对称卷积，以高效计算所需的逆卷积，从而直接参数化正交卷积层",
        "关键词": [
            "正交卷积层",
            "凯莱变换",
            "对抗鲁棒性",
            "傅里叶域",
            "斜对称卷积"
        ],
        "涉及的技术概念": {
            "凯莱变换": "用于将斜对称卷积转换为正交卷积，确保卷积层的正交性",
            "斜对称卷积": "在傅里叶域中定义的卷积类型，其特性使得凯莱变换的应用成为可能",
            "傅里叶域": "在此域中进行卷积操作，使得凯莱变换的逆卷积计算更为高效"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 604,
        "title": "Overfitting for Fun and Profit: Instance-Adaptive Data Compression",
        "html": "https://iclr.cc//virtual/2021/poster/3371",
        "abstract": "Neural data compression has been shown to outperform classical methods in terms of $RD$ performance, with results still improving rapidly.\nAt a high level, neural compression is based on an autoencoder that tries to reconstruct the input instance from a (quantized) latent representation, coupled with a prior that is used to losslessly compress these latents.\nDue to limitations on model capacity and imperfect optimization and generalization, such models will suboptimally compress test data in general.\nHowever, one of the great strengths of learned compression is that if the test-time data distribution is known and relatively low-entropy (e.g. a camera watching a static scene, a dash cam in an autonomous car, etc.), the model can easily be finetuned or adapted to this distribution, leading to improved $RD$ performance.\nIn this paper we take this concept to the extreme, adapting the full model to a single video, and sending model updates (quantized and compressed using a parameter-space prior) along with the latent representation. Unlike previous work, we finetune not only the encoder/latents but the entire model, and - during finetuning - take into account both the effect of model quantization and the additional costs incurred by sending the model updates. We evaluate an image compression model on I-frames (sampled at 2 fps) from videos of the Xiph dataset, and demonstrate that full-model adaptation improves $RD$ performance by ~1 dB, with respect to encoder-only finetuning.",
        "conference": "ICLR",
        "中文标题": "过拟合的乐趣与收益：实例自适应数据压缩",
        "摘要翻译": "神经数据压缩在率失真（RD）性能方面已被证明优于传统方法，且结果仍在迅速提升。从高层次来看，神经压缩基于一个自编码器，该自编码器试图从（量化的）潜在表示中重建输入实例，并结合一个用于无损压缩这些潜在表示的先验。由于模型容量的限制以及优化和泛化的不完美，这类模型通常会对测试数据进行次优压缩。然而，学习压缩的一个巨大优势是，如果测试时的数据分布已知且熵相对较低（例如，监控静态场景的摄像头、自动驾驶汽车中的行车记录仪等），模型可以轻松地对这一分布进行微调或适应，从而提高RD性能。在本文中，我们将这一概念推向极致，将整个模型适应于单个视频，并发送模型更新（使用参数空间先验进行量化和压缩）以及潜在表示。与之前的工作不同，我们不仅微调编码器/潜在表示，而且微调整个模型，并且在微调过程中考虑了模型量化的影响以及发送模型更新所产生的额外成本。我们在Xiph数据集的视频中以2 fps采样的I帧上评估了一个图像压缩模型，并证明全模型适应相对于仅编码器微调，将RD性能提高了约1 dB。",
        "领域": "图像压缩、深度学习、自适应学习",
        "问题": "如何通过实例自适应提高神经数据压缩的率失真性能",
        "动机": "探索在已知且低熵的测试数据分布下，通过模型微调或适应，提高神经数据压缩的性能",
        "方法": "将整个模型适应于单个视频，发送模型更新及潜在表示，并在微调过程中考虑模型量化和更新成本",
        "关键词": [
            "神经数据压缩",
            "实例自适应",
            "率失真优化",
            "模型微调",
            "量化"
        ],
        "涉及的技术概念": {
            "自编码器": "用于从量化的潜在表示中重建输入实例的基础架构",
            "率失真性能": "衡量压缩算法性能的指标，平衡压缩率和重建质量",
            "参数空间先验": "用于无损压缩模型更新的技术，优化压缩效率"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 605,
        "title": "Overparameterisation and worst-case generalisation: friend or foe?",
        "html": "https://iclr.cc//virtual/2021/poster/2683",
        "abstract": "Overparameterised neural networks have demonstrated the remarkable ability to perfectly fit training samples, while still generalising to unseen test samples. However, several recent works have revealed that such models' good average performance does not always translate to good worst-case performance: in particular, they may perform poorly on subgroups that are under-represented in the training set. In this paper, we show that in certain settings, overparameterised models' performance on under-represented subgroups may be improved via post-hoc processing. Specifically, such models' bias can be restricted to their classification layers, and manifest as structured prediction shifts for rare subgroups. We detail two post-hoc correction techniques to mitigate this bias, which operate purely on the outputs of standard model training. We empirically verify that with such post-hoc correction, overparameterisation can improve average and worst-case performance.",
        "conference": "ICLR",
        "中文标题": "过参数化与最坏情况泛化：是敌是友？",
        "摘要翻译": "过参数化的神经网络展示了完美拟合训练样本，同时仍能泛化到未见过的测试样本的显著能力。然而，最近的几项工作揭示了这类模型良好的平均性能并不总是转化为良好的最坏情况性能：特别是，它们可能在训练集中代表性不足的子组上表现不佳。在本文中，我们表明，在某些设置下，过参数化模型在代表性不足的子组上的性能可以通过事后处理得到改善。具体来说，这类模型的偏差可以限制在其分类层，并表现为对稀有子组的结构化预测偏移。我们详细介绍了两种事后校正技术来减轻这种偏差，这些技术仅基于标准模型训练的输出进行操作。我们通过实证验证，通过这种事后校正，过参数化可以提高平均和最坏情况的性能。",
        "领域": "深度学习理论、模型泛化性研究、偏差校正技术",
        "问题": "过参数化神经网络在代表性不足的子组上的性能不佳问题",
        "动机": "探索过参数化模型在最坏情况下的泛化能力，并寻找改善其在代表性不足子组上性能的方法",
        "方法": "提出并验证了两种事后校正技术，用于减轻过参数化模型在分类层中的偏差",
        "关键词": [
            "过参数化",
            "最坏情况泛化",
            "偏差校正",
            "事后处理",
            "模型泛化"
        ],
        "涉及的技术概念": {
            "过参数化": "指神经网络的参数数量远超训练样本数量，可能导致模型在训练数据上完美拟合但仍能泛化到测试数据",
            "最坏情况泛化": "评估模型在所有可能子组上的性能，特别是那些在训练集中代表性不足的子组",
            "事后校正技术": "在模型训练完成后应用的调整方法，旨在纠正模型在特定子组上的偏差，而不需要重新训练模型"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 606,
        "title": "PAC Confidence Predictions for Deep Neural Network Classifiers",
        "html": "https://iclr.cc//virtual/2021/poster/3264",
        "abstract": "A key challenge for deploying deep neural networks (DNNs) in safety critical settings is the need to provide rigorous ways to quantify their uncertainty. In this paper, we propose a novel algorithm for constructing predicted classification confidences for DNNs that comes with provable correctness guarantees. Our approach uses Clopper-Pearson confidence intervals for the Binomial distribution in conjunction with the histogram binning approach to calibrated prediction. In addition, we demonstrate how our predicted confidences can be used to enable downstream guarantees in two settings: (i) fast DNN inference, where we demonstrate how to compose a fast but inaccurate DNN with an accurate but slow DNN in a rigorous way to improve performance without sacrificing accuracy, and (ii) safe planning, where we guarantee safety when using a DNN to predict whether a given action is safe based on visual observations. In our experiments, we demonstrate that our approach can be used to provide guarantees for state-of-the-art DNNs.",
        "conference": "ICLR",
        "中文标题": "深度神经网络分类器的PAC置信度预测",
        "摘要翻译": "在安全关键环境中部署深度神经网络（DNNs）的一个关键挑战是需要提供严格的方法来量化其不确定性。本文中，我们提出了一种新颖的算法，用于构建DNNs的预测分类置信度，该算法带有可证明的正确性保证。我们的方法将二项分布的Clopper-Pearson置信区间与校准预测的直方图分箱方法结合使用。此外，我们展示了如何利用我们的预测置信度在两种设置中实现下游保证：（i）快速DNN推理，其中我们展示了如何以严格的方式将快速但不准确的DNN与准确但缓慢的DNN组合，以提高性能而不牺牲准确性，以及（ii）安全规划，其中我们保证在使用DNN基于视觉观察预测给定动作是否安全时的安全性。在我们的实验中，我们证明了我们的方法可用于为最先进的DNNs提供保证。",
        "领域": "不确定性量化、模型校准、安全关键系统",
        "问题": "如何为深度神经网络分类器提供具有严格正确性保证的置信度预测",
        "动机": "在安全关键环境中部署DNNs时，需要量化其不确定性以确保决策的可靠性和安全性",
        "方法": "结合Clopper-Pearson置信区间和直方图分箱方法，构建具有可证明正确性保证的DNN分类置信度预测算法",
        "关键词": [
            "置信度预测",
            "模型校准",
            "不确定性量化",
            "安全关键系统",
            "深度神经网络"
        ],
        "涉及的技术概念": {
            "Clopper-Pearson置信区间": "用于为二项分布提供严格的置信区间估计，确保预测置信度的统计正确性",
            "直方图分箱": "一种模型校准技术，通过将预测概率分箱来调整模型的输出，以提高其置信度的准确性",
            "安全规划": "在安全关键应用中，利用DNN的预测置信度来保证决策的安全性，特别是在基于视觉观察的动作预测中"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 607,
        "title": "Parameter-Based Value Functions",
        "html": "https://iclr.cc//virtual/2021/poster/3336",
        "abstract": "Traditional off-policy actor-critic Reinforcement Learning (RL) algorithms learn value functions of a single target policy. However, when value functions are updated to track the learned policy, they forget potentially useful information about old policies. We introduce a class of value functions called Parameter-Based Value Functions (PBVFs) whose inputs include the policy parameters. They can generalize across different policies. PBVFs can evaluate the performance of any policy given a state, a state-action pair, or a distribution over the RL agent's initial states. First we show how PBVFs yield novel off-policy policy gradient theorems. Then we derive off-policy actor-critic algorithms based on PBVFs trained by Monte Carlo or Temporal Difference methods. We show how learned PBVFs can zero-shot learn new policies that outperform any policy seen during training. Finally our algorithms are evaluated on a selection of discrete and continuous control tasks using shallow policies and deep neural networks. Their performance is comparable to state-of-the-art methods.",
        "conference": "ICLR",
        "中文标题": "基于参数的价值函数",
        "摘要翻译": "传统的离策略行动者-评论家强化学习（RL）算法学习单一目标策略的价值函数。然而，当价值函数被更新以跟踪学习到的策略时，它们会忘记关于旧策略的潜在有用信息。我们引入了一类称为基于参数的价值函数（PBVFs）的价值函数，其输入包括策略参数。它们可以跨不同策略进行泛化。PBVFs可以评估任何策略在给定状态、状态-动作对或RL代理初始状态分布下的表现。首先，我们展示了PBVFs如何产生新颖的离策略策略梯度定理。然后，我们推导出基于蒙特卡洛或时间差分方法训练的PBVFs的离策略行动者-评论家算法。我们展示了学习到的PBVFs如何零样本学习新策略，这些策略优于训练期间见过的任何策略。最后，我们的算法在使用浅层策略和深度神经网络的一系列离散和连续控制任务上进行了评估。它们的性能与最先进的方法相当。",
        "领域": "强化学习、策略优化、深度强化学习",
        "问题": "传统离策略强化学习算法在更新价值函数时会遗忘旧策略的有用信息",
        "动机": "通过引入基于参数的价值函数（PBVFs），保留并利用旧策略的信息，以提高策略的泛化能力和性能",
        "方法": "提出PBVFs概念，推导基于PBVFs的离策略策略梯度定理和行动者-评论家算法，通过蒙特卡洛或时间差分方法训练PBVFs",
        "关键词": [
            "基于参数的价值函数",
            "离策略学习",
            "策略梯度",
            "行动者-评论家算法",
            "零样本学习"
        ],
        "涉及的技术概念": {
            "基于参数的价值函数（PBVFs）": "一类输入包括策略参数的价值函数，能够跨不同策略进行泛化，评估任何策略的表现",
            "离策略策略梯度定理": "基于PBVFs推导出的定理，为离策略学习提供了理论基础",
            "零样本学习": "利用学习到的PBVFs直接学习新策略，无需额外训练数据，且性能优于训练期间见过的策略"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 608,
        "title": "Parameter Efficient Multimodal Transformers for Video Representation Learning",
        "html": "https://iclr.cc//virtual/2021/poster/2901",
        "abstract": "The recent success of Transformers in the language domain has motivated adapting it to a multimodal setting, where a new visual model is trained in tandem with an already pretrained language model. However, due to the excessive memory requirements from Transformers, existing work typically fixes the language model and train only the vision module, which limits its ability to learn cross-modal information in an end-to-end manner. In this work, we focus on reducing the parameters of multimodal Transformers in the context of audio-visual video representation learning. We alleviate the high memory requirement by sharing the parameters of Transformers across layers and modalities; we decompose the Transformer into modality-specific and modality-shared parts so that the model learns the dynamics of each modality both individually and together, and propose a novel parameter sharing scheme based on low-rank approximation. We show that our approach reduces parameters of the Transformers up to 97%, allowing us to train our model end-to-end from scratch. We also propose a negative sampling approach based on an instance similarity measured on the CNN embedding space that our model learns together with the Transformers. To demonstrate our approach, we pretrain our model on 30-second clips (480 frames) from Kinetics-700 and transfer it to audio-visual classification tasks.",
        "conference": "ICLR",
        "中文标题": "参数高效的多模态变换器用于视频表示学习",
        "摘要翻译": "变换器在语言领域的最近成功激励了将其适应到多模态环境中，其中新的视觉模型与已经预训练的语言模型同时训练。然而，由于变换器对内存的过高要求，现有工作通常固定语言模型并仅训练视觉模块，这限制了其以端到端方式学习跨模态信息的能力。在这项工作中，我们专注于在音频-视觉视频表示学习的背景下减少多模态变换器的参数。我们通过跨层和跨模态共享变换器的参数来缓解高内存需求；我们将变换器分解为模态特定和模态共享部分，以便模型分别和共同学习每个模态的动态，并提出了一种基于低秩近似的新参数共享方案。我们展示了我们的方法将变换器的参数减少了高达97%，使我们能够从头开始端到端训练我们的模型。我们还提出了一种基于CNN嵌入空间上测量的实例相似性的负采样方法，我们的模型与变换器一起学习。为了展示我们的方法，我们在来自Kinetics-700的30秒剪辑（480帧）上预训练我们的模型，并将其转移到音频-视觉分类任务中。",
        "领域": "多模态学习、视频理解、音频-视觉分类",
        "问题": "减少多模态变换器的参数需求，以支持端到端的跨模态学习",
        "动机": "现有方法因变换器的高内存需求而限制了对跨模态信息的端到端学习，本研究旨在通过参数共享和低秩近似技术解决这一问题",
        "方法": "通过跨层和跨模态共享变换器参数，分解变换器为模态特定和共享部分，并采用低秩近似进行参数共享，以及基于CNN嵌入空间实例相似性的负采样方法",
        "关键词": [
            "多模态变换器",
            "参数共享",
            "低秩近似",
            "音频-视觉分类",
            "端到端学习"
        ],
        "涉及的技术概念": {
            "多模态变换器": "用于同时处理来自不同模态（如音频和视觉）数据的变换器架构",
            "参数共享": "通过在不同层和模态间共享参数来减少模型的总参数数量",
            "低秩近似": "一种减少模型参数的技术，通过近似表示高维参数空间中的低维结构来实现"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 609,
        "title": "Parrot: Data-Driven Behavioral Priors for Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2021/poster/2862",
        "abstract": "Reinforcement learning provides a general framework for flexible decision making and control, but requires extensive data collection for each new task that an agent needs to learn. In other machine learning fields, such as natural language processing or computer vision, pre-training on large, previously collected datasets to bootstrap learning for new tasks has emerged as a powerful paradigm to reduce data requirements when learning a new task. In this paper, we ask the following question: how can we enable similarly useful pre-training for RL agents? We propose a method for pre-training behavioral priors that can capture complex input-output relationships observed in successful trials from a wide range of previously seen tasks, and we show how this learned prior can be used for rapidly learning new tasks without impeding the RL agent's ability to try out novel behaviors. We demonstrate the effectiveness of our approach in challenging robotic manipulation domains involving image observations and sparse reward functions, where our method outperforms prior works by a substantial margin. Additional materials can be found on our project website: https://sites.google.com/view/parrot-rl",
        "conference": "ICLR",
        "中文标题": "鹦鹉：强化学习的数据驱动行为先验",
        "摘要翻译": "强化学习为灵活的决策制定和控制提供了一个通用框架，但要求智能体为每个需要学习的新任务进行大量的数据收集。在其他机器学习领域，如自然语言处理或计算机视觉，利用先前收集的大型数据集进行预训练以引导新任务学习，已成为减少学习新任务时数据需求的有力范例。在本文中，我们提出以下问题：如何为强化学习智能体实现类似有用的预训练？我们提出了一种预训练行为先验的方法，这些先验能够捕捉从广泛先前任务的成功试验中观察到的复杂输入-输出关系，并且我们展示了如何利用这些学习到的先验快速学习新任务，而不妨碍强化学习智能体尝试新行为的能力。我们在涉及图像观察和稀疏奖励函数的挑战性机器人操作领域中展示了我们方法的有效性，其中我们的方法以显著优势超越了先前的工作。更多材料可以在我们的项目网站上找到：https://sites.google.com/view/parrot-rl",
        "领域": "强化学习、机器人操作、行为先验学习",
        "问题": "如何减少强化学习新任务学习时的数据需求",
        "动机": "探索如何通过预训练行为先验来减少强化学习新任务学习时的数据需求，同时不限制智能体尝试新行为的能力",
        "方法": "提出了一种预训练行为先验的方法，这些先验能够捕捉从广泛先前任务的成功试验中观察到的复杂输入-输出关系，用于快速学习新任务",
        "关键词": [
            "强化学习",
            "行为先验",
            "机器人操作",
            "预训练",
            "稀疏奖励"
        ],
        "涉及的技术概念": {
            "行为先验": "预训练的行为模型，能够捕捉从广泛先前任务的成功试验中观察到的复杂输入-输出关系，用于快速学习新任务",
            "稀疏奖励": "在强化学习中，奖励信号不频繁或难以获得的情况，增加了学习难度",
            "预训练": "利用先前收集的大型数据集进行训练，以引导新任务学习，减少学习新任务时的数据需求"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 610,
        "title": "Partitioned Learned Bloom Filters",
        "html": "https://iclr.cc//virtual/2021/poster/2672",
        "abstract": "Bloom filters are space-efficient probabilistic data structures that are used to test whether an element is a member of a set, and may return false positives.  Recently, variations referred to as learned Bloom filters were developed that can provide improved performance in terms of the rate of false positives, by using a learned model for the represented set.  However, previous methods for learned Bloom filters do not take full advantage of the learned model.  Here we show how to frame the problem of optimal model utilization as an optimization problem, and using our framework derive algorithms that can achieve near-optimal performance in many cases.",
        "conference": "ICLR",
        "中文标题": "分区学习型布隆过滤器",
        "摘要翻译": "布隆过滤器是一种空间效率高的概率数据结构，用于测试一个元素是否属于某个集合，可能会返回假阳性结果。最近，出现了被称为学习型布隆过滤器的变体，通过使用代表集合的学习模型，可以在假阳性率方面提供更好的性能。然而，之前的学习型布隆过滤器方法并未充分利用学习模型。本文展示了如何将最优模型利用问题构建为一个优化问题，并利用我们的框架推导出在许多情况下能够实现接近最优性能的算法。",
        "领域": "数据结构优化、机器学习应用、概率数据结构",
        "问题": "如何在学习型布隆过滤器中更有效地利用学习模型以减少假阳性率",
        "动机": "现有的学习型布隆过滤器未能充分利用学习模型的潜力，导致假阳性率的降低不够理想",
        "方法": "将最优模型利用问题构建为优化问题，并基于此框架推导出接近最优性能的算法",
        "关键词": [
            "学习型布隆过滤器",
            "假阳性率",
            "优化问题",
            "概率数据结构",
            "机器学习应用"
        ],
        "涉及的技术概念": {
            "学习型布隆过滤器": "一种通过使用学习模型来代表集合，以减少假阳性率的布隆过滤器变体",
            "假阳性率": "指布隆过滤器错误地认为一个不在集合中的元素属于集合的概率",
            "优化问题": "在本研究中，指的是如何最优地利用学习模型以减少假阳性率的问题"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 611,
        "title": "PC2WF: 3D Wireframe Reconstruction from Raw Point Clouds",
        "html": "https://iclr.cc//virtual/2021/poster/3169",
        "abstract": "We introduce PC2WF, the first end-to-end trainable deep network architecture to convert a 3D point cloud into a wireframe model. The network takes as input an unordered set of 3D points sampled from the surface of some object, and outputs a wireframe of that object, i.e., a sparse set of corner points linked by line segments. Recovering the wireframe is a challenging task, where the numbers of both vertices and edges are different for every instance, and a-priori unknown. Our architecture gradually builds up the model: It starts by encoding the points into feature vectors. Based on those features, it identifies a pool of candidate vertices, then prunes those candidates to a final set of corner vertices and refines their locations. Next, the corners are linked with an exhaustive set of candidate edges, which is again pruned to obtain the final wireframe. All steps are trainable, and errors can be backpropagated through the entire sequence. We validate the proposed model on a publicly available synthetic dataset, for which the ground truth wireframes are accessible, as well as on a new real-world dataset. Our model produces wireframe abstractions of good quality and outperforms several baselines.",
        "conference": "ICLR",
        "中文标题": "PC2WF：从原始点云进行三维线框重建",
        "摘要翻译": "我们介绍了PC2WF，这是第一个可端到端训练的深度网络架构，用于将三维点云转换为线框模型。该网络以从物体表面采样的无序三维点集作为输入，输出该物体的线框，即由线段连接的稀疏角点集。恢复线框是一项具有挑战性的任务，其中每个实例的顶点和边的数量都不同，且事先未知。我们的架构逐步构建模型：首先将点编码为特征向量。基于这些特征，它识别出一组候选顶点，然后对这些候选顶点进行修剪，得到最终的角点集并优化它们的位置。接着，角点通过一组详尽的候选边连接，这些边再次被修剪以获得最终的线框。所有步骤都是可训练的，并且误差可以通过整个序列反向传播。我们在一个公开可用的合成数据集上验证了所提出的模型，该数据集的真实线框是可访问的，同时也在一个新的真实世界数据集上进行了验证。我们的模型生成了质量良好的线框抽象，并优于几个基线。",
        "领域": "三维重建、点云处理、深度学习",
        "问题": "如何从无序的三维点云数据中重建出物体的线框模型",
        "动机": "解决从点云数据中自动且准确地重建物体线框模型的挑战，特别是在顶点和边数量未知的情况下",
        "方法": "采用端到端可训练的深度网络架构，逐步从点云中识别和优化角点，然后连接这些角点形成线框",
        "关键词": [
            "三维重建",
            "点云处理",
            "线框模型",
            "深度学习",
            "端到端训练"
        ],
        "涉及的技术概念": {
            "端到端训练": "整个网络架构从输入到输出都是可训练的，允许误差通过整个网络反向传播",
            "特征向量编码": "将无序的三维点集编码为特征向量，为后续的角点识别和优化提供基础",
            "候选顶点修剪": "从一组候选顶点中筛选出最终的角点集，并优化它们的位置，以提高线框模型的准确性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 612,
        "title": "PDE-Driven Spatiotemporal Disentanglement",
        "html": "https://iclr.cc//virtual/2021/poster/3233",
        "abstract": "A recent line of work in the machine learning community addresses the problem of predicting high-dimensional spatiotemporal phenomena by leveraging specific tools from the differential equations theory. Following this direction, we propose in this article a novel and general paradigm for this task based on a resolution method for partial differential equations: the separation of variables. This inspiration allows us to introduce a dynamical interpretation of spatiotemporal disentanglement. It induces a principled model based on learning disentangled spatial and temporal representations of a phenomenon to accurately predict future observations. We experimentally demonstrate the performance and broad applicability of our method against prior state-of-the-art models on physical and synthetic video datasets.",
        "conference": "ICLR",
        "中文标题": "偏微分方程驱动的时空解缠",
        "摘要翻译": "机器学习领域最近的一系列工作通过利用微分方程理论中的特定工具，解决了预测高维时空现象的问题。沿着这一方向，我们在本文中提出了一个基于偏微分方程求解方法——变量分离的新颖且通用的范式。这一灵感使我们引入了对时空解缠的动态解释。它诱导了一个基于学习现象的解缠空间和时间表示的原理性模型，以准确预测未来的观测结果。我们在物理和合成视频数据集上，通过实验证明了我们的方法相对于先前最先进模型的性能和广泛适用性。",
        "领域": "时空预测、视频分析、物理现象建模",
        "问题": "如何准确预测高维时空现象",
        "动机": "利用微分方程理论中的工具改进高维时空现象的预测准确性和模型泛化能力",
        "方法": "基于偏微分方程变量分离的方法，学习解缠的空间和时间表示",
        "关键词": [
            "时空解缠",
            "偏微分方程",
            "变量分离",
            "高维预测",
            "动态解释"
        ],
        "涉及的技术概念": {
            "偏微分方程": "用于建模和预测高维时空现象的基本数学工具",
            "变量分离": "一种解决偏微分方程的方法，本文中用于解缠时空表示",
            "时空解缠": "将时空现象分解为独立的空间和时间组件，以便更准确地预测未来状态"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 613,
        "title": "Perceptual Adversarial Robustness: Defense Against Unseen Threat Models",
        "html": "https://iclr.cc//virtual/2021/poster/2860",
        "abstract": "A key challenge in adversarial robustness is the lack of a precise mathematical characterization of human perception, used in the definition of adversarial attacks that are imperceptible to human eyes. Most current attacks and defenses try to get around this issue by considering restrictive adversarial threat models such as those bounded by $L_2$ or $L_\\infty$ distance, spatial perturbations, etc. However, models that are robust against any of these restrictive threat models are still fragile against other threat models, i.e. they have poor generalization to unforeseen attacks. Moreover, even if a model is robust against the union of several restrictive threat models, it is still susceptible to other imperceptible adversarial examples that are not contained in any of the constituent threat models. To resolve these issues, we propose adversarial training against the set of all imperceptible adversarial examples. Since this set is intractable to compute without a human in the loop, we approximate it using deep neural networks. We call this threat model the neural perceptual threat model (NPTM); it includes adversarial examples with a bounded neural perceptual distance (a neural network-based approximation of the true perceptual distance) to natural images. Through an extensive perceptual study, we show that the neural perceptual distance correlates well with human judgements of perceptibility of adversarial examples, validating our threat model.\n\nUnder the NPTM, we develop novel perceptual adversarial attacks and defenses. Because the NPTM is very broad, we find that Perceptual Adversarial Training (PAT) against a perceptual attack gives robustness against many other types of adversarial attacks. We test PAT on CIFAR-10 and ImageNet-100 against five diverse adversarial attacks: $L_2$, $L_\\infty$, spatial, recoloring, and JPEG. We find that PAT achieves state-of-the-art robustness against the union of these five attacks—more than doubling the accuracy over the next best model—without training against any of them. That is, PAT generalizes well to unforeseen perturbation types. This is vital in sensitive applications where a particular threat model cannot be assumed, and to the best of our knowledge, PAT is the first adversarial defense with this property.\n\nCode and data are available at https://github.com/cassidylaidlaw/perceptual-advex",
        "conference": "ICLR",
        "success": true,
        "中文标题": "感知对抗鲁棒性：防御未知的威胁模型",
        "摘要翻译": "对抗鲁棒性中的一个关键挑战是缺乏对人类感知的精确数学描述，而人类感知被用于定义对人眼难以察觉的对抗攻击。目前大多数攻击和防御都试图通过考虑限制性的对抗威胁模型来解决这个问题，例如那些受限于L2或L∞距离、空间扰动等。然而，对于任何这些限制性威胁模型具有鲁棒性的模型仍然容易受到其他威胁模型的影响，即它们对不可预见的攻击的泛化能力较差。此外，即使一个模型对几个限制性威胁模型的联合具有鲁棒性，它仍然容易受到其他不包含在任何组成威胁模型中的难以察觉的对抗样本的影响。为了解决这些问题，我们提出针对所有难以察觉的对抗样本集进行对抗训练。由于在没有人工参与的情况下，这个集合是难以计算的，因此我们使用深度神经网络来近似它。我们称这个威胁模型为神经感知威胁模型（NPTM）；它包括对抗样本，这些对抗样本与自然图像具有有限的神经感知距离（基于神经网络的真实感知距离的近似）。通过广泛的感知研究，我们表明神经感知距离与人类对对抗样本可感知性的判断密切相关，从而验证了我们的威胁模型。\\n\\n在NPTM下，我们开发了新的感知对抗攻击和防御。由于NPTM非常广泛，我们发现针对感知攻击进行感知对抗训练（PAT）可以提供针对许多其他类型对抗攻击的鲁棒性。我们针对五种不同的对抗攻击：L2、L∞、空间、重新着色和JPEG，在CIFAR-10和ImageNet-100上测试了PAT。我们发现，PAT在对抗这五种攻击的联合方面实现了最先进的鲁棒性——比下一个最好的模型提高了两倍以上的准确率——而没有针对其中任何一种攻击进行训练。也就是说，PAT可以很好地泛化到不可预见的扰动类型。这在无法假定特定威胁模型的敏感应用中至关重要，并且据我们所知，PAT是第一个具有此属性的对抗防御。",
        "领域": "对抗攻击与防御, 图像分类, 鲁棒性",
        "问题": "如何提高模型在面对未知或未预见的对抗攻击时的鲁棒性，克服现有防御方法泛化能力差的问题。",
        "动机": "现有的对抗防御方法通常针对特定的威胁模型进行优化，导致模型在面对其他类型的对抗攻击时表现脆弱。本研究旨在开发一种能够防御各种难以察觉的对抗样本，并能很好地泛化到不可预见的扰动类型的防御方法。",
        "方法": "提出了一种基于神经感知威胁模型（NPTM）的对抗训练方法，通过使用深度神经网络近似人类的感知距离，从而生成更具泛化性的对抗样本，并使用感知对抗训练（PAT）来提高模型对多种对抗攻击的鲁棒性。",
        "关键词": [
            "对抗鲁棒性",
            "神经感知威胁模型",
            "对抗训练",
            "泛化能力",
            "感知距离"
        ],
        "涉及的技术概念": {
            "对抗训练": "一种通过在训练数据中加入对抗样本来提高模型鲁棒性的技术。论文中，对抗训练用于防御基于NPTM生成的对抗样本。",
            "神经感知威胁模型（NPTM）": "一种使用深度神经网络近似人类感知距离的对抗威胁模型。它允许生成更符合人类感知的对抗样本，并用于训练更鲁棒的模型。"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 614,
        "title": "Personalized Federated Learning with First Order Model Optimization",
        "html": "https://iclr.cc//virtual/2021/poster/3315",
        "abstract": "While federated learning traditionally aims to train a single global model across decentralized local datasets, one model may not always be ideal for all participating clients. Here we propose an alternative, where each client only federates with other relevant clients to obtain a stronger model per client-specific objectives. To achieve this personalization, rather than computing a single model average with constant weights for the entire federation as in traditional FL, we efficiently calculate optimal weighted model combinations for each client, based on figuring out how much a client can benefit from another's model. We do not assume knowledge of any underlying data distributions or client similarities, and allow each client to optimize for arbitrary target distributions of interest, enabling greater flexibility for personalization. We evaluate and characterize our method on a variety of federated settings, datasets, and degrees of local data heterogeneity. Our method outperforms existing alternatives, while also enabling new features for personalized FL such as transfer outside of local data distributions.",
        "conference": "ICLR",
        "中文标题": "基于一阶模型优化的个性化联邦学习",
        "摘要翻译": "虽然联邦学习的传统目标是在分散的本地数据集上训练一个单一的全局模型，但一个模型可能并不总是适合所有参与的客户端。在这里，我们提出了一种替代方案，其中每个客户端仅与其他相关客户端联合，以获得针对每个客户端特定目标的更强模型。为了实现这种个性化，而不是像传统联邦学习那样为整个联邦计算一个具有恒定权重的单一模型平均值，我们基于计算一个客户端能从另一个客户端的模型中获益多少，为每个客户端高效地计算最优加权模型组合。我们不假设了解任何底层数据分布或客户端相似性，并允许每个客户端针对任意感兴趣的目标分布进行优化，从而为个性化提供了更大的灵活性。我们在各种联邦设置、数据集和本地数据异构性程度上评估和描述了我们的方法。我们的方法优于现有的替代方案，同时还为个性化联邦学习提供了新功能，例如在本地数据分布之外的转移。",
        "领域": "联邦学习、个性化学习、模型优化",
        "问题": "解决联邦学习中单一全局模型无法满足所有客户端个性化需求的问题",
        "动机": "为了在联邦学习中实现更高效的个性化模型训练，满足不同客户端的特定需求",
        "方法": "通过计算每个客户端从其他客户端模型中获益的程度，为每个客户端高效地计算最优加权模型组合，实现个性化联邦学习",
        "关键词": [
            "个性化联邦学习",
            "一阶模型优化",
            "数据异构性",
            "模型组合",
            "客户端特定目标"
        ],
        "涉及的技术概念": {
            "联邦学习": "一种机器学习方法，允许多个客户端在本地数据上训练模型而不共享数据，旨在保护数据隐私",
            "一阶模型优化": "通过优化模型的一阶导数（梯度）来改进模型性能的技术，用于提高个性化联邦学习的效率",
            "数据异构性": "指不同客户端之间数据分布的差异，是联邦学习中的一个主要挑战，影响模型的泛化能力和个性化效果"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 615,
        "title": "Physics-aware, probabilistic model order reduction with guaranteed stability",
        "html": "https://iclr.cc//virtual/2021/poster/2719",
        "abstract": "Given (small amounts of) time-series' data from  a high-dimensional, fine-grained, multiscale dynamical system, we propose a generative framework for learning an effective, lower-dimensional, coarse-grained dynamical model that is predictive of the fine-grained system's long-term evolution but also of its behavior under different initial conditions.\nWe target fine-grained models as they arise in physical applications (e.g. molecular dynamics, agent-based models), the dynamics  of which are strongly non-stationary but their transition to equilibrium is governed by unknown slow processes which are largely inaccessible by brute-force simulations.\nApproaches based on domain knowledge heavily rely on physical insight in identifying temporally slow features and fail to enforce the long-term stability of the learned dynamics. On the other hand, purely statistical frameworks lack interpretability and rely on large amounts of expensive simulation data (long and multiple trajectories) as they cannot infuse domain knowledge. \nThe generative framework proposed achieves  the aforementioned desiderata by  employing a flexible prior on the complex plane for the latent, slow processes, and  an intermediate layer of physics-motivated latent variables that reduces reliance on data and imbues inductive bias. In contrast to existing schemes, it does not require  the a priori definition of projection operators from the fine-grained description and addresses simultaneously the tasks of dimensionality reduction and model estimation.\nWe demonstrate its efficacy and accuracy in multiscale physical systems of particle dynamics where probabilistic, long-term predictions of phenomena not contained in the training data are produced.",
        "conference": "ICLR",
        "中文标题": "保证稳定性的物理感知概率模型降阶",
        "摘要翻译": "给定来自高维、细粒度、多尺度动力系统的（少量）时间序列数据，我们提出了一个生成框架，用于学习一个有效的、低维的、粗粒度的动力学模型，该模型不仅能够预测细粒度系统的长期演化，还能预测其在不同初始条件下的行为。我们针对物理应用中出现的细粒度模型（如分子动力学、基于代理的模型），这些模型的动态性非常非平稳，但它们向平衡态的过渡由未知的慢过程主导，这些过程在很大程度上无法通过暴力模拟来访问。基于领域知识的方法在识别时间慢特征方面严重依赖物理洞察力，并且无法强制学习到的动态性的长期稳定性。另一方面，纯统计框架缺乏可解释性，并且依赖于大量昂贵的模拟数据（长且多轨迹），因为它们无法融入领域知识。提出的生成框架通过在复平面上为潜在的慢过程采用灵活的先前，以及一个由物理动机驱动的潜在变量中间层，实现了上述期望，减少了对数据的依赖并注入了归纳偏差。与现有方案相比，它不需要从细粒度描述中先验定义投影算子，并同时解决了降维和模型估计的任务。我们在粒子动力学的多尺度物理系统中展示了其有效性和准确性，其中产生了训练数据中未包含现象的概率性长期预测。",
        "领域": "分子动力学模拟, 多尺度建模, 动力系统降阶",
        "问题": "如何从高维多尺度动力系统的少量时间序列数据中学习一个低维粗粒度模型，该模型能够预测系统的长期演化和不同初始条件下的行为。",
        "动机": "解决现有方法在识别慢过程特征和保证长期稳定性方面的不足，以及纯统计方法对大量数据的依赖和缺乏可解释性的问题。",
        "方法": "提出一个生成框架，通过在复平面上为潜在慢过程采用灵活的先前，并引入物理动机的潜在变量中间层，减少数据依赖并注入归纳偏差。",
        "关键词": [
            "模型降阶",
            "多尺度建模",
            "生成模型",
            "动力系统",
            "物理感知"
        ],
        "涉及的技术概念": {
            "复平面上的灵活先前": "用于建模潜在慢过程的技术，允许在复平面上灵活地表示慢过程的动态性。",
            "物理动机的潜在变量中间层": "减少对数据的依赖并注入归纳偏差，帮助模型更好地理解和预测系统的动态行为。",
            "无需先验定义投影算子": "与现有方法不同，该方法不需要预先定义从细粒度描述到粗粒度描述的投影算子，简化了模型构建过程。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 616,
        "title": "Plan-Based Relaxed Reward Shaping for Goal-Directed Tasks",
        "html": "https://iclr.cc//virtual/2021/poster/3020",
        "abstract": "In high-dimensional state spaces, the usefulness of Reinforcement Learning (RL) is limited by the problem of exploration. This issue has been addressed using potential-based reward shaping (PB-RS) previously. In the present work, we introduce Final-Volume-Preserving Reward Shaping (FV-RS). FV-RS relaxes the strict optimality guarantees of PB-RS to a guarantee of preserved long-term behavior. Being less restrictive, FV-RS allows for reward shaping functions that are even better suited for improving the sample efficiency of RL algorithms. In particular, we consider settings in which the agent has access to an approximate plan. Here, we use examples of simulated robotic manipulation tasks to demonstrate that plan-based FV-RS can indeed significantly improve the sample efficiency of RL over plan-based PB-RS.",
        "conference": "ICLR",
        "中文标题": "基于计划的宽松奖励塑形用于目标导向任务",
        "摘要翻译": "在高维状态空间中，强化学习（RL）的实用性受到探索问题的限制。这一问题之前已通过基于势的奖励塑形（PB-RS）得到解决。在本工作中，我们介绍了最终体积保持奖励塑形（FV-RS）。FV-RS放宽了PB-RS的严格最优性保证，转而保证长期行为的保持。由于限制较少，FV-RS允许奖励塑形函数更适合提高RL算法的样本效率。特别是，我们考虑了代理可以访问近似计划的情况。在这里，我们使用模拟机器人操作任务的例子来证明，基于计划的FV-RS确实可以显著提高RL的样本效率，优于基于计划的PB-RS。",
        "领域": "强化学习、机器人操作、样本效率优化",
        "问题": "在高维状态空间中，强化学习的探索效率问题",
        "动机": "提高强化学习算法在高维状态空间中的样本效率",
        "方法": "引入最终体积保持奖励塑形（FV-RS），放宽基于势的奖励塑形（PB-RS）的最优性保证，以保持长期行为，从而提高样本效率",
        "关键词": [
            "奖励塑形",
            "样本效率",
            "强化学习",
            "机器人操作",
            "高维状态空间"
        ],
        "涉及的技术概念": {
            "最终体积保持奖励塑形（FV-RS）": "一种放宽了严格最优性保证的奖励塑形方法，旨在保持长期行为，提高样本效率",
            "基于势的奖励塑形（PB-RS）": "之前解决强化学习探索问题的方法，提供严格的最优性保证",
            "样本效率": "指算法在达到一定性能水平所需的样本数量，是衡量强化学习算法效率的重要指标"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 617,
        "title": "Planning from Pixels using Inverse Dynamics Models",
        "html": "https://iclr.cc//virtual/2021/poster/3067",
        "abstract": "Learning dynamics models in high-dimensional observation spaces can be challenging for model-based RL agents. We propose a novel way to learn models in a latent space by learning to predict sequences of future actions conditioned on task completion. These models track task-relevant environment dynamics over a distribution of tasks, while simultaneously serving as an effective heuristic for planning with sparse rewards. We evaluate our method on challenging visual goal completion tasks and show a substantial increase in performance compared to prior model-free approaches.",
        "conference": "ICLR",
        "中文标题": "利用逆动力学模型从像素规划",
        "摘要翻译": "在高维观察空间中学习动力学模型对于基于模型的强化学习（RL）代理来说可能具有挑战性。我们提出了一种新颖的方法，通过学习预测以任务完成为条件的未来动作序列，在潜在空间中学习模型。这些模型在一系列任务中跟踪与任务相关的环境动态，同时作为稀疏奖励规划的有效启发式方法。我们在具有挑战性的视觉目标完成任务上评估了我们的方法，并显示与之前的无模型方法相比，性能有显著提升。",
        "领域": "强化学习、视觉导航、机器人控制",
        "问题": "在高维观察空间中有效学习动力学模型以支持基于模型的强化学习",
        "动机": "解决在高维观察空间中学习动力学模型的挑战，提高基于模型的强化学习在视觉目标完成任务中的性能",
        "方法": "通过在潜在空间中学习预测未来动作序列来学习模型，这些模型能够跟踪任务相关的环境动态并作为稀疏奖励规划的有效启发式",
        "关键词": [
            "逆动力学模型",
            "潜在空间学习",
            "强化学习",
            "视觉目标完成",
            "稀疏奖励"
        ],
        "涉及的技术概念": {
            "逆动力学模型": "用于从观察到的状态变化中推断出导致这些变化的动作，支持在潜在空间中的模型学习",
            "潜在空间学习": "在高维观察数据中学习低维表示，以简化动力学模型的复杂性",
            "稀疏奖励规划": "在奖励信号稀少的环境中进行有效规划的策略，通过利用学习到的模型作为启发式来指导决策"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 618,
        "title": "PlasticineLab: A Soft-Body Manipulation Benchmark with Differentiable Physics",
        "html": "https://iclr.cc//virtual/2021/poster/2981",
        "abstract": "Simulated virtual environments serve as one of the main driving forces behind developing and evaluating skill learning algorithms. However, existing environments typically only simulate rigid body physics. Additionally, the simulation process usually does not provide gradients that might be useful for planning and control optimizations. We introduce a new differentiable physics benchmark called PasticineLab, which includes a diverse collection of soft body manipulation tasks. In each task, the agent uses manipulators to deform the plasticine into a desired configuration. The underlying physics engine supports differentiable elastic and plastic deformation using the DiffTaichi system, posing many under-explored challenges to robotic agents. We evaluate several existing reinforcement learning (RL) methods and gradient-based methods on this benchmark. Experimental results suggest that 1) RL-based approaches struggle to solve most of the tasks efficiently;  2) gradient-based approaches, by optimizing open-loop control sequences with the built-in differentiable physics engine, can rapidly find a solution within tens of iterations, but still fall short on multi-stage tasks that require long-term planning. We expect that PlasticineLab will encourage the development of novel algorithms that combine differentiable physics and RL for more complex physics-based skill learning tasks. PlasticineLab will be made publicly available.",
        "conference": "ICLR",
        "中文标题": "PlasticineLab：一个具有可微分物理特性的软体操作基准",
        "摘要翻译": "模拟虚拟环境是开发和评估技能学习算法的主要驱动力之一。然而，现有的环境通常只模拟刚体物理。此外，模拟过程通常不提供可能对规划和控制优化有用的梯度。我们引入了一个名为PasticineLab的新可微分物理基准，它包括了一系列多样化的软体操作任务。在每个任务中，代理使用操纵器将塑性材料变形为所需配置。底层物理引擎使用DiffTaichi系统支持可微分的弹性和塑性变形，为机器人代理提出了许多尚未充分探索的挑战。我们在这个基准上评估了几种现有的强化学习（RL）方法和基于梯度的方法。实验结果表明：1）基于RL的方法难以高效解决大多数任务；2）基于梯度的方法通过使用内置的可微分物理引擎优化开环控制序列，可以在数十次迭代内快速找到解决方案，但在需要长期规划的多阶段任务上仍然存在不足。我们期望PlasticineLab能够鼓励开发结合可微分物理和RL的新算法，以应对更复杂的基于物理的技能学习任务。PlasticineLab将公开提供。",
        "领域": "软体机器人操作、可微分物理模拟、强化学习应用",
        "问题": "现有虚拟环境仅模拟刚体物理且不提供梯度信息，限制了技能学习算法的发展和应用",
        "动机": "开发一个支持可微分物理的软体操作基准，以促进结合可微分物理和强化学习的算法发展",
        "方法": "引入PlasticineLab基准，包含多样化的软体操作任务，利用DiffTaichi系统支持可微分的弹性和塑性变形，评估RL和基于梯度的方法",
        "关键词": [
            "可微分物理",
            "软体操作",
            "强化学习",
            "DiffTaichi系统",
            "控制优化"
        ],
        "涉及的技术概念": {
            "可微分物理": "支持计算物理模拟过程中的梯度，便于优化和控制",
            "DiffTaichi系统": "用于实现可微分的弹性和塑性变形，为软体操作提供物理支持",
            "强化学习": "用于开发和评估在复杂物理环境中的技能学习算法"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 619,
        "title": "PMI-Masking: Principled masking of correlated spans",
        "html": "https://iclr.cc//virtual/2021/poster/2783",
        "abstract": "Masking tokens uniformly at random constitutes a common flaw in the pretraining of Masked Language Models (MLMs) such as BERT. We show that such uniform masking allows an MLM to minimize its training objective by latching onto shallow local signals, leading to pretraining inefficiency and suboptimal downstream performance. To address this flaw, we propose PMI-Masking, a principled masking strategy based on the concept of Pointwise Mutual Information (PMI), which jointly masks a token n-gram if it exhibits high collocation over the corpus. PMI-Masking motivates, unifies, and improves upon prior more heuristic approaches that attempt to address the drawback of random uniform token masking, such as whole-word masking, entity/phrase masking, and random-span masking. Specifically, we show experimentally that PMI-Masking reaches the performance of prior masking approaches in half the training time, and consistently improves performance at the end of pretraining.",
        "conference": "ICLR",
        "中文标题": "PMI-掩码：相关跨度的原则性掩码",
        "摘要翻译": "在诸如BERT这样的掩码语言模型（MLM）的预训练中，均匀随机地掩码令牌构成了一个常见的缺陷。我们表明，这种均匀掩码允许MLM通过依赖浅层局部信号来最小化其训练目标，导致预训练效率低下和下游性能不佳。为了解决这一缺陷，我们提出了PMI-掩码，这是一种基于点互信息（PMI）概念的原则性掩码策略，如果一个令牌n-gram在语料库中表现出高共现性，则联合掩码它。PMI-掩码激发、统一并改进了之前试图解决随机均匀令牌掩码缺点的更启发式方法，如全词掩码、实体/短语掩码和随机跨度掩码。具体来说，我们通过实验表明，PMI-掩码在训练时间减半的情况下达到了之前掩码方法的性能，并在预训练结束时持续提高了性能。",
        "领域": "自然语言处理与视觉结合, 语言模型预训练, 文本挖掘",
        "问题": "解决掩码语言模型预训练中均匀随机掩码导致的效率低下和性能不佳问题",
        "动机": "提高掩码语言模型预训练的效率和质量，避免模型依赖浅层局部信号",
        "方法": "提出基于点互信息（PMI）的PMI-掩码策略，联合掩码高共现性的令牌n-gram",
        "关键词": [
            "PMI-掩码",
            "掩码语言模型",
            "预训练效率",
            "点互信息",
            "令牌n-gram"
        ],
        "涉及的技术概念": {
            "点互信息（PMI）": "用于衡量两个令牌在语料库中的共现性，指导掩码策略选择高共现性的令牌n-gram进行联合掩码",
            "掩码语言模型（MLM）": "一种通过预测被掩码的单词来学习语言表示的预训练模型",
            "令牌n-gram": "连续的n个令牌序列，PMI-掩码策略基于其共现性决定是否进行联合掩码"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 620,
        "title": "PolarNet: Learning to Optimize Polar Keypoints for Keypoint Based Object Detection",
        "html": "https://iclr.cc//virtual/2021/poster/3376",
        "abstract": "A variety of anchor-free object detectors have been actively proposed as possible alternatives to the mainstream anchor-based detectors that often rely on complicated design of anchor boxes. Despite achieving promising performance on par with anchor-based detectors, the existing anchor-free detectors such as FCOS or CenterNet predict objects based on standard Cartesian coordinates, which often yield poor quality keypoints. Further, the feature representation is also scale-sensitive. In this paper, we propose a new anchor-free keypoint based detector ``PolarNet', where keypoints are represented as a set of Polar coordinates instead of Cartesian coordinates. The ``PolarNet' detector learns offsets pointing to the corners of objects in order to learn high quality keypoints. Additionally, PolarNet uses features of corner points to localize objects, making the localization scale-insensitive. Finally in our experiments, we show that PolarNet, an anchor-free detector, outperforms the existing anchor-free detectors, and it is able to achieve highly competitive result on COCO test-dev benchmark ($47.8\\%$ and $50.3\\%$ AP under the single-model single-scale and multi-scale testing) which is on par with the state-of-the-art two-stage anchor-based object detectors. The code and the models are available at https://github.com/XiongweiWu/PolarNetV1",
        "conference": "ICLR",
        "中文标题": "PolarNet：学习优化基于极坐标关键点的目标检测",
        "摘要翻译": "作为主流基于锚框检测器的可能替代方案，各种无锚框目标检测器被积极提出，后者往往依赖于复杂的锚框设计。尽管在性能上与基于锚框的检测器相当，现有的无锚框检测器如FCOS或CenterNet基于标准笛卡尔坐标预测目标，这往往产生质量较差的关键点。此外，特征表示也对尺度敏感。在本文中，我们提出了一种新的基于关键点的无锚框检测器“PolarNet”，其中关键点被表示为一组极坐标而非笛卡尔坐标。“PolarNet”检测器学习指向物体角落的偏移量，以学习高质量的关键点。此外，PolarNet使用角落点的特征来定位物体，使得定位对尺度不敏感。最后，在我们的实验中，我们展示了PolarNet，一种无锚框检测器，超越了现有的无锚框检测器，并且能够在COCO测试开发基准上取得极具竞争力的结果（单模型单尺度和多尺度测试下的AP分别为47.8%和50.3%），与最先进的两阶段基于锚框的目标检测器相当。代码和模型可在https://github.com/XiongweiWu/PolarNetV1获取。",
        "领域": "目标检测",
        "问题": "现有无锚框检测器基于笛卡尔坐标预测目标，导致关键点质量差且特征表示对尺度敏感。",
        "动机": "通过使用极坐标表示关键点，提高关键点质量并实现尺度不敏感的特征表示，以提升目标检测性能。",
        "方法": "提出PolarNet检测器，使用极坐标表示关键点，学习指向物体角落的偏移量，并利用角落点特征进行物体定位。",
        "关键词": [
            "无锚框检测器",
            "极坐标关键点",
            "尺度不敏感"
        ],
        "涉及的技术概念": {
            "极坐标关键点": "用于表示目标的关键点，替代传统的笛卡尔坐标，以提高关键点质量。",
            "尺度不敏感特征": "通过使用角落点特征进行物体定位，使得检测器对不同尺度的物体具有鲁棒性。",
            "偏移量学习": "检测器学习指向物体角落的偏移量，以优化关键点的位置，提高检测精度。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 621,
        "title": "Policy-Driven Attack: Learning to Query for Hard-label Black-box Adversarial Examples",
        "html": "https://iclr.cc//virtual/2021/poster/2823",
        "abstract": "To craft black-box adversarial examples, adversaries need to query the victim model and take proper advantage of its feedback. Existing black-box attacks generally suffer from high query complexity, especially when only the top-1 decision (i.e., the hard-label prediction) of the victim model is available.  In this paper, we propose a novel hard-label black-box attack named Policy-Driven Attack, to reduce the query complexity. Our core idea is to learn promising search directions of the adversarial examples using a well-designed policy network in a novel reinforcement learning formulation, in which the queries become more sensible. Experimental results demonstrate that our method can significantly reduce the query complexity in comparison with existing state-of-the-art hard-label black-box attacks on various image classification benchmark datasets. Code and models for reproducing our results are available at https://github.com/ZiangYan/pda.pytorch",
        "conference": "ICLR",
        "中文标题": "策略驱动攻击：学习查询硬标签黑盒对抗样本",
        "摘要翻译": "为了制作黑盒对抗样本，攻击者需要查询受害者模型并合理利用其反馈。现有的黑盒攻击通常面临高查询复杂性的问题，尤其是当仅能获取受害者模型的top-1决策（即硬标签预测）时。本文提出了一种名为策略驱动攻击的新型硬标签黑盒攻击方法，旨在降低查询复杂性。我们的核心思想是在一种新颖的强化学习框架中，通过精心设计的策略网络学习对抗样本的有希望的搜索方向，从而使查询变得更加合理。实验结果表明，与现有的最先进硬标签黑盒攻击方法相比，我们的方法在各种图像分类基准数据集上能显著降低查询复杂性。重现我们结果的代码和模型可在https://github.com/ZiangYan/pda.pytorch获取。",
        "领域": "对抗样本生成、图像分类安全、强化学习应用",
        "问题": "降低硬标签黑盒对抗样本生成的查询复杂性",
        "动机": "现有的黑盒攻击方法在仅能获取硬标签预测时查询复杂性高，影响了攻击的效率和实用性",
        "方法": "通过强化学习框架中的策略网络学习对抗样本的搜索方向，优化查询策略",
        "关键词": [
            "硬标签黑盒攻击",
            "策略驱动攻击",
            "查询复杂性",
            "强化学习",
            "对抗样本"
        ],
        "涉及的技术概念": {
            "策略网络": "用于在强化学习框架中学习对抗样本的搜索方向，优化查询策略",
            "强化学习": "作为框架基础，用于训练策略网络以学习有效的查询策略",
            "硬标签预测": "攻击者仅能获取的模型输出形式，限制了攻击者可利用的信息量"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 622,
        "title": "Practical Massively Parallel Monte-Carlo Tree Search Applied to Molecular Design",
        "html": "https://iclr.cc//virtual/2021/poster/2528",
        "abstract": "It is common practice to use large computational resources to train neural networks, known from many examples, such as reinforcement learning applications. However, while massively parallel computing is often used for training models, it is rarely used to search solutions for combinatorial optimization problems. This paper proposes a novel massively parallel Monte-Carlo Tree Search (MP-MCTS) algorithm that works efficiently for a 1,000 worker scale on a distributed memory environment using multiple compute nodes and applies it to molecular design. This paper is the first work that applies distributed MCTS to a real-world and non-game problem. Existing works on large-scale parallel MCTS show efficient scalability in terms of the number of rollouts up to 100 workers. Still, they suffer from the degradation in the quality of the solutions. MP-MCTS maintains the search quality at a larger scale. By running MP-MCTS on 256 CPU cores for only 10 minutes, we obtained candidate molecules with similar scores to non-parallel MCTS running for 42 hours. Moreover, our results based on parallel MCTS (combined with a simple RNN model) significantly outperform existing state-of-the-art work. Our method is generic and is expected to speed up other applications of MCTS.",
        "conference": "ICLR",
        "中文标题": "实用的大规模并行蒙特卡洛树搜索在分子设计中的应用",
        "摘要翻译": "通常的做法是使用大量的计算资源来训练神经网络，这在许多例子中都有所体现，比如强化学习应用。然而，虽然大规模并行计算经常被用于训练模型，但在解决组合优化问题的搜索解决方案中却很少使用。本文提出了一种新颖的大规模并行蒙特卡洛树搜索（MP-MCTS）算法，该算法在分布式内存环境中使用多个计算节点，在1,000个工作节点规模上高效工作，并将其应用于分子设计。本文是将分布式MCTS应用于现实世界非游戏问题的首次尝试。现有的大规模并行MCTS工作在100个工作节点规模内展示了在滚动次数方面的有效可扩展性，但仍然存在解决方案质量下降的问题。MP-MCTS在更大规模上保持了搜索质量。通过在256个CPU核心上运行MP-MCTS仅10分钟，我们获得了与非并行MCTS运行42小时相似分数的候选分子。此外，我们基于并行MCTS（结合简单的RNN模型）的结果显著优于现有的最先进工作。我们的方法是通用的，预计将加速MCTS的其他应用。",
        "领域": "分子设计、组合优化、并行计算",
        "问题": "解决组合优化问题中大规模并行计算应用不足的问题",
        "动机": "探索大规模并行计算在组合优化问题中的应用潜力，特别是在分子设计领域",
        "方法": "提出了一种新颖的大规模并行蒙特卡洛树搜索（MP-MCTS）算法，并在分布式内存环境中实现高效运行",
        "关键词": [
            "大规模并行计算",
            "蒙特卡洛树搜索",
            "分子设计",
            "组合优化",
            "分布式计算"
        ],
        "涉及的技术概念": {
            "大规模并行蒙特卡洛树搜索（MP-MCTS）": "一种新颖的算法，能够在分布式内存环境中高效运行，适用于大规模并行计算",
            "组合优化问题": "论文中解决的问题类型，涉及在大量可能的组合中寻找最优解",
            "分布式计算": "论文中采用的计算方法，通过多个计算节点并行处理任务，以提高效率"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 623,
        "title": "Practical Real Time Recurrent Learning with a Sparse Approximation",
        "html": "https://iclr.cc//virtual/2021/poster/3203",
        "abstract": "Recurrent neural networks are usually trained with backpropagation through time, which requires storing a complete history of network states, and prohibits updating the weights 'online' (after every timestep). Real Time Recurrent Learning (RTRL) eliminates the need for history storage and allows for online weight updates, but does so at the expense of computational costs that are quartic in the state size. This renders RTRL training intractable for all but the smallest networks, even ones that are made highly sparse.\nWe introduce the Sparse n-step Approximation (SnAp) to the RTRL influence matrix. SnAp only tracks the influence of a parameter on hidden units that are reached by the computation graph within $n$ timesteps of the recurrent core. SnAp with $n=1$ is no more expensive than backpropagation but allows training on arbitrarily long sequences. We find that it substantially outperforms other RTRL approximations with comparable costs such as Unbiased Online Recurrent Optimization. For highly sparse networks, SnAp with $n=2$ remains tractable and can outperform backpropagation through time in terms of learning speed when updates are done online.",
        "conference": "ICLR",
        "中文标题": "实用的实时循环学习稀疏近似方法",
        "摘要翻译": "循环神经网络通常通过时间反向传播进行训练，这需要存储网络状态的完整历史，并且禁止'在线'（每个时间步之后）更新权重。实时循环学习（RTRL）消除了历史存储的需求，并允许在线权重更新，但这样做是以状态大小的四次方计算成本为代价的。这使得RTRL训练对于除最小网络之外的所有网络都变得不可行，即使是那些高度稀疏的网络。我们引入了对RTRL影响矩阵的稀疏n步近似（SnAp）。SnAp仅跟踪参数对在循环核心的n个时间步内由计算图到达的隐藏单元的影响。n=1的SnAp不比反向传播更昂贵，但允许在任意长的序列上进行训练。我们发现，它在成本相当的情况下大大优于其他RTRL近似，如无偏在线循环优化。对于高度稀疏的网络，n=2的SnAp仍然是可行的，并且可以在在线更新时在学习速度方面优于时间反向传播。",
        "领域": "循环神经网络、在线学习、稀疏网络",
        "问题": "解决实时循环学习（RTRL）在训练循环神经网络时的高计算成本问题",
        "动机": "为了使得RTRL训练对于更大规模的网络变得可行，同时保持在线更新的能力",
        "方法": "引入稀疏n步近似（SnAp）来减少RTRL影响矩阵的计算成本",
        "关键词": [
            "实时循环学习",
            "稀疏近似",
            "在线学习",
            "循环神经网络",
            "计算效率"
        ],
        "涉及的技术概念": {
            "实时循环学习（RTRL）": "一种允许在线权重更新的循环神经网络训练方法，但计算成本高",
            "稀疏n步近似（SnAp）": "一种减少RTRL计算成本的方法，通过限制影响矩阵的计算范围",
            "时间反向传播": "传统的循环神经网络训练方法，需要存储完整的网络状态历史"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 624,
        "title": "Predicting Classification Accuracy When Adding New Unobserved Classes",
        "html": "https://iclr.cc//virtual/2021/poster/2595",
        "abstract": "Multiclass classifiers are often designed and evaluated only on a sample from the classes on which they will eventually be applied. Hence, their final accuracy remains unknown. In this work we study how a classifier’s performance over the initial class sample can be used to extrapolate its expected accuracy on a larger, unobserved set of classes. For this, we define a measure of separation between correct and incorrect classes that is independent of the number of classes: the 'reversed ROC' (rROC), which is obtained by replacing the roles of classes and data-points in the common ROC. We show that the classification accuracy is a function of the rROC in multiclass classifiers, for which the learned representation of data from the initial class sample remains unchanged when new classes are added. Using these results we formulate a robust neural-network-based algorithm, 'CleaneX', which learns to estimate the accuracy of such classifiers on arbitrarily large sets of classes. Unlike previous methods, our method uses both the observed accuracies of the classifier and densities of classification scores, and therefore achieves remarkably better predictions than current state-of-the-art methods on both simulations and real datasets of object detection, face recognition, and brain decoding.",
        "conference": "ICLR",
        "中文标题": "预测添加未观察类别时的分类准确率",
        "摘要翻译": "多类分类器通常仅在其最终应用类别的一个样本上进行设计和评估。因此，它们的最终准确率仍然未知。在这项工作中，我们研究了如何利用分类器在初始类别样本上的表现来推断其在更大、未观察到的类别集上的预期准确率。为此，我们定义了一个与类别数量无关的正确与错误类别之间的分离度量：'反向ROC'（rROC），这是通过替换常见ROC中类别和数据点的角色获得的。我们展示了在多类分类器中，分类准确率是rROC的一个函数，对于这些分类器，当添加新类别时，初始类别样本的学习数据表示保持不变。利用这些结果，我们制定了一个基于神经网络的鲁棒算法'CleaneX'，该算法学习估计此类分类器在任意大类集上的准确率。与之前的方法不同，我们的方法既利用了分类器的观察准确率，又利用了分类分数的密度，因此在对象检测、人脸识别和大脑解码的模拟和真实数据集上，比当前最先进的方法实现了显著更好的预测。",
        "领域": "多类分类、对象检测、人脸识别",
        "问题": "如何预测分类器在添加未观察类别时的准确率",
        "动机": "解决分类器在未知类别上的准确率预测问题，以评估其在实际应用中的表现",
        "方法": "定义反向ROC（rROC）作为类别分离度量，并开发基于神经网络的算法CleaneX来预测分类准确率",
        "关键词": [
            "多类分类",
            "准确率预测",
            "反向ROC",
            "神经网络",
            "CleaneX"
        ],
        "涉及的技术概念": {
            "反向ROC（rROC）": "通过替换常见ROC中类别和数据点的角色定义的类别分离度量，用于预测分类准确率",
            "CleaneX算法": "基于神经网络的算法，利用观察到的分类器准确率和分类分数密度来预测在更大类别集上的准确率",
            "多类分类器": "设计用于处理多个类别的分类器，其性能在添加新类别时需要被准确预测"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 625,
        "title": "Predicting Inductive Biases of Pre-Trained Models",
        "html": "https://iclr.cc//virtual/2021/poster/3098",
        "abstract": "Most current NLP systems are based on a pre-train-then-fine-tune paradigm, in which a large neural network is first trained in a self-supervised way designed to encourage the network to extract broadly-useful linguistic features, and then fine-tuned for a specific task of interest. Recent work attempts to understand why this recipe works and explain when it fails. Currently, such analyses have produced two sets of apparently-contradictory results. Work that analyzes the representations that result from pre-training (via 'probing classifiers') finds evidence that rich features of linguistic structure can be decoded with high accuracy, but work that analyzes model behavior after fine-tuning (via 'challenge sets') indicates that decisions are often not based on such structure but rather on spurious heuristics specific to the training set. In this work, we test the hypothesis that the extent to which a feature influences a model's decisions can be predicted using a combination of two factors: The feature's 'extractability' after pre-training (measured using information-theoretic probing techniques), and the 'evidence' available during fine-tuning (defined as the feature's co-occurrence rate with the label). In experiments with both synthetic and natural language data, we find strong evidence (statistically significant correlations) supporting this hypothesis.",
        "conference": "ICLR",
        "中文标题": "预测预训练模型的归纳偏差",
        "摘要翻译": "当前大多数自然语言处理（NLP）系统基于‘预训练-微调’范式，其中首先以自监督的方式训练一个大型神经网络，旨在鼓励网络提取广泛有用的语言特征，然后针对特定任务进行微调。最近的工作试图理解这一方法为何有效以及解释其失败的情况。目前，这类分析产生了两种看似矛盾的结果。通过‘探测分类器’分析预训练得到的表示的工作发现，可以高精度解码语言结构的丰富特征；而通过‘挑战集’分析微调后模型行为的工作则表明，决策往往不是基于这种结构，而是基于训练集特有的虚假启发式。在本研究中，我们测试了一个假设：一个特征影响模型决策的程度可以通过两个因素的组合来预测：预训练后特征的‘可提取性’（使用信息论探测技术测量），以及微调期间可用的‘证据’（定义为特征与标签的共现率）。在合成和自然语言数据的实验中，我们发现了支持这一假设的强有力证据（统计上显著的相关性）。",
        "领域": "自然语言处理与视觉结合",
        "问题": "理解预训练模型在微调过程中的决策依据，以及预测哪些语言特征会影响模型的决策。",
        "动机": "为了解决当前对预训练模型在微调后决策依据理解上的矛盾，探索模型决策背后的机制。",
        "方法": "结合信息论探测技术和特征与标签的共现率，预测预训练模型中哪些特征会影响其决策。",
        "关键词": [
            "预训练模型",
            "归纳偏差",
            "信息论探测",
            "微调",
            "语言特征"
        ],
        "涉及的技术概念": {
            "预训练-微调范式": "一种先通过自监督学习预训练模型，再针对特定任务进行微调的方法。",
            "信息论探测技术": "用于测量预训练后特征的可提取性的技术。",
            "特征与标签的共现率": "在微调过程中，特征与标签同时出现的频率，作为影响模型决策的证据。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 626,
        "title": "Predicting Infectiousness for Proactive Contact Tracing",
        "html": "https://iclr.cc//virtual/2021/poster/2912",
        "abstract": "The COVID-19 pandemic has spread rapidly worldwide, overwhelming manual contact tracing in many countries and resulting in widespread lockdowns for emergency containment. Large-scale digital contact tracing (DCT) has emerged as a potential solution to resume economic and social activity while minimizing spread of the virus. Various DCT methods have been proposed, each making trade-offs be-tween privacy, mobility restrictions, and public health. The most common approach, binary contact tracing (BCT), models infection as a binary event, informed only by an individual’s test results, with corresponding binary recommendations that either all or none of the individual’s contacts quarantine. BCT ignores the inherent uncertainty in contacts and the infection process, which could be used to tailor messaging to high-risk individuals, and prompt proactive testing or earlier warnings. It also does not make use of observations such as symptoms or pre-existing medical conditions, which could be used to make more accurate infectiousness predictions. In this paper, we use a recently-proposed COVID-19 epidemiological simulator to develop and test methods that can be deployed to a smartphone to locally and proactively predict an individual’s infectiousness (risk of infecting others) based on their contact history and other information, while respecting strong privacy constraints. Predictions are used to provide personalized recommendations to the individual via an app, as well as to send anonymized messages to the individual’s contacts, who use this information to better predict their own infectiousness, an approach we call proactive contact tracing (PCT). Similarly to other works, we find that compared to no tracing, all DCT methods tested are able to reduce spread of the disease and thus save lives, even at low adoption rates, strongly supporting a role for DCT methods in managing the pandemic. Further, we find a deep-learning based PCT method which improves over BCT for equivalent average mobility, suggesting PCT could help in safe re-opening and second-wave prevention.",
        "conference": "ICLR",
        "中文标题": "预测传染性以实现主动接触追踪",
        "摘要翻译": "COVID-19疫情在全球迅速蔓延，使得许多国家的手动接触追踪不堪重负，导致广泛封锁以进行紧急遏制。大规模数字接触追踪（DCT）作为一种潜在解决方案出现，旨在恢复经济和社会活动的同时最小化病毒传播。已提出各种DCT方法，每种方法都在隐私、移动限制和公共卫生之间做出权衡。最常见的方法是二进制接触追踪（BCT），它将感染建模为一个二进制事件，仅基于个体的测试结果，并提供相应的二进制建议，即要么所有接触者隔离，要么都不隔离。BCT忽略了接触和感染过程中的固有不确定性，这些不确定性可用于向高风险个体定制消息，并促使主动测试或提前警告。它也没有利用诸如症状或已有医疗条件等观察结果，这些可用于做出更准确的传染性预测。在本文中，我们使用最近提出的COVID-19流行病学模拟器来开发和测试可以部署到智能手机上的方法，以基于个体的接触历史和其他信息，在尊重强隐私约束的情况下，本地和主动地预测个体的传染性（感染他人的风险）。预测结果用于通过应用程序向个体提供个性化建议，以及向个体的接触者发送匿名消息，后者利用这些信息更好地预测自己的传染性，这种方法我们称之为主动接触追踪（PCT）。与其他研究类似，我们发现与无追踪相比，所有测试的DCT方法都能够减少疾病传播从而挽救生命，即使在低采用率下也是如此，强烈支持DCT方法在管理疫情中的作用。此外，我们发现一种基于深度学习的PCT方法在相同平均移动性下优于BCT，表明PCT可能有助于安全重新开放和预防第二波疫情。",
        "领域": "流行病学模型、数字接触追踪、深度学习应用",
        "问题": "如何基于个体的接触历史和其他信息，在尊重隐私的前提下，主动预测个体的传染性。",
        "动机": "解决二进制接触追踪（BCT）方法在预测个体传染性时忽略接触和感染过程中的不确定性及未充分利用可用信息的问题。",
        "方法": "使用COVID-19流行病学模拟器开发和测试基于深度学习的主动接触追踪（PCT）方法，该方法能在智能手机上本地预测个体的传染性，并提供个性化建议和匿名消息。",
        "关键词": [
            "数字接触追踪",
            "传染性预测",
            "深度学习",
            "隐私保护",
            "流行病学模拟"
        ],
        "涉及的技术概念": {
            "数字接触追踪（DCT）": "一种利用数字技术追踪个体接触历史以控制疫情传播的方法。",
            "二进制接触追踪（BCT）": "一种将感染建模为二进制事件，仅基于个体测试结果提供隔离建议的接触追踪方法。",
            "主动接触追踪（PCT）": "一种基于个体接触历史和其他信息，主动预测个体传染性并提供个性化建议的接触追踪方法。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 627,
        "title": "Prediction and generalisation over directed actions by grid cells",
        "html": "https://iclr.cc//virtual/2021/poster/3259",
        "abstract": "Knowing how the effects of directed actions generalise to new situations (e.g. moving North, South, East and West, or turning left, right, etc.) is key to rapid generalisation across new situations. Markovian tasks can be characterised by a state space and a transition matrix and recent work has proposed that neural grid codes provide an efficient representation of the state space, as eigenvectors of a transition matrix reflecting diffusion across states, that allows efficient prediction of future state distributions. Here we extend the eigenbasis prediction model, utilising tools from Fourier analysis, to prediction over arbitrary translation-invariant directed transition structures (i.e. displacement and diffusion), showing that a single set of eigenvectors can support predictions over arbitrary directed actions via action-specific eigenvalues. We show how to define a 'sense of direction' to combine actions to reach a target state (ignoring task-specific deviations from translation-invariance), and demonstrate that adding the Fourier representations to a deep Q network aids policy learning in continuous control tasks. We show the equivalence between the generalised prediction framework and traditional models of grid cell firing driven by self-motion to perform path integration, either using oscillatory interference (via Fourier components as velocity-controlled oscillators) or continuous attractor networks (via analysis of the update dynamics). We thus provide a unifying framework for the role of the grid system in predictive planning, sense of direction and path integration: supporting generalisable inference over directed actions across different tasks.",
        "conference": "ICLR",
        "中文标题": "网格细胞对定向动作的预测与泛化",
        "摘要翻译": "了解定向动作的效果如何泛化到新情境（例如向北、南、东、西移动，或左转、右转等）是快速适应新情境的关键。马尔可夫任务可以通过状态空间和转移矩阵来表征，最近的研究提出，神经网格代码作为状态空间的高效表示，作为反映状态间扩散的转移矩阵的特征向量，能够有效预测未来状态分布。本文扩展了特征基预测模型，利用傅里叶分析工具，对任意平移不变的定向转移结构（即位移和扩散）进行预测，表明单一特征向量集可以通过动作特定的特征值支持对任意定向动作的预测。我们展示了如何定义‘方向感’以组合动作达到目标状态（忽略任务特定的平移不变性偏差），并证明将傅里叶表示添加到深度Q网络中有助于连续控制任务中的策略学习。我们展示了广义预测框架与由自运动驱动的传统网格细胞放电模型之间的等价性，以执行路径积分，无论是使用振荡干扰（通过傅里叶分量作为速度控制振荡器）还是连续吸引子网络（通过分析更新动态）。因此，我们为网格系统在预测规划、方向感和路径积分中的作用提供了一个统一的框架：支持跨不同任务的定向动作的可泛化推理。",
        "领域": "神经科学建模, 强化学习, 计算神经科学",
        "问题": "如何使网格细胞能够预测和泛化定向动作到新情境",
        "动机": "研究网格细胞如何支持对定向动作的预测和泛化，以促进跨任务的快速适应",
        "方法": "扩展特征基预测模型，利用傅里叶分析工具对任意平移不变的定向转移结构进行预测，并通过深度Q网络增强策略学习",
        "关键词": [
            "网格细胞",
            "傅里叶分析",
            "深度Q网络",
            "路径积分",
            "方向感"
        ],
        "涉及的技术概念": {
            "特征基预测模型": "用于预测未来状态分布的模型，基于状态空间的特征向量",
            "傅里叶分析": "用于分析和处理平移不变的定向转移结构的数学工具",
            "深度Q网络": "一种强化学习算法，用于学习在连续控制任务中的最优策略"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 628,
        "title": "Pre-training Text-to-Text Transformers for Concept-centric Common Sense",
        "html": "https://iclr.cc//virtual/2021/poster/3272",
        "abstract": "Pretrained language models (PTLM) have achieved impressive results in a range of natural language understanding (NLU) and generation (NLG) tasks that require a syntactic and semantic understanding of the text. However, current pre-training objectives such as masked token prediction (for BERT-style PTLMs) and masked span infilling (for T5-style PTLMs) do not explicitly model the relational and compositional commonsense knowledge about everyday concepts, which is crucial to many downstream tasks requiring commonsense reasoning. To augment PTLMs with common sense, we propose generative and contrastive objectives as intermediate self-supervised pre-training tasks between general pre-training and downstream task-specific fine-tuning. We also propose a joint training framework to unify generative and contrastive objectives so that these objectives can be more effective.\nOur proposed objectives can pack more commonsense knowledge into the parameters of a pre-trained text-to-text transformer without relying on external knowledge bases, yielding better performance on both NLU and NLG tasks. We apply our method on a pre-trained T5 model in an intermediate task transfer learning fashion to train a concept-aware language model (CALM) and experiment with five commonsense benchmarks (four NLU tasks and one NLG task). Experimental results show that CALM outperforms baseline methods by a consistent margin.",
        "conference": "ICLR",
        "中文标题": "面向概念中心常识的文本到文本转换器的预训练",
        "摘要翻译": "预训练语言模型（PTLM）在一系列需要文本句法和语义理解的自然语言理解（NLU）和生成（NLG）任务中取得了令人印象深刻的成果。然而，当前的预训练目标，如掩码标记预测（针对BERT风格的PTLM）和掩码跨度填充（针对T5风格的PTLM），并未明确建模关于日常概念的关系和组合常识知识，这对于许多需要常识推理的下游任务至关重要。为了增强PTLM的常识能力，我们提出了生成性和对比性目标作为通用预训练和下游任务特定微调之间的中间自监督预训练任务。我们还提出了一个联合训练框架，以统一生成性和对比性目标，从而使这些目标更加有效。我们提出的目标可以在不依赖外部知识库的情况下，将更多常识知识打包到预训练的文本到文本转换器的参数中，从而在NLU和NLG任务上获得更好的性能。我们以中间任务迁移学习的方式将我们的方法应用于预训练的T5模型，以训练一个概念感知语言模型（CALM），并在五个常识基准测试（四个NLU任务和一个NLG任务）上进行了实验。实验结果表明，CALM以一致的幅度优于基线方法。",
        "领域": "自然语言理解与生成、常识推理、预训练语言模型",
        "问题": "当前预训练语言模型在常识推理任务上的表现不足，缺乏对日常概念的关系和组合常识知识的建模。",
        "动机": "增强预训练语言模型的常识能力，以提升在需要常识推理的下游任务上的表现。",
        "方法": "提出生成性和对比性目标作为中间自监督预训练任务，并开发联合训练框架统一这些目标，以增强模型的常识知识。",
        "关键词": [
            "常识推理",
            "预训练语言模型",
            "自监督学习",
            "文本到文本转换",
            "概念感知"
        ],
        "涉及的技术概念": {
            "生成性目标": "用于在预训练阶段通过生成任务增强模型对常识知识的理解和应用能力。",
            "对比性目标": "通过对比学习区分正确和错误的常识知识，增强模型的常识推理能力。",
            "概念感知语言模型（CALM）": "通过中间任务迁移学习训练的语言模型，专门增强对日常概念的关系和组合常识知识的理解和应用。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 629,
        "title": "Primal Wasserstein Imitation Learning",
        "html": "https://iclr.cc//virtual/2021/poster/2569",
        "abstract": "Imitation Learning (IL) methods seek to match the behavior of an agent with that of an expert. In the present work, we propose a new IL method based on a conceptually simple algorithm: Primal Wasserstein Imitation Learning (PWIL), which ties to the primal form of the Wasserstein distance between the expert and the agent state-action distributions. We present a reward function which is derived offline, as opposed to recent adversarial IL algorithms that learn a reward function through interactions with the environment, and which requires little fine-tuning. We show that we can recover expert behavior on a variety of continuous control tasks of the MuJoCo domain in a sample efficient manner in terms of agent interactions and of expert interactions with the environment. Finally, we show that the behavior of the agent we train matches the behavior of the expert with the Wasserstein distance, rather than the commonly used proxy of performance.",
        "conference": "ICLR",
        "中文标题": "原始Wasserstein模仿学习",
        "摘要翻译": "模仿学习（IL）方法旨在使代理的行为与专家的行为相匹配。在本工作中，我们提出了一种基于概念简单算法的新IL方法：原始Wasserstein模仿学习（PWIL），该方法与专家和代理状态-动作分布的Wasserstein距离的原始形式相关联。我们提出了一种离线导出的奖励函数，与最近通过与环境交互学习奖励函数的对抗性IL算法相反，且需要很少的微调。我们展示了我们可以在MuJoCo领域的各种连续控制任务上，以样本高效的方式恢复专家行为，就代理交互和专家与环境的交互而言。最后，我们展示了我们训练的代理的行为与专家的行为相匹配，使用的是Wasserstein距离，而不是常用的性能代理。",
        "领域": "模仿学习、连续控制、强化学习",
        "问题": "如何在样本高效的情况下，使代理的行为与专家的行为相匹配。",
        "动机": "提出一种不需要通过与环境交互学习奖励函数且需要很少微调的模仿学习方法。",
        "方法": "提出了一种基于Wasserstein距离原始形式的新模仿学习方法PWIL，并展示了一种离线导出的奖励函数。",
        "关键词": [
            "模仿学习",
            "Wasserstein距离",
            "连续控制",
            "样本高效",
            "奖励函数"
        ],
        "涉及的技术概念": {
            "Wasserstein距离": "用于衡量专家和代理状态-动作分布之间的距离，是PWIL方法的核心。",
            "模仿学习": "旨在使代理的行为与专家的行为相匹配的学习方法。",
            "奖励函数": "PWIL方法中离线导出的函数，用于指导代理学习专家行为，减少了对环境交互的依赖。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 630,
        "title": "Private Image Reconstruction from System Side Channels Using Generative Models",
        "html": "https://iclr.cc//virtual/2021/poster/2886",
        "abstract": "System side channels denote effects imposed on the underlying system and hardware when running a program, such as its accessed CPU cache lines. Side channel analysis (SCA) allows attackers to infer program secrets based on observed side channel signals. Given the ever-growing adoption of machine learning as a service (MLaaS), image analysis software on cloud platforms has been exploited by reconstructing private user images from system side channels. Nevertheless, to date, SCA is still highly challenging, requiring technical knowledge of victim software's internal operations. For existing SCA attacks, comprehending such internal operations requires heavyweight program analysis or manual efforts.\n\nThis research proposes an attack framework to reconstruct private user images processed by media software via system side channels. The framework forms an effective workflow by incorporating convolutional networks, variational autoencoders, and generative adversarial networks. Our evaluation of two popular side channels shows that the reconstructed images consistently match user inputs, making privacy leakage attacks more practical. We also show surprising results that even one-bit data read/write pattern side channels, which are deemed minimally informative, can be used to reconstruct quality images using our framework.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "利用生成模型从系统侧信道重建私有图像",
        "摘要翻译": "系统侧信道指的是程序运行时对底层系统和硬件产生的影响，例如其访问的CPU缓存行。侧信道分析（SCA）允许攻击者基于观察到的侧信道信号推断程序秘密。随着机器学习即服务（MLaaS）的日益普及，云平台上的图像分析软件已被利用通过系统侧信道重建私有用户图像。然而，迄今为止，SCA仍然极具挑战性，需要了解受害软件内部操作的技术知识。对于现有的SCA攻击，理解这些内部操作需要重量级的程序分析或手动努力。本研究提出了一种攻击框架，通过系统侧信道重建媒体软件处理的私有用户图像。该框架通过结合卷积网络、变分自编码器和生成对抗网络，形成了一个有效的工作流程。我们对两种流行的侧信道的评估显示，重建的图像与用户输入一致，使得隐私泄露攻击更加实用。我们还展示了令人惊讶的结果，即使用我们框架，即使是被认为信息量最小的一位数据读写模式侧信道，也可以用于重建质量图像。",
        "领域": "隐私保护与安全",
        "问题": "如何从系统侧信道重建私有用户图像",
        "动机": "随着机器学习即服务的普及，云平台上的图像分析软件面临通过系统侧信道泄露用户隐私的风险，现有侧信道分析方法需要大量技术知识和手动努力，难以实用化。",
        "方法": "结合卷积网络、变分自编码器和生成对抗网络，构建一个有效的攻击框架，从系统侧信道重建私有用户图像。",
        "关键词": [
            "系统侧信道",
            "图像重建",
            "生成模型",
            "隐私泄露",
            "机器学习即服务"
        ],
        "涉及的技术概念": {
            "卷积网络": "用于从侧信道信号中提取特征，帮助重建图像。",
            "变分自编码器": "用于学习侧信道信号与原始图像之间的潜在表示，促进图像重建。",
            "生成对抗网络": "用于提高重建图像的质量和真实感，使其更接近原始用户输入。"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 631,
        "title": "Private Post-GAN Boosting",
        "html": "https://iclr.cc//virtual/2021/poster/3202",
        "abstract": "Differentially private GANs have proven to be a promising approach for generating realistic synthetic data without compromising the privacy of individuals. Due to the privacy-protective noise introduced in the  training, the convergence of GANs becomes even more elusive, which often leads to poor utility in the output generator at the end of training. We propose Private post-GAN boosting (Private PGB), a differentially private method that combines samples produced by the sequence of generators obtained during GAN training to create a high-quality synthetic dataset. To that end, our method leverages the Private Multiplicative Weights method (Hardt and Rothblum, 2010) to reweight generated samples. We evaluate Private PGB on two dimensional toy data, MNIST images, US Census data and a standard machine learning prediction task. Our experiments show that Private PGB improves upon a standard private GAN approach across a collection of quality measures. We also provide a non-private variant of PGB that improves the data quality of standard GAN training.",
        "conference": "ICLR",
        "中文标题": "私有后GAN增强",
        "摘要翻译": "差分私有GAN已被证明是一种在不损害个人隐私的情况下生成逼真合成数据的有前途的方法。由于在训练中引入了保护隐私的噪声，GAN的收敛变得更加难以捉摸，这往往导致训练结束时输出生成器的效用不佳。我们提出了私有后GAN增强（Private PGB），这是一种差分私有方法，它结合了在GAN训练过程中获得的一系列生成器产生的样本，以创建高质量的合成数据集。为此，我们的方法利用了私有乘法权重方法（Hardt和Rothblum，2010）来重新加权生成的样本。我们在二维玩具数据、MNIST图像、美国人口普查数据和一个标准的机器学习预测任务上评估了Private PGB。我们的实验表明，Private PGB在一系列质量指标上优于标准的私有GAN方法。我们还提供了一个非私有版本的PGB，它提高了标准GAN训练的数据质量。",
        "领域": "生成对抗网络、隐私保护机器学习、合成数据生成",
        "问题": "差分私有GAN在训练过程中由于引入隐私保护噪声导致收敛困难，生成器输出质量不佳的问题。",
        "动机": "提高差分私有GAN生成合成数据的质量，同时保护个人隐私。",
        "方法": "提出私有后GAN增强（Private PGB）方法，利用私有乘法权重方法重新加权训练过程中生成的一系列样本，以创建高质量的合成数据集。",
        "关键词": [
            "差分隐私",
            "生成对抗网络",
            "合成数据",
            "隐私保护",
            "数据增强"
        ],
        "涉及的技术概念": {
            "差分私有GAN": "在GAN训练中引入差分隐私保护机制，以生成不泄露个人隐私的合成数据。",
            "私有乘法权重方法": "用于重新加权生成样本的方法，以提高合成数据的质量。",
            "合成数据生成": "通过算法生成模拟真实数据统计特性的数据，用于隐私保护下的数据共享和分析。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 632,
        "title": "Probabilistic Numeric Convolutional Neural Networks",
        "html": "https://iclr.cc//virtual/2021/poster/2556",
        "abstract": "Continuous input signals like images and time series that are irregularly sampled or have missing values are challenging for existing deep learning methods. Coherently defined feature representations must depend on the values in unobserved regions of the input. Drawing from the work in probabilistic numerics, we propose Probabilistic Numeric Convolutional Neural Networks which represent features as Gaussian processes, providing a probabilistic description of discretization error. We then define a convolutional layer as the evolution of a PDE defined on this GP, followed by a nonlinearity. This approach also naturally admits steerable equivariant convolutions under e.g. the rotation group. In experiments we show that our approach yields a $3\\times$ reduction of error from the previous state of the art on the SuperPixel-MNIST dataset and competitive performance on the medical time series dataset PhysioNet2012.",
        "conference": "ICLR",
        "中文标题": "概率数值卷积神经网络",
        "摘要翻译": "对于不规则采样或含有缺失值的连续输入信号（如图像和时间序列），现有的深度学习方法面临挑战。一致定义的特征表示必须依赖于输入未观测区域的值。借鉴概率数值领域的工作，我们提出了概率数值卷积神经网络，它将特征表示为高斯过程，提供了离散化误差的概率描述。然后，我们将卷积层定义为在这个高斯过程上定义的偏微分方程的演化，后跟一个非线性操作。这种方法自然地允许在例如旋转群下的可操纵等变卷积。实验中，我们展示了我们的方法在SuperPixel-MNIST数据集上将误差从前沿技术减少了3倍，并在医疗时间序列数据集PhysioNet2012上表现出竞争性性能。",
        "领域": "图像处理, 时间序列分析, 医疗图像分析",
        "问题": "处理不规则采样或含有缺失值的连续输入信号",
        "动机": "为了解决现有深度学习方法在处理不规则采样或含有缺失值的连续输入信号时的挑战",
        "方法": "提出概率数值卷积神经网络，将特征表示为高斯过程，定义卷积层为高斯过程上偏微分方程的演化，后跟非线性操作",
        "关键词": [
            "概率数值",
            "卷积神经网络",
            "高斯过程",
            "偏微分方程",
            "等变卷积"
        ],
        "涉及的技术概念": {
            "高斯过程": "用于表示特征，提供离散化误差的概率描述",
            "偏微分方程": "用于定义卷积层的演化过程",
            "等变卷积": "允许在特定变换群（如旋转群）下的可操纵卷积操作"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 633,
        "title": "Probing BERT in Hyperbolic Spaces",
        "html": "https://iclr.cc//virtual/2021/poster/2905",
        "abstract": "Recently, a variety of probing tasks are proposed to discover linguistic properties learned in contextualized word embeddings. Many of these works implicitly assume these embeddings lay in certain metric spaces, typically the Euclidean space. This work considers a family of geometrically special spaces, the hyperbolic spaces, that exhibit better inductive biases for hierarchical structures and may better reveal linguistic hierarchies encoded in contextualized representations. We introduce a $\\textit{Poincaré probe}$, a structural probe projecting these embeddings into a Poincaré subspace with explicitly defined hierarchies. We focus on two probing objectives: (a) dependency trees where the hierarchy is defined as head-dependent structures; (b) lexical sentiments where the hierarchy is defined as the polarity of words (positivity and negativity). We argue that a key desideratum of a probe is its sensitivity to the existence of linguistic structures. We apply our probes on BERT, a typical contextualized embedding model. In a syntactic subspace, our probe better recovers tree structures than Euclidean probes, revealing the possibility that the geometry of BERT syntax may not necessarily be Euclidean. In a sentiment subspace, we reveal two possible meta-embeddings for positive and negative sentiments and show how lexically-controlled contextualization would change the geometric localization of embeddings. We demonstrate the findings with our Poincaré probe via extensive experiments and visualization. Our results can be reproduced at https://github.com/FranxYao/PoincareProbe",
        "conference": "ICLR",
        "中文标题": "在双曲空间中探索BERT",
        "摘要翻译": "最近，提出了多种探测任务来发现上下文词嵌入中学到的语言特性。这些工作中的许多都隐含地假设这些嵌入位于特定的度量空间中，通常是欧几里得空间。这项工作考虑了一类几何上特殊的空间，即双曲空间，这些空间对层次结构表现出更好的归纳偏差，并可能更好地揭示编码在上下文表示中的语言层次结构。我们介绍了一种$\textit{Poincaré探针}$，这是一种结构探针，将这些嵌入投影到一个具有明确定义层次结构的Poincaré子空间中。我们专注于两个探测目标：（a）依赖树，其中层次结构被定义为头-依赖结构；（b）词汇情感，其中层次结构被定义为词的极性（积极性和消极性）。我们认为探针的一个关键要求是其对语言结构存在的敏感性。我们在BERT上应用了我们的探针，这是一个典型的上下文嵌入模型。在句法子空间中，我们的探针比欧几里得探针更好地恢复了树结构，揭示了BERT语法的几何可能不一定是欧几里得的。在情感子空间中，我们揭示了积极和消极情感的两种可能的元嵌入，并展示了词汇控制的上下文化如何改变嵌入的几何定位。我们通过广泛的实验和可视化展示了我们的Poincaré探针的发现。我们的结果可以在https://github.com/FranxYao/PoincareProbe上重现。",
        "领域": "自然语言处理与视觉结合",
        "问题": "探索BERT模型在双曲空间中的表现及其对语言层次结构的编码能力",
        "动机": "研究BERT模型在非欧几里得空间（特别是双曲空间）中的表现，以更好地理解和利用其对语言层次结构的编码能力",
        "方法": "引入Poincaré探针，将BERT的上下文词嵌入投影到双曲空间中的Poincaré子空间，以探索语言层次结构",
        "关键词": [
            "双曲空间",
            "BERT",
            "Poincaré探针",
            "语言层次结构",
            "上下文词嵌入"
        ],
        "涉及的技术概念": {
            "双曲空间": "一种非欧几里得空间，具有对层次结构更好的归纳偏差，用于探索BERT模型中的语言层次结构",
            "Poincaré探针": "一种结构探针，用于将上下文词嵌入投影到双曲空间中的Poincaré子空间，以明确定义和探索语言层次结构",
            "上下文词嵌入": "BERT模型生成的词表示，考虑了词的上下文信息，用于捕捉语言特性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 634,
        "title": "Progressive Skeletonization: Trimming more fat from a network at initialization",
        "html": "https://iclr.cc//virtual/2021/poster/2957",
        "abstract": "Recent studies have shown that skeletonization (pruning parameters) of networks at initialization provides all the practical benefits of sparsity both at inference and training time, while only marginally degrading their performance. However, we observe that beyond a certain level of sparsity (approx 95%), these approaches fail to preserve the network performance, and to our surprise, in many cases perform even worse than trivial random pruning. To this end, we propose an objective to find a skeletonized network with maximum foresight connection sensitivity (FORCE) whereby the trainability, in terms of connection sensitivity, of a pruned network is taken into consideration. We then propose two approximate procedures to maximize our objective (1) Iterative SNIP: allows parameters that were unimportant at earlier stages of skeletonization to become important at later stages; and (2) FORCE: iterative process that allows exploration by allowing already pruned parameters to resurrect at later stages of skeletonization. Empirical analysis on a large suite of experiments show that our approach, while providing at least as good performance as other recent approaches on moderate pruning levels, provide remarkably improved performance on high pruning levels (could remove up to 99.5% parameters while keeping the networks trainable).",
        "conference": "ICLR",
        "中文标题": "渐进式骨架化：在网络初始化时修剪更多冗余",
        "摘要翻译": "最近的研究表明，在网络初始化时进行骨架化（参数修剪）在推理和训练时都能提供稀疏性的所有实际好处，同时仅略微降低其性能。然而，我们观察到，超过一定的稀疏度（约95%）后，这些方法无法保持网络性能，并且令人惊讶的是，在许多情况下甚至比简单的随机修剪表现更差。为此，我们提出了一个目标，即找到一个具有最大前瞻连接敏感度（FORCE）的骨架化网络，其中考虑了修剪网络在连接敏感度方面的可训练性。然后，我们提出了两种近似程序来最大化我们的目标：（1）迭代SNIP：允许在骨架化早期阶段不重要的参数在后期阶段变得重要；（2）FORCE：一个迭代过程，通过允许已经修剪的参数在骨架化的后期阶段复活来进行探索。大量实验的实证分析表明，我们的方法在中等修剪水平上至少提供了与其他最近方法相当的性能，在高修剪水平上提供了显著改进的性能（可以移除高达99.5%的参数，同时保持网络的可训练性）。",
        "领域": "神经网络优化",
        "问题": "在高稀疏度下保持网络性能的问题",
        "动机": "解决现有骨架化方法在高稀疏度下性能下降的问题",
        "方法": "提出了基于最大前瞻连接敏感度（FORCE）的骨架化方法和两种近似优化程序",
        "关键词": [
            "骨架化",
            "参数修剪",
            "连接敏感度",
            "网络优化",
            "高稀疏度"
        ],
        "涉及的技术概念": {
            "骨架化": "在网络初始化时修剪参数以提供稀疏性的方法",
            "前瞻连接敏感度（FORCE）": "衡量修剪网络在连接敏感度方面可训练性的指标",
            "迭代SNIP": "一种允许参数重要性随时间变化的骨架化方法"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 635,
        "title": "Projected Latent Markov Chain Monte Carlo: Conditional Sampling of Normalizing Flows",
        "html": "https://iclr.cc//virtual/2021/poster/2591",
        "abstract": "We introduce Projected Latent Markov Chain Monte Carlo (PL-MCMC), a technique for sampling from the exact conditional distributions learned by normalizing flows. As a conditional sampling method, PL-MCMC enables Monte Carlo Expectation Maximization (MC-EM) training of normalizing flows from incomplete data. Through experimental tests applying normalizing flows to missing data tasks for a variety of data sets, we demonstrate the efficacy of PL-MCMC for conditional sampling from normalizing flows.",
        "conference": "ICLR",
        "中文标题": "投影潜在马尔可夫链蒙特卡洛：归一化流的条件采样",
        "摘要翻译": "我们介绍了投影潜在马尔可夫链蒙特卡洛（PL-MCMC），这是一种从归一化流学习到的精确条件分布中进行采样的技术。作为一种条件采样方法，PL-MCMC使得从缺失数据中进行归一化流的蒙特卡洛期望最大化（MC-EM）训练成为可能。通过将归一化流应用于多种数据集的缺失数据任务的实验测试，我们证明了PL-MCMC在归一化流条件采样中的有效性。",
        "领域": "概率图模型、缺失数据处理、蒙特卡洛方法",
        "问题": "如何从归一化流学习到的条件分布中进行有效采样，特别是在处理缺失数据时。",
        "动机": "为了解决在缺失数据情况下，利用归一化流进行有效条件采样和模型训练的问题。",
        "方法": "提出投影潜在马尔可夫链蒙特卡洛（PL-MCMC）技术，用于从归一化流学习到的条件分布中进行采样，并应用于蒙特卡洛期望最大化（MC-EM）训练。",
        "关键词": [
            "归一化流",
            "条件采样",
            "马尔可夫链蒙特卡洛",
            "缺失数据",
            "期望最大化"
        ],
        "涉及的技术概念": {
            "归一化流": "一种用于建模复杂概率分布的技术，通过一系列可逆变换将简单分布转换为复杂分布。",
            "马尔可夫链蒙特卡洛（MCMC）": "一种通过构建马尔可夫链来从概率分布中采样的方法，用于近似计算复杂积分或优化问题。",
            "蒙特卡洛期望最大化（MC-EM）": "一种结合蒙特卡洛采样和期望最大化算法的技术，用于在缺失数据或不完全数据情况下进行参数估计。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 636,
        "title": "Property Controllable Variational Autoencoder via Invertible Mutual Dependence",
        "html": "https://iclr.cc//virtual/2021/poster/2938",
        "abstract": "Deep generative models have made important progress towards modeling complex, high dimensional data via learning latent representations. Their usefulness is nevertheless often limited by a lack of control over the generative process or a poor understanding of the latent representation. To overcome these issues, attention is now focused on discovering latent variables correlated to the data properties and ways to manipulate these properties. This paper presents the new Property controllable VAE (PCVAE), where a new Bayesian model is proposed to inductively bias the latent representation using explicit data properties via novel group-wise and property-wise disentanglement. Each data property corresponds seamlessly to a latent variable, by innovatively enforcing invertible mutual dependence between them. This allows us to move along the learned latent dimensions to control specific properties of the generated data with great precision. Quantitative and qualitative evaluations confirm that the PCVAE outperforms the existing models by up to 28% in capturing and 65% in manipulating the desired properties.",
        "conference": "ICLR",
        "中文标题": "通过可逆互依赖实现属性可控的变分自编码器",
        "摘要翻译": "深度生成模型通过学习潜在表示，在建模复杂高维数据方面取得了重要进展。然而，由于对生成过程缺乏控制或对潜在表示理解不足，它们的实用性往往受到限制。为了克服这些问题，当前的研究重点在于发现与数据属性相关的潜在变量以及操纵这些属性的方法。本文提出了新的属性可控变分自编码器（PCVAE），其中提出了一种新的贝叶斯模型，通过新颖的组间和属性间解缠，利用显式数据属性归纳偏置潜在表示。每个数据属性通过创新性地强制它们之间的可逆互依赖，无缝对应一个潜在变量。这使我们能够沿着学习到的潜在维度移动，以极高的精度控制生成数据的特定属性。定量和定性评估证实，PCVAE在捕获和操纵所需属性方面比现有模型高出28%和65%。",
        "领域": "生成模型、变分自编码器、属性控制",
        "问题": "深度生成模型在生成过程中缺乏控制和对潜在表示理解不足的问题",
        "动机": "提高对生成过程的控制能力，更好地理解和操纵数据的潜在表示",
        "方法": "提出属性可控变分自编码器（PCVAE），通过新的贝叶斯模型和组间及属性间解缠技术，实现潜在表示与数据属性的无缝对应和精确控制",
        "关键词": [
            "属性可控",
            "变分自编码器",
            "潜在表示",
            "贝叶斯模型",
            "解缠"
        ],
        "涉及的技术概念": {
            "变分自编码器": "一种深度生成模型，通过学习数据的潜在表示来生成新的数据样本",
            "贝叶斯模型": "在PCVAE中用于归纳偏置潜在表示，使其与数据属性相关联",
            "解缠": "通过组间和属性间的解缠技术，实现潜在变量与数据属性的一一对应，提高模型的可解释性和控制能力"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 637,
        "title": "Protecting DNNs from Theft using an Ensemble of Diverse Models",
        "html": "https://iclr.cc//virtual/2021/poster/2696",
        "abstract": "Several recent works have demonstrated highly effective model stealing (MS) attacks on Deep Neural Networks (DNNs) in black-box settings, even when the training data is unavailable. These attacks typically use some form of Out of Distribution (OOD) data to query the target model and use the predictions obtained to train a clone model. Such a clone model learns to approximate the decision boundary of the target model, achieving high accuracy on in-distribution examples. We propose Ensemble of Diverse Models (EDM) to defend against such MS attacks. EDM is made up of models that are trained to produce dissimilar predictions for OOD inputs. By using a different member of the ensemble to service different queries, our defense produces predictions that are highly discontinuous in the input space for the adversary's OOD queries. Such discontinuities cause the clone model trained on these predictions to have poor generalization on in-distribution examples. Our evaluations on several image classification tasks demonstrate that EDM defense can severely degrade the accuracy of clone models (up to $39.7\\%$). Our defense has minimal impact on the target accuracy, negligible computational costs during inference, and is compatible with existing defenses for MS attacks.",
        "conference": "ICLR",
        "中文标题": "使用多样化模型集成保护深度神经网络免受盗窃",
        "摘要翻译": "最近的一些工作展示了在黑盒设置下对深度神经网络（DNNs）进行非常有效的模型窃取（MS）攻击，即使训练数据不可用。这些攻击通常使用某种形式的分布外（OOD）数据查询目标模型，并利用获得的预测来训练克隆模型。这样的克隆模型学会近似目标模型的决策边界，在分布内示例上达到高准确率。我们提出了多样化模型集成（EDM）来防御此类MS攻击。EDM由训练用于对OOD输入产生不同预测的模型组成。通过使用集成的不同成员来服务不同的查询，我们的防御在对手的OOD查询的输入空间中产生高度不连续的预测。这种不连续性导致基于这些预测训练的克隆模型在分布内示例上泛化能力差。我们在几个图像分类任务上的评估表明，EDM防御可以严重降低克隆模型的准确率（高达39.7%）。我们的防御对目标准确率影响极小，推理过程中的计算成本可忽略不计，并且与现有的MS攻击防御兼容。",
        "领域": "模型安全、对抗性防御、图像分类",
        "问题": "防御深度神经网络模型被窃取的问题",
        "动机": "针对黑盒设置下的模型窃取攻击，提出一种有效的防御机制，保护模型知识产权",
        "方法": "提出多样化模型集成（EDM），通过训练产生对分布外输入不同预测的模型集成，使得克隆模型难以准确复制目标模型的决策边界",
        "关键词": [
            "模型窃取防御",
            "多样化模型集成",
            "分布外数据",
            "模型安全",
            "对抗性防御"
        ],
        "涉及的技术概念": {
            "模型窃取（MS）攻击": "攻击者通过查询目标模型并使用其预测训练克隆模型，试图复制目标模型的行为",
            "多样化模型集成（EDM）": "由多个模型组成的防御机制，这些模型对分布外输入产生不同的预测，增加克隆模型训练的难度",
            "分布外（OOD）数据": "不在目标模型训练数据分布内的数据，用于模型窃取攻击中查询目标模型以获取预测"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 638,
        "title": "Prototypical Contrastive Learning of Unsupervised Representations",
        "html": "https://iclr.cc//virtual/2021/poster/3090",
        "abstract": "This paper presents Prototypical Contrastive Learning (PCL), an unsupervised representation learning method that bridges contrastive learning with clustering. PCL not only learns low-level features for the task of instance discrimination, but more importantly, it implicitly encodes semantic structures of the data into the learned embedding space. Specifically, we introduce prototypes as latent variables to help find the maximum-likelihood estimation of the network parameters in an Expectation-Maximization framework. We iteratively perform E-step as finding the distribution of prototypes via clustering and M-step as optimizing the network via contrastive learning. We propose ProtoNCE loss, a generalized version of the InfoNCE loss for contrastive learning, which encourages representations to be closer to their assigned prototypes. PCL outperforms state-of-the-art instance-wise contrastive learning methods on multiple benchmarks with substantial improvement in low-resource transfer learning. Code and pretrained models are available at https://github.com/salesforce/PCL.",
        "conference": "ICLR",
        "中文标题": "原型对比学习的无监督表示学习",
        "摘要翻译": "本文提出了原型对比学习（PCL），一种将对比学习与聚类相结合的无监督表示学习方法。PCL不仅为实例判别任务学习低级特征，更重要的是，它隐式地将数据的语义结构编码到学习到的嵌入空间中。具体来说，我们引入原型作为潜在变量，以帮助在期望最大化框架中找到网络参数的最大似然估计。我们迭代执行E步，即通过聚类找到原型的分布，以及M步，即通过对比学习优化网络。我们提出了ProtoNCE损失，这是对比学习中InfoNCE损失的广义版本，它鼓励表示更接近其分配的原型。PCL在多个基准测试中优于最先进的实例级对比学习方法，在低资源迁移学习中实现了显著改进。代码和预训练模型可在https://github.com/salesforce/PCL获取。",
        "领域": "无监督学习、对比学习、聚类",
        "问题": "如何在无监督学习中有效地结合对比学习和聚类以学习数据的语义结构",
        "动机": "探索一种能够同时学习低级特征和高级语义结构的无监督表示学习方法",
        "方法": "通过引入原型作为潜在变量，在期望最大化框架中迭代执行聚类和对比学习，优化网络参数",
        "关键词": [
            "原型对比学习",
            "无监督表示学习",
            "聚类",
            "对比学习",
            "迁移学习"
        ],
        "涉及的技术概念": {
            "原型对比学习（PCL）": "一种将对比学习与聚类相结合的无监督表示学习方法，旨在学习数据的语义结构",
            "期望最大化框架": "用于在网络参数的最大似然估计中引入原型作为潜在变量的数学框架",
            "ProtoNCE损失": "对比学习中InfoNCE损失的广义版本，用于鼓励表示更接近其分配的原型"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 639,
        "title": "Prototypical Representation Learning for Relation Extraction",
        "html": "https://iclr.cc//virtual/2021/poster/3107",
        "abstract": "Recognizing relations between entities is a pivotal task of relational learning.  \nLearning relation representations from distantly-labeled datasets is difficult because of the abundant label noise and complicated expressions in human language.  \nThis paper aims to learn predictive, interpretable, and robust relation representations from distantly-labeled data that are effective in different settings, including supervised, distantly supervised, and few-shot learning. \nInstead of solely relying on the supervision from noisy labels, we propose to learn prototypes for each relation from contextual information to best explore the intrinsic semantics of relations. \nPrototypes are representations in the feature space abstracting the essential semantics of relations between entities in sentences.\nWe learn prototypes based on objectives with clear geometric interpretation, where the prototypes are unit vectors uniformly dispersed in a unit ball, and statement embeddings are centered at the end of their corresponding prototype vectors on the surface of the ball. \nThis approach allows us to learn meaningful, interpretable prototypes for the final classification.\nResults on several relation learning tasks show that our model significantly outperforms the previous state-of-the-art models.\nWe further demonstrate the robustness of the encoder and the interpretability of prototypes with extensive experiments.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "原型表示学习用于关系抽取",
        "摘要翻译": "识别实体间的关系是关系学习中的关键任务。从远距离标记的数据集中学习关系表示具有挑战性，因为人类语言中存在大量的标签噪声和复杂的表达方式。本文旨在从远距离标记的数据中学习预测性、可解释性强且鲁棒的关系表示，这些表示在包括监督学习、远距离监督学习和少样本学习在内的不同设置下都有效。我们提出不单纯依赖噪声标签的监督，而是从上下文信息中学习每个关系的原型，以最好地探索关系的内在语义。原型是特征空间中的表示，抽象了句子中实体间关系的本质语义。我们基于具有明确几何解释的目标学习原型，其中原型是单位球中均匀分散的单位向量，而陈述嵌入则位于球表面其对应原型向量的末端。这种方法使我们能够为最终分类学习有意义、可解释的原型。在多个关系学习任务上的结果表明，我们的模型显著优于之前的最先进模型。我们通过大量实验进一步证明了编码器的鲁棒性和原型的可解释性。",
        "领域": "自然语言处理与视觉结合",
        "问题": "从远距离标记的数据中学习预测性、可解释性强且鲁棒的关系表示",
        "动机": "解决远距离标记数据中因标签噪声和复杂表达导致的关系表示学习困难",
        "方法": "从上下文信息中学习每个关系的原型，基于具有明确几何解释的目标学习原型",
        "关键词": [
            "关系抽取",
            "原型学习",
            "远距离监督学习",
            "少样本学习",
            "可解释性"
        ],
        "涉及的技术概念": {
            "原型表示": "特征空间中的表示，抽象了句子中实体间关系的本质语义",
            "单位球": "原型作为单位向量均匀分散在单位球中，用于几何解释和分类",
            "陈述嵌入": "位于球表面其对应原型向量的末端，用于最终的关系分类"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 640,
        "title": "Provable Rich Observation Reinforcement Learning with Combinatorial Latent States",
        "html": "https://iclr.cc//virtual/2021/poster/3139",
        "abstract": "We propose a novel setting for reinforcement learning that combines two common real-world difficulties: presence of observations (such as camera images) and factored states (such as location of objects). In our setting, the agent receives observations generated stochastically from a 'latent' factored state. These observations are 'rich enough' to enable decoding of the latent state and remove partial observability concerns. Since the latent state is combinatorial, the size of state space is exponential in the number of latent factors. We create a learning algorithm FactoRL (Fact-o-Rel) for this setting,  which uses noise-contrastive learning to identify latent structures in emission processes and discover a factorized state space. We derive polynomial sample complexity guarantees for FactoRL which polynomially depend upon the number factors, and very weakly depend on the size of the observation space.  We also provide a guarantee of polynomial time complexity when given access to an efficient planning algorithm.",
        "conference": "ICLR",
        "中文标题": "可证明的丰富观察强化学习与组合潜在状态",
        "摘要翻译": "我们提出了一种新的强化学习设置，该设置结合了现实世界中常见的两种困难：存在观察（如相机图像）和分解状态（如物体的位置）。在我们的设置中，智能体接收从‘潜在’分解状态随机生成的观察。这些观察‘足够丰富’，能够解码潜在状态并消除部分可观察性的担忧。由于潜在状态是组合的，状态空间的大小随潜在因素的数量呈指数增长。我们为此设置创建了一个学习算法FactoRL（Fact-o-Rel），该算法使用噪声对比学习来识别发射过程中的潜在结构并发现分解的状态空间。我们为FactoRL推导了多项式样本复杂度保证，该保证多项式依赖于因素的数量，并且非常弱地依赖于观察空间的大小。我们还提供了在给定访问高效规划算法时的多项式时间复杂度保证。",
        "领域": "强化学习、计算机视觉与强化学习结合、状态空间分解",
        "问题": "如何在存在丰富观察和组合潜在状态的复杂环境中，有效地进行强化学习。",
        "动机": "解决现实世界中强化学习面临的两个主要挑战：处理来自复杂观察（如图像）的输入和在高维组合状态空间中进行有效学习。",
        "方法": "提出FactoRL算法，利用噪声对比学习识别潜在结构并发现分解的状态空间，同时提供样本和时间复杂度的理论保证。",
        "关键词": [
            "强化学习",
            "组合潜在状态",
            "噪声对比学习",
            "样本复杂度",
            "状态空间分解"
        ],
        "涉及的技术概念": {
            "噪声对比学习": "用于识别发射过程中的潜在结构，帮助发现分解的状态空间。",
            "组合潜在状态": "描述状态空间随潜在因素数量指数增长的特性，是算法处理的核心。",
            "多项式样本复杂度": "算法性能的理论保证，表明学习效率与因素数量的多项式依赖关系。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 641,
        "title": "Provably robust classification of adversarial examples with detection",
        "html": "https://iclr.cc//virtual/2021/poster/3279",
        "abstract": "Adversarial attacks against deep networks can be defended against either by building robust classifiers or, by creating classifiers that can \\emph{detect} the presence of adversarial perturbations.  Although it may intuitively seem easier to simply detect attacks rather than build a robust classifier, this has not bourne out in practice even empirically, as most detection methods have subsequently been broken by adaptive attacks, thus necessitating \\emph{verifiable} performance for detection mechanisms.  In this paper, we propose a new method for jointly training a provably robust classifier and detector.  Specifically, we show that by introducing an additional 'abstain/detection' into a classifier, we can modify existing certified defense mechanisms to allow the classifier to either robustly classify \\emph{or} detect adversarial attacks.  We extend the common interval bound propagation (IBP) method for certified robustness under $\\ell_\\infty$ perturbations to account for our new robust objective, and show that the method outperforms traditional IBP used in isolation, especially for large perturbation sizes.  Specifically, tests on MNIST and CIFAR-10 datasets exhibit promising results, for example with provable robust error less than $63.63\\%$ and $67.92\\%$, for $55.6\\%$ and $66.37\\%$ natural error, for $\\epsilon=8/255$ and $16/255$ on the CIFAR-10 dataset, respectively.\n",
        "conference": "ICLR",
        "中文标题": "可证明对抗样本的鲁棒分类与检测",
        "摘要翻译": "针对深度网络的对抗攻击可以通过构建鲁棒分类器或创建能够检测对抗性扰动的分类器来防御。尽管直觉上似乎简单地检测攻击比构建鲁棒分类器更容易，但这在实践中甚至经验上并未得到证实，因为大多数检测方法随后被自适应攻击所破解，因此需要检测机制具有可验证的性能。在本文中，我们提出了一种新的方法，用于联合训练一个可证明鲁棒的分类器和检测器。具体来说，我们展示了通过在分类器中引入一个额外的'放弃/检测'选项，我们可以修改现有的认证防御机制，使分类器能够鲁棒地分类或检测对抗攻击。我们扩展了常见的区间边界传播（IBP）方法，用于在ℓ∞扰动下的认证鲁棒性，以适应我们新的鲁棒目标，并展示了该方法优于单独使用的传统IBP，尤其是在大扰动尺寸下。具体来说，在MNIST和CIFAR-10数据集上的测试显示出有希望的结果，例如在CIFAR-10数据集上，对于ε=8/255和16/255，可证明的鲁棒错误率分别低于63.63%和67.92%，自然错误率分别为55.6%和66.37%。",
        "领域": "对抗样本防御、鲁棒分类、对抗检测",
        "问题": "如何同时实现对抗样本的鲁棒分类和检测",
        "动机": "现有的对抗样本检测方法容易被自适应攻击破解，需要开发具有可验证性能的检测机制",
        "方法": "通过在分类器中引入'放弃/检测'选项，并扩展区间边界传播（IBP）方法，联合训练一个可证明鲁棒的分类器和检测器",
        "关键词": [
            "对抗样本",
            "鲁棒分类",
            "对抗检测",
            "区间边界传播",
            "可验证防御"
        ],
        "涉及的技术概念": {
            "对抗样本": "经过精心设计的输入，旨在欺骗深度学习模型，使其做出错误的预测",
            "区间边界传播（IBP）": "一种用于在神经网络中传播输入不确定性的方法，用于认证模型在对抗攻击下的鲁棒性",
            "可验证防御": "指防御机制能够提供数学上的保证，证明在特定条件下的性能，如对抗攻击下的鲁棒性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 642,
        "title": "Proximal Gradient Descent-Ascent: Variable Convergence under KŁ Geometry",
        "html": "https://iclr.cc//virtual/2021/poster/2697",
        "abstract": "The gradient descent-ascent (GDA) algorithm has been widely applied to solve minimax optimization problems. In order to achieve convergent policy parameters for minimax optimization, it is important that GDA generates convergent variable sequences rather than convergent sequences of function value or gradient norm. However, the variable convergence of GDA has been proved only under convexity geometries, and it is lack of understanding in general nonconvex minimax optimization. This paper fills such a gap by studying the convergence of a more general proximal-GDA for regularized nonconvex-strongly-concave minimax optimization. Specifically, we show that proximal-GDA admits a novel Lyapunov function, which monotonically decreases in the minimax optimization process and drives the variable sequences to a critical point. By leveraging this Lyapunov function and the KL geometry that parameterizes the local geometries of general nonconvex functions, we formally establish the variable convergence of proximal-GDA to a certain critical point $x^*$, i.e., $x_t\\to x^*, y_t\\to y^*(x^*)$. Furthermore, over the full spectrum of the KL-parameterized geometry, we show that proximal-GDA achieves different types of convergence rates ranging from sublinear convergence up to finite-step convergence, depending on the geometry associated with the KL parameter. This is the first theoretical result on the variable convergence for nonconvex minimax optimization. ",
        "conference": "ICLR",
        "中文标题": "近端梯度下降-上升法：在KŁ几何下的变量收敛",
        "摘要翻译": "梯度下降-上升（GDA）算法已被广泛应用于解决极小极大优化问题。为了实现极小极大优化的收敛策略参数，重要的是GDA生成的是变量序列的收敛，而不是函数值或梯度范数的序列收敛。然而，GDA的变量收敛仅在凸性几何下被证明，在一般非凸极小极大优化中缺乏理解。本文通过研究一种更一般的近端-GDA对于正则化非凸-强凹极小极大优化的收敛性，填补了这一空白。具体来说，我们展示了近端-GDA允许一种新颖的Lyapunov函数，该函数在极小极大优化过程中单调递减，并驱动变量序列到达一个临界点。通过利用这个Lyapunov函数和参数化一般非凸函数局部几何的KL几何，我们正式建立了近端-GDA对某个临界点x*的变量收敛性，即x_t→x*, y_t→y*(x*)。此外，在KL参数化几何的全谱上，我们展示了近端-GDA根据与KL参数相关的几何，实现了从次线性收敛到有限步收敛的不同类型的收敛速率。这是关于非凸极小极大优化变量收敛的第一个理论结果。",
        "领域": "优化算法、非凸优化、极小极大问题",
        "问题": "解决非凸极小极大优化问题中变量序列的收敛性问题",
        "动机": "研究GDA算法在非凸极小极大优化中的变量收敛性，填补现有理论空白",
        "方法": "提出并分析一种更一般的近端-GDA算法，利用Lyapunov函数和KL几何理论证明其变量收敛性",
        "关键词": [
            "近端梯度下降-上升法",
            "非凸优化",
            "极小极大问题",
            "KL几何",
            "变量收敛"
        ],
        "涉及的技术概念": {
            "近端-GDA": "一种扩展的梯度下降-上升算法，用于处理正则化的非凸-强凹极小极大优化问题",
            "Lyapunov函数": "用于证明算法收敛性的函数，其在优化过程中单调递减",
            "KL几何": "用于参数化非凸函数局部几何的理论框架，帮助分析算法的收敛行为"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 643,
        "title": "Pruning Neural Networks at Initialization: Why Are We Missing the Mark?",
        "html": "https://iclr.cc//virtual/2021/poster/3159",
        "abstract": "Recent work has explored the possibility of pruning neural networks at initialization. We assess proposals for doing so: SNIP (Lee et al., 2019), GraSP (Wang et al., 2020), SynFlow (Tanaka et al., 2020), and magnitude pruning. Although these methods surpass the trivial baseline of random pruning, they remain below the accuracy of magnitude pruning after training, and we endeavor to understand why. We show that, unlike pruning after training, randomly shuffling the weights these methods prune within each layer or sampling new initial values preserves or improves accuracy. As such, the per-weight pruning decisions made by these methods can be replaced by a per-layer choice of the fraction of weights to prune. This property suggests broader challenges with the underlying pruning heuristics, the desire to prune at initialization, or both.",
        "conference": "ICLR",
        "中文标题": "在初始化时修剪神经网络：为何我们未能命中目标？",
        "摘要翻译": "最近的研究探索了在初始化时修剪神经网络的可能性。我们评估了以下几种方法：SNIP（Lee等人，2019年）、GraSP（Wang等人，2020年）、SynFlow（Tanaka等人，2020年）以及幅度修剪。尽管这些方法超越了随机修剪的简单基线，但它们仍然低于训练后幅度修剪的准确度，我们努力理解其中的原因。我们发现，与训练后修剪不同，随机打乱这些方法在每个层内修剪的权重或采样新的初始值可以保持或提高准确度。因此，这些方法所做的每个权重的修剪决策可以被替换为每个层选择修剪权重的比例。这一性质表明，关于基础修剪启发式、希望在初始化时修剪的愿望，或两者都存在更广泛的挑战。",
        "领域": "神经网络优化",
        "问题": "评估和比较在神经网络初始化阶段进行修剪的不同方法的有效性，并探讨其准确度低于训练后修剪的原因。",
        "动机": "探索在神经网络初始化阶段进行修剪的可行性，理解现有方法准确度不高的原因，并提出改进方向。",
        "方法": "通过比较SNIP、GraSP、SynFlow和幅度修剪等方法，分析它们在初始化阶段修剪神经网络的效果，并通过随机打乱权重或采样新初始值来测试修剪决策的影响。",
        "关键词": [
            "神经网络修剪",
            "初始化修剪",
            "权重优化",
            "模型压缩"
        ],
        "涉及的技术概念": {
            "SNIP": "一种在神经网络初始化阶段进行修剪的方法，旨在识别并移除对网络性能影响较小的权重。",
            "GraSP": "另一种初始化修剪技术，通过梯度信号保护重要权重，以提高修剪后的网络性能。",
            "幅度修剪": "一种常见的修剪方法，基于权重的幅度大小来决定是否修剪，通常在训练后进行以提高模型效率。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 644,
        "title": "PseudoSeg: Designing Pseudo Labels for Semantic Segmentation",
        "html": "https://iclr.cc//virtual/2021/poster/3033",
        "abstract": "Recent advances in semi-supervised learning (SSL) demonstrate that a combination of consistency regularization and pseudo-labeling can effectively improve image classification accuracy in the low-data regime. Compared to classification, semantic segmentation tasks require much more intensive labeling costs. Thus, these tasks greatly benefit from data-efficient training methods. However, structured outputs in segmentation render particular difficulties (e.g., designing pseudo-labeling and augmentation) to apply existing SSL strategies. To address this problem, we present a simple and novel re-design of pseudo-labeling to generate well-calibrated structured pseudo labels for training with unlabeled or weakly-labeled data. Our proposed pseudo-labeling strategy is network structure agnostic to apply in a one-stage consistency training framework. We demonstrate the effectiveness of the proposed pseudo-labeling strategy in both low-data and high-data regimes. Extensive experiments have validated that pseudo labels generated from wisely fusing diverse sources and strong data augmentation are crucial to consistency training for segmentation. The source code will be released.",
        "conference": "ICLR",
        "中文标题": "PseudoSeg：为语义分割设计伪标签",
        "摘要翻译": "半监督学习（SSL）的最新进展表明，一致性正则化和伪标记的结合可以有效提高低数据量情况下的图像分类准确率。与分类相比，语义分割任务需要更多的标注成本。因此，这些任务极大地受益于数据高效的训练方法。然而，分割中的结构化输出给应用现有的SSL策略带来了特别的困难（例如，设计伪标记和数据增强）。为了解决这个问题，我们提出了一种简单而新颖的伪标记重新设计，以生成校准良好的结构化伪标签，用于未标记或弱标记数据的训练。我们提出的伪标记策略与网络结构无关，可以应用于一阶段一致性训练框架中。我们证明了所提出的伪标记策略在低数据量和高数据量情况下的有效性。大量实验验证了，通过明智地融合不同来源和强数据增强生成的伪标签对于分割的一致性训练至关重要。源代码将被发布。",
        "领域": "语义分割、半监督学习、数据增强",
        "问题": "如何在语义分割任务中有效应用半监督学习策略，特别是在结构化输出带来的伪标记和数据增强设计上的困难。",
        "动机": "减少语义分割任务中的标注成本，提高数据利用效率，通过设计有效的伪标记策略来优化半监督学习在分割任务中的应用。",
        "方法": "提出了一种新颖的伪标记重新设计方法，生成校准良好的结构化伪标签，适用于未标记或弱标记数据的训练，该方法与网络结构无关，可应用于一阶段一致性训练框架。",
        "关键词": [
            "语义分割",
            "半监督学习",
            "伪标记",
            "数据增强",
            "一致性训练"
        ],
        "涉及的技术概念": {
            "伪标记": "在未标记或弱标记数据上生成用于训练的标签，以减少标注成本。",
            "一致性训练": "通过确保模型在不同数据增强或扰动下的预测一致性来提高模型性能的训练框架。",
            "数据增强": "通过对训练数据进行各种变换来增加数据的多样性，以提高模型的泛化能力。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 645,
        "title": "PSTNet: Point Spatio-Temporal Convolution on Point Cloud Sequences",
        "html": "https://iclr.cc//virtual/2021/poster/3101",
        "abstract": "Point cloud sequences are irregular and unordered in the spatial dimension while exhibiting regularities and order in the temporal dimension. Therefore, existing grid based convolutions for conventional video processing cannot be directly applied to spatio-temporal modeling of raw point cloud sequences. In this paper, we propose a point spatio-temporal (PST) convolution to achieve informative representations of point cloud sequences. The proposed PST convolution first disentangles space and time in point cloud sequences.  Then, a spatial convolution is employed to capture the local structure of points in the 3D space, and a temporal convolution is used to model the dynamics of the spatial regions along the time dimension.  Furthermore, we incorporate the proposed PST convolution into a deep network, namely PSTNet, to extract features of point cloud sequences in a hierarchical manner.  Extensive experiments on widely-used 3D action recognition and 4D semantic segmentation datasets demonstrate the effectiveness of PSTNet to model point cloud sequences.",
        "conference": "ICLR",
        "中文标题": "PSTNet：点云序列的点时空卷积",
        "摘要翻译": "点云序列在空间维度上是不规则且无序的，而在时间维度上则表现出规律性和有序性。因此，现有的基于网格的传统视频处理卷积方法不能直接应用于原始点云序列的时空建模。本文提出了一种点时空（PST）卷积方法，以实现点云序列的信息丰富表示。所提出的PST卷积首先解耦了点云序列中的空间和时间。然后，采用空间卷积捕捉3D空间中点的局部结构，使用时间卷积沿时间维度建模空间区域的动态变化。此外，我们将提出的PST卷积整合到一个深度网络中，即PSTNet，以分层方式提取点云序列的特征。在广泛使用的3D动作识别和4D语义分割数据集上进行的大量实验证明了PSTNet在建模点云序列方面的有效性。",
        "领域": "点云处理, 3D动作识别, 4D语义分割",
        "问题": "如何有效地对点云序列进行时空建模",
        "动机": "点云序列在空间维度上的不规则性和无序性使得传统的基于网格的卷积方法无法直接应用，需要开发新的方法来处理这种数据",
        "方法": "提出点时空（PST）卷积方法，先解耦点云序列中的空间和时间，然后分别使用空间卷积和时间卷积捕捉局部结构和动态变化，最后整合到深度网络PSTNet中进行特征提取",
        "关键词": [
            "点云序列",
            "时空卷积",
            "3D动作识别",
            "4D语义分割",
            "PSTNet"
        ],
        "涉及的技术概念": {
            "点时空卷积": "解耦点云序列中的空间和时间，分别处理以捕捉局部结构和动态变化",
            "空间卷积": "用于捕捉3D空间中点的局部结构",
            "时间卷积": "用于沿时间维度建模空间区域的动态变化"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 646,
        "title": "QPLEX: Duplex Dueling Multi-Agent Q-Learning",
        "html": "https://iclr.cc//virtual/2021/poster/3237",
        "abstract": "We explore value-based multi-agent reinforcement learning (MARL) in the popular paradigm of centralized training with decentralized execution (CTDE). CTDE has an important concept, Individual-Global-Max (IGM) principle, which requires the consistency between joint and local action selections to support efficient local decision-making. However, in order to achieve scalability, existing MARL methods either limit representation expressiveness of their value function classes or relax the IGM consistency, which may suffer from instability risk or may not perform well in complex domains. This paper presents a novel MARL approach, called duPLEX dueling multi-agent Q-learning (QPLEX), which takes a duplex dueling network architecture to factorize the joint value function. This duplex dueling structure encodes the IGM principle into the neural network architecture and thus enables efficient value function learning. Theoretical analysis shows that QPLEX achieves a complete IGM function class. Empirical experiments on StarCraft II micromanagement tasks demonstrate that QPLEX significantly outperforms state-of-the-art baselines in both online and offline data collection settings, and also reveal that QPLEX achieves high sample efficiency and can benefit from offline datasets without additional online exploration.",
        "conference": "ICLR",
        "中文标题": "QPLEX：双工对决多智能体Q学习",
        "摘要翻译": "我们在集中训练与分散执行（CTDE）的流行范式下探索了基于值的多智能体强化学习（MARL）。CTDE有一个重要的概念，即个体-全局最大化（IGM）原则，它要求联合和局部行动选择之间的一致性，以支持有效的局部决策。然而，为了实现可扩展性，现有的MARL方法要么限制了其价值函数类的表示表达能力，要么放松了IGM一致性，这可能会遭受不稳定风险或在复杂领域中表现不佳。本文提出了一种新的MARL方法，称为双工对决多智能体Q学习（QPLEX），它采用双工对决网络架构来分解联合价值函数。这种双工对决结构将IGM原则编码到神经网络架构中，从而实现了高效的价值函数学习。理论分析表明，QPLEX实现了一个完整的IGM函数类。在《星际争霸II》微管理任务上的实证实验表明，QPLEX在在线和离线数据收集设置中均显著优于最先进的基线，并且还揭示了QPLEX实现了高样本效率，并且可以从离线数据集中受益而无需额外的在线探索。",
        "领域": "多智能体强化学习",
        "问题": "如何在保持个体-全局最大化（IGM）原则一致性的同时，提高多智能体强化学习的可扩展性和性能。",
        "动机": "现有的多智能体强化学习方法在追求可扩展性时，往往牺牲了价值函数类的表示表达能力或放松了IGM一致性，导致性能不稳定或在复杂任务中表现不佳。",
        "方法": "提出了一种名为QPLEX的新方法，采用双工对决网络架构分解联合价值函数，将IGM原则编码到神经网络架构中，以实现高效的价值函数学习。",
        "关键词": [
            "多智能体强化学习",
            "双工对决网络",
            "IGM原则"
        ],
        "涉及的技术概念": {
            "集中训练与分散执行（CTDE）": "一种多智能体强化学习的训练范式，允许在训练时集中信息，在执行时分散决策。",
            "个体-全局最大化（IGM）原则": "确保联合和局部行动选择之间一致性的原则，以支持有效的局部决策。",
            "双工对决网络架构": "一种网络架构，用于分解联合价值函数，同时编码IGM原则，以提高学习效率和性能。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 647,
        "title": "Quantifying Differences in Reward Functions",
        "html": "https://iclr.cc//virtual/2021/poster/3348",
        "abstract": "For many tasks, the reward function is inaccessible to introspection or too complex to be specified procedurally, and must instead be learned from user data. Prior work has evaluated learned reward functions by evaluating policies optimized for the learned reward. However, this method cannot distinguish between the learned reward function failing to reflect user preferences and the policy optimization process failing to optimize the learned reward. Moreover, this method can only tell us about behavior in the evaluation environment, but the reward may incentivize very different behavior in even a slightly different deployment environment. To address these problems, we introduce the Equivalent-Policy Invariant Comparison (EPIC) distance to quantify the difference between two reward functions directly, without a policy optimization step. We prove EPIC is invariant on an equivalence class of reward functions that always induce the same optimal policy. Furthermore, we find EPIC can be efficiently approximated and is more robust than baselines to the choice of coverage distribution. Finally, we show that EPIC distance bounds the regret of optimal policies even under different transition dynamics, and we confirm empirically that it predicts policy training success. Our source code is available at https://github.com/HumanCompatibleAI/evaluating-rewards.",
        "conference": "ICLR",
        "中文标题": "量化奖励函数的差异",
        "摘要翻译": "对于许多任务，奖励函数既无法通过内省获得，也无法通过程序化方式指定其复杂性，而必须从用户数据中学习。先前的工作通过评估为学习到的奖励优化的策略来评估学习到的奖励函数。然而，这种方法无法区分学习到的奖励函数未能反映用户偏好与策略优化过程未能优化学习到的奖励之间的差异。此外，这种方法只能告诉我们评估环境中的行为，但奖励可能在甚至略有不同的部署环境中激励完全不同的行为。为了解决这些问题，我们引入了等效策略不变比较（EPIC）距离，以直接量化两个奖励函数之间的差异，而无需策略优化步骤。我们证明EPIC在总是诱导相同最优策略的奖励函数等价类上是不变的。此外，我们发现EPIC可以高效近似，并且比基线方法对覆盖分布的选择更具鲁棒性。最后，我们展示了即使在不同的转移动态下，EPIC距离也能限制最优策略的遗憾，并且我们通过实验证实它能够预测策略训练的成功。我们的源代码可在https://github.com/HumanCompatibleAI/evaluating-rewards获取。",
        "领域": "强化学习、奖励函数学习、策略优化",
        "问题": "如何直接量化两个奖励函数之间的差异，而无需依赖策略优化的结果",
        "动机": "现有方法无法区分奖励函数学习失败与策略优化失败，且评估结果受限于特定环境",
        "方法": "引入等效策略不变比较（EPIC）距离，直接比较奖励函数，无需策略优化步骤",
        "关键词": [
            "奖励函数",
            "策略优化",
            "EPIC距离",
            "强化学习",
            "用户偏好"
        ],
        "涉及的技术概念": {
            "等效策略不变比较（EPIC）距离": "用于直接量化两个奖励函数之间的差异，无需进行策略优化，具有高效近似和鲁棒性强的特点",
            "奖励函数等价类": "一组总是诱导相同最优策略的奖励函数，EPIC距离在此类函数上保持不变",
            "覆盖分布": "影响奖励函数比较的鲁棒性，EPIC距离对此分布的选择具有较强的适应性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 648,
        "title": "Random Feature Attention",
        "html": "https://iclr.cc//virtual/2021/poster/3213",
        "abstract": "Transformers are state-of-the-art models for a variety of sequence modeling tasks. At their core is an attention function which models pairwise interactions between the inputs at every timestep. While attention is powerful, it does not scale efficiently to long sequences due to its quadratic time and space complexity in the sequence length. We propose RFA, a linear time and space attention that uses random feature methods to approximate the softmax function, and explore its application in transformers. RFA can be used as a drop-in replacement for conventional softmax attention and offers a straightforward way of learning with recency bias through an optional gating mechanism. Experiments on language modeling and machine translation demonstrate that RFA achieves similar or better performance compared to strong transformer baselines. In the machine translation experiment, RFA decodes twice as fast as a vanilla transformer. Compared to existing efficient transformer variants, RFA is competitive in terms of both accuracy and efficiency on three long text classification datasets. Our analysis shows that RFA’s efficiency gains are especially notable on long sequences, suggesting that RFA will be particularly useful in tasks that require working with large inputs, fast decoding speed, or low memory footprints.",
        "conference": "ICLR",
        "中文标题": "随机特征注意力",
        "摘要翻译": "Transformer是多种序列建模任务的最先进模型。其核心是一个注意力函数，该函数在每一步建模输入之间的成对交互。尽管注意力功能强大，但由于其在序列长度上的二次时间和空间复杂度，它无法高效地扩展到长序列。我们提出了RFA，一种使用随机特征方法近似softmax函数的线性时间和空间注意力，并探索了其在Transformer中的应用。RFA可以作为传统softmax注意力的直接替代品，并通过可选的门控机制提供了一种简单的方法来学习最近偏置。在语言建模和机器翻译上的实验表明，RFA与强大的Transformer基线相比，实现了相似或更好的性能。在机器翻译实验中，RFA的解码速度是普通Transformer的两倍。与现有的高效Transformer变体相比，RFA在三个长文本分类数据集上的准确性和效率都具有竞争力。我们的分析表明，RFA的效率提升在长序列上尤为显著，这表明RFA在需要处理大输入、快速解码速度或低内存占用的任务中将特别有用。",
        "领域": "自然语言处理与视觉结合, 序列建模, 机器翻译",
        "问题": "解决Transformer模型中注意力机制在长序列上时间和空间复杂度高的问题",
        "动机": "提高Transformer模型在处理长序列时的效率，同时保持或提升模型性能",
        "方法": "提出了一种名为RFA的线性时间和空间注意力机制，使用随机特征方法近似softmax函数，并探索其在Transformer中的应用",
        "关键词": [
            "随机特征注意力",
            "Transformer",
            "序列建模",
            "机器翻译",
            "长文本分类"
        ],
        "涉及的技术概念": {
            "随机特征方法": "用于近似softmax函数，减少计算复杂度",
            "线性时间和空间注意力": "RFA的核心，使得注意力机制在长序列上更加高效",
            "门控机制": "可选的机制，用于学习最近偏置，增强模型性能"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 649,
        "title": "Randomized Automatic Differentiation",
        "html": "https://iclr.cc//virtual/2021/poster/2684",
        "abstract": "The successes of deep learning, variational inference, and many other fields have been aided by specialized implementations of reverse-mode automatic differentiation (AD) to compute gradients of mega-dimensional objectives. The AD techniques underlying these tools were designed to compute exact gradients to numerical precision, but modern machine learning models are almost always trained with stochastic gradient descent. Why spend computation and memory on exact (minibatch) gradients only to use them for stochastic optimization? We develop a general framework and approach for randomized automatic differentiation (RAD), which can allow unbiased gradient estimates to be computed with reduced memory in return for variance. We examine limitations of the general approach, and argue that we must leverage problem specific structure to realize benefits. We develop RAD techniques for a variety of simple neural network architectures, and show that for a fixed memory budget, RAD converges in fewer iterations than using a small batch size for feedforward networks, and in a similar number for recurrent networks. We also show that RAD can be applied to scientific computing, and use it to develop a low-memory stochastic gradient method for optimizing the control parameters of a linear reaction-diffusion PDE representing a fission reactor.",
        "conference": "ICLR",
        "中文标题": "随机自动微分",
        "摘要翻译": "深度学习、变分推断以及其他许多领域的成功，得益于专门实现的反向模式自动微分（AD）技术，用于计算超维目标的梯度。这些工具背后的AD技术旨在计算数值精度上的精确梯度，但现代机器学习模型几乎总是使用随机梯度下降进行训练。为什么要花费计算和内存资源在精确（小批量）梯度上，仅仅是为了将它们用于随机优化？我们开发了一个随机自动微分（RAD）的通用框架和方法，可以在减少内存的情况下计算无偏梯度估计，以换取方差。我们研究了通用方法的局限性，并认为必须利用问题特定的结构来实现效益。我们为多种简单的神经网络架构开发了RAD技术，并表明对于固定的内存预算，RAD在前馈网络中比使用小批量大小收敛得更快，在循环网络中收敛的迭代次数相近。我们还展示了RAD可以应用于科学计算，并利用它开发了一种低内存随机梯度方法，用于优化代表裂变反应堆的线性反应-扩散PDE的控制参数。",
        "领域": "深度学习优化、变分推断、科学计算",
        "问题": "如何在减少内存使用的情况下，通过引入随机性来估计梯度，以支持大规模机器学习模型的训练。",
        "动机": "现代机器学习模型通常使用随机梯度下降进行训练，而传统的自动微分技术计算的是精确梯度，这在计算和内存上可能不是最优的。",
        "方法": "开发了一种随机自动微分（RAD）的通用框架和方法，通过引入随机性来减少内存使用，同时保持梯度的无偏估计。",
        "关键词": [
            "随机自动微分",
            "梯度估计",
            "内存优化",
            "深度学习优化",
            "科学计算"
        ],
        "涉及的技术概念": {
            "随机自动微分（RAD）": "一种通过引入随机性来减少内存使用的自动微分技术，用于计算无偏梯度估计。",
            "反向模式自动微分（AD）": "一种计算梯度的技术，特别适用于深度学习中的反向传播。",
            "随机梯度下降": "一种优化算法，通过使用梯度的随机估计来更新模型参数，常用于大规模机器学习模型的训练。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 650,
        "title": "Randomized Ensembled Double Q-Learning: Learning Fast Without a Model",
        "html": "https://iclr.cc//virtual/2021/poster/3320",
        "abstract": "Using a high Update-To-Data (UTD) ratio, model-based methods have recently achieved much higher sample efficiency than previous model-free methods for continuous-action DRL benchmarks. In this paper, we introduce a simple model-free algorithm, Randomized Ensembled Double Q-Learning (REDQ), and show that its performance is just as good as, if not better than, a state-of-the-art model-based algorithm for the MuJoCo benchmark. Moreover, REDQ can achieve this performance using fewer parameters than the model-based method, and with less wall-clock run time. REDQ has three carefully integrated ingredients which allow it to achieve its high performance: (i) a UTD ratio $\\gg 1$; (ii) an ensemble of Q functions; (iii) in-target minimization across a random subset of Q functions from the ensemble. Through carefully designed experiments, we provide a detailed analysis of REDQ and related model-free algorithms. To our knowledge, REDQ is the first successful model-free DRL algorithm for continuous-action spaces using a UTD ratio $\\gg 1$. ",
        "conference": "ICLR",
        "中文标题": "随机集成双Q学习：无需模型快速学习",
        "摘要翻译": "使用高更新数据比（UTD），基于模型的方法最近在连续动作深度强化学习（DRL）基准测试中实现了比以往无模型方法更高的样本效率。本文介绍了一种简单的无模型算法——随机集成双Q学习（REDQ），并表明其在MuJoCo基准测试中的性能至少与最先进的基于模型算法相当，甚至更优。此外，REDQ能够使用比基于模型方法更少的参数和更短的运行时间实现这一性能。REDQ有三个精心整合的要素，使其能够实现高性能：（i）UTD比远大于1；（ii）Q函数的集成；（iii）在集成中随机选择的Q函数子集上进行目标内最小化。通过精心设计的实验，我们对REDQ及相关无模型算法进行了详细分析。据我们所知，REDQ是第一个成功使用UTD比远大于1的无模型DRL算法，适用于连续动作空间。",
        "领域": "深度强化学习、连续动作空间优化、算法效率提升",
        "问题": "如何在连续动作空间的深度强化学习中，无需模型即可实现高样本效率和快速学习。",
        "动机": "解决基于模型的方法在连续动作空间深度强化学习中样本效率高但实现复杂的问题，提出一种简单且高效的无模型算法。",
        "方法": "提出随机集成双Q学习（REDQ）算法，结合高UTD比、Q函数集成和随机子集目标内最小化三个要素，实现高效学习。",
        "关键词": [
            "随机集成双Q学习",
            "连续动作空间",
            "深度强化学习",
            "样本效率",
            "无模型算法"
        ],
        "涉及的技术概念": {
            "UTD比": "更新数据比，用于衡量算法更新频率与数据收集效率的关系，REDQ中UTD比远大于1以提高样本效率。",
            "Q函数集成": "使用多个Q函数进行集成，以提高算法的稳定性和性能。",
            "目标内最小化": "在Q函数集成的随机子集上进行目标值的最小化，以减少过高估计并提高学习效率。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 651,
        "title": "Rank the Episodes: A Simple Approach for Exploration in Procedurally-Generated Environments",
        "html": "https://iclr.cc//virtual/2021/poster/2671",
        "abstract": "Exploration under sparse reward is a long-standing challenge of model-free reinforcement learning. The state-of-the-art methods address this challenge by introducing intrinsic rewards to encourage exploration in novel states or uncertain environment dynamics. Unfortunately, methods based on intrinsic rewards often fall short in procedurally-generated environments, where a different environment is generated in each episode so that the agent is not likely to visit the same state more than once. Motivated by how humans distinguish good exploration behaviors by looking into the entire episode, we introduce RAPID, a simple yet effective episode-level exploration method for procedurally-generated environments. RAPID regards each episode as a whole and gives an episodic exploration score from both per-episode and long-term views. Those highly scored episodes are treated as good exploration behaviors and are stored in a small ranking buffer. The agent then imitates the episodes in the buffer to reproduce the past good exploration behaviors. We demonstrate our method on several procedurally-generated MiniGrid environments, a first-person-view 3D Maze navigation task from MiniWorld, and several sparse MuJoCo tasks. The results show that RAPID significantly outperforms the state-of-the-art intrinsic reward strategies in terms of sample efficiency and final performance. The code is available at https://github.com/daochenzha/rapid",
        "conference": "ICLR",
        "中文标题": "为情节排名：一种在程序生成环境中探索的简单方法",
        "摘要翻译": "在稀疏奖励下的探索是模型无关强化学习长期面临的挑战。最先进的方法通过引入内在奖励来鼓励在新状态或不确定环境动态中的探索，以应对这一挑战。然而，在程序生成环境中，基于内在奖励的方法往往表现不佳，因为每个情节都会生成一个不同的环境，使得智能体不太可能多次访问同一状态。受到人类通过观察整个情节来区分良好探索行为的启发，我们引入了RAPID，一种简单而有效的针对程序生成环境的情节级探索方法。RAPID将每个情节视为一个整体，并从单情节和长期视角给出情节探索评分。那些评分高的情节被视为良好的探索行为，并被存储在一个小型排名缓冲区中。智能体随后模仿缓冲区中的情节，以重现过去的良好探索行为。我们在几个程序生成的MiniGrid环境、来自MiniWorld的第一人称视角3D迷宫导航任务以及几个稀疏MuJoCo任务上展示了我们的方法。结果表明，RAPID在样本效率和最终性能方面显著优于最先进的内在奖励策略。代码可在https://github.com/daochenzha/rapid获取。",
        "领域": "强化学习探索策略、程序生成环境适应、稀疏奖励优化",
        "问题": "解决在程序生成环境中，由于环境不断变化导致传统基于内在奖励的探索方法效果不佳的问题。",
        "动机": "受到人类通过评估整个情节来识别有效探索行为的启发，开发一种能够适应程序生成环境变化的探索方法。",
        "方法": "提出RAPID方法，通过评估和排名整个情节的探索效果，存储并模仿高评分情节的探索行为。",
        "关键词": [
            "程序生成环境",
            "情节级探索",
            "内在奖励",
            "样本效率",
            "强化学习"
        ],
        "涉及的技术概念": {
            "情节级探索评分": "通过评估整个情节的探索效果来指导智能体的探索行为。",
            "排名缓冲区": "存储高探索评分的情节，供智能体模仿以重现有效探索行为。",
            "内在奖励策略": "传统方法通过内在奖励鼓励探索，但在程序生成环境中效果有限。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 652,
        "title": "Rao-Blackwellizing the Straight-Through Gumbel-Softmax Gradient Estimator",
        "html": "https://iclr.cc//virtual/2021/poster/2724",
        "abstract": "Gradient estimation in models with discrete latent variables is a challenging problem, because the simplest unbiased estimators tend to have high variance. To counteract this, modern estimators either introduce bias, rely on multiple function evaluations, or use learned, input-dependent baselines. Thus, there is a need for estimators that require minimal tuning, are computationally cheap, and have low mean squared error. In this paper, we show that the variance of the straight-through variant of the popular Gumbel-Softmax estimator can be reduced through Rao-Blackwellization without increasing the number of function evaluations. This provably reduces the mean squared error. We empirically demonstrate that this leads to variance reduction, faster convergence, and generally improved performance in two unsupervised latent variable models.",
        "conference": "ICLR",
        "中文标题": "Rao-Blackwell化直通Gumbel-Softmax梯度估计器",
        "摘要翻译": "在具有离散潜在变量的模型中，梯度估计是一个具有挑战性的问题，因为最简单的无偏估计器往往具有高方差。为了抵消这一点，现代估计器要么引入偏差，依赖于多次函数评估，要么使用学习的、输入相关的基线。因此，需要那些需要最少调整、计算成本低且均方误差小的估计器。在本文中，我们展示了流行的Gumbel-Softmax估计器的直通变体的方差可以通过Rao-Blackwell化减少，而不增加函数评估的次数。这被证明可以减少均方误差。我们通过实证表明，在两个无监督潜在变量模型中，这导致了方差减少、更快的收敛和整体性能的提升。",
        "领域": "概率图模型, 变分推断, 无监督学习",
        "问题": "减少离散潜在变量模型中梯度估计的方差，提高估计效率",
        "动机": "解决离散潜在变量模型中梯度估计高方差的问题，寻求一种计算效率高、调整少的估计方法",
        "方法": "通过Rao-Blackwell化减少Gumbel-Softmax估计器的直通变体的方差，不增加函数评估次数",
        "关键词": [
            "梯度估计",
            "Gumbel-Softmax",
            "Rao-Blackwell化",
            "离散潜在变量",
            "无监督学习"
        ],
        "涉及的技术概念": {
            "Gumbel-Softmax估计器": "一种用于离散潜在变量模型的梯度估计方法，通过引入Gumbel噪声和温度参数来近似离散分布的梯度",
            "Rao-Blackwell化": "一种减少估计器方差的技术，通过条件期望来改进估计器的性能",
            "直通梯度估计": "一种梯度估计策略，允许梯度通过离散操作直接传播，常用于训练包含离散变量的模型"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 653,
        "title": "Rapid Neural Architecture Search by Learning to Generate Graphs from Datasets",
        "html": "https://iclr.cc//virtual/2021/poster/3142",
        "abstract": "Despite the success of recent Neural Architecture Search (NAS) methods on various tasks which have shown to output networks that largely outperform human-designed networks, conventional NAS methods have mostly tackled the optimization of searching for the network architecture for a single task (dataset), which does not generalize well across multiple tasks (datasets). Moreover, since such task-specific methods search for a neural architecture from scratch for every given task, they incur a large computational cost, which is problematic when the time and monetary budget are limited. In this paper, we propose an efficient NAS framework that is trained once on a database consisting of datasets and pretrained networks and can rapidly search for a neural architecture for a novel dataset. The proposed MetaD2A (Meta Dataset-to-Architecture) model can stochastically generate graphs (architectures) from a given set (dataset) via a cross-modal latent space learned with amortized meta-learning. Moreover, we also propose a meta-performance predictor to estimate and select the best architecture without direct training on target datasets. The experimental results demonstrate that our model meta-learned on subsets of ImageNet-1K and architectures from NAS-Bench 201 search space successfully generalizes to multiple unseen datasets including CIFAR-10 and CIFAR-100, with an average search time of 33 GPU seconds. Even under MobileNetV3 search space, MetaD2A is 5.5K times faster than NSGANetV2, a transferable NAS method, with comparable performance. We believe that the MetaD2A proposes a new research direction for rapid NAS as well as ways to utilize the knowledge from rich databases of datasets and architectures accumulated over the past years. Code is available at https://github.com/HayeonLee/MetaD2A.",
        "conference": "ICLR",
        "中文标题": "通过学习从数据集生成图实现快速神经架构搜索",
        "摘要翻译": "尽管最近的神经架构搜索（NAS）方法在各种任务上取得了成功，显示出能够输出大幅超越人工设计网络的网络架构，但传统的NAS方法主要解决了为单一任务（数据集）搜索网络架构的优化问题，这在跨多个任务（数据集）时泛化能力不强。此外，由于这种针对特定任务的方法为每个给定任务从头开始搜索神经架构，它们产生了大量的计算成本，这在时间和金钱预算有限时是有问题的。在本文中，我们提出了一个高效的NAS框架，该框架在一个由数据集和预训练网络组成的数据库上进行一次性训练，并能够快速为新数据集搜索神经架构。提出的MetaD2A（元数据集到架构）模型可以通过使用摊销元学习学习的跨模态潜在空间，从给定集合（数据集）中随机生成图（架构）。此外，我们还提出了一个元性能预测器，用于估计和选择最佳架构，而无需在目标数据集上直接训练。实验结果表明，我们的模型在ImageNet-1K的子集和NAS-Bench 201搜索空间的架构上进行元学习后，成功泛化到包括CIFAR-10和CIFAR-100在内的多个未见数据集，平均搜索时间为33 GPU秒。即使在MobileNetV3搜索空间下，MetaD2A也比可转移NAS方法NSGANetV2快5.5K倍，性能相当。我们相信MetaD2A为快速NAS提出了新的研究方向，以及利用过去几年积累的丰富数据集和架构数据库知识的方法。代码可在https://github.com/HayeonLee/MetaD2A获取。",
        "领域": "神经架构搜索、深度学习优化、跨任务学习",
        "问题": "传统神经架构搜索方法在跨任务泛化能力和计算成本方面的问题",
        "动机": "提高神经架构搜索的效率和跨任务泛化能力，减少计算成本",
        "方法": "提出MetaD2A框架，通过元学习和跨模态潜在空间快速生成和选择神经架构",
        "关键词": [
            "神经架构搜索",
            "元学习",
            "跨模态学习",
            "快速搜索",
            "性能预测"
        ],
        "涉及的技术概念": {
            "神经架构搜索（NAS）": "自动化设计神经网络架构的技术，旨在找到最优的网络结构",
            "元学习": "学习如何学习的方法，使模型能够快速适应新任务",
            "跨模态潜在空间": "通过元学习构建的空间，用于从数据集生成对应的神经架构"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 654,
        "title": "Rapid Task-Solving in Novel Environments",
        "html": "https://iclr.cc//virtual/2021/poster/3211",
        "abstract": "We propose the challenge of rapid task-solving in novel environments (RTS), wherein an agent must solve a series of tasks as rapidly as possible in an unfamiliar environment. An effective RTS agent must balance between exploring the unfamiliar environment and solving its current task, all while building a model of the new environment over which it can plan when faced with later tasks. While modern deep RL agents exhibit some of these abilities in isolation, none are suitable for the full RTS challenge. To enable progress toward RTS, we introduce two challenge domains: (1) a minimal RTS challenge called the Memory&Planning Game and (2) One-Shot StreetLearn Navigation, which introduces scale and complexity from real-world data. We demonstrate that state-of-the-art deep RL agents fail at RTS in both domains, and that this failure is due to an inability to plan over gathered knowledge. We develop Episodic Planning Networks (EPNs) and show that deep-RL agents with EPNs excel at RTS, outperforming the nearest baseline by factors of 2-3 and learning to navigate held-out StreetLearn maps within a single episode. We show that EPNs learn to execute a value iteration-like planning algorithm and that they generalize to situations beyond their training experience.",
        "conference": "ICLR",
        "中文标题": "新环境中的快速任务解决",
        "摘要翻译": "我们提出了在新环境中快速解决任务（RTS）的挑战，其中智能体必须在一个不熟悉的环境中尽可能快地解决一系列任务。一个有效的RTS智能体必须在探索不熟悉的环境和解决当前任务之间取得平衡，同时建立一个新环境的模型，以便在面对后续任务时可以进行规划。虽然现代深度强化学习智能体在孤立情况下表现出其中一些能力，但没有一个适合完整的RTS挑战。为了推动RTS的进展，我们引入了两个挑战领域：（1）一个称为记忆与规划游戏的最小RTS挑战，和（2）一次性StreetLearn导航，它从真实世界数据中引入了规模和复杂性。我们证明了最先进的深度强化学习智能体在这两个领域中都无法完成RTS，并且这种失败是由于无法对收集到的知识进行规划。我们开发了情节规划网络（EPNs），并展示了带有EPNs的深度强化学习智能体在RTS中表现出色，比最近的基线高出2-3倍，并且能够在单个情节内学习导航保留的StreetLearn地图。我们展示了EPNs学会执行一种类似于价值迭代的规划算法，并且它们能够泛化到超出其训练经验的情况。",
        "领域": "强化学习、智能导航、环境建模",
        "问题": "智能体在新环境中快速解决任务的能力不足",
        "动机": "探索智能体在不熟悉环境中快速适应和解决任务的能力，以推动智能体在复杂环境中的应用",
        "方法": "开发情节规划网络（EPNs），结合深度强化学习，使智能体能够在新环境中有效规划和快速适应",
        "关键词": [
            "快速任务解决",
            "情节规划网络",
            "深度强化学习",
            "环境建模",
            "智能导航"
        ],
        "涉及的技术概念": {
            "情节规划网络（EPNs）": "一种使深度强化学习智能体能够在新环境中进行有效规划的技术，通过模拟类似于价值迭代的规划算法来提高任务解决效率",
            "深度强化学习": "结合深度学习和强化学习的技术，用于训练智能体在复杂环境中做出决策",
            "环境建模": "智能体通过探索和学习建立对不熟悉环境的内部表示，以便于后续任务的规划和执行"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 655,
        "title": "Recurrent Independent Mechanisms",
        "html": "https://iclr.cc//virtual/2021/poster/3224",
        "abstract": "We explore the hypothesis that learning modular structures which reflect the dynamics of the environment can lead to better generalization and robustness to changes that only affect a few of the underlying causes. We propose Recurrent Independent Mechanisms (RIMs), a new recurrent architecture in which multiple groups of recurrent cells operate with nearly independent transition dynamics, communicate only sparingly through the bottleneck of attention, and compete with each other so they are updated only at time steps where they are most relevant.  We show that this leads to specialization amongst the RIMs, which in turn allows for remarkably improved generalization on tasks where some factors of variation differ systematically between training and evaluation.\n",
        "conference": "ICLR",
        "中文标题": "循环独立机制",
        "摘要翻译": "我们探讨了一个假设，即学习反映环境动态的模块化结构可以带来更好的泛化能力以及对仅影响少数潜在原因的变化的鲁棒性。我们提出了循环独立机制（RIMs），这是一种新的循环架构，其中多组循环细胞以几乎独立的动态转换操作，仅通过注意力的瓶颈进行稀疏通信，并且相互竞争，因此它们仅在它们最相关的时间步骤被更新。我们表明，这导致了RIMs之间的专业化，进而使得在训练和评估之间某些变化因素系统性地不同的任务上，泛化能力得到了显著提升。",
        "领域": "深度学习与计算机视觉结合、模块化神经网络、注意力机制应用",
        "问题": "如何通过模块化结构提高模型对环境中动态变化的泛化能力和鲁棒性。",
        "动机": "探索模块化结构学习环境动态以提升模型泛化能力和对特定变化的鲁棒性。",
        "方法": "提出循环独立机制（RIMs），通过多组几乎独立操作的循环细胞，利用注意力机制稀疏通信和竞争更新机制，实现专业化分工。",
        "关键词": [
            "循环独立机制",
            "模块化学习",
            "注意力机制",
            "泛化能力",
            "鲁棒性"
        ],
        "涉及的技术概念": {
            "循环独立机制（RIMs）": "一种新的循环架构，通过多组几乎独立操作的循环细胞提高模型的泛化能力和鲁棒性。",
            "注意力机制": "用于在RIMs中实现稀疏通信，优化信息流动和模型效率。",
            "专业化分工": "RIMs通过竞争机制实现细胞间的专业化，提升对特定任务或变化的处理能力。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 656,
        "title": "Reducing the Computational Cost of Deep Generative Models with Binary Neural Networks",
        "html": "https://iclr.cc//virtual/2021/poster/2946",
        "abstract": "Deep generative models provide a powerful set of tools to understand real-world data. But as these models improve, they increase in size and complexity, so their computational cost in memory and execution time grows. Using binary weights in neural networks is one method which has shown promise in reducing this cost. However, whether binary neural networks can be used in generative models is an open problem. In this work we show, for the first time, that we can successfully train generative models which utilize binary neural networks. This reduces the computational cost of the models massively. We develop a new class of binary weight normalization, and provide insights for architecture designs of these binarized generative models. We demonstrate that two state-of-the-art deep generative models, the ResNet VAE and Flow++ models, can be binarized effectively using these techniques. We train binary models that achieve loss values close to those of the regular models but are 90%-94% smaller in size, and also allow significant speed-ups in execution time.",
        "conference": "ICLR",
        "中文标题": "利用二元神经网络降低深度生成模型的计算成本",
        "摘要翻译": "深度生成模型提供了一套强大的工具来理解现实世界的数据。但随着这些模型的改进，它们的规模和复杂性增加，因此在内存和执行时间上的计算成本也随之增长。在神经网络中使用二元权重是一种显示出降低这一成本潜力的方法。然而，二元神经网络是否可用于生成模型仍是一个未解决的问题。在这项工作中，我们首次展示了可以成功训练利用二元神经网络的生成模型。这大大降低了模型的计算成本。我们开发了一类新的二元权重归一化方法，并为这些二元化生成模型的架构设计提供了见解。我们证明了两种最先进的深度生成模型，ResNet VAE和Flow++模型，可以使用这些技术有效地二元化。我们训练的二元模型实现了接近常规模型的损失值，但大小减少了90%-94%，并且还显著加快了执行时间。",
        "领域": "生成模型优化、神经网络压缩、深度学习效率提升",
        "问题": "如何降低深度生成模型的计算成本，同时保持其性能",
        "动机": "深度生成模型的计算成本随着模型规模和复杂性的增加而增长，限制了其应用范围，因此需要寻找有效的方法来降低这一成本",
        "方法": "开发了一种新的二元权重归一化方法，并探索了二元化生成模型的架构设计，成功将二元神经网络应用于生成模型的训练",
        "关键词": [
            "二元神经网络",
            "生成模型",
            "计算成本降低",
            "权重归一化",
            "模型压缩"
        ],
        "涉及的技术概念": {
            "二元神经网络": "使用二元权重（通常为+1和-1）的神经网络，显著减少模型大小和加速计算",
            "权重归一化": "一种技术，用于在训练二元神经网络时稳定和优化权重，帮助模型保持性能",
            "生成模型二元化": "将传统的深度生成模型转换为使用二元权重的过程，旨在减少模型的计算资源需求"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 657,
        "title": "Refining Deep Generative Models via Discriminator Gradient Flow",
        "html": "https://iclr.cc//virtual/2021/poster/3109",
        "abstract": "Deep generative modeling has seen impressive advances in recent years, to the point where it is now commonplace to see simulated samples (e.g., images) that closely resemble real-world data. However, generation quality is generally inconsistent for any given model and can vary dramatically between samples. We introduce Discriminator Gradient $f$low (DG$f$low), a new technique that improves generated samples via the gradient flow of entropy-regularized $f$-divergences between the real and the generated data distributions. The gradient flow takes the form of a non-linear Fokker-Plank equation, which can be easily simulated by sampling from the equivalent McKean-Vlasov process. By refining inferior samples, our technique avoids wasteful sample rejection used by previous methods (DRS & MH-GAN). Compared to existing works that focus on specific GAN variants, we show our refinement approach can be applied to GANs with vector-valued critics and even other deep generative models such as VAEs and Normalizing Flows. Empirical results on multiple synthetic, image, and text datasets demonstrate that DG$f$low leads to significant improvement in the quality of generated samples for a variety of generative models, outperforming the state-of-the-art Discriminator Optimal Transport (DOT) and Discriminator Driven Latent Sampling (DDLS) methods.",
        "conference": "ICLR",
        "中文标题": "通过判别器梯度流优化深度生成模型",
        "摘要翻译": "近年来，深度生成模型取得了令人瞩目的进展，以至于现在常见到模拟样本（如图像）与现实世界数据极为相似。然而，对于任何给定模型，生成质量通常不一致，样本之间可能存在显著差异。我们引入了判别器梯度流（DGflow），这是一种新技术，通过真实数据分布与生成数据分布之间熵正则化的f-散度的梯度流来改进生成的样本。梯度流表现为非线性Fokker-Plank方程，可以通过从等效的McKean-Vlasov过程中采样来轻松模拟。通过优化劣质样本，我们的技术避免了先前方法（DRS和MH-GAN）使用的浪费性样本拒绝。与专注于特定GAN变体的现有工作相比，我们展示了我们的优化方法可以应用于具有向量值评论家的GAN，甚至其他深度生成模型，如VAEs和归一化流。在多个合成、图像和文本数据集上的实证结果表明，DGflow在各种生成模型中显著提高了生成样本的质量，优于最先进的判别器最优传输（DOT）和判别器驱动潜在采样（DDLS）方法。",
        "领域": "生成对抗网络, 变分自编码器, 归一化流",
        "问题": "提高深度生成模型生成样本的质量和一致性",
        "动机": "解决深度生成模型在生成样本时质量不一致的问题，避免样本浪费",
        "方法": "引入判别器梯度流（DGflow）技术，通过熵正则化的f-散度的梯度流优化生成样本",
        "关键词": [
            "判别器梯度流",
            "深度生成模型",
            "样本优化",
            "f-散度",
            "McKean-Vlasov过程"
        ],
        "涉及的技术概念": {
            "判别器梯度流（DGflow）": "一种通过梯度流优化生成样本的新技术，利用熵正则化的f-散度",
            "f-散度": "用于衡量真实数据分布与生成数据分布之间的差异，是DGflow技术的核心",
            "McKean-Vlasov过程": "用于模拟非线性Fokker-Plank方程的等效过程，便于实现DGflow技术"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 658,
        "title": "Regularization Matters in Policy Optimization - An Empirical Study on Continuous Control",
        "html": "https://iclr.cc//virtual/2021/poster/2916",
        "abstract": "Deep Reinforcement Learning (Deep RL) has been receiving increasingly more attention  thanks to its encouraging performance on a variety of control tasks. Yet, conventional regularization techniques in training neural networks (e.g., $L_2$ regularization, dropout) have been largely ignored in RL methods, possibly because agents are typically trained and evaluated in the same environment, and because the deep RL community focuses more on high-level algorithm designs. In this work, we present the first comprehensive study of regularization techniques with multiple policy optimization algorithms on continuous control tasks. Interestingly, we find conventional regularization techniques on the policy networks can often bring large improvement, especially on harder tasks. Our findings are shown to be robust against training hyperparameter variations. We also compare these techniques with the more widely used entropy regularization. In addition, we study regularizing different components and find that only regularizing the policy network is typically the best. We further analyze why regularization may help generalization in RL from four perspectives - sample complexity, reward distribution, weight norm, and noise robustness. We hope our study provides guidance for future practices in regularizing policy optimization algorithms. Our code is available at https://github.com/xuanlinli17/iclr2021_rlreg .",
        "conference": "ICLR",
        "中文标题": "正则化在策略优化中的重要性——关于连续控制的实证研究",
        "摘要翻译": "深度强化学习（Deep RL）因其在各种控制任务上的出色表现而受到越来越多的关注。然而，在强化学习方法中，训练神经网络时的常规正则化技术（如L2正则化、dropout）大多被忽视，这可能是因为智能体通常在相同的环境中进行训练和评估，以及深度强化学习社区更关注于高级算法设计。在这项工作中，我们首次全面研究了在连续控制任务中结合多种策略优化算法的正则化技术。有趣的是，我们发现对策略网络应用常规的正则化技术往往能带来显著的改进，尤其是在更困难的任务上。我们的发现对于训练超参数的变化表现出鲁棒性。我们还比较了这些技术与更广泛使用的熵正则化。此外，我们研究了正则化不同组件的影响，发现通常仅正则化策略网络效果最佳。我们从四个角度进一步分析了正则化可能有助于强化学习泛化的原因——样本复杂度、奖励分布、权重范数和噪声鲁棒性。我们希望我们的研究能为未来正则化策略优化算法的实践提供指导。我们的代码可在https://github.com/xuanlinli17/iclr2021_rlreg 获取。",
        "领域": "深度强化学习、策略优化、连续控制",
        "问题": "研究在深度强化学习中常规正则化技术对策略优化算法性能的影响",
        "动机": "探索常规正则化技术在强化学习中的应用，尤其是在策略优化算法中，以提升模型在连续控制任务中的表现",
        "方法": "通过实证研究，比较和分析多种正则化技术在连续控制任务中对策略优化算法性能的影响，包括常规正则化技术和熵正则化",
        "关键词": [
            "深度强化学习",
            "策略优化",
            "正则化技术",
            "连续控制",
            "泛化能力"
        ],
        "涉及的技术概念": {
            "L2正则化": "用于防止模型过拟合，通过在损失函数中添加权重向量的L2范数作为惩罚项",
            "熵正则化": "通过增加策略的熵来鼓励探索，防止策略过早收敛到局部最优",
            "策略网络": "在强化学习中用于决定智能体行为的神经网络，本研究主要关注对其应用正则化技术的影响"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 659,
        "title": "Regularized Inverse Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2021/poster/2850",
        "abstract": "Inverse Reinforcement Learning (IRL) aims to facilitate a learner’s ability to imitate expert behavior by acquiring reward functions that explain the expert’s decisions. Regularized IRLapplies strongly convex regularizers to the learner’s policy in order to avoid the expert’s behavior being rationalized by arbitrary constant rewards, also known as degenerate solutions. We propose tractable solutions, and practical methods to obtain them, for regularized IRL. Current methods are restricted to the maximum-entropy IRL framework, limiting them to Shannon-entropy regularizers, as well as proposing solutions that are intractable in practice.  We present theoretical backing for our proposed IRL method’s applicability to both discrete and continuous controls, empirically validating our performance on a variety of tasks.",
        "conference": "ICLR",
        "中文标题": "正则化逆强化学习",
        "摘要翻译": "逆强化学习（IRL）旨在通过获取解释专家决策的奖励函数，促进学习者模仿专家行为的能力。正则化IRL对学习者的策略应用强凸正则化器，以避免专家的行为被任意常数奖励（也称为退化解）合理化。我们提出了正则化IRL的可行解及其实用方法。当前的方法仅限于最大熵IRL框架，限制了它们只能使用香农熵正则化器，并且提出的解在实践中难以处理。我们为我们提出的IRL方法在离散和连续控制中的适用性提供了理论支持，并通过在各种任务上的实证验证了我们的性能。",
        "领域": "逆强化学习",
        "问题": "避免专家行为被任意常数奖励合理化，即退化解的问题",
        "动机": "提高逆强化学习方法的实用性和适用性，特别是在处理离散和连续控制任务时",
        "方法": "应用强凸正则化器到学习者的策略，提出新的可行解及其实用方法",
        "关键词": [
            "逆强化学习",
            "正则化",
            "强凸正则化器",
            "最大熵框架",
            "离散和连续控制"
        ],
        "涉及的技术概念": {
            "逆强化学习": "通过观察专家行为来推断奖励函数，以促进模仿学习",
            "强凸正则化器": "应用于学习者策略的正则化方法，以避免退化解",
            "最大熵框架": "一种逆强化学习方法，限制使用香农熵正则化器"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 660,
        "title": "Reinforcement Learning with Random Delays",
        "html": "https://iclr.cc//virtual/2021/poster/3078",
        "abstract": "Action and observation delays commonly occur in many Reinforcement Learning applications, such as remote control scenarios. We study the anatomy of randomly delayed environments, and show that partially resampling trajectory fragments in hindsight allows for off-policy multi-step value estimation. We apply this principle to derive Delay-Correcting Actor-Critic (DCAC), an algorithm based on Soft Actor-Critic with significantly better performance in environments with delays. This is shown theoretically and also demonstrated practically on a delay-augmented version of the MuJoCo continuous control benchmark.",
        "conference": "ICLR",
        "中文标题": "随机延迟下的强化学习",
        "摘要翻译": "动作和观察延迟在许多强化学习应用中普遍存在，例如远程控制场景。我们研究了随机延迟环境的结构，并表明事后部分重采样轨迹片段允许进行离策略多步价值估计。我们应用这一原理推导出延迟校正演员-评论家（DCAC），这是一种基于软演员-评论家的算法，在延迟环境中表现出显著更好的性能。这一点在理论上得到了展示，并在延迟增强版的MuJoCo连续控制基准上进行了实际验证。",
        "领域": "强化学习、连续控制、远程控制",
        "问题": "解决强化学习在随机延迟环境中的性能下降问题",
        "动机": "研究随机延迟对强化学习性能的影响，并提出有效的解决方案",
        "方法": "通过部分重采样轨迹片段进行离策略多步价值估计，并开发延迟校正演员-评论家（DCAC）算法",
        "关键词": [
            "随机延迟",
            "强化学习",
            "延迟校正",
            "演员-评论家",
            "MuJoCo"
        ],
        "涉及的技术概念": {
            "离策略多步价值估计": "用于在随机延迟环境中估计动作价值的技术",
            "延迟校正演员-评论家（DCAC）": "基于软演员-评论家的算法，专门设计用于处理延迟环境",
            "MuJoCo连续控制基准": "用于评估算法性能的标准测试环境"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 661,
        "title": "Relating by Contrasting: A Data-efficient Framework for Multimodal Generative Models",
        "html": "https://iclr.cc//virtual/2021/poster/3143",
        "abstract": "Multimodal learning for generative models often refers to the learning of abstract concepts from the commonality of information in multiple modalities, such as vision and language. While it has proven effective for learning generalisable representations, the training of such models often requires a large amount of related multimodal data that shares commonality, which can be expensive to come by. To mitigate this, we develop a novel contrastive framework for generative model learning, allowing us to train the model not just by the commonality between modalities, but by the distinction between 'related' and 'unrelated' multimodal data. We show in experiments that our method enables data-efficient multimodal learning on challenging datasets for various multimodal VAE models. We also show that under our proposed framework, the generative model can accurately identify related samples from unrelated ones, making it possible to make use of the plentiful unlabeled, unpaired multimodal data.",
        "conference": "ICLR",
        "中文标题": "通过对比建立关联：一种数据高效的多模态生成模型框架",
        "摘要翻译": "生成模型的多模态学习通常指的是从多种模态（如视觉和语言）信息的共性中学习抽象概念。虽然这种方法在学习可泛化表示方面已被证明有效，但此类模型的训练往往需要大量具有共性的相关多模态数据，这些数据的获取成本可能很高。为了缓解这一问题，我们开发了一种新颖的对比框架用于生成模型学习，使我们不仅能够通过模态间的共性来训练模型，还能通过‘相关’与‘不相关’多模态数据之间的差异进行训练。我们在实验中表明，我们的方法能够在具有挑战性的数据集上实现数据高效的多模态学习，适用于各种多模态VAE模型。我们还表明，在我们提出的框架下，生成模型能够准确识别相关样本与不相关样本，从而使得利用大量未标记、未配对的多模态数据成为可能。",
        "领域": "多模态学习、生成模型、对比学习",
        "问题": "减少多模态生成模型训练对大量相关多模态数据的依赖",
        "动机": "解决多模态生成模型训练过程中需要大量相关多模态数据的高成本问题",
        "方法": "开发了一种新颖的对比框架，通过利用相关与不相关多模态数据之间的差异来训练生成模型",
        "关键词": [
            "多模态学习",
            "生成模型",
            "对比学习",
            "数据效率",
            "VAE"
        ],
        "涉及的技术概念": {
            "多模态学习": "从多种模态（如视觉和语言）中学习抽象概念，以提高模型的泛化能力",
            "对比学习": "通过比较相关与不相关数据之间的差异来训练模型，以提高数据效率和模型性能",
            "VAE（变分自编码器）": "一种生成模型，用于学习数据的潜在表示，并在我们的框架中用于多模态数据的生成和理解"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 662,
        "title": "Remembering for the Right Reasons: Explanations Reduce Catastrophic Forgetting",
        "html": "https://iclr.cc//virtual/2021/poster/2950",
        "abstract": "The goal of continual learning (CL) is to learn a sequence of tasks without suffering from the phenomenon of catastrophic forgetting. Previous work has shown that leveraging memory in the form of a replay buffer can reduce performance degradation on prior tasks. We hypothesize that forgetting can be further reduced when the model is encouraged to remember the \\textit{evidence} for previously made decisions. As a first step towards exploring this hypothesis, we propose a simple novel training paradigm, called Remembering for the Right Reasons (RRR), that additionally stores visual model explanations for each example in the buffer and ensures the model has ``the right reasons'' for its predictions by encouraging its explanations to remain consistent with those used to make decisions at training time. Without this constraint, there is a drift in explanations and increase in forgetting as conventional continual learning algorithms learn new tasks. We demonstrate how RRR can be easily added to any memory or regularization-based approach and results in reduced forgetting, and more importantly, improved model explanations. We have evaluated our approach in the standard and few-shot settings and observed a consistent improvement across various CL approaches using different architectures and techniques to generate model explanations and demonstrated our approach showing a promising connection between explainability and continual learning. Our code is available at \\url{https://github.com/SaynaEbrahimi/Remembering-for-the-Right-Reasons}.",
        "conference": "ICLR",
        "中文标题": "为正确理由记忆：解释减少灾难性遗忘",
        "摘要翻译": "持续学习（CL）的目标是在不遭受灾难性遗忘现象的情况下学习一系列任务。先前的工作表明，利用重放缓冲区的形式可以减轻对先前任务性能的下降。我们假设，当模型被鼓励记住先前决策的‘证据’时，遗忘可以进一步减少。作为探索这一假设的第一步，我们提出了一种简单新颖的训练范式，称为‘为正确理由记忆’（RRR），它额外存储了缓冲区中每个示例的视觉模型解释，并通过鼓励其解释与训练时用于做出决策的解释保持一致，确保模型有‘正确的理由’进行预测。没有这一约束，随着传统持续学习算法学习新任务，解释会发生漂移，遗忘会增加。我们展示了RRR如何可以轻松添加到任何基于记忆或正则化的方法中，并导致遗忘减少，更重要的是，改进模型解释。我们已经在标准和少样本设置中评估了我们的方法，并观察到使用不同架构和技术生成模型解释的各种CL方法中的一致改进，展示了我们的方法在可解释性和持续学习之间显示出有希望的联系。我们的代码可在https://github.com/SaynaEbrahimi/Remembering-for-the-Right-Reasons获取。",
        "领域": "持续学习、模型解释性、灾难性遗忘",
        "问题": "如何在持续学习过程中减少灾难性遗忘，并保持模型解释的一致性",
        "动机": "探索通过鼓励模型记住决策证据来减少灾难性遗忘的可能性",
        "方法": "提出了一种名为‘为正确理由记忆’（RRR）的新训练范式，通过存储和保持模型解释的一致性来减少遗忘",
        "关键词": [
            "持续学习",
            "灾难性遗忘",
            "模型解释性",
            "RRR",
            "视觉模型解释"
        ],
        "涉及的技术概念": {
            "持续学习": "一种学习范式，旨在不忘记先前学习任务的情况下学习新任务",
            "灾难性遗忘": "在学习新任务时，模型忘记先前学习任务的现象",
            "模型解释性": "理解和解释模型决策过程的能力，RRR通过保持解释一致性来改进这一点"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 663,
        "title": "Removing Undesirable Feature Contributions Using Out-of-Distribution Data",
        "html": "https://iclr.cc//virtual/2021/poster/2608",
        "abstract": "Several data augmentation methods deploy unlabeled-in-distribution (UID) data to bridge the gap between the training and inference of neural networks. However, these methods have clear limitations in terms of availability of UID data and dependence of algorithms on pseudo-labels. Herein, we propose a data augmentation method to improve generalization in both adversarial and standard learning by using out-of-distribution (OOD) data that are devoid of the abovementioned issues. We show how to improve generalization theoretically using OOD data in each learning scenario and complement our theoretical analysis with experiments on CIFAR-10, CIFAR-100, and a subset of ImageNet. The results indicate that undesirable features are shared even among image data that seem to have little correlation from a human point of view. We also present the advantages of the proposed method through comparison with other data augmentation methods, which can be used in the absence of UID data. Furthermore, we demonstrate that the proposed method can further improve the existing state-of-the-art adversarial training.",
        "conference": "ICLR",
        "中文标题": "利用分布外数据消除不良特征贡献",
        "摘要翻译": "多种数据增强方法采用分布内未标记（UID）数据来缩小神经网络训练与推理之间的差距。然而，这些方法在UID数据的可用性及算法对伪标签的依赖性方面存在明显限制。本文提出了一种数据增强方法，通过使用不存在上述问题的分布外（OOD）数据，在对抗性学习和标准学习中均能提高泛化能力。我们展示了如何在每种学习场景中理论上使用OOD数据提高泛化能力，并通过在CIFAR-10、CIFAR-100和ImageNet子集上的实验补充了我们的理论分析。结果表明，即使是从人类角度看似乎相关性很小的图像数据之间，也存在共享的不良特征。我们还通过与其他数据增强方法的比较，展示了所提方法在缺乏UID数据时的优势。此外，我们证明了所提方法能进一步提升现有的最先进对抗性训练。",
        "领域": "对抗性学习、数据增强、图像分类",
        "问题": "如何利用分布外数据提高神经网络的泛化能力，同时避免依赖分布内未标记数据和伪标签的限制",
        "动机": "现有的数据增强方法依赖于分布内未标记数据和伪标签，这限制了方法的可用性和效果。研究旨在探索利用分布外数据来克服这些限制，提高模型在对抗性和标准学习场景下的泛化能力。",
        "方法": "提出了一种新的数据增强方法，该方法利用分布外数据来训练神经网络，理论上分析了该方法在提高泛化能力方面的有效性，并通过在多个数据集上的实验验证了其效果。",
        "关键词": [
            "分布外数据",
            "数据增强",
            "对抗性学习",
            "泛化能力",
            "图像分类"
        ],
        "涉及的技术概念": {
            "分布外数据（OOD）": "指与训练数据分布不同的数据，用于提高模型的泛化能力，避免对特定数据分布的依赖。",
            "数据增强": "通过增加训练数据的多样性来提高模型的泛化能力和鲁棒性的技术。",
            "对抗性学习": "一种旨在提高模型对对抗性攻击鲁棒性的学习方法，通过模拟攻击来增强模型的防御能力。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 664,
        "title": "Representation Balancing Offline Model-based Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2021/poster/2653",
        "abstract": "One of the main challenges in offline and off-policy reinforcement learning is to cope with the distribution shift that arises from the mismatch between the target policy and the data collection policy. In this paper, we focus on a model-based approach, particularly on learning the representation for a robust model of the environment under the distribution shift, which has been first studied by Representation Balancing MDP (RepBM). Although this prior work has shown promising results, there are a number of shortcomings that still hinder its applicability to practical tasks. In particular, we address the curse of horizon exhibited by RepBM, rejecting most of the pre-collected data in long-term tasks. We present a new objective for model learning motivated by recent advances in the estimation of stationary distribution corrections. This effectively overcomes the aforementioned limitation of RepBM, as well as naturally extending to continuous action spaces and stochastic policies. We also present an offline model-based policy optimization using this new objective, yielding the state-of-the-art performance in a representative set of benchmark offline RL tasks.",
        "conference": "ICLR",
        "中文标题": "表示平衡的离线模型强化学习",
        "摘要翻译": "离线和离策略强化学习中的一个主要挑战是应对由目标策略与数据收集策略不匹配引起的分布偏移。在本文中，我们专注于一种基于模型的方法，特别是在分布偏移下学习环境的鲁棒模型表示，这首先由表示平衡MDP（RepBM）研究。尽管先前的工作显示出有希望的结果，但仍有许多缺点阻碍其应用于实际任务。特别是，我们解决了RepBM表现出的视野诅咒问题，该问题在长期任务中拒绝了大部分预先收集的数据。我们提出了一个新的模型学习目标，该目标受到最近在稳态分布校正估计方面的进展的启发。这有效地克服了RepBM的上述限制，同时也自然地扩展到连续动作空间和随机策略。我们还提出了一种使用这一新目标的离线模型策略优化，在一组代表性的离线RL基准任务中实现了最先进的性能。",
        "领域": "强化学习、模型优化、策略学习",
        "问题": "解决离线和离策略强化学习中的分布偏移问题",
        "动机": "克服RepBM在长期任务中因视野诅咒而拒绝大部分预收集数据的限制，提高模型在实际任务中的适用性",
        "方法": "提出新的模型学习目标，基于稳态分布校正估计的最新进展，克服RepBM的限制，并扩展到连续动作空间和随机策略",
        "关键词": [
            "离线强化学习",
            "模型优化",
            "分布偏移",
            "稳态分布校正",
            "策略优化"
        ],
        "涉及的技术概念": {
            "表示平衡MDP（RepBM）": "一种在分布偏移下学习环境鲁棒模型表示的方法",
            "稳态分布校正": "用于估计和校正模型中的稳态分布差异，以克服分布偏移问题",
            "离线模型策略优化": "利用新提出的模型学习目标进行策略优化，以提高离线强化学习任务的性能"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 665,
        "title": "Representation learning for improved interpretability and classification accuracy of clinical factors from EEG",
        "html": "https://iclr.cc//virtual/2021/poster/3197",
        "abstract": "Despite extensive standardization, diagnostic interviews for mental health disorders encompass substantial subjective judgment. Previous studies have demonstrated that EEG-based neural measures can function as reliable objective correlates of depression, or even predictors of depression and its course. However, their clinical utility has not been fully realized because of 1) the lack of automated ways to deal with the inherent noise associated with EEG data at scale, and 2) the lack of knowledge of which aspects of the EEG signal may be markers of a clinical disorder. Here we adapt an unsupervised pipeline from the recent deep representation learning literature to address these problems by 1) learning a disentangled representation using $\\beta$-VAE to denoise the signal, and 2) extracting interpretable features associated with a sparse set of clinical labels using a Symbol-Concept Association Network (SCAN). We demonstrate that our method is able to outperform the canonical hand-engineered baseline classification method on a number of factors, including participant age and depression diagnosis. Furthermore, our method recovers a representation that can be used to automatically extract denoised Event Related Potentials (ERPs) from novel, single EEG trajectories, and supports fast supervised re-mapping to various clinical labels, allowing clinicians to re-use a single EEG representation regardless of updates to the standardized diagnostic system. Finally, single factors of the learned disentangled representations often correspond to meaningful markers of clinical factors, as automatically detected by SCAN, allowing for human interpretability and post-hoc expert analysis of the recommendations made by the model.",
        "conference": "ICLR",
        "中文标题": "用于提高从脑电图(EEG)中提取临床因素可解释性和分类准确性的表示学习",
        "摘要翻译": "尽管有广泛的标准化，心理健康障碍的诊断访谈仍包含大量的主观判断。先前的研究表明，基于脑电图(EEG)的神经测量可以作为抑郁症的可靠客观相关指标，甚至是抑郁症及其病程的预测因子。然而，由于1)缺乏自动化方法来大规模处理与EEG数据相关的固有噪声，以及2)对EEG信号的哪些方面可能是临床障碍的标记物缺乏了解，其临床效用尚未完全实现。在这里，我们采用了一种来自最近深度表示学习文献的无监督流程来解决这些问题，通过1)使用β-VAE学习解缠表示以去噪信号，以及2)使用符号-概念关联网络(SCAN)提取与稀疏临床标签集相关的可解释特征。我们证明，我们的方法在多个因素上能够超越经典的手工设计基线分类方法，包括参与者年龄和抑郁症诊断。此外，我们的方法恢复了一种表示，可用于从新的单一EEG轨迹中自动提取去噪的事件相关电位(ERPs)，并支持快速监督重映射到各种临床标签，使临床医生能够重用单一EEG表示，无论标准化诊断系统的更新如何。最后，学习到的解缠表示的单因素通常对应于临床因素的有意义标记，如SCAN自动检测到的，允许人类可解释性和对模型建议的事后专家分析。",
        "领域": "脑电图分析、抑郁症诊断、深度学习应用",
        "问题": "提高从EEG数据中提取临床因素的可解释性和分类准确性",
        "动机": "解决EEG数据固有噪声处理缺乏自动化方法和对EEG信号中哪些方面可作为临床障碍标记物认识不足的问题",
        "方法": "采用β-VAE学习解缠表示以去噪信号，并使用符号-概念关联网络(SCAN)提取与稀疏临床标签集相关的可解释特征",
        "关键词": [
            "表示学习",
            "EEG去噪",
            "抑郁症诊断",
            "β-VAE",
            "SCAN"
        ],
        "涉及的技术概念": {
            "β-VAE": "用于学习解缠表示以去噪EEG信号的技术",
            "符号-概念关联网络(SCAN)": "用于提取与稀疏临床标签集相关的可解释特征的网络",
            "事件相关电位(ERPs)": "从EEG数据中提取的去噪信号，用于临床诊断"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 666,
        "title": "Representation Learning for Sequence Data with Deep Autoencoding Predictive Components",
        "html": "https://iclr.cc//virtual/2021/poster/2825",
        "abstract": "We propose Deep Autoencoding Predictive Components (DAPC) -- a self-supervised representation learning method for sequence data, based on the intuition that useful representations of sequence data should exhibit a simple structure in the latent space. We encourage this latent structure by maximizing an estimate of \\emph{predictive information} of latent feature sequences, which is the mutual information between the past and future windows at each time step. In contrast to the mutual information lower bound commonly used by contrastive learning, the estimate of predictive information we adopt is exact under a Gaussian assumption. Additionally, it can be computed without negative sampling. To reduce the degeneracy of the latent space extracted by powerful encoders and keep useful information from the inputs, we regularize predictive information learning with a challenging masked reconstruction loss. We demonstrate that our method recovers the latent space of noisy dynamical systems, extracts predictive features for forecasting tasks, and improves automatic speech recognition when used to pretrain the encoder on large amounts of unlabeled data.",
        "conference": "ICLR",
        "中文标题": "序列数据的深度自编码预测组件表示学习",
        "摘要翻译": "我们提出了深度自编码预测组件（DAPC）——一种基于自监督的序列数据表示学习方法，其核心思想是序列数据的有用表示应在潜在空间中展现出简单的结构。我们通过最大化潜在特征序列的预测信息估计来鼓励这种潜在结构，这里的预测信息指的是每个时间步骤过去和未来窗口之间的互信息。与对比学习常用的互信息下界不同，我们采用的预测信息估计在高斯假设下是精确的。此外，它可以在不进行负采样的情况下计算。为了减少由强大编码器提取的潜在空间的退化，并从输入中保留有用信息，我们通过具有挑战性的掩码重建损失来正则化预测信息学习。我们证明了我们的方法能够恢复噪声动态系统的潜在空间，为预测任务提取预测特征，并在大量未标记数据上预训练编码器时提高自动语音识别的性能。",
        "领域": "自监督学习, 序列建模, 自动语音识别",
        "问题": "如何从序列数据中学习有用的表示，这些表示在潜在空间中具有简单结构，并且能够有效地用于预测任务。",
        "动机": "探索一种自监督学习方法，该方法能够从序列数据中提取有意义的潜在表示，这些表示不仅结构简单，而且能够捕捉到序列数据中的预测信息，从而提高下游任务的性能。",
        "方法": "提出深度自编码预测组件（DAPC），通过最大化潜在特征序列的预测信息估计来学习表示，并使用掩码重建损失进行正则化，以避免潜在空间的退化。",
        "关键词": [
            "自监督学习",
            "序列表示学习",
            "预测信息",
            "掩码重建",
            "自动语音识别"
        ],
        "涉及的技术概念": {
            "预测信息": "在论文中用于衡量潜在特征序列中过去和未来窗口之间的互信息，是学习有用表示的关键指标。",
            "掩码重建损失": "用于正则化预测信息学习，防止潜在空间退化，确保从输入中保留有用信息。",
            "高斯假设": "在论文中用于精确估计预测信息，避免了对比学习中互信息下界的限制。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 667,
        "title": "Representation Learning via Invariant Causal Mechanisms",
        "html": "https://iclr.cc//virtual/2021/poster/3350",
        "abstract": "Self-supervised learning has emerged as a strategy to reduce the reliance on costly supervised signal by pretraining representations only using unlabeled data. These methods combine heuristic proxy classification tasks with data augmentations and have achieved significant success, but our theoretical understanding of this success remains limited. In this paper we analyze self-supervised representation learning using a causal framework.  We show how data augmentations can be more effectively utilized through explicit invariance constraints on the proxy classifiers employed during pretraining. Based on this, we propose a novel self-supervised objective, Representation Learning via Invariant Causal Mechanisms (ReLIC), that enforces invariant prediction of proxy targets across augmentations through an invariance regularizer which yields improved generalization guarantees. Further, using causality we generalize contrastive learning, a particular kind of self-supervised method,  and provide an alternative theoretical explanation for the  success  of  these  methods. Empirically, ReLIC significantly outperforms competing methods in terms of robustness and out-of-distribution generalization on ImageNet, while also significantly outperforming these methods on Atari achieving above human-level performance on 51 out of 57 games.",
        "conference": "ICLR",
        "中文标题": "通过不变因果机制进行表示学习",
        "摘要翻译": "自监督学习已成为一种策略，通过仅使用未标记数据预训练表示来减少对昂贵监督信号的依赖。这些方法将启发式代理分类任务与数据增强相结合，并取得了显著成功，但我们对这一成功的理论理解仍然有限。在本文中，我们使用因果框架分析自监督表示学习。我们展示了如何通过在预训练期间使用的代理分类器上施加显式不变性约束来更有效地利用数据增强。基于此，我们提出了一种新颖的自监督目标，即通过不变因果机制进行表示学习（ReLIC），该目标通过不变性正则化器强制执行跨增强的代理目标的不变预测，从而提供改进的泛化保证。此外，利用因果关系，我们推广了对比学习（一种特定类型的自监督方法），并为这些方法的成功提供了另一种理论解释。实证上，ReLIC在ImageNet上的鲁棒性和分布外泛化方面显著优于竞争方法，同时在Atari上也显著优于这些方法，在57个游戏中51个达到了超越人类水平的表现。",
        "领域": "自监督学习、因果推理、深度强化学习",
        "问题": "如何减少对昂贵监督信号的依赖，同时提高模型的泛化能力和鲁棒性。",
        "动机": "探索自监督学习中数据增强和不变性约束的理论基础，以提高表示学习的效率和效果。",
        "方法": "提出了一种新的自监督学习目标ReLIC，通过不变性正则化器强制执行跨增强的代理目标的不变预测，并结合因果框架推广对比学习。",
        "关键词": [
            "自监督学习",
            "因果推理",
            "不变性约束",
            "表示学习",
            "深度强化学习"
        ],
        "涉及的技术概念": {
            "不变因果机制": "在表示学习中引入因果框架，通过不变性约束提高模型的泛化能力。",
            "自监督学习": "一种减少对监督信号依赖的学习策略，通过未标记数据预训练模型。",
            "对比学习": "一种自监督学习方法，通过比较正负样本来学习数据表示，本文通过因果框架对其进行推广和理论解释。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 668,
        "title": "Representing Partial Programs with Blended Abstract Semantics",
        "html": "https://iclr.cc//virtual/2021/poster/3184",
        "abstract": "Synthesizing programs from examples requires searching over a vast, combinatorial space of possible programs. In this search process, a key challenge is representing the behavior of a partially written program before it can be executed, to judge if it is on the right track and predict where to search next. We introduce a general technique for representing partially written programs in a program synthesis engine. We take inspiration from the technique of abstract interpretation, in which an approximate execution model is used to determine if an unfinished program will eventually satisfy a goal specification. Here we learn an approximate execution model implemented as a modular neural network. By constructing compositional program representations that implicitly encode the interpretation semantics of the underlying programming language, we can represent partial programs using a flexible combination of concrete execution state and learned neural representations, using the learned approximate semantics when concrete semantics are not known (in unfinished parts of the program). We show that these hybrid neuro-symbolic representations enable execution-guided synthesizers to use more powerful language constructs, such as loops and higher-order functions, and can be used to synthesize programs more accurately for a given search budget than pure neural approaches in several domains.",
        "conference": "ICLR",
        "中文标题": "使用混合抽象语义表示部分程序",
        "摘要翻译": "从示例中合成程序需要在大量组合可能的程序空间中进行搜索。在这一搜索过程中，一个关键挑战是在部分编写的程序可以执行之前表示其行为，以判断其是否在正确的轨道上并预测下一步搜索的方向。我们介绍了一种在程序合成引擎中表示部分编写程序的通用技术。我们从抽象解释技术中获得灵感，其中使用近似执行模型来确定未完成的程序最终是否满足目标规范。在这里，我们学习了一个作为模块化神经网络实现的近似执行模型。通过构建组合程序表示，这些表示隐式编码了底层编程语言的解释语义，我们可以使用具体执行状态和学习到的神经表示的灵活组合来表示部分程序，在具体语义未知时（在程序的未完成部分）使用学习到的近似语义。我们展示了这些混合神经符号表示使执行引导的合成器能够使用更强大的语言构造，如循环和高阶函数，并且与纯神经方法相比，在几个领域中可以在给定的搜索预算内更准确地合成程序。",
        "领域": "程序合成、神经符号计算、抽象解释",
        "问题": "如何在程序合成过程中有效表示部分编写的程序的行为，以指导搜索方向。",
        "动机": "解决在程序合成中表示部分程序行为的挑战，以提高合成效率和准确性。",
        "方法": "结合抽象解释技术和模块化神经网络，构建混合神经符号表示来近似执行部分程序。",
        "关键词": [
            "程序合成",
            "神经符号计算",
            "抽象解释",
            "模块化神经网络",
            "执行引导合成"
        ],
        "涉及的技术概念": {
            "抽象解释": "用于近似执行程序的技术，帮助判断未完成程序是否满足目标规范。",
            "模块化神经网络": "实现近似执行模型的神经网络结构，能够灵活组合具体和抽象的程序表示。",
            "神经符号计算": "结合神经网络和符号逻辑的方法，用于在程序合成中表示和执行部分程序。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 669,
        "title": "Repurposing Pretrained Models for Robust Out-of-domain Few-Shot Learning",
        "html": "https://iclr.cc//virtual/2021/poster/3250",
        "abstract": "Model-agnostic meta-learning (MAML) is a popular method for few-shot learning but assumes that we have access to the meta-training set. In practice, training on the meta-training set may not always be an option due to data privacy concerns, intellectual property issues, or merely lack of computing resources. In this paper, we consider the novel problem of repurposing pretrained MAML checkpoints to solve new few-shot classification tasks. Because of the potential distribution mismatch, the original MAML steps may no longer be optimal. Therefore we propose an alternative meta-testing procedure and combine MAML gradient steps with adversarial training and uncertainty-based stepsize adaptation. Our method outperforms 'vanilla' MAML on same-domain and cross-domains benchmarks using both SGD and Adam optimizers and shows improved robustness to the choice of base stepsize.",
        "conference": "ICLR",
        "中文标题": "重用预训练模型以实现鲁棒的域外少样本学习",
        "摘要翻译": "模型无关的元学习（MAML）是少样本学习的一种流行方法，但它假设我们可以访问元训练集。实际上，由于数据隐私问题、知识产权问题或仅仅是缺乏计算资源，对元训练集进行训练可能并不总是一个选项。在本文中，我们考虑了重用预训练的MAML检查点来解决新的少样本分类任务的新问题。由于潜在的分发不匹配，原始的MAML步骤可能不再是最优的。因此，我们提出了一种替代的元测试程序，并将MAML梯度步骤与对抗训练和基于不确定性的步长适应相结合。我们的方法在使用SGD和Adam优化器的同域和跨域基准测试中优于'普通'MAML，并显示出对基础步长选择的改进鲁棒性。",
        "领域": "元学习、少样本学习、对抗训练",
        "问题": "如何在不访问原始元训练集的情况下，重用预训练的MAML模型来解决新的少样本分类任务。",
        "动机": "解决由于数据隐私、知识产权或计算资源限制而无法访问原始元训练集的问题，同时提高模型在新任务上的性能和鲁棒性。",
        "方法": "提出了一种替代的元测试程序，结合MAML梯度步骤、对抗训练和基于不确定性的步长适应，以优化预训练模型在新任务上的表现。",
        "关键词": [
            "元学习",
            "少样本学习",
            "对抗训练",
            "步长适应",
            "模型重用"
        ],
        "涉及的技术概念": {
            "模型无关的元学习（MAML）": "一种流行的少样本学习方法，通过元训练使模型能够快速适应新任务。",
            "对抗训练": "用于提高模型对输入变化的鲁棒性，通过在训练过程中引入对抗性样本。",
            "基于不确定性的步长适应": "根据模型预测的不确定性动态调整学习步长，以优化训练过程。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 670,
        "title": "Reset-Free Lifelong Learning with Skill-Space Planning",
        "html": "https://iclr.cc//virtual/2021/poster/3326",
        "abstract": "The objective of \\textit{lifelong} reinforcement learning (RL) is to optimize agents which can continuously adapt and interact in changing environments. However, current RL approaches fail drastically when environments are non-stationary and interactions are non-episodic. We propose \\textit{Lifelong Skill Planning} (LiSP), an algorithmic framework for lifelong RL based on planning in an abstract space of higher-order skills. We learn the skills in an unsupervised manner using intrinsic rewards and plan over the learned skills using a learned dynamics model. Moreover, our framework permits skill discovery even from offline data, thereby reducing the need for excessive real-world interactions. We demonstrate empirically that LiSP successfully enables long-horizon planning and learns agents that can avoid catastrophic failures even in challenging non-stationary and non-episodic environments derived from gridworld and MuJoCo benchmarks.",
        "conference": "ICLR",
        "中文标题": "无需重置的终身学习与技能空间规划",
        "摘要翻译": "终身强化学习（RL）的目标是优化能够持续适应并在变化环境中互动的智能体。然而，当环境非平稳且互动非片段化时，当前的RL方法表现极为不佳。我们提出了《终身技能规划》（LiSP），这是一个基于高阶技能抽象空间规划的终身RL算法框架。我们使用内在奖励以无监督方式学习技能，并利用学习到的动态模型在已学技能上进行规划。此外，我们的框架允许从离线数据中发现技能，从而减少对现实世界互动的过度需求。我们通过实验证明，LiSP成功实现了长视距规划，并在源自gridworld和MuJoCo基准的挑战性非平稳和非片段化环境中学习到了能够避免灾难性失败的智能体。",
        "领域": "强化学习、机器人学习、自适应系统",
        "问题": "解决在非平稳和非片段化环境中终身强化学习智能体的适应和规划问题",
        "动机": "当前强化学习方法在非平稳和非片段化环境中的表现不佳，需要一种能够持续适应并有效规划的方法",
        "方法": "提出LiSP框架，通过无监督学习高阶技能并在技能空间进行规划，利用内在奖励和动态模型优化智能体行为",
        "关键词": [
            "终身学习",
            "技能规划",
            "强化学习",
            "非平稳环境",
            "无监督学习"
        ],
        "涉及的技术概念": {
            "终身技能规划（LiSP）": "一个基于高阶技能抽象空间规划的终身RL算法框架，用于在变化环境中持续学习和适应",
            "内在奖励": "用于无监督学习技能，鼓励智能体探索和学习有用的行为模式",
            "动态模型": "用于在已学技能上进行规划，预测行为结果并优化决策过程"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 671,
        "title": "ResNet After All: Neural ODEs and Their Numerical Solution",
        "html": "https://iclr.cc//virtual/2021/poster/2936",
        "abstract": "A key appeal of the recently proposed Neural Ordinary Differential Equation (ODE) framework is that it seems to provide a continuous-time extension of discrete residual neural networks. \nAs we show herein, though, trained Neural ODE models actually depend on the specific numerical method used during training.\nIf the trained model is supposed to be a flow generated from an ODE, it should be possible to choose another numerical solver with equal or smaller numerical error without loss of performance.\nWe observe that if training relies on a solver with overly coarse discretization, then testing with another solver of equal or smaller numerical error results in a sharp drop in accuracy. \nIn such cases, the combination of vector field and numerical method cannot be interpreted as a flow generated from an ODE, which arguably poses a fatal breakdown of the Neural ODE concept.\nWe observe, however, that there exists a critical step size beyond which the training yields a valid ODE vector field. \nWe propose a method that monitors the behavior of the ODE solver during training to adapt its step size, aiming to ensure a valid ODE without unnecessarily increasing computational cost.\nWe verify this adaption algorithm on a common bench mark dataset as well as a synthetic dataset. \n",
        "conference": "ICLR",
        "中文标题": "终究是ResNet：神经ODE及其数值解法",
        "摘要翻译": "最近提出的神经常微分方程（ODE）框架的一个关键吸引力在于，它似乎提供了离散残差神经网络的连续时间扩展。然而，正如我们在此展示的，训练后的神经ODE模型实际上依赖于训练期间使用的特定数值方法。如果训练后的模型应该是从ODE生成的流，那么应该可以选择另一个具有相等或更小数值误差的数值求解器而不会损失性能。我们观察到，如果训练依赖于一个过于粗糙离散化的求解器，那么使用另一个具有相等或更小数值误差的求解器进行测试会导致准确率急剧下降。在这种情况下，向量场和数值方法的组合不能被解释为由ODE生成的流，这可以说是神经ODE概念的一个致命崩溃。然而，我们观察到存在一个临界步长，超过这个步长，训练会产生一个有效的ODE向量场。我们提出了一种方法，该方法在训练期间监控ODE求解器的行为，以调整其步长，旨在确保有效的ODE而不不必要地增加计算成本。我们在一个常见的基准数据集以及一个合成数据集上验证了这个适应算法。",
        "领域": "深度学习理论、神经网络架构、数值优化",
        "问题": "神经ODE框架在实际应用中依赖于特定的数值求解方法，这限制了其作为连续时间模型的通用性和灵活性。",
        "动机": "探索神经ODE模型在实际训练中对数值方法的依赖性，并提出一种方法来确保模型的有效性和灵活性。",
        "方法": "提出了一种在训练过程中监控和调整ODE求解器步长的方法，以确保生成的向量场有效且计算成本合理。",
        "关键词": [
            "神经ODE",
            "数值解法",
            "步长适应",
            "向量场",
            "深度学习理论"
        ],
        "涉及的技术概念": {
            "神经ODE": "一种将神经网络与常微分方程结合的框架，旨在提供连续时间下的模型动态。",
            "数值解法": "用于近似求解常微分方程的数学方法，影响神经ODE模型的训练和性能。",
            "步长适应": "在训练过程中动态调整数值求解器的步长，以平衡模型的有效性和计算效率。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 672,
        "title": "Rethinking Architecture Selection in Differentiable NAS",
        "html": "https://iclr.cc//virtual/2021/poster/2787",
        "abstract": "Differentiable Neural Architecture Search is one of the most popular Neural Architecture Search (NAS) methods for its search efficiency and simplicity, accomplished by jointly optimizing the model weight and architecture parameters in a weight-sharing supernet via gradient-based algorithms. At the end of the search phase, the operations with the largest architecture parameters will be selected to form the final architecture, with the implicit assumption that the values of architecture parameters reflect the operation strength. While much has been discussed about the supernet's optimization, the architecture selection process has received little attention. We provide empirical and theoretical analysis to show that the magnitude of architecture parameters does not necessarily indicate how much the operation contributes to the supernet's performance. We propose an alternative perturbation-based architecture selection that directly measures each operation's influence on the supernet. We re-evaluate several differentiable NAS methods with the proposed architecture selection and find that it is able to extract significantly improved architectures from the underlying supernets consistently. Furthermore, we find that several failure modes of DARTS can be greatly alleviated with the proposed selection method, indicating that much of the poor generalization observed in DARTS can be attributed to the failure of magnitude-based architecture selection rather than entirely the optimization of its supernet.",
        "conference": "ICLR",
        "中文标题": "重新思考可微分神经架构搜索中的架构选择",
        "摘要翻译": "可微分神经架构搜索（Differentiable Neural Architecture Search, DNAS）因其搜索效率和简洁性成为最流行的神经架构搜索（NAS）方法之一，它通过基于梯度的算法在权重共享的超网络中联合优化模型权重和架构参数来实现。在搜索阶段结束时，将选择具有最大架构参数的操作以形成最终架构，隐含的假设是架构参数的值反映了操作强度。虽然关于超网络的优化已有大量讨论，但架构选择过程却鲜少受到关注。我们提供了实证和理论分析，表明架构参数的大小并不一定反映操作对超网络性能的贡献程度。我们提出了一种基于扰动的替代架构选择方法，直接测量每个操作对超网络的影响。我们用提出的架构选择方法重新评估了几种可微分NAS方法，发现它能够一致地从底层超网络中提取出显著改进的架构。此外，我们发现DARTS的几种失败模式可以通过提出的选择方法大大缓解，这表明在DARTS中观察到的许多泛化能力差可以归因于基于幅度的架构选择的失败，而不是完全归因于其超网络的优化。",
        "领域": "神经架构搜索、深度学习优化、自动化机器学习",
        "问题": "可微分神经架构搜索中架构参数大小不一定准确反映操作对超网络性能的贡献程度",
        "动机": "解决可微分神经架构搜索中架构选择过程缺乏关注和基于幅度的架构选择方法可能不准确的问题",
        "方法": "提出一种基于扰动的架构选择方法，直接测量每个操作对超网络性能的影响",
        "关键词": [
            "可微分神经架构搜索",
            "架构选择",
            "超网络优化",
            "DARTS",
            "扰动分析"
        ],
        "涉及的技术概念": {
            "可微分神经架构搜索": "一种通过梯度下降联合优化模型权重和架构参数的神经架构搜索方法",
            "超网络": "在神经架构搜索中，一个包含所有可能架构的共享权重的大型网络",
            "基于扰动的架构选择": "一种通过直接测量操作对超网络性能的影响来选择架构的新方法"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 673,
        "title": "Rethinking Attention with Performers",
        "html": "https://iclr.cc//virtual/2021/poster/2726",
        "abstract": "We introduce Performers, Transformer architectures which can estimate regular (softmax) full-rank-attention Transformers with provable accuracy, but using only linear (as opposed to quadratic) space and time complexity, without relying on any priors such as sparsity or low-rankness. To approximate softmax attention-kernels, Performers use a novel Fast Attention Via positive Orthogonal Random features approach (FAVOR+), which may be of independent interest for scalable kernel methods. FAVOR+ can also be used to efficiently model kernelizable attention mechanisms beyond softmax. This representational power is crucial to accurately compare softmax with other kernels for the first time on large-scale tasks, beyond the reach of regular Transformers, and investigate optimal attention-kernels. Performers are linear architectures fully compatible with regular Transformers and with strong theoretical guarantees: unbiased or nearly-unbiased estimation of the attention matrix, uniform convergence and low  estimation variance. We tested Performers on a rich set of tasks stretching from pixel-prediction through text models to protein sequence modeling. We demonstrate competitive results with other examined efficient sparse and dense attention methods, showcasing effectiveness of the novel attention-learning paradigm leveraged by Performers. ",
        "conference": "ICLR",
        "中文标题": "重新思考注意力机制与Performers",
        "摘要翻译": "我们介绍了Performers，这是一种Transformer架构，能够以可证明的准确度估计常规（softmax）全秩注意力Transformer，同时仅使用线性（而非二次）空间和时间复杂度，而不依赖于任何先验条件，如稀疏性或低秩性。为了近似softmax注意力核，Performers采用了一种新颖的快速注意力通过正正交随机特征方法（FAVOR+），这对于可扩展的核方法可能具有独立的意义。FAVOR+也可用于高效建模超越softmax的可核化注意力机制。这种表示能力对于首次在大规模任务上准确比较softmax与其他核至关重要，超出了常规Transformer的范围，并研究最优注意力核。Performers是完全兼容常规Transformer的线性架构，并具有强大的理论保证：注意力矩阵的无偏或近乎无偏估计、均匀收敛和低估计方差。我们在从像素预测到文本模型再到蛋白质序列建模的一系列丰富任务上测试了Performers。我们展示了与其他检查过的高效稀疏和密集注意力方法相比的竞争性结果，展示了Performers所利用的新颖注意力学习范式的有效性。",
        "领域": "自然语言处理与视觉结合, 蛋白质序列建模, 大规模机器学习",
        "问题": "如何在不牺牲准确性的前提下，降低Transformer模型中的注意力机制计算复杂度",
        "动机": "解决Transformer模型中全秩注意力机制计算复杂度高的问题，使其能够在大规模任务上高效运行",
        "方法": "引入Performers架构和FAVOR+方法，通过线性空间和时间复杂度近似softmax注意力核",
        "关键词": [
            "Performers",
            "FAVOR+",
            "线性复杂度",
            "注意力机制",
            "大规模任务"
        ],
        "涉及的技术概念": {
            "FAVOR+": "一种快速注意力通过正正交随机特征方法，用于近似softmax注意力核，降低计算复杂度",
            "线性复杂度": "Performers架构的核心优势，使得模型在大规模数据上运行时更加高效",
            "注意力矩阵的无偏估计": "Performers提供的理论保证之一，确保模型估计的准确性和可靠性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 674,
        "title": "Rethinking Embedding Coupling in Pre-trained Language Models",
        "html": "https://iclr.cc//virtual/2021/poster/2735",
        "abstract": "We re-evaluate the standard practice of sharing weights between input and output embeddings in state-of-the-art pre-trained language models. We show that decoupled embeddings provide increased modeling flexibility, allowing us to significantly improve the efficiency of parameter allocation in the input embedding of multilingual models. By reallocating the input embedding parameters in the Transformer layers, we achieve dramatically better performance on standard natural language understanding tasks with the same number of parameters during fine-tuning. We also show that allocating additional capacity to the output embedding provides benefits to the model that persist through the fine-tuning stage even though the output embedding is discarded after pre-training. Our analysis shows that larger output embeddings prevent the model's last layers from overspecializing to the pre-training task and encourage Transformer representations to be more general and more transferable to other tasks and languages. Harnessing these findings, we are able to train models that achieve strong performance on the XTREME benchmark without increasing the number of parameters at the fine-tuning stage. ",
        "conference": "ICLR",
        "中文标题": "重新思考预训练语言模型中的嵌入耦合",
        "摘要翻译": "我们重新评估了在现有最先进的预训练语言模型中输入和输出嵌入共享权重的标准做法。研究表明，解耦嵌入提供了更高的建模灵活性，使我们能够显著提高多语言模型输入嵌入参数分配的效率。通过重新分配Transformer层中的输入嵌入参数，我们在微调阶段使用相同数量的参数，在标准的自然语言理解任务上实现了显著更好的性能。我们还发现，为输出嵌入分配额外的容量对模型有益，这种益处会持续到微调阶段，尽管输出嵌入在预训练后会被丢弃。我们的分析表明，更大的输出嵌入可以防止模型的最后层过度专门化于预训练任务，并鼓励Transformer表示更加通用，更易于迁移到其他任务和语言。利用这些发现，我们能够训练出在XTREME基准测试中表现强劲的模型，而无需在微调阶段增加参数数量。",
        "领域": "自然语言处理与视觉结合, 多语言模型, 预训练语言模型",
        "问题": "预训练语言模型中输入和输出嵌入共享权重的效率问题",
        "动机": "提高多语言模型参数分配的效率和模型性能",
        "方法": "通过解耦输入和输出嵌入，重新分配Transformer层中的输入嵌入参数，以及增加输出嵌入的容量",
        "关键词": [
            "嵌入解耦",
            "参数分配",
            "多语言模型",
            "Transformer",
            "XTREME基准测试"
        ],
        "涉及的技术概念": {
            "嵌入解耦": "在预训练语言模型中分离输入和输出嵌入的权重，以提高建模灵活性和参数效率",
            "参数分配": "优化模型参数的使用，特别是在多语言模型的输入嵌入中，以提高性能",
            "Transformer表示": "通过调整输出嵌入的大小，改善模型的通用性和迁移能力"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 675,
        "title": "Rethinking Positional Encoding in Language Pre-training",
        "html": "https://iclr.cc//virtual/2021/poster/2982",
        "abstract": "In this work, we investigate the positional encoding methods used in language pre-training (e.g., BERT) and identify several problems in the existing formulations. First, we show that in the absolute positional encoding, the addition operation applied on positional embeddings and word embeddings brings mixed correlations between the two heterogeneous information resources. It may bring unnecessary randomness in the attention and further limit the expressiveness of the model.  Second, we question whether treating the position of the symbol \\texttt{[CLS]} the same as other words is a reasonable design, considering its special role (the representation of the entire sentence) in the downstream tasks. Motivated from above analysis, we propose a new positional encoding method called \\textbf{T}ransformer with \\textbf{U}ntied \\textbf{P}ositional \\textbf{E}ncoding (TUPE). In the self-attention module, TUPE computes the word contextual correlation and positional correlation separately with different parameterizations and then adds them together. This design removes the mixed and noisy correlations over heterogeneous embeddings and offers more expressiveness by using different projection matrices. Furthermore, TUPE unties the \\texttt{[CLS]} symbol from other positions, making it easier to capture information from all positions. Extensive experiments and ablation studies on GLUE benchmark demonstrate the effectiveness of the proposed method. Codes and models are released at \\url{https://github.com/guolinke/TUPE}.",
        "conference": "ICLR",
        "中文标题": "重新思考语言预训练中的位置编码",
        "摘要翻译": "在这项工作中，我们研究了语言预训练（例如BERT）中使用的位置编码方法，并识别了现有公式中的几个问题。首先，我们展示了在绝对位置编码中，应用于位置嵌入和词嵌入的加法操作带来了两种异构信息源之间的混合相关性。这可能会在注意力中引入不必要的随机性，并进一步限制模型的表达能力。其次，考虑到[CLS]符号在下游任务中的特殊作用（整个句子的表示），我们质疑将其位置与其他单词相同对待是否是一个合理的设计。基于上述分析的动机，我们提出了一种新的位置编码方法，称为具有解绑位置编码的Transformer（TUPE）。在自注意力模块中，TUPE用不同的参数化分别计算词上下文相关性和位置相关性，然后将它们相加。这种设计消除了异构嵌入之间的混合和噪声相关性，并通过使用不同的投影矩阵提供了更多的表达能力。此外，TUPE将[CLS]符号与其他位置解绑，使其更容易从所有位置捕获信息。在GLUE基准上的大量实验和消融研究证明了所提出方法的有效性。代码和模型发布于https://github.com/guolinke/TUPE。",
        "领域": "自然语言处理与视觉结合",
        "问题": "解决现有位置编码方法在语言预训练中引入的混合相关性和对[CLS]符号位置处理不当的问题",
        "动机": "识别并解决现有位置编码方法在表达能力和设计合理性上的限制",
        "方法": "提出了一种新的位置编码方法TUPE，通过解绑位置编码和词上下文相关性计算，以及特殊处理[CLS]符号的位置，来提高模型的表达能力和效率",
        "关键词": [
            "位置编码",
            "语言预训练",
            "自注意力机制",
            "Transformer",
            "TUPE"
        ],
        "涉及的技术概念": {
            "绝对位置编码": "在语言预训练中用于表示单词在句子中位置的技术，通过加法操作与词嵌入结合",
            "自注意力机制": "Transformer模型中的核心机制，用于计算输入序列中各个元素之间的相关性",
            "TUPE": "一种新的位置编码方法，通过解绑位置和词上下文相关性计算，以及特殊处理[CLS]符号的位置，来提高模型的表达能力和效率"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 676,
        "title": "Rethinking Soft Labels for Knowledge Distillation: A Bias–Variance Tradeoff Perspective",
        "html": "https://iclr.cc//virtual/2021/poster/2807",
        "abstract": "Knowledge distillation is an effective approach to leverage a well-trained network or an ensemble of them, named as the teacher, to guide the training of a student network.  The outputs from the teacher network are used as soft labels for supervising the training of a new network.  Recent studies (M ̈uller et al., 2019; Yuan et al., 2020) revealed an intriguing property of the soft labels that making labels soft serves as a good regularization to the student network.   From the perspective of statistical learning,  regularization aims to reduce the variance,  however how bias and variance change is not clear for training with soft labels.   In this paper, we investigate the bias-variance tradeoff brought by distillation with soft labels.   Specifically,  we observe that during training the bias-variance tradeoff varies sample-wisely. Further, under the same distillation temperature setting, we observe that the distillation performance is negatively associated with the number of some specific samples, which are named as regularization samples since these samples lead to bias increasing and variance decreasing.  Nevertheless, we empirically find that completely filtering out regularization samples also deteriorates distillation performance.  Our discoveries inspired us to propose the novel weighted soft labels to help the network adaptively handle the sample-wise bias-variance tradeoff.  Experiments on standard evaluation benchmarks validate the effectiveness of our method. Our code is available in the supplementary.",
        "conference": "ICLR",
        "中文标题": "重新思考知识蒸馏中的软标签：一种偏差-方差权衡的视角",
        "摘要翻译": "知识蒸馏是一种有效的方法，它利用一个训练良好的网络或它们的集合（称为教师网络）来指导学生网络的训练。教师网络的输出被用作监督新网络训练的软标签。最近的研究（Müller等人，2019；Yuan等人，2020）揭示了软标签的一个有趣特性，即软化标签可以作为对学生网络的一种良好正则化。从统计学习的角度来看，正则化旨在减少方差，然而对于使用软标签训练时偏差和方差如何变化尚不清楚。在本文中，我们研究了由软标签蒸馏带来的偏差-方差权衡。具体来说，我们观察到在训练过程中，偏差-方差权衡随样本而变化。此外，在相同的蒸馏温度设置下，我们观察到蒸馏性能与某些特定样本的数量呈负相关，这些样本被称为正则化样本，因为它们导致偏差增加和方差减少。然而，我们经验性地发现，完全过滤掉正则化样本也会恶化蒸馏性能。我们的发现启发我们提出新颖的加权软标签，以帮助网络自适应地处理样本级的偏差-方差权衡。在标准评估基准上的实验验证了我们方法的有效性。我们的代码可在补充材料中找到。",
        "领域": "知识蒸馏、模型压缩、深度学习优化",
        "问题": "研究在使用软标签进行知识蒸馏时，偏差和方差如何变化及其对模型性能的影响。",
        "动机": "探索软标签在知识蒸馏中的正则化作用及其对偏差和方差的影响，以优化学生网络的训练过程。",
        "方法": "通过分析偏差-方差权衡随样本变化的特性，提出加权软标签方法，以自适应地处理样本级的偏差-方差权衡。",
        "关键词": [
            "知识蒸馏",
            "软标签",
            "偏差-方差权衡",
            "正则化样本",
            "加权软标签"
        ],
        "涉及的技术概念": {
            "知识蒸馏": "一种模型压缩技术，通过教师网络指导学生网络的训练，以提高学生网络的性能。",
            "软标签": "教师网络输出的概率分布，用于指导学生网络的训练，相比硬标签提供更多信息。",
            "偏差-方差权衡": "统计学习中的一个基本概念，描述了模型复杂度和泛化能力之间的平衡关系。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 677,
        "title": "Rethinking the Role of Gradient-based Attribution Methods for Model Interpretability",
        "html": "https://iclr.cc//virtual/2021/poster/2943",
        "abstract": "Current methods for the interpretability of discriminative deep neural networks commonly rely on the model's input-gradients, i.e., the gradients of the output logits w.r.t. the inputs. The common assumption is that these input-gradients contain information regarding $p_{\\theta} ( y\\mid \\mathbf{x} )$, the model's discriminative capabilities, thus justifying their use for interpretability. However, in this work, we show that these input-gradients can be arbitrarily manipulated as a consequence of the shift-invariance of softmax without changing the discriminative function. This leaves an open question: given that input-gradients can be arbitrary, why are they highly structured and explanatory in standard models?\n\nIn this work, we re-interpret the logits of standard softmax-based classifiers as unnormalized log-densities of the data distribution and show that input-gradients can be viewed as gradients of a class-conditional generative model $p_{\\theta}(\\mathbf{x} \\mid y)$ implicit in the discriminative model. This leads us to hypothesize that the highly structured and explanatory nature of input-gradients may be due to the alignment of this class-conditional model $p_{\\theta}(\\mathbf{x} \\mid y)$ with that of the ground truth data distribution $p_{\\text{data}} (\\mathbf{x} \\mid y)$. We test this hypothesis by studying the effect of density alignment on gradient explanations. To achieve this density alignment, we use an algorithm called score-matching, and propose novel approximations to this algorithm to enable training large-scale models.\n\nOur experiments show that improving the alignment of the implicit density model with the data distribution enhances gradient structure and explanatory power while reducing this alignment has the opposite effect. This also leads us to conjecture that unintended density alignment in standard neural network training may explain the highly structured nature of input-gradients observed in practice. Overall, our finding that input-gradients capture information regarding an implicit generative model implies that we need to re-think their use for interpreting discriminative models.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "重新思考基于梯度的归因方法在模型可解释性中的作用",
        "摘要翻译": "目前用于判别式深度神经网络可解释性的方法通常依赖于模型的输入梯度，即输出 logits 相对于输入的梯度。一个常见的假设是，这些输入梯度包含关于 $p_{\\\\theta} ( y\\\\mid \\\\mathbf{x} )$ 的信息，即模型判别能力，从而证明了它们用于可解释性的合理性。然而，在这项工作中，我们表明，由于 softmax 的移位不变性，这些输入梯度可以被任意操纵，而不会改变判别函数。这就留下了一个悬而未决的问题：既然输入梯度可以是任意的，为什么它们在标准模型中具有高度的结构化和解释性？\\n\\n在这项工作中，我们将标准 softmax 分类器的 logits 重新解释为数据分布的未归一化对数密度，并表明输入梯度可以被视为判别模型中隐含的类条件生成模型 $p_{\\\\theta}(\\\\mathbf{x} \\\\mid y)$ 的梯度。这使我们假设输入梯度的高度结构化和解释性可能归因于该类条件模型 $p_{\\\\theta}(\\\\mathbf{x} \\\\mid y)$ 与真实数据分布 $p_{\\\\text{data}} (\\\\mathbf{x} \\\\mid y)$ 的对齐。我们通过研究密度对齐对梯度解释的影响来检验这个假设。为了实现这种密度对齐，我们使用了一种称为 score-matching 的算法，并提出了该算法的新颖近似，以实现大规模模型的训练。\\n\\n我们的实验表明，提高隐式密度模型与数据分布的对齐可以增强梯度结构和解释能力，而降低这种对齐则会产生相反的效果。这也让我们推测，标准神经网络训练中无意的密度对齐可能解释了实践中观察到的输入梯度的高度结构化性质。总的来说，我们发现输入梯度捕获了关于隐式生成模型的信息，这意味着我们需要重新思考它们在解释判别模型中的使用。",
        "领域": "模型可解释性, 深度学习, 梯度分析",
        "问题": "输入梯度在判别式模型中是否真正反映了模型的判别能力，以及为什么即使输入梯度可以被任意操纵，它们仍然表现出结构化和可解释的特性。",
        "动机": "现有方法依赖输入梯度来解释深度学习模型，但输入梯度可能被操纵，从而质疑了其可信度。研究的目的是为了理解输入梯度在判别模型中的作用以及其结构化和可解释性的原因。",
        "方法": "该论文将softmax分类器的logits重新解释为数据分布的未归一化对数密度，并将输入梯度视为类条件生成模型的梯度。通过score-matching算法实现密度对齐，并提出了该算法的新颖近似，以实现大规模模型的训练。通过实验验证了隐式密度模型与数据分布的对齐对梯度结构和解释能力的影响。",
        "关键词": [
            "模型可解释性",
            "输入梯度",
            "密度对齐",
            "Score-matching",
            "生成模型"
        ],
        "涉及的技术概念": {
            "输入梯度": "模型输出相对于输入的梯度，传统上被用于解释模型如何根据输入进行决策。论文质疑了其在判别模型中的可靠性。",
            "Score-matching": "一种用于密度估计的算法，用于对齐隐式密度模型与数据分布。论文使用此方法来研究密度对齐对梯度解释的影响。"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 678,
        "title": "Retrieval-Augmented Generation for Code Summarization via Hybrid GNN",
        "html": "https://iclr.cc//virtual/2021/poster/3330",
        "abstract": "Source code summarization aims to generate natural language summaries from structured code snippets for better understanding code functionalities. However, automatic code summarization is challenging due to the complexity of the source code and the language gap between the source code and natural language summaries. Most previous approaches either rely on retrieval-based (which can take advantage of similar examples seen from the retrieval database, but have low generalization performance) or generation-based methods (which have better generalization performance, but cannot take advantage of similar examples).\nThis paper proposes a novel retrieval-augmented mechanism to combine the benefits of both worlds.\nFurthermore, to mitigate the limitation of Graph Neural Networks (GNNs) on capturing global graph structure information of source code, we propose a novel attention-based dynamic graph to complement the static graph representation of the source code, and design a hybrid message passing GNN for capturing both the local and global structural information. To evaluate the proposed approach, we release a new challenging benchmark, crawled from diversified large-scale open-source C projects (total 95k+ unique functions in the dataset). Our method achieves the state-of-the-art performance, improving existing methods by 1.42, 2.44 and 1.29 in terms of BLEU-4, ROUGE-L and METEOR.",
        "conference": "ICLR",
        "中文标题": "通过混合图神经网络实现检索增强的代码摘要生成",
        "摘要翻译": "源代码摘要的目标是从结构化的代码片段生成自然语言摘要，以便更好地理解代码功能。然而，由于源代码的复杂性以及源代码与自然语言摘要之间的语言差异，自动代码摘要具有挑战性。大多数先前的方法要么依赖于基于检索的方法（可以利用从检索数据库中看到的类似示例，但泛化性能较低），要么依赖于基于生成的方法（具有更好的泛化性能，但不能利用类似示例）。本文提出了一种新颖的检索增强机制，以结合两者的优势。此外，为了缓解图神经网络（GNNs）在捕获源代码的全局图结构信息方面的限制，我们提出了一种新颖的基于注意力的动态图来补充源代码的静态图表示，并设计了一种混合消息传递GNN，用于捕获局部和全局结构信息。为了评估所提出的方法，我们发布了一个新的具有挑战性的基准，该基准是从多样化的大规模开源C项目中爬取的（数据集中共有95k+独特函数）。我们的方法实现了最先进的性能，在BLEU-4、ROUGE-L和METEOR方面分别比现有方法提高了1.42、2.44和1.29。",
        "领域": "代码摘要生成、图神经网络、自然语言处理与编程语言结合",
        "问题": "解决源代码与自然语言摘要之间的语言差异，以及如何有效结合检索和生成方法的优势进行代码摘要生成。",
        "动机": "结合检索和生成方法的优势，提高代码摘要的生成质量和泛化能力，同时通过改进图神经网络来更好地捕获源代码的结构信息。",
        "方法": "提出了一种检索增强机制结合基于注意力的动态图和静态图表示，设计了一种混合消息传递GNN来捕获源代码的局部和全局结构信息。",
        "关键词": [
            "代码摘要生成",
            "检索增强生成",
            "混合图神经网络",
            "注意力机制",
            "动态图表示"
        ],
        "涉及的技术概念": {
            "检索增强机制": "结合检索和生成方法的优势，提高摘要生成的准确性和泛化能力。",
            "基于注意力的动态图": "用于补充源代码的静态图表示，更好地捕获源代码的全局结构信息。",
            "混合消息传递GNN": "设计用于同时捕获源代码的局部和全局结构信息，提高代码摘要的质量。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 679,
        "title": "Return-Based Contrastive Representation Learning for Reinforcement  Learning",
        "html": "https://iclr.cc//virtual/2021/poster/3151",
        "abstract": "Recently, various auxiliary tasks have been proposed to accelerate representation learning and improve sample efficiency in deep reinforcement learning (RL). However, existing auxiliary tasks do not take the characteristics of RL problems into consideration and are unsupervised. By leveraging returns, the most important feedback signals in RL, we propose a novel auxiliary task that forces the learnt representations to discriminate state-action pairs with different returns. Our auxiliary loss is theoretically justified to learn representations that capture the structure of a new form of state-action abstraction, under which state-action pairs with similar return distributions are aggregated together. Empirically, our algorithm outperforms strong baselines on complex tasks in Atari games and DeepMind Control suite, and achieves even better performance when combined with existing auxiliary tasks.",
        "conference": "ICLR",
        "中文标题": "基于回报的对比表示学习在强化学习中的应用",
        "摘要翻译": "最近，为了加速表示学习并提高深度强化学习（RL）中的样本效率，提出了各种辅助任务。然而，现有的辅助任务没有考虑到RL问题的特性，并且是无监督的。通过利用回报——RL中最重要的反馈信号，我们提出了一种新的辅助任务，该任务迫使学习到的表示能够区分具有不同回报的状态-动作对。我们的辅助损失在理论上被证明可以学习捕捉一种新形式的状态-动作抽象结构的表示，在这种结构下，具有相似回报分布的状态-动作对被聚合在一起。实证上，我们的算法在Atari游戏和DeepMind Control套件的复杂任务上优于强基线，并且在与现有辅助任务结合时实现了更好的性能。",
        "领域": "深度强化学习",
        "问题": "如何通过利用回报信号来改进强化学习中的表示学习",
        "动机": "现有的辅助任务未充分考虑强化学习问题的特性，且缺乏监督信号，限制了表示学习的效果和样本效率",
        "方法": "提出一种新的基于回报的对比表示学习辅助任务，通过区分不同回报的状态-动作对来学习更有意义的表示",
        "关键词": [
            "强化学习",
            "表示学习",
            "对比学习",
            "回报信号",
            "辅助任务"
        ],
        "涉及的技术概念": {
            "回报信号": "强化学习中的反馈信号，用于指导学习过程，本文中作为区分状态-动作对的关键依据",
            "对比表示学习": "一种学习表示的方法，通过对比相似和不相似的样本来提高表示的区分度",
            "状态-动作抽象": "将具有相似回报分布的状态-动作对聚合在一起，形成更高层次的抽象表示"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 680,
        "title": "Revisiting Dynamic Convolution via Matrix Decomposition",
        "html": "https://iclr.cc//virtual/2021/poster/2520",
        "abstract": "Recent research in dynamic convolution shows substantial performance boost for efficient CNNs, due to the adaptive aggregation of K static convolution kernels. It has two limitations: (a) it increases the number of convolutional weights by K-times, and (b) the joint optimization of dynamic attention and static convolution kernels is challenging. In this paper, we revisit it from a new perspective of matrix decomposition and reveal the key issue is that dynamic convolution applies dynamic attention over channel groups after projecting into a higher dimensional latent space. To address this issue, we propose dynamic channel fusion to replace dynamic attention over channel groups. Dynamic channel fusion not only enables significant dimension reduction of the latent space, but also mitigates the joint optimization difficulty. As a result, our method is easier to train and requires significantly fewer parameters without sacrificing accuracy. Source code is at https://github.com/liyunsheng13/dcd.",
        "conference": "ICLR",
        "中文标题": "通过矩阵分解重新审视动态卷积",
        "摘要翻译": "最近关于动态卷积的研究表明，由于K个静态卷积核的自适应聚合，高效CNNs的性能得到了显著提升。它有两个局限性：(a)它将卷积权重的数量增加了K倍，(b)动态注意力和静态卷积核的联合优化具有挑战性。在本文中，我们从矩阵分解的新视角重新审视了这一问题，并揭示了关键问题在于动态卷积在将通道组投影到更高维的潜在空间后应用了动态注意力。为了解决这个问题，我们提出了动态通道融合来替代通道组上的动态注意力。动态通道融合不仅能够显著减少潜在空间的维度，还能缓解联合优化的困难。因此，我们的方法更易于训练，且在不牺牲准确性的情况下需要显著更少的参数。源代码位于https://github.com/liyunsheng13/dcd。",
        "领域": "卷积神经网络优化",
        "问题": "动态卷积在增加卷积权重数量和联合优化动态注意力与静态卷积核方面存在局限性",
        "动机": "解决动态卷积在参数效率和优化难度上的问题",
        "方法": "通过矩阵分解视角提出动态通道融合技术，以减少潜在空间维度和简化优化过程",
        "关键词": [
            "动态卷积",
            "矩阵分解",
            "通道融合",
            "参数效率",
            "优化难度"
        ],
        "涉及的技术概念": {
            "动态卷积": "通过自适应聚合多个静态卷积核来提升模型性能的技术",
            "矩阵分解": "用于分析和简化动态卷积中权重增加问题的数学工具",
            "动态通道融合": "提出的新技术，用于替代动态注意力，减少潜在空间维度和优化难度"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 681,
        "title": "Revisiting Few-sample BERT Fine-tuning",
        "html": "https://iclr.cc//virtual/2021/poster/2678",
        "abstract": "This paper is a study of fine-tuning of BERT contextual representations, with focus on commonly observed instabilities in few-sample scenarios. We identify several factors that cause this instability: the common use of a non-standard optimization method with biased gradient estimation; the limited applicability of significant parts of the BERT network for down-stream tasks; and the prevalent practice of using a pre-determined, and small number of training iterations. We empirically test the impact of these factors, and identify alternative practices that resolve the commonly observed instability of the process. In light of these observations, we re-visit recently proposed methods to improve few-sample fine-tuning with BERT and re-evaluate their effectiveness. Generally, we observe the impact of these methods diminishes significantly with our modified process. ",
        "conference": "ICLR",
        "中文标题": "重新审视小样本BERT微调",
        "摘要翻译": "本文是对BERT上下文表示微调的研究，重点关注在小样本场景中常见的不稳定性问题。我们识别出导致这种不稳定性的几个因素：使用非标准优化方法导致的梯度估计偏差；BERT网络中大部分内容对下游任务的适用性有限；以及普遍采用预定的、较少的训练迭代次数的做法。我们实证测试了这些因素的影响，并找出了解决过程中常见不稳定性的替代做法。基于这些观察，我们重新审视了最近提出的改进小样本BERT微调的方法，并重新评估了它们的有效性。总体而言，我们发现这些方法在我们修改后的过程中影响显著减弱。",
        "领域": "自然语言处理与视觉结合",
        "问题": "解决BERT在小样本微调过程中的不稳定性问题",
        "动机": "研究旨在识别并解决BERT在小样本微调中的不稳定性，以提高模型在下游任务中的表现",
        "方法": "通过实证测试识别不稳定性因素，并提出替代做法以改进微调过程",
        "关键词": [
            "BERT微调",
            "小样本学习",
            "优化方法",
            "梯度估计",
            "训练迭代"
        ],
        "涉及的技术概念": {
            "非标准优化方法": "论文中提到的导致梯度估计偏差的优化方法，影响微调过程的稳定性",
            "BERT网络适用性": "指BERT网络中部分内容对下游任务的适用性有限，影响微调效果",
            "训练迭代次数": "预定的、较少的训练迭代次数是导致微调不稳定的一个因素"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 682,
        "title": "Revisiting Hierarchical Approach for Persistent Long-Term Video Prediction",
        "html": "https://iclr.cc//virtual/2021/poster/2718",
        "abstract": "Learning to predict the long-term future of video frames is notoriously challenging due to the inherent ambiguities in a distant future and dramatic amplification of prediction error over time. Despite the recent advances in the literature, existing approaches are limited to moderately short-term prediction (less than a few seconds), while extrapolating it to a longer future quickly leads to destruction in structure and content. In this work, we revisit the hierarchical models in video prediction. Our method generates future frames by first estimating a sequence of dense semantic structures and subsequently translating the estimated structures to pixels by video-to-video translation model. Despite the simplicity, we show that modeling structures and their dynamics in categorical structure space with stochastic sequential estimator leads to surprisingly successful long-term prediction. We evaluate our method on two challenging video prediction scenarios, \\emph{car driving} and \\emph{human dancing}, and demonstrate that it can generate complicated scene structures and motions over a very long time horizon (\\ie~thousands frames), setting a new standard of video prediction with orders of magnitude longer prediction time than existing approaches. Video results are available at https://1konny.github.io/HVP/.",
        "conference": "ICLR",
        "中文标题": "重新审视持久长期视频预测的层次化方法",
        "摘要翻译": "学习预测视频帧的长期未来由于遥远未来固有的模糊性和预测误差随时间的急剧放大而极具挑战性。尽管文献中最近有所进展，现有方法仅限于中等短期预测（少于几秒），而将其外推到更长的未来会迅速导致结构和内容的破坏。在这项工作中，我们重新审视了视频预测中的层次化模型。我们的方法通过首先生成一系列密集语义结构的估计，然后通过视频到视频的翻译模型将估计的结构转换为像素来生成未来帧。尽管方法简单，我们展示了在分类结构空间中对结构及其动态进行建模，结合随机序列估计器，可以意外成功地实现长期预测。我们在两个具有挑战性的视频预测场景——汽车驾驶和人类舞蹈——上评估了我们的方法，并证明它可以在非常长的时间范围内（即数千帧）生成复杂的场景结构和运动，为视频预测设定了新的标准，其预测时间比现有方法长几个数量级。视频结果可在https://1konny.github.io/HVP/查看。",
        "领域": "视频预测、语义结构估计、视频到视频翻译",
        "问题": "解决长期视频预测中由于时间延长导致的结构和内容破坏问题",
        "动机": "探索如何通过层次化模型和语义结构估计，实现比现有方法更长时间的准确视频预测",
        "方法": "采用层次化模型，首先生成密集语义结构的序列估计，然后通过视频到视频翻译模型将结构转换为像素",
        "关键词": [
            "长期视频预测",
            "层次化模型",
            "语义结构估计",
            "视频到视频翻译",
            "随机序列估计器"
        ],
        "涉及的技术概念": {
            "层次化模型": "用于视频预测的模型，通过分层次处理视频帧，首先生成高级语义结构，再转换为具体像素",
            "语义结构估计": "预测视频中对象的语义结构和动态，作为生成未来帧的基础",
            "视频到视频翻译模型": "将估计的语义结构转换为具体视频帧的模型，实现从结构到像素的转换"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 683,
        "title": "Revisiting Locally Supervised Learning: an Alternative to End-to-end Training",
        "html": "https://iclr.cc//virtual/2021/poster/3135",
        "abstract": "Due to the need to store the intermediate activations for back-propagation, end-to-end (E2E) training of deep networks usually suffers from high GPUs memory footprint. This paper aims to address this problem by revisiting the locally supervised learning, where a network is split into gradient-isolated modules and trained with local supervision. We experimentally show that simply training local modules with E2E loss tends to collapse task-relevant information at early layers, and hence hurts the performance of the full model. To avoid this issue, we propose an information propagation (InfoPro) loss, which encourages local modules to preserve as much useful information as possible, while progressively discard task-irrelevant information. As InfoPro loss is difficult to compute in its original form, we derive a feasible upper bound as a surrogate optimization objective, yielding a simple but effective algorithm. In fact, we show that the proposed method boils down to minimizing the combination of a reconstruction loss and a normal cross-entropy/contrastive term. Extensive empirical results on five datasets (i.e., CIFAR, SVHN, STL-10, ImageNet and Cityscapes) validate that InfoPro is capable of achieving competitive performance with less than 40% memory footprint compared to E2E training, while allowing using training data with higher-resolution or larger batch sizes under the same GPU memory constraint. Our method also enables training local modules asynchronously for potential training acceleration.",
        "conference": "ICLR",
        "中文标题": "重新审视局部监督学习：端到端训练的替代方案",
        "摘要翻译": "由于需要存储中间激活以进行反向传播，深度网络的端到端（E2E）训练通常面临高GPU内存占用的问题。本文旨在通过重新审视局部监督学习来解决这一问题，其中网络被分割为梯度隔离的模块，并使用局部监督进行训练。我们通过实验表明，简单地使用E2E损失训练局部模块往往会导致任务相关信息在早期层崩溃，从而损害完整模型的性能。为了避免这一问题，我们提出了一种信息传播（InfoPro）损失，它鼓励局部模块尽可能保留有用的信息，同时逐步丢弃与任务无关的信息。由于InfoPro损失在其原始形式下难以计算，我们推导出一个可行的上界作为替代优化目标，产生了一个简单但有效的算法。事实上，我们表明所提出的方法归结为最小化重建损失和正常交叉熵/对比项的组合。在五个数据集（即CIFAR、SVHN、STL-10、ImageNet和Cityscapes）上的广泛实证结果验证了InfoPro能够在不到E2E训练40%的内存占用下实现竞争性能，同时允许在相同的GPU内存约束下使用更高分辨率或更大批量的训练数据。我们的方法还支持异步训练局部模块以实现潜在的训练加速。",
        "领域": "深度学习优化、计算机视觉、神经网络训练",
        "问题": "解决端到端训练中高GPU内存占用的问题",
        "动机": "通过局部监督学习减少内存占用，同时保持模型性能",
        "方法": "提出信息传播（InfoPro）损失，结合重建损失和交叉熵/对比项，优化局部模块训练",
        "关键词": [
            "局部监督学习",
            "信息传播损失",
            "GPU内存优化",
            "异步训练",
            "深度学习"
        ],
        "涉及的技术概念": {
            "局部监督学习": "将网络分割为梯度隔离的模块，使用局部监督进行训练，以减少内存占用",
            "信息传播（InfoPro）损失": "鼓励局部模块保留有用信息，丢弃无关信息，以优化模型性能",
            "重建损失": "在InfoPro损失中用于保留输入数据的关键信息"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 684,
        "title": "Reweighting Augmented Samples by Minimizing the Maximal Expected Loss",
        "html": "https://iclr.cc//virtual/2021/poster/3131",
        "abstract": "Data augmentation is an effective technique to improve the generalization of deep neural networks. However, previous data augmentation methods usually treat the augmented samples equally without considering their individual impacts on the model. To address this, for the augmented samples from the same training example, we propose to assign different weights to them. We construct the maximal expected loss which is the supremum over any reweighted loss on augmented samples. Inspired by adversarial training, we minimize this maximal expected loss (MMEL) and obtain a simple and interpretable closed-form solution: more attention should be paid to augmented samples with large loss values (i.e., harder examples). Minimizing this maximal expected loss enables the model to perform well under any reweighting strategy. The proposed method can generally be applied on top of any data augmentation methods. Experiments are conducted on both natural language understanding tasks with token-level data augmentation, and image classification tasks with commonly-used image augmentation techniques like random crop and horizontal flip. Empirical results show that the proposed method improves the generalization performance of the model.",
        "conference": "ICLR",
        "中文标题": "通过最小化最大期望损失重新加权增强样本",
        "摘要翻译": "数据增强是提高深度神经网络泛化能力的有效技术。然而，以往的数据增强方法通常平等对待所有增强样本，没有考虑它们对模型的个体影响。为了解决这个问题，对于来自同一训练样本的增强样本，我们提出为它们分配不同的权重。我们构建了最大期望损失，这是对增强样本上任何重新加权损失的上确界。受对抗训练的启发，我们最小化这个最大期望损失（MMEL），并得到一个简单且可解释的闭式解：应该更多地关注损失值大的增强样本（即更难处理的例子）。最小化这个最大期望损失使模型在任何重新加权策略下都能表现良好。所提出的方法可以普遍应用于任何数据增强方法之上。实验在自然语言理解任务（使用令牌级数据增强）和图像分类任务（使用常用的图像增强技术，如随机裁剪和水平翻转）上进行。实证结果表明，所提出的方法提高了模型的泛化性能。",
        "领域": "数据增强、自然语言处理、图像分类",
        "问题": "如何为数据增强过程中生成的样本分配不同的权重，以提高模型的泛化能力",
        "动机": "传统数据增强方法平等对待所有增强样本，忽视了不同样本对模型训练效果的个体差异，导致模型泛化能力提升有限",
        "方法": "提出通过最小化最大期望损失（MMEL）的方法，为增强样本分配不同权重，特别关注损失值大的样本，以提高模型在任何重新加权策略下的表现",
        "关键词": [
            "数据增强",
            "最大期望损失",
            "模型泛化",
            "权重分配",
            "对抗训练"
        ],
        "涉及的技术概念": {
            "最大期望损失（MMEL）": "构建的上确界损失，用于评估和优化增强样本的权重分配策略",
            "对抗训练": "启发于对抗训练的思想，通过最小化最大期望损失来提高模型对难样本的关注",
            "闭式解": "通过数学推导得到的简单且可解释的权重分配方案，直接指导模型训练"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 685,
        "title": "R-GAP: Recursive Gradient Attack on Privacy",
        "html": "https://iclr.cc//virtual/2021/poster/3194",
        "abstract": "Federated learning frameworks have been regarded as a promising approach to break the dilemma between demands on privacy and the promise of learning from large collections of distributed data. Many such frameworks only ask collaborators to share their local update of a common model, i.e. gradients with respect to locally stored data, instead of exposing their raw data to other collaborators. However, recent optimization-based gradient attacks show that raw data can often be accurately recovered from gradients. It has been shown that minimizing the Euclidean distance between true gradients and those calculated from estimated data is often effective in fully recovering private data. However, there is a fundamental lack of theoretical understanding of how and when gradients can lead to unique recovery of original data. Our research fills this gap by providing a closed-form recursive procedure to recover data from gradients in deep neural networks. We name it Recursive Gradient Attack on Privacy (R-GAP). Experimental results demonstrate that R-GAP  works as well as or even better than optimization-based approaches at a fraction of the computation under certain conditions. Additionally, we propose a Rank Analysis method, which can be used to estimate the risk of gradient attacks inherent in certain network architectures, regardless of whether an optimization-based or closed-form-recursive attack is used. Experimental results demonstrate the utility of the rank analysis towards improving the network's security. Source code is available for download from https://github.com/JunyiZhu-AI/R-GAP.",
        "conference": "ICLR",
        "中文标题": "R-GAP：递归梯度攻击隐私",
        "摘要翻译": "联邦学习框架被视为一种有前景的方法，以解决在隐私需求与从大量分布式数据中学习的承诺之间的困境。许多此类框架仅要求协作者共享他们对共同模型的本地更新，即相对于本地存储数据的梯度，而不是将原始数据暴露给其他协作者。然而，最近的基于优化的梯度攻击表明，原始数据往往可以从梯度中准确恢复。已经证明，最小化真实梯度与从估计数据计算的梯度之间的欧几里得距离，通常在完全恢复私有数据方面是有效的。然而，关于梯度如何以及何时能够导致原始数据的唯一恢复，存在根本性的理论理解缺乏。我们的研究通过提供一个封闭形式的递归程序来从深度神经网络中的梯度恢复数据，填补了这一空白。我们将其命名为递归梯度攻击隐私（R-GAP）。实验结果表明，在某些条件下，R-GAP的表现与基于优化的方法相当甚至更好，而计算量仅为后者的一小部分。此外，我们提出了一种秩分析方法，可用于估计某些网络架构中固有的梯度攻击风险，无论是否使用基于优化或封闭形式递归攻击。实验结果证明了秩分析在提高网络安全性方面的效用。源代码可从https://github.com/JunyiZhu-AI/R-GAP下载。",
        "领域": "联邦学习、隐私保护、深度学习安全",
        "问题": "如何从梯度中准确恢复原始数据，以及理解梯度导致原始数据唯一恢复的条件。",
        "动机": "填补关于梯度如何以及何时能够导致原始数据唯一恢复的理论理解空白，并提供一种更高效的方法来恢复数据。",
        "方法": "提出了一种封闭形式的递归程序R-GAP来从梯度恢复数据，并引入了秩分析方法来评估梯度攻击风险。",
        "关键词": [
            "联邦学习",
            "梯度攻击",
            "隐私保护",
            "数据恢复",
            "深度学习安全"
        ],
        "涉及的技术概念": {
            "递归梯度攻击（R-GAP）": "一种封闭形式的递归程序，用于从深度神经网络中的梯度恢复原始数据。",
            "秩分析": "一种评估网络架构中梯度攻击风险的方法，有助于提高网络的安全性。",
            "欧几里得距离最小化": "在梯度攻击中用于有效恢复原始数据的技术，通过最小化真实梯度与估计梯度之间的距离来实现。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 686,
        "title": "Ringing ReLUs: Harmonic Distortion Analysis of Nonlinear Feedforward Networks",
        "html": "https://iclr.cc//virtual/2021/poster/3043",
        "abstract": "In this paper, we apply harmonic distortion analysis to understand the effect of nonlinearities in the spectral domain. Each nonlinear layer creates higher-frequency harmonics, which we call 'blueshift', whose magnitude increases with network depth, thereby increasing the “roughness” of the output landscape. Unlike differential models (such as vanishing gradients, sharpness), this provides a more global view of how network architectures behave across larger areas of their parameter domain. For example, the model predicts that residual connections are able to counter the effect by dampening corresponding higher frequency modes. We empirically verify the connection between blueshift and architectural choices, and provide evidence for a connection with trainability.",
        "conference": "ICLR",
        "中文标题": "振铃ReLUs：非线性前馈网络的谐波失真分析",
        "摘要翻译": "在本文中，我们应用谐波失真分析来理解非线性在频谱域中的影响。每个非线性层都会产生更高频率的谐波，我们称之为‘蓝移’，其幅度随着网络深度的增加而增加，从而增加了输出景观的‘粗糙度’。与微分模型（如梯度消失、锐度）不同，这提供了网络架构在其参数域较大区域内行为的更全局视图。例如，模型预测残差连接能够通过抑制相应的高频模式来抵消这种效应。我们实证验证了蓝移与架构选择之间的联系，并提供了与可训练性相关的证据。",
        "领域": "深度学习理论分析、神经网络架构设计、信号处理与深度学习结合",
        "问题": "分析非线性前馈网络中非线性层在频谱域中的影响，特别是谐波失真和蓝移现象。",
        "动机": "理解非线性层如何影响网络的频谱特性，以及这些影响如何与网络架构选择和可训练性相关联。",
        "方法": "应用谐波失真分析技术，研究非线性层产生的谐波效应，并通过实证验证架构选择对蓝移现象的影响。",
        "关键词": [
            "谐波失真分析",
            "蓝移现象",
            "非线性前馈网络",
            "残差连接",
            "可训练性"
        ],
        "涉及的技术概念": {
            "谐波失真分析": "用于分析非线性层在频谱域中产生的谐波效应，揭示了网络行为的全局特性。",
            "蓝移现象": "指非线性层产生的高频谐波，其幅度随网络深度增加，影响输出景观的粗糙度。",
            "残差连接": "一种网络架构设计，能够通过抑制高频模式来抵消蓝移效应，改善网络性能。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 687,
        "title": "Risk-Averse Offline Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2021/poster/3116",
        "abstract": "Training Reinforcement Learning (RL) agents in high-stakes applications might be too prohibitive due to the risk associated to exploration. Thus, the agent can only use data previously collected by safe policies. While previous work considers optimizing the average performance using offline data, we focus on optimizing a risk-averse criteria, namely the CVaR. In particular, we present the Offline Risk-Averse Actor-Critic (O-RAAC), a model-free RL algorithm that is able to learn risk-averse policies in a fully offline setting. We show that O-RAAC learns policies with higher CVaR than risk-neutral approaches in different robot control tasks. Furthermore, considering risk-averse criteria guarantees distributional robustness of the average performance with respect to particular distribution shifts. We demonstrate empirically that in the presence of natural distribution-shifts, O-RAAC learns policies with good average performance. \n",
        "conference": "ICLR",
        "中文标题": "风险规避的离线强化学习",
        "摘要翻译": "在高风险应用中训练强化学习（RL）代理可能由于探索带来的风险而过于昂贵。因此，代理只能使用之前由安全策略收集的数据。虽然之前的工作考虑使用离线数据优化平均性能，但我们专注于优化一个风险规避标准，即CVaR。特别是，我们提出了离线风险规避演员-评论家（O-RAAC），这是一种无模型的RL算法，能够在完全离线的环境中学习风险规避策略。我们展示了O-RAAC在不同机器人控制任务中学习的策略比风险中性方法具有更高的CVaR。此外，考虑风险规避标准保证了平均性能在特定分布变化下的分布鲁棒性。我们通过实验证明，在存在自然分布变化的情况下，O-RAAC学习的策略具有良好的平均性能。",
        "领域": "强化学习、机器人控制、风险规避策略",
        "问题": "在高风险应用中，如何利用离线数据学习风险规避策略",
        "动机": "探索高风险应用中的强化学习代理可能带来不可接受的风险，因此需要开发能够在完全离线环境中学习风险规避策略的方法",
        "方法": "提出了离线风险规避演员-评论家（O-RAAC）算法，这是一种无模型的强化学习方法，专注于优化条件风险价值（CVaR）",
        "关键词": [
            "离线强化学习",
            "风险规避",
            "CVaR",
            "机器人控制",
            "分布鲁棒性"
        ],
        "涉及的技术概念": {
            "条件风险价值（CVaR）": "用于衡量和优化在不利情况下的预期损失，是论文中风险规避策略的核心指标",
            "无模型强化学习": "不依赖于环境模型的强化学习方法，使得算法更加灵活和广泛适用",
            "分布鲁棒性": "指算法在面对数据分布变化时仍能保持良好性能的能力，论文中通过风险规避标准来保证这一点"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 688,
        "title": "RMSprop converges with proper hyper-parameter",
        "html": "https://iclr.cc//virtual/2021/poster/3374",
        "abstract": "Despite the existence of divergence examples, RMSprop remains \none of the most popular algorithms in machine learning. Towards closing the gap between theory and practice, we prove that RMSprop converges with proper choice of hyper-parameters under certain conditions. More specifically, we prove that when the hyper-parameter $\\beta_2$ is close enough to $1$, RMSprop and its random shuffling version converge to a bounded region in general, and to critical points in the interpolation regime. It is worth mentioning that our results do not depend on  ``bounded gradient'  assumption, which is often the key assumption utilized by existing theoretical work for Adam-type adaptive gradient method. Removing this assumption allows us to establish a phase transition from divergence to non-divergence for RMSprop. \n\nFinally, based on our theory, we conjecture that in practice there is a critical threshold $\\sf{\\beta_2^*}$, such that RMSprop generates reasonably good results only if $1>\\beta_2\\ge \\sf{\\beta_2^*}$. We provide empirical evidence for such a phase transition in our numerical experiments.",
        "conference": "ICLR",
        "中文标题": "RMSprop在适当超参数下收敛",
        "摘要翻译": "尽管存在发散的例子，RMSprop仍然是机器学习中最流行的算法之一。为了缩小理论与实践之间的差距，我们证明了在某些条件下，通过适当选择超参数，RMSprop能够收敛。更具体地说，我们证明了当超参数β₂足够接近1时，RMSprop及其随机打乱版本通常会收敛到一个有界区域，并在插值区域收敛到临界点。值得一提的是，我们的结果不依赖于“有界梯度”假设，这一假设通常是现有理论工作用于Adam型自适应梯度方法的关键假设。移除这一假设使我们能够为RMSprop建立一个从发散到不发散的相变。最后，基于我们的理论，我们推测在实践中存在一个临界阈值β₂*，只有当1>β₂≥β₂*时，RMSprop才能产生相当好的结果。我们在数值实验中为这种相变提供了经验证据。",
        "领域": "优化算法",
        "问题": "RMSprop算法在特定条件下的收敛性问题",
        "动机": "缩小RMSprop算法在理论与实践之间的差距，特别是在不依赖有界梯度假设的情况下证明其收敛性",
        "方法": "通过理论分析和数值实验，证明RMSprop在超参数β₂接近1时的收敛性，并探索临界阈值β₂*的存在",
        "关键词": [
            "RMSprop",
            "超参数优化",
            "收敛性分析"
        ],
        "涉及的技术概念": {
            "RMSprop": "一种自适应学习率的优化算法，用于机器学习中的参数优化",
            "超参数β₂": "RMSprop算法中的一个关键超参数，控制梯度平方的指数衰减率",
            "临界阈值β₂*": "在实践中，RMSprop算法产生良好结果所需的β₂的最小值"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 689,
        "title": "RNNLogic: Learning Logic Rules for Reasoning on Knowledge Graphs",
        "html": "https://iclr.cc//virtual/2021/poster/3084",
        "abstract": "This paper studies learning logic rules for reasoning on knowledge graphs. Logic rules provide interpretable explanations when used for prediction as well as being able to generalize to other tasks, and hence are critical to learn. Existing methods either suffer from the problem of searching in a large search space (e.g., neural logic programming) or ineffective optimization due to sparse rewards (e.g., techniques based on reinforcement learning). To address these limitations, this paper proposes a probabilistic model called RNNLogic. RNNLogic treats logic rules as a latent variable, and simultaneously trains a rule generator as well as a reasoning predictor with logic rules. We develop an EM-based algorithm for optimization. In each iteration, the reasoning predictor is updated to explore some generated logic rules for reasoning. Then in the E-step, we select a set of high-quality rules from all generated rules with both the rule generator and reasoning predictor via posterior inference; and in the M-step, the rule generator is updated with the rules selected in the E-step. Experiments on four datasets prove the effectiveness of RNNLogic.",
        "conference": "ICLR",
        "中文标题": "RNNLogic：学习知识图谱推理的逻辑规则",
        "摘要翻译": "本文研究学习用于知识图谱推理的逻辑规则。逻辑规则在用于预测时能提供可解释的解释，并且能够泛化到其他任务，因此学习它们至关重要。现有方法要么存在在大搜索空间中搜索的问题（例如，神经逻辑编程），要么由于稀疏奖励而优化效果不佳（例如，基于强化学习的技术）。为了解决这些限制，本文提出了一个名为RNNLogic的概率模型。RNNLogic将逻辑规则视为潜在变量，并同时训练一个规则生成器和一个使用逻辑规则的推理预测器。我们开发了一种基于EM的优化算法。在每次迭代中，推理预测器被更新以探索一些生成的逻辑规则进行推理。然后在E步中，我们通过后验推理从所有生成的规则中选择一组高质量的规则，这些规则由规则生成器和推理预测器共同决定；在M步中，规则生成器根据E步中选择的规则进行更新。在四个数据集上的实验证明了RNNLogic的有效性。",
        "领域": "知识图谱推理、逻辑规则学习、概率模型",
        "问题": "解决在大搜索空间中高效学习逻辑规则以及由于稀疏奖励导致的优化效果不佳的问题",
        "动机": "为了提高知识图谱推理的可解释性和泛化能力，同时解决现有方法在搜索空间和优化效率上的限制",
        "方法": "提出RNNLogic概率模型，将逻辑规则视为潜在变量，并同时训练规则生成器和推理预测器，采用基于EM的算法进行优化",
        "关键词": [
            "知识图谱推理",
            "逻辑规则学习",
            "RNNLogic",
            "EM算法",
            "概率模型"
        ],
        "涉及的技术概念": {
            "RNNLogic": "一个概率模型，用于学习知识图谱推理的逻辑规则，将逻辑规则视为潜在变量",
            "EM算法": "用于优化RNNLogic模型的算法，通过E步和M步迭代更新规则生成器和推理预测器",
            "后验推理": "在E步中用于从生成的规则中选择高质量规则的方法，结合了规则生成器和推理预测器的信息"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 690,
        "title": "Robust and Generalizable Visual Representation Learning via Random Convolutions",
        "html": "https://iclr.cc//virtual/2021/poster/2877",
        "abstract": "While successful for various computer vision tasks, deep neural networks have shown to be vulnerable to texture style shifts and small perturbations to which humans are robust. In this work, we show that the robustness of neural networks can be greatly improved through the use of random convolutions as data augmentation. Random convolutions are approximately shape-preserving and may distort local textures. Intuitively, randomized convolutions create an infinite number of new domains with similar global shapes but random local texture. Therefore, we explore using outputs of multi-scale random convolutions as new images or mixing them with the original images during training. When applying a network trained with our approach to unseen domains, our method consistently improves the performance on domain generalization benchmarks and is scalable to ImageNet. In particular, in the challenging scenario of generalizing to the sketch domain in PACS and to ImageNet-Sketch, our method outperforms state-of-art methods by a large margin. More interestingly, our method can benefit downstream tasks by providing a more robust pretrained visual representation.",
        "conference": "ICLR",
        "中文标题": "通过随机卷积实现鲁棒且可泛化的视觉表示学习",
        "摘要翻译": "尽管深度神经网络在各种计算机视觉任务中取得了成功，但它们对于人类能够适应的纹理风格变化和小扰动表现出脆弱性。在这项工作中，我们展示了通过使用随机卷积作为数据增强手段，可以显著提高神经网络的鲁棒性。随机卷积大致保持形状不变，但可能会扭曲局部纹理。直观上，随机卷积创造了无限数量的新领域，这些领域具有相似的全局形状但随机的局部纹理。因此，我们探索在训练过程中使用多尺度随机卷积的输出作为新图像或将其与原始图像混合。当将采用我们方法训练的网络应用于未见过的领域时，我们的方法在领域泛化基准测试中持续提高了性能，并且可扩展到ImageNet。特别是在PACS中泛化到草图领域和ImageNet-Sketch的挑战性场景中，我们的方法以较大优势超越了现有技术。更有趣的是，我们的方法可以通过提供更鲁棒的预训练视觉表示来使下游任务受益。",
        "领域": "图像分类, 领域泛化, 数据增强",
        "问题": "深度神经网络对于纹理风格变化和小扰动的脆弱性问题",
        "动机": "提高神经网络对于纹理风格变化和小扰动的鲁棒性，使其能够更好地泛化到未见过的领域",
        "方法": "使用随机卷积作为数据增强手段，创造具有相似全局形状但随机局部纹理的新图像，以提高模型的鲁棒性和泛化能力",
        "关键词": [
            "随机卷积",
            "领域泛化",
            "数据增强",
            "鲁棒性",
            "视觉表示学习"
        ],
        "涉及的技术概念": {
            "随机卷积": "作为数据增强手段，创造具有相似全局形状但随机局部纹理的新图像，以提高模型的鲁棒性",
            "领域泛化": "指模型在训练时未见过的领域上也能保持良好的性能，是评估模型泛化能力的重要指标",
            "数据增强": "通过变换原始数据生成新的训练样本，以增加数据的多样性，提高模型的泛化能力"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 691,
        "title": "Robust Curriculum Learning: from clean label detection to noisy label self-correction",
        "html": "https://iclr.cc//virtual/2021/poster/3000",
        "abstract": "Neural network training can easily overfit noisy labels resulting in poor generalization performance. Existing methods address this problem by (1) filtering out the noisy data and only using the clean data for training or (2) relabeling the noisy data by the model during training or by another model trained only on a clean dataset. However, the former does not leverage the features' information of wrongly-labeled data, while the latter may produce wrong pseudo-labels for some data and introduce extra noises. In this paper, we propose a smooth transition and interplay between these two strategies as a curriculum that selects training samples dynamically. In particular, we start with learning from clean data and then gradually move to learn noisy-labeled data with pseudo labels produced by a time-ensemble of the model and data augmentations. Instead of using the instantaneous loss computed at the current step, our data selection is based on the dynamics of both the loss and output consistency for each sample across historical steps and different data augmentations, resulting in more precise detection of both clean labels and correct pseudo labels. On multiple benchmarks of noisy labels, we show that our curriculum learning strategy can significantly improve the test accuracy without any auxiliary model or extra clean data.",
        "conference": "ICLR",
        "中文标题": "鲁棒课程学习：从干净标签检测到噪声标签自校正",
        "摘要翻译": "神经网络训练容易过拟合噪声标签，导致泛化性能不佳。现有方法通过（1）过滤掉噪声数据，仅使用干净数据进行训练，或（2）在训练过程中通过模型或另一个仅在干净数据集上训练的模型重新标记噪声数据来解决这个问题。然而，前者没有利用错误标记数据的特征信息，而后者可能为某些数据产生错误的伪标签并引入额外的噪声。在本文中，我们提出了一种在这两种策略之间平滑过渡和相互作用的课程，动态选择训练样本。具体来说，我们从学习干净数据开始，然后逐渐转向学习带有由模型的时间集成和数据增强产生的伪标签的噪声标记数据。我们的数据选择不是基于当前步骤计算的瞬时损失，而是基于每个样本在历史步骤和不同数据增强中的损失和输出一致性的动态，从而更精确地检测干净标签和正确的伪标签。在多个噪声标签基准测试中，我们表明我们的课程学习策略可以显著提高测试准确率，而无需任何辅助模型或额外的干净数据。",
        "领域": "深度学习、噪声标签学习、自监督学习",
        "问题": "解决神经网络在训练过程中对噪声标签过拟合的问题，提高模型的泛化性能。",
        "动机": "现有方法要么不利用噪声数据的特征信息，要么可能引入错误的伪标签，因此需要一种更有效的方法来动态选择训练样本，平衡干净数据和噪声数据的学习。",
        "方法": "提出一种课程学习策略，从干净数据开始学习，逐步过渡到使用模型的时间集成和数据增强产生的伪标签学习噪声数据，基于损失和输出一致性的动态选择样本。",
        "关键词": [
            "噪声标签学习",
            "课程学习",
            "自校正",
            "数据增强",
            "时间集成"
        ],
        "涉及的技术概念": {
            "课程学习": "动态调整学习策略，从简单到复杂逐步学习，以提高模型性能和泛化能力。",
            "伪标签": "通过模型预测生成的标签，用于噪声数据的自校正。",
            "时间集成": "利用模型在不同训练阶段的预测结果集成，提高伪标签的准确性。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 692,
        "title": "Robust early-learning: Hindering the memorization of noisy labels",
        "html": "https://iclr.cc//virtual/2021/poster/3129",
        "abstract": "The \\textit{memorization effects} of deep networks show that they will first memorize training data with clean labels and then those with noisy labels. The \\textit{early stopping} method therefore can be exploited for learning with noisy labels. However, the side effect brought by noisy labels will influence the memorization of clean labels before early stopping. In this paper, motivated by the \\textit{lottery ticket hypothesis} which shows that only partial parameters are important for generalization, we find that only partial parameters are important for fitting clean labels and generalize well, which we term as \\textit{critical parameters}; while the other parameters tend to fit noisy labels and cannot generalize well, which we term as \\textit{non-critical parameters}. Based on this, we propose \\textit{robust early-learning} to reduce the side effect of noisy labels before early stopping and thus enhance the memorization of clean labels. Specifically, in each iteration, we divide all parameters into the critical and non-critical ones, and then perform different update rules for different types of parameters. Extensive experiments on benchmark-simulated and real-world label-noise datasets demonstrate the superiority of the proposed method over the state-of-the-art label-noise learning methods.",
        "conference": "ICLR",
        "中文标题": "鲁棒早期学习：阻碍噪声标签的记忆",
        "摘要翻译": "深度网络的记忆效应表明，它们会首先记忆带有干净标签的训练数据，然后是带有噪声标签的数据。因此，早期停止方法可以被利用于带有噪声标签的学习。然而，噪声标签带来的副作用会在早期停止之前影响干净标签的记忆。在本文中，受到彩票假设的启发，该假设表明只有部分参数对泛化重要，我们发现只有部分参数对拟合干净标签和良好泛化重要，我们称之为关键参数；而其他参数倾向于拟合噪声标签且不能良好泛化，我们称之为非关键参数。基于此，我们提出了鲁棒早期学习，以减少早期停止前噪声标签的副作用，从而增强干净标签的记忆。具体来说，在每次迭代中，我们将所有参数分为关键和非关键两类，然后对不同类型的参数执行不同的更新规则。在基准模拟和真实世界标签噪声数据集上的大量实验证明了所提方法在标签噪声学习领域的最先进方法中的优越性。",
        "领域": "深度学习噪声标签学习、模型泛化、神经网络训练优化",
        "问题": "如何在存在噪声标签的情况下，优化深度学习模型的训练过程，以减少噪声标签对模型性能的负面影响。",
        "动机": "受到深度网络记忆效应和彩票假设的启发，研究旨在通过识别和区分关键与非关键参数，减少噪声标签在训练早期对模型学习干净标签的干扰。",
        "方法": "提出鲁棒早期学习方法，通过在每个训练迭代中区分关键和非关键参数，并应用不同的更新规则，以减少噪声标签的影响并增强干净标签的记忆。",
        "关键词": [
            "噪声标签学习",
            "鲁棒早期学习",
            "关键参数",
            "非关键参数",
            "模型泛化"
        ],
        "涉及的技术概念": {
            "记忆效应": "深度网络在训练过程中首先记忆干净标签数据，随后记忆噪声标签数据的现象。",
            "彩票假设": "表明只有部分网络参数对模型泛化能力至关重要的理论。",
            "关键参数与非关键参数": "关键参数指对拟合干净标签和良好泛化重要的参数；非关键参数指倾向于拟合噪声标签且泛化能力差的参数。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 693,
        "title": "Robust Learning of Fixed-Structure Bayesian Networks in Nearly-Linear Time",
        "html": "https://iclr.cc//virtual/2021/poster/3328",
        "abstract": "We study the problem of learning Bayesian networks where an $\\epsilon$-fraction of the samples are adversarially corrupted.  We focus on the fully-observable case where the underlying graph structure is known.  In this work, we present the first nearly-linear time algorithm for this problem with a dimension-independent error guarantee.  Previous robust algorithms with comparable error guarantees are slower by at least a factor of $(d/\\epsilon)$, where $d$ is the number of variables in the Bayesian network and $\\epsilon$ is the fraction of corrupted samples.\n\nOur algorithm and analysis are considerably simpler than those in previous work.  We achieve this by establishing a direct connection between robust learning of Bayesian networks and robust mean estimation.  As a subroutine in our algorithm, we develop a robust mean estimation algorithm whose runtime is nearly-linear in the number of nonzeros in the input samples, which may be of independent interest.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "近乎线性时间内固定结构贝叶斯网络的鲁棒学习",
        "摘要翻译": "我们研究了贝叶斯网络的学习问题，其中 $\\\\epsilon$ 比例的样本受到对抗性破坏。我们专注于完全可观察的情况，即底层图结构是已知的。在这项工作中，我们提出了第一个具有维度无关误差保证的近乎线性时间算法来解决这个问题。先前具有可比误差保证的鲁棒算法速度较慢，至少慢了 $(d/\\\\epsilon)$ 倍，其中 $d$ 是贝叶斯网络中变量的数量，$\\\\epsilon$ 是损坏样本的比例。\\n\\n我们的算法和分析比之前的工作要简单得多。我们通过在贝叶斯网络的鲁棒学习和鲁棒均值估计之间建立直接联系来实现这一点。作为我们算法中的一个子程序，我们开发了一种鲁棒均值估计算法，其运行时间在输入样本中的非零数中几乎是线性的，这可能具有独立的意义。",
        "领域": "贝叶斯网络学习",
        "问题": "在存在对抗性数据损坏的情况下，如何高效地学习固定结构的贝叶斯网络。",
        "动机": "现有鲁棒贝叶斯网络学习算法在处理大规模数据时效率较低，尤其是在数据受到对抗性损坏的情况下。需要开发更高效的算法来解决这个问题。",
        "方法": "通过建立贝叶斯网络的鲁棒学习和鲁棒均值估计之间的直接联系，并开发一种新的近乎线性时间的鲁棒均值估计算法作为子程序，实现贝叶斯网络的鲁棒学习。",
        "关键词": [
            "贝叶斯网络",
            "鲁棒学习",
            "均值估计",
            "近乎线性时间算法",
            "对抗性数据损坏"
        ],
        "涉及的技术概念": {
            "鲁棒学习": "在存在噪声或异常值的情况下，学习算法仍能保持较高的准确性和泛化能力。本文中，鲁棒学习用于处理被对抗性破坏的样本。",
            "贝叶斯网络": "一种概率图模型，用于表示变量之间的条件依赖关系。本文研究如何从数据中学习贝叶斯网络的参数。"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 694,
        "title": "Robust Overfitting may be mitigated by properly learned smoothening",
        "html": "https://iclr.cc//virtual/2021/poster/3030",
        "abstract": "A recent study (Rice et al.,  2020) revealed overfitting to be a dominant phenomenon in adversarially robust training of deep networks, and that appropriate early-stopping of adversarial training (AT) could match the performance gains of most recent algorithmic improvements. This intriguing problem of robust overfitting motivates us to seek more remedies. As a pilot study, this paper investigates two empirical means to inject more learned smoothening during AT: one leveraging knowledge distillation and self-training to smooth the logits, the other performing stochastic weight averaging (Izmailov et al., 2018) to smooth the weights. Despite the embarrassing simplicity, the two approaches are surprisingly effective and hassle-free in mitigating robust overfitting. Experiments demonstrate that by plugging in them to AT, we can simultaneously boost the standard accuracy by $3.72\\%\\sim6.68\\%$ and robust accuracy by $0.22\\%\\sim2 .03\\%$, across multiple datasets (STL-10, SVHN, CIFAR-10, CIFAR-100, and Tiny ImageNet), perturbation types ($\\ell_{\\infty}$ and $\\ell_2$), and robustified methods (PGD, TRADES, and FSGM), establishing the new state-of-the-art bar in AT. We present systematic visualizations and analyses to dive into their possible working mechanisms. We also carefully exclude the possibility of gradient masking by evaluating our models' robustness against transfer attacks. Codes are available at https://github.com/VITA-Group/Alleviate-Robust-Overfitting.",
        "conference": "ICLR",
        "中文标题": "通过适当学习平滑可能缓解鲁棒过拟合",
        "摘要翻译": "最近的一项研究（Rice等人，2020年）揭示了在深度网络的对抗性鲁棒训练中，过拟合是一个主导现象，并且对抗训练（AT）的适当早期停止可以匹配大多数最新算法改进的性能提升。这一引人入胜的鲁棒过拟合问题激励我们寻求更多的补救措施。作为一项试点研究，本文研究了两种在AT中注入更多学习平滑的经验方法：一种利用知识蒸馏和自我训练来平滑逻辑，另一种执行随机权重平均（Izmailov等人，2018年）来平滑权重。尽管方法简单，这两种方法在缓解鲁棒过拟合方面出奇地有效且无麻烦。实验表明，通过将它们插入AT，我们可以在多个数据集（STL-10、SVHN、CIFAR-10、CIFAR-100和Tiny ImageNet）、扰动类型（ℓ∞和ℓ2）和鲁棒化方法（PGD、TRADES和FSGM）上同时提高标准准确率3.72%∼6.68%和鲁棒准确率0.22%∼2.03%，确立了AT中的最新技术水平。我们提供了系统的可视化和分析，以深入探讨它们可能的工作机制。我们还通过评估我们的模型对转移攻击的鲁棒性，仔细排除了梯度掩蔽的可能性。代码可在https://github.com/VITA-Group/Alleviate-Robust-Overfitting获取。",
        "领域": "对抗性训练、知识蒸馏、随机权重平均",
        "问题": "缓解深度网络在对抗性鲁棒训练中的过拟合问题",
        "动机": "探索更多有效的方法来缓解对抗性训练中的鲁棒过拟合现象",
        "方法": "利用知识蒸馏和自我训练平滑逻辑，以及执行随机权重平均平滑权重",
        "关键词": [
            "对抗性训练",
            "知识蒸馏",
            "随机权重平均",
            "鲁棒过拟合",
            "深度学习"
        ],
        "涉及的技术概念": {
            "对抗性训练（AT）": "一种训练深度网络以提高其对对抗性攻击鲁棒性的方法",
            "知识蒸馏": "通过教师模型指导学生模型训练，用于平滑逻辑",
            "随机权重平均（SWA）": "通过平均多个时间点的模型权重来平滑权重，提高模型泛化能力"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 695,
        "title": "Robust Pruning at Initialization",
        "html": "https://iclr.cc//virtual/2021/poster/2902",
        "abstract": "Overparameterized Neural Networks (NN) display state-of-the-art performance. However, there is a growing need for smaller, energy-efficient, neural networks to be able to use machine learning applications on devices with limited computational resources. A popular approach consists of using pruning techniques. While these techniques have traditionally focused on pruning pre-trained NN (LeCun et al.,1990; Hassibi et al., 1993), recent work by Lee et al. (2018) has shown promising results when pruning at initialization. However, for Deep NNs, such procedures remain unsatisfactory as the resulting pruned networks can be difficult to train and, for instance, they do not prevent one layer from being fully pruned. In this paper, we provide a comprehensive theoretical analysis of Magnitude and Gradient based pruning at initialization and training of sparse architectures.  This allows us to propose novel principled approaches which we validate experimentally on a variety of NN architectures.",
        "conference": "ICLR",
        "中文标题": "初始化时的鲁棒剪枝",
        "摘要翻译": "过参数化的神经网络（NN）展现了最先进的性能。然而，对于计算资源有限的设备，越来越需要更小、更节能的神经网络来使用机器学习应用。一种流行的方法是使用剪枝技术。虽然这些技术传统上专注于剪枝预训练的神经网络（LeCun等人，1990；Hassibi等人，1993），但Lee等人（2018）的最新工作显示了在初始化时剪枝的有希望的结果。然而，对于深度神经网络，这样的过程仍然不尽如人意，因为得到的剪枝网络可能难以训练，例如，它们不能防止某一层被完全剪枝。在本文中，我们提供了基于幅度和梯度的初始化剪枝和稀疏架构训练的全面理论分析。这使我们能够提出新的原则性方法，我们在各种神经网络架构上进行了实验验证。",
        "领域": "神经网络剪枝",
        "问题": "如何在神经网络初始化阶段进行有效的剪枝，以避免训练困难和层被完全剪枝的问题。",
        "动机": "为了在计算资源有限的设备上部署更小、更节能的神经网络，需要开发在初始化阶段就能有效剪枝的方法。",
        "方法": "提出了基于幅度和梯度的剪枝方法，并在初始化阶段和训练过程中对稀疏架构进行了全面的理论分析和实验验证。",
        "关键词": [
            "神经网络剪枝",
            "初始化剪枝",
            "稀疏架构"
        ],
        "涉及的技术概念": {
            "幅度剪枝": "基于权重幅度的大小来决定剪枝哪些连接，以减少网络的复杂度。",
            "梯度剪枝": "利用梯度信息来指导剪枝过程，以保留对网络性能最重要的连接。",
            "稀疏架构": "通过剪枝技术得到的网络架构，其中大部分连接被移除，以减少计算资源的使用。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 696,
        "title": "Robust Reinforcement Learning on State Observations with Learned Optimal Adversary",
        "html": "https://iclr.cc//virtual/2021/poster/2624",
        "abstract": "We study the robustness of reinforcement learning (RL) with adversarially perturbed state observations, which aligns with the setting of many adversarial attacks to deep reinforcement learning (DRL) and is also important for rolling out real-world RL agent under unpredictable sensing noise. With a fixed agent policy, we demonstrate that an optimal adversary to perturb state observations can be found, which is guaranteed to obtain the worst case agent reward. For DRL settings, this leads to a novel empirical adversarial attack to RL agents via a learned adversary that is much stronger than previous ones. To enhance the robustness of an agent, we propose a framework of alternating training with learned adversaries (ATLA), which trains an adversary online together with the agent using policy gradient following the optimal adversarial attack framework. Additionally, inspired by the analysis of state-adversarial Markov decision process (SA-MDP), we show that past states and actions (history) can be useful for learning a robust agent, and we empirically find a LSTM based policy can be more robust under adversaries. Empirical evaluations on a few continuous control environments show that ATLA achieves state-of-the-art performance under strong adversaries. Our code is available at https://github.com/huanzhang12/ATLA_robust_RL.",
        "conference": "ICLR",
        "中文标题": "基于状态观测的鲁棒强化学习与学习最优对抗者",
        "摘要翻译": "我们研究了在对抗性扰动状态观测下的强化学习（RL）的鲁棒性，这与许多对深度强化学习（DRL）的对抗攻击设置一致，并且对于在不可预测的感知噪声下推出真实世界的RL代理也非常重要。对于一个固定的代理策略，我们证明了可以找到一个扰动状态观测的最优对抗者，这保证了获得最坏情况下的代理奖励。对于DRL设置，这导致了一种新颖的通过学习的对抗者对RL代理进行实证对抗攻击，比之前的攻击要强大得多。为了增强代理的鲁棒性，我们提出了一个与学习对抗者交替训练（ATLA）的框架，该框架使用策略梯度按照最优对抗攻击框架在线训练对抗者与代理。此外，受到状态对抗马尔可夫决策过程（SA-MDP）分析的启发，我们展示了过去的状态和动作（历史）可以用于学习一个鲁棒的代理，并且我们实证发现基于LSTM的策略在对抗者下可以更加鲁棒。在几个连续控制环境上的实证评估表明，ATLA在强对抗者下实现了最先进的性能。我们的代码可在https://github.com/huanzhang12/ATLA_robust_RL获取。",
        "领域": "深度强化学习",
        "问题": "在对抗性扰动状态观测下增强强化学习的鲁棒性",
        "动机": "研究在对抗性攻击和不可预测的感知噪声下，如何提高强化学习代理的鲁棒性",
        "方法": "提出交替训练框架ATLA，结合学习的最优对抗者和策略梯度方法，以及利用历史信息增强代理的鲁棒性",
        "关键词": [
            "鲁棒强化学习",
            "对抗性攻击",
            "ATLA框架",
            "LSTM策略",
            "状态对抗MDP"
        ],
        "涉及的技术概念": {
            "最优对抗者": "在固定代理策略下，能够扰动状态观测以获得最坏情况代理奖励的对抗者",
            "ATLA框架": "交替训练代理和对抗者的框架，通过在线学习提高代理的鲁棒性",
            "状态对抗MDP": "分析状态对抗下的马尔可夫决策过程，用于理解历史信息在提高代理鲁棒性中的作用"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 697,
        "title": "RODE: Learning Roles to Decompose Multi-Agent Tasks",
        "html": "https://iclr.cc//virtual/2021/poster/2717",
        "abstract": "Role-based learning holds the promise of achieving scalable multi-agent learning by decomposing complex tasks using roles. However, it is largely unclear how to efficiently discover such a set of roles. To solve this problem, we propose to first decompose joint action spaces into restricted role action spaces by clustering actions according to their effects on the environment and other agents. Learning a role selector based on action effects makes role discovery much easier because it forms a bi-level learning hierarchy: the role selector searches in a smaller role space and at a lower temporal resolution, while role policies learn in significantly reduced primitive action-observation spaces. We further integrate information about action effects into the role policies to boost learning efficiency and policy generalization. By virtue of these advances, our method (1) outperforms the current state-of-the-art MARL algorithms on 9 of the 14 scenarios that comprise the challenging StarCraft II micromanagement benchmark and (2) achieves rapid transfer to new environments with three times the number of agents. Demonstrative videos can be viewed at https://sites.google.com/view/rode-marl.",
        "conference": "ICLR",
        "中文标题": "RODE：通过学习角色分解多智能体任务",
        "摘要翻译": "基于角色的学习通过使用角色分解复杂任务，有望实现可扩展的多智能体学习。然而，如何高效地发现这样一组角色在很大程度上尚不明确。为了解决这个问题，我们提出首先根据动作对环境和其它智能体的影响，将联合动作空间分解为受限的角色动作空间。基于动作效果学习角色选择器使得角色发现变得容易得多，因为它形成了一个双层学习层次：角色选择器在较小的角色空间和较低的时间分辨率下搜索，而角色策略则在显著减少的原始动作-观察空间中学习。我们进一步将关于动作效果的信息整合到角色策略中，以提高学习效率和策略泛化能力。凭借这些进步，我们的方法（1）在构成具有挑战性的《星际争霸II》微操作基准的14个场景中的9个上，表现优于当前最先进的多智能体强化学习算法；（2）实现了对新环境的快速迁移，智能体数量增加了三倍。演示视频可在https://sites.google.com/view/rode-marl查看。",
        "领域": "多智能体系统、强化学习、角色发现",
        "问题": "如何高效地发现一组角色以分解复杂多智能体任务",
        "动机": "提高多智能体学习的可扩展性和效率，通过角色分解复杂任务",
        "方法": "通过动作效果聚类分解联合动作空间，构建双层学习层次（角色选择器和角色策略），并整合动作效果信息以提高学习效率和策略泛化",
        "关键词": [
            "多智能体学习",
            "角色发现",
            "动作效果聚类",
            "双层学习层次",
            "策略泛化"
        ],
        "涉及的技术概念": {
            "角色选择器": "基于动作效果在较小的角色空间和较低的时间分辨率下搜索，简化角色发现过程",
            "角色策略": "在显著减少的原始动作-观察空间中学习，提高学习效率",
            "动作效果聚类": "根据动作对环境和其它智能体的影响，将联合动作空间分解为受限的角色动作空间"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 698,
        "title": "SAFENet: A Secure, Accurate and Fast Neural Network Inference",
        "html": "https://iclr.cc//virtual/2021/poster/3278",
        "abstract": "The advances in neural networks have driven many companies to provide prediction services to users in a wide range of applications. However, current prediction systems raise privacy concerns regarding the user's private data. A cryptographic neural network inference service is an efficient way to allow two parties to execute neural network inference without revealing either party’s data or model. Nevertheless, existing cryptographic neural network inference services suffer from huge running latency; in particular, the latency of communication-expensive cryptographic activation function is 3 orders of magnitude higher than plaintext-domain activation function. And activations are the necessary components of the modern neural networks. Therefore, slow cryptographic activation has become the primary obstacle of efficient cryptographic inference. \n\nIn this paper, we propose a new technique, called SAFENet, to enable a Secure, Accurate and Fast nEural Network inference service. To speedup secure inference and guarantee inference accuracy, SAFENet includes channel-wise activation approximation with multiple-degree options. This is implemented by keeping the most useful activation channels and replacing the remaining, less useful, channels with various-degree polynomials. SAFENet also supports mixed-precision activation approximation by automatically assigning different replacement ratios to various layer; further increasing the approximation ratio and reducing inference latency. Our experimental results show SAFENet obtains the state-of-the-art inference latency and performance, reducing latency by $38\\% \\sim 61\\%$ or improving accuracy by $1.8\\% \\sim 4\\%$ over prior techniques on various encrypted datasets.",
        "conference": "ICLR",
        "中文标题": "SAFENet：一种安全、准确且快速的神经网络推理服务",
        "摘要翻译": "神经网络的进步推动了许多公司在广泛的应用中为用户提供预测服务。然而，当前的预测系统引发了关于用户隐私数据的隐私问题。加密神经网络推理服务是一种高效的方式，允许两方执行神经网络推理而不泄露任何一方的数据或模型。尽管如此，现有的加密神经网络推理服务存在巨大的运行延迟；特别是，通信成本高昂的加密激活函数的延迟比明文域激活函数高出3个数量级。而激活是现代神经网络的必要组成部分。因此，缓慢的加密激活已成为高效加密推理的主要障碍。在本文中，我们提出了一种名为SAFENet的新技术，以实现安全、准确且快速的神经网络推理服务。为了加速安全推理并保证推理准确性，SAFENet包括具有多度选项的通道级激活近似。这是通过保留最有用的激活通道并用各种度数的多项式替换剩余的、不太有用的通道来实现的。SAFENet还支持混合精度激活近似，通过自动为不同层分配不同的替换比率；进一步提高近似比率并减少推理延迟。我们的实验结果表明，SAFENet在各种加密数据集上获得了最先进的推理延迟和性能，与现有技术相比，延迟减少了38%至61%，或准确率提高了1.8%至4%。",
        "领域": "加密神经网络推理、隐私保护机器学习、高效计算",
        "问题": "解决加密神经网络推理服务中的高延迟问题，特别是在加密激活函数方面。",
        "动机": "当前加密神经网络推理服务的高延迟限制了其在实际应用中的广泛使用，特别是在需要快速响应的场景中。",
        "方法": "提出SAFENet技术，通过通道级激活近似和混合精度激活近似来加速加密神经网络推理，同时保持高准确率。",
        "关键词": [
            "加密神经网络推理",
            "隐私保护",
            "激活近似",
            "混合精度",
            "高效计算"
        ],
        "涉及的技术概念": {
            "通道级激活近似": "通过保留最有用的激活通道并用多项式替换其他通道来加速加密激活函数的计算。",
            "混合精度激活近似": "自动为神经网络的不同层分配不同的激活近似精度，以进一步提高计算效率和准确率。",
            "加密神经网络推理": "一种允许在不泄露数据或模型的情况下执行神经网络推理的技术，保护用户隐私和模型安全。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 699,
        "title": "SALD: Sign Agnostic Learning with Derivatives",
        "html": "https://iclr.cc//virtual/2021/poster/3221",
        "abstract": "Learning 3D geometry directly from raw data, such as point clouds, triangle soups, or unoriented meshes is still a challenging task that feeds many downstream computer vision and graphics applications. \n\nIn this paper, we introduce SALD: a method for learning implicit neural representations of shapes directly from raw data. We generalize sign agnostic learning (SAL) to include derivatives: given an unsigned distance function to the input raw data, we advocate a novel sign agnostic regression loss, incorporating both pointwise values and gradients of the unsigned distance function. Optimizing this loss leads to a signed implicit function solution, the zero level set of which is a high quality and valid manifold approximation to the input 3D data. The motivation behind SALD is that incorporating derivatives in a regression loss leads to a lower sample complexity, and consequently better fitting. In addition, we provide empirical evidence, as well as theoretical motivation in 2D that SAL enjoys a minimal surface property, favoring minimal area solutions. More importantly, we are able to show that this property still holds for SALD, i.e.,  with derivatives included.\n\nWe demonstrate the efficacy of SALD for shape space learning on two challenging datasets: ShapeNet that contains inconsistent orientation and non-manifold meshes, and D-Faust that contains raw 3D scans (triangle soups). On both these datasets, we present state-of-the-art results.",
        "conference": "ICLR",
        "中文标题": "SALD：包含导数的符号无关学习",
        "摘要翻译": "直接从原始数据（如点云、三角形汤或无定向网格）学习3D几何仍然是一项具有挑战性的任务，这项任务为许多下游计算机视觉和图形应用提供支持。在本文中，我们介绍了SALD：一种直接从原始数据学习形状的隐式神经表示的方法。我们将符号无关学习（SAL）推广到包含导数：给定输入原始数据的无符号距离函数，我们提出了一种新的符号无关回归损失，该损失结合了无符号距离函数的点值和梯度。优化这一损失导致了一个有符号的隐式函数解，其零水平集是对输入3D数据的高质量和有效流形近似。SALD背后的动机是，在回归损失中纳入导数会导致较低的样本复杂性，从而获得更好的拟合。此外，我们提供了经验证据，以及在2D中的理论动机，表明SAL享有最小表面属性，倾向于最小面积解。更重要的是，我们能够证明这一属性对于SALD仍然成立，即包含导数时也是如此。我们在两个具有挑战性的数据集上展示了SALD在形状空间学习中的有效性：包含不一致方向和非流形网格的ShapeNet，以及包含原始3D扫描（三角形汤）的D-Faust。在这两个数据集上，我们都展示了最先进的结果。",
        "领域": "3D形状重建, 隐式神经表示, 计算机图形学",
        "问题": "直接从原始3D数据（如点云、三角形汤或无定向网格）学习高质量的3D几何表示",
        "动机": "通过引入导数信息降低样本复杂性，提高从原始3D数据学习隐式神经表示的准确性和效率",
        "方法": "提出了一种新的符号无关回归损失，该损失结合了无符号距离函数的点值和梯度，优化这一损失以获得高质量的3D形状表示",
        "关键词": [
            "符号无关学习",
            "隐式神经表示",
            "3D形状重建",
            "导数回归损失",
            "最小表面属性"
        ],
        "涉及的技术概念": {
            "符号无关学习（SAL）": "一种直接从无符号距离函数学习形状表示的方法，无需预先知道符号信息",
            "隐式神经表示": "使用神经网络隐式地表示3D形状，能够处理不完整或噪声数据",
            "导数回归损失": "在回归损失中引入导数信息，以提高学习效率和准确性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 700,
        "title": "Saliency is a Possible Red Herring When Diagnosing Poor Generalization",
        "html": "https://iclr.cc//virtual/2021/poster/3280",
        "abstract": "Poor generalization is one symptom of models that learn to predict target variables using spuriously-correlated image features present only in the training distribution instead of the true image features that denote a class. It is often thought that this can be diagnosed visually using attribution (aka saliency) maps. We study if this assumption is correct. In some prediction tasks, such as for medical images, one may have some images with masks drawn by a human expert, indicating a region of the image containing relevant information to make the prediction. We study multiple methods that take advantage of such auxiliary labels, by training networks to ignore distracting features which may be found outside of the region of interest. This mask information is only used during training and has an impact on generalization accuracy depending on the severity of the shift between the training and test distributions. Surprisingly, while these methods improve generalization performance in the presence of a covariate shift, there is no strong correspondence between the correction of attribution towards the features a human expert have labelled as important and generalization performance. These results suggest that the root cause of poor generalization may not always be spatially defined, and raise questions about the utility of masks as 'attribution priors' as well as saliency maps for explainable predictions.",
        "conference": "ICLR",
        "中文标题": "显著性可能是诊断泛化能力差时的误导因素",
        "摘要翻译": "泛化能力差是模型仅利用训练分布中存在的虚假相关图像特征而非表示类别的真实图像特征来预测目标变量的一个症状。人们通常认为这可以通过归因（即显著性）图进行视觉诊断。我们研究这一假设是否正确。在某些预测任务中，如医学图像，可能会有一些由人类专家绘制的掩码图像，指示包含做出预测相关信息图像区域。我们研究了多种利用此类辅助标签的方法，通过训练网络忽略可能在感兴趣区域外找到的干扰特征。这种掩码信息仅在训练期间使用，并根据训练和测试分布之间变化的严重程度对泛化准确性产生影响。令人惊讶的是，尽管这些方法在存在协变量变化时提高了泛化性能，但归因校正与人类专家标记为重要特征之间的泛化性能并无强烈对应关系。这些结果表明，泛化能力差的根本原因可能并不总是空间定义的，并对掩码作为'归因先验'以及显著性图对于可解释预测的效用提出了疑问。",
        "领域": "医学图像分析",
        "问题": "研究模型泛化能力差是否可以通过显著性图准确诊断",
        "动机": "探讨显著性图在诊断模型泛化问题中的有效性，特别是在医学图像分析中利用专家标注的掩码信息",
        "方法": "利用专家标注的掩码信息训练网络忽略干扰特征，研究其对模型泛化性能的影响",
        "关键词": [
            "泛化能力",
            "显著性图",
            "医学图像分析",
            "掩码信息",
            "协变量变化"
        ],
        "涉及的技术概念": {
            "归因图": "用于视觉诊断模型预测依据的技术，本研究探讨其在诊断泛化问题中的有效性",
            "掩码信息": "由人类专家标注的图像区域，指示与预测任务相关的信息，用于训练模型忽略干扰特征",
            "协变量变化": "训练和测试数据分布之间的变化，影响模型的泛化性能"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 701,
        "title": "SaliencyMix: A Saliency Guided Data Augmentation Strategy for Better Regularization",
        "html": "https://iclr.cc//virtual/2021/poster/2986",
        "abstract": "Advanced data augmentation strategies have widely been studied to improve the generalization ability of deep learning models. Regional dropout is one of the popular solutions that guides the model to focus on less discriminative parts by randomly removing image regions, resulting in improved regularization. However, such information removal is undesirable. On the other hand, recent strategies suggest to randomly cut and mix patches and their labels among training images, to enjoy the advantages of regional dropout without having any pointless pixel in the augmented images. We argue that such random selection strategies of the patches may not necessarily represent sufficient information about the corresponding object and thereby mixing the labels according to that uninformative patch enables the model to learn unexpected feature representation. Therefore, we propose SaliencyMix that carefully selects a representative image patch with the help of a saliency map and mixes this indicative patch with the target image, thus leading the model to learn more appropriate feature representation. SaliencyMix achieves the best known top-1 error of $21.26\\%$ and $20.09\\%$ for ResNet-50 and ResNet-101 architectures on ImageNet classification, respectively, and also improves the model robustness against adversarial perturbations. Furthermore, models that are trained with SaliencyMix, help to improve the object detection performance.  Source code is available at \\url{https://github.com/SaliencyMix/SaliencyMix}.",
        "conference": "ICLR",
        "中文标题": "SaliencyMix：一种基于显著性的数据增强策略以实现更好的正则化",
        "摘要翻译": "为了提高深度学习模型的泛化能力，先进的数据增强策略已被广泛研究。区域丢弃是一种流行的解决方案，它通过随机移除图像区域来引导模型关注较少区分性的部分，从而改善正则化。然而，这种信息移除是不理想的。另一方面，最近的策略建议在训练图像中随机剪切和混合图像块及其标签，以享受区域丢弃的优势，同时不产生任何无意义的像素。我们认为，这种随机选择图像块的策略可能不一定充分代表相应对象的足够信息，因此根据这种无信息性的图像块混合标签会使模型学习到意外的特征表示。因此，我们提出了SaliencyMix，它借助显著性图精心选择一个有代表性的图像块，并将这个指示性的图像块与目标图像混合，从而引导模型学习更合适的特征表示。SaliencyMix在ImageNet分类上为ResNet-50和ResNet-101架构分别实现了21.26%和20.09%的最佳已知top-1错误率，并且还提高了模型对抗对抗性扰动的鲁棒性。此外，使用SaliencyMix训练的模型有助于提高目标检测性能。源代码可在https://github.com/SaliencyMix/SaliencyMix获取。",
        "领域": "图像分类, 目标检测, 对抗性防御",
        "问题": "如何在不移除有用信息的情况下，通过数据增强策略提高深度学习模型的泛化能力和鲁棒性",
        "动机": "现有的区域丢弃和随机混合策略可能导致模型学习到不准确的特征表示，因此需要一种更有效的数据增强方法来引导模型学习更合适的特征",
        "方法": "提出SaliencyMix策略，利用显著性图选择有代表性的图像块进行混合，以提高模型的特征学习能力和鲁棒性",
        "关键词": [
            "数据增强",
            "显著性图",
            "正则化",
            "对抗性鲁棒性",
            "目标检测"
        ],
        "涉及的技术概念": {
            "显著性图": "用于识别图像中最具信息量的区域，指导数据增强过程中选择有代表性的图像块",
            "区域丢弃": "一种数据增强技术，通过随机移除图像区域来强制模型关注其他部分，以提高泛化能力",
            "对抗性扰动": "对输入数据的小幅修改，可能导致模型错误分类，SaliencyMix提高了模型对此类扰动的鲁棒性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 702,
        "title": "Sample-Efficient Automated Deep Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2021/poster/3206",
        "abstract": "Despite significant progress in challenging problems across various domains, applying state-of-the-art deep reinforcement learning (RL) algorithms remains challenging due to their sensitivity to the choice of hyperparameters. This sensitivity can partly be attributed to the non-stationarity of the RL problem, potentially requiring different hyperparameter settings at various stages of the learning process. Additionally, in the RL setting, hyperparameter optimization (HPO) requires a large number of environment interactions, hindering the transfer of the successes in RL to real-world applications. In this work, we tackle the issues of sample-efficient and dynamic HPO in RL. We propose a population-based automated RL (AutoRL) framework to meta-optimize arbitrary off-policy RL algorithms. In this framework, we optimize the hyperparameters and also the neural architecture while simultaneously training the agent. By sharing the collected experience across the population, we substantially increase the sample efficiency of the meta-optimization. We demonstrate the capabilities of our sample-efficient AutoRL approach in a case study with the popular TD3 algorithm in the MuJoCo benchmark suite, where we reduce the number of environment interactions needed for meta-optimization by up to an order of magnitude compared to population-based training.",
        "conference": "ICLR",
        "中文标题": "样本高效的自动化深度强化学习",
        "摘要翻译": "尽管在各个领域的挑战性问题中取得了显著进展，但由于对超参数选择的敏感性，应用最先进的深度强化学习（RL）算法仍然具有挑战性。这种敏感性部分归因于RL问题的非平稳性，可能需要在学习过程的不同阶段采用不同的超参数设置。此外，在RL设置中，超参数优化（HPO）需要大量的环境交互，这阻碍了RL成功向现实世界应用的转移。在这项工作中，我们解决了RL中样本高效和动态HPO的问题。我们提出了一个基于群体的自动化RL（AutoRL）框架，用于元优化任意的离策略RL算法。在这个框架中，我们不仅优化了超参数，还优化了神经架构，同时训练智能体。通过在群体中共享收集到的经验，我们显著提高了元优化的样本效率。我们在MuJoCo基准套件中使用流行的TD3算法进行了案例研究，展示了我们样本高效AutoRL方法的能力，其中我们将元优化所需的环境交互次数比基于群体的训练减少了一个数量级。",
        "领域": "深度强化学习、自动化机器学习、超参数优化",
        "问题": "解决深度强化学习算法对超参数选择的敏感性和样本效率低下的问题",
        "动机": "减少深度强化学习算法在超参数优化过程中对环境交互的需求，提高算法的样本效率和实用性",
        "方法": "提出一个基于群体的自动化RL框架，通过共享经验和同时优化超参数及神经架构来提高样本效率",
        "关键词": [
            "自动化强化学习",
            "超参数优化",
            "样本效率",
            "神经架构搜索",
            "元优化"
        ],
        "涉及的技术概念": {
            "自动化强化学习（AutoRL）": "一个框架，用于自动化地优化强化学习算法的超参数和神经架构",
            "超参数优化（HPO）": "在强化学习中调整算法参数以提高性能的过程",
            "元优化": "在更高层次上优化学习过程本身，包括超参数和架构的优化"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 703,
        "title": "Scalable Bayesian Inverse Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2021/poster/3152",
        "abstract": "Bayesian inference over the reward presents an ideal solution to the ill-posed nature of the inverse reinforcement learning problem. Unfortunately current methods generally do not scale well beyond the small tabular setting due to the need for an inner-loop MDP solver, and even non-Bayesian methods that do themselves scale often require extensive interaction with the environment to perform well, being inappropriate for high stakes or costly applications such as healthcare. In this paper we introduce our method, Approximate Variational Reward Imitation Learning (AVRIL), that addresses both of these issues by jointly learning an approximate posterior distribution over the reward that scales to arbitrarily complicated state spaces alongside an appropriate policy in a completely offline manner through a variational approach to said latent reward. Applying our method to real medical data alongside classic control simulations, we demonstrate Bayesian reward inference in environments beyond the scope of current methods, as well as task performance competitive with focused offline imitation learning algorithms.",
        "conference": "ICLR",
        "中文标题": "可扩展的贝叶斯逆向强化学习",
        "摘要翻译": "在逆向强化学习问题的不适定性面前，对奖励进行贝叶斯推断提供了一个理想的解决方案。不幸的是，由于需要一个内循环的MDP求解器，当前的方法通常无法很好地扩展到小型表格设置之外，甚至那些本身可扩展的非贝叶斯方法也需要与环境进行大量交互才能表现良好，这不适合高风险或成本高昂的应用，如医疗保健。在本文中，我们介绍了我们的方法——近似变分奖励模仿学习（AVRIL），通过联合学习一个可扩展到任意复杂状态空间的奖励的近似后验分布，以及通过变分方法对潜在奖励进行完全离线的适当策略，解决了这两个问题。将我们的方法应用于真实医疗数据和经典控制模拟，我们在超出当前方法范围的环境中展示了贝叶斯奖励推断，以及与专注的离线模仿学习算法竞争的任务性能。",
        "领域": "逆向强化学习、医疗保健应用、离线学习",
        "问题": "解决逆向强化学习在复杂状态空间中的可扩展性问题，以及在不需要大量环境交互的情况下进行高效学习。",
        "动机": "为了在如医疗保健等高成本或高风险的应用中实现有效的逆向强化学习，需要一种既能够扩展到复杂状态空间又不需要大量环境交互的方法。",
        "方法": "提出了近似变分奖励模仿学习（AVRIL）方法，通过变分方法联合学习奖励的近似后验分布和策略，实现完全离线学习。",
        "关键词": [
            "贝叶斯推断",
            "逆向强化学习",
            "变分方法",
            "离线学习",
            "医疗保健应用"
        ],
        "涉及的技术概念": {
            "贝叶斯推断": "用于处理逆向强化学习问题中的不适定性，通过概率分布表达不确定性。",
            "变分方法": "用于近似复杂后验分布，使得模型能够扩展到任意复杂的状态空间。",
            "离线学习": "指在不与环境进行交互的情况下学习策略，适用于高风险或成本高昂的应用场景。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 704,
        "title": "Scalable Learning and MAP Inference for Nonsymmetric Determinantal Point Processes",
        "html": "https://iclr.cc//virtual/2021/poster/2661",
        "abstract": "Determinantal point processes (DPPs) have attracted significant attention in machine learning for their ability to model subsets drawn from a large item collection. Recent work shows that nonsymmetric DPP (NDPP) kernels have significant advantages over symmetric kernels in terms of modeling power and predictive performance. However, for an item collection of size $M$, existing NDPP learning and inference algorithms require memory quadratic in $M$ and runtime cubic (for learning) or quadratic (for inference) in $M$, making them impractical for many typical subset selection tasks. In this work, we develop a learning algorithm with space and time requirements linear in $M$ by introducing a new NDPP kernel decomposition. We also derive a linear-complexity NDPP maximum a posteriori (MAP) inference algorithm that applies not only to our new kernel but also to that of prior work. Through evaluation on real-world datasets, we show that our algorithms scale significantly better, and can match the predictive performance of prior work.",
        "conference": "ICLR",
        "中文标题": "可扩展的非对称行列式点过程的学习与最大后验推断",
        "摘要翻译": "行列式点过程（DPPs）因其能够模拟从大型项目集合中抽取子集的能力，在机器学习领域引起了广泛关注。最近的研究表明，非对称DPP（NDPP）核在建模能力和预测性能方面比对称核具有显著优势。然而，对于一个大小为$M$的项目集合，现有的NDPP学习和推断算法需要内存与$M$的平方成正比，运行时与$M$的立方（学习）或平方（推断）成正比，这使得它们对于许多典型的子集选择任务来说不切实际。在这项工作中，我们通过引入一种新的NDPP核分解，开发了一种空间和时间需求与$M$成线性关系的学习算法。我们还推导了一种线性复杂度的NDPP最大后验（MAP）推断算法，该算法不仅适用于我们的新核，也适用于先前工作的核。通过对真实世界数据集的评估，我们展示了我们的算法在可扩展性上显著优于现有方法，并且能够匹配先前工作的预测性能。",
        "领域": "机器学习",
        "问题": "解决非对称行列式点过程（NDPP）在大型项目集合上的学习和推断算法内存和运行时复杂度高的问题",
        "动机": "现有的NDPP学习和推断算法在处理大型项目集合时，由于内存和运行时的高复杂度，难以实际应用",
        "方法": "引入新的NDPP核分解方法，开发空间和时间需求与项目集合大小成线性关系的学习和推断算法",
        "关键词": [
            "行列式点过程",
            "非对称核",
            "最大后验推断",
            "线性复杂度",
            "子集选择"
        ],
        "涉及的技术概念": {
            "行列式点过程": "一种用于模拟从大型项目集合中抽取子集的概率模型",
            "非对称核": "在行列式点过程中，非对称核比对称核具有更强的建模能力和预测性能",
            "最大后验推断": "一种在给定观测数据下，估计模型参数的方法，本文中用于NDPP的推断"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 705,
        "title": "Scalable Transfer Learning with Expert Models",
        "html": "https://iclr.cc//virtual/2021/poster/2545",
        "abstract": "Transfer of pre-trained representations can improve sample efficiency and reduce computational requirements for new tasks. However, representations used for transfer are usually generic, and are not tailored to a particular distribution of downstream tasks. We explore the use of expert representations for transfer with a simple, yet effective, strategy. We train a diverse set of experts by exploiting existing label structures, and use cheap-to-compute performance proxies to select the relevant expert for each target task. This strategy scales the process of transferring to new tasks, since it does not revisit the pre-training data during transfer. Accordingly, it requires little extra compute per target task, and results in a speed-up of 2-3 orders of magnitude compared to competing approaches. Further, we provide an adapter-based architecture able to compress many experts into a single model. We evaluate our approach on two different data sources and demonstrate that it outperforms baselines on over 20 diverse vision tasks in both cases.",
        "conference": "ICLR",
        "中文标题": "可扩展的专家模型迁移学习",
        "摘要翻译": "预训练表示的迁移可以提高新任务的样本效率并减少计算需求。然而，用于迁移的表示通常是通用的，并未针对特定的下游任务分布进行定制。我们探索了一种简单而有效的策略，即使用专家表示进行迁移。我们通过利用现有的标签结构训练了一组多样化的专家，并使用计算成本低的性能代理为每个目标任务选择相关的专家。这一策略扩展了迁移到新任务的过程，因为它不需要在迁移过程中重新访问预训练数据。因此，每个目标任务只需要很少的额外计算，并且与竞争方法相比，速度提高了2-3个数量级。此外，我们提供了一种基于适配器的架构，能够将多个专家压缩到一个模型中。我们在两种不同的数据源上评估了我们的方法，并证明在这两种情况下，它在超过20个不同的视觉任务上都优于基线。",
        "领域": "迁移学习、计算机视觉、模型压缩",
        "问题": "如何有效地将预训练模型的知识迁移到多样化的下游任务中，同时减少计算成本和保持高性能。",
        "动机": "现有的迁移学习方法通常使用通用的预训练表示，这些表示未针对特定任务分布进行优化，导致在新任务上的样本效率和计算效率不高。",
        "方法": "通过训练一组多样化的专家模型，并利用计算成本低的性能代理选择最适合目标任务的专家，实现高效的知识迁移。此外，采用基于适配器的架构将多个专家模型压缩到单一模型中。",
        "关键词": [
            "迁移学习",
            "专家模型",
            "模型压缩",
            "性能代理",
            "适配器架构"
        ],
        "涉及的技术概念": {
            "专家表示": "通过训练多样化的专家模型来捕获不同任务的特征表示，以提高迁移的针对性和效率。",
            "性能代理": "用于快速评估和选择最适合目标任务的专家模型的计算成本低的指标或方法。",
            "适配器架构": "一种能够将多个专家模型的知识压缩到单一模型中的技术，以减少模型存储和计算资源的需求。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 706,
        "title": "Scaling Symbolic Methods using Gradients for Neural Model Explanation",
        "html": "https://iclr.cc//virtual/2021/poster/2581",
        "abstract": "Symbolic techniques based on Satisfiability Modulo Theory (SMT) solvers have been proposed for analyzing and verifying neural network properties, but their usage has been fairly limited owing to their poor scalability with larger networks. In this work, we propose a technique for combining gradient-based methods with symbolic techniques to scale such analyses and demonstrate its application for model explanation. In particular, we apply this technique to identify minimal regions in an input that are most relevant for a neural network's prediction. Our approach uses gradient information (based on Integrated Gradients) to focus on a subset of neurons in the first layer, which allows our technique to scale to large networks. The corresponding SMT constraints encode the minimal input mask discovery problem such that after masking the input, the activations of the selected neurons are still above a threshold. After solving for the minimal masks, our approach scores the mask regions to generate a relative ordering of the features within the mask. This produces a saliency map which explains' where a model is looking' when making a prediction. We evaluate our technique on three datasets-MNIST, ImageNet, and Beer Reviews, and demonstrate both quantitatively and qualitatively that the regions generated by our approach are sparser and achieve higher saliency scores compared to the gradient-based methods alone. Code and examples are at - https://github.com/google-research/google-research/tree/master/smug_saliency",
        "conference": "ICLR",
        "中文标题": "利用梯度扩展符号方法以进行神经模型解释",
        "摘要翻译": "基于可满足性模理论(SMT)求解器的符号技术已被提出用于分析和验证神经网络属性，但由于其在较大网络上扩展性差，其使用相当有限。在这项工作中，我们提出了一种将基于梯度的方法与符号技术相结合的技术，以扩展此类分析，并展示了其在模型解释中的应用。特别是，我们应用这一技术来识别输入中对神经网络预测最相关的最小区域。我们的方法使用梯度信息（基于集成梯度）来聚焦于第一层中的神经元子集，这使得我们的技术能够扩展到大型网络。相应的SMT约束编码了最小输入掩码发现问题，即在掩码输入后，所选神经元的激活仍然高于阈值。在解决最小掩码后，我们的方法对掩码区域进行评分，以生成掩码内特征的相对排序。这产生了一个显著性图，解释了模型在做出预测时‘看’哪里。我们在三个数据集（MNIST、ImageNet和啤酒评论）上评估了我们的技术，并定量和定性地证明了与单独使用基于梯度的方法相比，我们的方法生成的区域更稀疏，并且实现了更高的显著性分数。代码和示例位于 - https://github.com/google-research/google-research/tree/master/smug_saliency",
        "领域": "神经网络解释性、模型验证、显著性分析",
        "问题": "如何提高符号方法在大型神经网络中的可扩展性，以便更有效地进行模型解释",
        "动机": "现有的基于SMT求解器的符号技术在分析大型神经网络时扩展性差，限制了其在模型解释中的应用",
        "方法": "结合梯度信息与符号技术，聚焦于第一层神经元的子集，通过SMT约束编码最小输入掩码发现问题，生成显著性图",
        "关键词": [
            "符号方法",
            "梯度信息",
            "模型解释",
            "显著性分析",
            "SMT求解器"
        ],
        "涉及的技术概念": {
            "可满足性模理论(SMT)求解器": "用于分析和验证神经网络属性的符号技术，能够处理逻辑公式和理论约束",
            "集成梯度": "一种基于梯度的方法，用于确定输入特征对模型预测的贡献，帮助聚焦于关键神经元",
            "显著性图": "一种可视化技术，用于展示模型在做出预测时关注的输入区域，帮助理解模型的决策过程"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 707,
        "title": "Scaling the Convex Barrier with Active Sets",
        "html": "https://iclr.cc//virtual/2021/poster/3035",
        "abstract": "Tight and efficient neural network bounding is of critical importance for the scaling of neural network verification systems. A number of efficient specialised dual solvers for neural network bounds have been presented recently, but they are often too loose to verify more challenging properties. This lack of tightness is linked to the weakness of the employed relaxation, which is usually a linear program of size linear in the number of neurons. While a tighter linear relaxation for piecewise linear activations exists, it comes at the cost of exponentially many constraints and thus currently lacks an efficient customised solver. We alleviate this deficiency via a novel dual algorithm that realises the full potential of the new relaxation by operating on a small active set of dual variables. Our method recovers the strengths of the new relaxation in the dual space: tightness and a linear separation oracle. At the same time, it shares the benefits of previous dual approaches for weaker relaxations: massive parallelism, GPU implementation, low cost per iteration and valid bounds at any time. As a consequence, we obtain better bounds than off-the-shelf solvers in only a fraction of their running time and recover the speed-accuracy trade-offs of looser dual solvers if the computational budget is small. We demonstrate that this results in significant formal verification speed-ups.",
        "conference": "ICLR",
        "中文标题": "利用活动集扩展凸障碍",
        "摘要翻译": "紧密且高效的神经网络边界对于神经网络验证系统的扩展至关重要。最近，已经提出了许多高效的专门用于神经网络边界的对偶求解器，但它们往往过于宽松，无法验证更具挑战性的属性。这种紧密性的缺乏与所采用的松弛方法的弱点有关，这通常是一个大小与神经元数量成线性的线性程序。虽然对于分段线性激活函数存在更紧密的线性松弛方法，但它以指数级多的约束为代价，因此目前缺乏高效的定制求解器。我们通过一种新颖的对偶算法来缓解这一缺陷，该算法通过操作一小部分活动对偶变量来实现新松弛方法的全部潜力。我们的方法在对偶空间中恢复了新松弛方法的优势：紧密性和线性分离预言机。同时，它分享了之前对较弱松弛方法的对偶方法的优点：大规模并行性、GPU实现、每次迭代的低成本以及随时有效的边界。因此，我们仅在现成求解器运行时间的一小部分内获得了更好的边界，并且在计算预算较小的情况下恢复了宽松对偶求解器的速度-准确性权衡。我们证明这导致了形式验证速度的显著提升。",
        "领域": "神经网络验证、凸优化、形式验证",
        "问题": "解决神经网络验证系统中边界计算不够紧密和高效的问题",
        "动机": "提高神经网络验证的效率和准确性，特别是在处理具有挑战性的属性时",
        "方法": "提出了一种新颖的对偶算法，通过操作一小部分活动对偶变量来实现更紧密的线性松弛方法",
        "关键词": [
            "神经网络验证",
            "凸优化",
            "形式验证",
            "对偶算法",
            "线性松弛"
        ],
        "涉及的技术概念": {
            "对偶算法": "用于实现更紧密的线性松弛方法，通过操作一小部分活动对偶变量来提高效率和准确性",
            "线性松弛": "一种优化技术，用于近似解决复杂的优化问题，特别是在神经网络验证中",
            "形式验证": "使用数学方法验证系统或算法的正确性，特别是在神经网络中确保其行为符合预期"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 708,
        "title": "Score-Based Generative Modeling through Stochastic Differential Equations",
        "html": "https://iclr.cc//virtual/2021/poster/3177",
        "abstract": "Creating noise from data is easy; creating data from noise is generative modeling. We present a stochastic differential equation (SDE) that smoothly transforms a complex data distribution to a known prior distribution by slowly injecting noise, and a corresponding reverse-time SDE that transforms the prior distribution back into the data distribution by slowly removing the noise. \nCrucially, the reverse-time SDE depends only on the time-dependent gradient field (a.k.a., score) of the perturbed data distribution. By leveraging advances in score-based generative modeling, we can accurately estimate these scores with neural networks, and use numerical SDE solvers to generate samples. We show that this framework encapsulates previous approaches in score-based generative modeling and diffusion probabilistic modeling, allowing for new sampling procedures and new modeling capabilities. In particular, we introduce a predictor-corrector framework to correct errors in the evolution of the discretized reverse-time SDE. We also derive an equivalent neural ODE that samples from the same distribution as the SDE, but additionally enables exact likelihood computation, and improved sampling efficiency. In addition, we provide a new way to solve inverse problems with score-based models, as demonstrated with experiments on class-conditional generation, image inpainting, and colorization. Combined with multiple architectural improvements, we achieve record-breaking performance for unconditional image generation on CIFAR-10 with an Inception score of 9.89 and FID of 2.20, a competitive likelihood of 2.99 bits/dim, and demonstrate high fidelity generation of $1024\\times 1024$ images for the first time from a score-based generative model.",
        "conference": "ICLR",
        "中文标题": "基于随机微分方程的分数生成建模",
        "摘要翻译": "从数据中创建噪声是容易的；从噪声中创建数据则是生成建模。我们提出了一种随机微分方程（SDE），通过缓慢注入噪声将复杂的数据分布平滑地转换为已知的先验分布，以及一个相应的逆时间SDE，通过缓慢去除噪声将先验分布转换回数据分布。关键在于，逆时间SDE仅依赖于扰动数据分布的时间依赖梯度场（即分数）。通过利用分数生成建模的进展，我们可以用神经网络准确估计这些分数，并使用数值SDE求解器生成样本。我们展示了这个框架封装了分数生成建模和扩散概率建模中的先前方法，允许新的采样程序和新的建模能力。特别是，我们引入了一个预测-校正框架来纠正离散化逆时间SDE演化中的错误。我们还推导了一个等效的神经ODE，它从与SDE相同的分布中采样，但额外支持精确的似然计算和改进的采样效率。此外，我们提供了一种用分数模型解决逆问题的新方法，如通过类别条件生成、图像修复和彩色化实验所展示的。结合多种架构改进，我们在CIFAR-10上实现了无条件图像生成的创纪录性能，Inception得分为9.89，FID为2.20，竞争性似然为2.99位/维度，并首次从基于分数的生成模型中展示了1024×1024图像的高保真生成。",
        "领域": "生成模型、图像生成、逆问题求解",
        "问题": "如何通过随机微分方程实现复杂数据分布与已知先验分布之间的转换，并高效生成高质量样本",
        "动机": "探索一种能够封装现有分数生成建模和扩散概率建模方法，同时支持新采样程序和建模能力的统一框架",
        "方法": "提出基于随机微分方程的分数生成建模框架，利用神经网络估计分数，采用数值SDE求解器生成样本，并引入预测-校正框架和神经ODE以提高效率和精度",
        "关键词": [
            "随机微分方程",
            "分数生成建模",
            "神经ODE",
            "图像生成",
            "逆问题"
        ],
        "涉及的技术概念": {
            "随机微分方程（SDE）": "用于描述数据分布与先验分布之间转换过程的数学模型",
            "分数（梯度场）": "扰动数据分布的时间依赖梯度场，是逆时间SDE的关键依赖项",
            "神经ODE": "等效于SDE的神经网络模型，支持精确似然计算和改进的采样效率"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 709,
        "title": "SCoRe: Pre-Training for Context Representation in Conversational Semantic Parsing",
        "html": "https://iclr.cc//virtual/2021/poster/3270",
        "abstract": "Conversational Semantic Parsing (CSP) is the task of converting a sequence of natural language queries to formal language (e.g., SQL, SPARQL) that can be executed against a structured ontology (e.g.  databases, knowledge bases).  To accomplish  this  task,  a  CSP  system  needs  to  model  the  relation  between  the unstructured language utterance and the structured ontology while representing the multi-turn dynamics of the dialog. Pre-trained language models (LMs) are the state-of-the-art for various natural language processing tasks. However, existing pre-trained LMs that use language modeling training objectives over free-form text have limited ability to represent natural language references to contextual structural data. In this work, we present SCORE, a new pre-training approach for CSP tasks designed to induce representations that capture the alignment between the dialogue flow and the structural context. We demonstrate the broad applicability of SCORE to CSP tasks by combining SCORE with strong base systems on four different tasks (SPARC, COSQL, MWOZ, and SQA). We show that SCORE can improve the performance over all these base systems by a significant margin and achieves state-of-the-art results on three of them.",
        "conference": "ICLR",
        "中文标题": "SCoRe：对话语义解析中上下文表示的预训练",
        "摘要翻译": "对话语义解析（CSP）是将一系列自然语言查询转换为可以针对结构化本体（如数据库、知识库）执行的形式语言（如SQL、SPARQL）的任务。为了完成这一任务，CSP系统需要在表示对话的多轮动态的同时，建模非结构化语言表达与结构化本体之间的关系。预训练语言模型（LMs）是各种自然语言处理任务的最新技术。然而，现有的使用自由文本上的语言建模训练目标的预训练LMs在表示对上下文结构数据的自然语言引用方面能力有限。在这项工作中，我们提出了SCORE，一种为CSP任务设计的新的预训练方法，旨在诱导能够捕捉对话流与结构上下文之间对齐的表示。我们通过将SCORE与四个不同任务（SPARC、COSQL、MWOZ和SQA）上的强大基础系统结合，展示了SCORE对CSP任务的广泛适用性。我们表明，SCORE可以显著提高所有这些基础系统的性能，并在其中三个任务上取得了最先进的结果。",
        "领域": "自然语言处理与视觉结合、对话系统、语义解析",
        "问题": "如何提高预训练语言模型在对话语义解析任务中对上下文结构数据的表示能力。",
        "动机": "现有的预训练语言模型在表示自然语言对上下文结构数据的引用方面能力有限，影响了对话语义解析任务的性能。",
        "方法": "提出了一种新的预训练方法SCORE，旨在诱导能够捕捉对话流与结构上下文之间对齐的表示，并与强大的基础系统结合应用于多个CSP任务。",
        "关键词": [
            "对话语义解析",
            "预训练语言模型",
            "上下文表示",
            "结构化本体",
            "多轮对话"
        ],
        "涉及的技术概念": {
            "对话语义解析（CSP）": "将自然语言查询转换为形式语言的任务，以便在结构化本体上执行。",
            "预训练语言模型（LMs）": "通过在大规模文本数据上预训练来学习语言表示的模型，用于各种自然语言处理任务。",
            "结构化本体": "如数据库和知识库等，为信息提供结构化表示的系统，CSP任务需要将自然语言查询映射到这些结构上。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 710,
        "title": "SEDONA: Search for Decoupled Neural Networks toward Greedy Block-wise Learning",
        "html": "https://iclr.cc//virtual/2021/poster/2972",
        "abstract": "Backward locking and update locking are well-known sources of inefficiency in backpropagation that prevent from concurrently updating layers. Several works have recently suggested using local error signals to train network blocks asynchronously to overcome these limitations. However, they often require numerous iterations of trial-and-error to find the best configuration for local training, including how to decouple network blocks and which auxiliary networks to use for each block. In this work, we propose a differentiable search algorithm named SEDONA to automate this process. Experimental results show that our algorithm can consistently discover transferable decoupled architectures for VGG and ResNet variants, and significantly outperforms the ones trained with end-to-end backpropagation and other state-of-the-art greedy-leaning methods in CIFAR-10, Tiny-ImageNet and ImageNet.",
        "conference": "ICLR",
        "中文标题": "SEDONA：面向贪婪块式学习的解耦神经网络搜索",
        "摘要翻译": "反向锁定和更新锁定是反向传播中众所周知的效率低下原因，它们阻碍了层的并行更新。最近有几项工作提出使用局部误差信号来异步训练网络块以克服这些限制。然而，这些方法通常需要大量的试错迭代来找到局部训练的最佳配置，包括如何解耦网络块以及为每个块使用哪些辅助网络。在这项工作中，我们提出了一种名为SEDONA的可微分搜索算法来自动化这一过程。实验结果表明，我们的算法能够持续为VGG和ResNet变体发现可转移的解耦架构，并在CIFAR-10、Tiny-ImageNet和ImageNet上显著优于使用端到端反向传播和其他最先进的贪婪学习方法训练的模型。",
        "领域": "神经网络架构搜索、深度学习优化、并行训练",
        "问题": "解决反向传播中的反向锁定和更新锁定问题，实现网络块的并行更新和高效训练。",
        "动机": "克服传统反向传播方法在并行更新网络层时的效率低下问题，自动化寻找最优解耦网络架构和辅助网络配置的过程。",
        "方法": "提出了一种名为SEDONA的可微分搜索算法，用于自动发现最优的解耦网络架构和辅助网络配置，实现网络块的异步训练。",
        "关键词": [
            "解耦神经网络",
            "贪婪块式学习",
            "可微分搜索",
            "并行训练",
            "神经网络架构搜索"
        ],
        "涉及的技术概念": {
            "反向锁定": "在反向传播过程中，由于依赖前一层的梯度计算，导致层更新无法并行进行，影响训练效率。",
            "更新锁定": "在反向传播中，由于需要等待所有层的梯度计算完成后才能更新权重，限制了训练速度。",
            "可微分搜索算法": "一种自动化搜索最优网络架构的方法，通过可微分的方式优化网络配置，减少人工试错的需求。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 711,
        "title": "SEED: Self-supervised Distillation For Visual Representation",
        "html": "https://iclr.cc//virtual/2021/poster/2707",
        "abstract": "This paper is concerned with self-supervised learning for small models. The problem is motivated by our empirical studies that while the widely used contrastive self-supervised learning method has shown great progress on large model training, it does not work well for small models. To address this problem, we propose a new learning paradigm, named $\\textbf{SE}$lf-Sup$\\textbf{E}$rvised $\\textbf{D}$istillation (${\\large S}$EED), where we leverage a larger network (as Teacher) to transfer its representational knowledge into a smaller architecture (as Student) in a self-supervised fashion. Instead of directly learning from unlabeled data, we train a student encoder to mimic the similarity score distribution inferred by a teacher over a set of instances. We show that ${\\large S}$EED dramatically boosts the performance of small networks on downstream tasks. Compared with self-supervised baselines, ${\\large S}$EED improves the top-1 accuracy from 42.2% to 67.6% on EfficientNet-B0 and from 36.3% to 68.2% on MobileNet-v3-Large on the ImageNet-1k dataset. ",
        "conference": "ICLR",
        "中文标题": "SEED：视觉表示的自监督蒸馏",
        "摘要翻译": "本文关注于小模型的自监督学习。问题的动机来自于我们的实证研究，即虽然广泛使用的对比自监督学习方法在大模型训练上显示出巨大进展，但对于小模型效果不佳。为了解决这个问题，我们提出了一种新的学习范式，名为自监督蒸馏（SEED），其中我们利用一个更大的网络（作为教师）以自监督的方式将其表示知识转移到一个更小的架构（作为学生）中。与直接从无标签数据中学习不同，我们训练一个学生编码器来模仿教师在一组实例上推断出的相似性分数分布。我们展示了SEED显著提高了小网络在下游任务上的性能。与自监督基线相比，SEED在ImageNet-1k数据集上将EfficientNet-B0的top-1准确率从42.2%提高到67.6%，将MobileNet-v3-Large的top-1准确率从36.3%提高到68.2%。",
        "领域": "自监督学习、知识蒸馏、小模型优化",
        "问题": "小模型在自监督学习中的表现不佳",
        "动机": "提升小模型在自监督学习中的表现，使其能够更好地应用于下游任务",
        "方法": "提出自监督蒸馏（SEED）方法，通过教师模型向学生模型转移表示知识，以自监督的方式提升小模型的性能",
        "关键词": [
            "自监督学习",
            "知识蒸馏",
            "小模型优化",
            "ImageNet-1k",
            "相似性分数分布"
        ],
        "涉及的技术概念": {
            "自监督学习": "一种无需人工标注数据的学习方法，通过数据自身的结构或特性来学习表示",
            "知识蒸馏": "通过教师模型向学生模型转移知识，以提升学生模型的性能和泛化能力",
            "相似性分数分布": "教师模型在一组实例上推断出的相似性分数分布，学生模型通过模仿这一分布来学习"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 712,
        "title": "Selective Classification Can Magnify Disparities Across Groups",
        "html": "https://iclr.cc//virtual/2021/poster/3060",
        "abstract": "Selective classification, in which models can abstain on uncertain predictions, is a natural approach to improving accuracy in settings where errors are costly but abstentions are manageable. In this paper, we find that while selective classification can improve average accuracies, it can simultaneously magnify existing accuracy disparities between various groups within a population, especially in the presence of spurious correlations. We observe this behavior consistently across five vision and NLP datasets. Surprisingly, increasing abstentions can even decrease accuracies on some groups. To better understand this phenomenon, we study the margin distribution, which captures the model’s confidences over all predictions. For symmetric margin distributions, we prove that whether selective classification monotonically improves or worsens accuracy is fully determined by the accuracy at full coverage (i.e., without any abstentions) and whether the distribution satisfies a property we call left-log-concavity. Our analysis also shows that selective classification tends to magnify full-coverage accuracy disparities. Motivated by our analysis, we train distributionally-robust models that achieve similar full-coverage accuracies across groups and show that selective classification uniformly improves each group on these models. Altogether, our results suggest that selective classification should be used with care and underscore the importance of training models to perform equally well across groups at full coverage.",
        "conference": "ICLR",
        "中文标题": "选择性分类可能放大群体间的差异",
        "摘要翻译": "选择性分类，即模型可以对不确定的预测选择弃权，是在错误成本高但弃权可管理的设置中提高准确性的自然方法。在本文中，我们发现，虽然选择性分类可以提高平均准确性，但它同时可能放大人口中不同群体之间现有的准确性差异，尤其是在存在虚假相关性的情况下。我们在五个视觉和自然语言处理数据集中一致观察到了这种行为。令人惊讶的是，增加弃权甚至可能降低某些群体的准确性。为了更好地理解这一现象，我们研究了边际分布，它捕捉了模型对所有预测的置信度。对于对称的边际分布，我们证明了选择性分类是否单调提高或降低准确性完全取决于全覆盖率（即没有任何弃权）下的准确性以及分布是否满足我们称之为左对数凹性的属性。我们的分析还表明，选择性分类倾向于放大全覆盖率下的准确性差异。受我们分析的启发，我们训练了分布鲁棒模型，这些模型在不同群体间实现了相似的全覆盖率准确性，并表明选择性分类在这些模型上均匀地提高了每个群体的准确性。总之，我们的结果表明，选择性分类应谨慎使用，并强调了训练模型在全覆盖率下在不同群体间表现同等重要的重要性。",
        "领域": "机器学习公平性、选择性分类、计算机视觉与自然语言处理",
        "问题": "选择性分类在提高平均准确性的同时，可能放大不同群体间的准确性差异。",
        "动机": "研究选择性分类如何影响不同群体间的准确性差异，特别是在存在虚假相关性的情况下。",
        "方法": "通过分析边际分布和训练分布鲁棒模型，研究选择性分类对群体间差异的影响。",
        "关键词": [
            "选择性分类",
            "群体差异",
            "边际分布",
            "分布鲁棒模型",
            "虚假相关性"
        ],
        "涉及的技术概念": {
            "选择性分类": "模型可以对不确定的预测选择弃权，以提高准确性。",
            "边际分布": "捕捉模型对所有预测的置信度，用于分析选择性分类的影响。",
            "分布鲁棒模型": "在不同群体间实现相似的全覆盖率准确性的模型，用于减少选择性分类带来的差异。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 713,
        "title": "Selectivity considered harmful: evaluating the causal impact of class selectivity in DNNs",
        "html": "https://iclr.cc//virtual/2021/poster/2799",
        "abstract": "The properties of individual neurons are often analyzed in order to understand the biological and artificial neural networks in which they're embedded. Class selectivity—typically defined as how different a neuron's responses are across different classes of stimuli or data samples—is commonly used for this purpose. However, it remains an open question whether it is necessary and/or sufficient for deep neural networks (DNNs) to learn class selectivity in individual units. We investigated the causal impact of class selectivity on network function by directly regularizing for or against class selectivity. Using this regularizer to reduce class selectivity across units in convolutional neural networks increased test accuracy by over 2% in ResNet18 and 1% in ResNet50 trained on Tiny ImageNet. For ResNet20 trained on CIFAR10 we could reduce class selectivity by a factor of 2.5 with no impact on test accuracy, and reduce it nearly to zero with only a small (~2%) drop in test accuracy. In contrast, regularizing to increase class selectivity significantly decreased test accuracy across all models and datasets. These results indicate that class selectivity in individual units is neither sufficient nor strictly necessary, and can even impair DNN performance. They also encourage caution when focusing on the properties of single units as representative of the mechanisms by which DNNs function.",
        "conference": "ICLR",
        "中文标题": "选择性有害论：评估深度神经网络中类别选择性的因果影响",
        "摘要翻译": "为了理解生物和人工神经网络，常常分析单个神经元的特性。类别选择性——通常定义为神经元对不同类别刺激或数据样本反应的差异程度——常被用于此目的。然而，深度神经网络（DNNs）是否需要在单个单元中学习类别选择性，这仍然是一个开放性问题。我们通过直接对类别选择性进行正则化，研究了类别选择性对网络功能的因果影响。在卷积神经网络中使用这种正则化减少类别选择性，使得在Tiny ImageNet上训练的ResNet18测试准确率提高了超过2%，ResNet50提高了1%。对于在CIFAR10上训练的ResNet20，我们可以将类别选择性减少2.5倍而不影响测试准确率，并且几乎可以将其降至零，仅导致测试准确率小幅下降（约2%）。相比之下，正则化以增加类别选择性在所有模型和数据集上都显著降低了测试准确率。这些结果表明，单个单元中的类别选择性既不充分也不严格必要，甚至可能损害DNN性能。这也提醒我们在关注单个单元特性作为DNN功能机制代表时需要谨慎。",
        "领域": "深度学习理论、神经网络优化、计算机视觉",
        "问题": "评估深度神经网络中类别选择性对网络性能的因果影响",
        "动机": "探讨类别选择性在深度神经网络中的必要性和充分性，以及其对网络性能的实际影响",
        "方法": "通过正则化技术直接调整类别选择性，观察其对不同模型和数据集测试准确率的影响",
        "关键词": [
            "类别选择性",
            "深度神经网络",
            "正则化",
            "网络性能",
            "因果影响"
        ],
        "涉及的技术概念": {
            "类别选择性": "衡量神经元对不同类别刺激或数据样本反应的差异程度，用于分析神经网络的特性",
            "正则化": "通过引入额外的约束或惩罚项来调整模型的学习过程，以减少类别选择性或增加类别选择性",
            "测试准确率": "评估模型性能的指标，反映模型在未见数据上的预测准确性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 714,
        "title": "Self-supervised Adversarial Robustness for the Low-label, High-data Regime",
        "html": "https://iclr.cc//virtual/2021/poster/3025",
        "abstract": "Recent work discovered that training models to be invariant to adversarial perturbations requires substantially larger datasets than those required for standard classification. Perhaps more surprisingly, these larger datasets can be 'mostly' unlabeled. Pseudo-labeling, a technique simultaneously pioneered by four separate and simultaneous works in 2019, has been proposed as a competitive alternative to labeled data for training adversarially robust models. However, when the amount of labeled data decreases, the performance of pseudo-labeling catastrophically drops, thus questioning the theoretical insights put forward by Uesato et al. (2019), which suggest that the sample complexity for learning an adversarially robust model from unlabeled data should match the fully supervised case. We introduce Bootstrap Your Own Robust Latents (BYORL), a self-supervised learning technique based on BYOL for training adversarially robust models. Our method enables us to train robust representations without any labels (reconciling practice with theory). Most notably, this robust representation can be leveraged by a linear classifier to train adversarially robust models, even when the linear classifier is not trained adversarially. We evaluate BYORL and pseudo-labeling on CIFAR-10 and ImageNet and demonstrate that BYORL achieves significantly higher robustness (i.e., models resulting from BYORL are up to two times more accurate). Experiments on CIFAR-10 against $\\ell_2$ and $\\ell_\\infty$ norm-bounded perturbations demonstrate that BYORL achieves near state-of-the-art robustness with as little as 500 labeled examples. We also note that against $\\ell_2$ norm-bounded perturbations of size $\\epsilon = 128/255$, BYORL surpasses the known state-of-the-art with an accuracy under attack of 77.61% (against 72.91% for the prior art).",
        "conference": "ICLR",
        "中文标题": "自监督对抗鲁棒性：低标签高数据场景下的应用",
        "摘要翻译": "最近的研究发现，训练模型以对抗扰动不变性所需的数据集规模远大于标准分类所需的数据集。更令人惊讶的是，这些更大的数据集可以‘大部分’是无标签的。伪标签技术，这一在2019年由四项独立且同时进行的工作同时开创的技术，已被提出作为训练对抗鲁棒模型的标签数据的竞争性替代方案。然而，当标签数据量减少时，伪标签技术的性能会灾难性下降，从而对Uesato等人（2019）提出的理论见解提出了质疑，该见解认为从无标签数据学习对抗鲁棒模型的样本复杂度应与完全监督的情况相匹配。我们介绍了Bootstrap Your Own Robust Latents（BYORL），一种基于BYOL的自监督学习技术，用于训练对抗鲁棒模型。我们的方法使我们能够在没有任何标签的情况下训练鲁棒表示（将实践与理论相协调）。最值得注意的是，这种鲁棒表示可以被线性分类器利用来训练对抗鲁棒模型，即使线性分类器本身不是对抗训练的。我们在CIFAR-10和ImageNet上评估了BYORL和伪标签技术，并证明BYORL实现了显著更高的鲁棒性（即，BYORL产生的模型准确率提高了两倍）。在CIFAR-10上针对ℓ2和ℓ∞范数限制的扰动的实验表明，BYORL仅需500个标签示例即可实现接近最先进的鲁棒性。我们还注意到，针对大小为ε=128/255的ℓ2范数限制的扰动，BYORL以77.61%的攻击下准确率（之前的最先进技术为72.91%）超越了已知的最先进技术。",
        "领域": "对抗性机器学习、自监督学习、图像分类",
        "问题": "在低标签高数据场景下，如何有效训练对抗鲁棒的模型",
        "动机": "解决在标签数据稀缺情况下训练对抗鲁棒模型时伪标签技术性能下降的问题",
        "方法": "提出BYORL，一种基于BYOL的自监督学习技术，用于训练对抗鲁棒模型",
        "关键词": [
            "自监督学习",
            "对抗鲁棒性",
            "伪标签技术",
            "BYORL",
            "低标签高数据"
        ],
        "涉及的技术概念": {
            "自监督学习": "在无标签数据上训练模型的技术，BYORL利用此技术训练对抗鲁棒表示",
            "对抗鲁棒性": "模型在面对对抗性攻击时保持性能的能力，BYORL旨在提升此能力",
            "伪标签技术": "一种利用模型预测为无标签数据生成伪标签的技术，用于训练对抗鲁棒模型"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 715,
        "title": "Self-supervised Learning from a Multi-view Perspective",
        "html": "https://iclr.cc//virtual/2021/poster/2613",
        "abstract": "As a subset of unsupervised representation learning, self-supervised representation learning adopts self-defined signals as supervision and uses the learned representation for downstream tasks, such as object detection and image captioning. Many proposed approaches for self-supervised learning follow naturally a multi-view perspective, where the input (e.g., original images) and the self-supervised signals (e.g., augmented images) can be seen as two redundant views of the data. Building from this multi-view perspective, this paper provides an information-theoretical framework to better understand the properties that encourage successful self-supervised learning. Specifically, we demonstrate that self-supervised learned representations can extract task-relevant information and discard task-irrelevant information. Our theoretical framework paves the way to a larger space of self-supervised learning objective design. In particular, we propose a composite objective that bridges the gap between prior contrastive and predictive learning objectives, and introduce an additional objective term to discard task-irrelevant information. To verify our analysis, we conduct controlled experiments to evaluate the impact of the composite objectives. We also explore our framework's empirical generalization beyond the multi-view perspective, where the cross-view redundancy may not be clearly observed.",
        "conference": "ICLR",
        "中文标题": "从多视角看自监督学习",
        "摘要翻译": "作为无监督表示学习的一个子集，自监督表示学习采用自定义信号作为监督，并将学习到的表示用于下游任务，如目标检测和图像描述。许多提出的自监督学习方法自然遵循多视角视角，其中输入（例如原始图像）和自监督信号（例如增强图像）可以被视为数据的两个冗余视图。基于这种多视角视角，本文提供了一个信息理论框架，以更好地理解促进成功自监督学习的属性。具体来说，我们证明了自监督学习到的表示可以提取任务相关信息并丢弃任务无关信息。我们的理论框架为自监督学习目标设计的更大空间铺平了道路。特别是，我们提出了一个复合目标，弥合了先前对比和预测学习目标之间的差距，并引入了一个额外的目标项来丢弃任务无关信息。为了验证我们的分析，我们进行了控制实验以评估复合目标的影响。我们还探索了我们的框架在多视角视角之外的实证泛化，其中跨视角冗余可能无法清晰观察到。",
        "领域": "自监督学习、表示学习、计算机视觉",
        "问题": "如何通过多视角理解自监督学习的属性，并设计更有效的学习目标",
        "动机": "探索自监督学习在多视角下的理论基础，以促进更有效的表示学习",
        "方法": "提出信息理论框架分析自监督学习属性，设计复合目标结合对比和预测学习，并引入新目标项丢弃无关信息",
        "关键词": [
            "自监督学习",
            "多视角学习",
            "信息理论",
            "表示学习",
            "复合目标"
        ],
        "涉及的技术概念": {
            "自监督表示学习": "采用自定义信号作为监督，学习数据表示用于下游任务",
            "多视角视角": "将输入和自监督信号视为数据的冗余视图，用于理解学习过程",
            "信息理论框架": "用于分析自监督学习属性，指导学习目标设计的理论工具"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 716,
        "title": "Self-Supervised Learning of Compressed Video Representations",
        "html": "https://iclr.cc//virtual/2021/poster/2915",
        "abstract": "Self-supervised learning of video representations has received great attention. Existing methods typically require frames to be decoded before being processed, which increases compute and storage requirements and ultimately hinders large-scale training. In this work, we propose an efficient self-supervised approach to learn video representations by eliminating the expensive decoding step. We use a three-stream video architecture that encodes I-frames and P-frames of a compressed video. Unlike existing approaches that encode I-frames and P-frames individually, we propose to jointly encode them by establishing bidirectional dynamic connections across streams. To enable self-supervised learning, we propose two pretext tasks that leverage the multimodal nature (RGB, motion vector, residuals) and the internal GOP structure of compressed videos. The first task asks our network to predict zeroth-order motion statistics in a spatio-temporal pyramid; the second task asks correspondence types between I-frames and P-frames after applying temporal transformations. We show that our approach achieves competitive performance on compressed video recognition both in supervised and self-supervised regimes. \n",
        "conference": "ICLR",
        "中文标题": "压缩视频表示的自监督学习",
        "摘要翻译": "视频表示的自监督学习已受到极大关注。现有方法通常需要在处理前解码帧，这增加了计算和存储需求，并最终阻碍了大规模训练。在这项工作中，我们提出了一种高效的自监督方法，通过消除昂贵的解码步骤来学习视频表示。我们使用一个三流视频架构，对压缩视频的I帧和P帧进行编码。与现有方法单独编码I帧和P帧不同，我们提出通过建立跨流的双向动态连接来联合编码它们。为了实现自监督学习，我们提出了两个利用压缩视频的多模态性质（RGB、运动矢量、残差）和内部GOP结构的预训练任务。第一个任务要求我们的网络在时空金字塔中预测零阶运动统计；第二个任务要求在应用时间变换后预测I帧和P帧之间的对应类型。我们展示了我们的方法在监督和自监督机制下在压缩视频识别上都达到了竞争性的性能。",
        "领域": "视频理解、自监督学习、压缩视频处理",
        "问题": "如何高效地从压缩视频中学习表示，避免昂贵的解码步骤",
        "动机": "减少视频表示学习中的计算和存储需求，促进大规模训练",
        "方法": "提出一种三流视频架构，联合编码I帧和P帧，并通过两个预训练任务实现自监督学习",
        "关键词": [
            "自监督学习",
            "压缩视频",
            "视频表示",
            "三流架构",
            "预训练任务"
        ],
        "涉及的技术概念": {
            "三流视频架构": "用于编码压缩视频中的I帧和P帧，通过建立双向动态连接联合编码",
            "自监督学习": "通过设计预训练任务，利用视频数据本身进行学习，无需人工标注",
            "预训练任务": "设计两个任务利用压缩视频的多模态性质和内部结构，指导模型学习有效的视频表示"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 717,
        "title": "Self-Supervised Policy Adaptation during Deployment",
        "html": "https://iclr.cc//virtual/2021/poster/2761",
        "abstract": "In most real world scenarios, a policy trained by reinforcement learning in one environment needs to be deployed in another, potentially quite different environment. However, generalization across different environments is known to be hard. A natural solution would be to keep training after deployment in the new environment, but this cannot be done if the new environment offers no reward signal. Our work explores the use of self-supervision to allow the policy to continue training after deployment without using any rewards. While previous methods explicitly anticipate changes in the new environment, we assume no prior knowledge of those changes yet still obtain significant improvements. Empirical evaluations are performed on diverse simulation environments from DeepMind Control suite and ViZDoom, as well as real robotic manipulation tasks in  continuously changing environments, taking observations from an uncalibrated camera. Our method improves generalization in 31 out of 36 environments across various tasks and outperforms domain randomization on a majority of environments. Webpage and implementation: https://nicklashansen.github.io/PAD/.",
        "conference": "ICLR",
        "中文标题": "部署期间的自监督策略适应",
        "摘要翻译": "在大多数现实世界场景中，通过强化学习在一个环境中训练的策略需要部署在另一个可能非常不同的环境中。然而，已知在不同环境间的泛化是困难的。一个自然的解决方案是在新环境中部署后继续训练，但如果新环境不提供奖励信号，这就无法实现。我们的工作探索了使用自监督来允许策略在部署后不使用任何奖励的情况下继续训练。虽然之前的方法明确预期新环境中的变化，但我们假设对这些变化没有任何先验知识，但仍然获得了显著的改进。实证评估在DeepMind Control套件和ViZDoom的多样化模拟环境以及真实机器人操作任务中进行，这些任务在持续变化的环境中，从一个未校准的摄像头获取观察。我们的方法在36个环境中的31个环境中改进了泛化能力，并在大多数环境中优于领域随机化。网页和实现：https://nicklashansen.github.io/PAD/。",
        "领域": "强化学习、机器人操作、自监督学习",
        "问题": "解决强化学习策略在新环境中部署时的泛化问题，特别是在缺乏奖励信号的情况下。",
        "动机": "研究动机是探索在不依赖奖励信号的情况下，通过自监督学习使强化学习策略在新环境中继续适应和优化。",
        "方法": "采用自监督学习方法，允许策略在部署后无需奖励信号即可继续训练，通过实证评估在多种模拟和真实环境中验证方法的有效性。",
        "关键词": [
            "自监督学习",
            "策略适应",
            "强化学习",
            "机器人操作",
            "环境泛化"
        ],
        "涉及的技术概念": {
            "自监督学习": "用于在没有外部奖励信号的情况下，通过策略自身生成监督信号来继续训练。",
            "强化学习": "基础学习方法，用于训练策略在特定环境中做出决策。",
            "环境泛化": "指策略在不同环境间保持性能的能力，是本研究要解决的核心问题。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 718,
        "title": "Self-supervised Representation Learning with Relative Predictive Coding",
        "html": "https://iclr.cc//virtual/2021/poster/2792",
        "abstract": "This paper introduces Relative Predictive Coding (RPC), a new contrastive representation learning objective that maintains a good balance among training stability, minibatch size sensitivity, and downstream task performance. The key to the success of RPC is two-fold. First, RPC introduces the relative parameters to regularize the objective for boundedness and low variance. Second, RPC contains no logarithm and exponential score functions, which are the main cause of training instability in prior contrastive objectives. We empirically verify the effectiveness of RPC on benchmark vision and speech self-supervised learning tasks. Lastly, we relate RPC with mutual information (MI) estimation, showing RPC can be used to estimate MI with low variance.",
        "conference": "ICLR",
        "中文标题": "基于相对预测编码的自监督表示学习",
        "摘要翻译": "本文介绍了相对预测编码（RPC），一种新的对比表示学习目标，它在训练稳定性、小批量大小敏感性和下游任务性能之间保持了良好的平衡。RPC成功的关键有两点。首先，RPC引入了相对参数来正则化目标，以确保有界性和低方差。其次，RPC不包含对数和指数评分函数，这些是先前对比目标中训练不稳定的主要原因。我们在基准视觉和语音自监督学习任务上实证验证了RPC的有效性。最后，我们将RPC与互信息（MI）估计联系起来，表明RPC可以用于低方差的MI估计。",
        "领域": "自监督学习、对比学习、表示学习",
        "问题": "如何在自监督学习中设计一个既稳定又高效的表示学习目标",
        "动机": "解决现有对比学习目标在训练稳定性、对小批量大小的敏感性和下游任务性能之间的不平衡问题",
        "方法": "引入相对预测编码（RPC），通过相对参数正则化目标和避免使用对数和指数评分函数来提高训练稳定性和降低方差",
        "关键词": [
            "相对预测编码",
            "自监督学习",
            "对比学习",
            "表示学习",
            "互信息估计"
        ],
        "涉及的技术概念": {
            "相对预测编码（RPC）": "一种新的对比表示学习目标，通过引入相对参数和避免使用不稳定的评分函数来提高训练效果",
            "互信息（MI）估计": "RPC可以用于估计互信息，且具有低方差的特性",
            "对比学习": "RPC属于对比学习的一种，旨在通过比较正负样本来学习有效的表示"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 719,
        "title": "Self-supervised Visual Reinforcement Learning with Object-centric Representations",
        "html": "https://iclr.cc//virtual/2021/poster/3331",
        "abstract": "Autonomous agents need large repertoires of skills to act reasonably on new tasks that they have not seen before. However, acquiring these skills using only a stream of high-dimensional, unstructured, and unlabeled observations is a tricky challenge for any autonomous agent. Previous methods have used variational autoencoders to encode a scene into a low-dimensional vector that can be used as a goal for an agent to discover new skills. Nevertheless, in compositional/multi-object environments it is difficult to disentangle all the factors of variation into such a fixed-length representation of the whole scene. We propose to use object-centric representations as a modular and structured observation space, which is learned with a compositional generative world model.\nWe show that the structure in the representations in combination with goal-conditioned attention policies helps the autonomous agent to discover and learn useful skills. These skills can be further combined to address compositional tasks like the manipulation of several different objects.",
        "conference": "ICLR",
        "中文标题": "基于物体中心表征的自监督视觉强化学习",
        "摘要翻译": "自主智能体需要大量的技能库，以便在未曾见过的新任务上合理行动。然而，仅使用高维、非结构化和未标记的观察流来获取这些技能，对任何自主智能体来说都是一个棘手的挑战。先前的方法使用变分自编码器将场景编码为一个低维向量，作为智能体发现新技能的目标。然而，在组合/多对象环境中，将所有变化因素解耦到这样一个固定长度的整个场景表征中是困难的。我们提出使用物体中心表征作为一个模块化和结构化的观察空间，这是通过一个组合生成世界模型学习的。我们展示了这些表征中的结构，结合目标条件注意力策略，帮助自主智能体发现和学习有用的技能。这些技能可以进一步组合，以解决如操纵几个不同物体这样的组合任务。",
        "领域": "强化学习、计算机视觉、机器人操作",
        "问题": "如何在仅使用高维、非结构化和未标记的观察流的情况下，使自主智能体获取大量技能以应对新任务。",
        "动机": "解决自主智能体在组合/多对象环境中难以通过固定长度的整个场景表征解耦所有变化因素，从而发现和学习有用技能的挑战。",
        "方法": "提出使用物体中心表征作为模块化和结构化的观察空间，结合目标条件注意力策略，通过组合生成世界模型学习，帮助智能体发现和学习技能。",
        "关键词": [
            "自监督学习",
            "物体中心表征",
            "强化学习",
            "组合任务",
            "目标条件注意力"
        ],
        "涉及的技术概念": {
            "物体中心表征": "作为模块化和结构化的观察空间，帮助智能体在组合/多对象环境中解耦变化因素。",
            "目标条件注意力策略": "结合物体中心表征，帮助智能体发现和学习有用的技能。",
            "组合生成世界模型": "用于学习物体中心表征，支持智能体在复杂环境中操作多个对象。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 720,
        "title": "Self-training For Few-shot Transfer Across Extreme Task Differences",
        "html": "https://iclr.cc//virtual/2021/poster/3168",
        "abstract": "Most few-shot learning techniques are pre-trained on a large, labeled “base dataset”. In problem domains where such large labeled datasets are not available for pre-training (e.g., X-ray, satellite images), one must resort to pre-training in a different “source” problem domain (e.g., ImageNet), which can be very different from the desired target task. Traditional few-shot and transfer learning techniques fail in the presence of such extreme differences between the source and target tasks. In this paper, we present a simple and effective solution to tackle this extreme domain gap: self-training a source domain representation on unlabeled data from the target domain. We show that this improves one-shot performance on the target domain by 2.9 points on average on the challenging BSCD-FSL benchmark consisting of datasets from multiple domains.",
        "conference": "ICLR",
        "中文标题": "自训练用于跨极端任务差异的少样本迁移",
        "摘要翻译": "大多数少样本学习技术都是在大型、有标签的“基础数据集”上进行预训练的。在那些无法获得如此大型有标签数据集进行预训练的问题领域（例如，X光、卫星图像），人们必须依赖于在不同“源”问题领域（例如，ImageNet）进行预训练，这可能与期望的目标任务非常不同。传统的少样本和迁移学习技术在源任务和目标任务之间存在如此极端差异时会失败。在本文中，我们提出了一个简单而有效的解决方案来应对这种极端领域差距：在目标领域的未标记数据上自训练源领域表示。我们证明，在由多个领域的数据集组成的挑战性BSCD-FSL基准测试中，这种方法将目标领域的一次性性能平均提高了2.9个百分点。",
        "领域": "少样本学习, 迁移学习, 跨领域学习",
        "问题": "解决在源任务和目标任务之间存在极端差异时，传统少样本和迁移学习技术失败的问题。",
        "动机": "在缺乏大型有标签数据集的问题领域中，提高少样本学习技术的适应性和性能。",
        "方法": "在目标领域的未标记数据上自训练源领域表示。",
        "关键词": [
            "自训练",
            "少样本学习",
            "迁移学习",
            "跨领域学习",
            "BSCD-FSL"
        ],
        "涉及的技术概念": {
            "自训练": "在目标领域的未标记数据上训练源领域表示，以减少领域差距。",
            "少样本学习": "在仅有少量样本的情况下进行学习，适用于数据稀缺的问题领域。",
            "迁移学习": "将从一个领域学到的知识迁移到另一个相关领域，以提高学习效率和性能。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 721,
        "title": "Semantic Re-tuning with Contrastive Tension",
        "html": "https://iclr.cc//virtual/2021/poster/2937",
        "abstract": "Extracting semantically useful natural language sentence representations from pre-trained deep neural networks such as Transformers remains a challenge. We first demonstrate that pre-training objectives impose a significant task bias onto the final layers of models with a layer-wise survey of the Semantic Textual Similarity (STS) correlations for multiple common Transformer language models. We then propose a new self-supervised method called Contrastive Tension (CT) to counter such biases. CT frames the training objective as a noise-contrastive task between the final layer representations of two independent models, in turn making the final layer representations suitable for feature extraction. Results from multiple common unsupervised and supervised STS tasks indicate that CT outperforms previous State Of The Art (SOTA), and when combining CT with supervised data we improve upon previous SOTA results with large margins. ",
        "conference": "ICLR",
        "中文标题": "通过对比张力进行语义重调",
        "摘要翻译": "从预训练的深度神经网络（如Transformer）中提取语义上有用的自然语言句子表示仍然是一个挑战。我们首先通过层面对多个常见Transformer语言模型的语义文本相似性（STS）相关性进行调查，证明了预训练目标对模型的最终层施加了显著的任务偏差。然后，我们提出了一种新的自监督方法，称为对比张力（CT），以对抗这种偏差。CT将训练目标构建为两个独立模型最终层表示之间的噪声对比任务，从而使最终层表示适合特征提取。多个常见的无监督和有监督STS任务的结果表明，CT优于之前的最先进技术（SOTA），并且当CT与有监督数据结合时，我们以较大幅度改进了之前的SOTA结果。",
        "领域": "自然语言处理与视觉结合",
        "问题": "如何从预训练的深度神经网络中提取语义上有用的自然语言句子表示",
        "动机": "预训练目标对模型的最终层施加了显著的任务偏差，影响了语义文本相似性（STS）的表现",
        "方法": "提出了一种新的自监督方法对比张力（CT），通过将训练目标构建为两个独立模型最终层表示之间的噪声对比任务，来优化最终层表示",
        "关键词": [
            "语义重调",
            "对比张力",
            "Transformer",
            "语义文本相似性",
            "自监督学习"
        ],
        "涉及的技术概念": {
            "对比张力（CT）": "一种新的自监督方法，通过噪声对比任务优化模型最终层表示，使其更适合特征提取",
            "语义文本相似性（STS）": "用于评估模型在理解自然语言句子语义相似性方面的能力",
            "Transformer语言模型": "一种基于自注意力机制的深度神经网络架构，广泛用于自然语言处理任务"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 722,
        "title": "Semi-supervised Keypoint Localization",
        "html": "https://iclr.cc//virtual/2021/poster/2815",
        "abstract": "Knowledge about the locations of keypoints of an object in an image can assist in fine-grained classification and identification tasks, particularly for the case of objects that exhibit large variations in poses that greatly influence their visual appearance, such as wild animals. However, supervised training of a keypoint detection network requires annotating a large image dataset for each animal species, which is a labor-intensive task. To reduce the need for labeled data, we propose to learn simultaneously keypoint heatmaps and pose invariant keypoint representations in a semi-supervised manner using a small set of labeled images along with a larger set of unlabeled images. Keypoint representations are learnt with a semantic keypoint consistency constraint that forces the keypoint detection network to learn similar features for the same keypoint across the dataset. Pose invariance is achieved by making keypoint representations for the image and its augmented copies closer together in feature space. Our semi-supervised approach significantly outperforms previous methods on several benchmarks for human and animal body landmark localization.",
        "conference": "ICLR",
        "中文标题": "半监督关键点定位",
        "摘要翻译": "了解图像中物体关键点的位置可以帮助细粒度分类和识别任务，特别是对于那些姿态变化大且显著影响其视觉外观的物体，如野生动物。然而，监督训练关键点检测网络需要对每种动物物种的大量图像数据集进行标注，这是一项劳动密集型的任务。为了减少对标记数据的需求，我们提出以半监督的方式同时学习关键点热图和姿态不变的关键点表示，使用一小部分标记图像和大量未标记图像。关键点表示通过语义关键点一致性约束学习，该约束迫使关键点检测网络学习数据集中相同关键点的相似特征。通过使图像及其增强副本的关键点表示在特征空间中更接近，实现了姿态不变性。我们的半监督方法在几个用于人类和动物身体地标定位的基准测试中显著优于以前的方法。",
        "领域": "关键点检测",
        "问题": "减少关键点检测中对大量标记数据的依赖",
        "动机": "为了降低标注成本并提高关键点检测的泛化能力",
        "方法": "提出一种半监督学习方法，同时学习关键点热图和姿态不变的关键点表示，利用少量标记数据和大量未标记数据",
        "关键词": [
            "半监督学习",
            "关键点检测",
            "姿态不变性",
            "细粒度分类",
            "语义一致性"
        ],
        "涉及的技术概念": {
            "关键点热图": "用于表示图像中关键点可能位置的二维概率分布图",
            "姿态不变的关键点表示": "在不同姿态下保持关键点特征一致性的表示方法",
            "语义关键点一致性约束": "确保相同关键点在数据集中具有相似特征的约束条件"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 723,
        "title": "SenSeI: Sensitive Set Invariance for Enforcing Individual Fairness",
        "html": "https://iclr.cc//virtual/2021/poster/2777",
        "abstract": "In this paper, we cast fair machine learning as invariant machine learning. We first formulate a version of individual fairness that enforces invariance on certain sensitive sets. We then design a transport-based regularizer that enforces this version of individual fairness and develop an algorithm to minimize the regularizer efficiently. Our theoretical results guarantee the proposed approach trains certifiably fair ML models. Finally, in the experimental studies we demonstrate improved fairness metrics in comparison to several recent fair training procedures on three ML tasks that are susceptible to algorithmic bias.",
        "conference": "ICLR",
        "中文标题": "SenSeI：敏感集不变性以强化个体公平性",
        "摘要翻译": "在本文中，我们将公平机器学习视为不变机器学习。我们首先制定了一种个体公平性的版本，该版本在特定的敏感集上强制执行不变性。然后，我们设计了一个基于传输的正则化器来强制执行这种个体公平性，并开发了一种算法来高效地最小化正则化器。我们的理论结果保证了所提出的方法能够训练出可证明公平的机器学习模型。最后，在实验研究中，我们展示了与几种最近的公平训练程序相比，在三个容易受到算法偏差影响的机器学习任务上，公平性指标有所提高。",
        "领域": "公平机器学习、算法偏差纠正、个体公平性",
        "问题": "如何在机器学习模型中强制执行个体公平性，以减少算法偏差",
        "动机": "为了解决机器学习模型中存在的算法偏差问题，确保模型对所有个体公平",
        "方法": "通过设计基于传输的正则化器和开发高效算法，强制执行敏感集上的不变性，以训练出公平的机器学习模型",
        "关键词": [
            "个体公平性",
            "敏感集不变性",
            "算法偏差纠正",
            "公平机器学习",
            "传输正则化"
        ],
        "涉及的技术概念": {
            "敏感集不变性": "在特定的敏感集上强制执行不变性，以确保机器学习模型的个体公平性",
            "传输正则化": "设计基于传输的正则化器，用于在训练过程中强制执行个体公平性",
            "算法偏差纠正": "通过理论保证和实验验证，纠正机器学习模型中的算法偏差，提高公平性指标"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 724,
        "title": "Separation and Concentration in Deep Networks",
        "html": "https://iclr.cc//virtual/2021/poster/2842",
        "abstract": "Numerical experiments demonstrate that deep neural network classifiers progressively separate class distributions around their mean, achieving linear separability on the training set, and increasing the Fisher discriminant ratio. We explain this mechanism with two types of operators. We prove that a rectifier without biases applied to sign-invariant tight frames can separate class means and increase Fisher ratios. On the opposite, a soft-thresholding on tight frames can reduce within-class variabilities while preserving class means. Variance reduction bounds are proved for Gaussian mixture models. For image classification, we show that separation of class means can be achieved with rectified wavelet tight frames that are not learned. It defines a scattering transform. Learning  $1 \\times 1$ convolutional tight frames along scattering channels and applying a soft-thresholding reduces within-class variabilities. The resulting scattering network reaches the classification accuracy of ResNet-18 on CIFAR-10 and ImageNet, with fewer layers and no learned biases.",
        "conference": "ICLR",
        "中文标题": "深度网络中的分离与集中",
        "摘要翻译": "数值实验表明，深度神经网络分类器逐步在类分布均值周围实现分离，在训练集上达到线性可分性，并增加Fisher判别比。我们用两种类型的算子来解释这一机制。我们证明，无偏置的整流器应用于符号不变的紧框架可以分离类均值并增加Fisher比。相反，紧框架上的软阈值可以在保持类均值的同时减少类内变异性。对于高斯混合模型，我们证明了方差减少的界限。对于图像分类，我们展示了类均值的分离可以通过未学习的整流小波紧框架实现。这定义了一个散射变换。沿着散射通道学习1×1卷积紧框架并应用软阈值减少了类内变异性。由此产生的散射网络在CIFAR-10和ImageNet上达到了与ResNet-18相同的分类准确率，但层数更少且无学习偏置。",
        "领域": "图像分类、深度神经网络、模式识别",
        "问题": "深度神经网络在分类任务中如何实现类分布的分离和集中",
        "动机": "探索深度神经网络分类器在训练过程中如何实现类分布的线性可分性，并提高分类性能",
        "方法": "通过两种算子（无偏置的整流器和软阈值）在紧框架上的应用，分析类均值分离和类内变异性减少的机制",
        "关键词": [
            "深度神经网络",
            "Fisher判别比",
            "散射变换",
            "图像分类",
            "紧框架"
        ],
        "涉及的技术概念": {
            "Fisher判别比": "用于衡量类间分离度和类内集中度的指标，论文中用于评估分类器的性能",
            "紧框架": "一种数学工具，用于信号的表示和处理，论文中用于实现类均值的分离和类内变异性的减少",
            "散射变换": "一种基于小波的信号表示方法，论文中用于构建无需学习的深度网络结构，实现高效的图像分类"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 725,
        "title": "Seq2Tens: An Efficient Representation of Sequences by Low-Rank Tensor Projections",
        "html": "https://iclr.cc//virtual/2021/poster/3342",
        "abstract": "Sequential data such as time series, video, or text can be challenging to analyse as the ordered structure gives rise to complex dependencies. At the heart of this is non-commutativity, in the sense that reordering the elements of a sequence can completely change its meaning. We use a classical mathematical object -- the free algebra -- to capture this non-commutativity. To address the innate computational complexity of this algebra, we use compositions of low-rank tensor projections. This yields modular and scalable building blocks that give state-of-the-art performance on standard benchmarks such as multivariate time series classification, mortality prediction and generative models for video.",
        "conference": "ICLR",
        "中文标题": "Seq2Tens：通过低秩张量投影高效表示序列",
        "摘要翻译": "诸如时间序列、视频或文本等序列数据由于其有序结构产生的复杂依赖关系而难以分析。其核心在于非交换性，即序列元素的重新排序可能完全改变其含义。我们使用一个经典的数学对象——自由代数——来捕捉这种非交换性。为了应对这一代数固有的计算复杂性，我们采用了低秩张量投影的组合。这产生了模块化和可扩展的构建块，这些构建块在多元时间序列分类、死亡率预测和视频生成模型等标准基准测试中达到了最先进的性能。",
        "领域": "时间序列分析, 视频处理, 自然语言处理",
        "问题": "如何高效表示和分析具有复杂依赖关系的序列数据",
        "动机": "序列数据的非交换性使得其分析变得复杂，需要一种能够捕捉这种特性的高效表示方法",
        "方法": "使用自由代数捕捉序列的非交换性，并通过低秩张量投影的组合来降低计算复杂性",
        "关键词": [
            "序列表示",
            "低秩张量投影",
            "自由代数",
            "时间序列分类",
            "视频生成模型"
        ],
        "涉及的技术概念": {
            "自由代数": "用于捕捉序列数据的非交换性特性",
            "低秩张量投影": "用于降低自由代数表示的计算复杂性，提高效率",
            "模块化和可扩展的构建块": "通过组合低秩张量投影创建的构建块，用于在多个应用领域实现高性能"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 726,
        "title": "Sequential Density Ratio Estimation for Simultaneous Optimization of Speed and Accuracy",
        "html": "https://iclr.cc//virtual/2021/poster/3247",
        "abstract": "Classifying sequential data as early and as accurately as possible is a challenging yet critical problem, especially when a sampling cost is high. One algorithm that achieves this goal is the sequential probability ratio test (SPRT), which is known as Bayes-optimal: it can keep the expected number of data samples as small as possible, given the desired error upper-bound. However, the original SPRT makes two critical assumptions that limit its application in real-world scenarios: (i) samples are independently and identically distributed, and (ii) the likelihood of the data being derived from each class can be calculated precisely. Here, we propose the SPRT-TANDEM, a deep neural network-based SPRT algorithm that overcomes the above two obstacles. The SPRT-TANDEM sequentially estimates the log-likelihood ratio of two alternative hypotheses by leveraging a novel Loss function for Log-Likelihood Ratio estimation (LLLR) while allowing correlations up to $N (\\in \\mathbb{N})$  preceding samples. In tests on one original and two public video databases, Nosaic MNIST, UCF101, and SiW, the SPRT-TANDEM achieves statistically significantly better classification accuracy than other baseline classifiers, with a smaller number of data samples. The code and Nosaic MNIST are publicly available at https://github.com/TaikiMiyagawa/SPRT-TANDEM.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "序列密度比估计以实现速度和准确性的同时优化",
        "摘要翻译": "尽可能早且准确地分类序列数据是一个具有挑战性但又至关重要的问题，尤其是在采样成本较高时。实现这一目标的一种算法是序列概率比测试（SPRT），它被称为贝叶斯最优：在给定期望误差上限的情况下，它可以尽可能保持数据样本的期望数量最小。然而，原始的SPRT做出了两个关键假设，限制了其在现实世界场景中的应用：（i）样本是独立同分布的，（ii）可以精确计算数据来自每个类别的可能性。在这里，我们提出了SPRT-TANDEM，一种基于深度神经网络的SPRT算法，克服了上述两个障碍。SPRT-TANDEM通过利用一种新颖的对数似然比估计（LLLR）损失函数，顺序估计两个替代假设的对数似然比，同时允许最多$N（∈ℕ）$个前样本的相关性。在一个原始和两个公共视频数据库（Nosaic MNIST、UCF101和SiW）的测试中，SPRT-TANDEM在数据样本数量较少的情况下，统计上显著优于其他基线分类器的分类准确率。代码和Nosaic MNIST可在https://github.com/TaikiMiyagawa/SPRT-TANDEM公开获取。",
        "领域": "序列数据分析、深度学习、视频分类",
        "问题": "如何在采样成本高的情况下，尽可能早且准确地分类序列数据",
        "动机": "克服原始SPRT算法在现实世界应用中的两个关键限制：样本独立同分布假设和数据类别可能性精确计算假设",
        "方法": "提出基于深度神经网络的SPRT-TANDEM算法，利用新颖的对数似然比估计损失函数顺序估计两个替代假设的对数似然比，并允许前样本的相关性",
        "关键词": [
            "序列概率比测试",
            "深度学习",
            "对数似然比估计",
            "视频分类",
            "序列数据分析"
        ],
        "涉及的技术概念": {
            "序列概率比测试（SPRT）": "一种贝叶斯最优算法，用于在给定期望误差上限的情况下，尽可能保持数据样本的期望数量最小",
            "对数似然比估计（LLLR）": "SPRT-TANDEM算法中用于顺序估计两个替代假设对数似然比的损失函数",
            "深度神经网络": "SPRT-TANDEM算法的基础，用于克服原始SPRT算法的限制"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 727,
        "title": "Set Prediction without Imposing Structure as Conditional Density Estimation",
        "html": "https://iclr.cc//virtual/2021/poster/2835",
        "abstract": "Set prediction is about learning to predict a collection of unordered variables with unknown interrelations. Training such models with set losses imposes the structure of a metric space over sets. We focus on stochastic and underdefined cases, where an incorrectly chosen loss function leads to implausible predictions. Example tasks include conditional point-cloud reconstruction and predicting future states of molecules. In this paper we propose an alternative to training via set losses, by viewing learning as conditional density estimation. Our learning framework fits deep energy-based models and approximates the intractable likelihood with gradient-guided sampling. Furthermore, we propose a stochastically augmented prediction algorithm that enables multiple predictions, reflecting the possible variations in the target set. We empirically demonstrate on a variety of datasets the capability to learn multi-modal densities and produce different plausible predictions. Our approach is competitive with previous set prediction models on standard benchmarks. More importantly, it extends the family of addressable tasks beyond those that have unambiguous predictions.",
        "conference": "ICLR",
        "中文标题": "无需强加结构的集合预测作为条件密度估计",
        "摘要翻译": "集合预测涉及学习预测一组无序变量，这些变量之间的相互关系未知。使用集合损失训练此类模型会在集合上强加一个度量空间的结构。我们关注的是随机和未定义的情况，其中错误选择的损失函数会导致不合理的预测。示例任务包括条件点云重建和预测分子的未来状态。在本文中，我们提出了一种替代通过集合损失进行训练的方法，即将学习视为条件密度估计。我们的学习框架适用于深度基于能量的模型，并通过梯度引导采样近似难以处理的似然。此外，我们提出了一种随机增强的预测算法，能够生成多个预测，反映目标集合中可能的变化。我们在多种数据集上实证展示了学习多模态密度和产生不同合理预测的能力。我们的方法在标准基准测试中与之前的集合预测模型具有竞争力。更重要的是，它将可处理的任务家族扩展到了那些预测不明确的任务之外。",
        "领域": "条件点云重建, 分子状态预测, 多模态密度估计",
        "问题": "解决在集合预测中错误选择损失函数导致不合理预测的问题",
        "动机": "为了扩展集合预测模型的应用范围，使其能够处理预测不明确的任务",
        "方法": "提出将学习视为条件密度估计的框架，使用深度基于能量的模型和梯度引导采样近似难以处理的似然，并引入随机增强的预测算法",
        "关键词": [
            "集合预测",
            "条件密度估计",
            "深度基于能量的模型",
            "梯度引导采样",
            "随机增强预测"
        ],
        "涉及的技术概念": {
            "条件密度估计": "在本文中用于替代传统的集合损失训练方法，通过学习数据的条件分布来进行预测",
            "深度基于能量的模型": "用于建模复杂的数据分布，通过能量函数来定义数据的概率分布",
            "梯度引导采样": "一种近似难以处理似然的方法，通过梯度信息引导采样过程以提高效率"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 728,
        "title": "Shape or Texture: Understanding Discriminative Features in CNNs",
        "html": "https://iclr.cc//virtual/2021/poster/3180",
        "abstract": "Contrasting the previous evidence that neurons in the later layers of a Convolutional Neural Network (CNN) respond to complex object shapes, recent studies have shown that CNNs actually exhibit a 'texture bias': given an image with both texture and shape cues (e.g., a stylized image), a CNN is biased towards predicting the category corresponding to the texture. However, these previous studies conduct experiments on the final classification output of the network, and fail to robustly evaluate the bias contained (i) in the latent representations, and (ii) on a per-pixel level. In this paper, we design a series of experiments that overcome these issues. We do this with the goal of better understanding what type of shape information contained in the network is discriminative, where shape information is encoded, as well as when the network learns about object shape during training. We show that a network learns the majority of overall shape information at the first few epochs of training and that this information is largely encoded in the last few layers of a CNN. Finally, we show that the encoding of shape does not imply the encoding of localized per-pixel semantic information. The experimental results and findings provide a more accurate understanding of the behaviour of current CNNs, thus helping to inform future design choices.",
        "conference": "ICLR",
        "中文标题": "形状或纹理：理解CNN中的判别性特征",
        "摘要翻译": "与先前证据表明卷积神经网络（CNN）的后期层神经元对复杂物体形状有响应相反，最近的研究显示CNN实际上表现出一种‘纹理偏向’：给定一个同时包含纹理和形状线索的图像（例如，风格化图像），CNN倾向于预测与纹理相对应的类别。然而，这些先前的研究仅对网络的最终分类输出进行了实验，未能稳健评估（i）潜在表示中包含的偏向，以及（ii）像素级别的偏向。在本文中，我们设计了一系列实验来克服这些问题。我们这样做的目的是为了更好地理解网络中包含的哪种形状信息是判别性的，形状信息在哪里编码，以及网络在训练过程中何时学习物体形状。我们表明，网络在训练的最初几个时期学习大部分总体形状信息，并且这些信息主要编码在CNN的最后几层中。最后，我们表明形状的编码并不意味着编码了局部化的每像素语义信息。实验结果和发现提供了对当前CNN行为更准确的理解，从而有助于指导未来的设计选择。",
        "领域": "图像分类、神经网络解释性、深度学习模型分析",
        "问题": "理解CNN在图像分类任务中更倾向于使用形状还是纹理作为判别性特征",
        "动机": "揭示CNN在处理图像时对形状和纹理信息的偏好，以指导更有效的网络设计和训练策略",
        "方法": "设计一系列实验评估CNN潜在表示和像素级别的纹理与形状偏向，分析形状信息在网络的编码位置和学习时机",
        "关键词": [
            "纹理偏向",
            "形状信息",
            "CNN解释性",
            "图像分类",
            "深度学习"
        ],
        "涉及的技术概念": {
            "纹理偏向": "CNN在处理图像时倾向于依赖纹理信息而非形状信息进行分类的倾向",
            "潜在表示": "网络中隐含的特征表示，本研究关注于这些表示中形状和纹理信息的编码情况",
            "像素级别分析": "对图像中每个像素的语义信息进行分析，以评估CNN对形状和纹理信息的处理方式"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 729,
        "title": "Shape-Texture Debiased Neural Network Training",
        "html": "https://iclr.cc//virtual/2021/poster/2870",
        "abstract": "Shape and texture are two prominent and complementary cues for recognizing objects. Nonetheless, Convolutional Neural Networks are often biased towards either texture or shape, depending on the training dataset. Our ablation shows that such bias degenerates model performance. Motivated by this observation, we develop a simple algorithm for shape-texture debiased learning. To prevent models from exclusively attending on a single cue in representation learning, we augment training data with images with conflicting shape and texture information (eg, an image of chimpanzee shape but with lemon texture) and, most importantly, provide the corresponding supervisions from shape and texture simultaneously. \n\nExperiments show that our method successfully improves model performance on several image recognition benchmarks and adversarial robustness. For example, by training on ImageNet, it helps ResNet-152 achieve substantial improvements on ImageNet (+1.2%), ImageNet-A  (+5.2%), ImageNet-C (+8.3%) and Stylized-ImageNet (+11.1%), and on defending against FGSM adversarial attacker on ImageNet (+14.4%). Our method also claims to be compatible with other advanced data augmentation strategies, eg, Mixup, and CutMix. The code is available here: https://github.com/LiYingwei/ShapeTextureDebiasedTraining.",
        "conference": "ICLR",
        "中文标题": "形状-纹理去偏神经网络训练",
        "摘要翻译": "形状和纹理是识别物体的两个显著且互补的线索。然而，卷积神经网络往往偏向于纹理或形状，这取决于训练数据集。我们的消融研究表明，这种偏差会降低模型性能。基于这一观察，我们开发了一种简单的形状-纹理去偏学习算法。为了防止模型在表示学习中仅关注单一线索，我们通过添加具有冲突形状和纹理信息的图像（例如，具有黑猩猩形状但带有柠檬纹理的图像）来增强训练数据，并且最重要的是，同时提供来自形状和纹理的相应监督。实验表明，我们的方法成功提高了在几个图像识别基准和对抗鲁棒性上的模型性能。例如，通过在ImageNet上训练，它帮助ResNet-152在ImageNet（+1.2%）、ImageNet-A（+5.2%）、ImageNet-C（+8.3%）和Stylized-ImageNet（+11.1%）上实现了显著改进，并在防御ImageNet上的FGSM对抗攻击者时（+14.4%）表现出色。我们的方法还声称与其他高级数据增强策略兼容，例如Mixup和CutMix。代码可在此处获取：https://github.com/LiYingwei/ShapeTextureDebiasedTraining。",
        "领域": "图像识别、对抗鲁棒性、数据增强",
        "问题": "解决卷积神经网络在训练过程中对形状或纹理的偏向问题，以提高模型性能和对抗鲁棒性。",
        "动机": "观察到卷积神经网络在表示学习中往往偏向于单一线索（形状或纹理），这种偏差会降低模型性能，因此开发了一种去偏学习算法。",
        "方法": "通过添加具有冲突形状和纹理信息的图像增强训练数据，并同时提供来自形状和纹理的监督，以实现形状-纹理去偏学习。",
        "关键词": [
            "形状-纹理去偏",
            "图像识别",
            "对抗鲁棒性",
            "数据增强",
            "卷积神经网络"
        ],
        "涉及的技术概念": {
            "形状-纹理去偏": "通过同时考虑形状和纹理信息，减少模型在表示学习中对单一线索的依赖，以提高识别性能。",
            "对抗鲁棒性": "模型在面对对抗攻击时的稳定性和性能保持能力，本文方法显著提高了模型在对抗攻击下的表现。",
            "数据增强": "通过添加具有特定属性的训练数据（如冲突的形状和纹理信息），以增强模型的泛化能力和性能。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 730,
        "title": "Shapley explainability on the data manifold",
        "html": "https://iclr.cc//virtual/2021/poster/2856",
        "abstract": "Explainability in AI is crucial for model development, compliance with regulation, and providing operational nuance to predictions. The Shapley framework for explainability attributes a model’s predictions to its input features in a mathematically principled and model-agnostic way. However, general implementations of Shapley explainability make an untenable assumption: that the model’s features are uncorrelated. In this work, we demonstrate unambiguous drawbacks of this assumption and develop two solutions to Shapley explainability that respect the data manifold. One solution, based on generative modelling, provides flexible access to data imputations; the other directly learns the Shapley value-function, providing performance and stability at the cost of flexibility. While “off-manifold” Shapley values can (i) give rise to incorrect explanations, (ii) hide implicit model dependence on sensitive attributes, and (iii) lead to unintelligible explanations in higher-dimensional data, on-manifold explainability overcomes these problems.\n",
        "conference": "ICLR",
        "中文标题": "数据流形上的Shapley可解释性",
        "摘要翻译": "AI中的可解释性对于模型开发、法规遵从性以及为预测提供操作细节至关重要。Shapley可解释性框架以数学原理和模型无关的方式，将模型的预测归因于其输入特征。然而，Shapley可解释性的一般实现做了一个站不住脚的假设：模型的特征是不相关的。在这项工作中，我们展示了这一假设的明确缺点，并开发了两种尊重数据流形的Shapley可解释性解决方案。一种基于生成模型的解决方案提供了对数据插补的灵活访问；另一种直接学习Shapley值函数，以灵活性为代价提供性能和稳定性。虽然“离流形”Shapley值可能（i）产生不正确的解释，（ii）隐藏模型对敏感属性的隐式依赖，以及（iii）在高维数据中导致难以理解的解释，但“在流形”可解释性克服了这些问题。",
        "领域": "可解释性AI、生成模型、特征相关性分析",
        "问题": "解决Shapley可解释性方法中假设特征不相关导致的解释不准确问题",
        "动机": "提高AI模型预测的可解释性，确保解释的准确性和可靠性，避免因特征相关性假设不成立而导致的错误解释",
        "方法": "开发了两种方法：一种基于生成模型灵活处理数据插补，另一种直接学习Shapley值函数以提高性能和稳定性",
        "关键词": [
            "Shapley可解释性",
            "数据流形",
            "生成模型",
            "特征相关性",
            "模型解释"
        ],
        "涉及的技术概念": {
            "Shapley可解释性框架": "一种将模型预测归因于输入特征的数学原理和模型无关的方法",
            "数据流形": "指数据在特征空间中的几何结构，尊重数据流形意味着在解释时考虑数据的实际分布和特征间的相关性",
            "生成模型": "用于模拟数据生成过程的模型，这里用于提供对数据插补的灵活访问，以支持更准确的Shapley值计算"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 731,
        "title": "Shapley Explanation Networks",
        "html": "https://iclr.cc//virtual/2021/poster/3172",
        "abstract": "Shapley values have become one of the most popular feature attribution explanation methods. However, most prior work has focused on post-hoc Shapley explanations, which can be computationally demanding due to its exponential time complexity and preclude model regularization based on Shapley explanations during training. Thus, we propose to incorporate Shapley values themselves as latent representations in deep models thereby making Shapley explanations first-class citizens in the modeling paradigm. This intrinsic explanation approach enables layer-wise explanations, explanation regularization of the model during training, and fast explanation computation at test time. We define the Shapley transform that transforms the input into a Shapley representation given a specific function. We operationalize the Shapley transform as a neural network module and construct both shallow and deep networks, called ShapNets, by composing Shapley modules. We prove that our Shallow ShapNets compute the exact Shapley values and our Deep ShapNets maintain the missingness and accuracy properties of Shapley values. We demonstrate on synthetic and real-world datasets that our ShapNets enable layer-wise Shapley explanations, novel Shapley regularizations during training, and fast computation while maintaining reasonable performance. Code is available at https://github.com/inouye-lab/ShapleyExplanationNetworks.",
        "conference": "ICLR",
        "中文标题": "沙普利解释网络",
        "摘要翻译": "沙普利值已成为最受欢迎的特征归因解释方法之一。然而，大多数先前的工作集中在事后沙普利解释上，由于其指数时间复杂度，计算需求大，并且在训练过程中排除了基于沙普利解释的模型正则化。因此，我们提出将沙普利值本身作为深度模型中的潜在表示，从而使沙普利解释成为建模范式中的一等公民。这种内在解释方法支持分层解释、训练期间的模型解释正则化以及测试时的快速解释计算。我们定义了沙普利变换，该变换在给定特定函数的情况下将输入转换为沙普利表示。我们将沙普利变换操作化为神经网络模块，并通过组合沙普利模块构建了浅层和深层网络，称为ShapNets。我们证明了我们的浅层ShapNets计算了精确的沙普利值，而我们的深层ShapNets保持了沙普利值的缺失性和准确性属性。我们在合成和真实世界数据集上展示了我们的ShapNets能够实现分层沙普利解释、训练期间的新颖沙普利正则化以及快速计算，同时保持合理的性能。代码可在https://github.com/inouye-lab/ShapleyExplanationNetworks获取。",
        "领域": "可解释人工智能、深度学习、特征归因",
        "问题": "如何高效地将沙普利值整合到深度学习模型中，以支持模型训练期间的正则化和快速解释计算。",
        "动机": "解决现有沙普利解释方法计算成本高、无法在模型训练过程中进行正则化的问题。",
        "方法": "提出将沙普利值作为深度模型中的潜在表示，定义并实现沙普利变换作为神经网络模块，构建浅层和深层ShapNets。",
        "关键词": [
            "沙普利值",
            "可解释性",
            "深度学习",
            "特征归因",
            "神经网络"
        ],
        "涉及的技术概念": {
            "沙普利值": "用于特征归因的解释方法，衡量每个特征对模型预测的贡献。",
            "沙普利变换": "将输入数据转换为沙普利表示的函数，作为神经网络模块实现。",
            "ShapNets": "通过组合沙普利模块构建的神经网络，支持分层解释和训练正则化。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 732,
        "title": "Share or Not? Learning to Schedule Language-Specific Capacity for Multilingual Translation",
        "html": "https://iclr.cc//virtual/2021/poster/3193",
        "abstract": "Using a mix of shared and language-specific (LS) parameters has shown promise in multilingual neural machine  translation (MNMT), but the question of when and where LS capacity matters most is still under-studied. We offer such a study by proposing conditional language-specific routing (CLSR). CLSR employs hard binary gates conditioned on token representations to dynamically select LS or shared paths. By manipulating these gates, it can schedule LS capacity across sub-layers in MNMT subject to the guidance of translation signals and budget constraints. Moreover, CLSR can easily scale up to massively multilingual settings. Experiments with Transformer on OPUS-100 and WMT datasets show that: 1) MNMT is sensitive to both the amount and the position of LS modeling: distributing 10%-30% LS computation to the top and/or bottom encoder/decoder layers delivers the best performance; and 2) one-to-many translation benefits more from CLSR compared to many-to-one translation, particularly with unbalanced training data. Our study further verifies the trade-off between the shared capacity and LS capacity for multilingual translation. We corroborate our analysis by confirming the soundness of our findings as foundation of our improved multilingual Transformers. Source code and models are available at https://github.com/googleinterns/cct-m4.",
        "conference": "ICLR",
        "中文标题": "共享与否？学习为多语言翻译安排语言特定容量",
        "摘要翻译": "在 multilingual neural machine translation (MNMT) 中，使用共享和语言特定（LS）参数的混合已经显示出前景，但关于何时何地LS容量最为重要的问题仍未充分研究。我们通过提出条件语言特定路由（CLSR）来进行这样的研究。CLSR利用基于令牌表示的硬二元门来动态选择LS或共享路径。通过操纵这些门，它可以根据翻译信号和预算约束的指导，在MNMT的子层之间安排LS容量。此外，CLSR可以轻松扩展到大规模多语言设置。在OPUS-100和WMT数据集上使用Transformer进行的实验表明：1）MNMT对LS建模的数量和位置都很敏感：将10%-30%的LS计算分配到编码器/解码器的顶部和/或底部层提供了最佳性能；2）与多对一翻译相比，一对多翻译从CLSR中获益更多，特别是在训练数据不平衡的情况下。我们的研究进一步验证了多语言翻译中共享容量和LS容量之间的权衡。我们通过确认我们发现的合理性作为我们改进的多语言Transformers的基础来证实我们的分析。源代码和模型可在https://github.com/googleinterns/cct-m4获取。",
        "领域": "多语言神经机器翻译",
        "问题": "研究在多语言神经机器翻译中，何时何地使用语言特定（LS）参数最为有效",
        "动机": "探索在多语言神经机器翻译中优化语言特定参数的使用，以提高翻译性能",
        "方法": "提出条件语言特定路由（CLSR），通过动态选择LS或共享路径来安排LS容量",
        "关键词": [
            "多语言神经机器翻译",
            "条件语言特定路由",
            "Transformer模型"
        ],
        "涉及的技术概念": {
            "条件语言特定路由（CLSR）": "一种动态选择LS或共享路径的技术，用于在多语言神经机器翻译中优化语言特定参数的使用",
            "硬二元门": "基于令牌表示的机制，用于在CLSR中动态选择路径",
            "多语言Transformers": "改进的Transformer模型，用于多语言神经机器翻译，优化了共享和语言特定容量的使用"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 733,
        "title": "Sharper Generalization Bounds for Learning with Gradient-dominated Objective Functions",
        "html": "https://iclr.cc//virtual/2021/poster/3141",
        "abstract": "Stochastic optimization has become the workhorse behind many successful machine learning applications, which motivates a lot of theoretical analysis to understand its empirical behavior. As a comparison, there is far less work to study the generalization behavior especially in a non-convex learning setting. In this paper, we study the generalization behavior of stochastic optimization by leveraging the algorithmic stability for learning with $\\beta$-gradient-dominated objective functions. We develop generalization bounds of the order $O(1/(n\\beta))$ plus the convergence rate of the optimization algorithm, where $n$ is the sample size. Our stability analysis significantly improves the existing non-convex analysis by removing the bounded gradient assumption and implying better generalization bounds. We achieve this improvement by exploiting the smoothness of loss functions instead of the Lipschitz condition in Charles & Papailiopoulos (2018). We apply our general results to various stochastic optimization algorithms, which show clearly how the variance-reduction techniques improve not only training but also generalization. Furthermore, our discussion explains how interpolation helps generalization for highly expressive models.",
        "conference": "ICLR",
        "中文标题": "梯度主导目标函数学习中更尖锐的泛化界限",
        "摘要翻译": "随机优化已成为许多成功机器学习应用背后的主力军，这激发了大量理论分析以理解其经验行为。相比之下，研究泛化行为的作品要少得多，尤其是在非凸学习设置中。在本文中，我们通过利用算法稳定性来研究随机优化的泛化行为，用于学习具有β-梯度主导目标函数的模型。我们开发了阶为O(1/(nβ))加上优化算法收敛速率的泛化界限，其中n是样本大小。我们的稳定性分析通过移除有界梯度假设并暗示更好的泛化界限，显著改进了现有的非凸分析。我们通过利用损失函数的平滑性而非Charles & Papailiopoulos (2018)中的Lipschitz条件来实现这一改进。我们将一般结果应用于各种随机优化算法，清楚地展示了方差减少技术如何不仅改善训练而且改善泛化。此外，我们的讨论解释了插值如何帮助高度表达模型的泛化。",
        "领域": "随机优化、非凸学习、泛化理论",
        "问题": "研究随机优化在非凸学习设置中的泛化行为",
        "动机": "理解随机优化在机器学习应用中的成功背后的理论原因，尤其是在非凸学习设置中泛化行为的不足",
        "方法": "利用算法稳定性分析，开发基于β-梯度主导目标函数的泛化界限，并通过损失函数的平滑性改进现有分析",
        "关键词": [
            "随机优化",
            "泛化界限",
            "非凸学习",
            "算法稳定性",
            "方差减少"
        ],
        "涉及的技术概念": {
            "β-梯度主导目标函数": "用于描述目标函数在优化过程中的行为，确保优化算法能够有效收敛",
            "算法稳定性": "分析随机优化算法泛化能力的关键工具，通过衡量算法对输入数据微小变化的敏感性来评估其泛化性能",
            "方差减少技术": "用于减少随机优化算法中的方差，从而不仅加速训练过程，还提高模型的泛化能力"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 734,
        "title": "Sharpness-aware Minimization for Efficiently Improving Generalization",
        "html": "https://iclr.cc//virtual/2021/poster/2782",
        "abstract": "In today's heavily overparameterized models, the value of the training loss provides few guarantees on model generalization ability. Indeed, optimizing only the training loss value, as is commonly done, can easily lead to suboptimal model quality. Motivated by the connection between geometry of the loss landscape and generalization---including a generalization bound that we prove here---we introduce a novel, effective procedure for instead simultaneously minimizing loss value and loss sharpness.  In particular, our procedure, Sharpness-Aware Minimization (SAM), seeks parameters that lie in neighborhoods having uniformly low loss; this formulation results in a min-max optimization problem on which gradient descent can be performed efficiently. We present empirical results showing that SAM improves model generalization across a variety of benchmark datasets (e.g., CIFAR-{10, 100}, ImageNet, finetuning tasks) and models, yielding novel state-of-the-art performance for several.  Additionally, we find that SAM natively provides robustness to label noise on par with that provided by state-of-the-art procedures that specifically target learning with noisy labels.",
        "conference": "ICLR",
        "中文标题": "锐度感知最小化：高效提升泛化能力",
        "摘要翻译": "在当今高度过参数化的模型中，训练损失的值对模型泛化能力的保证很少。事实上，如通常所做的那样，仅优化训练损失值很容易导致模型质量不佳。受到损失景观几何与泛化之间联系的启发——包括我们在此证明的一个泛化边界——我们引入了一种新颖、有效的程序，以同时最小化损失值和损失锐度。特别是，我们的程序，锐度感知最小化（SAM），寻求位于具有均匀低损失的邻域中的参数；这一表述导致了一个可以高效执行梯度下降的极小极大优化问题。我们展示了实证结果，表明SAM在各种基准数据集（例如，CIFAR-{10, 100}，ImageNet，微调任务）和模型上改善了模型的泛化能力，为几个任务提供了新的最先进性能。此外，我们发现SAM天然提供了与专门针对带有噪声标签学习的最先进程序相媲美的标签噪声鲁棒性。",
        "领域": "深度学习优化、模型泛化、标签噪声鲁棒性",
        "问题": "在过参数化模型中，仅优化训练损失值容易导致泛化能力不足的问题",
        "动机": "探索损失景观几何与模型泛化能力之间的关系，提出一种同时优化损失值和损失锐度的方法以提高模型泛化能力",
        "方法": "提出锐度感知最小化（SAM）方法，通过寻找位于低损失邻域的参数，解决极小极大优化问题，以提高模型泛化能力",
        "关键词": [
            "锐度感知最小化",
            "模型泛化",
            "损失景观",
            "过参数化模型",
            "标签噪声鲁棒性"
        ],
        "涉及的技术概念": {
            "锐度感知最小化（SAM）": "一种同时最小化损失值和损失锐度的优化方法，旨在提高模型的泛化能力",
            "损失景观": "描述损失函数在不同参数值下的表现，与模型的泛化能力密切相关",
            "极小极大优化问题": "SAM方法通过解决这类问题来寻找在低损失邻域中的参数，以实现更好的泛化性能"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 735,
        "title": "Signatory: differentiable computations of the signature and logsignature transforms, on both CPU and GPU",
        "html": "https://iclr.cc//virtual/2021/poster/2566",
        "abstract": "Signatory is a library for calculating and performing functionality related to the signature and logsignature transforms. The focus is on machine learning, and as such includes features such as CPU parallelism, GPU support, and backpropagation. To our knowledge it is the first GPU-capable library for these operations. Signatory implements new features not available in previous libraries, such as efficient precomputation strategies. Furthermore, several novel algorithmic improvements are introduced, producing substantial real-world speedups even on the CPU without parallelism. The library operates as a Python wrapper around C++, and is compatible with the PyTorch ecosystem. It may be installed directly via \\texttt{pip}. Source code, documentation, examples, benchmarks and tests may be found at \\texttt{\\url{https://github.com/patrick-kidger/signatory}}. The license is Apache-2.0.",
        "conference": "ICLR",
        "中文标题": "Signatory：在CPU和GPU上可微分计算签名和对数签名变换",
        "摘要翻译": "Signatory是一个用于计算和执行与签名及对数签名变换相关功能的库。其重点在于机器学习，因此包含了诸如CPU并行、GPU支持以及反向传播等功能。据我们所知，它是第一个支持这些操作的GPU能力库。Signatory实现了之前库中不可用的新特性，如高效的预计算策略。此外，引入了若干新颖的算法改进，即使在非并行的CPU上也能实现显著的现实世界加速。该库作为围绕C++的Python包装器运行，并与PyTorch生态系统兼容。它可以直接通过pip安装。源代码、文档、示例、基准测试和测试可以在https://github.com/patrick-kidger/signatory找到。许可证为Apache-2.0。",
        "领域": "机器学习库开发、GPU加速计算、深度学习工具链",
        "问题": "提供高效的签名和对数签名变换计算，支持GPU加速和机器学习应用",
        "动机": "开发一个支持GPU加速的签名和对数签名变换库，填补现有库在性能和功能上的不足",
        "方法": "通过C++和Python的结合实现高效的预计算策略和算法改进，支持CPU并行和GPU加速",
        "关键词": [
            "签名变换",
            "对数签名变换",
            "GPU加速",
            "机器学习库",
            "PyTorch兼容"
        ],
        "涉及的技术概念": {
            "签名变换": "用于捕捉路径数据的特征，广泛应用于机器学习和数据分析",
            "对数签名变换": "签名变换的压缩表示，减少特征维度同时保留重要信息",
            "GPU加速": "利用图形处理单元进行并行计算，显著提高计算效率"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 736,
        "title": "Simple Augmentation Goes a Long Way: ADRL for DNN Quantization",
        "html": "https://iclr.cc//virtual/2021/poster/3162",
        "abstract": "Mixed precision quantization improves DNN performance by assigning different layers with different bit-width values. Searching for the optimal bit-width for each layer, however, remains a challenge. Deep Reinforcement Learning (DRL) shows some recent promise. It however suffers instability due to function approximation errors, causing large variances in the early training stages, slow convergence, and suboptimal policies in the mixed-precision quantization problem. This paper proposes augmented DRL (ADRL) as a way to alleviate these issues. This new strategy augments the neural networks in DRL with a complementary scheme to boost the performance of learning. The paper examines the effectiveness of ADRL both analytically and empirically, showing that it can produce more accurate quantized models than the state of the art DRL-based quantization while improving the learning speed by 4.5-64 times. ",
        "conference": "ICLR",
        "中文标题": "简单增强大有裨益：用于深度神经网络量化的增强深度强化学习",
        "摘要翻译": "混合精度量化通过为不同层分配不同的位宽值来提高深度神经网络（DNN）的性能。然而，为每一层寻找最优位宽仍然是一个挑战。深度强化学习（DRL）最近显示出一些前景。但由于函数逼近误差，它存在不稳定性，导致在早期训练阶段方差大、收敛慢以及在混合精度量化问题中的策略次优。本文提出增强深度强化学习（ADRL）作为缓解这些问题的方法。这一新策略通过补充方案增强DRL中的神经网络，以提高学习性能。本文通过分析和实证检验了ADRL的有效性，表明它能够比基于DRL的最先进量化方法产生更精确的量化模型，同时将学习速度提高4.5至64倍。",
        "领域": "神经网络量化、深度强化学习、混合精度计算",
        "问题": "在深度神经网络量化中，如何高效地为每一层寻找最优位宽，同时解决深度强化学习在量化过程中的不稳定性和收敛慢的问题。",
        "动机": "深度强化学习在混合精度量化中显示出潜力，但由于函数逼近误差导致的不稳定性、早期训练阶段的大方差、慢收敛和次优策略，限制了其应用效果。",
        "方法": "提出增强深度强化学习（ADRL），通过补充方案增强DRL中的神经网络，以提高学习性能和稳定性。",
        "关键词": [
            "混合精度量化",
            "深度强化学习",
            "神经网络增强",
            "学习速度优化",
            "量化模型精度"
        ],
        "涉及的技术概念": {
            "混合精度量化": "通过为神经网络的不同层分配不同的位宽值，以提高模型性能和效率的技术。",
            "深度强化学习（DRL）": "一种结合深度学习和强化学习的方法，用于解决复杂的决策问题，如神经网络量化中的位宽分配。",
            "增强深度强化学习（ADRL）": "本文提出的方法，通过增强DRL中的神经网络，提高学习速度和量化模型的精度，解决DRL在量化过程中的不稳定性和收敛慢的问题。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 737,
        "title": "Simple Spectral Graph Convolution",
        "html": "https://iclr.cc//virtual/2021/poster/3377",
        "abstract": "Graph Convolutional Networks (GCNs) are leading methods for learning graph representations. However, without specially designed architectures, the performance of GCNs degrades quickly with increased depth. As the aggregated neighborhood size and neural network depth are two completely orthogonal aspects of graph representation, several methods focus on summarizing the neighborhood by aggregating K-hop neighborhoods of nodes while using shallow neural networks. However, these methods still encounter oversmoothing, and suffer from high computation and storage costs. In this paper, we use a modified Markov Diffusion Kernel to derive a variant of GCN called Simple Spectral Graph Convolution (SSGC). Our spectral analysis shows that our simple spectral graph convolution used in SSGC is a trade-off of low- and high-pass filter bands which capture the global and local contexts of each node. We provide two theoretical claims which demonstrate that we can aggregate over a sequence of increasingly larger neighborhoods compared to competitors while limiting severe oversmoothing.  Our experimental evaluations show that SSGC with a linear learner is competitive in text and node classification tasks. Moreover, SSGC is comparable to other state-of-the-art methods for node clustering and community prediction tasks.",
        "conference": "ICLR",
        "中文标题": "简单谱图卷积",
        "摘要翻译": "图卷积网络（GCNs）是学习图表示的主要方法。然而，如果没有特别设计的架构，GCNs的性能会随着深度的增加而迅速下降。由于聚合邻域大小和神经网络深度是图表示的两个完全正交的方面，几种方法通过聚合节点的K跳邻域来总结邻域，同时使用浅层神经网络。然而，这些方法仍然会遇到过度平滑的问题，并且遭受高计算和存储成本的困扰。在本文中，我们使用改进的马尔可夫扩散核来推导出一种称为简单谱图卷积（SSGC）的GCN变体。我们的谱分析表明，SSGC中使用的简单谱图卷积是低通和高通滤波器带的折衷，捕捉了每个节点的全局和局部上下文。我们提供了两个理论主张，证明与竞争对手相比，我们可以在限制严重过度平滑的同时，聚合一系列越来越大的邻域。我们的实验评估表明，带有线性学习器的SSGC在文本和节点分类任务中具有竞争力。此外，SSGC在节点聚类和社区预测任务中与其他最先进的方法相当。",
        "领域": "图神经网络、节点分类、社区检测",
        "问题": "解决图卷积网络在深度增加时性能下降和过度平滑的问题",
        "动机": "提高图卷积网络在处理大规模图数据时的效率和性能，同时减少过度平滑现象",
        "方法": "使用改进的马尔可夫扩散核推导出简单谱图卷积（SSGC），通过平衡低通和高通滤波器带捕捉节点的全局和局部上下文",
        "关键词": [
            "图卷积网络",
            "谱图卷积",
            "节点分类",
            "社区预测",
            "过度平滑"
        ],
        "涉及的技术概念": {
            "马尔可夫扩散核": "用于推导SSGC，帮助捕捉图数据的全局和局部特征",
            "低通和高通滤波器带": "在SSGC中用于平衡捕捉节点的全局和局部上下文",
            "过度平滑": "图卷积网络中的一种现象，SSGC通过理论主张和实验评估来限制这一现象"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 738,
        "title": "Single-Photon Image Classification",
        "html": "https://iclr.cc//virtual/2021/poster/3024",
        "abstract": "Quantum Computing based Machine Learning mainly focuses on quantum computing hardware that is experimentally challenging to realize due to requiring quantum gates that operate at very low temperature. We demonstrate the existence of a 'quantum computing toy model' that illustrates key aspects of quantum information processing while being experimentally accessible with room temperature optics. Pondering the question of the theoretical classification accuracy performance limit for MNIST (respectively 'Fashion-MNIST') classifiers, subject to the constraint that a decision has to be made after detection of the very first photon that passed through an image-filter, we show that a machine learning system that is permitted to use quantum interference on the photon's state can substantially outperform any machine learning system that can not.  Specifically, we prove that a 'classical' MNIST (respectively 'Fashion-MNIST') classifier cannot achieve an accuracy of better than $21.28\\%$ (respectively $18.28\\%$ for 'Fashion-MNIST') if it must make a decision after seeing a single photon falling on one of the $28\\times 28$ image pixels of a detector array.  We further demonstrate that a classifier that is permitted to employ quantum interference by optically transforming the photon state prior to detection can achieve a classification accuracy of at least $41.27\\%$ for MNIST (respectively $36.14\\%$ for 'Fashion-MNIST'). We show in detail how to train the corresponding quantum state transformation with TensorFlow and also explain how this example can serve as a teaching tool for the measurement process in quantum mechanics.\n",
        "conference": "ICLR",
        "中文标题": "单光子图像分类",
        "摘要翻译": "基于量子计算的机器学习主要关注于量子计算硬件，这些硬件由于需要在极低温度下操作的量子门而实验上难以实现。我们展示了一个‘量子计算玩具模型’的存在，该模型在实验上可通过室温光学实现，同时阐释了量子信息处理的关键方面。思考在必须通过检测穿过图像滤波器的第一个光子后做出决策的约束下，MNIST（或‘Fashion-MNIST’）分类器的理论分类准确率性能极限问题时，我们展示了允许在光子状态上使用量子干涉的机器学习系统可以显著优于任何不能使用量子干涉的系统。具体来说，我们证明了如果‘经典’MNIST（或‘Fashion-MNIST’）分类器必须在检测到单个光子落在检测器阵列的28×28图像像素之一后做出决策，则其准确率不能超过21.28%（对于‘Fashion-MNIST’为18.28%）。我们进一步展示了允许通过光学转换光子状态在检测前使用量子干涉的分类器，对于MNIST至少可以达到41.27%的分类准确率（对于‘Fashion-MNIST’为36.14%）。我们详细展示了如何使用TensorFlow训练相应的量子状态转换，并解释了此示例如何作为量子力学中测量过程的教学工具。",
        "领域": "量子机器学习、图像分类、量子光学",
        "问题": "在单光子检测约束下，提高图像分类的准确率",
        "动机": "探索在量子计算硬件难以实现的条件下，通过量子干涉提升图像分类性能的可能性",
        "方法": "利用量子干涉和光学转换光子状态，结合TensorFlow进行量子状态转换的训练",
        "关键词": [
            "单光子图像分类",
            "量子干涉",
            "量子机器学习",
            "TensorFlow",
            "量子光学"
        ],
        "涉及的技术概念": {
            "量子干涉": "用于在光子状态上实现信息处理，提升分类准确率",
            "量子计算玩具模型": "在室温下通过光学实现，用于阐释量子信息处理的关键方面",
            "TensorFlow": "用于训练量子状态转换，实现分类器的优化"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 739,
        "title": "Single-Timescale Actor-Critic Provably Finds Globally Optimal Policy",
        "html": "https://iclr.cc//virtual/2021/poster/2740",
        "abstract": "We study the global convergence and global optimality of actor-critic, one of the most popular families of reinforcement learning algorithms. While most existing works on actor-critic employ bi-level or two-timescale updates, we focus on the more practical single-timescale setting, where the actor and critic are updated simultaneously. Specifically, in each iteration, the critic update is obtained by applying the Bellman evaluation operator only once while the actor is updated in the policy gradient direction computed using the critic. Moreover, we consider two function approximation settings where both the actor and critic are represented by linear or deep neural networks. For both cases, we prove that the actor sequence converges to a globally optimal policy at a sublinear $O(K^{-1/2})$ rate, where $K$ is the number of iterations. To the best of our knowledge, we establish the rate of convergence and global optimality of single-timescale actor-critic with linear function approximation for the first time. Moreover, under the broader scope of policy optimization with nonlinear function approximation, we prove that actor-critic with deep neural network finds the globally optimal policy at a sublinear rate for the first time. ",
        "conference": "ICLR",
        "中文标题": "单时间尺度演员-评论家算法可证明找到全局最优策略",
        "摘要翻译": "我们研究了演员-评论家算法（强化学习中最流行的算法家族之一）的全局收敛性和全局最优性。虽然大多数现有关于演员-评论家的工作采用双层或双时间尺度更新，但我们关注更实用的单时间尺度设置，其中演员和评论家同时更新。具体来说，在每次迭代中，评论家更新通过仅应用一次贝尔曼评估算子获得，而演员则使用评论家计算出的策略梯度方向进行更新。此外，我们考虑了两种函数逼近设置，其中演员和评论家都由线性或深度神经网络表示。对于这两种情况，我们证明了演员序列以次线性$O(K^{-1/2})$速率收敛到全局最优策略，其中$K$是迭代次数。据我们所知，我们首次建立了具有线性函数逼近的单时间尺度演员-评论家的收敛速率和全局最优性。此外，在非线性函数逼近的策略优化更广泛范围内，我们首次证明了具有深度神经网络的演员-评论家以次线性速率找到全局最优策略。",
        "领域": "强化学习, 策略优化, 深度神经网络",
        "问题": "研究单时间尺度演员-评论家算法在全局收敛性和全局最优性方面的表现",
        "动机": "探索更实用的单时间尺度设置下演员-评论家算法的性能，以解决现有工作中双层或双时间尺度更新方法的局限性",
        "方法": "在单时间尺度设置下，同时更新演员和评论家，使用贝尔曼评估算子进行评论家更新，策略梯度方向进行演员更新，并在线性和深度神经网络两种函数逼近设置下验证算法的性能",
        "关键词": [
            "单时间尺度",
            "演员-评论家",
            "全局最优策略",
            "线性函数逼近",
            "深度神经网络"
        ],
        "涉及的技术概念": {
            "贝尔曼评估算子": "用于在每次迭代中更新评论家，评估当前策略的价值",
            "策略梯度方向": "用于更新演员，指导策略向更优方向调整",
            "次线性收敛速率": "描述了算法收敛到全局最优策略的速度，$O(K^{-1/2})$表示随着迭代次数增加，收敛速度减慢"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 740,
        "title": "SkipW: Resource Adaptable RNN with Strict Upper Computational Limit",
        "html": "https://iclr.cc//virtual/2021/poster/3160",
        "abstract": "We introduce Skip-Window, a method to allow recurrent neural networks (RNNs) to trade off accuracy for computational cost during the analysis of a sequence. Similarly to existing approaches, Skip-Window extends existing RNN cells by adding a mechanism to encourage the model to process fewer inputs. Unlike existing approaches, Skip-Window is able to respect a strict computational budget, making this model more suitable for limited hardware. We evaluate this approach on two datasets: a human activity recognition task and adding task. Our results show that Skip-Window is able to exceed the accuracy of existing approaches for a lower computational cost while strictly limiting said cost.",
        "conference": "ICLR",
        "中文标题": "SkipW：具有严格计算上限的资源适应性循环神经网络",
        "摘要翻译": "我们介绍了Skip-Window方法，该方法允许循环神经网络（RNNs）在序列分析过程中以计算成本为代价换取准确性。与现有方法类似，Skip-Window通过添加一种机制来扩展现有的RNN单元，以鼓励模型处理更少的输入。不同于现有方法，Skip-Window能够严格遵守计算预算，这使得该模型更适合于有限硬件。我们在两个数据集上评估了这一方法：一个人体活动识别任务和加法任务。我们的结果表明，Skip-Window能够在严格限制计算成本的同时，以更低的计算成本超越现有方法的准确性。",
        "领域": "循环神经网络优化、硬件适应性深度学习、序列分析",
        "问题": "如何在严格的计算预算下，使循环神经网络（RNNs）在序列分析中实现计算成本与准确性的平衡。",
        "动机": "开发一种能够在有限硬件资源下有效工作的循环神经网络，同时保持或超越现有方法的准确性。",
        "方法": "通过Skip-Window方法扩展RNN单元，引入机制减少输入处理量，严格遵守计算预算。",
        "关键词": [
            "Skip-Window",
            "循环神经网络",
            "计算预算",
            "硬件适应性",
            "序列分析"
        ],
        "涉及的技术概念": {
            "Skip-Window": "一种扩展RNN单元的方法，通过减少输入处理量来降低计算成本，同时保持模型性能。",
            "循环神经网络（RNNs）": "用于处理序列数据的神经网络，能够捕捉时间序列中的长期依赖关系。",
            "计算预算": "在模型设计和运行过程中设定的最大计算资源限制，确保模型在有限硬件上的可行性。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 741,
        "title": "Sliced Kernelized Stein Discrepancy",
        "html": "https://iclr.cc//virtual/2021/poster/2803",
        "abstract": "Kernelized Stein discrepancy (KSD), though being extensively used in goodness-of-fit tests and model learning, suffers from the curse-of-dimensionality. We address this issue by proposing the sliced Stein discrepancy and its scalable and kernelized variants, which employs kernel-based test functions defined on the optimal one-dimensional projections. When applied to goodness-of-fit tests, extensive experiments show the proposed discrepancy significantly outperforms KSD and various baselines in high dimensions. For model learning, we show its advantages by training an independent component analysis when compared with existing Stein discrepancy baselines. We further propose a novel particle inference method called sliced Stein variational gradient descent (S-SVGD) which alleviates the mode-collapse issue of SVGD in training variational autoencoders.",
        "conference": "ICLR",
        "中文标题": "切片核化斯坦差异",
        "摘要翻译": "核化斯坦差异（KSD）虽然在拟合优度测试和模型学习中被广泛使用，但受到维度诅咒的困扰。我们通过提出切片斯坦差异及其可扩展和核化的变体来解决这个问题，这些变体采用了基于核的测试函数，定义在最优的一维投影上。当应用于拟合优度测试时，大量实验表明，在高维度中，所提出的差异显著优于KSD和各种基线。对于模型学习，我们通过与现有的斯坦差异基线相比，训练独立成分分析来展示其优势。我们进一步提出了一种新的粒子推理方法，称为切片斯坦变分梯度下降（S-SVGD），它缓解了SVGD在训练变分自编码器时的模式崩溃问题。",
        "领域": "变分自编码器、独立成分分析、拟合优度测试",
        "问题": "解决核化斯坦差异在高维度中的性能下降问题",
        "动机": "提高在高维度情况下拟合优度测试和模型学习的效率和准确性",
        "方法": "提出切片斯坦差异及其核化变体，以及切片斯坦变分梯度下降方法",
        "关键词": [
            "切片斯坦差异",
            "核化斯坦差异",
            "拟合优度测试",
            "变分自编码器",
            "独立成分分析"
        ],
        "涉及的技术概念": {
            "切片斯坦差异": "一种改进的斯坦差异，通过在最优一维投影上定义核基测试函数，以解决高维度问题",
            "核化斯坦差异": "传统的斯坦差异方法，使用核函数来衡量两个分布之间的差异",
            "切片斯坦变分梯度下降": "一种新的粒子推理方法，旨在解决SVGD在训练变分自编码器时的模式崩溃问题"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 742,
        "title": "SMiRL: Surprise Minimizing Reinforcement Learning in Unstable Environments",
        "html": "https://iclr.cc//virtual/2021/poster/3047",
        "abstract": "Every living organism struggles against disruptive environmental forces to carve out and maintain an orderly niche. We propose that such a struggle to achieve and preserve order might offer a principle for the emergence of useful behaviors in artificial agents. We formalize this idea into an unsupervised reinforcement learning method called surprise minimizing reinforcement learning (SMiRL). SMiRL alternates between learning a density model to evaluate the surprise of a stimulus, and improving the policy to seek more predictable stimuli. The policy seeks out stable and repeatable situations that counteract the environment's prevailing sources of entropy. This might include avoiding other hostile agents, or finding a stable, balanced pose for a bipedal robot in the face of disturbance forces. We demonstrate that our surprise minimizing agents can successfully play Tetris, Doom, control a humanoid to avoid falls, and navigate to escape enemies in a maze without any task-specific reward supervision. We further show that SMiRL can be used together with standard task rewards to accelerate reward-driven learning.",
        "conference": "ICLR",
        "中文标题": "SMiRL：不稳定环境中的惊喜最小化强化学习",
        "摘要翻译": "每一种生物都在与破坏性的环境力量作斗争，以开辟并维持一个有序的生态位。我们提出，这种实现并保持秩序的斗争可能为人工代理中涌现有用行为提供了一条原则。我们将这一想法形式化为一种名为惊喜最小化强化学习（SMiRL）的无监督强化学习方法。SMiRL在学习一个密度模型以评估刺激的惊喜程度与改进策略以寻求更可预测的刺激之间交替进行。该策略寻找稳定且可重复的情境，以抵消环境中主要的熵源。这可能包括避开其他敌对代理，或为双足机器人在面对干扰力时找到一个稳定、平衡的姿态。我们证明，我们的惊喜最小化代理可以成功地玩俄罗斯方块、毁灭战士，控制人形机器人避免跌倒，并在没有任何任务特定奖励监督的情况下在迷宫中导航逃脱敌人。我们进一步表明，SMiRL可以与标准任务奖励一起使用，以加速奖励驱动的学习。",
        "领域": "强化学习、机器人控制、游戏AI",
        "问题": "如何在无监督的情况下，通过最小化惊喜来引导强化学习代理在动态环境中学习有用的行为。",
        "动机": "探索通过模拟生物对抗环境破坏性力量以维持秩序的行为，为人工代理学习提供新的无监督学习原则。",
        "方法": "提出惊喜最小化强化学习（SMiRL）方法，通过交替学习密度模型评估刺激的惊喜程度和优化策略以寻求更可预测的刺激，来抵消环境中的熵源。",
        "关键词": [
            "惊喜最小化",
            "无监督强化学习",
            "动态环境适应",
            "熵抵消",
            "策略优化"
        ],
        "涉及的技术概念": {
            "惊喜最小化": "通过最小化代理遇到的情境的惊喜程度，引导代理学习在动态环境中维持秩序的行为。",
            "密度模型": "用于评估当前情境的惊喜程度，即情境与已学习模型之间的差异。",
            "策略优化": "调整代理的行为策略，以寻求更可预测和稳定的情境，从而抵消环境中的熵源。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 743,
        "title": "SOLAR: Sparse Orthogonal Learned and Random Embeddings",
        "html": "https://iclr.cc//virtual/2021/poster/3284",
        "abstract": "Dense embedding models are commonly deployed in commercial search engines, wherein all the document vectors are pre-computed, and near-neighbor search (NNS) is performed with the query vector to find relevant documents. However, the bottleneck of indexing a large number of dense vectors and performing an NNS hurts the query time and accuracy of these models. In this paper, we argue that high-dimensional and ultra-sparse embedding is a significantly superior alternative to dense low-dimensional embedding for both query efficiency and accuracy. Extreme sparsity eliminates the need for NNS by replacing them with simple lookups, while its high dimensionality ensures that the embeddings are informative even when sparse. However, learning extremely high dimensional embeddings leads to blow up in the model size. To make the training feasible, we propose a partitioning algorithm that learns such high dimensional embeddings across multiple GPUs without any communication. This is facilitated by our novel asymmetric mixture of Sparse, Orthogonal, Learned and Random (SOLAR) Embeddings. The label vectors are random, sparse, and near-orthogonal by design, while the query vectors are learned and sparse. We theoretically prove that our way of one-sided learning is equivalent to learning both query and label embeddings. With these unique properties, we can successfully train 500K dimensional SOLAR embeddings for the tasks of searching through 1.6M books and multi-label classification on the three largest public datasets. We achieve superior precision and recall compared to the respective state-of-the-art baselines for each task with up to 10 times faster speed.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "SOLAR：稀疏正交学习与随机嵌入",
        "摘要翻译": "在商业搜索引擎中，密集嵌入模型被广泛部署，其中所有文档向量都是预先计算的，并通过查询向量执行近邻搜索（NNS）以找到相关文档。然而，索引大量密集向量和执行NNS的瓶颈影响了这些模型的查询时间和准确性。在本文中，我们认为高维和超稀疏嵌入在查询效率和准确性上都是密集低维嵌入的显著优越替代方案。极端稀疏性通过用简单查找替换NNS来消除其需求，而其高维度确保了即使在稀疏情况下嵌入也是信息丰富的。然而，学习极高维度的嵌入会导致模型大小的爆炸性增长。为了使训练可行，我们提出了一种分区算法，可以在多个GPU上学习这种高维嵌入而无需任何通信。这得益于我们新颖的稀疏、正交、学习和随机（SOLAR）嵌入的非对称混合。标签向量在设计上是随机、稀疏且接近正交的，而查询向量是学习且稀疏的。我们从理论上证明，我们这种单边学习的方式等同于学习查询和标签嵌入。凭借这些独特的属性，我们成功地训练了500K维的SOLAR嵌入，用于搜索160万本书籍的任务以及在三个最大的公共数据集上进行多标签分类。与各自的最先进基线相比，我们在每个任务上都实现了更高的精确度和召回率，速度提高了多达10倍。",
        "领域": "信息检索与多标签分类",
        "问题": "解决密集嵌入模型在索引大量向量和执行近邻搜索时的效率与准确性问题",
        "动机": "探索高维和超稀疏嵌入作为密集低维嵌入的替代方案，以提高查询效率和准确性",
        "方法": "提出一种分区算法和SOLAR嵌入的非对称混合，支持在多个GPU上无通信学习高维稀疏嵌入",
        "关键词": [
            "稀疏嵌入",
            "高维嵌入",
            "信息检索",
            "多标签分类",
            "GPU加速"
        ],
        "涉及的技术概念": {
            "稀疏嵌入": "通过极端稀疏性简化近邻搜索，提高查询效率",
            "正交学习": "确保嵌入向量的正交性，增强嵌入的信息量和区分度",
            "非对称混合": "结合随机稀疏标签向量和学习稀疏查询向量，优化模型训练和性能"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 744,
        "title": "Solving Compositional Reinforcement Learning Problems via Task Reduction",
        "html": "https://iclr.cc//virtual/2021/poster/3368",
        "abstract": "We propose a novel learning paradigm, Self-Imitation via Reduction (SIR), for solving compositional reinforcement learning problems. SIR is based on two core ideas: task reduction and self-imitation. Task reduction tackles a hard-to-solve task by actively reducing it to an easier task whose solution is known by the RL agent. Once the original hard task is successfully solved by task reduction, the agent naturally obtains a self-generated solution trajectory to imitate. By continuously collecting and imitating such demonstrations, the agent is able to progressively expand the solved subspace in the entire task space. Experiment results show that SIR can significantly accelerate and improve learning on a variety of challenging sparse-reward continuous-control problems with compositional structures. Code and videos are available at https://sites.google.com/view/sir-compositional.",
        "conference": "ICLR",
        "中文标题": "通过任务简化解决组合式强化学习问题",
        "摘要翻译": "我们提出了一种新颖的学习范式——通过简化的自我模仿（SIR），用于解决组合式强化学习问题。SIR基于两个核心理念：任务简化和自我模仿。任务简化通过主动将一个难以解决的任务简化为强化学习代理已知解决方案的更容易任务来应对。一旦原始困难任务通过任务简化成功解决，代理自然获得了一个自我生成的解决方案轨迹以供模仿。通过不断收集和模仿这些示范，代理能够逐步扩大在整个任务空间中已解决的子空间。实验结果表明，SIR能够在多种具有组合结构的挑战性稀疏奖励连续控制问题上显著加速和改善学习。代码和视频可在https://sites.google.com/view/sir-compositional获取。",
        "领域": "强化学习、连续控制、组合任务学习",
        "问题": "解决组合式强化学习中的困难任务",
        "动机": "通过任务简化和自我模仿，提高强化学习代理在组合式任务中的学习效率和效果",
        "方法": "提出SIR学习范式，结合任务简化和自我模仿，逐步扩大已解决任务子空间",
        "关键词": [
            "组合式强化学习",
            "任务简化",
            "自我模仿",
            "连续控制",
            "稀疏奖励"
        ],
        "涉及的技术概念": {
            "任务简化": "将复杂任务简化为代理已知解决方案的简单任务，以促进学习",
            "自我模仿": "代理模仿自己生成的解决方案轨迹，以提高学习效率",
            "稀疏奖励": "在强化学习中，奖励信号稀少，增加了学习的难度"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 745,
        "title": "Sparse encoding for more-interpretable feature-selecting representations in probabilistic matrix factorization",
        "html": "https://iclr.cc//virtual/2021/poster/3262",
        "abstract": "Dimensionality reduction methods for count data are critical to a wide range of applications in medical informatics and other fields where model interpretability is paramount. For such data, hierarchical Poisson matrix factorization (HPF) and other sparse probabilistic non-negative matrix factorization (NMF) methods are considered to be interpretable generative models. They consist of sparse transformations for decoding their learned representations into predictions. However, sparsity in representation decoding does not necessarily imply sparsity in the encoding of representations from the original data features.  HPF is often incorrectly interpreted in the literature as if it possesses encoder sparsity. The distinction between decoder sparsity and encoder sparsity is subtle but important. Due to the lack of encoder sparsity, HPF does not possess the column-clustering property of classical NMF -- the factor loading matrix does not sufficiently define how each factor is formed from the original features. We address this deficiency by self-consistently enforcing encoder sparsity, using a generalized additive model  (GAM), thereby allowing one to relate each representation coordinate to a subset of the original data features. In doing so, the method also gains the ability to perform feature selection. We demonstrate our method on simulated data and give an example of how encoder sparsity is of practical use in a concrete application of representing inpatient comorbidities in Medicare patients.",
        "conference": "ICLR",
        "中文标题": "稀疏编码在概率矩阵分解中实现更具解释性的特征选择表示",
        "摘要翻译": "对于计数数据的降维方法在医学信息学及其他模型可解释性至关重要的领域中有着广泛的应用。对于此类数据，层次泊松矩阵分解（HPF）及其他稀疏概率非负矩阵分解（NMF）方法被认为是可解释的生成模型。它们包含稀疏变换，用于将学习到的表示解码为预测。然而，表示解码中的稀疏性并不一定意味着从原始数据特征编码表示时的稀疏性。HPF在文献中经常被错误地解释为具有编码稀疏性。解码稀疏性与编码稀疏性之间的区别虽微妙但重要。由于缺乏编码稀疏性，HPF不具备经典NMF的列聚类特性——因子载荷矩阵并未充分定义每个因子是如何从原始特征形成的。我们通过使用广义加性模型（GAM）自洽地强制编码稀疏性来解决这一不足，从而允许将每个表示坐标与原始数据特征的子集相关联。在此过程中，该方法还获得了执行特征选择的能力。我们在模拟数据上展示了我们的方法，并举例说明了编码稀疏性在表示医疗保险患者住院并发症的具体应用中的实际用途。",
        "领域": "非负矩阵分解",
        "问题": "解决概率矩阵分解中编码稀疏性不足的问题，以提高模型的可解释性和特征选择能力",
        "动机": "提升模型的可解释性，特别是在需要明确理解每个表示坐标如何与原始数据特征相关联的应用场景中",
        "方法": "通过广义加性模型（GAM）自洽地强制编码稀疏性，实现特征选择和提升模型的可解释性",
        "关键词": [
            "稀疏编码",
            "概率矩阵分解",
            "特征选择",
            "广义加性模型",
            "可解释性"
        ],
        "涉及的技术概念": {
            "层次泊松矩阵分解（HPF）": "一种用于计数数据的稀疏概率非负矩阵分解方法，被认为是可解释的生成模型",
            "广义加性模型（GAM）": "用于自洽地强制编码稀疏性，允许将每个表示坐标与原始数据特征的子集相关联",
            "编码稀疏性": "指从原始数据特征编码表示时的稀疏性，对于提升模型的可解释性和特征选择能力至关重要"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 746,
        "title": "Sparse Quantized Spectral Clustering",
        "html": "https://iclr.cc//virtual/2021/poster/2523",
        "abstract": "Given a large data matrix, sparsifying, quantizing, and/or performing other entry-wise nonlinear operations can have numerous benefits, ranging from speeding up iterative algorithms for core numerical linear algebra problems to providing nonlinear filters to design state-of-the-art neural network models. Here, we exploit tools from random matrix theory to make precise statements about how the eigenspectrum of a matrix changes under such nonlinear transformations. In particular, we show that very little change occurs in the informative eigenstructure, even under drastic sparsification/quantization, and consequently that very little downstream performance loss occurs when working with very aggressively sparsified or quantized spectral clustering problems.\nWe illustrate how these results depend on the nonlinearity, we characterize a phase transition beyond which spectral clustering becomes possible, and we show when such nonlinear transformations can introduce spurious non-informative eigenvectors.",
        "conference": "ICLR",
        "中文标题": "稀疏量化谱聚类",
        "摘要翻译": "给定一个大型数据矩阵，稀疏化、量化以及/或执行其他逐项非线性操作可以带来诸多好处，范围从加速核心数值线性代数问题的迭代算法，到提供非线性滤波器以设计最先进的神经网络模型。在此，我们利用随机矩阵理论的工具，精确描述矩阵的特征谱在这些非线性变换下如何变化。特别是，我们展示了即使在极端稀疏化/量化的情况下，信息性特征结构的变化也非常小，因此在使用非常激进的稀疏化或量化谱聚类问题时，下游性能损失非常小。我们说明了这些结果如何依赖于非线性，我们描述了一个相变，超过这个相变谱聚类成为可能，并且我们展示了这些非线性变换何时可以引入虚假的非信息性特征向量。",
        "领域": "谱聚类、数据稀疏化、非线性变换",
        "问题": "如何在极端稀疏化和量化条件下保持谱聚类的性能",
        "动机": "探索在数据矩阵进行非线性变换（如稀疏化和量化）后，如何保持或最小化谱聚类性能的损失",
        "方法": "利用随机矩阵理论分析非线性变换对矩阵特征谱的影响，并研究这些变换对谱聚类性能的影响",
        "关键词": [
            "谱聚类",
            "稀疏化",
            "量化",
            "随机矩阵理论",
            "非线性变换"
        ],
        "涉及的技术概念": {
            "随机矩阵理论": "用于分析非线性变换对矩阵特征谱影响的数学工具",
            "稀疏化": "减少数据矩阵中非零元素的数量，以加速计算或减少存储需求",
            "量化": "将数据矩阵中的元素转换为有限的离散值，以减少存储需求或加速计算"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 747,
        "title": "Spatial Dependency Networks: Neural Layers for Improved Generative Image Modeling",
        "html": "https://iclr.cc//virtual/2021/poster/3133",
        "abstract": "How to improve generative modeling by better exploiting spatial regularities and coherence in images? We introduce a novel neural network for building image generators (decoders) and apply it to variational autoencoders (VAEs). In our spatial dependency networks (SDNs), feature maps at each level of a deep neural net are computed in a spatially coherent way, using a sequential gating-based mechanism that distributes contextual information across 2-D space. We show that augmenting the decoder of a hierarchical VAE by spatial dependency layers considerably improves density estimation over baseline convolutional architectures and the state-of-the-art among the models within the same class. Furthermore, we demonstrate that SDN can be applied to large images by synthesizing samples of high quality and coherence. In a vanilla VAE setting, we find that a powerful SDN decoder also improves learning disentangled representations, indicating that neural architectures play an important role in this task. Our results suggest favoring spatial dependency over convolutional layers in various VAE settings. The accompanying source code is given at https://github.com/djordjemila/sdn.",
        "conference": "ICLR",
        "中文标题": "空间依赖网络：用于改进生成图像建模的神经层",
        "摘要翻译": "如何通过更好地利用图像中的空间规律性和连贯性来改进生成建模？我们引入了一种新颖的神经网络用于构建图像生成器（解码器），并将其应用于变分自编码器（VAEs）。在我们的空间依赖网络（SDNs）中，深度神经网络每一层的特征图都是以空间连贯的方式计算的，使用了一种基于顺序门控的机制，该机制在二维空间中分布上下文信息。我们展示了通过空间依赖层增强分层VAE的解码器，可以显著提高密度估计，优于基线卷积架构和同类模型中的最新技术。此外，我们证明了SDN可以应用于大图像，通过合成高质量和连贯性的样本。在普通的VAE设置中，我们发现强大的SDN解码器也改进了学习解耦表示，表明神经架构在这一任务中扮演着重要角色。我们的结果表明，在各种VAE设置中，应优先考虑空间依赖层而非卷积层。随附的源代码可在https://github.com/djordjemila/sdn找到。",
        "领域": "生成模型、变分自编码器、图像合成",
        "问题": "如何通过更好地利用图像中的空间规律性和连贯性来改进生成建模",
        "动机": "探索和利用图像中的空间规律性和连贯性，以提高生成模型的质量和效率",
        "方法": "引入空间依赖网络（SDNs），使用基于顺序门控的机制在二维空间中分布上下文信息，以空间连贯的方式计算特征图",
        "关键词": [
            "空间依赖网络",
            "变分自编码器",
            "生成建模",
            "图像合成",
            "解耦表示"
        ],
        "涉及的技术概念": {
            "空间依赖网络（SDNs）": "一种新颖的神经网络，用于构建图像生成器，通过顺序门控机制在二维空间中分布上下文信息，以提高生成模型的空间连贯性",
            "变分自编码器（VAEs）": "一种生成模型，通过学习数据的潜在变量分布来生成新的数据样本，SDNs被应用于VAEs的解码器部分以提高性能",
            "解耦表示": "在VAE设置中，通过学习分离数据的不同因素（如形状、颜色等）的表示，SDN解码器有助于改进这一过程"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 748,
        "title": "Spatially Structured Recurrent Modules",
        "html": "https://iclr.cc//virtual/2021/poster/3333",
        "abstract": "Capturing the structure of a data-generating process by means of appropriate inductive biases can help in learning models that generalise well and are robust to changes in the input distribution. While methods that harness spatial and temporal structures find broad application, recent work has demonstrated the potential of models that leverage sparse and modular structure using an ensemble of sparingly interacting modules. In this work, we take a step towards dynamic models that are capable of simultaneously exploiting both modular and spatiotemporal structures. To this end, we model the dynamical system as a collection of autonomous but sparsely interacting sub-systems that interact according to a learned topology which is informed by the spatial structure of the underlying system. This gives rise to a class of models that are well suited for capturing the dynamics of systems that only offer local views into their state, along with corresponding spatial locations of those views. On the tasks of video prediction from cropped frames and multi-agent world modelling from partial observations in the challenging Starcraft2 domain, we find our models to be more robust to the number of available views and better capable of generalisation to novel tasks without additional training than strong baselines that perform equally well or better on the training distribution. ",
        "conference": "ICLR",
        "success": true,
        "中文标题": "空间结构化循环模块",
        "摘要翻译": "通过适当的归纳偏差捕捉数据生成过程的结构，有助于学习泛化能力强且对输入分布变化具有鲁棒性的模型。虽然利用空间和时间结构的方法应用广泛，但最近的研究表明，利用稀疏和模块化结构，通过一组稀疏交互的模块构建模型具有潜力。在这项工作中，我们朝着能够同时利用模块化和时空结构的动态模型迈出了一步。为此，我们将动态系统建模为一组自主但稀疏交互的子系统，这些子系统根据由底层系统的空间结构信息所学习到的拓扑结构进行交互。这产生了一类非常适合捕捉仅提供对其状态的局部视图以及这些视图的相应空间位置的系统动态的模型。在从裁剪帧进行视频预测和在具有挑战性的Starcraft2领域从部分观察进行多智能体世界建模的任务中，我们发现我们的模型对可用视图的数量更加鲁棒，并且在不进行额外训练的情况下能够更好地泛化到新任务，优于在训练分布上表现同等或更好的强基线。",
        "领域": "动态系统建模",
        "问题": "如何同时利用模块化和时空结构来构建更鲁棒和泛化能力强的动态模型",
        "动机": "探索能够捕捉数据生成过程结构的模型，以提高模型的泛化能力和鲁棒性",
        "方法": "将动态系统建模为一组自主但稀疏交互的子系统，这些子系统根据学习到的空间结构信息拓扑进行交互",
        "关键词": [
            "动态系统建模",
            "模块化结构",
            "时空结构",
            "稀疏交互",
            "泛化能力"
        ],
        "涉及的技术概念": {
            "归纳偏差": "用于捕捉数据生成过程的结构，帮助模型学习泛化能力强且对输入分布变化具有鲁棒性",
            "稀疏交互模块": "通过一组稀疏交互的模块构建模型，以利用稀疏和模块化结构",
            "空间结构信息拓扑": "根据底层系统的空间结构信息学习到的拓扑结构，指导子系统间的交互"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 749,
        "title": "Spatio-Temporal Graph Scattering Transform",
        "html": "https://iclr.cc//virtual/2021/poster/3080",
        "abstract": "Although spatio-temporal graph neural networks have achieved great empirical success in handling multiple correlated time series, they may be impractical in some real-world scenarios due to a lack of sufficient high-quality training data. Furthermore, spatio-temporal graph neural networks lack theoretical interpretation. To address these issues, we put forth a novel mathematically designed framework to analyze spatio-temporal data. Our proposed spatio-temporal graph scattering transform (ST-GST) extends traditional scattering transform to the spatio-temporal domain. It performs iterative applications of spatio-temporal graph wavelets and  nonlinear activation functions, which can be viewed as a forward pass of spatio-temporal graph convolutional networks without training. Since all the filter coefficients in ST-GST are mathematically designed, it is promising for the real-world scenarios with limited training data, and also allows for a theoretical analysis, which shows that  the proposed ST-GST is stable to small perturbations of input signals and structures. Finally, our experiments show that i) ST-GST outperforms spatio-temporal graph convolutional networks by an increase of 35% in accuracy for MSR Action3D dataset; ii) it is  better and computationally more efficient to design the transform based on separable  spatio-temporal graphs than the joint ones; and iii) nonlinearity in ST-GST is critical to empirical performance.",
        "conference": "ICLR",
        "中文标题": "时空图散射变换",
        "摘要翻译": "尽管时空图神经网络在处理多个相关时间序列方面取得了巨大的实证成功，但在一些现实世界场景中，由于缺乏足够的高质量训练数据，它们可能不实用。此外，时空图神经网络缺乏理论解释。为了解决这些问题，我们提出了一种新颖的数学设计框架来分析时空数据。我们提出的时空图散射变换（ST-GST）将传统的散射变换扩展到了时空领域。它执行时空图小波和非线性激活函数的迭代应用，可以视为无需训练的时空图卷积网络的前向传递。由于ST-GST中的所有滤波器系数都是数学设计的，它对于训练数据有限的现实世界场景是有前景的，并且允许进行理论分析，这表明所提出的ST-GST对于输入信号和结构的小扰动是稳定的。最后，我们的实验表明：i) ST-GST在MSR Action3D数据集上的准确率比时空图卷积网络提高了35%；ii) 基于可分离时空图设计变换比联合设计更优且计算效率更高；iii) ST-GST中的非线性对实证性能至关重要。",
        "领域": "时空数据分析、图神经网络、信号处理",
        "问题": "解决时空图神经网络在缺乏高质量训练数据和理论解释方面的限制",
        "动机": "为了在训练数据有限的情况下提供一种无需训练、具有理论基础的时空数据分析方法",
        "方法": "提出时空图散射变换（ST-GST），通过数学设计的滤波器系数和迭代应用时空图小波及非线性激活函数来分析时空数据",
        "关键词": [
            "时空图散射变换",
            "图神经网络",
            "时空数据分析",
            "数学设计框架",
            "非线性激活函数"
        ],
        "涉及的技术概念": {
            "时空图散射变换": "将传统散射变换扩展到时空领域，用于无需训练的时空数据分析",
            "时空图小波": "在ST-GST中用于捕捉时空数据的多尺度特征",
            "非线性激活函数": "在ST-GST中引入非线性，对提升模型性能至关重要"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 750,
        "title": "SSD: A Unified Framework for Self-Supervised Outlier Detection",
        "html": "https://iclr.cc//virtual/2021/poster/2676",
        "abstract": "We ask the following question: what training information is required to design an effective outlier/out-of-distribution (OOD) detector, i.e., detecting samples that lie far away from training distribution? Since unlabeled data is easily accessible for many applications, the most compelling approach is to develop detectors based on only unlabeled in-distribution data. However, we observe that most existing detectors based on unlabeled data perform poorly, often equivalent to a random prediction. In contrast, existing state-of-the-art OOD detectors achieve impressive performance but require access to fine-grained data labels for supervised training. We propose SSD, an outlier detector based on only unlabeled in-distribution data. We use self-supervised representation learning followed by a Mahalanobis distance based detection in the feature space. We demonstrate that SSD outperforms most existing detectors based on unlabeled data by a large margin. Additionally, SSD even achieves performance on par, and sometimes even better, with supervised training based detectors.  Finally, we expand our detection framework with two key extensions. First, we formulate few-shot OOD detection, in which the detector has access to only one to five samples from each class of the targeted OOD dataset. Second, we extend our framework to incorporate training data labels, if available. We find that our novel detection framework based on SSD displays enhanced performance with these extensions, and achieves state-of-the-art performance. Our code is publicly available at https://github.com/inspire-group/SSD.",
        "conference": "ICLR",
        "中文标题": "SSD：一种自监督异常检测的统一框架",
        "摘要翻译": "我们提出以下问题：设计一个有效的异常/分布外（OOD）检测器需要哪些训练信息，即检测远离训练分布的样本？由于在许多应用中未标记数据易于获取，最引人注目的方法是仅基于未标记的分布内数据开发检测器。然而，我们观察到大多数基于未标记数据的现有检测器表现不佳，通常等同于随机预测。相比之下，现有的最先进的OOD检测器实现了令人印象深刻的性能，但需要访问细粒度的数据标签进行监督训练。我们提出了SSD，一种仅基于未标记的分布内数据的异常检测器。我们使用自监督表示学习，然后在特征空间中进行基于马氏距离的检测。我们证明，SSD大幅优于大多数基于未标记数据的现有检测器。此外，SSD甚至达到了与基于监督训练的检测器相当，有时甚至更好的性能。最后，我们通过两个关键扩展来扩展我们的检测框架。首先，我们制定了少样本OOD检测，其中检测器只能访问目标OOD数据集中每个类的一到五个样本。其次，我们扩展了我们的框架以纳入训练数据标签（如果可用）。我们发现，基于SSD的新检测框架通过这些扩展显示出增强的性能，并实现了最先进的性能。我们的代码公开在https://github.com/inspire-group/SSD。",
        "领域": "异常检测、自监督学习、分布外检测",
        "问题": "如何仅使用未标记的分布内数据设计有效的异常/分布外检测器",
        "动机": "现有基于未标记数据的异常检测器性能不佳，而需要标签的检测器虽然性能好但不适用于无标签场景",
        "方法": "采用自监督表示学习结合特征空间的马氏距离检测",
        "关键词": [
            "自监督学习",
            "异常检测",
            "分布外检测",
            "马氏距离",
            "少样本学习"
        ],
        "涉及的技术概念": {
            "自监督表示学习": "用于从未标记数据中学习有用的特征表示，为后续的异常检测提供基础",
            "马氏距离": "在特征空间中用于测量样本与分布内数据的距离，进而判断是否为异常",
            "少样本OOD检测": "扩展框架以处理每个类别只有极少样本的情况，提高检测器的适用性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 751,
        "title": "Stabilized Medical Image Attacks",
        "html": "https://iclr.cc//virtual/2021/poster/3344",
        "abstract": "Convolutional Neural Networks (CNNs) have advanced existing medical systems for automatic disease diagnosis. However, a threat to these systems arises that adversarial attacks make CNNs vulnerable. Inaccurate diagnosis results make a negative influence on human healthcare. There is a need to investigate potential adversarial attacks to robustify deep medical diagnosis systems. On the other side, there are several modalities of medical images (e.g., CT, fundus, and endoscopic image) of which each type is significantly different from others. It is more challenging to generate adversarial perturbations for different types of medical images. In this paper, we propose an image-based medical adversarial attack method to consistently produce adversarial perturbations on medical images. The objective function of our method consists of a loss deviation term and a loss stabilization term. The loss deviation term increases the divergence between the CNN prediction of an adversarial example and its ground truth label. Meanwhile, the loss stabilization term ensures similar CNN predictions of this example and its smoothed input. From the perspective of the whole iterations for perturbation generation, the proposed loss stabilization term exhaustively searches the perturbation space to smooth the single spot for local optimum escape. We further analyze the KL-divergence of the proposed loss function and find that the loss stabilization term makes the perturbations updated towards a fixed objective spot while deviating from the ground truth. This stabilization ensures the proposed medical attack effective for different types of medical images while producing perturbations in small variance. Experiments on several medical image analysis benchmarks including the recent COVID-19 dataset show the stability of the proposed method.",
        "conference": "ICLR",
        "中文标题": "稳定的医学图像攻击",
        "摘要翻译": "卷积神经网络（CNNs）已经推动了现有医疗系统在自动疾病诊断方面的进步。然而，这些系统面临的一个威胁是，对抗性攻击使得CNNs变得脆弱。不准确的诊断结果对人类健康产生了负面影响。有必要研究潜在的对抗性攻击，以强化深度医疗诊断系统的鲁棒性。另一方面，医学图像有多种模态（如CT、眼底和内窥镜图像），每种类型与其他类型显著不同。为不同类型的医学图像生成对抗性扰动更具挑战性。在本文中，我们提出了一种基于图像的医学对抗性攻击方法，以在医学图像上持续产生对抗性扰动。我们方法的目标函数包括一个损失偏差项和一个损失稳定项。损失偏差项增加了对抗性例子的CNN预测与其真实标签之间的差异。同时，损失稳定项确保了这个例子及其平滑输入的CNN预测相似。从扰动生成的整个迭代过程来看，提出的损失稳定项详尽地搜索扰动空间，以平滑单个点以逃离局部最优。我们进一步分析了提出的损失函数的KL散度，发现损失稳定项使扰动朝着一个固定的目标点更新，同时偏离真实标签。这种稳定确保了提出的医学攻击对不同类型的医学图像有效，同时产生的扰动方差小。在包括最近的COVID-19数据集在内的几个医学图像分析基准上的实验显示了该方法的稳定性。",
        "领域": "医学图像分析、对抗性攻击、深度学习安全",
        "问题": "如何为不同类型的医学图像生成稳定且有效的对抗性扰动，以测试和增强深度医疗诊断系统的鲁棒性。",
        "动机": "研究对抗性攻击对卷积神经网络在医学图像诊断中的影响，旨在通过生成稳定的对抗性扰动来强化医疗诊断系统，防止因对抗性攻击导致的误诊。",
        "方法": "提出了一种基于图像的医学对抗性攻击方法，该方法通过结合损失偏差项和损失稳定项的目标函数，持续产生对抗性扰动，确保扰动对不同类型医学图像的有效性和稳定性。",
        "关键词": [
            "医学图像",
            "对抗性攻击",
            "卷积神经网络",
            "损失稳定",
            "KL散度"
        ],
        "涉及的技术概念": {
            "对抗性攻击": "在本文中指通过精心设计的扰动使卷积神经网络产生错误预测的技术，用于测试和增强医疗诊断系统的鲁棒性。",
            "损失偏差项": "目标函数的一部分，用于增加对抗性例子的CNN预测与其真实标签之间的差异，引导扰动生成。",
            "损失稳定项": "目标函数的另一部分，确保对抗性例子及其平滑输入的CNN预测相似，帮助扰动在迭代过程中逃离局部最优，提高对不同类型医学图像的适应性。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 752,
        "title": "Statistical inference for individual fairness",
        "html": "https://iclr.cc//virtual/2021/poster/2966",
        "abstract": "As we rely on machine learning (ML) models to make more consequential decisions, the issue of ML models perpetuating unwanted social biases has come to the fore of the public's and the research community's attention. In this paper, we focus on the problem of detecting violations of individual fairness in ML models. We formalize the problem as measuring the susceptibility of ML models against a form of adversarial attack and develop a suite of inference tools for the adversarial loss. The tools allow practitioners to assess the individual fairness of ML models in a statistically-principled way: form confidence intervals for the adversarial loss and test hypotheses of model fairness with (asymptotic) non-coverage/Type I error rate control. We demonstrate the utility of our tools in a real-world case study.",
        "conference": "ICLR",
        "中文标题": "个体公平性的统计推断",
        "摘要翻译": "随着我们依赖机器学习（ML）模型做出更多关键决策，ML模型延续不期望的社会偏见的问题已经引起了公众和研究界的关注。在本文中，我们专注于检测ML模型中个体公平性违规的问题。我们将问题形式化为测量ML模型对一种对抗性攻击的敏感性，并开发了一套针对对抗性损失的推断工具。这些工具允许从业者以统计上合理的方式评估ML模型的个体公平性：为对抗性损失形成置信区间，并以（渐近）非覆盖/类型I错误率控制测试模型公平性的假设。我们通过一个真实世界的案例研究展示了我们工具的实用性。",
        "领域": "机器学习公平性、对抗性攻击、统计推断",
        "问题": "检测机器学习模型中的个体公平性违规问题",
        "动机": "解决机器学习模型可能延续社会偏见的问题，确保模型决策的个体公平性",
        "方法": "将问题形式化为对抗性攻击的敏感性测量，开发了一套针对对抗性损失的统计推断工具",
        "关键词": [
            "个体公平性",
            "对抗性攻击",
            "统计推断",
            "机器学习公平性",
            "假设检验"
        ],
        "涉及的技术概念": {
            "个体公平性": "确保机器学习模型对每个个体的决策是公平的，不因个体特征而产生偏见",
            "对抗性攻击": "一种试图通过微小、通常难以察觉的输入变化来误导机器学习模型的技术",
            "统计推断": "使用数据分析和概率理论来推断模型行为的技术，用于评估模型公平性和性能"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 753,
        "title": "Stochastic Security: Adversarial Defense Using Long-Run Dynamics of Energy-Based Models",
        "html": "https://iclr.cc//virtual/2021/poster/3228",
        "abstract": "The vulnerability of deep networks to adversarial attacks is a central problem for deep learning from the perspective of both cognition and security. The current most successful defense method is to train a classifier using adversarial images created during learning. Another defense approach involves transformation or purification of the original input to remove adversarial signals before the image is classified. We focus on defending naturally-trained classifiers using Markov Chain Monte Carlo (MCMC) sampling with an Energy-Based Model (EBM) for adversarial purification. In contrast to adversarial training, our approach is intended to secure highly vulnerable pre-existing classifiers. To our knowledge, no prior defensive transformation is capable of securing naturally-trained classifiers, and our method is the first to validate a post-training defense approach that is distinct from current successful defenses which modify classifier training.\n\nThe memoryless behavior of long-run MCMC sampling will eventually remove adversarial signals, while metastable behavior preserves consistent appearance of MCMC samples after many steps to allow accurate long-run prediction. Balancing these factors can lead to effective purification and robust classification. We evaluate adversarial defense with an EBM using the strongest known attacks against purification. Our contributions are 1) an improved method for training EBM's with realistic long-run MCMC samples for effective purification, 2) an Expectation-Over-Transformation (EOT) defense that resolves ambiguities for evaluating stochastic defenses and from which the EOT attack naturally follows, and 3) state-of-the-art adversarial defense for naturally-trained classifiers and competitive defense compared to adversarial training on CIFAR-10, SVHN, and CIFAR-100. Our code and pre-trained models are available at https://github.com/point0bar1/ebm-defense.",
        "conference": "ICLR",
        "中文标题": "随机安全性：基于能量模型长期动态的对抗防御",
        "摘要翻译": "深度网络对对抗攻击的脆弱性是从认知和安全角度对深度学习的一个核心问题。当前最成功的防御方法是在学习过程中使用对抗图像训练分类器。另一种防御方法涉及在图像分类前对原始输入进行转换或净化以去除对抗信号。我们专注于使用马尔可夫链蒙特卡洛（MCMC）采样与基于能量模型（EBM）进行对抗净化，以防御自然训练的分类器。与对抗训练相比，我们的方法旨在保护高度脆弱的预先存在的分类器。据我们所知，没有先前的防御转换能够保护自然训练的分类器，我们的方法是第一个验证了与当前修改分类器训练的成功防御不同的训练后防御方法。长期MCMC采样的无记忆行为最终将去除对抗信号，而亚稳态行为在多次步骤后保持MCMC样本的一致外观，以允许准确的长期预测。平衡这些因素可以导致有效的净化和鲁棒分类。我们使用已知最强的净化攻击评估了基于EBM的对抗防御。我们的贡献包括1）一种改进的训练EBM的方法，使用现实的长期MCMC样本进行有效净化，2）一种期望过转换（EOT）防御，解决了评估随机防御的模糊性，并从中自然衍生出EOT攻击，以及3）在CIFAR-10、SVHN和CIFAR-100上，为自然训练的分类器提供了最先进的对抗防御，并与对抗训练相比具有竞争力的防御。我们的代码和预训练模型可在https://github.com/point0bar1/ebm-defense获取。",
        "领域": "对抗防御、深度学习安全、图像分类",
        "问题": "解决深度网络对对抗攻击的脆弱性问题，特别是针对自然训练的分类器的防御。",
        "动机": "当前大多数成功的防御方法需要修改分类器的训练过程，而本研究旨在提供一种能够保护预先存在的、未经对抗训练的分类器的防御方法。",
        "方法": "使用基于能量模型（EBM）和马尔可夫链蒙特卡洛（MCMC）采样进行对抗净化，提出了一种改进的EBM训练方法和期望过转换（EOT）防御策略。",
        "关键词": [
            "对抗防御",
            "能量模型",
            "马尔可夫链蒙特卡洛",
            "自然训练分类器",
            "对抗净化"
        ],
        "涉及的技术概念": {
            "基于能量模型（EBM）": "用于对抗净化，通过建模数据的能量分布来区分和去除对抗信号。",
            "马尔可夫链蒙特卡洛（MCMC）采样": "用于从EBM中生成样本，长期运行可以去除对抗信号，同时保持样本的一致性。",
            "期望过转换（EOT）防御": "一种评估随机防御的方法，解决了评估过程中的模糊性问题，并衍生出相应的攻击策略。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 754,
        "title": "Structured Prediction as Translation between Augmented Natural Languages",
        "html": "https://iclr.cc//virtual/2021/poster/2952",
        "abstract": "We propose a new framework, Translation between Augmented Natural Languages (TANL), to solve many structured prediction language tasks including joint entity and relation extraction, nested named entity recognition, relation classification, semantic role labeling, event extraction, coreference resolution, and dialogue state tracking. Instead of tackling the problem by training task-specific discriminative classifiers, we frame it as a translation task between augmented natural languages, from which the task-relevant information can be easily extracted. Our approach can match or outperform task-specific models on all tasks, and in particular achieves new state-of-the-art results on joint entity and relation extraction (CoNLL04, ADE, NYT, and ACE2005 datasets), relation classification (FewRel and TACRED), and semantic role labeling (CoNLL-2005 and CoNLL-2012). We accomplish this while using the same architecture and hyperparameters for all tasks, and even when training a single model to solve all tasks at the same time (multi-task learning). Finally, we show that our framework can also significantly improve the performance in a low-resource regime, thanks to better use of label semantics.",
        "conference": "ICLR",
        "中文标题": "结构化预测作为增强自然语言间的翻译",
        "摘要翻译": "我们提出了一个新的框架，即增强自然语言间的翻译（TANL），用于解决包括联合实体和关系抽取、嵌套命名实体识别、关系分类、语义角色标注、事件抽取、共指消解和对话状态跟踪在内的多种结构化预测语言任务。不同于通过训练特定任务的判别分类器来解决问题，我们将其框架化为增强自然语言间的翻译任务，从中可以轻松提取任务相关信息。我们的方法在所有任务上都能匹配或超越特定任务的模型，特别是在联合实体和关系抽取（CoNLL04、ADE、NYT和ACE2005数据集）、关系分类（FewRel和TACRED）以及语义角色标注（CoNLL-2005和CoNLL-2012）上取得了新的最先进结果。我们在所有任务上使用相同的架构和超参数，甚至在训练一个模型同时解决所有任务（多任务学习）时也能实现这一点。最后，我们展示了由于更好地利用了标签语义，我们的框架在资源匮乏的情况下也能显著提高性能。",
        "领域": "自然语言处理与视觉结合, 语义角色标注, 关系抽取",
        "问题": "解决多种结构化预测语言任务，如联合实体和关系抽取、嵌套命名实体识别等",
        "动机": "通过将结构化预测任务框架化为增强自然语言间的翻译任务，简化信息提取过程，提高模型泛化能力和性能",
        "方法": "提出TANL框架，将结构化预测任务视为增强自然语言间的翻译任务，使用统一的架构和超参数处理多种任务，支持多任务学习",
        "关键词": [
            "结构化预测",
            "自然语言处理",
            "多任务学习",
            "增强自然语言",
            "翻译任务"
        ],
        "涉及的技术概念": {
            "增强自然语言": "通过增加特定信息或结构来丰富自然语言表达，以便于机器理解和处理",
            "多任务学习": "同时训练一个模型解决多个相关任务，以提高模型的泛化能力和效率",
            "语义角色标注": "识别句子中谓词与其相关论元之间的语义关系，是自然语言处理中的一项基础任务"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 755,
        "title": "Supervised Contrastive Learning for Pre-trained Language Model Fine-tuning",
        "html": "https://iclr.cc//virtual/2021/poster/3275",
        "abstract": "State-of-the-art natural language understanding classification models follow two-stages: pre-training a large language model on an auxiliary task, and then fine-tuning the model on a task-specific labeled dataset using cross-entropy loss. However, the cross-entropy loss has several shortcomings that can lead to sub-optimal generalization and instability. Driven by the intuition that good generalization requires capturing the similarity between examples in one class and contrasting them with examples in other classes, we propose a supervised contrastive learning (SCL) objective for the fine-tuning stage. Combined with cross-entropy, our proposed SCL loss obtains significant improvements over a strong RoBERTa-Large baseline on multiple datasets of the GLUE benchmark in few-shot learning settings, without requiring specialized architecture, data augmentations, memory banks, or additional unsupervised data. Our proposed fine-tuning objective leads to models that are more robust to different levels of noise in the fine-tuning training data, and can generalize better to related tasks with limited labeled data.",
        "conference": "ICLR",
        "中文标题": "监督对比学习用于预训练语言模型的微调",
        "摘要翻译": "最先进的自然语言理解分类模型遵循两个阶段：首先在辅助任务上预训练一个大型语言模型，然后使用交叉熵损失在任务特定的标记数据集上微调模型。然而，交叉熵损失有几个缺点，可能导致次优的泛化和不稳定性。受到好泛化需要捕捉同一类别中示例之间的相似性并将它们与其他类别中的示例进行对比的直觉驱动，我们为微调阶段提出了一个监督对比学习（SCL）目标。结合交叉熵，我们提出的SCL损失在GLUE基准测试的多个数据集上的少量学习设置中，相对于强大的RoBERTa-Large基线，取得了显著的改进，而不需要专门的架构、数据增强、记忆库或额外的无监督数据。我们提出的微调目标使得模型对微调训练数据中不同级别的噪声更加鲁棒，并且能够在有限的标记数据下更好地泛化到相关任务。",
        "领域": "自然语言处理与视觉结合, 文本分类, 语言模型微调",
        "问题": "解决交叉熵损失在语言模型微调中导致的泛化能力不足和训练不稳定的问题",
        "动机": "通过捕捉同类样本间的相似性并对比不同类样本，提升模型在少量标记数据下的泛化能力和鲁棒性",
        "方法": "提出监督对比学习（SCL）目标，结合交叉熵损失进行模型微调",
        "关键词": [
            "监督对比学习",
            "语言模型微调",
            "少量学习",
            "鲁棒性",
            "泛化能力"
        ],
        "涉及的技术概念": {
            "监督对比学习（SCL）": "用于微调阶段，通过对比同类和不同类样本提升模型泛化能力",
            "交叉熵损失": "传统微调中使用的损失函数，用于衡量模型预测与真实标签之间的差异",
            "RoBERTa-Large": "作为基线模型，是一种预训练的大型语言模型，用于自然语言理解任务"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 756,
        "title": "Support-set bottlenecks for video-text representation learning",
        "html": "https://iclr.cc//virtual/2021/poster/2999",
        "abstract": "The dominant paradigm for learning video-text representations – noise contrastive learning – increases the similarity of the representations of pairs of samples that are known to be related, such as text and video from the same sample, and pushes away the representations of all other pairs. We posit that this last behaviour is too strict, enforcing dissimilar representations even for samples that are semantically-related – for example, visually similar videos or ones that share the same depicted action. In this paper, we propose a novel method that alleviates this by leveraging a generative model to naturally push these related samples together: each sample’s caption must be reconstructed as a weighted combination of a support set of visual representations. This simple idea ensures that representations are not overly-specialized to individual samples, are reusable across the dataset, and results in representations that explicitly encode semantics shared between samples, unlike noise contrastive learning. Our proposed method outperforms others by a large margin on MSR-VTT, VATEX, ActivityNet, and MSVD for video-to-text and text-to-video retrieval.",
        "conference": "ICLR",
        "中文标题": "视频-文本表示学习中的支持集瓶颈",
        "摘要翻译": "学习视频-文本表示的主导范式——噪声对比学习——增加了已知相关样本对（如同一样本的文本和视频）表示的相似性，并推开了所有其他样本对的表示。我们认为后一种行为过于严格，即使对于语义相关的样本（例如视觉上相似的视频或描绘相同动作的视频）也强制表示不相似。在本文中，我们提出了一种新方法，通过利用生成模型自然地将这些相关样本推到一起：每个样本的标题必须被重构为视觉表示支持集的加权组合。这一简单想法确保表示不会过度专门化于个别样本，可以在数据集中重复使用，并且产生明确编码样本间共享语义的表示，与噪声对比学习不同。我们提出的方法在MSR-VTT、VATEX、ActivityNet和MSVD上的视频到文本和文本到视频检索任务中大幅优于其他方法。",
        "领域": "视频文本检索, 表示学习, 多模态学习",
        "问题": "噪声对比学习在处理视频-文本表示学习时过于严格，导致语义相关样本的表示被不必要地推开。",
        "动机": "为了解决噪声对比学习在处理语义相关样本时的不足，提出一种能够自然地将相关样本推到一起的方法。",
        "方法": "利用生成模型将每个样本的标题重构为视觉表示支持集的加权组合，以确保表示的可重用性和共享语义的明确编码。",
        "关键词": [
            "视频文本检索",
            "表示学习",
            "噪声对比学习",
            "生成模型",
            "支持集"
        ],
        "涉及的技术概念": {
            "噪声对比学习": "一种通过增加相关样本对表示的相似性并推开不相关样本对表示的学习范式。",
            "生成模型": "用于将样本标题重构为视觉表示支持集的加权组合，以促进相关样本的自然聚集。",
            "支持集": "一组视觉表示，用于重构样本标题，确保表示的可重用性和共享语义的编码。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 757,
        "title": "Symmetry-Aware Actor-Critic for 3D Molecular Design",
        "html": "https://iclr.cc//virtual/2021/poster/3032",
        "abstract": "Automating molecular design using deep reinforcement learning (RL) has the potential to greatly accelerate the search for novel materials. Despite recent progress on leveraging graph representations to design molecules, such methods are fundamentally limited by the lack of three-dimensional (3D) information. In light of this, we propose a novel actor-critic architecture for 3D molecular design that can generate molecular structures unattainable with previous approaches. This is achieved by exploiting the symmetries of the design process through a rotationally covariant state-action representation based on a spherical harmonics series expansion. We demonstrate the benefits of our approach on several 3D molecular design tasks, where we find that building in such symmetries significantly improves generalization and the quality of generated molecules.",
        "conference": "ICLR",
        "中文标题": "对称感知的演员-评论家模型用于三维分子设计",
        "摘要翻译": "利用深度强化学习（RL）自动化分子设计有可能极大地加速新材料的搜索。尽管最近在利用图表示设计分子方面取得了进展，但这些方法由于缺乏三维（3D）信息而受到根本限制。鉴于此，我们提出了一种新颖的演员-评论家架构，用于三维分子设计，能够生成以前方法无法获得的分子结构。这是通过基于球谐级数展开的旋转协变状态-动作表示来利用设计过程的对称性实现的。我们在几个三维分子设计任务上展示了我们方法的好处，发现构建这样的对称性显著提高了泛化能力和生成分子的质量。",
        "领域": "分子生成设计、深度强化学习、三维分子建模",
        "问题": "如何利用深度强化学习自动化设计包含三维信息的分子结构",
        "动机": "现有的基于图表示的分子设计方法缺乏三维信息，限制了分子设计的可能性和质量",
        "方法": "提出了一种新颖的演员-评论家架构，通过基于球谐级数展开的旋转协变状态-动作表示来利用设计过程的对称性，生成包含三维信息的分子结构",
        "关键词": [
            "分子生成设计",
            "深度强化学习",
            "三维分子建模",
            "演员-评论家模型",
            "对称性利用"
        ],
        "涉及的技术概念": {
            "演员-评论家模型": "论文中用于结合策略梯度方法和价值函数方法的深度强化学习框架，以优化分子设计过程",
            "球谐级数展开": "用于表示旋转协变的状态-动作空间，使得模型能够利用分子设计中的对称性",
            "旋转协变表示": "确保模型在处理三维分子设计时能够保持对旋转操作的协变性，从而提高生成分子的质量和泛化能力"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 758,
        "title": "Systematic generalisation with group invariant predictions",
        "html": "https://iclr.cc//virtual/2021/poster/2649",
        "abstract": "We consider situations where the presence of dominant simpler correlations with the target variable in a training set can cause an SGD-trained neural network to be less reliant on more persistently correlating complex features. When the non-persistent, simpler correlations correspond to non-semantic background factors, a neural network trained on this data can exhibit dramatic failure upon encountering systematic distributional shift, where the correlating background features are recombined with different objects. We perform an empirical study on three synthetic datasets, showing that group invariance methods across inferred partitionings of the training set can lead to significant improvements at such test-time situations. We also suggest a simple invariance penalty, showing with experiments on our setups that it can perform better than alternatives. We find that even without assuming access to any systematically shifted validation sets, one can still find improvements over an ERM-trained reference model.",
        "conference": "ICLR",
        "中文标题": "通过群不变预测实现系统泛化",
        "摘要翻译": "我们考虑在训练集中存在与目标变量主导的简单相关性时，可能导致SGD训练的神经网络较少依赖更持久相关的复杂特征的情况。当这些非持久、简单的相关性对应于非语义背景因素时，在这种数据上训练的神经网络在遇到系统分布变化时可能会表现出显著的失败，其中相关的背景特征与不同的对象重新组合。我们在三个合成数据集上进行了实证研究，表明在训练集的推断分区上应用群不变方法可以在此类测试时情况下带来显著改进。我们还提出了一种简单的不变性惩罚，通过在我们的设置上的实验表明，它比其他替代方法表现更好。我们发现，即使不假设访问任何系统变化的验证集，仍然可以找到比ERM训练的参考模型更好的改进。",
        "领域": "深度学习泛化能力、群不变性学习、分布偏移适应",
        "问题": "解决神经网络在训练集中因简单相关性主导而忽视复杂特征，导致在系统分布变化时表现不佳的问题。",
        "动机": "研究旨在提高神经网络在面对系统分布变化时的泛化能力，减少对非语义背景因素的依赖。",
        "方法": "采用群不变性方法在训练集的推断分区上，并提出一种简单的不变性惩罚，以改善模型在测试时的表现。",
        "关键词": [
            "群不变性",
            "系统泛化",
            "分布偏移",
            "不变性惩罚",
            "神经网络训练"
        ],
        "涉及的技术概念": {
            "群不变性": "在训练集的推断分区上应用，旨在提高模型对系统分布变化的适应能力。",
            "不变性惩罚": "一种简单的方法，用于增强模型对复杂特征的依赖，减少对非语义背景因素的敏感度。",
            "ERM训练": "经验风险最小化训练，作为参考模型，用于比较群不变性方法和不变性惩罚的效果。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 759,
        "title": "Taking Notes on the Fly Helps Language Pre-Training",
        "html": "https://iclr.cc//virtual/2021/poster/2522",
        "abstract": "How to make unsupervised language pre-training more efficient and less resource-intensive is an important research direction in NLP. In this paper, we focus on improving the efficiency of language pre-training methods through providing better data utilization. It is well-known that in language data corpus, words follow a heavy-tail distribution. A large proportion of words appear only very few times and the embeddings of rare words are usually poorly optimized. We argue that such embeddings carry inadequate semantic signals, which could make the data utilization inefficient and slow down the pre-training of the entire model. To mitigate this problem, we propose Taking Notes on the Fly (TNF), which takes notes for rare words on the fly during pre-training to help the model understand them when they occur next time. Specifically, TNF maintains a note dictionary and saves a rare word's contextual information in it as notes when the rare word occurs in a sentence. When the same rare word occurs again during training, the note information saved beforehand can be employed to enhance the semantics of the current sentence. By doing so, TNF provides a better data utilization since cross-sentence information is employed to cover the inadequate semantics caused by rare words in the sentences. We implement TNF on both BERT and ELECTRA to check its efficiency and effectiveness.  Experimental results show that TNF's training time is 60% less than its backbone pre-training models when reaching the same performance.  When trained with same number of iterations, TNF outperforms its backbone methods on most of downstream tasks and the average GLUE score. Code is attached in the supplementary material.",
        "conference": "ICLR",
        "中文标题": "飞行中做笔记助力语言预训练",
        "摘要翻译": "如何使无监督语言预训练更高效且资源消耗更少是自然语言处理（NLP）中的一个重要研究方向。本文中，我们专注于通过提供更好的数据利用来提高语言预训练方法的效率。众所周知，在语言数据语料库中，词汇遵循重尾分布。大量词汇仅出现极少次数，而稀有词汇的嵌入通常优化不佳。我们认为，这样的嵌入携带不足的语义信号，可能导致数据利用效率低下，并减慢整个模型的预训练速度。为了缓解这一问题，我们提出了飞行中做笔记（TNF），在预训练过程中为稀有词汇即时做笔记，以帮助模型在下次遇到这些词汇时理解它们。具体来说，TNF维护一个笔记字典，并在稀有词汇出现在句子中时，将其上下文信息作为笔记保存。当同一稀有词汇在训练过程中再次出现时，预先保存的笔记信息可以用来增强当前句子的语义。通过这种方式，TNF提供了更好的数据利用，因为跨句子信息被用来覆盖由句子中稀有词汇引起的语义不足。我们在BERT和ELECTRA上实现了TNF，以检查其效率和有效性。实验结果表明，当达到相同性能时，TNF的训练时间比其骨干预训练模型少60%。当以相同迭代次数训练时，TNF在大多数下游任务和平均GLUE分数上优于其骨干方法。代码附在补充材料中。",
        "领域": "自然语言处理与视觉结合",
        "问题": "提高无监督语言预训练的效率并减少资源消耗",
        "动机": "稀有词汇的嵌入优化不佳导致数据利用效率低下，影响模型预训练速度",
        "方法": "提出飞行中做笔记（TNF）方法，通过保存和利用稀有词汇的上下文信息来增强语义理解",
        "关键词": [
            "语言预训练",
            "数据利用",
            "稀有词汇",
            "语义增强",
            "效率提升"
        ],
        "涉及的技术概念": {
            "飞行中做笔记（TNF）": "在预训练过程中为稀有词汇即时保存上下文信息，以增强模型对这些词汇的理解",
            "重尾分布": "描述词汇在语言数据语料库中出现频率的分布特性，大量词汇出现频率极低",
            "嵌入优化": "指对词汇嵌入表示进行优化，以提高模型对词汇语义的理解能力"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 760,
        "title": "Taming GANs with Lookahead-Minmax",
        "html": "https://iclr.cc//virtual/2021/poster/3358",
        "abstract": "Generative Adversarial Networks are notoriously challenging to train. The underlying minmax optimization is highly susceptible to the variance of the stochastic gradient and the rotational component of the associated game vector field. To tackle these challenges, we propose the Lookahead algorithm for minmax optimization, originally developed for single objective minimization only. The backtracking step of our Lookahead–minmax naturally handles the rotational game dynamics, a property which was identified to be key for enabling gradient ascent descent methods to converge on challenging examples often analyzed in the literature. Moreover, it implicitly handles high variance without using large mini-batches, known to be essential for reaching state of the art performance. Experimental results on MNIST, SVHN, CIFAR-10, and ImageNet demonstrate a clear advantage of combining Lookahead–minmax with Adam or extragradient, in terms of performance and improved stability, for negligible memory and computational cost. Using 30-fold fewer parameters and 16-fold smaller minibatches we outperform the reported performance of the class-dependent BigGAN on CIFAR-10 by obtaining FID of 12.19 without using the class labels, bringing state-of-the-art GAN training within reach of common computational resources.",
        "conference": "ICLR",
        "中文标题": "驯服GANs：使用前瞻-最小最大算法",
        "摘要翻译": "生成对抗网络（GANs）的训练 notoriously 具有挑战性。其基础的最小最大优化极易受到随机梯度的方差和相关游戏向量场的旋转分量的影响。为了解决这些挑战，我们提出了用于最小最大优化的前瞻算法，该算法最初仅为单一目标最小化而开发。我们的前瞻-最小最大算法的回溯步骤自然地处理了旋转游戏动态，这一特性被认为是使梯度上升下降方法能够在文献中经常分析的挑战性例子上收敛的关键。此外，它隐式地处理了高方差，而不需要使用已知对达到最先进性能至关重要的大批量。在MNIST、SVHN、CIFAR-10和ImageNet上的实验结果表明，将前瞻-最小最大与Adam或外梯度相结合，在性能和稳定性方面具有明显优势，且内存和计算成本可忽略不计。使用30倍少的参数和16倍小的迷你批次，我们在CIFAR-10上超越了类依赖BigGAN的报告性能，获得了12.19的FID，而不使用类标签，使得最先进的GAN训练触手可及于常见的计算资源。",
        "领域": "生成对抗网络、图像生成、深度学习优化",
        "问题": "解决生成对抗网络训练中的不稳定性和高方差问题",
        "动机": "提高生成对抗网络的训练稳定性和效率，使其在有限的计算资源下也能达到最先进的性能",
        "方法": "提出前瞻-最小最大算法，结合Adam或外梯度优化器，以处理旋转游戏动态和高方差问题",
        "关键词": [
            "生成对抗网络",
            "最小最大优化",
            "前瞻算法",
            "训练稳定性",
            "图像生成"
        ],
        "涉及的技术概念": {
            "前瞻算法": "用于最小最大优化的算法，通过回溯步骤处理旋转游戏动态",
            "最小最大优化": "生成对抗网络训练中的核心优化问题，旨在找到生成器和判别器之间的平衡点",
            "FID": "Frechet Inception Distance，用于评估生成图像质量的指标，值越低表示生成图像质量越高"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 761,
        "title": "Targeted Attack against Deep Neural Networks via Flipping Limited Weight Bits",
        "html": "https://iclr.cc//virtual/2021/poster/2631",
        "abstract": "To explore the vulnerability of deep neural networks (DNNs), many attack paradigms have been well studied, such as the poisoning-based backdoor attack in the training stage and the adversarial attack in the inference stage. In this paper, we study a novel attack paradigm, which modifies model parameters in the deployment stage for malicious purposes. Specifically, our goal is to misclassify a specific sample into a target class without any sample modification, while not significantly reduce the prediction accuracy of other samples to ensure the stealthiness. To this end, we formulate this problem as a binary integer programming (BIP), since the parameters are stored as binary bits ($i.e.$, 0 and 1) in the memory. By utilizing the latest technique in integer programming, we equivalently reformulate this BIP problem as a continuous optimization problem, which can be effectively and efficiently solved using the alternating direction method of multipliers (ADMM) method. Consequently, the flipped critical bits can be easily determined through optimization, rather than using a heuristic strategy. Extensive experiments demonstrate the superiority of our method in attacking DNNs.",
        "conference": "ICLR",
        "中文标题": "通过翻转有限权重位对深度神经网络进行针对性攻击",
        "摘要翻译": "为了探索深度神经网络（DNNs）的脆弱性，许多攻击范式已被深入研究，如训练阶段基于投毒的后门攻击和推理阶段的对抗攻击。本文研究了一种新的攻击范式，即在部署阶段修改模型参数以达到恶意目的。具体而言，我们的目标是在不修改任何样本的情况下，将特定样本误分类为目标类别，同时不显著降低其他样本的预测准确率以确保隐蔽性。为此，我们将此问题表述为二进制整数规划（BIP）问题，因为参数在内存中以二进制位（即0和1）存储。通过利用整数编程中的最新技术，我们将这个BIP问题等价地重新表述为一个连续优化问题，该问题可以使用交替方向乘子法（ADMM）有效且高效地解决。因此，翻转的关键位可以通过优化轻松确定，而不是使用启发式策略。大量实验证明了我们的方法在攻击DNNs方面的优越性。",
        "领域": "对抗攻击、模型安全、深度神经网络",
        "问题": "在深度神经网络的部署阶段，通过修改模型参数实现特定样本的误分类，同时保持对其他样本预测准确率的影响最小化。",
        "动机": "探索深度神经网络在部署阶段的新攻击范式，揭示模型参数修改对网络行为的影响。",
        "方法": "将攻击问题建模为二进制整数规划问题，并利用整数编程技术将其转化为连续优化问题，采用交替方向乘子法（ADMM）进行求解。",
        "关键词": [
            "针对性攻击",
            "深度神经网络",
            "二进制整数规划",
            "交替方向乘子法",
            "模型安全"
        ],
        "涉及的技术概念": {
            "二进制整数规划（BIP）": "用于将攻击问题建模为二进制位翻转的优化问题，以确定需要修改的模型参数位。",
            "交替方向乘子法（ADMM）": "用于高效解决转化后的连续优化问题，确定翻转的关键位。",
            "模型参数修改": "在部署阶段直接修改模型的二进制参数位，以实现特定攻击目的而不影响其他样本的预测准确率。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 762,
        "title": "Task-Agnostic Morphology Evolution",
        "html": "https://iclr.cc//virtual/2021/poster/2987",
        "abstract": "Deep reinforcement learning primarily focuses on learning behavior, usually overlooking the fact that an agent's function is largely determined by form. So, how should one go about finding a morphology fit for solving tasks in a given environment? Current approaches that co-adapt morphology and behavior use a specific task's reward as a signal for morphology optimization. However, this often requires expensive policy optimization and results in task-dependent morphologies that are not built to generalize. In this work, we propose a new approach, Task-Agnostic Morphology Evolution (TAME), to alleviate both of these issues. Without any task or reward specification, TAME evolves morphologies by only applying randomly sampled action primitives on a population of agents. This is accomplished using an information-theoretic objective that efficiently ranks agents by their ability to reach diverse states in the environment and the causality of their actions. Finally, we empirically demonstrate that across 2D, 3D, and manipulation environments TAME can evolve morphologies that match the multi-task performance of those learned with task supervised algorithms. Our code and videos can be found at https://sites.google.com/view/task-agnostic-evolution .\n",
        "conference": "ICLR",
        "中文标题": "任务无关的形态进化",
        "摘要翻译": "深度强化学习主要关注于学习行为，通常忽略了代理的功能很大程度上由形态决定的事实。那么，应该如何去寻找适合在给定环境中解决任务的形态呢？当前共同适应形态和行为的方法使用特定任务的奖励作为形态优化的信号。然而，这通常需要昂贵的策略优化，并导致依赖于任务的形态，这些形态并不具备泛化能力。在这项工作中，我们提出了一种新方法，任务无关的形态进化（TAME），以缓解这两个问题。无需任何任务或奖励规范，TAME仅通过在代理群体上应用随机采样的动作原语来进化形态。这是通过使用一个信息论目标实现的，该目标通过代理在环境中达到多样状态的能力及其动作的因果关系来高效地排名代理。最后，我们通过实验证明，在2D、3D和操作环境中，TAME能够进化出与任务监督算法学习的形态相匹配的多任务性能形态。我们的代码和视频可以在https://sites.google.com/view/task-agnostic-evolution找到。",
        "领域": "强化学习、机器人学、进化算法",
        "问题": "如何在无需特定任务奖励的情况下，进化出能够泛化到多任务的代理形态",
        "动机": "现有的形态和行为共同适应方法依赖于特定任务的奖励，导致形态优化成本高且泛化能力差",
        "方法": "提出任务无关的形态进化（TAME）方法，通过随机采样的动作原语和信息论目标进化形态",
        "关键词": [
            "任务无关",
            "形态进化",
            "强化学习",
            "信息论目标",
            "多任务性能"
        ],
        "涉及的技术概念": {
            "任务无关的形态进化（TAME）": "一种无需任务或奖励规范，通过随机动作原语和信息论目标进化代理形态的方法",
            "信息论目标": "用于评估代理在环境中达到多样状态的能力及其动作的因果关系，以高效排名代理",
            "动作原语": "随机采样的基本动作，用于在代理群体上应用以进化形态"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 763,
        "title": "Teaching Temporal Logics to Neural Networks",
        "html": "https://iclr.cc//virtual/2021/poster/3332",
        "abstract": "We study two fundamental questions in neuro-symbolic computing: can deep learning tackle challenging problems in logics end-to-end, and can neural networks learn the semantics of logics. In this work we focus on linear-time temporal logic (LTL), as it is widely used in verification. We train a Transformer on the problem to directly predict a solution, i.e. a trace, to a given LTL formula. The training data is generated with classical solvers, which, however, only provide one of many possible solutions to each formula. We demonstrate that it is sufficient to train on those particular solutions to formulas, and that Transformers can predict solutions even to formulas from benchmarks from the literature on which the classical solver timed out. Transformers also generalize to the semantics of the logics: while they often deviate from the solutions found by the classical solvers, they still predict correct solutions to most formulas.",
        "conference": "ICLR",
        "中文标题": "教授时序逻辑给神经网络",
        "摘要翻译": "我们研究了神经符号计算中的两个基本问题：深度学习能否端到端地解决逻辑中的挑战性问题，以及神经网络能否学习逻辑的语义。在这项工作中，我们专注于线性时序逻辑（LTL），因为它在验证中被广泛使用。我们训练了一个Transformer模型，直接预测给定LTL公式的解，即一个轨迹。训练数据是通过经典求解器生成的，然而，这些求解器对每个公式只提供众多可能解中的一个。我们证明，在这些特定公式解上训练是足够的，并且Transformer可以预测甚至文献中经典求解器超时的基准公式的解。Transformer还能够泛化到逻辑的语义：虽然它们经常偏离经典求解器找到的解，但它们仍然能预测大多数公式的正确解。",
        "领域": "神经符号计算、时序逻辑学习、深度学习应用",
        "问题": "深度学习能否端到端地解决逻辑中的挑战性问题，以及神经网络能否学习逻辑的语义。",
        "动机": "探索深度学习在逻辑问题解决和逻辑语义学习方面的潜力。",
        "方法": "使用Transformer模型直接预测给定线性时序逻辑（LTL）公式的解，训练数据由经典求解器生成。",
        "关键词": [
            "神经符号计算",
            "时序逻辑",
            "Transformer模型",
            "深度学习",
            "逻辑语义"
        ],
        "涉及的技术概念": {
            "线性时序逻辑（LTL）": "一种广泛用于验证的时序逻辑，用于描述系统随时间的行为。",
            "Transformer模型": "一种基于自注意力机制的深度学习模型，用于直接预测LTL公式的解。",
            "经典求解器": "用于生成训练数据的传统逻辑求解工具，提供LTL公式的一个可能解。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 764,
        "title": "Teaching with Commentaries",
        "html": "https://iclr.cc//virtual/2021/poster/2551",
        "abstract": "Effective training of deep neural networks can be challenging, and there remain many open questions on how to best learn these models. Recently developed methods to improve neural network training examine teaching: providing learned information during the training process to improve downstream model performance. In this paper, we take steps towards extending the scope of teaching. We propose a flexible teaching framework using commentaries,  learned meta-information helpful for training on a particular task. We present gradient-based methods to learn commentaries, leveraging recent work on implicit differentiation for scalability. We explore diverse applications of commentaries, from weighting training examples, to parameterising label-dependent data augmentation policies, to representing attention masks that highlight salient image regions. We find that commentaries can improve training speed and/or performance, and provide insights about the dataset and training process. We also observe that commentaries generalise: they can be reused when training new models to obtain performance benefits, suggesting a use-case where commentaries are stored with a dataset and leveraged in future for improved model training. ",
        "conference": "ICLR",
        "中文标题": "使用评论进行教学",
        "摘要翻译": "深度神经网络的有效训练可能具有挑战性，关于如何最好地学习这些模型仍存在许多开放性问题。最近开发的改进神经网络训练的方法考察了教学：在训练过程中提供学习到的信息以提高下游模型性能。在本文中，我们采取措施扩展教学的范围。我们提出了一个使用评论的灵活教学框架，评论是学习到的对特定任务训练有帮助的元信息。我们提出了基于梯度的方法来学习评论，利用最近关于隐式微分的工作以实现可扩展性。我们探索了评论的多样化应用，从加权训练样本，到参数化依赖于标签的数据增强策略，再到表示突出显著图像区域的注意力掩码。我们发现评论可以提高训练速度和/或性能，并提供关于数据集和训练过程的见解。我们还观察到评论具有泛化能力：它们可以在训练新模型时重复使用以获得性能优势，这表明了一种使用场景，即评论与数据集一起存储并在未来用于改进模型训练。",
        "领域": "深度学习优化、神经网络训练、数据增强",
        "问题": "如何通过教学框架提高深度神经网络的训练效率和性能",
        "动机": "探索和扩展教学在深度神经网络训练中的应用，以提高模型性能和训练速度",
        "方法": "提出一个使用评论的灵活教学框架，采用基于梯度的方法学习评论，并探索其在多种应用中的效果",
        "关键词": [
            "教学框架",
            "评论学习",
            "梯度方法",
            "数据增强",
            "注意力掩码"
        ],
        "涉及的技术概念": {
            "评论": "学习到的元信息，用于在特定任务训练中提供帮助",
            "隐式微分": "用于实现评论学习方法的可扩展性",
            "注意力掩码": "用于突出图像中的显著区域，帮助模型更好地关注重要信息"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 765,
        "title": "Temporally-Extended ε-Greedy Exploration",
        "html": "https://iclr.cc//virtual/2021/poster/3210",
        "abstract": "Recent work on exploration in reinforcement learning (RL) has led to a series of increasingly complex solutions to the problem. This increase in complexity often comes at the expense of generality. Recent empirical studies suggest that, when applied to a broader set of domains, some sophisticated exploration methods are outperformed by simpler counterparts, such as ε-greedy. In this paper we propose an exploration algorithm that retains the simplicity of ε-greedy while reducing dithering. We build on a simple hypothesis: the main limitation of ε-greedy exploration is its lack of temporal persistence, which limits its ability to escape local optima. We propose a temporally extended form of ε-greedy that simply repeats the sampled action for a random duration. It turns out that, for many duration distributions, this suffices to improve exploration on a large set of domains. Interestingly, a class of distributions inspired by ecological models of animal foraging behaviour yields particularly strong performance.",
        "conference": "ICLR",
        "中文标题": "时间扩展的ε-贪婪探索",
        "摘要翻译": "最近在强化学习（RL）探索方面的研究导致了一系列越来越复杂的解决方案。这种复杂性的增加往往以牺牲通用性为代价。最近的实证研究表明，当应用于更广泛的领域时，一些复杂的探索方法的表现不如简单的对应方法，如ε-贪婪。在本文中，我们提出了一种探索算法，它保留了ε-贪婪的简单性，同时减少了抖动。我们基于一个简单的假设：ε-贪婪探索的主要限制是其缺乏时间持久性，这限制了其逃离局部最优的能力。我们提出了一种时间扩展形式的ε-贪婪，它简单地重复采样动作一段随机持续时间。事实证明，对于许多持续时间分布，这足以在大量领域上改进探索。有趣的是，受到动物觅食行为生态模型启发的一类分布表现尤为出色。",
        "领域": "强化学习探索、算法优化、行为模型",
        "问题": "如何在保留ε-贪婪探索简单性的同时，减少其抖动并提高探索效率",
        "动机": "解决ε-贪婪探索因缺乏时间持久性而难以逃离局部最优的问题",
        "方法": "提出一种时间扩展的ε-贪婪探索算法，通过重复采样动作一段随机持续时间来提高探索效率",
        "关键词": [
            "ε-贪婪探索",
            "时间扩展",
            "强化学习",
            "探索算法",
            "行为模型"
        ],
        "涉及的技术概念": {
            "ε-贪婪探索": "一种简单的探索策略，以ε概率随机选择动作，以1-ε概率选择当前最优动作",
            "时间持久性": "指探索策略在时间维度上的连续性，影响算法逃离局部最优的能力",
            "动物觅食行为模型": "受生态学启发的模型，用于设计探索策略中的持续时间分布，以提高探索效率"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 766,
        "title": "Tent: Fully Test-Time Adaptation by Entropy Minimization",
        "html": "https://iclr.cc//virtual/2021/poster/2874",
        "abstract": "A model must adapt itself to generalize to new and different data during testing. In this setting of fully test-time adaptation the model has only the test data and its own parameters. We propose to adapt by test entropy minimization (tent): we optimize the model for confidence as measured by the entropy of its predictions. Our method estimates normalization statistics and optimizes channel-wise affine transformations to update online on each batch. Tent reduces generalization error for image classification on corrupted ImageNet and CIFAR-10/100 and reaches a new state-of-the-art error on ImageNet-C. Tent handles source-free domain adaptation on digit recognition from SVHN to MNIST/MNIST-M/USPS, on semantic segmentation from GTA to Cityscapes, and on the VisDA-C benchmark. These results are achieved in one epoch of test-time optimization without altering training.",
        "conference": "ICLR",
        "中文标题": "Tent：通过熵最小化实现完全测试时适应",
        "摘要翻译": "模型必须在测试期间适应自身以泛化到新的和不同的数据。在完全测试时适应的设置中，模型仅有测试数据及其自身参数。我们提出通过测试熵最小化（tent）进行适应：我们优化模型的置信度，以其预测的熵为衡量标准。我们的方法估计归一化统计量并优化通道仿射变换，以在每个批次上在线更新。Tent减少了在损坏的ImageNet和CIFAR-10/100上的图像分类泛化误差，并在ImageNet-C上达到了新的最先进错误率。Tent处理了从SVHN到MNIST/MNIST-M/USPS的数字识别的无源域适应，从GTA到Cityscapes的语义分割，以及VisDA-C基准测试。这些结果是在不改变训练的情况下，通过一个测试时优化周期实现的。",
        "领域": "图像分类、语义分割、域适应",
        "问题": "解决模型在测试时对新和不同数据的泛化能力问题",
        "动机": "提高模型在测试阶段对不同数据分布的适应能力，无需重新训练",
        "方法": "通过测试熵最小化优化模型的置信度，估计归一化统计量并优化通道仿射变换进行在线更新",
        "关键词": [
            "测试时适应",
            "熵最小化",
            "域适应",
            "图像分类",
            "语义分割"
        ],
        "涉及的技术概念": {
            "测试熵最小化": "通过最小化预测熵来优化模型的置信度，提高测试时的适应能力",
            "通道仿射变换": "用于调整模型参数以适应测试数据分布的线性变换",
            "无源域适应": "在没有源域数据的情况下，使模型适应目标域的技术"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 767,
        "title": "Text Generation by Learning from Demonstrations",
        "html": "https://iclr.cc//virtual/2021/poster/2765",
        "abstract": "Current approaches to text generation largely rely on autoregressive models and maximum likelihood estimation. This paradigm leads to (i) diverse but low-quality samples due to mismatched learning objective and evaluation metric (likelihood vs. quality) and (ii) exposure bias due to mismatched history distributions (gold vs. model-generated). To alleviate these problems, we frame text generation as an offline reinforcement learning (RL) problem with expert demonstrations (i.e., the reference), where the goal is to maximize quality given model-generated histories. We propose GOLD (generation by off-policy learning from demonstrations): an easy-to-optimize algorithm that learns from the demonstrations by importance weighting. Intuitively, GOLD upweights confident tokens and downweights unconfident ones in the reference during training, avoiding optimization issues faced by prior RL approaches that rely on online data collection. According to both automatic and human evaluation, models trained by GOLD outperform those trained by MLE and policy gradient on summarization, question generation, and machine translation. Further, our models are less sensitive to decoding algorithms and alleviate exposure bias.",
        "conference": "ICLR",
        "中文标题": "通过从示范中学习进行文本生成",
        "摘要翻译": "当前的文本生成方法主要依赖于自回归模型和最大似然估计。这种范式导致（i）由于学习目标和评估指标（似然与质量）不匹配而产生多样但低质量的样本，以及（ii）由于历史分布（黄金与模型生成）不匹配而产生的暴露偏差。为了缓解这些问题，我们将文本生成框架化为一个带有专家示范（即参考）的离线强化学习（RL）问题，其目标是在给定模型生成的历史下最大化质量。我们提出了GOLD（通过从示范中进行离策略学习生成）：一种易于优化的算法，通过重要性加权从示范中学习。直观地说，GOLD在训练过程中对参考中的自信令牌进行加权，对不自信的令牌进行降权，避免了依赖在线数据收集的先前RL方法所面临的优化问题。根据自动和人工评估，通过GOLD训练的模型在摘要、问题生成和机器翻译方面优于通过MLE和策略梯度训练的模型。此外，我们的模型对解码算法不太敏感，并缓解了暴露偏差。",
        "领域": "自然语言生成、强化学习应用、文本摘要",
        "问题": "解决文本生成中由于最大似然估计导致的质量与多样性不平衡及暴露偏差问题",
        "动机": "提高文本生成的质量和减少暴露偏差，通过从示范中学习优化生成过程",
        "方法": "提出GOLD算法，通过离策略学习和重要性加权从专家示范中学习，优化文本生成过程",
        "关键词": [
            "文本生成",
            "强化学习",
            "重要性加权",
            "暴露偏差",
            "GOLD算法"
        ],
        "涉及的技术概念": {
            "离线强化学习": "在文本生成中应用离线强化学习，利用专家示范优化生成过程，避免在线数据收集的问题",
            "重要性加权": "在训练过程中调整参考文本中令牌的权重，优化学习过程",
            "暴露偏差": "模型在训练和生成阶段历史分布不一致导致的问题，GOLD算法通过优化减轻这一影响"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 768,
        "title": "The Deep Bootstrap Framework: Good Online Learners are Good Offline Generalizers",
        "html": "https://iclr.cc//virtual/2021/poster/2584",
        "abstract": "We propose a new framework for reasoning about generalization in deep learning. \nThe core idea is to couple the Real World, where optimizers take stochastic gradient steps on the empirical loss, to an Ideal World, where optimizers take steps on the population loss. This leads to an alternate decomposition of test error into: (1) the Ideal World test error plus (2) the gap between the two worlds. If the gap (2) is universally small, this reduces the problem of generalization in offline learning to the problem of optimization in online learning.\nWe then give empirical evidence that this gap between worlds can be small in realistic deep learning settings, in particular supervised image classification. For example, CNNs generalize better than MLPs on image distributions in the Real World, but this is 'because' they optimize faster on the population loss in the Ideal World. This suggests our framework is a useful tool for understanding generalization in deep learning, and lays the foundation for future research in this direction. ",
        "conference": "ICLR",
        "中文标题": "深度引导框架：优秀的在线学习者是优秀的离线泛化者",
        "摘要翻译": "我们提出了一个新的框架，用于推理深度学习中的泛化问题。核心思想是将现实世界（优化器在经验损失上采取随机梯度步骤）与理想世界（优化器在总体损失上采取步骤）耦合。这导致了对测试误差的另一种分解：（1）理想世界的测试误差加上（2）两个世界之间的差距。如果差距（2）普遍较小，这将离线学习中的泛化问题简化为在线学习中的优化问题。然后，我们提供了经验证据，表明在现实的深度学习设置中，特别是监督图像分类，这种世界之间的差距可以很小。例如，在现实世界的图像分布上，CNNs比MLPs泛化得更好，但这是因为它们在理想世界的总体损失上优化得更快。这表明我们的框架是理解深度学习中泛化的有用工具，并为这一方向的未来研究奠定了基础。",
        "领域": "深度学习理论、监督学习、图像分类",
        "问题": "如何理解和改进深度学习模型的泛化能力",
        "动机": "为了提供一个新框架，将深度学习中的泛化问题与在线学习中的优化问题联系起来，从而更好地理解泛化现象",
        "方法": "通过耦合现实世界和理想世界的优化过程，分析测试误差的分解，并实证研究两个世界之间的差距",
        "关键词": [
            "深度学习泛化",
            "在线学习",
            "监督图像分类",
            "优化差距",
            "CNNs与MLPs比较"
        ],
        "涉及的技术概念": {
            "现实世界与理想世界耦合": "框架中将现实世界的经验损失优化与理想世界的总体损失优化联系起来，用于分析泛化能力",
            "测试误差分解": "将测试误差分解为理想世界误差和两个世界之间的差距，简化泛化问题的理解",
            "优化差距": "实证研究中观察到的现实世界与理想世界优化性能之间的差距，影响模型的泛化能力"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 769,
        "title": "The geometry of integration in text classification RNNs",
        "html": "https://iclr.cc//virtual/2021/poster/2576",
        "abstract": "Despite the widespread application of recurrent neural networks (RNNs), a unified understanding of how RNNs solve particular tasks remains elusive.  In particular, it is unclear what dynamical patterns arise in trained RNNs, and how those pat-terns depend on the training dataset or task.  This work addresses these questions in the context of text classification, building on earlier work studying the dynamics of binary sentiment-classification networks (Maheswaranathan et al., 2019).  We study text-classification tasks beyond the binary case, exploring the dynamics ofRNNs trained on both natural and synthetic datasets.  These dynamics, which we find to be both interpretable and low-dimensional, share a common mechanism across architectures and datasets:  specifically, these text-classification networks use low-dimensional attractor manifolds to accumulate evidence for each class as they process the text.  The dimensionality and geometry of the attractor manifold are determined by the structure of the training dataset, with the dimensionality reflecting the number of scalar quantities the network remembers in order to classify.In categorical classification, for example, we show that this dimensionality is one less than the number of classes. Correlations in the dataset, such as those induced by ordering, can further reduce the dimensionality of the attractor manifold; we show how to predict this reduction using simple word-count statistics computed on the training dataset. To the degree that integration of evidence towards a decision is a common computational primitive, this work continues to lay the foundation for using dynamical systems techniques to study the inner workings of RNNs.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "文本分类循环神经网络中积分几何的研究",
        "摘要翻译": "尽管循环神经网络（RNNs）应用广泛，但对于RNNs如何解决特定任务的统一理解仍然不足。特别是，尚不清楚训练后的RNNs中会出现哪些动态模式，以及这些模式如何依赖于训练数据集或任务。本研究在文本分类的背景下探讨这些问题，基于早期研究二元情感分类网络动态的工作（Maheswaranathan等人，2019）。我们研究了超越二元情况的文本分类任务，探索了在自然和合成数据集上训练的RNNs的动态。这些动态，我们发现既具有可解释性又低维，在架构和数据集之间共享一个共同的机制：具体来说，这些文本分类网络使用低维吸引子流形在处理文本时为每个类别积累证据。吸引子流形的维数和几何由训练数据集的结构决定，维数反映了网络为了分类而记住的标量数量。例如，在分类分类中，我们展示了这个维数比类别数少一。数据集中的相关性，如由排序引起的相关性，可以进一步减少吸引子流形的维数；我们展示了如何使用在训练数据集上计算的简单词频统计来预测这种减少。鉴于证据的整合是决策的常见计算原语，这项工作继续为使用动态系统技术研究RNNs的内部工作机制奠定基础。",
        "领域": "自然语言处理与视觉结合",
        "问题": "理解循环神经网络（RNNs）在文本分类任务中的动态模式和机制",
        "动机": "探索RNNs在文本分类任务中的动态行为及其与数据集结构的关系，以增进对RNNs工作机制的理解",
        "方法": "研究在自然和合成数据集上训练的RNNs的动态，分析吸引子流形的维数和几何与数据集结构的关系",
        "关键词": [
            "循环神经网络",
            "文本分类",
            "动态系统",
            "吸引子流形",
            "数据集结构"
        ],
        "涉及的技术概念": {
            "循环神经网络（RNNs）": "用于处理序列数据的神经网络，本研究探讨其在文本分类任务中的动态行为",
            "吸引子流形": "RNNs在处理文本时使用的低维结构，用于为每个类别积累证据，其维数和几何由数据集结构决定",
            "动态系统技术": "用于研究RNNs内部工作机制的方法，通过分析网络的动态行为来理解其分类决策过程"
        },
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 770,
        "title": "The Importance of Pessimism in Fixed-Dataset Policy Optimization",
        "html": "https://iclr.cc//virtual/2021/poster/2655",
        "abstract": "We study worst-case guarantees on the expected return of fixed-dataset policy optimization algorithms. Our core contribution is a unified conceptual and mathematical framework for the study of algorithms in this regime. This analysis reveals that for naive approaches, the possibility of erroneous value overestimation leads to a difficult-to-satisfy requirement: in order to guarantee that we select a policy which is near-optimal, we may need the dataset to be informative of the value of every policy. To avoid this, algorithms can follow the pessimism principle, which states that we should choose the policy which acts optimally in the worst possible world. We show why pessimistic algorithms can achieve good performance even when the dataset is not informative of every policy, and derive families of algorithms which follow this principle. These theoretical findings are validated by experiments on a tabular gridworld, and deep learning experiments on four MinAtar environments.",
        "conference": "ICLR",
        "中文标题": "固定数据集策略优化中悲观主义的重要性",
        "摘要翻译": "我们研究了固定数据集策略优化算法在预期回报上的最坏情况保证。我们的核心贡献是为这一领域算法的研究提供了一个统一的概念和数学框架。这一分析揭示，对于天真的方法，错误的价值高估可能性导致了一个难以满足的要求：为了确保我们选择一个接近最优的策略，我们可能需要数据集对每个策略的价值都有信息量。为了避免这一点，算法可以遵循悲观主义原则，即我们应该选择在最坏可能世界中表现最优的策略。我们展示了为什么悲观算法即使在不了解每个策略的数据集情况下也能实现良好性能，并推导了遵循这一原则的算法家族。这些理论发现通过在表格网格世界上的实验和四个MinAtar环境的深度学习实验得到了验证。",
        "领域": "强化学习、策略优化、深度强化学习",
        "问题": "如何在固定数据集条件下优化策略以保证预期回报的最坏情况性能",
        "动机": "研究固定数据集策略优化算法在最坏情况下保证预期回报的可能性，避免因价值高估而导致的性能下降",
        "方法": "提出并应用悲观主义原则，推导出能够在数据集不全面情况下仍能保证性能的算法家族，并通过实验验证",
        "关键词": [
            "固定数据集",
            "策略优化",
            "悲观主义原则",
            "MinAtar环境",
            "价值高估"
        ],
        "涉及的技术概念": {
            "悲观主义原则": "选择在最坏可能世界中表现最优的策略，以避免因数据集不全面而导致的价值高估问题",
            "固定数据集策略优化": "在给定固定数据集条件下优化策略的方法，研究其预期回报的最坏情况保证",
            "价值高估": "在策略优化过程中，由于数据集限制可能导致对某些策略价值的错误高估，影响最终策略选择的性能"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 771,
        "title": "The inductive bias of ReLU networks on orthogonally separable data",
        "html": "https://iclr.cc//virtual/2021/poster/2889",
        "abstract": "We study the inductive bias of two-layer ReLU networks trained by gradient flow. We identify a class of easy-to-learn (`orthogonally separable') datasets, and characterise the solution that ReLU networks trained on such datasets converge to. Irrespective of network width, the solution turns out to be a combination of two max-margin classifiers: one corresponding to the positive data subset and one corresponding to the negative data subset.\nThe proof is based on the recently introduced concept of extremal sectors, for which we prove a number of properties in the context of orthogonal separability. In particular, we prove stationarity of activation patterns from some time $T$ onwards, which enables a reduction of the ReLU network to an ensemble of linear subnetworks.\n",
        "conference": "ICLR",
        "中文标题": "ReLU网络在正交可分数据上的归纳偏置",
        "摘要翻译": "我们研究了通过梯度流训练的两层ReLU网络的归纳偏置。我们识别了一类易于学习（'正交可分'）的数据集，并描述了ReLU网络在此类数据集上训练后收敛到的解。无论网络宽度如何，解结果都是两个最大边际分类器的组合：一个对应于正数据子集，另一个对应于负数据子集。证明基于最近引入的极值扇区概念，我们在正交可分性的背景下证明了其若干性质。特别是，我们证明了从某个时间T开始激活模式的稳定性，这使得ReLU网络可以简化为线性子网络的集合。",
        "领域": "深度学习理论、神经网络优化、模式识别",
        "问题": "理解ReLU网络在特定类型数据（正交可分数据集）上的归纳偏置及其收敛行为",
        "动机": "探索ReLU网络在易于学习的数据集上的训练动态和收敛解的特性，以深入理解其学习机制",
        "方法": "通过梯度流训练两层ReLU网络，利用极值扇区概念分析网络在正交可分数据上的行为，并证明激活模式的稳定性",
        "关键词": [
            "ReLU网络",
            "归纳偏置",
            "正交可分数据",
            "梯度流",
            "最大边际分类器"
        ],
        "涉及的技术概念": {
            "归纳偏置": "指学习算法在学习过程中对某些假设的偏好，影响模型的学习和泛化能力",
            "梯度流": "一种连续时间版本的梯度下降，用于分析神经网络训练的动力学",
            "极值扇区": "用于分析ReLU网络在特定数据分布下行为的工具，帮助理解网络的收敛解"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 772,
        "title": "The Intrinsic Dimension of Images and Its Impact on Learning",
        "html": "https://iclr.cc//virtual/2021/poster/3230",
        "abstract": "It is widely believed that natural image data exhibits low-dimensional structure despite the high dimensionality of conventional pixel representations.  This idea underlies a common intuition for the remarkable success of deep learning in computer vision. In this work, we apply dimension estimation tools to popular datasets and investigate the role of low-dimensional structure in deep learning.  We find that common natural image datasets indeed have very low intrinsic dimension relative to the high number of pixels in the images.  Additionally, we find that low dimensional datasets are easier for neural networks to learn, and models solving these tasks generalize better from training to test data.   Along the way,  we develop a technique for validating our dimension estimation tools on synthetic data generated by GANs allowing us to actively manipulate the intrinsic dimension by controlling the image generation process. Code for our experiments may be found  \\href{https://github.com/ppope/dimensions}{here}.",
        "conference": "ICLR",
        "中文标题": "图像的内在维度及其对学习的影响",
        "摘要翻译": "人们普遍认为，尽管传统像素表示具有高维度，但自然图像数据展现出低维结构。这一观点构成了深度学习在计算机视觉领域取得显著成功的常见直觉基础。在本研究中，我们对流行数据集应用维度估计工具，并探讨低维结构在深度学习中的作用。我们发现，常见的自然图像数据集相对于图像中的高像素数确实具有非常低的内在维度。此外，我们发现低维数据集对神经网络来说更容易学习，并且解决这些任务的模型从训练数据到测试数据的泛化能力更强。在此过程中，我们开发了一种技术，用于在由GAN生成的合成数据上验证我们的维度估计工具，这使我们能够通过控制图像生成过程来主动操纵内在维度。我们的实验代码可以在这里找到。",
        "领域": "深度学习理论、计算机视觉、生成对抗网络",
        "问题": "探讨自然图像数据的低维结构特性及其对深度学习模型学习和泛化能力的影响",
        "动机": "理解为何深度学习在计算机视觉领域能够取得显著成功，以及低维数据结构在这一过程中的作用",
        "方法": "应用维度估计工具分析数据集的内在维度，开发技术验证维度估计工具的有效性，并通过控制GAN生成的图像过程操纵内在维度",
        "关键词": [
            "内在维度",
            "深度学习",
            "计算机视觉",
            "生成对抗网络",
            "维度估计"
        ],
        "涉及的技术概念": {
            "内在维度": "描述数据实际所在的低维空间，远低于其原始表示的高维空间，影响模型的学习效率和泛化能力",
            "维度估计工具": "用于估计数据集内在维度的技术或方法，帮助理解数据的结构特性",
            "生成对抗网络": "用于生成合成数据的技术，通过控制生成过程可以操纵数据的内在维度，用于验证维度估计工具的有效性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 773,
        "title": "Theoretical Analysis of Self-Training with Deep Networks on Unlabeled Data",
        "html": "https://iclr.cc//virtual/2021/poster/2547",
        "abstract": "Self-training algorithms, which train a model to fit pseudolabels predicted by another previously-learned model, have been very successful for learning with unlabeled data using neural networks. However, the current theoretical understanding of self-training only applies to linear models. This work provides a unified theoretical analysis of self-training with deep networks for semi-supervised learning, unsupervised domain adaptation, and unsupervised learning. At the core of our analysis is a simple but realistic “expansion” assumption, which states that a low-probability subset of the data must expand to a neighborhood with large probability relative to the subset. We also assume that neighborhoods of examples in different classes have minimal overlap. We prove that under these assumptions, the minimizers of population objectives based on self-training and input-consistency regularization will achieve high accuracy with respect to ground-truth labels. By using off-the-shelf generalization bounds, we immediately convert this result to sample complexity guarantees for neural nets that are polynomial in the margin and Lipschitzness. Our results help explain the empirical successes of recently proposed self-training algorithms which use input consistency regularization.",
        "conference": "ICLR",
        "中文标题": "深度网络在无标签数据上自训练的理论分析",
        "摘要翻译": "自训练算法通过训练模型以适应另一个先前学习模型预测的伪标签，在使用神经网络进行无标签数据学习方面取得了巨大成功。然而，目前对自训练的理论理解仅适用于线性模型。这项工作为半监督学习、无监督领域适应和无监督学习中的深度网络自训练提供了一个统一的理论分析。我们分析的核心是一个简单但现实的“扩展”假设，该假设指出数据的低概率子集必须扩展到相对于该子集具有较大概率的邻域。我们还假设不同类别样本的邻域具有最小的重叠。我们证明，在这些假设下，基于自训练和输入一致性正则化的总体目标的最小化器将实现相对于真实标签的高准确度。通过使用现成的泛化界限，我们立即将这一结果转化为对神经网络的样本复杂度保证，这些保证在边际和Lipschitzness上是多项式的。我们的结果有助于解释最近提出的使用输入一致性正则化的自训练算法的经验成功。",
        "领域": "半监督学习, 无监督领域适应, 无监督学习",
        "问题": "理解深度网络在无标签数据上自训练的理论基础",
        "动机": "当前对自训练的理论理解仅适用于线性模型，缺乏对深度网络的理论分析",
        "方法": "提出一个统一的理论分析框架，基于“扩展”假设和输入一致性正则化，分析自训练算法在半监督学习、无监督领域适应和无监督学习中的应用",
        "关键词": [
            "自训练",
            "深度网络",
            "无标签数据",
            "半监督学习",
            "输入一致性正则化"
        ],
        "涉及的技术概念": {
            "扩展假设": "假设数据的低概率子集必须扩展到相对于该子集具有较大概率的邻域，为自训练算法的理论分析提供基础",
            "输入一致性正则化": "一种正则化技术，用于确保模型对输入的小变化具有一致性，提高模型的泛化能力",
            "Lipschitzness": "描述函数变化率的数学概念，用于量化神经网络的复杂性和泛化能力"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 774,
        "title": "Theoretical bounds on estimation error for meta-learning",
        "html": "https://iclr.cc//virtual/2021/poster/2895",
        "abstract": "Machine learning models have traditionally been developed under the assumption that the training and test distributions match exactly. However, recent success in few-shot learning and related problems are encouraging signs that these models can be adapted to more realistic settings where train and test distributions differ. Unfortunately, there is severely limited theoretical support for these algorithms and little is known about the difficulty of these problems. In this work, we provide novel information-theoretic lower-bounds on minimax rates of convergence for algorithms that are trained on data from multiple sources and tested on novel data. Our bounds depend intuitively on the information shared between sources of data, and characterize the difficulty of learning in this setting for arbitrary algorithms. We demonstrate these bounds on a hierarchical Bayesian model of meta-learning, computing both upper and lower bounds on parameter estimation via maximum-a-posteriori inference.",
        "conference": "ICLR",
        "中文标题": "元学习估计误差的理论界限",
        "摘要翻译": "机器学习模型传统上是在训练和测试分布完全匹配的假设下开发的。然而，最近在少样本学习及相关问题上的成功，是这些模型能够适应训练和测试分布不同的更现实设置的一个令人鼓舞的迹象。不幸的是，这些算法的理论支持非常有限，对这些问题的难度知之甚少。在这项工作中，我们为从多个数据源训练并在新数据上测试的算法提供了新颖的信息论下界，关于最小最大收敛率。我们的界限直观地依赖于数据源之间共享的信息，并描述了在这种设置下学习对于任意算法的难度。我们通过在元学习的层次贝叶斯模型上演示这些界限，通过最大后验推理计算参数估计的上界和下界。",
        "领域": "元学习",
        "问题": "在训练和测试分布不同的情况下，机器学习模型的适应性和性能评估的理论支持不足",
        "动机": "为元学习算法在训练和测试分布不匹配的情况下的性能提供理论界限，以填补当前理论支持的空白",
        "方法": "利用信息论方法推导最小最大收敛率的下界，并在层次贝叶斯模型中进行参数估计的上下界计算",
        "关键词": [
            "元学习",
            "信息论界限",
            "层次贝叶斯模型",
            "最小最大收敛率",
            "最大后验推理"
        ],
        "涉及的技术概念": {
            "信息论界限": "用于量化在训练和测试分布不同情况下，元学习算法的性能极限",
            "层次贝叶斯模型": "作为元学习的一个实例，用于展示理论界限在实际模型中的应用",
            "最大后验推理": "用于在层次贝叶斯模型中计算参数估计的上下界，以验证理论界限"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 775,
        "title": "The Recurrent Neural Tangent Kernel",
        "html": "https://iclr.cc//virtual/2021/poster/2590",
        "abstract": "The study of deep neural networks (DNNs) in the infinite-width limit, via the so-called neural tangent kernel (NTK) approach, has provided new insights into the dynamics of learning, generalization, and the impact of initialization. One key DNN architecture remains to be kernelized, namely, the recurrent neural network (RNN).  In this paper we introduce and study the Recurrent Neural Tangent Kernel (RNTK), which provides new insights into the behavior of  overparametrized RNNs. A key property of the RNTK should greatly benefit practitioners is its ability to compare inputs of different length. To this end, we characterize how the RNTK weights different time steps to form its output under different initialization parameters and nonlinearity choices. A synthetic and 56 real-world data experiments demonstrate that the RNTK offers significant performance gains over other kernels, including standard NTKs, across a wide array of data sets. ",
        "conference": "ICLR",
        "中文标题": "循环神经正切核",
        "摘要翻译": "通过所谓的神经正切核（NTK）方法，在无限宽度极限下对深度神经网络（DNNs）的研究，为学习动态、泛化以及初始化影响提供了新的见解。一个关键的DNN架构尚未被核化，即循环神经网络（RNN）。在本文中，我们介绍并研究了循环神经正切核（RNTK），它为过参数化RNNs的行为提供了新的见解。RNTK的一个关键特性是其能够比较不同长度的输入，这应该会极大地惠及实践者。为此，我们描述了RNTK在不同初始化参数和非线性选择下如何加权不同时间步以形成其输出。合成和56个真实世界数据的实验表明，RNTK在包括标准NTKs在内的多种数据集上提供了显著的性能提升。",
        "领域": "深度学习理论、循环神经网络、核方法",
        "问题": "如何将神经正切核方法扩展到循环神经网络，以理解和优化其学习动态和泛化能力。",
        "动机": "探索循环神经网络在无限宽度极限下的行为，为实践者提供更有效的工具来比较不同长度的输入。",
        "方法": "引入并研究循环神经正切核（RNTK），分析其在不同初始化参数和非线性选择下的行为，并通过实验验证其性能。",
        "关键词": [
            "循环神经正切核",
            "无限宽度极限",
            "过参数化",
            "循环神经网络",
            "核方法"
        ],
        "涉及的技术概念": {
            "神经正切核（NTK）": "用于在无限宽度极限下分析深度神经网络的学习动态和泛化能力的工具。",
            "循环神经网络（RNN）": "一种处理序列数据的神经网络架构，本文研究其在无限宽度极限下的行为。",
            "过参数化": "指网络的参数数量远大于训练样本数量的情况，本文研究过参数化RNNs的行为。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 776,
        "title": "The Risks of Invariant Risk Minimization",
        "html": "https://iclr.cc//virtual/2021/poster/2752",
        "abstract": "Invariant Causal Prediction (Peters et al., 2016) is a technique for out-of-distribution generalization which assumes that some aspects of the data distribution vary across the training set but that the underlying causal mechanisms remain constant. Recently, Arjovsky et al. (2019) proposed Invariant Risk Minimization (IRM), an objective based on this idea for learning deep, invariant features of data which are a complex function of latent variables; many alternatives have subsequently been suggested.  However, formal guarantees for all of these works are severely lacking.  In this paper,  we present the first analysis of classification under the IRM objective—as well as these recently proposed alternatives—under a fairly natural and general model. In the linear case, we show simple conditions under which the optimal solution succeeds or, more often, fails to recover the optimal invariant predictor. We furthermore present the very first results in the non-linear regime: we demonstrate that IRM can fail catastrophically unless the test data is sufficiently similar to the training distribution—this is precisely the issue that it was intended to solve. Thus, in this setting we find that IRM and its alternatives fundamentally do not improve over standard Empirical Risk Minimization.",
        "conference": "ICLR",
        "中文标题": "不变风险最小化的风险",
        "摘要翻译": "不变因果预测（Peters等人，2016）是一种用于分布外泛化的技术，它假设数据分布的某些方面在训练集中变化，但潜在的因果机制保持不变。最近，Arjovsky等人（2019）提出了不变风险最小化（IRM），这是一个基于这一思想的客观目标，用于学习数据的深层不变特征，这些特征是潜在变量的复杂函数；随后提出了许多替代方案。然而，所有这些工作的正式保证都严重缺乏。在本文中，我们首次在一个相当自然和一般的模型下，对IRM目标以及这些最近提出的替代方案下的分类进行了分析。在线性情况下，我们展示了简单条件下最优解成功或更常见地未能恢复最优不变预测器的情况。此外，我们首次展示了非线性区域的结果：我们证明，除非测试数据与训练分布足够相似，否则IRM可能会灾难性地失败——这正是它旨在解决的问题。因此，在这种设置下，我们发现IRM及其替代方案基本上没有比标准的经验风险最小化有所改进。",
        "领域": "机器学习理论",
        "问题": "分析不变风险最小化（IRM）及其替代方案在分类任务中的表现，特别是在分布外泛化方面的有效性。",
        "动机": "由于现有关于IRM及其替代方案的正式保证严重缺乏，本研究旨在填补这一空白，特别是在线性和非线性情况下，评估这些方法在恢复最优不变预测器方面的能力。",
        "方法": "本研究在一个自然和一般的模型下，对IRM目标及其替代方案下的分类进行了分析，包括线性和非线性情况下的条件分析。",
        "关键词": [
            "不变风险最小化",
            "分布外泛化",
            "因果预测",
            "经验风险最小化"
        ],
        "涉及的技术概念": {
            "不变因果预测": "一种假设数据分布的某些方面变化但因果机制不变的技术，用于分布外泛化。",
            "不变风险最小化": "一种学习数据深层不变特征的客观目标，旨在解决分布外泛化问题。",
            "经验风险最小化": "一种标准的机器学习方法，通过最小化训练数据上的损失来学习模型。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 777,
        "title": "The role of Disentanglement in Generalisation",
        "html": "https://iclr.cc//virtual/2021/poster/3173",
        "abstract": "Combinatorial generalisation — the ability to understand and produce novel combinations of familiar elements — is a core capacity of human intelligence that current AI systems struggle with. Recently, it has been suggested that learning disentangled representations may help address this problem. It is claimed that such representations should be able to capture the compositional structure of the world which can then be combined to support combinatorial generalisation. In this study, we systematically tested how the degree of disentanglement affects various forms of generalisation, including two forms of combinatorial generalisation that varied in difficulty. We trained three classes of variational autoencoders (VAEs) on two datasets on an unsupervised task by excluding combinations of generative factors during training. At test time we ask the models to reconstruct the missing combinations in order to measure generalisation performance. Irrespective of the degree of disentanglement, we found that the models supported only weak combinatorial generalisation. We obtained the same outcome when we directly input perfectly disentangled representations as the latents, and when we tested a model on a more complex task that explicitly required independent generative factors to be controlled. While learning disentangled representations does improve interpretability and sample efficiency in some downstream tasks, our results suggest that they are not sufficient for supporting more difficult forms of generalisation.",
        "conference": "ICLR",
        "中文标题": "解缠在泛化中的作用",
        "摘要翻译": "组合泛化——即理解和产生熟悉元素的新组合的能力——是人类智能的核心能力，而当前的AI系统在这方面存在困难。最近，有建议认为学习解缠表示可能有助于解决这个问题。据称，这样的表示应该能够捕捉世界的组合结构，然后可以结合起来支持组合泛化。在本研究中，我们系统地测试了解缠程度如何影响各种形式的泛化，包括两种难度不同的组合泛化形式。我们通过在训练期间排除生成因素的组合，在两个数据集上对三类变分自编码器（VAEs）进行了无监督任务的训练。在测试时，我们要求模型重建缺失的组合以衡量泛化性能。无论解缠程度如何，我们发现模型仅支持弱组合泛化。当我们直接将完美解缠的表示作为潜在输入时，以及当我们在一个更复杂的任务上测试一个模型时，该任务明确要求控制独立的生成因素，我们得到了相同的结果。虽然学习解缠表示确实在某些下游任务中提高了可解释性和样本效率，但我们的结果表明，它们不足以支持更困难形式的泛化。",
        "领域": "表示学习、组合泛化、变分自编码器",
        "问题": "探索解缠表示是否能够支持组合泛化，特别是更困难形式的泛化。",
        "动机": "当前AI系统在组合泛化方面存在困难，研究解缠表示是否能作为解决方案。",
        "方法": "使用三类变分自编码器（VAEs）在无监督任务上训练，通过排除生成因素的组合来测试泛化性能。",
        "关键词": [
            "解缠表示",
            "组合泛化",
            "变分自编码器",
            "无监督学习",
            "生成因素"
        ],
        "涉及的技术概念": {
            "解缠表示": "旨在分离数据中的独立变化因素，以提高模型的可解释性和泛化能力。",
            "变分自编码器（VAEs）": "一种生成模型，用于学习数据的潜在表示，本研究中使用来探索解缠表示对泛化的影响。",
            "组合泛化": "理解和产生熟悉元素的新组合的能力，本研究探讨解缠表示是否能够支持这种能力。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 778,
        "title": "The Role of Momentum Parameters in the Optimal Convergence of Adaptive Polyak's Heavy-ball Methods",
        "html": "https://iclr.cc//virtual/2021/poster/2771",
        "abstract": "The adaptive stochastic gradient descent (SGD) with momentum has been widely adopted in deep learning as well as convex optimization. In practice, the last iterate is commonly used as the final solution. However, the available regret analysis and the setting of constant momentum parameters only guarantee the optimal convergence of the averaged solution. In this paper, we fill this theory-practice gap by investigating the convergence of the last iterate (referred to as {\\it individual convergence}), which is a more difficult task than convergence analysis of the averaged solution. Specifically, in the constrained convex cases, we prove that the adaptive Polyak's Heavy-ball (HB) method, in which the step size is only updated using the exponential moving average strategy, attains an individual convergence rate of $O(\\frac{1}{\\sqrt{t}})$, as opposed to that of $O(\\frac{\\log t}{\\sqrt {t}})$ of SGD, where $t$ is the number of iterations. Our new analysis not only shows how the HB momentum and its time-varying weight help us to achieve the acceleration in convex optimization but also gives valuable hints how the momentum parameters should be scheduled in deep learning. Empirical results validate the correctness of our convergence analysis in optimizing convex functions and demonstrate the improved performance of the adaptive HB methods in training deep networks.",
        "conference": "ICLR",
        "中文标题": "动量参数在自适应Polyak重球法最优收敛中的作用",
        "摘要翻译": "带有动量的自适应随机梯度下降（SGD）已在深度学习和凸优化中广泛采用。在实践中，最后一次迭代通常被用作最终解。然而，现有的遗憾分析和恒定动量参数的设置仅保证了平均解的最优收敛。在本文中，我们通过研究最后一次迭代的收敛（称为个体收敛）来填补这一理论与实践之间的差距，这比平均解的收敛分析更为困难。具体来说，在约束凸情况下，我们证明了自适应Polyak重球（HB）方法，其中步长仅使用指数移动平均策略更新，达到了O(1/√t)的个体收敛率，而SGD的收敛率为O(log t/√t)，其中t是迭代次数。我们的新分析不仅展示了HB动量及其时变权重如何帮助我们在凸优化中实现加速，而且还提供了关于在深度学习中应如何安排动量参数的有价值提示。实证结果验证了我们在优化凸函数时收敛分析的正确性，并展示了自适应HB方法在训练深度网络中的改进性能。",
        "领域": "深度学习优化、凸优化、自适应学习率方法",
        "问题": "解决自适应随机梯度下降方法中最后一次迭代的收敛性问题，以及动量参数的最优设置问题。",
        "动机": "填补自适应随机梯度下降方法在理论与实践之间的差距，特别是在最后一次迭代的收敛性和动量参数设置方面。",
        "方法": "研究自适应Polyak重球方法，通过指数移动平均策略更新步长，分析其个体收敛性，并与SGD进行比较。",
        "关键词": [
            "自适应随机梯度下降",
            "Polyak重球方法",
            "个体收敛",
            "动量参数",
            "深度学习优化"
        ],
        "涉及的技术概念": {
            "自适应随机梯度下降": "一种优化算法，通过调整学习率来适应不同的数据特征，以提高训练效率和模型性能。",
            "Polyak重球方法": "一种带有动量的优化方法，通过引入动量项来加速收敛过程，特别是在凸优化问题中。",
            "个体收敛": "指优化算法中最后一次迭代的收敛性能，与平均解的收敛性能相比，更能反映实际应用中的表现。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 779,
        "title": "The Traveling Observer Model: Multi-task Learning Through Spatial Variable Embeddings",
        "html": "https://iclr.cc//virtual/2021/poster/3007",
        "abstract": "This paper frames a general prediction system as an observer traveling around a continuous space, measuring values at some locations, and predicting them at others. The observer is completely agnostic about any particular task being solved; it cares only about measurement locations and their values. This perspective leads to a machine learning framework in which seemingly unrelated tasks can be solved by a single model, by embedding their input and output variables into a shared space. An implementation of the framework is developed in which these variable embeddings are learned jointly with internal model parameters. In experiments, the approach is shown to (1) recover intuitive locations of variables in space and time, (2) exploit regularities across related datasets with completely disjoint input and output spaces, and (3) exploit regularities across seemingly unrelated tasks, outperforming task-specific single-task models and multi-task learning alternatives. The results suggest that even seemingly unrelated tasks may originate from similar underlying processes, a fact that the traveling observer model can use to make better predictions.",
        "conference": "ICLR",
        "中文标题": "旅行观察者模型：通过空间变量嵌入实现多任务学习",
        "摘要翻译": "本文提出了一种通用预测系统的框架，该系统被视作一个在连续空间中移动的观察者，它在某些位置测量值，并在其他位置进行预测。观察者对正在解决的任何特定任务完全无知；它只关心测量位置及其值。这一视角引出了一个机器学习框架，在该框架中，通过将输入和输出变量嵌入到一个共享空间中，可以由单一模型解决看似无关的任务。开发了该框架的一个实现，其中这些变量嵌入与内部模型参数联合学习。在实验中，该方法被证明能够（1）恢复变量在空间和时间中的直观位置，（2）利用输入和输出空间完全不相交的相关数据集之间的规律性，（3）利用看似无关任务之间的规律性，优于特定任务的单任务模型和多任务学习替代方案。结果表明，即使是看似无关的任务也可能源自相似的底层过程，旅行观察者模型可以利用这一事实做出更好的预测。",
        "领域": "多任务学习, 空间变量嵌入, 预测系统",
        "问题": "如何通过单一模型解决看似无关的任务",
        "动机": "探索不同任务之间潜在的相似性，以提高预测性能",
        "方法": "通过将输入和输出变量嵌入到共享空间，实现多任务学习",
        "关键词": [
            "多任务学习",
            "空间变量嵌入",
            "预测系统",
            "共享空间",
            "观察者模型"
        ],
        "涉及的技术概念": {
            "空间变量嵌入": "将输入和输出变量映射到一个共享的连续空间中，以便模型能够学习不同任务之间的关系",
            "多任务学习": "通过共享表示学习多个任务，以提高模型的泛化能力和效率",
            "观察者模型": "一个在连续空间中移动的框架，用于测量和预测值，而不关心具体的任务"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 780,
        "title": "The Unreasonable Effectiveness of Patches in Deep Convolutional Kernels Methods",
        "html": "https://iclr.cc//virtual/2021/poster/2616",
        "abstract": "A recent line of work showed that  various forms of convolutional  kernel methods can be competitive with standard supervised deep convolutional networks on datasets like CIFAR-10, obtaining accuracies in the range of 87-90% while being more amenable to theoretical analysis. In this work, we highlight the importance of a data-dependent feature extraction step that is key to the obtain good performance in convolutional kernel methods. This step typically corresponds to a whitened dictionary of patches, and gives rise to a data-driven convolutional kernel methods.We extensively study its effect, demonstrating it is the key ingredient for high performance of these methods. Specifically, we show that one of the simplest instances of such kernel methods, based on a single layer of  image patches followed by a linear classifier is already obtaining classification accuracies on CIFAR-10 in the same range as previous more sophisticated convolutional kernel methods. We scale this method to the challenging ImageNet dataset, showing such a simple approach can exceed all existing non-learned representation methods. This is a new baseline for object recognition without representation learning methods, that  initiates the investigation of  convolutional kernel models  on ImageNet. We conduct experiments to analyze the dictionary that we used, our ablations showing they exhibit low-dimensional properties.",
        "conference": "ICLR",
        "中文标题": "深度卷积核方法中补丁的不合理有效性",
        "摘要翻译": "最近的一系列研究表明，各种形式的卷积核方法可以在CIFAR-10等数据集上与标准的监督深度卷积网络竞争，获得87-90%的准确率，同时更易于理论分析。在这项工作中，我们强调了数据依赖性特征提取步骤的重要性，这是卷积核方法获得良好性能的关键。这一步骤通常对应于一个白化的补丁字典，并产生数据驱动的卷积核方法。我们广泛研究了其效果，证明它是这些方法高性能的关键因素。具体来说，我们展示了基于单层图像补丁后接线性分类器的这种核方法的最简单实例，已经在CIFAR-10上获得了与之前更复杂的卷积核方法相同的分类准确率范围。我们将这种方法扩展到具有挑战性的ImageNet数据集，表明这种简单的方法可以超过所有现有的非学习表示方法。这是没有表示学习方法的对象识别的新基线，它启动了卷积核模型在ImageNet上的研究。我们进行了实验来分析我们使用的字典，我们的消融研究表明它们表现出低维特性。",
        "领域": "卷积核方法、图像分类、特征提取",
        "问题": "如何在卷积核方法中通过数据依赖性特征提取步骤提高性能",
        "动机": "探索卷积核方法在图像分类任务中的潜力，特别是在不依赖复杂表示学习的情况下实现高性能",
        "方法": "采用基于单层图像补丁和线性分类器的简单卷积核方法，并通过数据驱动的特征提取步骤优化性能",
        "关键词": [
            "卷积核方法",
            "特征提取",
            "图像分类",
            "CIFAR-10",
            "ImageNet"
        ],
        "涉及的技术概念": {
            "数据依赖性特征提取": "在卷积核方法中，通过分析输入数据来优化特征提取步骤，以提高模型性能",
            "白化的补丁字典": "用于预处理图像补丁的技术，旨在减少数据冗余和增强特征表示",
            "线性分类器": "在卷积核方法的最后阶段使用，用于基于提取的特征进行分类决策"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 781,
        "title": "Tilted Empirical Risk Minimization",
        "html": "https://iclr.cc//virtual/2021/poster/2679",
        "abstract": "Empirical risk minimization (ERM) is typically designed to perform well on the average loss, which can result in estimators that are sensitive to outliers, generalize poorly, or treat subgroups unfairly. While many methods aim to address these problems individually, in this work, we explore them through a unified framework---tilted empirical risk minimization (TERM). In particular, we show that it is possible to flexibly tune the impact of individual losses through a straightforward extension to ERM using a hyperparameter called the tilt. We provide several interpretations of the resulting framework: We show that TERM can increase or decrease the influence of outliers, respectively, to enable fairness or robustness; has variance-reduction properties that can benefit generalization; and can be viewed as a smooth approximation to a superquantile method. We develop batch and stochastic first-order optimization methods for solving TERM, and show that the problem can be efficiently solved relative to common alternatives. Finally, we demonstrate that TERM can be used for a multitude of applications, such as enforcing fairness between subgroups, mitigating the effect of outliers, and handling class imbalance. TERM is not only competitive with existing solutions tailored to these individual problems, but can also enable entirely new applications, such as simultaneously addressing outliers and promoting fairness.",
        "conference": "ICLR",
        "中文标题": "倾斜经验风险最小化",
        "摘要翻译": "经验风险最小化（ERM）通常设计为在平均损失上表现良好，这可能导致估计器对异常值敏感、泛化能力差或对子组不公平。虽然许多方法旨在单独解决这些问题，但在本工作中，我们通过一个统一的框架——倾斜经验风险最小化（TERM）来探索它们。特别是，我们展示了通过使用称为倾斜的超参数对ERM进行简单扩展，可以灵活调整个体损失的影响。我们提供了对结果框架的几种解释：我们展示了TERM可以分别增加或减少异常值的影响，以实现公平性或鲁棒性；具有可以有益于泛化的方差减少特性；并且可以被视为超分位数方法的平滑近似。我们开发了用于解决TERM的批量和随机一阶优化方法，并表明相对于常见替代方案，该问题可以高效解决。最后，我们证明了TERM可以用于多种应用，例如在子组之间实施公平性、减轻异常值的影响以及处理类别不平衡。TERM不仅与针对这些个别问题的现有解决方案竞争，而且还可以实现全新的应用，例如同时解决异常值和促进公平性。",
        "领域": "机器学习公平性, 鲁棒机器学习, 优化算法",
        "问题": "解决经验风险最小化在处理异常值、泛化能力和子组公平性方面的局限性",
        "动机": "通过统一的框架同时解决经验风险最小化在公平性、鲁棒性和泛化能力方面的问题",
        "方法": "引入倾斜超参数扩展经验风险最小化，开发批量和随机一阶优化方法",
        "关键词": [
            "倾斜经验风险最小化",
            "机器学习公平性",
            "鲁棒性优化",
            "异常值处理",
            "类别不平衡"
        ],
        "涉及的技术概念": {
            "倾斜经验风险最小化（TERM）": "通过引入倾斜超参数调整个体损失的影响，以实现公平性、鲁棒性和泛化能力的平衡",
            "超分位数方法": "TERM可以视为超分位数方法的平滑近似，用于处理分布尾部的极端值",
            "一阶优化方法": "开发了批量和随机一阶优化方法，用于高效解决TERM问题"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 782,
        "title": "Tomographic Auto-Encoder: Unsupervised Bayesian Recovery of Corrupted Data",
        "html": "https://iclr.cc//virtual/2021/poster/2666",
        "abstract": "We propose a new probabilistic method for unsupervised recovery of corrupted data. Given a large ensemble of degraded samples, our method recovers accurate posteriors of clean values, allowing the exploration of the manifold of possible reconstructed data and hence characterising the underlying uncertainty. In this set-ting, direct application of classical variational methods often gives rise to collapsed densities that do not adequately explore the solution space.  Instead, we derive our novel reduced entropy condition approximate inference method that results in rich posteriors.  We test our model in a data recovery task under the common setting of missing values and noise, demonstrating superior performance to existing variational methods for imputation and de-noising with different real data sets. We further show higher classification accuracy after imputation, proving the advantage of propagating uncertainty to downstream tasks with our model.",
        "conference": "ICLR",
        "中文标题": "层析自编码器：无监督贝叶斯恢复损坏数据",
        "摘要翻译": "我们提出了一种新的概率方法，用于无监督恢复损坏数据。给定大量退化样本，我们的方法能够恢复干净值的准确后验，从而探索可能重建数据的流形，进而表征潜在的不确定性。在此设置下，直接应用经典的变分方法往往会产生坍塌的密度，无法充分探索解空间。相反，我们推导出了新颖的降熵条件近似推理方法，该方法能够产生丰富的后验。我们在缺失值和噪声的常见设置下测试了我们的模型在数据恢复任务中的表现，证明了在不同真实数据集上，对于插补和去噪任务，我们的方法优于现有的变分方法。我们进一步展示了插补后更高的分类准确率，证明了我们的模型在将不确定性传播到下游任务中的优势。",
        "领域": "无监督学习、数据恢复、概率建模",
        "问题": "如何在无监督设置下有效恢复损坏数据并表征不确定性",
        "动机": "解决现有变分方法在恢复损坏数据时后验坍塌、无法充分探索解空间的问题",
        "方法": "提出降熵条件近似推理方法，生成丰富后验以探索数据重建的流形",
        "关键词": [
            "无监督学习",
            "数据恢复",
            "贝叶斯方法",
            "降熵条件",
            "近似推理"
        ],
        "涉及的技术概念": {
            "降熵条件近似推理": "一种新颖的近似推理方法，通过降低熵的条件来避免后验坍塌，生成能够充分探索解空间的丰富后验",
            "数据流形": "指数据在潜在空间中的分布结构，通过探索数据流形可以更好地理解数据的潜在特性和不确定性",
            "后验坍塌": "指在变分推理中，后验分布过于集中，无法充分反映数据的不确定性和多样性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 783,
        "title": "Topology-Aware Segmentation Using Discrete Morse Theory",
        "html": "https://iclr.cc//virtual/2021/poster/2910",
        "abstract": "In the segmentation of fine-scale structures from natural and biomedical images, per-pixel accuracy is not the only metric of concern. Topological correctness, such as vessel connectivity and membrane closure, is crucial for downstream analysis tasks. In this paper, we propose a new approach to train deep image segmentation networks for better topological accuracy. In particular, leveraging the power of discrete Morse theory (DMT), we identify global structures, including 1D skeletons and 2D patches, which are important for topological accuracy. Trained with a novel loss based on these global structures, the network performance is significantly improved especially near topologically challenging locations (such as weak spots of connections and membranes). On diverse datasets, our method achieves superior performance on both the DICE score and topological metrics.",
        "conference": "ICLR",
        "中文标题": "基于离散莫尔斯理论的拓扑感知分割",
        "摘要翻译": "在自然和生物医学图像中精细结构的分割过程中，像素级精度并非唯一关注的指标。拓扑正确性，如血管连通性和膜闭合性，对于后续分析任务至关重要。本文提出了一种新方法，用于训练深度图像分割网络以获得更好的拓扑准确性。特别是利用离散莫尔斯理论（DMT）的力量，我们识别了对拓扑准确性重要的全局结构，包括1D骨架和2D补丁。通过基于这些全局结构的新颖损失函数训练，网络性能在拓扑挑战性位置（如连接的弱点和膜）附近显著提高。在多样化的数据集上，我们的方法在DICE分数和拓扑指标上均实现了卓越的性能。",
        "领域": "图像分割、生物医学图像分析、拓扑数据分析",
        "问题": "提高图像分割中拓扑结构的准确性",
        "动机": "为了解决在图像分割过程中保持关键拓扑结构（如血管连通性和膜闭合性）的挑战",
        "方法": "利用离散莫尔斯理论识别对拓扑准确性重要的全局结构，并基于这些结构设计新颖的损失函数来训练深度分割网络",
        "关键词": [
            "离散莫尔斯理论",
            "拓扑感知分割",
            "深度图像分割",
            "拓扑准确性",
            "生物医学图像"
        ],
        "涉及的技术概念": {
            "离散莫尔斯理论": "用于识别和分析图像中的全局拓扑结构，如1D骨架和2D补丁，以提高分割的拓扑准确性",
            "拓扑准确性": "指分割结果在保持如血管连通性和膜闭合性等关键拓扑结构方面的正确性",
            "深度图像分割网络": "采用深度学习技术进行图像分割的网络，本文通过改进其损失函数来优化拓扑准确性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 784,
        "title": "Towards Faster and Stabilized GAN Training for High-fidelity Few-shot Image Synthesis",
        "html": "https://iclr.cc//virtual/2021/poster/3048",
        "abstract": "Training Generative Adversarial Networks (GAN) on high-fidelity images usually requires large-scale GPU-clusters and a vast number of training images. In this paper, we study the few-shot image synthesis task for GAN with minimum computing cost. We propose a light-weight GAN structure that gains superior quality on 1024^2 resolution. Notably, the model converges from scratch with just a few hours of training on a single RTX-2080 GPU, and has a consistent performance, even with less than 100 training samples. Two technique designs constitute our work, a skip-layer channel-wise excitation module and a self-supervised discriminator trained as a feature-encoder. With thirteen datasets covering a wide variety of image domains (The datasets and code are available at https://github.com/odegeasslbc/FastGAN-pytorch), we show our model's superior performance compared to the state-of-the-art StyleGAN2, when data and computing budget are limited.",
        "conference": "ICLR",
        "中文标题": "迈向更快更稳定的GAN训练以实现高保真少样本图像合成",
        "摘要翻译": "在高保真图像上训练生成对抗网络（GAN）通常需要大规模的GPU集群和大量的训练图像。在本文中，我们研究了以最小计算成本实现GAN的少样本图像合成任务。我们提出了一种轻量级的GAN结构，在1024^2分辨率上获得了卓越的质量。值得注意的是，该模型仅需在单个RTX-2080 GPU上训练几小时即可从零开始收敛，并且即使在少于100个训练样本的情况下也能保持一致的性能。我们的工作由两个技术设计构成，一个是跳跃层通道激励模块，另一个是作为特征编码器训练的自监督判别器。通过覆盖广泛图像领域的十三个数据集（数据集和代码可在https://github.com/odegeasslbc/FastGAN-pytorch获取），我们展示了在数据和计算预算有限的情况下，我们的模型与最先进的StyleGAN2相比具有优越的性能。",
        "领域": "生成对抗网络、少样本学习、图像合成",
        "问题": "如何在有限的计算资源和少量训练样本下实现高保真图像的快速稳定合成",
        "动机": "减少高保真图像合成所需的计算资源和训练样本数量，降低训练成本",
        "方法": "提出轻量级GAN结构，包含跳跃层通道激励模块和自监督判别器，实现快速收敛和稳定训练",
        "关键词": [
            "轻量级GAN",
            "少样本学习",
            "高保真图像合成",
            "自监督学习",
            "跳跃层激励"
        ],
        "涉及的技术概念": {
            "跳跃层通道激励模块": "用于增强模型对图像特征的提取能力，提高生成图像的质量",
            "自监督判别器": "作为特征编码器训练，帮助模型在少量样本下学习更有效的特征表示",
            "轻量级GAN结构": "设计用于减少计算资源消耗，同时保持或提高生成图像的质量"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 785,
        "title": "Towards Impartial Multi-task Learning",
        "html": "https://iclr.cc//virtual/2021/poster/2894",
        "abstract": "Multi-task learning (MTL) has been widely used in representation learning. However, naively training all tasks simultaneously may lead to the partial training issue, where specific tasks are trained more adequately than others. In this paper, we propose to learn multiple tasks impartially. Specifically, for the task-shared parameters, we optimize the scaling factors via a closed-form solution, such that the aggregated gradient (sum of raw gradients weighted by the scaling factors) has equal projections onto individual tasks. For the task-specific parameters, we dynamically weigh the task losses so that all of them are kept at a comparable scale. Further, we find the above gradient balance and loss balance are complementary and thus propose a hybrid balance method to further improve the performance. Our impartial multi-task learning (IMTL) can be end-to-end trained without any heuristic hyper-parameter tuning, and is general to be applied on all kinds of losses without any distribution assumption. Moreover, our IMTL can converge to similar results even when the task losses are designed to have different scales, and thus it is scale-invariant. We extensively evaluate our IMTL on the standard MTL benchmarks including Cityscapes, NYUv2 and CelebA. It outperforms existing loss weighting methods under the same experimental settings.",
        "conference": "ICLR",
        "中文标题": "迈向公正的多任务学习",
        "摘要翻译": "多任务学习（MTL）在表示学习中被广泛应用。然而，简单地同时训练所有任务可能会导致部分训练问题，即某些任务比其他任务得到更充分的训练。在本文中，我们提出了一种公正地学习多个任务的方法。具体来说，对于任务共享的参数，我们通过闭式解优化缩放因子，使得聚合梯度（由缩放因子加权的原始梯度的总和）在各个任务上的投影相等。对于任务特定的参数，我们动态地权衡任务损失，使得所有损失保持在可比较的规模。此外，我们发现上述梯度平衡和损失平衡是互补的，因此提出了一种混合平衡方法以进一步提高性能。我们的公正多任务学习（IMTL）可以端到端训练，无需任何启发式超参数调整，并且适用于所有类型的损失，无需任何分布假设。此外，即使任务损失设计有不同的规模，我们的IMTL也能收敛到相似的结果，因此它是规模不变的。我们在包括Cityscapes、NYUv2和CelebA在内的标准MTL基准上广泛评估了我们的IMTL。在相同的实验设置下，它优于现有的损失加权方法。",
        "领域": "多任务学习",
        "问题": "解决多任务学习中部分任务训练不充分的问题",
        "动机": "为了在多任务学习中实现各任务的公正训练，避免特定任务被过度训练而其他任务训练不足",
        "方法": "通过优化任务共享参数的缩放因子和动态权衡任务特定参数的损失，实现梯度平衡和损失平衡，并提出混合平衡方法",
        "关键词": [
            "多任务学习",
            "梯度平衡",
            "损失平衡",
            "公正训练",
            "规模不变性"
        ],
        "涉及的技术概念": {
            "梯度平衡": "通过优化缩放因子使得聚合梯度在各个任务上的投影相等，确保各任务梯度更新均衡",
            "损失平衡": "动态调整任务损失权重，保持所有任务损失在可比较的规模，避免某些任务主导训练过程",
            "混合平衡方法": "结合梯度平衡和损失平衡的优势，进一步提高多任务学习的性能和公正性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 786,
        "title": "Towards Nonlinear Disentanglement in Natural Data with Temporal Sparse Coding",
        "html": "https://iclr.cc//virtual/2021/poster/3144",
        "abstract": "Disentangling the underlying generative factors from complex data has so far been limited to carefully constructed scenarios. We propose a path towards natural data by first showing that the statistics of natural data provide enough structure to enable disentanglement, both theoretically and empirically. Specifically, we provide evidence that objects in natural movies undergo transitions that are typically small in magnitude with occasional large jumps, which is characteristic of a temporally sparse distribution. To address this finding we provide a novel proof that relies on a sparse prior on temporally adjacent observations to recover the true latent variables up to permutations and sign flips, directly providing a stronger result than previous work. We show that equipping practical estimation methods with our prior often surpasses the current state-of-the-art on several established benchmark datasets without any impractical assumptions, such as knowledge of the number of changing generative factors. Furthermore, we contribute two new benchmarks, Natural Sprites and KITTI Masks, which integrate the measured natural dynamics to enable disentanglement evaluation with more realistic datasets. We leverage these benchmarks to test our theory, demonstrating improved performance. We also identify non-obvious challenges for current methods in scaling to more natural domains. Taken together our work addresses key issues in disentanglement research for moving towards more natural settings. ",
        "conference": "ICLR",
        "中文标题": "面向自然数据中非线性解耦的时间稀疏编码",
        "摘要翻译": "迄今为止，从复杂数据中解耦潜在的生成因素仅限于精心构建的场景。我们提出了一条通向自然数据的路径，首先从理论和实证上证明自然数据的统计提供了足够的结构来实现解耦。具体来说，我们提供的证据表明，自然电影中的对象经历的变化通常在幅度上较小，偶尔会有大的跳跃，这是时间稀疏分布的特征。为了应对这一发现，我们提供了一个新颖的证明，该证明依赖于对时间相邻观察的稀疏先验，以恢复真实的潜在变量，直至排列和符号翻转，直接提供了比先前工作更强的结果。我们展示了将我们的先验应用于实际估计方法中，经常在几个已建立的基准数据集上超越当前的最先进技术，而无需任何不切实际的假设，如知道变化的生成因素的数量。此外，我们贡献了两个新的基准，Natural Sprites和KITTI Masks，它们整合了测量的自然动态，以启用更真实的数据集进行解耦评估。我们利用这些基准来测试我们的理论，展示了改进的性能。我们还识别了当前方法在扩展到更自然领域时面临的非明显挑战。总之，我们的工作解决了在向更自然设置迈进中的解耦研究中的关键问题。",
        "领域": "生成模型、无监督学习、视频理解",
        "问题": "如何在自然数据中实现非线性解耦，即从复杂数据中分离出潜在的生成因素。",
        "动机": "当前解耦研究多限于精心设计的场景，缺乏对自然数据的适用性，本研究旨在填补这一空白。",
        "方法": "提出了一种基于时间稀疏编码的方法，利用自然数据的统计特性，通过稀疏先验恢复潜在变量。",
        "关键词": [
            "非线性解耦",
            "时间稀疏编码",
            "自然数据",
            "生成模型",
            "无监督学习"
        ],
        "涉及的技术概念": {
            "时间稀疏编码": "利用时间相邻观察的稀疏性来恢复潜在变量，是本研究中的核心技术。",
            "非线性解耦": "指从复杂数据中分离出潜在的生成因素，本研究旨在在自然数据中实现这一目标。",
            "稀疏先验": "在模型中使用的一种假设，认为数据在某种表示下是稀疏的，本研究利用这一先验来提高解耦的准确性。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 787,
        "title": "Towards Resolving the Implicit Bias of Gradient Descent for Matrix Factorization: Greedy Low-Rank Learning",
        "html": "https://iclr.cc//virtual/2021/poster/3291",
        "abstract": "Matrix factorization is a simple and natural test-bed to investigate the implicit regularization of gradient descent. Gunasekar et al. (2017) conjectured that gradient flow with infinitesimal initialization converges to the solution that minimizes the nuclear norm, but a series of recent papers argued that the language of norm minimization is not sufficient to give a full characterization for the implicit regularization. In this work, we provide theoretical and empirical evidence that for depth-2 matrix factorization, gradient flow with infinitesimal initialization is mathematically equivalent to a simple heuristic rank minimization algorithm, Greedy Low-Rank Learning, under some reasonable assumptions. This generalizes the rank minimization view from previous works to a much broader setting and enables us to construct counter-examples to refute the conjecture from Gunasekar et al. (2017). We also extend the results to the case where depth >= 3, and we show that the benefit of being deeper is that the above convergence has a much weaker dependence over initialization magnitude so that this rank minimization is more likely to take effect for initialization with practical scale.",
        "conference": "ICLR",
        "中文标题": "解决矩阵分解中梯度下降隐式偏差的探索：贪婪低秩学习",
        "摘要翻译": "矩阵分解是研究梯度下降隐式正则化的一个简单而自然的测试平台。Gunasekar等人（2017年）推测，在无限小初始化的条件下，梯度流会收敛到最小化核范数的解，但最近的一系列论文认为，范数最小化的语言不足以完全描述隐式正则化。在这项工作中，我们提供了理论和实证证据，表明对于深度为2的矩阵分解，在无限小初始化的条件下，梯度流在数学上等同于一个简单的启发式秩最小化算法——贪婪低秩学习，这一结论基于一些合理的假设。这将秩最小化的视角从先前的工作推广到了一个更广泛的设置中，并使我们能够构建反例来反驳Gunasekar等人（2017年）的推测。我们还将结果扩展到了深度大于等于3的情况，并且我们展示了深度增加的好处在于上述收敛对初始化大小的依赖要弱得多，因此这种秩最小化更有可能在实际规模的初始化下发挥作用。",
        "领域": "矩阵分解、梯度下降优化、低秩学习",
        "问题": "解决梯度下降在矩阵分解中的隐式偏差问题，以及如何更有效地进行低秩学习。",
        "动机": "探索梯度下降在矩阵分解中的隐式正则化行为，特别是其在无限小初始化条件下的行为，以及如何通过贪婪低秩学习算法来更有效地实现秩最小化。",
        "方法": "通过理论和实证研究，证明了在特定条件下梯度流与贪婪低秩学习算法的等价性，并扩展了这一发现到更深层次的矩阵分解中。",
        "关键词": [
            "矩阵分解",
            "梯度下降",
            "低秩学习",
            "隐式正则化",
            "秩最小化"
        ],
        "涉及的技术概念": {
            "梯度下降": "用于优化矩阵分解模型，研究其在无限小初始化条件下的隐式正则化行为。",
            "核范数": "在矩阵分解中，核范数最小化被推测为梯度下降隐式正则化的结果之一。",
            "贪婪低秩学习": "一种启发式秩最小化算法，本研究证明其在特定条件下与梯度流数学等价。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 788,
        "title": "Towards Robustness Against Natural Language Word Substitutions",
        "html": "https://iclr.cc//virtual/2021/poster/2924",
        "abstract": "Robustness against word substitutions has a well-defined and widely acceptable form, i.e., using semantically similar words as substitutions, and thus it is considered as a fundamental stepping-stone towards broader robustness in natural language processing. Previous defense methods capture word substitutions in vector space by using either l_2-ball or hyper-rectangle, which results in perturbation sets that are not inclusive enough or unnecessarily large, and thus impedes mimicry of worst cases for robust training. In this paper, we introduce a novel Adversarial Sparse Convex Combination (ASCC) method. We model the word substitution attack space as a convex hull and leverages a regularization term to enforce perturbation towards an actual substitution, thus aligning our modeling better with the discrete textual space. Based on  ASCC method, we further propose ASCC-defense, which leverages ASCC to generate worst-case perturbations and incorporates adversarial training towards robustness. Experiments show that ASCC-defense outperforms the current state-of-the-arts in terms of robustness on two prevailing NLP tasks, i.e., sentiment analysis and natural language inference, concerning several attacks across multiple model architectures. Besides, we also envision a new class of defense towards robustness in NLP, where our robustly trained word vectors can be plugged into a normally trained model and enforce its robustness without applying any other defense techniques.",
        "conference": "ICLR",
        "中文标题": "迈向对抗自然语言词汇替换的鲁棒性",
        "摘要翻译": "对抗词汇替换的鲁棒性具有明确且广泛接受的形式，即使用语义相似的词汇作为替换，因此它被视为实现自然语言处理更广泛鲁棒性的基础。以往的防御方法通过在向量空间中使用l_2球或超矩形来捕捉词汇替换，这导致了扰动集要么不够包容，要么不必要地大，从而阻碍了对鲁棒训练中最坏情况的模拟。在本文中，我们介绍了一种新颖的对抗性稀疏凸组合（ASCC）方法。我们将词汇替换攻击空间建模为一个凸包，并利用正则化项来强制扰动朝向实际的替换，从而使我们的建模更好地与离散的文本空间对齐。基于ASCC方法，我们进一步提出了ASCC-defense，它利用ASCC生成最坏情况的扰动，并结合对抗训练以提高鲁棒性。实验表明，ASCC-defense在两个主流的NLP任务（即情感分析和自然语言推理）上，在多种模型架构和多种攻击下的鲁棒性方面优于当前的最新技术。此外，我们还设想了一类新的NLP鲁棒性防御方法，其中我们鲁棒训练的词向量可以插入到正常训练的模型中，并在不应用任何其他防御技术的情况下强制执行其鲁棒性。",
        "领域": "自然语言处理与视觉结合, 情感分析, 自然语言推理",
        "问题": "如何提高自然语言处理模型对词汇替换攻击的鲁棒性",
        "动机": "现有的防御方法在模拟词汇替换攻击时存在扰动集不够包容或不必要大的问题，阻碍了鲁棒训练的效果",
        "方法": "提出对抗性稀疏凸组合（ASCC）方法，将词汇替换攻击空间建模为凸包，并结合正则化项和对抗训练以提高鲁棒性",
        "关键词": [
            "对抗性训练",
            "词汇替换",
            "鲁棒性",
            "自然语言处理",
            "凸组合"
        ],
        "涉及的技术概念": {
            "对抗性稀疏凸组合（ASCC）": "一种新颖的方法，用于建模词汇替换攻击空间，通过凸包和正则化项来更好地模拟离散文本空间中的扰动",
            "ASCC-defense": "基于ASCC方法的防御策略，通过生成最坏情况的扰动并结合对抗训练来提高模型的鲁棒性",
            "鲁棒训练的词向量": "通过鲁棒训练得到的词向量，可以直接插入到正常训练的模型中以提高其对抗词汇替换攻击的能力，无需其他防御技术"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 789,
        "title": "Towards Robust Neural Networks via Close-loop Control",
        "html": "https://iclr.cc//virtual/2021/poster/2963",
        "abstract": "Despite their success in massive engineering applications, deep neural networks are vulnerable to various perturbations due to their black-box nature. Recent study has shown that a deep neural network can misclassify the data even if the input data is perturbed by an imperceptible amount. In this paper, we address the robustness issue of neural networks by a novel close-loop control method from the perspective of dynamic systems. Instead of modifying the parameters in a fixed neural network architecture, a close-loop control process is added to generate control signals adaptively for the perturbed or corrupted data. We connect the robustness of neural networks with optimal control using the geometrical information of underlying data to design the control objective. The detailed analysis shows how the embedding manifolds of state trajectory affect error estimation of the proposed method. Our approach can simultaneously maintain the performance on clean data and improve the robustness against many types of data perturbations. It can also further improve the performance of robustly trained neural networks against different perturbations. To the best of our knowledge, this is the first work that improves the robustness of neural networks with close-loop control.",
        "conference": "ICLR",
        "中文标题": "通过闭环控制实现鲁棒神经网络",
        "摘要翻译": "尽管深度神经网络在大量工程应用中取得了成功，但由于其黑箱特性，它们对各种扰动非常敏感。最近的研究表明，即使输入数据受到难以察觉的微小扰动，深度神经网络也可能对数据进行错误分类。在本文中，我们从动态系统的角度出发，通过一种新颖的闭环控制方法来解决神经网络的鲁棒性问题。与在固定的神经网络架构中修改参数不同，我们添加了一个闭环控制过程，以自适应地为受扰动或损坏的数据生成控制信号。我们利用基础数据的几何信息将神经网络的鲁棒性与最优控制联系起来，以设计控制目标。详细的分析展示了状态轨迹的嵌入流形如何影响所提出方法的误差估计。我们的方法能够同时保持对干净数据的性能，并提高对多种数据扰动的鲁棒性。它还能进一步提高经过鲁棒训练的神经网络对不同扰动的性能。据我们所知，这是首个利用闭环控制提高神经网络鲁棒性的工作。",
        "领域": "深度学习鲁棒性、动态系统控制、对抗性攻击防御",
        "问题": "解决深度神经网络对微小扰动敏感导致的错误分类问题",
        "动机": "提高神经网络对各种数据扰动的鲁棒性，同时保持其在干净数据上的性能",
        "方法": "采用闭环控制方法，自适应生成控制信号，利用几何信息设计控制目标",
        "关键词": [
            "闭环控制",
            "神经网络鲁棒性",
            "动态系统",
            "对抗性防御",
            "几何信息"
        ],
        "涉及的技术概念": {
            "闭环控制": "用于自适应生成控制信号，提高神经网络对扰动的鲁棒性",
            "动态系统": "从动态系统的角度分析和设计神经网络的鲁棒性控制方法",
            "几何信息": "利用基础数据的几何信息设计控制目标，连接神经网络的鲁棒性与最优控制"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 790,
        "title": "Tradeoffs in Data Augmentation: An Empirical Study",
        "html": "https://iclr.cc//virtual/2021/poster/3212",
        "abstract": "Though data augmentation has become a standard component of deep neural network training, the underlying mechanism behind the effectiveness of these techniques remains poorly understood. In practice, augmentation policies are often chosen using heuristics of distribution shift or augmentation diversity. Inspired by these, we conduct an empirical study to quantify how data augmentation improves model generalization. We introduce two interpretable and easy-to-compute measures: Affinity and Diversity. We find that augmentation performance is predicted not by either of these alone but by jointly optimizing the two.",
        "conference": "ICLR",
        "中文标题": "数据增强的权衡：一项实证研究",
        "摘要翻译": "尽管数据增强已成为深度神经网络训练的标准组成部分，但这些技术有效性背后的机制仍然知之甚少。在实践中，增强策略通常通过分布偏移或增强多样性的启发式方法选择。受此启发，我们进行了一项实证研究，以量化数据增强如何提高模型的泛化能力。我们引入了两个可解释且易于计算的度量：亲和力和多样性。我们发现，增强性能不是由其中任何一个单独预测的，而是通过联合优化两者来预测的。",
        "领域": "深度学习优化、数据增强技术、模型泛化研究",
        "问题": "理解数据增强技术如何以及为何能提高模型泛化能力",
        "动机": "探索数据增强背后的机制，以更科学地选择增强策略",
        "方法": "引入亲和力和多样性两个度量，通过实证研究量化数据增强对模型泛化的影响",
        "关键词": [
            "数据增强",
            "模型泛化",
            "亲和力",
            "多样性",
            "实证研究"
        ],
        "涉及的技术概念": {
            "亲和力": "衡量增强数据与原始数据之间相似性的度量，用于评估增强策略的适用性",
            "多样性": "衡量增强数据变化范围的度量，用于评估增强策略的广度",
            "联合优化": "同时考虑亲和力和多样性，以找到最优的数据增强策略"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 791,
        "title": "Training BatchNorm and Only BatchNorm: On the Expressive Power of Random Features in CNNs",
        "html": "https://iclr.cc//virtual/2021/poster/3292",
        "abstract": "A wide variety of deep learning techniques from style transfer to multitask learning rely on training affine transformations of features. Most prominent among these is the popular feature normalization technique BatchNorm, which normalizes activations and then subsequently applies a learned affine transform. In this paper, we aim to understand the role and expressive power of affine parameters used to transform features in this way. To isolate the contribution of these parameters from that of the learned features they transform, we investigate the performance achieved when training only these parameters in BatchNorm and freezing all weights at their random initializations. Doing so leads to surprisingly high performance considering the significant limitations that this style of training imposes. For example, sufficiently deep ResNets reach 82% (CIFAR-10) and 32% (ImageNet, top-5) accuracy in this configuration, far higher than when training an equivalent number of randomly chosen parameters elsewhere in the network. BatchNorm achieves this performance in part by naturally learning to disable around a third of the random features. Not only do these results highlight the expressive power of affine parameters in deep learning, but - in a broader sense - they characterize the expressive power of neural networks constructed simply by shifting and rescaling random features.",
        "conference": "ICLR",
        "中文标题": "仅训练BatchNorm：论CNN中随机特征的表达能力",
        "摘要翻译": "从风格迁移到多任务学习，深度学习技术的广泛应用依赖于训练特征的仿射变换。其中最突出的是流行的特征归一化技术BatchNorm，它先对激活进行归一化，然后应用学习的仿射变换。在本文中，我们旨在理解以这种方式用于变换特征的仿射参数的作用和表达能力。为了将这些参数的贡献与它们变换的学习特征的贡献隔离开来，我们研究了仅训练BatchNorm中的这些参数并将所有权重冻结在它们的随机初始化时的性能。考虑到这种训练方式施加的显著限制，这样做会带来令人惊讶的高性能。例如，足够深的ResNets在这种配置下达到82%（CIFAR-10）和32%（ImageNet，top-5）的准确率，远高于在网络其他部分训练相同数量的随机选择参数时的准确率。BatchNorm通过自然地学会禁用大约三分之一的随机特征来实现这一性能。这些结果不仅突出了仿射参数在深度学习中的表达能力，而且在更广泛的意义上，它们描述了仅通过移动和缩放随机特征构建的神经网络的表达能力。",
        "领域": "深度学习优化、神经网络架构、特征归一化",
        "问题": "理解并量化BatchNorm中仿射变换参数在特征表达中的作用和能力",
        "动机": "探索在深度学习模型中，仅通过调整BatchNorm层的参数（而保持其他权重随机初始化不变）所能达到的性能，以此来评估仿射变换参数的表达能力",
        "方法": "通过实验研究，仅训练BatchNorm层的仿射变换参数，同时冻结网络中其他所有层的权重，观察和分析模型在不同数据集上的表现",
        "关键词": [
            "BatchNorm",
            "仿射变换",
            "随机特征",
            "神经网络表达能力",
            "深度学习优化"
        ],
        "涉及的技术概念": {
            "BatchNorm": "一种流行的特征归一化技术，通过归一化激活并应用学习的仿射变换来加速深度神经网络的训练和提高性能",
            "仿射变换": "在BatchNorm中用于调整归一化后特征的尺度和偏移的参数，本研究重点探讨其表达能力",
            "随机特征": "指在神经网络初始化时随机生成的权重，本研究通过仅训练BatchNorm参数来探索这些随机特征经过简单变换后的表达能力"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 792,
        "title": "Training GANs with Stronger Augmentations via Contrastive Discriminator",
        "html": "https://iclr.cc//virtual/2021/poster/2840",
        "abstract": "Recent works in Generative Adversarial Networks (GANs) are actively revisiting various data augmentation techniques as an effective way to prevent discriminator overfitting. It is still unclear, however, that which augmentations could actually improve GANs, and in particular, how to apply a wider range of augmentations in training. In this paper, we propose a novel way to address these questions by incorporating a recent contrastive representation learning scheme into the GAN discriminator, coined ContraD. This 'fusion' enables the discriminators to work with much stronger augmentations without increasing their training instability, thereby preventing the discriminator overfitting issue in GANs more effectively. Even better, we observe that the contrastive learning itself also benefits from our GAN training, i.e., by maintaining discriminative features between real and fake samples, suggesting a strong coherence between the two worlds: good contrastive representations are also good for GAN discriminators, and vice versa. Our experimental results show that GANs with ContraD consistently improve FID and IS compared to other recent techniques incorporating data augmentations, still maintaining highly discriminative features in the discriminator in terms of the linear evaluation. Finally, as a byproduct, we also show that our GANs trained in an unsupervised manner (without labels) can induce many conditional generative models via a simple latent sampling, leveraging the learned features of ContraD. Code is available at https://github.com/jh-jeong/ContraD.",
        "conference": "ICLR",
        "中文标题": "通过对比判别器以更强数据增强训练GAN",
        "摘要翻译": "生成对抗网络（GANs）的最新研究正在积极重新审视各种数据增强技术，作为防止判别器过拟合的有效方法。然而，哪些增强实际上可以改善GANs，特别是如何在训练中应用更广泛的增强，目前尚不明确。在本文中，我们提出了一种新颖的方法来解决这些问题，通过将最近的对比表示学习方案融入GAN判别器中，称为ContraD。这种'融合'使判别器能够在训练不稳定性不增加的情况下使用更强的增强，从而更有效地防止GAN中的判别器过拟合问题。更妙的是，我们观察到对比学习本身也从我们的GAN训练中受益，即通过保持真实和假样本之间的判别性特征，这表明了两个世界之间的强烈一致性：好的对比表示也对GAN判别器有益，反之亦然。我们的实验结果表明，与其他最近结合数据增强的技术相比，使用ContraD的GANs在FID和IS上持续改进，同时在判别器中保持高度判别性特征。最后，作为副产品，我们还展示了我们的GANs以无监督方式（无标签）训练可以通过简单的潜在采样诱导许多条件生成模型，利用ContraD的学习特征。代码可在https://github.com/jh-jeong/ContraD获取。",
        "领域": "生成对抗网络、数据增强、对比学习",
        "问题": "如何有效应用更广泛的数据增强技术以防止GAN判别器过拟合",
        "动机": "探索哪些数据增强技术能有效改善GANs，并研究如何在训练中更广泛地应用这些技术",
        "方法": "将对比表示学习方案融入GAN判别器，提出ContraD方法，使判别器能使用更强的数据增强而不增加训练不稳定性",
        "关键词": [
            "生成对抗网络",
            "数据增强",
            "对比学习",
            "判别器过拟合",
            "ContraD"
        ],
        "涉及的技术概念": {
            "对比表示学习": "用于提升判别器对增强数据的处理能力，防止过拟合",
            "数据增强": "在训练过程中应用，以增加数据的多样性，防止模型过拟合",
            "判别器过拟合": "指判别器在训练过程中对训练数据过度适应，导致对新数据的泛化能力下降"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 793,
        "title": "Training independent subnetworks for robust prediction",
        "html": "https://iclr.cc//virtual/2021/poster/3062",
        "abstract": "Recent approaches to efficiently ensemble neural networks have shown that strong robustness and uncertainty performance  can be achieved with a negligible gain in parameters over the original network. However, these methods still require multiple forward passes for prediction, leading to a significant runtime cost. In this work, we show a surprising result:\nthe benefits of using multiple predictions can be achieved 'for free' under a single model's forward pass. In particular, we show that, using a multi-input multi-output (MIMO) configuration, one can utilize a single model's capacity to train multiple subnetworks that independently learn the task at hand. By ensembling the predictions made by the subnetworks, we improve model robustness without increasing compute. We observe a significant improvement in negative log-likelihood, accuracy, and calibration error on CIFAR10, CIFAR100,  ImageNet, and their out-of-distribution variants compared to previous methods.",
        "conference": "ICLR",
        "中文标题": "训练独立子网络以实现稳健预测",
        "摘要翻译": "最近关于高效集成神经网络的方法表明，可以在原始网络参数几乎不增加的情况下，实现强大的鲁棒性和不确定性性能。然而，这些方法仍然需要进行多次前向传播来进行预测，导致显著的运行时成本。在这项工作中，我们展示了一个令人惊讶的结果：使用单一模型的前向传播可以‘免费’实现使用多次预测的好处。具体来说，我们展示了通过使用多输入多输出（MIMO）配置，可以利用单一模型的容量来训练多个独立学习当前任务的子网络。通过集成这些子网络的预测，我们在不增加计算量的情况下提高了模型的鲁棒性。与之前的方法相比，我们在CIFAR10、CIFAR100、ImageNet及其分布外变体上观察到负对数似然、准确率和校准误差的显著改善。",
        "领域": "模型鲁棒性增强、神经网络集成、分布外泛化",
        "问题": "如何在几乎不增加参数和计算成本的情况下，提高神经网络的鲁棒性和不确定性性能",
        "动机": "减少集成方法中的多次前向传播带来的运行时成本，同时保持或提高模型的鲁棒性和性能",
        "方法": "采用多输入多输出（MIMO）配置，在单一模型中训练多个独立子网络，并通过集成这些子网络的预测来提高性能",
        "关键词": [
            "模型鲁棒性",
            "神经网络集成",
            "MIMO配置",
            "分布外泛化",
            "计算效率"
        ],
        "涉及的技术概念": {
            "多输入多输出（MIMO）配置": "允许单一模型同时处理多个输入并产生多个输出，用于训练多个独立子网络",
            "子网络独立学习": "在单一模型框架内，多个子网络独立学习相同任务，增加模型的多样性和鲁棒性",
            "集成预测": "通过结合多个子网络的预测结果，提高模型的整体性能和不确定性估计"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 794,
        "title": "Training with Quantization Noise for Extreme Model Compression",
        "html": "https://iclr.cc//virtual/2021/poster/2772",
        "abstract": "We tackle the problem of producing compact models, maximizing their accuracy for a given model size. A standard solution is to train networks with Quantization Aware Training, where the weights are quantized during training and the gradients approximated with the Straight-Through Estimator. In this paper, we extend this approach to work with extreme compression methods where the approximations introduced by STE are severe. Our proposal is to only quantize a different random subset of weights during each forward, allowing for unbiased gradients to flow through the other weights. Controlling the amount of noise and its form allows for extreme compression rates while maintaining the performance of the original model. As a result we establish new state-of-the-art compromises between accuracy and model size both in natural language processing and image classification. For example, applying our method to state-of-the-art Transformer and ConvNet architectures, we can achieve 82.5% accuracy on MNLI by compressing RoBERTa to 14 MB and 80.0% top-1 accuracy on ImageNet by compressing an EfficientNet-B3 to 3.3 MB.",
        "conference": "ICLR",
        "中文标题": "量化噪声训练用于极端模型压缩",
        "摘要翻译": "我们致力于解决生产紧凑模型的问题，以在给定模型大小下最大化其准确性。一个标准的解决方案是通过量化感知训练来训练网络，其中权重在训练期间被量化，并且梯度通过直通估计器近似。在本文中，我们将这种方法扩展到适用于极端压缩方法，其中STE引入的近似是严重的。我们的建议是在每次前向传播时仅量化不同的随机权重子集，允许无偏梯度通过其他权重流动。控制噪声的数量和形式允许在保持原始模型性能的同时实现极端压缩率。因此，我们在自然语言处理和图像分类中建立了准确性和模型大小之间的新的最先进折衷方案。例如，将我们的方法应用于最先进的Transformer和ConvNet架构，我们可以通过将RoBERTa压缩到14 MB在MNLI上达到82.5%的准确率，以及通过将EfficientNet-B3压缩到3.3 MB在ImageNet上达到80.0%的top-1准确率。",
        "领域": "模型压缩、自然语言处理、图像分类",
        "问题": "在极端压缩条件下保持模型准确性的问题",
        "动机": "研究如何在极端压缩方法中保持模型性能，特别是在量化感知训练中梯度近似严重的情况下",
        "方法": "通过每次前向传播时仅量化不同的随机权重子集，控制噪声的数量和形式，以实现极端压缩率同时保持模型性能",
        "关键词": [
            "量化感知训练",
            "极端模型压缩",
            "随机子集量化",
            "Transformer",
            "ConvNet"
        ],
        "涉及的技术概念": {
            "量化感知训练": "在训练期间量化权重并使用直通估计器近似梯度，以减少模型大小",
            "直通估计器": "用于在量化感知训练中近似梯度的技术，允许梯度通过量化操作传播",
            "随机子集量化": "在每次前向传播时仅量化不同的随机权重子集，以减少梯度近似的影响并保持模型性能"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 795,
        "title": "Trajectory Prediction using Equivariant Continuous Convolution",
        "html": "https://iclr.cc//virtual/2021/poster/3189",
        "abstract": "Trajectory prediction is a critical part of many AI applications, for example, the safe operation of autonomous vehicles. However, current methods are prone to making inconsistent and physically unrealistic predictions. We leverage insights from  fluid dynamics to overcome this limitation by considering internal symmetry in real-world trajectories. We propose a novel model, Equivariant Continous COnvolution (ECCO) for improved trajectory prediction.  ECCO uses rotationally-equivariant continuous convolutions to embed the symmetries of the system. On both vehicle and pedestrian trajectory datasets, ECCO attains competitive accuracy  with significantly fewer parameters. It is also more sample efficient, generalizing automatically from few data points in any orientation.  Lastly, ECCO improves generalization with equivariance, resulting in more physically consistent predictions.   Our method provides a fresh perspective towards increasing trust and transparency in deep learning models. Our code and data can be found at https://github.com/Rose-STL-Lab/ECCO.",
        "conference": "ICLR",
        "中文标题": "使用等变连续卷积进行轨迹预测",
        "摘要翻译": "轨迹预测是许多人工智能应用的关键部分，例如自动驾驶汽车的安全操作。然而，当前的方法容易做出不一致且物理上不现实的预测。我们利用流体动力学的见解，通过考虑现实世界轨迹中的内部对称性来克服这一限制。我们提出了一种新颖的模型——等变连续卷积（ECCO），用于改进轨迹预测。ECCO使用旋转等变连续卷积来嵌入系统的对称性。在车辆和行人轨迹数据集上，ECCO以显著更少的参数实现了竞争性的准确性。它还更具样本效率，能够从任何方向的少量数据点自动泛化。最后，ECCO通过等变性提高了泛化能力，从而产生更物理一致的预测。我们的方法为提高深度学习模型的信任和透明度提供了新的视角。我们的代码和数据可以在https://github.com/Rose-STL-Lab/ECCO找到。",
        "领域": "自动驾驶、行人轨迹预测、流体动力学应用",
        "问题": "当前轨迹预测方法存在不一致和物理上不现实的预测问题",
        "动机": "利用流体动力学的对称性原理，提高轨迹预测的物理一致性和准确性",
        "方法": "提出等变连续卷积（ECCO）模型，利用旋转等变连续卷积嵌入系统对称性，减少参数数量同时保持高准确性",
        "关键词": [
            "轨迹预测",
            "等变连续卷积",
            "自动驾驶",
            "行人轨迹",
            "流体动力学"
        ],
        "涉及的技术概念": {
            "等变连续卷积": "一种能够嵌入系统对称性的卷积方法，用于提高轨迹预测的物理一致性和准确性",
            "旋转等变性": "模型能够自动适应不同方向的输入数据，提高样本效率和泛化能力",
            "物理一致性": "预测结果符合物理规律，提高模型的可信度和实用性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 796,
        "title": "Transformer protein language models are unsupervised structure learners",
        "html": "https://iclr.cc//virtual/2021/poster/3016",
        "abstract": "Unsupervised contact prediction is central to uncovering physical, structural, and functional constraints for protein structure determination and design. For decades, the predominant approach has been to infer evolutionary constraints from a set of related sequences. In the past year, protein language models have emerged as a potential alternative, but performance has fallen short of state-of-the-art approaches in bioinformatics. In this paper we demonstrate that Transformer attention maps learn contacts from the unsupervised language modeling objective. We find the highest capacity models that have been trained to date already outperform a state-of-the-art unsupervised contact prediction pipeline, suggesting these pipelines can be replaced with a single forward pass of an end-to-end model.",
        "conference": "ICLR",
        "中文标题": "Transformer蛋白质语言模型是无监督结构学习器",
        "摘要翻译": "无监督接触预测是揭示蛋白质结构确定和设计中物理、结构及功能约束的核心。几十年来，主流方法是从一组相关序列中推断进化约束。过去一年中，蛋白质语言模型作为一种潜在替代方案出现，但其性能尚未达到生物信息学领域的最先进方法。本文中，我们证明了Transformer注意力图能够从无监督语言建模目标中学习接触。我们发现迄今为止训练的最高容量模型已经超越了最先进的无监督接触预测流程，这表明这些流程可以被端到端模型的单次前向传播所替代。",
        "领域": "蛋白质结构预测",
        "问题": "如何通过无监督学习预测蛋白质的接触信息",
        "动机": "探索蛋白质语言模型在无监督接触预测中的潜力，以替代传统的基于进化约束的方法",
        "方法": "利用Transformer注意力图从无监督语言建模目标中学习蛋白质接触信息",
        "关键词": [
            "蛋白质语言模型",
            "无监督学习",
            "Transformer",
            "接触预测",
            "生物信息学"
        ],
        "涉及的技术概念": {
            "Transformer注意力图": "用于从蛋白质序列中学习接触信息的机制，通过注意力权重揭示序列间的相互作用",
            "无监督语言建模": "一种不依赖于标注数据的学习方法，用于从蛋白质序列中提取结构和功能信息",
            "端到端模型": "一种直接从输入到输出进行预测的模型架构，简化了传统多步骤预测流程"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 797,
        "title": "Transient Non-stationarity and Generalisation in Deep Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2021/poster/3156",
        "abstract": "Non-stationarity can arise in Reinforcement Learning (RL) even in stationary environments. For example, most RL algorithms collect new data throughout training, using a non-stationary behaviour policy. Due to the transience of this non-stationarity, it is often not explicitly addressed in deep RL and a single neural network is continually updated. However, we find evidence that neural networks exhibit a memory effect, where these transient non-stationarities can permanently impact the latent representation and adversely affect generalisation performance. Consequently, to improve generalisation of deep RL agents, we propose Iterated Relearning (ITER). ITER augments standard RL training by repeated knowledge transfer of the current policy into a freshly initialised network, which thereby experiences less non-stationarity during training. Experimentally, we show that ITER improves performance on the challenging generalisation benchmarks ProcGen and Multiroom.",
        "conference": "ICLR",
        "中文标题": "深度强化学习中的瞬时非平稳性与泛化",
        "摘要翻译": "在强化学习（RL）中，即使在平稳的环境中也可能出现非平稳性。例如，大多数RL算法在训练过程中使用非平稳的行为策略收集新数据。由于这种非平稳性的瞬时性，在深度RL中通常不会明确处理，而是持续更新单个神经网络。然而，我们发现证据表明神经网络表现出记忆效应，这些瞬时的非平稳性可能会永久影响潜在表示，并对泛化性能产生不利影响。因此，为了提高深度RL代理的泛化能力，我们提出了迭代再学习（ITER）。ITER通过将当前策略的知识重复转移到新初始化的网络中来增强标准RL训练，从而在训练过程中经历较少的非平稳性。实验上，我们展示了ITER在具有挑战性的泛化基准测试ProcGen和Multiroom上提高了性能。",
        "领域": "深度强化学习",
        "问题": "深度强化学习中的非平稳性对神经网络潜在表示和泛化性能的长期影响",
        "动机": "解决深度强化学习中由于训练过程中的非平稳性导致的神经网络记忆效应，进而影响模型泛化能力的问题",
        "方法": "提出迭代再学习（ITER）方法，通过重复将当前策略的知识转移到新初始化的网络中来减少训练过程中的非平稳性",
        "关键词": [
            "深度强化学习",
            "非平稳性",
            "泛化性能",
            "迭代再学习",
            "记忆效应"
        ],
        "涉及的技术概念": {
            "非平稳性": "在强化学习中，由于行为策略的变化导致的环境动态变化，影响模型的训练和泛化",
            "记忆效应": "神经网络在训练过程中对早期数据的记忆，可能导致对后续数据的处理出现偏差",
            "迭代再学习（ITER）": "一种通过重复知识转移来减少训练过程中非平稳性影响的方法，旨在提高模型的泛化能力"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 798,
        "title": "TropEx: An Algorithm for Extracting Linear Terms in Deep Neural Networks",
        "html": "https://iclr.cc//virtual/2021/poster/3324",
        "abstract": "Deep neural networks with rectified linear (ReLU) activations are piecewise linear functions, where hyperplanes partition the input space into an astronomically high number of linear regions. Previous work focused on counting linear regions to measure the network's expressive power and on analyzing geometric properties of the hyperplane configurations. In contrast, we aim to understand the impact of the linear terms on network performance, by examining the information encoded in their coefficients. To this end, we derive TropEx, a nontrivial tropical algebra-inspired algorithm to systematically extract linear terms based on data. Applied to convolutional and fully-connected networks, our algorithm uncovers significant differences in how the different networks utilize linear regions for generalization. This underlines the importance of systematic linear term exploration, to better understand generalization in neural networks trained with complex data sets.",
        "conference": "ICLR",
        "中文标题": "TropEx：一种用于提取深度神经网络中线性项的算法",
        "摘要翻译": "使用修正线性（ReLU）激活函数的深度神经网络是分段线性函数，其中超平面将输入空间划分为天文数字般多的线性区域。以往的研究集中于通过计数线性区域来衡量网络的表达能力，并分析超平面配置的几何特性。相比之下，我们的目标是通过检查线性项系数中编码的信息，来理解线性项对网络性能的影响。为此，我们推导出了TropEx，这是一种非平凡的受热带代数启发的算法，用于基于数据系统地提取线性项。应用于卷积和全连接网络时，我们的算法揭示了不同网络如何利用线性区域进行泛化的显著差异。这强调了系统探索线性项的重要性，以更好地理解使用复杂数据集训练的神经网络的泛化能力。",
        "领域": "深度学习理论、神经网络优化、计算机视觉",
        "问题": "理解线性项对深度神经网络性能的影响",
        "动机": "探索线性项在神经网络泛化中的作用，以更深入地理解神经网络的性能",
        "方法": "开发了一种名为TropEx的算法，该算法受热带代数启发，用于系统地提取和分析神经网络中的线性项",
        "关键词": [
            "线性项提取",
            "热带代数",
            "神经网络泛化",
            "ReLU激活函数",
            "深度学习理论"
        ],
        "涉及的技术概念": {
            "热带代数": "一种数学结构，用于在TropEx算法中系统地提取线性项",
            "ReLU激活函数": "在深度神经网络中使用的激活函数，导致网络成为分段线性函数",
            "线性区域": "输入空间中被超平面划分的区域，研究这些区域有助于理解网络的泛化能力"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 799,
        "title": "Trusted Multi-View Classification",
        "html": "https://iclr.cc//virtual/2021/poster/2908",
        "abstract": "Multi-view classification (MVC) generally focuses on improving classification accuracy by using information from different views, typically integrating them into a unified comprehensive representation for downstream tasks. However, it is also crucial to dynamically assess the quality of a view for different samples in order to provide reliable uncertainty estimations, which indicate whether predictions can be trusted. To this end, we propose a novel multi-view classification method, termed trusted multi-view classification, which provides a new paradigm for multi-view learning by dynamically integrating different views at an evidence level. The algorithm jointly utilizes multiple views to promote both classification reliability (uncertainty estimation during testing) and robustness (out-of-distribution-awareness during training) by integrating evidence from each view. To achieve this, the Dirichlet distribution is used to model the distribution of the class probabilities, parameterized with evidence from different views and integrated with the Dempster-Shafer theory. The unified learning framework induces accurate uncertainty and accordingly endows the model with both reliability and robustness for out-of-distribution samples. Extensive experimental results validate the effectiveness of the proposed model in accuracy, reliability and robustness.",
        "conference": "ICLR",
        "中文标题": "可信多视图分类",
        "摘要翻译": "多视图分类（MVC）通常侧重于通过利用不同视图的信息来提高分类准确性，通常将它们整合为一个统一的综合表示以用于下游任务。然而，动态评估不同样本的视图质量以提供可靠的不确定性估计同样重要，这些估计表明预测是否可信。为此，我们提出了一种新颖的多视图分类方法，称为可信多视图分类，它通过在证据级别动态整合不同视图，为多视图学习提供了新的范式。该算法通过整合来自每个视图的证据，联合利用多个视图来提升分类的可靠性（测试期间的不确定性估计）和鲁棒性（训练期间的分布外感知）。为了实现这一点，使用Dirichlet分布来建模类别概率的分布，参数化来自不同视图的证据，并与Dempster-Shafer理论整合。这一统一的学习框架诱导出准确的不确定性，并因此赋予模型对于分布外样本的可靠性和鲁棒性。大量的实验结果验证了所提出模型在准确性、可靠性和鲁棒性方面的有效性。",
        "领域": "多视图学习、不确定性估计、分布外检测",
        "问题": "如何在多视图分类中动态评估不同视图的质量，提供可靠的不确定性估计，以增强模型的可靠性和鲁棒性。",
        "动机": "当前多视图分类方法主要关注提高分类准确性，而忽视了动态评估视图质量和提供不确定性估计的重要性，这限制了模型在实际应用中的可信度和适应性。",
        "方法": "提出了一种基于证据级别的可信多视图分类方法，通过Dirichlet分布建模类别概率分布，并结合Dempster-Shafer理论动态整合不同视图的证据，以提高分类的可靠性和鲁棒性。",
        "关键词": [
            "可信多视图分类",
            "不确定性估计",
            "Dirichlet分布",
            "Dempster-Shafer理论",
            "分布外感知"
        ],
        "涉及的技术概念": {
            "Dirichlet分布": "用于建模类别概率的分布，参数化来自不同视图的证据，为不确定性估计提供数学基础。",
            "Dempster-Shafer理论": "用于整合来自不同视图的证据，提供了一种动态评估视图质量和整合信息的方法。",
            "分布外感知": "在训练期间识别和处理分布外样本的能力，增强模型在面对未知数据时的鲁棒性。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 800,
        "title": "UMEC: Unified model and embedding compression for efficient recommendation systems",
        "html": "https://iclr.cc//virtual/2021/poster/2976",
        "abstract": "The recommendation system (RS) plays an important role in the content recommendation and retrieval scenarios. The core part of the system is the Ranking neural network, which is usually a bottleneck of whole system performance during online inference.  In this work, we propose a unified model and embedding compression (UMEC) framework to hammer an efficient neural network-based recommendation system.  Our framework jointly learns input feature selection and neural network compression together, and solve them as an end-to-end resource-constrained optimization problem using ADMM.  Our method outperforms other baselines in terms of neural network Flops, sparse embedding feature size and the number of sparse embedding features.  We evaluate our method on the public benchmark of DLRM, trained over the Kaggle Criteo dataset. The codes can be found at https://github.com/VITA-Group/UMEC.",
        "conference": "ICLR",
        "中文标题": "UMEC：统一模型与嵌入压缩的高效推荐系统",
        "摘要翻译": "推荐系统（RS）在内容推荐和检索场景中扮演着重要角色。系统的核心部分是排序神经网络，这通常是在线推理时整个系统性能的瓶颈。在这项工作中，我们提出了一个统一的模型和嵌入压缩（UMEC）框架，以打造一个高效的基于神经网络的推荐系统。我们的框架联合学习输入特征选择和神经网络压缩，并将它们作为一个端到端的资源约束优化问题使用ADMM来解决。我们的方法在神经网络Flops、稀疏嵌入特征大小和稀疏嵌入特征数量方面优于其他基线。我们在DLRM的公共基准上评估了我们的方法，该基准是在Kaggle Criteo数据集上训练的。代码可以在https://github.com/VITA-Group/UMEC找到。",
        "领域": "推荐系统、神经网络压缩、特征选择",
        "问题": "解决推荐系统中排序神经网络在线推理时的性能瓶颈问题",
        "动机": "提高推荐系统的效率，通过压缩模型和嵌入来减少资源消耗",
        "方法": "提出UMEC框架，联合学习输入特征选择和神经网络压缩，使用ADMM解决端到端的资源约束优化问题",
        "关键词": [
            "推荐系统",
            "模型压缩",
            "嵌入压缩",
            "ADMM",
            "特征选择"
        ],
        "涉及的技术概念": {
            "排序神经网络": "推荐系统中用于排序的核心组件，通常成为性能瓶颈",
            "ADMM": "交替方向乘子法，用于解决资源约束优化问题",
            "稀疏嵌入特征": "通过压缩减少嵌入特征的大小和数量，以提高效率"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 801,
        "title": "Unbiased Teacher for Semi-Supervised Object Detection",
        "html": "https://iclr.cc//virtual/2021/poster/2757",
        "abstract": "Semi-supervised learning, i.e., training networks with both labeled and unlabeled data, has made significant progress recently. However, existing works have primarily focused on image classification tasks and neglected object detection which requires more annotation effort. In this work, we revisit the Semi-Supervised Object Detection (SS-OD) and identify the pseudo-labeling bias issue in SS-OD. To address this, we introduce Unbiased Teacher, a simple yet effective approach that jointly trains a student and a gradually progressing teacher in a mutually-beneficial manner. Together with a class-balance loss to downweight overly confident pseudo-labels, Unbiased Teacher consistently improved state-of-the-art methods by significant margins on COCO-standard, COCO-additional, and VOC datasets. Specifically, Unbiased Teacher achieves 6.8 absolute mAP improvements against state-of-the-art method when using 1% of labeled data on MS-COCO, achieves around 10 mAP improvements against the supervised baseline when using only 0.5, 1, 2% of labeled data on MS-COCO.",
        "conference": "ICLR",
        "中文标题": "半监督目标检测的无偏教师",
        "摘要翻译": "半监督学习，即同时使用标记和未标记数据训练网络，近年来取得了显著进展。然而，现有的工作主要集中在图像分类任务上，忽视了需要更多标注努力的目标检测。在这项工作中，我们重新审视了半监督目标检测（SS-OD），并识别了SS-OD中的伪标签偏差问题。为了解决这个问题，我们引入了无偏教师，这是一种简单而有效的方法，它以互利的方式联合训练学生和逐渐进步的教师。结合一个类别平衡损失来降低过于自信的伪标签的权重，无偏教师在COCO标准、COCO附加和VOC数据集上持续显著提高了最先进方法的性能。具体来说，当在MS-COCO上使用1%的标记数据时，无偏教师相对于最先进方法实现了6.8个绝对mAP的提升；当在MS-COCO上仅使用0.5%、1%、2%的标记数据时，相对于监督基线实现了约10个mAP的提升。",
        "领域": "半监督学习、目标检测、深度学习",
        "问题": "解决半监督目标检测中的伪标签偏差问题",
        "动机": "现有的半监督学习方法主要集中在图像分类任务上，忽视了目标检测任务，而目标检测需要更多的标注努力。",
        "方法": "引入无偏教师方法，联合训练学生和逐渐进步的教师，并使用类别平衡损失来降低过于自信的伪标签的权重。",
        "关键词": [
            "半监督学习",
            "目标检测",
            "无偏教师",
            "伪标签偏差",
            "类别平衡损失"
        ],
        "涉及的技术概念": {
            "半监督学习": "同时使用标记和未标记数据训练网络的方法",
            "无偏教师": "一种联合训练学生和逐渐进步的教师的方法，用于解决伪标签偏差问题",
            "类别平衡损失": "用于降低过于自信的伪标签权重的损失函数，以改善模型性能"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 802,
        "title": "Uncertainty-aware Active Learning for Optimal Bayesian Classifier",
        "html": "https://iclr.cc//virtual/2021/poster/3026",
        "abstract": "For pool-based active learning, in each iteration a candidate training sample is chosen for labeling by optimizing an acquisition function. In Bayesian classification, expected Loss Reduction~(ELR) methods maximize the expected reduction in the classification error given a new labeled candidate based on a one-step-look-ahead strategy. ELR is the optimal strategy with a single query; however, since such myopic strategies cannot identify the long-term effect of a query on the classification error, ELR may get stuck before reaching the optimal classifier.  In this paper, inspired by the mean objective cost of uncertainty (MOCU), a metric quantifying the uncertainty directly affecting the classification error, we propose an acquisition function based on a weighted form of MOCU. Similar to ELR, the proposed method focuses on the reduction of the uncertainty that pertains to the classification error. But unlike any other existing scheme, it provides the critical advantage that the resulting Bayesian active learning algorithm guarantees convergence to the optimal classifier of the true model. We demonstrate its performance with both synthetic and real-world datasets.",
        "conference": "ICLR",
        "中文标题": "不确定性感知的主动学习用于最优贝叶斯分类器",
        "摘要翻译": "对于基于池的主动学习，在每次迭代中，通过优化获取函数来选择候选训练样本进行标记。在贝叶斯分类中，预期损失减少（ELR）方法基于一步前瞻策略，最大化给定新标记候选后分类误差的预期减少。ELR是单次查询的最优策略；然而，由于这种短视策略无法识别查询对分类误差的长期影响，ELR可能在达到最优分类器之前停滞不前。本文受平均不确定性目标成本（MOCU）启发，提出了一种基于加权形式MOCU的获取函数，MOCU是一种直接量化影响分类误差的不确定性的度量。与ELR类似，所提出的方法专注于减少与分类误差相关的不确定性。但与任何其他现有方案不同，它提供了关键优势，即由此产生的贝叶斯主动学习算法保证收敛于真实模型的最优分类器。我们通过合成和真实世界数据集展示了其性能。",
        "领域": "贝叶斯学习、主动学习、分类算法",
        "问题": "解决在主动学习过程中，如何选择最优的候选训练样本以最小化分类误差的问题。",
        "动机": "现有的预期损失减少（ELR）方法虽然对于单次查询是最优的，但由于其短视性质，无法考虑查询对分类误差的长期影响，可能导致学习过程停滞不前。",
        "方法": "提出了一种基于加权形式平均不确定性目标成本（MOCU）的获取函数，该方法专注于减少与分类误差相关的不确定性，并保证算法收敛于最优分类器。",
        "关键词": [
            "主动学习",
            "贝叶斯分类",
            "不确定性量化",
            "MOCU",
            "分类误差"
        ],
        "涉及的技术概念": {
            "预期损失减少（ELR）": "一种基于一步前瞻策略的方法，用于最大化给定新标记候选后分类误差的预期减少。",
            "平均不确定性目标成本（MOCU）": "一种直接量化影响分类误差的不确定性的度量，用于构建新的获取函数。",
            "贝叶斯主动学习": "一种结合贝叶斯推理和主动学习的方法，旨在通过选择最有信息的样本来优化学习过程。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 803,
        "title": "Uncertainty Estimation and Calibration with Finite-State Probabilistic RNNs",
        "html": "https://iclr.cc//virtual/2021/poster/2658",
        "abstract": "Uncertainty quantification is crucial for building reliable and trustable machine learning systems. We propose to estimate uncertainty in recurrent neural networks (RNNs) via stochastic discrete state transitions over recurrent timesteps. The uncertainty of the model can be quantified by running a prediction several times, each time sampling from the recurrent state transition distribution, leading to potentially different results if the model is uncertain. Alongside uncertainty quantification, our proposed method offers several advantages in different settings. The proposed method can (1) learn deterministic and probabilistic automata from data, (2) learn well-calibrated models on real-world classification tasks, (3) improve the performance of out-of-distribution detection, and (4) control the exploration-exploitation trade-off in reinforcement learning. An implementation is available.",
        "conference": "ICLR",
        "中文标题": "有限状态概率循环神经网络的不确定性估计与校准",
        "摘要翻译": "不确定性量化对于构建可靠和可信的机器学习系统至关重要。我们提出通过在循环时间步长上进行随机离散状态转换来估计循环神经网络（RNNs）中的不确定性。通过多次运行预测，每次从循环状态转换分布中采样，如果模型存在不确定性，则可能导致不同的结果，从而量化模型的不确定性。除了不确定性量化外，我们提出的方法在不同设置下还提供了几个优势。所提出的方法可以（1）从数据中学习确定性和概率自动机，（2）在真实世界分类任务上学习良好校准的模型，（3）提高分布外检测的性能，以及（4）控制强化学习中的探索-利用权衡。提供了实现。",
        "领域": "循环神经网络、不确定性量化、强化学习",
        "问题": "如何在循环神经网络中有效估计和校准不确定性，以提高模型的可靠性和可信度",
        "动机": "为了构建更加可靠和可信的机器学习系统，需要有效量化模型预测中的不确定性",
        "方法": "通过在循环时间步长上进行随机离散状态转换来估计不确定性，并利用该方法在多个应用场景中展示优势",
        "关键词": [
            "不确定性量化",
            "循环神经网络",
            "状态转换",
            "模型校准",
            "强化学习"
        ],
        "涉及的技术概念": {
            "随机离散状态转换": "通过在循环时间步长上进行随机离散状态转换来估计模型的不确定性",
            "模型校准": "确保模型预测的不确定性与其实际误差率相匹配，提高模型的可靠性",
            "探索-利用权衡": "在强化学习中平衡尝试新行动（探索）和选择已知最佳行动（利用）的策略"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 804,
        "title": "Uncertainty Estimation in Autoregressive Structured Prediction",
        "html": "https://iclr.cc//virtual/2021/poster/3015",
        "abstract": "Uncertainty estimation is important for ensuring safety and robustness of AI systems.  While most research in the area has focused on un-structured prediction tasks, limited work has investigated general uncertainty estimation approaches for structured prediction. Thus, this work aims to investigate uncertainty estimation for structured prediction tasks within a single unified and interpretable probabilistic ensemble-based framework.  We consider: uncertainty estimation for sequence data at the token-level and complete sequence-level; interpretations for, and applications of, various measures of uncertainty; and discuss both the theoretical and practical challenges associated with obtaining them. This work also provides baselines for token-level and sequence-level error detection, and sequence-level out-of-domain input detection on the WMT’14 English-French and WMT’17 English-German translation and LibriSpeech speech recognition datasets.",
        "conference": "ICLR",
        "中文标题": "自回归结构化预测中的不确定性估计",
        "摘要翻译": "不确定性估计对于确保AI系统的安全性和鲁棒性至关重要。虽然该领域的大多数研究都集中在非结构化预测任务上，但有限的工作研究了结构化预测的通用不确定性估计方法。因此，本研究旨在通过一个统一且可解释的基于概率集成的框架，研究结构化预测任务中的不确定性估计。我们考虑了：在标记级别和完整序列级别对序列数据进行不确定性估计；对各种不确定性测量的解释和应用；并讨论了获取这些测量所涉及的理论和实践挑战。这项工作还为WMT’14英法翻译、WMT’17英德翻译和LibriSpeech语音识别数据集上的标记级别和序列级别错误检测以及序列级别域外输入检测提供了基线。",
        "领域": "自然语言处理与视觉结合、机器翻译、语音识别",
        "问题": "结构化预测任务中的不确定性估计",
        "动机": "研究旨在填补结构化预测任务中不确定性估计研究的空白，通过一个统一且可解释的框架来提高AI系统的安全性和鲁棒性。",
        "方法": "采用基于概率集成的框架，对序列数据进行标记级别和完整序列级别的不确定性估计，并探讨不确定性测量的解释和应用。",
        "关键词": [
            "不确定性估计",
            "结构化预测",
            "概率集成",
            "序列数据",
            "错误检测"
        ],
        "涉及的技术概念": {
            "自回归模型": "用于结构化预测任务，通过历史数据预测未来数据点。",
            "概率集成": "通过集成多个模型的预测结果来估计不确定性，提高预测的准确性和鲁棒性。",
            "序列级别不确定性估计": "在完整序列级别上评估预测的不确定性，用于错误检测和域外输入检测。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 805,
        "title": "Uncertainty in Gradient Boosting via Ensembles",
        "html": "https://iclr.cc//virtual/2021/poster/2928",
        "abstract": "For many practical, high-risk applications, it is essential to quantify uncertainty in a model's predictions to avoid costly mistakes. While predictive uncertainty is widely studied for neural networks, the topic seems to be under-explored for models based on gradient boosting. However, gradient boosting often achieves state-of-the-art results on tabular data. This work examines a probabilistic ensemble-based framework for deriving uncertainty estimates in the predictions of gradient boosting classification and regression models. We conducted experiments on a range of synthetic and real datasets and investigated the applicability of ensemble approaches to gradient boosting models that are themselves ensembles of decision trees. Our analysis shows that ensembles of gradient boosting models successfully detect anomalous inputs while having limited ability to improve the predicted total uncertainty. Importantly, we also propose a concept of a virtual ensemble to get the benefits of an ensemble via only one gradient boosting model, which significantly reduces complexity. ",
        "conference": "ICLR",
        "中文标题": "通过集成方法量化梯度提升中的不确定性",
        "摘要翻译": "对于许多实际的高风险应用而言，量化模型预测中的不确定性以避免代价高昂的错误至关重要。虽然预测不确定性在神经网络中得到了广泛研究，但对于基于梯度提升的模型，这一主题似乎尚未得到充分探索。然而，梯度提升通常在表格数据上达到最先进的结果。本研究探讨了一种基于概率集成的方法框架，用于在梯度提升分类和回归模型的预测中导出不确定性估计。我们在一系列合成和真实数据集上进行了实验，并研究了集成方法对于本身就是决策树集成的梯度提升模型的适用性。我们的分析表明，梯度提升模型的集成成功地检测到了异常输入，但在改善预测的总不确定性方面能力有限。重要的是，我们还提出了虚拟集成的概念，通过仅一个梯度提升模型获得集成的益处，这显著降低了复杂性。",
        "领域": "集成学习、不确定性量化、梯度提升",
        "问题": "量化梯度提升模型预测中的不确定性",
        "动机": "在高风险应用中避免因模型预测不确定性导致的错误",
        "方法": "采用基于概率集成的框架来估计梯度提升模型预测的不确定性，并提出虚拟集成的概念以减少复杂性",
        "关键词": [
            "不确定性量化",
            "梯度提升",
            "集成学习",
            "虚拟集成",
            "异常检测"
        ],
        "涉及的技术概念": {
            "梯度提升": "一种集成学习方法，通过迭代地添加决策树来优化模型性能",
            "不确定性量化": "评估模型预测的不确定性，对于高风险决策尤为重要",
            "虚拟集成": "提出的新概念，旨在通过单一模型模拟集成效果，降低计算复杂性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 806,
        "title": "Uncertainty Sets for Image Classifiers using Conformal Prediction",
        "html": "https://iclr.cc//virtual/2021/poster/3246",
        "abstract": "Convolutional image classifiers can achieve high predictive accuracy, but quanti\u0002fying their uncertainty remains an unresolved challenge, hindering their deployment in consequential settings. Existing uncertainty quantification techniques, such as Platt scaling, attempt to calibrate the network’s probability estimates, but they do not have formal guarantees. We present an algorithm that modifies any classifier to output a predictive set containing the true label with a user-specified probability, such as 90%. The algorithm is simple and fast like Platt scaling, but provides a formal finite-sample coverage guarantee for every model and dataset. Our method modifies an existing conformal prediction algorithm to give more sta\u0002ble predictive sets by regularizing the small scores of unlikely classes after Platt scaling. In experiments on both Imagenet and Imagenet-V2 with ResNet-152 and other classifiers, our scheme outperforms existing approaches, achieving coverage with sets that are often factors of 5 to 10 smaller than a stand-alone Platt scaling baseline.",
        "conference": "ICLR",
        "中文标题": "使用共形预测为图像分类器构建不确定性集合",
        "摘要翻译": "卷积图像分类器可以实现高预测准确率，但量化其不确定性仍是一个未解决的挑战，这阻碍了它们在重要场景中的部署。现有的不确定性量化技术，如Platt缩放，试图校准网络的概率估计，但它们没有正式的保证。我们提出了一种算法，可以修改任何分类器，使其输出一个包含真实标签的预测集合，该集合以用户指定的概率（如90%）包含真实标签。该算法像Platt缩放一样简单快速，但为每个模型和数据集提供了正式的有限样本覆盖保证。我们的方法修改了现有的共形预测算法，通过在Platt缩放后正则化不太可能类别的小分数，来提供更稳定的预测集合。在Imagenet和Imagenet-V2上使用ResNet-152和其他分类器进行的实验中，我们的方案优于现有方法，实现的覆盖集合通常比独立的Platt缩放基线小5到10倍。",
        "领域": "图像分类、不确定性量化、共形预测",
        "问题": "量化卷积图像分类器的不确定性，并提供正式的覆盖保证",
        "动机": "解决现有不确定性量化技术缺乏正式保证的问题，提高分类器在重要场景中的可靠性和部署可能性",
        "方法": "提出一种基于共形预测的算法，通过修改现有分类器输出预测集合，并在Platt缩放后正则化不太可能类别的小分数，以提供更稳定的预测集合和正式的覆盖保证",
        "关键词": [
            "共形预测",
            "不确定性量化",
            "图像分类",
            "Platt缩放",
            "覆盖保证"
        ],
        "涉及的技术概念": {
            "共形预测": "一种统计方法，用于生成具有正式覆盖保证的预测集合",
            "Platt缩放": "一种校准分类器概率估计的技术，用于提高预测的可靠性",
            "正则化": "在共形预测中用于调整不太可能类别的分数，以稳定预测集合的大小"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 807,
        "title": "Understanding and Improving Encoder Layer Fusion in Sequence-to-Sequence Learning",
        "html": "https://iclr.cc//virtual/2021/poster/3132",
        "abstract": "Encoder layer fusion (EncoderFusion) is a technique to fuse all the encoder layers (instead of the uppermost layer) for sequence-to-sequence (Seq2Seq) models, which has proven effective on various NLP tasks. However, it is still not entirely clear why and when EncoderFusion should work. In this paper, our main contribution is to take a step further in understanding EncoderFusion. Many of previous studies believe that the success of EncoderFusion comes from exploiting surface and syntactic information embedded in lower encoder layers. Unlike them, we find that the encoder embedding layer is more important than other intermediate encoder layers. In addition, the uppermost decoder layer consistently pays more attention to the encoder embedding layer across NLP tasks. Based on this observation, we propose a simple fusion method, SurfaceFusion, by fusing only the encoder embedding layer for the softmax layer. Experimental results show that SurfaceFusion outperforms EncoderFusion on several NLP benchmarks, including machine translation, text summarization, and grammatical error correction. It obtains the state-of-the-art performance on WMT16 Romanian-English and WMT14 English-French translation tasks. Extensive analyses reveal that SurfaceFusion learns more expressive bilingual word embeddings by building a closer relationship between relevant source and target embeddings. Source code is freely available at https://github.com/SunbowLiu/SurfaceFusion.",
        "conference": "ICLR",
        "中文标题": "理解与改进序列到序列学习中的编码器层融合",
        "摘要翻译": "编码器层融合（EncoderFusion）是一种为序列到序列（Seq2Seq）模型融合所有编码器层（而非仅最上层）的技术，已在多种自然语言处理（NLP）任务中证明有效。然而，关于EncoderFusion为何及何时有效，目前尚未完全明了。本文的主要贡献在于进一步理解EncoderFusion。许多先前研究认为，EncoderFusion的成功源于利用了较低编码器层中嵌入的表面和句法信息。与这些研究不同，我们发现编码器的嵌入层比其他中间编码器层更为重要。此外，最上层解码器层在不同NLP任务中始终对编码器嵌入层给予更多关注。基于这一观察，我们提出了一种简单的融合方法——SurfaceFusion，仅融合编码器嵌入层用于softmax层。实验结果表明，SurfaceFusion在包括机器翻译、文本摘要和语法错误纠正在内的多个NLP基准测试中优于EncoderFusion。在WMT16罗马尼亚语-英语和WMT14英语-法语翻译任务中，SurfaceFusion取得了最先进的性能。广泛的分析揭示，SurfaceFusion通过建立相关源和目标嵌入之间更紧密的关系，学习了更具表现力的双语词嵌入。源代码可在https://github.com/SunbowLiu/SurfaceFusion免费获取。",
        "领域": "自然语言处理与视觉结合",
        "问题": "如何更有效地融合编码器层以提升序列到序列模型的性能",
        "动机": "探索编码器层融合技术的工作原理及其优化方法，以提高模型在多种NLP任务中的表现",
        "方法": "提出SurfaceFusion方法，仅融合编码器嵌入层用于softmax层，以简化并优化编码器层融合过程",
        "关键词": [
            "编码器层融合",
            "序列到序列学习",
            "自然语言处理"
        ],
        "涉及的技术概念": {
            "编码器层融合（EncoderFusion）": "一种融合所有编码器层而非仅最上层的技术，旨在提升Seq2Seq模型在NLP任务中的表现",
            "SurfaceFusion": "本文提出的简化融合方法，仅融合编码器嵌入层，以优化模型性能",
            "双语词嵌入": "通过建立源语言和目标语言词嵌入之间的紧密关系，提升模型在翻译等任务中的表现"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 808,
        "title": "Understanding and Improving Lexical Choice in Non-Autoregressive Translation",
        "html": "https://iclr.cc//virtual/2021/poster/3147",
        "abstract": "Knowledge distillation (KD) is essential for training non-autoregressive translation (NAT) models by reducing the complexity of the raw data with an autoregressive teacher model. In this study, we empirically show that as a side effect of this training, the lexical choice errors on low-frequency words are propagated to the NAT model from the teacher model. To alleviate this problem, we propose to expose the raw data to NAT models to restore the useful information of low-frequency words, which are missed in the distilled data. To this end, we introduce an extra Kullback-Leibler divergence term derived by comparing the lexical choice of NAT model and that embedded in the raw data. Experimental results across language pairs and model architectures demonstrate the effectiveness and universality of the proposed approach.  Extensive analyses confirm our claim that our approach improves performance by reducing the lexical choice errors on low-frequency words.  Encouragingly, our approach pushes the SOTA NAT performance on the WMT14 English-German and WMT16 Romanian-English datasets up to 27.8 and 33.8 BLEU points, respectively. ",
        "conference": "ICLR",
        "中文标题": "理解并改进非自回归翻译中的词汇选择",
        "摘要翻译": "知识蒸馏（KD）通过使用自回归教师模型减少原始数据的复杂性，对于训练非自回归翻译（NAT）模型至关重要。在本研究中，我们实证表明，作为这种训练的副作用，低频词的词汇选择错误会从教师模型传播到NAT模型。为了缓解这个问题，我们提出将原始数据暴露给NAT模型，以恢复在蒸馏数据中丢失的低频词的有用信息。为此，我们引入了一个额外的Kullback-Leibler散度项，通过比较NAT模型的词汇选择和原始数据中嵌入的词汇选择得出。跨语言对和模型架构的实验结果证明了所提出方法的有效性和普遍性。广泛的分析证实了我们的主张，即我们的方法通过减少低频词的词汇选择错误来提高性能。令人鼓舞的是，我们的方法将WMT14英语-德语和WMT16罗马尼亚语-英语数据集上的SOTA NAT性能分别推至27.8和33.8 BLEU点。",
        "领域": "机器翻译、非自回归模型、知识蒸馏",
        "问题": "解决非自回归翻译模型中低频词词汇选择错误的问题",
        "动机": "减少从教师模型传播到非自回归翻译模型的低频词词汇选择错误，提高翻译质量",
        "方法": "通过将原始数据暴露给NAT模型并引入额外的Kullback-Leibler散度项来恢复低频词的有用信息",
        "关键词": [
            "非自回归翻译",
            "知识蒸馏",
            "词汇选择",
            "低频词",
            "Kullback-Leibler散度"
        ],
        "涉及的技术概念": {
            "知识蒸馏": "通过自回归教师模型减少原始数据的复杂性，用于训练非自回归翻译模型",
            "非自回归翻译": "一种翻译模型，其生成目标序列时不依赖于之前生成的词",
            "Kullback-Leibler散度": "用于比较NAT模型的词汇选择和原始数据中嵌入的词汇选择，以恢复低频词的有用信息"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 809,
        "title": "Understanding Over-parameterization in Generative Adversarial Networks",
        "html": "https://iclr.cc//virtual/2021/poster/3216",
        "abstract": "A broad class of unsupervised deep learning methods such as Generative Adversarial Networks (GANs) involve training of overparameterized models where the number of parameters of the model exceeds a certain threshold. Indeed, most successful GANs used in practice are trained using overparameterized generator and discriminator networks, both in terms of depth and width. A large body of work in supervised learning have shown the importance of model overparameterization in the convergence of the gradient descent (GD) to globally optimal solutions. In contrast, the unsupervised setting and GANs in particular involve non-convex concave mini-max optimization problems that are often trained using Gradient Descent/Ascent (GDA).\nThe role and benefits of model overparameterization in the convergence of GDA to a global saddle point in non-convex concave problems is far less understood. In this work, we present a comprehensive analysis of the importance of model overparameterization in GANs both theoretically and empirically. We theoretically show that in an overparameterized GAN model with a $1$-layer neural network generator and a linear discriminator, GDA converges to a global saddle point of the underlying non-convex concave min-max problem. To the best of our knowledge, this is the first result for global convergence of GDA in such settings. Our theory is based on a more general result that holds for a broader class of nonlinear generators and discriminators that obey certain assumptions (including deeper generators and random feature discriminators). Our theory utilizes and builds upon a novel connection with the convergence analysis of linear time-varying dynamical systems which may have broader implications for understanding the convergence behavior of GDA for non-convex concave problems involving overparameterized models. We also empirically study the role of model overparameterization in GANs using several large-scale experiments on CIFAR-10 and Celeb-A datasets. Our experiments show that overparameterization improves the quality of generated samples across various model architectures and datasets. Remarkably, we observe that overparameterization leads to faster and more stable convergence behavior of GDA across the board.",
        "conference": "ICLR",
        "中文标题": "理解生成对抗网络中的过参数化",
        "摘要翻译": "一类广泛的非监督深度学习方法，如生成对抗网络（GANs），涉及训练过参数化模型，其中模型的参数数量超过某个阈值。实际上，实践中使用的大多数成功的GANs都是通过过参数化的生成器和判别器网络进行训练的，无论是在深度还是宽度上。监督学习中的大量工作已经展示了模型过参数化在梯度下降（GD）收敛到全局最优解中的重要性。相比之下，非监督设置特别是GANs涉及非凸凹的极小极大优化问题，这些问题通常使用梯度下降/上升（GDA）进行训练。模型过参数化在GDA收敛到非凸凹问题的全局鞍点中的作用和好处远未被充分理解。在这项工作中，我们从理论和实证两方面对GANs中模型过参数化的重要性进行了全面分析。我们理论上表明，在一个具有一层神经网络生成器和线性判别器的过参数化GAN模型中，GDA收敛到基础非凸凹极小极大问题的全局鞍点。据我们所知，这是GDA在此类设置中全局收敛的第一个结果。我们的理论基于一个更一般的结果，该结果适用于一类更广泛的非线性生成器和判别器，这些生成器和判别器遵循某些假设（包括更深的生成器和随机特征判别器）。我们的理论利用并建立了一个与线性时变动态系统收敛分析的新颖联系，这可能对理解涉及过参数化模型的非凸凹问题的GDA收敛行为具有更广泛的意义。我们还通过CIFAR-10和Celeb-A数据集上的几个大规模实验，实证研究了模型过参数化在GANs中的作用。我们的实验表明，过参数化提高了各种模型架构和数据集上生成样本的质量。值得注意的是，我们观察到过参数化导致GDA在所有情况下更快更稳定的收敛行为。",
        "领域": "生成对抗网络、深度学习优化、非凸优化",
        "问题": "理解模型过参数化在生成对抗网络训练中的作用及其对梯度下降/上升算法收敛性的影响",
        "动机": "探索过参数化在非监督学习特别是生成对抗网络中对优化算法收敛性的影响，填补现有研究的空白",
        "方法": "通过理论分析和实证研究，探讨过参数化GANs中GDA算法的全局收敛性，并利用大规模实验验证过参数化对生成样本质量和算法收敛速度的影响",
        "关键词": [
            "过参数化",
            "生成对抗网络",
            "梯度下降/上升",
            "非凸优化",
            "全局收敛"
        ],
        "涉及的技术概念": {
            "过参数化": "指模型的参数数量超过某个阈值，有助于梯度下降算法收敛到全局最优解",
            "梯度下降/上升（GDA）": "用于训练生成对抗网络的优化算法，涉及生成器和判别器的交替优化",
            "非凸凹优化": "生成对抗网络训练中涉及的优化问题类型，其解空间复杂，难以找到全局最优解"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 810,
        "title": "Understanding the effects of data parallelism and sparsity on neural network training",
        "html": "https://iclr.cc//virtual/2021/poster/3069",
        "abstract": "We study two factors in neural network training: data parallelism and sparsity; here, data parallelism means processing training data in parallel using distributed systems (or equivalently increasing batch size), so that training can be accelerated; for sparsity, we refer to pruning parameters in a neural network model, so as to reduce computational and memory cost. Despite their promising benefits, however, understanding of their effects on neural network training remains elusive. In this work, we first measure these effects rigorously by conducting extensive experiments while tuning all metaparameters involved in the optimization. As a result, we find across various workloads of data set, network model, and optimization algorithm that there exists a general scaling trend between batch size and number of training steps to convergence for the effect of data parallelism, and further, difficulty of training under sparsity. Then, we develop a theoretical analysis based on the convergence properties of stochastic gradient methods and smoothness of the optimization landscape, which illustrates the observed phenomena precisely and generally, establishing a better account of the effects of data parallelism and sparsity on neural network training.",
        "conference": "ICLR",
        "中文标题": "理解数据并行性和稀疏性对神经网络训练的影响",
        "摘要翻译": "我们研究了神经网络训练中的两个因素：数据并行性和稀疏性；这里，数据并行性意味着使用分布式系统并行处理训练数据（或等效地增加批量大小），以加速训练；对于稀疏性，我们指的是修剪神经网络模型中的参数，以减少计算和内存成本。尽管它们有令人期待的益处，但对它们如何影响神经网络训练的理解仍然模糊。在这项工作中，我们首先通过进行广泛的实验，同时调整优化中涉及的所有元参数，严格测量这些影响。结果，我们发现，在数据集、网络模型和优化算法的各种工作负载中，存在批量大小与收敛所需的训练步骤数之间的一般缩放趋势，以及稀疏性下训练的难度。然后，我们基于随机梯度方法的收敛性和优化景观的平滑性，开发了一个理论分析，精确且一般地说明了观察到的现象，为数据并行性和稀疏性对神经网络训练的影响建立了更好的解释。",
        "领域": "深度学习优化、分布式深度学习、模型压缩",
        "问题": "理解数据并行性和稀疏性如何影响神经网络训练的效率和效果",
        "动机": "探索数据并行性和稀疏性在神经网络训练中的具体影响，以优化训练过程和模型性能",
        "方法": "通过广泛的实验测量数据并行性和稀疏性的影响，并基于随机梯度方法的收敛性和优化景观的平滑性进行理论分析",
        "关键词": [
            "数据并行性",
            "稀疏性",
            "神经网络训练",
            "批量大小",
            "模型修剪"
        ],
        "涉及的技术概念": {
            "数据并行性": "使用分布式系统并行处理训练数据或增加批量大小以加速训练",
            "稀疏性": "修剪神经网络模型中的参数以减少计算和内存成本",
            "随机梯度方法": "用于分析数据并行性和稀疏性对神经网络训练影响的优化算法"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 811,
        "title": "Understanding the failure modes of out-of-distribution generalization",
        "html": "https://iclr.cc//virtual/2021/poster/2659",
        "abstract": "Empirical studies suggest that machine learning models often rely on features, such as the background, that may be spuriously correlated with the label only during training time, resulting in poor accuracy during test-time. In this work, we identify the fundamental factors that give rise to this behavior, by explaining why models fail this way even in easy-to-learn tasks where one would expect these models to succeed. In particular, through a theoretical study of gradient-descent-trained linear classifiers on some easy-to-learn tasks, we uncover two complementary failure modes. These modes arise from how spurious correlations induce two kinds of skews in the data: one geometric in nature and another, statistical. Finally, we construct natural modifications of image classification datasets to understand when these failure modes can arise in practice. We also design experiments to isolate the two failure modes when training modern neural networks on these datasets.",
        "conference": "ICLR",
        "中文标题": "理解分布外泛化的失败模式",
        "摘要翻译": "实证研究表明，机器学习模型常常依赖于那些仅在训练时与标签虚假相关的特征，如背景，这导致测试时的准确率不佳。在这项工作中，我们通过解释为什么在人们预期这些模型应该成功的易学任务中，模型仍会以这种方式失败，来识别导致这种行为的基本因素。特别是，通过对一些易学任务中梯度下降训练的线性分类器的理论研究，我们揭示了两种互补的失败模式。这些模式源于虚假相关性如何诱导数据中的两种偏差：一种是几何性质的，另一种是统计性质的。最后，我们构建了图像分类数据集的自然修改，以理解这些失败模式在实践中何时会出现。我们还设计了实验来隔离这两种失败模式，当在这些数据集上训练现代神经网络时。",
        "领域": "机器学习泛化性研究、图像分类、模型鲁棒性分析",
        "问题": "机器学习模型在分布外数据上泛化能力差的问题",
        "动机": "探究模型在易学任务中失败的根本原因，特别是在存在虚假相关性的情况下",
        "方法": "通过理论分析梯度下降训练的线性分类器，识别并实验验证两种由虚假相关性引起的失败模式",
        "关键词": [
            "分布外泛化",
            "虚假相关性",
            "梯度下降",
            "线性分类器",
            "模型鲁棒性"
        ],
        "涉及的技术概念": {
            "梯度下降": "用于训练线性分类器的优化方法，本研究通过分析其行为来理解模型失败的原因",
            "虚假相关性": "指模型在训练数据中学习到的与标签无关的特征相关性，本研究探讨了其对模型泛化能力的负面影响",
            "线性分类器": "本研究的理论分析对象，用于简化问题并揭示模型失败的基本模式"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 812,
        "title": "Understanding the role of importance weighting for deep learning",
        "html": "https://iclr.cc//virtual/2021/poster/2669",
        "abstract": "The recent paper by Byrd & Lipton (2019), based on empirical observations, raises a major concern on the impact of importance weighting for the over-parameterized deep learning models. They observe that as long as the model can separate the training data, the impact of importance weighting diminishes as the training proceeds. Nevertheless, there lacks a rigorous characterization of this phenomenon. In this paper, we provide formal characterizations and theoretical justifications on the role of importance weighting with respect to the implicit bias of gradient descent and margin-based learning theory. We reveal both the optimization dynamics and generalization performance under deep learning models. Our work not only explains the various novel phenomenons observed for importance weighting in deep learning, but also extends to the studies where the weights are being optimized as part of the model, which applies to a number of topics under active research.",
        "conference": "ICLR",
        "中文标题": "理解重要性加权在深度学习中的作用",
        "摘要翻译": "Byrd & Lipton（2019）最近的论文基于实证观察，提出了关于重要性加权对过参数化深度学习模型影响的主要关切。他们观察到，只要模型能够分离训练数据，重要性加权的影响随着训练的进行而减弱。然而，缺乏对这一现象的严格描述。在本文中，我们提供了关于重要性加权在梯度下降的隐式偏差和基于边缘的学习理论中作用的正式描述和理论证明。我们揭示了深度学习模型下的优化动态和泛化性能。我们的工作不仅解释了在深度学习中观察到的关于重要性加权的各种新现象，还扩展到权重作为模型一部分被优化的研究，这适用于许多正在积极研究的主题。",
        "领域": "深度学习理论、优化算法、泛化理论",
        "问题": "重要性加权在过参数化深度学习模型中的作用及其影响",
        "动机": "为了严格描述和理论证明重要性加权在深度学习中的角色，特别是在梯度下降的隐式偏差和基于边缘的学习理论中的影响",
        "方法": "通过理论分析和实证研究，探讨重要性加权对深度学习模型优化动态和泛化性能的影响",
        "关键词": [
            "重要性加权",
            "深度学习",
            "优化动态",
            "泛化性能",
            "梯度下降"
        ],
        "涉及的技术概念": {
            "重要性加权": "在深度学习中用于调整训练样本权重的技术，以影响模型的学习过程",
            "梯度下降的隐式偏差": "指梯度下降算法在优化过程中倾向于某些解的倾向性，影响模型的最终性能",
            "基于边缘的学习理论": "一种理论框架，用于分析模型在训练数据上的分类边缘与其泛化能力之间的关系"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 813,
        "title": "Undistillable: Making A Nasty Teacher That CANNOT teach students",
        "html": "https://iclr.cc//virtual/2021/poster/3114",
        "abstract": "Knowledge Distillation (KD) is a widely used technique to transfer knowledge from pre-trained teacher models to  (usually more lightweight) student models. However, in certain situations, this technique is more of a curse than a blessing. For instance, KD poses a potential risk of exposing intellectual properties (IPs): even if a trained machine learning model is released in ``black boxes'' (e.g., as executable software or APIs without open-sourcing code), it can still be replicated by KD through imitating input-output behaviors. To prevent this unwanted effect of KD, this paper introduces and investigates a concept called $\\textit{Nasty Teacher}$: a specially trained teacher network that yields nearly the same performance as a normal one, but would significantly degrade the performance of student models learned by imitating it. We propose a simple yet effective algorithm to build the nasty teacher, called $\\textit{self-undermining knowledge distillation}$. Specifically, we aim to maximize the difference between the output of the nasty teacher and a normal pre-trained network. Extensive experiments on several datasets demonstrate that our method is effective on both standard KD and data-free KD, providing the desirable KD-immunity to model owners for the first time. We hope our preliminary study can draw more awareness and interest in this new practical problem of both social and legal importance. Our codes and pre-trained models can be found at: $\\url{https://github.com/VITA-Group/Nasty-Teacher}$.",
        "conference": "ICLR",
        "中文标题": "不可蒸馏：制造一个无法教授学生的恶劣教师",
        "摘要翻译": "知识蒸馏（KD）是一种广泛使用的技术，用于将知识从预训练的教师模型转移到（通常更轻量级的）学生模型。然而，在某些情况下，这项技术弊大于利。例如，KD存在暴露知识产权（IP）的潜在风险：即使一个训练好的机器学习模型以“黑盒”形式发布（例如，作为可执行软件或不开放源代码的API），它仍然可以通过模仿输入输出行为被KD复制。为了防止KD的这种不良影响，本文引入并研究了一个称为“恶劣教师”的概念：一种特殊训练的教师网络，其性能与普通教师网络几乎相同，但会显著降低通过模仿它学习的学生模型的性能。我们提出了一种简单而有效的算法来构建恶劣教师，称为“自我削弱知识蒸馏”。具体来说，我们的目标是最大化恶劣教师和普通预训练网络输出之间的差异。在多个数据集上的大量实验表明，我们的方法在标准KD和无数据KD上都有效，首次为模型所有者提供了理想的KD免疫。我们希望我们的初步研究能够引起对这一具有社会和法律重要性的新实际问题的更多认识和兴趣。我们的代码和预训练模型可以在以下网址找到：https://github.com/VITA-Group/Nasty-Teacher。",
        "领域": "模型安全、知识蒸馏、知识产权保护",
        "问题": "如何防止通过知识蒸馏技术复制和泄露预训练模型的知识产权",
        "动机": "保护机器学习模型的知识产权，防止通过知识蒸馏技术被非法复制",
        "方法": "提出一种称为“自我削弱知识蒸馏”的算法，构建性能与普通教师网络相近但能显著降低学生模型性能的“恶劣教师”网络",
        "关键词": [
            "知识蒸馏",
            "模型安全",
            "知识产权保护",
            "恶劣教师",
            "自我削弱知识蒸馏"
        ],
        "涉及的技术概念": {
            "知识蒸馏": "一种将知识从教师模型转移到学生模型的技术，本文中用于探讨其潜在的知识产权风险",
            "恶劣教师": "一种特殊训练的教师网络，旨在防止通过知识蒸馏技术复制模型，通过最大化与普通教师网络的输出差异来实现",
            "自我削弱知识蒸馏": "本文提出的算法，用于构建恶劣教师网络，通过自我削弱的方式防止知识被有效蒸馏"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 814,
        "title": "Universal approximation power of deep residual neural networks via nonlinear control theory",
        "html": "https://iclr.cc//virtual/2021/poster/3010",
        "abstract": "In this paper, we explain the universal approximation capabilities of deep residual neural networks through geometric nonlinear control. Inspired by recent work establishing links between residual networks and control systems, we provide a general sufficient condition for a residual network to have the power of universal approximation by asking the activation function, or one of its derivatives, to satisfy a quadratic differential equation. Many activation functions used in practice satisfy this assumption, exactly or approximately, and we show this property to be sufficient for an adequately deep neural network with $n+1$ neurons per\nlayer to approximate arbitrarily well, on a compact set and with respect to the supremum norm, any continuous function from $\\mathbb{R}^n$ to $\\mathbb{R}^n$. We further show this result to hold for very simple architectures for which the weights only need to assume two values. The first key technical contribution consists of relating the universal approximation problem to controllability of an ensemble of control systems corresponding to a residual network and to leverage classical Lie algebraic techniques to characterize controllability. The second technical contribution is to identify monotonicity as the bridge between controllability of finite ensembles and uniform approximability on compact sets.",
        "conference": "ICLR",
        "中文标题": "通过非线性控制理论探讨深度残差神经网络的通用逼近能力",
        "摘要翻译": "本文通过几何非线性控制理论解释了深度残差神经网络的通用逼近能力。受近期建立残差网络与控制系统之间联系的研究启发，我们提出了一个通用的充分条件，即要求激活函数或其某一导数满足二次微分方程，以确保残差网络具备通用逼近能力。实践中使用的许多激活函数都精确或近似满足这一假设，我们证明这一性质足以让每层具有n+1个神经元的足够深度神经网络，在紧集上且相对于上确界范数，任意好地逼近从ℝⁿ到ℝⁿ的任何连续函数。我们进一步证明这一结果适用于权重仅需取两个值的非常简单的架构。第一个关键技术贡献在于将通用逼近问题与对应于残差网络的控制系统集合的可控性联系起来，并利用经典的李代数技术来表征可控性。第二个技术贡献是识别单调性作为有限集合可控性与紧集上一致可逼近性之间的桥梁。",
        "领域": "深度学习理论、神经网络架构、控制理论与深度学习结合",
        "问题": "探讨深度残差神经网络是否具备通用逼近能力及其条件",
        "动机": "建立残差网络与控制系统之间的联系，为深度残差神经网络的通用逼近能力提供理论支持",
        "方法": "通过几何非线性控制理论，提出激活函数满足二次微分方程的充分条件，并利用李代数技术和单调性分析",
        "关键词": [
            "深度残差神经网络",
            "通用逼近能力",
            "非线性控制理论",
            "激活函数",
            "可控性"
        ],
        "涉及的技术概念": {
            "几何非线性控制": "用于解释和证明深度残差神经网络的通用逼近能力",
            "二次微分方程": "激活函数或其导数需满足的条件，以确保网络的通用逼近能力",
            "李代数技术": "用于表征控制系统集合的可控性，进而分析网络的逼近能力"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 815,
        "title": "Universal Weakly Supervised Segmentation by Pixel-to-Segment Contrastive Learning",
        "html": "https://iclr.cc//virtual/2021/poster/3167",
        "abstract": "Weakly supervised segmentation is challenging as sparsely labeled pixels do not provide sufficient supervision:  A semantic segment may contain multiple distinctive regions whereas adjacent segments may appear similar.  Common approaches use the few labeled pixels in all training images to train a segmentation model, and then propagate labels within each image based on visual or feature similarity.  Instead, we treat segmentation as a semi-supervised pixel-wise metric learning problem, where pixels in different segments are mapped to distinctive features.   Naturally, our unlabeled pixels participate not only in data-driven grouping within each image, but also in discriminative feature learning within and across images.  Our results on Pascal VOC and DensePose datasets demonstrate our substantial accuracy gain on various forms of weak supervision including image-level tags, bounding boxes, labeled points, and scribbles.",
        "conference": "ICLR",
        "中文标题": "通过像素到片段对比学习的通用弱监督分割",
        "摘要翻译": "弱监督分割具有挑战性，因为稀疏标记的像素无法提供足够的监督：一个语义片段可能包含多个独特的区域，而相邻的片段可能看起来相似。常见的方法使用所有训练图像中的少量标记像素来训练分割模型，然后基于视觉或特征相似性在每个图像内传播标签。相反，我们将分割视为半监督的像素级度量学习问题，其中不同片段中的像素被映射到独特的特征。自然地，我们的未标记像素不仅参与每个图像内的数据驱动分组，还参与图像内和跨图像的判别性特征学习。我们在Pascal VOC和DensePose数据集上的结果表明，在各种形式的弱监督下，包括图像级标签、边界框、标记点和涂鸦，我们的方法都取得了显著的准确性提升。",
        "领域": "图像分割、弱监督学习、半监督学习",
        "问题": "解决在稀疏标记像素下进行准确图像分割的挑战",
        "动机": "由于稀疏标记像素提供的监督不足，传统方法难以准确分割包含多个独特区域或相似相邻区域的图像",
        "方法": "将分割问题视为半监督的像素级度量学习问题，通过对比学习将不同片段中的像素映射到独特的特征空间",
        "关键词": [
            "弱监督分割",
            "对比学习",
            "像素级度量学习",
            "半监督学习",
            "特征学习"
        ],
        "涉及的技术概念": {
            "弱监督分割": "在仅有少量标记像素的情况下进行图像分割的技术",
            "对比学习": "通过比较正负样本来学习特征表示的方法，用于增强像素特征的区分度",
            "像素级度量学习": "学习一个度量空间，使得相同类别的像素在特征空间中靠近，不同类别的像素远离"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 816,
        "title": "Unlearnable Examples: Making Personal Data Unexploitable",
        "html": "https://iclr.cc//virtual/2021/poster/2831",
        "abstract": "The volume of 'free' data on the internet has been key to the current success of deep learning. However, it also raises privacy concerns about the unauthorized exploitation of personal data for training commercial models. It is thus crucial to develop methods to prevent unauthorized data exploitation. This paper raises the question: can data be made unlearnable for deep learning models? We present a type of error-minimizing noise that can indeed make training examples unlearnable. Error-minimizing noise is intentionally generated to reduce the error of one or more of the training example(s) close to zero, which can trick the model into believing there is 'nothing' to learn from these example(s). The noise is restricted to be imperceptible to human eyes, and thus does not affect normal data utility. We empirically verify the effectiveness of error-minimizing noise in both sample-wise and class-wise forms. We also demonstrate its flexibility under extensive experimental settings and practicability in a case study of face recognition. Our work establishes an important ﬁrst step towards making personal data unexploitable to deep learning models.",
        "conference": "ICLR",
        "中文标题": "不可学习样本：使个人数据无法被利用",
        "摘要翻译": "互联网上‘免费’数据的数量是深度学习当前成功的关键。然而，这也引发了关于未经授权利用个人数据训练商业模型的隐私担忧。因此，开发防止未经授权数据利用的方法至关重要。本文提出了一个问题：数据能否被制成对深度学习模型不可学习？我们提出了一种误差最小化噪声，确实可以使训练样本变得不可学习。误差最小化噪声是故意生成的，以减少一个或多个训练样本的误差接近于零，这可以欺骗模型认为这些样本‘没有’什么可学习的。这种噪声被限制为对人眼不可见，因此不影响数据的正常使用。我们通过实验验证了误差最小化噪声在样本级和类别级形式下的有效性。我们还展示了其在广泛实验设置下的灵活性以及在面部识别案例研究中的实用性。我们的工作为使得个人数据对深度学习模型不可利用迈出了重要的第一步。",
        "领域": "隐私保护深度学习、对抗样本生成、面部识别安全",
        "问题": "如何防止个人数据被未经授权用于训练深度学习模型",
        "动机": "解决个人数据在未经授权情况下被用于训练商业模型引发的隐私问题",
        "方法": "提出并验证了一种误差最小化噪声，使数据对深度学习模型不可学习",
        "关键词": [
            "不可学习样本",
            "误差最小化噪声",
            "隐私保护",
            "对抗样本",
            "面部识别"
        ],
        "涉及的技术概念": {
            "误差最小化噪声": "故意生成的噪声，用于减少训练样本的误差接近于零，使模型认为这些样本无可学习之处",
            "对抗样本": "通过添加特定噪声生成的样本，旨在欺骗深度学习模型",
            "隐私保护深度学习": "研究如何在保护个人隐私的前提下进行深度学习模型训练的技术领域"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 817,
        "title": "Unsupervised Audiovisual Synthesis via Exemplar Autoencoders",
        "html": "https://iclr.cc//virtual/2021/poster/2705",
        "abstract": "We present an unsupervised approach that converts the input speech of any individual into audiovisual streams of potentially-infinitely many output speakers. Our approach builds on simple autoencoders that project out-of-sample data onto the distribution of the training set. We use exemplar autoencoders to learn the voice, stylistic prosody, and visual appearance of a specific target exemplar speech. In contrast to existing methods, the proposed approach can be easily extended to an arbitrarily large number of speakers and styles using only 3 minutes of target audio-video data, without requiring any training data for the input speaker. To do so, we learn audiovisual bottleneck representations that capture the structured linguistic content of speech. We outperform prior approaches on both audio and video synthesis.\n",
        "conference": "ICLR",
        "中文标题": "通过范例自动编码器的无监督视听合成",
        "摘要翻译": "我们提出了一种无监督方法，可以将任何个体的输入语音转换为潜在无限多输出说话者的视听流。我们的方法基于简单的自动编码器，这些编码器将样本外数据投影到训练集的分布上。我们使用范例自动编码器来学习特定目标范例语音的声音、风格韵律和视觉外观。与现有方法相比，所提出的方法可以仅使用3分钟的目标音频-视频数据，轻松扩展到任意数量的说话者和风格，而不需要输入说话者的任何训练数据。为此，我们学习了捕捉语音结构化语言内容的视听瓶颈表示。我们在音频和视频合成方面均优于先前的方法。",
        "领域": "语音合成、视觉语音合成、无监督学习",
        "问题": "如何无监督地将输入语音转换为多说话者的视听流",
        "动机": "开发一种无需输入说话者训练数据即可扩展到多说话者和风格的方法",
        "方法": "使用范例自动编码器学习目标范例的特征，并利用视听瓶颈表示捕捉语音内容",
        "关键词": [
            "无监督学习",
            "视听合成",
            "范例自动编码器",
            "语音转换",
            "视觉语音合成"
        ],
        "涉及的技术概念": {
            "范例自动编码器": "用于学习特定目标范例的声音、风格韵律和视觉外观的自动编码器",
            "视听瓶颈表示": "捕捉语音结构化语言内容的表示，用于合成高质量的视听流",
            "无监督学习": "不需要输入说话者的训练数据，仅需目标音频-视频数据进行模型训练"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 818,
        "title": "Unsupervised Discovery of 3D Physical Objects",
        "html": "https://iclr.cc//virtual/2021/poster/3207",
        "abstract": "We study the problem of unsupervised physical object discovery. While existing frameworks aim to decompose scenes into 2D segments based off each object's appearance, we explore how physics, especially object interactions, facilitates disentangling of 3D geometry and position of objects from video, in an unsupervised manner. Drawing inspiration from developmental psychology, our Physical Object Discovery Network (POD-Net) uses both multi-scale pixel cues and physical motion cues to accurately segment observable and partially occluded objects of varying sizes, and infer properties of those objects. Our model reliably segments objects on both synthetic and real scenes.  The discovered object properties can also be used to reason about physical events.",
        "conference": "ICLR",
        "中文标题": "无监督发现的3D物理对象",
        "摘要翻译": "我们研究了无监督物理对象发现的问题。虽然现有框架旨在根据每个对象的外观将场景分解为2D片段，但我们探索了物理学，特别是对象交互，如何以无监督的方式促进从视频中解耦出对象的3D几何和位置。受到发展心理学的启发，我们的物理对象发现网络（POD-Net）使用多尺度像素线索和物理运动线索来准确分割可观察和部分遮挡的不同大小的对象，并推断这些对象的属性。我们的模型在合成场景和真实场景上都能可靠地分割对象。发现的对象属性也可以用于推理物理事件。",
        "领域": "3D对象识别、视频理解、物理场景理解",
        "问题": "如何在无监督的情况下从视频中解耦出对象的3D几何和位置",
        "动机": "探索物理学特别是对象交互如何促进无监督地从视频中解耦出对象的3D几何和位置",
        "方法": "使用多尺度像素线索和物理运动线索的物理对象发现网络（POD-Net）来分割对象并推断其属性",
        "关键词": [
            "无监督学习",
            "3D对象发现",
            "物理场景理解",
            "视频分割",
            "对象属性推理"
        ],
        "涉及的技术概念": {
            "无监督学习": "在无标签数据的情况下，模型自我学习数据的内在结构和模式",
            "多尺度像素线索": "利用不同尺度的像素信息来增强对象分割的准确性",
            "物理运动线索": "通过分析对象的物理运动来辅助对象的识别和分割"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 819,
        "title": "Unsupervised Meta-Learning through Latent-Space Interpolation in Generative Models",
        "html": "https://iclr.cc//virtual/2021/poster/3175",
        "abstract": "Several recently proposed unsupervised meta-learning approaches rely on synthetic meta-tasks created using techniques such as random selection, clustering and/or augmentation. In this work, we describe a novel approach that generates meta-tasks using generative models. The proposed family of algorithms generate pairs of in-class and out-of-class samples from the latent space in a principled way, allowing us to create synthetic classes forming the training and validation data of a meta-task. We find that the proposed approach, LAtent Space Interpolation Unsupervised Meta-learning (LASIUM), outperforms or is competitive with current unsupervised learning baselines on few-shot classification tasks on the most widely used benchmark datasets. ",
        "conference": "ICLR",
        "中文标题": "通过生成模型中潜在空间插值的无监督元学习",
        "摘要翻译": "最近提出的几种无监督元学习方法依赖于使用随机选择、聚类和/或增强等技术创建的合成元任务。在这项工作中，我们描述了一种利用生成模型生成元任务的新方法。所提出的算法家族以一种有原则的方式从潜在空间生成类内和类外样本对，使我们能够创建形成元任务训练和验证数据的合成类。我们发现，所提出的方法——潜在空间插值无监督元学习（LASIUM），在最广泛使用的基准数据集上的少样本分类任务中，优于或与当前的无监督学习基线相竞争。",
        "领域": "生成模型、元学习、少样本学习",
        "问题": "如何在无监督学习环境下，通过生成模型有效地创建和利用元任务以提高少样本分类的性能。",
        "动机": "探索和开发一种新的无监督元学习方法，该方法能够通过生成模型在潜在空间中有效地生成元任务，从而在少样本分类任务中实现更好的性能。",
        "方法": "提出了一种基于生成模型的算法家族，通过在潜在空间中系统地生成类内和类外样本对来创建元任务，进而训练和验证模型。",
        "关键词": [
            "无监督元学习",
            "潜在空间插值",
            "生成模型",
            "少样本分类",
            "LASIUM"
        ],
        "涉及的技术概念": {
            "潜在空间插值": "在生成模型的潜在空间中系统地生成样本对，用于创建元任务的训练和验证数据。",
            "无监督元学习": "在没有人工标注的情况下，通过学习如何学习来提高模型在新任务上的性能。",
            "生成模型": "能够学习数据分布并生成新样本的模型，用于创建元任务中的合成类。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 820,
        "title": "Unsupervised Object Keypoint Learning using Local Spatial Predictability",
        "html": "https://iclr.cc//virtual/2021/poster/3023",
        "abstract": "We propose PermaKey, a novel approach to representation learning based on object keypoints. It leverages the predictability of local image regions from spatial neighborhoods to identify salient regions that correspond to object parts, which are then converted to keypoints. Unlike prior approaches, it utilizes predictability to discover object keypoints, an intrinsic property of objects. This ensures that it does not overly bias keypoints to focus on characteristics that are not unique to objects, such as movement, shape, colour etc.  We demonstrate the efficacy of PermaKey on Atari where it learns keypoints corresponding to the most salient object parts and is robust to certain visual distractors. Further, on downstream RL tasks in the Atari domain we demonstrate how agents equipped with our keypoints outperform those using competing alternatives, even on challenging environments with moving backgrounds or distractor objects.\n",
        "conference": "ICLR",
        "中文标题": "基于局部空间可预测性的无监督物体关键点学习",
        "摘要翻译": "我们提出了PermaKey，一种基于物体关键点的表示学习新方法。它利用局部图像区域从空间邻域的可预测性来识别对应于物体部分的显著区域，然后将这些区域转换为关键点。与之前的方法不同，它利用可预测性来发现物体关键点，这是物体的内在属性。这确保了它不会过度偏向于关注非物体特有的特征，如运动、形状、颜色等。我们在Atari上展示了PermaKey的有效性，它学习了对应于最显著物体部分的关键点，并且对某些视觉干扰物具有鲁棒性。此外，在Atari领域的下游强化学习任务中，我们展示了配备我们关键点的智能体如何在使用竞争替代方案的智能体上表现更优，即使在具有移动背景或干扰物体的挑战性环境中也是如此。",
        "领域": "物体关键点检测、表示学习、强化学习",
        "问题": "如何在无监督的情况下学习物体的关键点表示，避免过度关注非物体特有的特征。",
        "动机": "为了解决现有方法在物体关键点学习中可能过度依赖非物体特有特征（如运动、形状、颜色等）的问题，提出一种基于局部空间可预测性的新方法。",
        "方法": "提出PermaKey方法，通过利用局部图像区域从空间邻域的可预测性来识别和转换物体部分的显著区域为关键点。",
        "关键词": [
            "无监督学习",
            "物体关键点",
            "表示学习",
            "强化学习",
            "Atari"
        ],
        "涉及的技术概念": {
            "局部空间可预测性": "用于识别对应于物体部分的显著区域，是PermaKey方法的核心。",
            "物体关键点": "通过可预测性发现的物体内在属性，用于表示学习。",
            "强化学习": "在下游任务中，使用PermaKey学习的关键点来提升智能体的表现。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 821,
        "title": "Unsupervised Representation Learning for Time Series with Temporal Neighborhood Coding",
        "html": "https://iclr.cc//virtual/2021/poster/2897",
        "abstract": "Time series are often complex and rich in information but sparsely labeled and therefore challenging to model. In this paper, we propose a self-supervised framework for learning robust and generalizable representations for time series. Our approach, called Temporal Neighborhood Coding (TNC), takes advantage of the local smoothness of a signal's generative process to define neighborhoods in time with stationary properties. Using a debiased contrastive objective, our framework learns time series representations by ensuring that in the encoding space, the distribution of signals from within a neighborhood is distinguishable from the distribution of non-neighboring signals. Our motivation stems from the medical field, where the ability to model the dynamic nature of time series data is especially valuable for identifying, tracking, and predicting the underlying patients' latent states in settings where labeling data is practically impossible. We compare our method to recently developed unsupervised representation learning approaches and demonstrate superior performance on clustering and classification tasks for multiple datasets.",
        "conference": "ICLR",
        "中文标题": "时间序列的无监督表示学习：时序邻域编码",
        "摘要翻译": "时间序列通常复杂且信息丰富，但标记稀疏，因此建模具有挑战性。在本文中，我们提出了一个自监督框架，用于学习时间序列的鲁棒且可泛化的表示。我们的方法称为时序邻域编码（TNC），利用信号生成过程的局部平滑性来定义具有平稳特性的时间邻域。通过使用去偏对比目标，我们的框架通过学习确保在编码空间中，来自同一邻域的信号分布与非邻域信号的分布是可区分的，从而学习时间序列的表示。我们的动机来源于医学领域，在标记数据几乎不可能的情况下，建模时间序列数据的动态特性对于识别、跟踪和预测患者潜在状态尤其有价值。我们将我们的方法与最近开发的无监督表示学习方法进行了比较，并在多个数据集的聚类和分类任务上展示了优越的性能。",
        "领域": "时间序列分析, 自监督学习, 医学信号处理",
        "问题": "如何在标记稀疏的情况下，学习时间序列的鲁棒且可泛化的表示。",
        "动机": "在医学等领域，标记数据难以获取，需要一种能够有效建模时间序列动态特性的方法。",
        "方法": "提出时序邻域编码（TNC）方法，利用信号的局部平滑性定义时间邻域，并通过去偏对比目标学习区分邻域与非邻域信号的表示。",
        "关键词": [
            "时间序列",
            "自监督学习",
            "时序邻域编码",
            "去偏对比学习",
            "医学信号处理"
        ],
        "涉及的技术概念": {
            "时序邻域编码（TNC）": "利用信号生成过程的局部平滑性定义时间邻域，用于学习时间序列的表示。",
            "去偏对比目标": "用于确保编码空间中邻域内信号与非邻域信号的分布是可区分的，从而优化表示学习。",
            "自监督学习": "在没有大量标记数据的情况下，通过设计特定的学习任务来学习数据的表示。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 822,
        "title": "UPDeT: Universal Multi-agent RL via Policy Decoupling with Transformers",
        "html": "https://iclr.cc//virtual/2021/poster/2811",
        "abstract": "Recent advances in multi-agent reinforcement learning have been largely limited in training one model from scratch for every new task. The limitation is due to the restricted model architecture related to fixed input and output dimensions. This hinders the experience accumulation and transfer of the learned agent over tasks with diverse levels of difficulty (e.g. 3 vs 3 or 5 vs 6 multi-agent games).  In this paper, we make the first attempt to explore a universal multi-agent reinforcement learning pipeline, designing one single architecture to fit tasks with the requirement of different observation and action configurations. Unlike previous RNN-based models, we utilize a transformer-based model to generate a flexible policy by decoupling the policy distribution from the intertwined input observation with an importance weight measured by the merits of the self-attention mechanism. Compared to a standard transformer block, the proposed model, named as Universal Policy Decoupling Transformer (UPDeT), further relaxes the action restriction and makes the multi-agent task's decision process more explainable. UPDeT is general enough to be plugged into any multi-agent reinforcement learning pipeline and equip them with strong generalization abilities that enables the handling of multiple tasks at a time. Extensive experiments on large-scale SMAC multi-agent competitive games demonstrate that the proposed UPDeT-based multi-agent reinforcement learning achieves significant results relative to state-of-the-art approaches, demonstrating advantageous transfer capability in terms of both performance and training speed (10 times faster).",
        "conference": "ICLR",
        "中文标题": "UPDeT：通过策略解耦与变换器的通用多智能体强化学习",
        "摘要翻译": "近年来，多智能体强化学习的进展在很大程度上局限于为每个新任务从头开始训练一个模型。这一限制源于与固定输入和输出维度相关的受限模型架构。这阻碍了学习智能体在不同难度任务（如3对3或5对6的多智能体游戏）上的经验积累和迁移。在本文中，我们首次尝试探索一种通用的多智能体强化学习流程，设计一个单一的架构以适应需要不同观察和行动配置的任务。与之前基于RNN的模型不同，我们利用基于变换器的模型，通过将策略分布与通过自注意力机制优点衡量的重要性权重解耦，生成一个灵活的策略。与标准的变换器块相比，所提出的模型，名为通用策略解耦变换器（UPDeT），进一步放宽了行动限制，并使多智能体任务的决策过程更具解释性。UPDeT足够通用，可以插入任何多智能体强化学习流程，并赋予它们强大的泛化能力，使其能够同时处理多个任务。在大型SMAC多智能体竞争游戏上的大量实验表明，基于UPDeT的多智能体强化学习相对于最先进的方法取得了显著成果，展示了在性能和训练速度（快10倍）方面的优势迁移能力。",
        "领域": "多智能体强化学习、策略解耦、变换器模型",
        "问题": "解决多智能体强化学习中模型架构固定导致的泛化能力不足问题",
        "动机": "探索一种通用的多智能体强化学习流程，以提高模型在不同任务间的泛化能力和迁移效率",
        "方法": "利用基于变换器的模型，通过策略解耦和自注意力机制，生成灵活的策略以适应不同观察和行动配置的任务",
        "关键词": [
            "多智能体强化学习",
            "策略解耦",
            "变换器模型",
            "泛化能力",
            "自注意力机制"
        ],
        "涉及的技术概念": {
            "策略解耦": "将策略分布与输入观察解耦，以提高模型的灵活性和适应性",
            "变换器模型": "利用自注意力机制处理输入数据，生成灵活的策略分布",
            "自注意力机制": "衡量输入观察的重要性权重，帮助模型更有效地处理多智能体任务"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 823,
        "title": "Usable Information and Evolution of Optimal Representations During Training",
        "html": "https://iclr.cc//virtual/2021/poster/2864",
        "abstract": "We introduce a notion of usable information contained in the representation learned by a deep network, and use it to study how optimal representations for the task emerge during training. We show that the implicit regularization coming from training with Stochastic Gradient Descent with a high learning-rate and small batch size plays an important role in learning minimal sufficient representations for the task. In the process of arriving at a minimal sufficient representation, we find that the content of the representation changes dynamically during training. In particular, we find that semantically meaningful but ultimately irrelevant information is encoded in the early transient dynamics of training, before being later discarded. In addition, we evaluate how perturbing the initial part of training impacts the learning dynamics and the resulting representations. We show these effects on both perceptual decision-making tasks inspired by neuroscience literature, as well as on standard image classification tasks.",
        "conference": "ICLR",
        "中文标题": "可用信息与训练过程中最优表征的演化",
        "摘要翻译": "我们引入了深度网络学习表征中所含可用信息的概念，并利用这一概念研究了任务最优表征在训练过程中是如何形成的。我们展示了使用高学习率和小批量大小的随机梯度下降训练所带来的隐式正则化在学习任务的最小充分表征中扮演了重要角色。在达到最小充分表征的过程中，我们发现表征的内容在训练过程中动态变化。特别是，我们发现语义上有意义但最终无关的信息在训练的早期瞬态动态中被编码，随后被丢弃。此外，我们评估了扰动训练初始部分如何影响学习动态和最终的表征。我们在受神经科学文献启发的感知决策任务以及标准图像分类任务上展示了这些效应。",
        "领域": "深度学习理论、神经网络优化、表征学习",
        "问题": "研究深度网络在训练过程中如何形成对任务最优的表征，以及训练动态如何影响这些表征的形成。",
        "动机": "理解深度网络在学习过程中如何动态地形成和优化其内部表征，以及训练策略（如学习率和批量大小）如何影响这一过程。",
        "方法": "引入可用信息的概念来量化表征的质量，使用随机梯度下降（SGD）进行训练，分析训练动态和表征变化，特别是在早期训练阶段的信息编码和后续的丢弃过程。",
        "关键词": [
            "可用信息",
            "最优表征",
            "训练动态",
            "随机梯度下降",
            "表征学习"
        ],
        "涉及的技术概念": {
            "可用信息": "用于量化深度网络学习表征中所含对任务有用的信息量，帮助理解表征的质量。",
            "随机梯度下降（SGD）": "一种优化算法，用于训练深度网络，本研究特别关注其高学习率和小批量大小对学习最小充分表征的影响。",
            "表征学习": "研究深度网络如何从数据中学习有用的表征，本研究中关注的是表征在训练过程中的动态变化和优化。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 824,
        "title": "Using latent space regression to analyze and leverage compositionality in GANs",
        "html": "https://iclr.cc//virtual/2021/poster/2871",
        "abstract": "In recent years, Generative Adversarial Networks have become ubiquitous in both research and public perception, but how GANs convert an unstructured latent code to a high quality output is still an open question. In this work, we investigate regression into the latent space as a probe to understand the compositional properties of GANs.  We find that combining the regressor and a pretrained generator provides a strong image prior, allowing us to create composite images from a collage of random image parts at inference time while maintaining global consistency. To compare compositional properties across different generators, we measure the trade-offs between reconstruction of the unrealistic input and image quality of the regenerated samples. We find that the regression approach enables more localized editing of individual image parts compared to direct editing in the latent space, and we conduct experiments to quantify this independence effect. Our method is agnostic to the semantics of edits, and does not require labels or predefined concepts during training. Beyond image composition, our method extends to a number of related applications, such as image inpainting or example-based image editing, which we demonstrate on several GANs and datasets, and\nbecause it uses only a single forward pass, it can operate in real-time. Code is available on our project page: https://chail.github.io/latent-composition/.",
        "conference": "ICLR",
        "中文标题": "利用潜在空间回归分析并利用GANs的组合性",
        "摘要翻译": "近年来，生成对抗网络（GANs）在研究和公众认知中变得无处不在，但GANs如何将非结构化的潜在代码转换为高质量输出仍然是一个未解决的问题。在这项工作中，我们研究了潜在空间回归作为一种探针来理解GANs的组合特性。我们发现，将回归器与预训练的生成器结合提供了强大的图像先验，使我们能够在推理时从随机图像部分的拼贴中创建复合图像，同时保持全局一致性。为了比较不同生成器的组合特性，我们测量了不现实输入的重建与再生样本图像质量之间的权衡。我们发现，与直接在潜在空间中进行编辑相比，回归方法能够对单个图像部分进行更局部的编辑，并且我们进行了实验来量化这种独立效应。我们的方法对编辑的语义是不可知的，并且在训练过程中不需要标签或预定义的概念。除了图像组合，我们的方法还扩展到许多相关应用，如图像修复或基于示例的图像编辑，我们在多个GANs和数据集上展示了这一点，并且因为它仅使用单次前向传播，所以可以实时操作。代码可在我们的项目页面上找到：https://chail.github.io/latent-composition/。",
        "领域": "生成对抗网络、图像编辑、图像修复",
        "问题": "理解并利用GANs如何将非结构化的潜在代码转换为高质量输出的组合特性",
        "动机": "探索GANs的组合特性，以提升图像编辑和修复的质量和效率",
        "方法": "通过潜在空间回归分析GANs的组合特性，结合回归器和预训练生成器创建复合图像",
        "关键词": [
            "潜在空间回归",
            "生成对抗网络",
            "图像编辑",
            "图像修复",
            "组合性"
        ],
        "涉及的技术概念": {
            "潜在空间回归": "用于分析GANs如何将潜在代码转换为高质量输出的技术，通过回归方法理解GANs的组合特性",
            "生成对抗网络": "一种深度学习模型，通过生成器和判别器的对抗训练生成高质量图像",
            "图像先验": "在图像生成或编辑过程中，利用预训练模型提供的关于图像结构和内容的先验知识"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 825,
        "title": "VAEBM: A Symbiosis between Variational Autoencoders and Energy-based Models",
        "html": "https://iclr.cc//virtual/2021/poster/2615",
        "abstract": "Energy-based models (EBMs) have recently been successful in representing complex distributions of small images. However, sampling from them requires expensive Markov chain Monte Carlo (MCMC) iterations that mix slowly in high dimensional pixel space. Unlike EBMs, variational autoencoders (VAEs) generate samples quickly and are equipped with a latent space that enables fast traversal of the data manifold. However, VAEs tend to assign high probability density to regions in data space outside the actual data distribution and often fail at generating sharp images. In this paper, we propose VAEBM, a symbiotic composition of a VAE and an EBM that offers the best of both worlds. VAEBM captures the overall mode structure of the data distribution using a state-of-the-art VAE and it relies on its EBM component to explicitly exclude non-data-like regions from the model and refine the image samples. Moreover, the VAE component in VAEBM allows us to speed up MCMC updates by reparameterizing them in the VAE's latent space. Our experimental results show that VAEBM outperforms state-of-the-art VAEs and EBMs in generative quality on several benchmark image datasets by a large margin. It can generate high-quality images as large as 256$\\times$256 pixels with short MCMC chains. We also demonstrate that VAEBM provides complete mode coverage and performs well in out-of-distribution detection. ",
        "conference": "ICLR",
        "中文标题": "VAEBM：变分自编码器与基于能量的模型的共生关系",
        "摘要翻译": "基于能量的模型（EBMs）最近在表示小图像的复杂分布方面取得了成功。然而，从这些模型中采样需要昂贵的马尔可夫链蒙特卡洛（MCMC）迭代，这些迭代在高维像素空间中混合缓慢。与EBMs不同，变分自编码器（VAEs）能够快速生成样本，并且配备了潜在空间，能够快速遍历数据流形。然而，VAEs倾向于将高概率密度分配给数据空间中实际数据分布之外的区域，并且经常无法生成清晰的图像。在本文中，我们提出了VAEBM，这是一种VAE和EBM的共生组合，提供了两者的最佳特性。VAEBM使用最先进的VAE捕获数据分布的总体模式结构，并依赖其EBM组件明确地从模型中排除非数据类区域并细化图像样本。此外，VAEBM中的VAE组件允许我们通过在VAE的潜在空间中重新参数化来加速MCMC更新。我们的实验结果表明，VAEBM在几个基准图像数据集上的生成质量上大幅优于最先进的VAEs和EBMs。它能够生成高达256×256像素的高质量图像，且MCMC链较短。我们还证明了VAEBM提供了完整的模式覆盖，并在分布外检测中表现良好。",
        "领域": "生成模型、图像生成、深度学习",
        "问题": "解决变分自编码器（VAEs）和基于能量的模型（EBMs）在图像生成中的局限性问题",
        "动机": "结合VAEs和EBMs的优势，提高图像生成的质量和效率",
        "方法": "提出VAEBM模型，结合VAE捕获数据分布总体模式结构的能力和EBM排除非数据类区域并细化样本的能力，同时在VAE的潜在空间中重新参数化以加速MCMC更新",
        "关键词": [
            "VAEBM",
            "变分自编码器",
            "基于能量的模型",
            "图像生成",
            "MCMC加速"
        ],
        "涉及的技术概念": {
            "变分自编码器（VAE）": "用于快速生成样本和捕获数据分布的总体模式结构",
            "基于能量的模型（EBM）": "用于明确排除非数据类区域并细化图像样本",
            "马尔可夫链蒙特卡洛（MCMC）": "用于从EBMs中采样，VAEBM通过在VAE的潜在空间中重新参数化来加速这一过程"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 826,
        "title": "VA-RED$^2$: Video Adaptive Redundancy Reduction",
        "html": "https://iclr.cc//virtual/2021/poster/2971",
        "abstract": "Performing inference on deep learning models for videos remains a challenge due to the large amount of computational resources required to achieve robust recognition. An inherent property of real-world videos is the high correlation of information across frames which can translate into redundancy in either temporal or spatial feature maps of the models, or both. The type of redundant features depends on the dynamics and type of events in the video: static videos have more temporal redundancy while videos focusing on objects tend to have more channel redundancy. Here we present a redundancy reduction framework, termed VA-RED$^2$, which is input-dependent. Specifically, our VA-RED$^2$ framework uses an input-dependent policy to decide how many features need to be computed for temporal and channel dimensions. To keep the capacity of the original model, after fully computing the necessary features, we reconstruct the remaining redundant features from those using cheap linear operations. We learn the adaptive policy jointly with the network weights in a differentiable way with a shared-weight mechanism, making it highly efficient. Extensive experiments on multiple video datasets and different visual tasks show that our framework achieves $20\\% - 40\\%$ reduction in computation (FLOPs) when compared to state-of-the-art methods without any performance loss. Project page: http://people.csail.mit.edu/bpan/va-red/.",
        "conference": "ICLR",
        "中文标题": "VA-RED2：视频自适应冗余减少",
        "摘要翻译": "由于实现稳健识别需要大量的计算资源，对视频的深度学习模型进行推理仍然是一个挑战。现实世界视频的一个固有特性是跨帧信息的高度相关性，这可以转化为模型在时间或空间特征图中的冗余，或两者兼而有之。冗余特征的类型取决于视频的动态和事件类型：静态视频具有更多的时间冗余，而专注于对象的视频则倾向于具有更多的通道冗余。在此，我们提出了一个冗余减少框架，称为VA-RED2，它是输入依赖的。具体来说，我们的VA-RED2框架使用一个输入依赖的策略来决定需要为时间和通道维度计算多少特征。为了保持原始模型的能力，在完全计算必要的特征后，我们使用廉价的线性操作从这些特征中重建剩余的冗余特征。我们以可微分的方式与网络权重联合学习自适应策略，采用共享权重机制，使其非常高效。在多个视频数据集和不同视觉任务上的大量实验表明，与最先进的方法相比，我们的框架在不损失任何性能的情况下实现了20%到40%的计算量（FLOPs）减少。项目页面：http://people.csail.mit.edu/bpan/va-red/。",
        "领域": "视频理解、深度学习优化、计算效率提升",
        "问题": "减少视频深度学习模型推理时的计算冗余",
        "动机": "解决视频处理中因信息高度相关性导致的特征冗余问题，提高计算效率",
        "方法": "提出输入依赖的冗余减少框架VA-RED2，通过自适应策略决定计算哪些特征，并使用线性操作重建冗余特征",
        "关键词": [
            "视频理解",
            "冗余减少",
            "计算效率",
            "自适应策略",
            "深度学习优化"
        ],
        "涉及的技术概念": {
            "输入依赖策略": "根据输入视频动态决定计算哪些特征，以减少冗余",
            "特征重建": "通过线性操作从已计算的特征中重建冗余特征，保持模型能力",
            "共享权重机制": "在可微分的方式下联合学习自适应策略和网络权重，提高效率"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 827,
        "title": "Variational Information Bottleneck for Effective Low-Resource Fine-Tuning",
        "html": "https://iclr.cc//virtual/2021/poster/2560",
        "abstract": "While large-scale pretrained language models have obtained impressive results when fine-tuned on a wide variety of tasks, they still often suffer from overfitting in low-resource scenarios. Since such models are general-purpose feature extractors, many of these features are inevitably irrelevant for a given target task.  We propose to use Variational Information Bottleneck (VIB) to suppress irrelevant features when fine-tuning on low-resource target tasks, and show that our method successfully reduces overfitting.  Moreover, we show that our VIB model finds sentence representations that are more robust to biases in natural language inference datasets, and thereby obtains better generalization to out-of-domain datasets. Evaluation on seven low-resource datasets in different tasks shows that our method significantly improves transfer learning in low-resource scenarios, surpassing prior work. Moreover, it improves generalization on 13 out of 15 out-of-domain natural language inference benchmarks.  Our code is publicly available in https://github.com/rabeehk/vibert.",
        "conference": "ICLR",
        "中文标题": "变分信息瓶颈在低资源微调中的有效应用",
        "摘要翻译": "尽管大规模预训练语言模型在广泛的任务上进行微调时取得了令人印象深刻的结果，但在低资源场景下，它们仍然经常遭受过拟合的问题。由于这些模型是通用特征提取器，许多特征对于给定的目标任务来说不可避免地是无关的。我们提出使用变分信息瓶颈（VIB）来在低资源目标任务微调时抑制无关特征，并展示我们的方法成功地减少了过拟合。此外，我们还展示了我们的VIB模型找到了对自然语言推理数据集中的偏见更加鲁棒的句子表示，从而获得了对域外数据集更好的泛化能力。在不同任务的七个低资源数据集上的评估表明，我们的方法显著提高了低资源场景下的迁移学习效果，超越了先前的工作。此外，它在15个域外自然语言推理基准测试中的13个上提高了泛化能力。我们的代码已在https://github.com/rabeehk/vibert上公开。",
        "领域": "自然语言处理与视觉结合、迁移学习、自然语言推理",
        "问题": "解决大规模预训练语言模型在低资源场景下微调时的过拟合问题",
        "动机": "由于预训练模型作为通用特征提取器，包含许多与目标任务无关的特征，导致在低资源场景下容易过拟合，因此需要一种方法来抑制这些无关特征，提高模型的泛化能力。",
        "方法": "采用变分信息瓶颈（VIB）技术，在低资源目标任务微调过程中抑制无关特征，减少过拟合，并提高模型的泛化能力。",
        "关键词": [
            "变分信息瓶颈",
            "低资源微调",
            "过拟合抑制",
            "自然语言推理",
            "迁移学习"
        ],
        "涉及的技术概念": {
            "变分信息瓶颈（VIB）": "用于在模型微调过程中抑制与目标任务无关的特征，减少过拟合，提高模型的泛化能力。",
            "过拟合": "指模型在训练数据上表现良好，但在未见过的数据上表现不佳的现象，本文通过VIB技术来缓解这一问题。",
            "自然语言推理": "一种评估模型理解自然语言能力的任务，本文通过VIB技术提高了模型在这一任务上的泛化能力。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 828,
        "title": "Variational Intrinsic Control Revisited",
        "html": "https://iclr.cc//virtual/2021/poster/3149",
        "abstract": "In this paper, we revisit variational intrinsic control (VIC), an unsupervised reinforcement learning method for finding the largest set of intrinsic options available to an agent. In the original work by Gregor et al. (2016), two VIC algorithms were proposed: one that represents the options explicitly, and the other that does it implicitly. We show that the intrinsic reward used in the latter is subject to bias in stochastic environments, causing convergence to suboptimal solutions. To correct this behavior, we propose two methods respectively based on the transitional probability model and Gaussian Mixture Model. We substantiate our claims through rigorous mathematical derivations and experimental analyses. ",
        "conference": "ICLR",
        "中文标题": "变分内在控制再探",
        "摘要翻译": "本文重新审视了变分内在控制（VIC），这是一种用于发现智能体可用最大内在选项集的无监督强化学习方法。在Gregor等人（2016）的原始工作中，提出了两种VIC算法：一种明确表示选项，另一种则隐式表示。我们表明，后者中使用的内在奖励在随机环境中容易受到偏差的影响，导致收敛到次优解。为了纠正这种行为，我们提出了分别基于转移概率模型和高斯混合模型的两种方法。我们通过严格的数学推导和实验分析证实了我们的主张。",
        "领域": "强化学习、无监督学习、智能体控制",
        "问题": "解决变分内在控制在随机环境中因内在奖励偏差导致收敛到次优解的问题",
        "动机": "为了纠正变分内在控制在随机环境中的偏差问题，提高算法的性能和稳定性",
        "方法": "提出了基于转移概率模型和高斯混合模型的两种改进方法",
        "关键词": [
            "变分内在控制",
            "无监督强化学习",
            "随机环境",
            "转移概率模型",
            "高斯混合模型"
        ],
        "涉及的技术概念": {
            "变分内在控制": "一种无监督强化学习方法，用于发现智能体可用的最大内在选项集",
            "转移概率模型": "用于纠正内在奖励偏差，提高算法在随机环境中的性能",
            "高斯混合模型": "另一种用于纠正内在奖励偏差的方法，通过模型化环境的不确定性来优化算法性能"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 829,
        "title": "Variational State-Space Models for Localisation and Dense 3D Mapping in 6 DoF",
        "html": "https://iclr.cc//virtual/2021/poster/2879",
        "abstract": "We solve the problem of 6-DoF localisation and 3D dense reconstruction in spatial environments as approximate Bayesian inference in a deep state-space model. Our approach leverages both learning and domain knowledge from multiple-view geometry and rigid-body dynamics. This results in an expressive predictive model of the world, often missing in current state-of-the-art visual SLAM solutions. The combination of variational inference, neural networks and a differentiable raycaster ensures that our model is amenable to end-to-end gradient-based optimisation. We evaluate our approach on realistic unmanned aerial vehicle flight data, nearing the performance of state-of-the-art visual-inertial odometry systems. We demonstrate the applicability of the model to generative prediction and planning.",
        "conference": "ICLR",
        "中文标题": "变分状态空间模型在6自由度定位与密集三维建图中的应用",
        "摘要翻译": "我们通过深度状态空间模型中的近似贝叶斯推断，解决了空间环境中6自由度定位和3D密集重建的问题。我们的方法利用了多视图几何和刚体动力学的学习与领域知识。这导致了一个对世界具有表达力的预测模型，这在当前最先进的视觉SLAM解决方案中常常缺失。变分推断、神经网络和可微分光线投射器的结合确保了我们的模型适合基于梯度的端到端优化。我们在现实的无人机飞行数据上评估了我们的方法，接近了最先进的视觉惯性里程计系统的性能。我们展示了该模型在生成预测和规划中的适用性。",
        "领域": "视觉SLAM、三维重建、无人机导航",
        "问题": "解决在复杂空间环境中进行精确的6自由度定位和密集3D重建的问题",
        "动机": "当前最先进的视觉SLAM解决方案缺乏对世界的表达力预测模型，本研究旨在填补这一空白",
        "方法": "结合变分推断、神经网络和可微分光线投射器，利用多视图几何和刚体动力学的知识，构建深度状态空间模型进行端到端优化",
        "关键词": [
            "变分推断",
            "深度状态空间模型",
            "6自由度定位",
            "密集3D重建",
            "视觉SLAM"
        ],
        "涉及的技术概念": {
            "变分推断": "用于在深度状态空间模型中实现近似贝叶斯推断，优化模型参数",
            "深度状态空间模型": "构建对空间环境的表达力预测模型，支持6自由度定位和3D重建",
            "可微分光线投射器": "在模型中实现光线投射操作的可微分版本，支持端到端的梯度优化"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 830,
        "title": "VCNet and Functional Targeted Regularization For Learning Causal Effects of Continuous Treatments",
        "html": "https://iclr.cc//virtual/2021/poster/2904",
        "abstract": "Motivated by the rising abundance of observational data with continuous treatments, we investigate the problem of estimating the average dose-response curve (ADRF). Available parametric methods are limited in their model space, and previous attempts in leveraging neural network to enhance model expressiveness relied on partitioning continuous treatment into blocks and using separate heads for each block; this however produces in practice discontinuous ADRFs. Therefore, the question of how to adapt the structure and training of neural network to estimate ADRFs remains open. This paper makes two important contributions. First, we propose a novel varying coefficient neural network (VCNet) that improves model expressiveness while preserving continuity of the estimated ADRF. Second, to improve finite sample performance, we generalize targeted regularization to obtain a doubly robust estimator of the whole ADRF curve.",
        "conference": "ICLR",
        "中文标题": "VCNet与功能目标正则化用于学习连续治疗的因果效应",
        "摘要翻译": "受到观测数据中连续治疗日益增多的启发，我们研究了估计平均剂量-响应曲线（ADRF）的问题。现有的参数方法在其模型空间上存在限制，之前尝试利用神经网络增强模型表达能力的方法依赖于将连续治疗划分为块并为每个块使用单独的头部；然而，这在实际中产生了不连续的ADRF。因此，如何调整神经网络的结构和训练以估计ADRF的问题仍然开放。本文做出了两个重要贡献。首先，我们提出了一种新颖的变系数神经网络（VCNet），它在提高模型表达能力的同时保持了估计ADRF的连续性。其次，为了提高有限样本性能，我们推广了目标正则化以获得整个ADRF曲线的双重稳健估计器。",
        "领域": "因果推断、连续治疗效应估计、神经网络应用",
        "问题": "如何有效估计连续治疗下的平均剂量-响应曲线（ADRF）",
        "动机": "解决现有方法在模型表达能力和ADRF连续性上的限制",
        "方法": "提出变系数神经网络（VCNet）和推广目标正则化方法",
        "关键词": [
            "连续治疗效应",
            "变系数神经网络",
            "目标正则化",
            "因果推断",
            "ADRF估计"
        ],
        "涉及的技术概念": {
            "变系数神经网络（VCNet）": "一种新颖的神经网络结构，旨在提高模型对连续治疗效应的表达能力同时保持ADRF的连续性",
            "目标正则化": "一种推广的正则化方法，用于提高估计器在有限样本下的性能，实现双重稳健性",
            "平均剂量-响应曲线（ADRF）": "描述治疗剂量与响应之间关系的曲线，本文重点研究其在连续治疗下的估计问题"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 831,
        "title": "Vector-output ReLU Neural Network Problems are Copositive Programs: Convex Analysis of Two Layer Networks and Polynomial-time Algorithms",
        "html": "https://iclr.cc//virtual/2021/poster/3254",
        "abstract": "We describe the convex semi-infinite dual of the two-layer vector-output ReLU neural network training problem. This semi-infinite dual admits a finite dimensional representation, but its support is over a convex set which is difficult to characterize. In particular, we demonstrate that the non-convex neural network training problem is equivalent to a finite-dimensional convex copositive program. Our work is the first to identify this strong connection between the global optima of neural networks and those of copositive programs. We thus demonstrate how neural networks implicitly attempt to solve copositive programs via semi-nonnegative matrix factorization, and draw key insights from this formulation. We describe the first algorithms for provably finding the global minimum of the vector output neural network training problem, which are polynomial in the number of samples for a fixed data rank, yet exponential in the dimension. However, in the case of convolutional architectures, the computational complexity is exponential in only the filter size and polynomial in all other parameters. We describe the circumstances in which we can find the global optimum of this neural network training problem exactly with soft-thresholded SVD, and provide a copositive relaxation which is guaranteed to be exact for certain classes of problems, and which corresponds with the solution of Stochastic Gradient Descent in practice.",
        "conference": "ICLR",
        "中文标题": "向量输出ReLU神经网络问题是共正规划：两层网络的凸分析与多项式时间算法",
        "摘要翻译": "我们描述了两层向量输出ReLU神经网络训练问题的凸半无限对偶。这个半无限对偶允许有限维表示，但其支持集在一个难以表征的凸集上。特别是，我们证明了非凸神经网络训练问题等价于一个有限维凸共正规划。我们的工作是第一个识别出神经网络全局最优解与共正规划全局最优解之间这种强烈联系的研究。因此，我们展示了神经网络如何通过半非负矩阵分解隐式尝试解决共正规划，并从这个公式中提取关键见解。我们描述了第一个算法，用于可证明地找到向量输出神经网络训练问题的全局最小值，这些算法在固定数据秩的样本数量上是多项式的，但在维度上是指数的。然而，在卷积架构的情况下，计算复杂度仅在滤波器大小上是指数的，在所有其他参数上是多项式的。我们描述了在哪些情况下我们可以通过软阈值SVD精确找到这个神经网络训练问题的全局最优解，并提供了一个共正松弛，保证对某些类别的问题是精确的，并且与实践中随机梯度下降的解相对应。",
        "领域": "深度学习优化、神经网络理论、凸优化",
        "问题": "解决两层向量输出ReLU神经网络训练问题的全局最优解寻找问题",
        "动机": "探索神经网络训练问题与共正规划之间的强联系，为神经网络训练提供新的理论和方法支持",
        "方法": "通过将神经网络训练问题转化为共正规划问题，利用半非负矩阵分解和凸优化技术，开发多项式时间算法寻找全局最优解",
        "关键词": [
            "共正规划",
            "ReLU神经网络",
            "全局优化",
            "半非负矩阵分解",
            "凸分析"
        ],
        "涉及的技术概念": {
            "共正规划": "用于描述和解决神经网络训练问题的凸优化框架，揭示了神经网络训练与共正规划之间的等价性",
            "半非负矩阵分解": "神经网络隐式尝试解决共正规划的技术手段，用于从数据中提取特征",
            "软阈值SVD": "在特定情况下精确找到神经网络训练问题全局最优解的算法，基于奇异值分解和软阈值处理"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 832,
        "title": "Very Deep VAEs Generalize Autoregressive Models and Can Outperform Them on Images",
        "html": "https://iclr.cc//virtual/2021/poster/2790",
        "abstract": "We present a hierarchical VAE that, for the first time, generates samples quickly $\\textit{and}$ outperforms the PixelCNN in log-likelihood on all natural image benchmarks. We begin by observing that, in theory, VAEs can actually represent autoregressive models, as well as faster, better models if they exist, when made sufficiently deep. Despite this, autoregressive models have historically outperformed VAEs in log-likelihood. We test if insufficient depth explains why by scaling a VAE to greater stochastic depth than previously explored and evaluating it CIFAR-10, ImageNet, and FFHQ. In comparison to the PixelCNN, these very deep VAEs achieve higher likelihoods, use fewer parameters, generate samples thousands of times faster, and are more easily applied to high-resolution images. Qualitative studies suggest this is because the VAE learns efficient hierarchical visual representations. We release our source code and models at https://github.com/openai/vdvae.",
        "conference": "ICLR",
        "中文标题": "非常深的变分自编码器泛化自回归模型并在图像上可能超越它们",
        "摘要翻译": "我们提出了一种层次化的变分自编码器（VAE），首次在生成样本的速度上快于PixelCNN，并且在所有自然图像基准测试中的对数似然性上超越了它。我们首先观察到，理论上，当变分自编码器足够深时，它们实际上可以表示自回归模型，以及如果存在更快、更好的模型。尽管如此，自回归模型在历史上在对数似然性上一直优于变分自编码器。我们测试了深度不足是否是原因，通过将变分自编码器扩展到比以前探索的更深的随机深度，并在CIFAR-10、ImageNet和FFHQ上进行了评估。与PixelCNN相比，这些非常深的变分自编码器实现了更高的似然性，使用了更少的参数，生成样本的速度快了几千倍，并且更容易应用于高分辨率图像。定性研究表明，这是因为变分自编码器学习了高效的层次化视觉表示。我们在https://github.com/openai/vdvae上发布了我们的源代码和模型。",
        "领域": "生成模型、图像生成、深度学习",
        "问题": "变分自编码器（VAE）在生成图像时的对数似然性通常不如自回归模型，且生成速度慢。",
        "动机": "探索是否通过增加变分自编码器的深度，可以使其在生成图像的对数似然性和速度上超越自回归模型。",
        "方法": "开发了一种层次化的变分自编码器，并将其扩展到前所未有的深度，以评估其在多个自然图像数据集上的性能。",
        "关键词": [
            "变分自编码器",
            "自回归模型",
            "图像生成",
            "对数似然性",
            "层次化表示"
        ],
        "涉及的技术概念": {
            "变分自编码器（VAE）": "一种生成模型，通过学习数据的潜在变量分布来生成新的数据样本。",
            "自回归模型": "一种生成模型，通过基于先前像素预测下一个像素来生成图像。",
            "对数似然性": "用于评估生成模型性能的指标，衡量模型生成的数据与真实数据分布的接近程度。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 833,
        "title": "Viewmaker Networks: Learning Views for Unsupervised Representation Learning",
        "html": "https://iclr.cc//virtual/2021/poster/2544",
        "abstract": "Many recent methods for unsupervised representation learning train models to be invariant to different 'views,' or distorted versions of an input. However, designing these views requires considerable trial and error by human experts, hindering widespread adoption of unsupervised representation learning methods across domains and modalities. To address this, we propose viewmaker networks: generative models that learn to produce useful views from a given input. Viewmakers are stochastic bounded adversaries: they produce views by generating and then adding an $\\ell_p$-bounded perturbation to the input, and are trained adversarially with respect to the main encoder network. Remarkably, when pretraining on CIFAR-10, our learned views enable comparable transfer accuracy to the well-tuned SimCLR augmentations---despite not including transformations like cropping or color jitter. Furthermore, our learned views significantly outperform baseline augmentations on speech recordings (+9 points on average) and wearable sensor data (+17 points on average). Viewmaker views can also be combined with handcrafted views: they improve robustness to common image corruptions and can increase transfer performance in cases where handcrafted views are less explored. These results suggest that viewmakers may provide a path towards more general representation learning algorithms---reducing the domain expertise and effort needed to pretrain on a much wider set of domains. Code is available at https://github.com/alextamkin/viewmaker.",
        "conference": "ICLR",
        "中文标题": "视图生成器网络：学习无监督表示学习的视图",
        "摘要翻译": "许多最近的无监督表示学习方法训练模型对不同的'视图'或输入的扭曲版本保持不变。然而，设计这些视图需要人类专家进行大量的试错，阻碍了无监督表示学习方法在各个领域和模态中的广泛应用。为了解决这个问题，我们提出了视图生成器网络：一种生成模型，学习从给定输入中产生有用的视图。视图生成器是随机有界对手：它们通过生成然后向输入添加一个有界扰动来产生视图，并且与主编码器网络进行对抗训练。值得注意的是，当在CIFAR-10上进行预训练时，我们学习的视图能够实现与经过良好调整的SimCLR增强相当的转移准确度——尽管不包括像裁剪或颜色抖动这样的变换。此外，我们学习的视图在语音录音（平均+9分）和可穿戴传感器数据（平均+17分）上显著优于基线增强。视图生成器的视图也可以与手工制作的视图结合使用：它们提高了对常见图像损坏的鲁棒性，并且可以在手工制作的视图较少探索的情况下提高转移性能。这些结果表明，视图生成器可能提供了一条通向更通用的表示学习算法的路径——减少了在更广泛的领域上进行预训练所需的领域专业知识和努力。代码可在https://github.com/alextamkin/viewmaker获取。",
        "领域": "无监督学习、表示学习、数据增强",
        "问题": "如何自动生成有效的视图以改进无监督表示学习，减少对人工设计视图的依赖",
        "动机": "减少无监督表示学习中对人工设计视图的依赖，提高方法在不同领域和模态中的适用性",
        "方法": "提出视图生成器网络，通过生成有界扰动来产生视图，并与主编码器网络进行对抗训练",
        "关键词": [
            "视图生成器",
            "无监督学习",
            "表示学习",
            "数据增强",
            "对抗训练"
        ],
        "涉及的技术概念": {
            "视图生成器网络": "生成模型，用于自动产生有助于无监督表示学习的视图",
            "有界扰动": "视图生成器生成的扰动，用于在不显著改变输入数据的情况下产生新视图",
            "对抗训练": "视图生成器与主编码器网络之间的训练策略，旨在提高视图的质量和多样性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 834,
        "title": "VTNet: Visual Transformer Network for Object Goal Navigation",
        "html": "https://iclr.cc//virtual/2021/poster/3287",
        "abstract": "Object goal navigation aims to steer an agent towards a target object based on observations of the agent. It is of pivotal importance to design effective visual representations of the observed scene in determining navigation actions.  In this paper, we introduce a Visual Transformer Network (VTNet) for learning informative visual representation in navigation.  VTNet is a highly effective structure that embodies two key properties for visual representations: First, the relationships among all the object instances in a scene are exploited; Second, the spatial locations of objects and image regions are emphasized so that directional navigation signals can be learned. Furthermore, we also develop a pre-training scheme to associate the visual representations with navigation signals, and thus facilitate navigation policy learning. In a nutshell, VTNet embeds object and region features with their location cues as spatial-aware descriptors and then incorporates all the encoded descriptors through attention operations to achieve informative representation for navigation. Given such visual representations, agents are able to explore the correlations between visual observations and navigation actions. For example, an agent would prioritize ``turning right'' over ``turning left'' when the visual representation emphasizes on the right side of activation map. Experiments in the artificial environment AI2-Thor demonstrate that VTNet significantly outperforms state-of-the-art methods in unseen testing environments.",
        "conference": "ICLR",
        "中文标题": "VTNet：用于目标物体导航的视觉Transformer网络",
        "摘要翻译": "目标物体导航旨在基于代理的观察，引导代理朝向目标物体。设计观察场景的有效视觉表示对于确定导航行动至关重要。本文介绍了一种用于导航中学习信息丰富视觉表示的视觉Transformer网络（VTNet）。VTNet是一种高效结构，体现了视觉表示的两个关键属性：首先，利用场景中所有物体实例之间的关系；其次，强调物体和图像区域的空间位置，以便学习方向性导航信号。此外，我们还开发了一种预训练方案，将视觉表示与导航信号关联起来，从而促进导航策略的学习。简而言之，VTNet将物体和区域特征与其位置线索嵌入为空间感知描述符，然后通过注意力操作整合所有编码的描述符，以实现导航的信息丰富表示。给定这样的视觉表示，代理能够探索视觉观察与导航行动之间的相关性。例如，当视觉表示强调激活图的右侧时，代理会优先选择“向右转”而不是“向左转”。在人工环境AI2-Thor中的实验表明，VTNet在未见过的测试环境中显著优于最先进的方法。",
        "领域": "视觉导航、Transformer网络、物体识别",
        "问题": "如何在目标物体导航中设计有效的视觉表示以指导代理行动",
        "动机": "为了解决目标物体导航中视觉表示的有效性问题，提高代理在未知环境中的导航能力",
        "方法": "提出了一种视觉Transformer网络（VTNet），通过利用物体间关系和强调空间位置来学习信息丰富的视觉表示，并开发了预训练方案以关联视觉表示和导航信号",
        "关键词": [
            "视觉Transformer网络",
            "目标物体导航",
            "空间感知描述符",
            "注意力机制",
            "预训练方案"
        ],
        "涉及的技术概念": {
            "视觉Transformer网络": "一种用于学习导航中信息丰富视觉表示的网络结构，通过注意力机制整合物体和区域特征",
            "空间感知描述符": "嵌入物体和区域特征及其位置线索的描述符，用于增强导航信号的方向性学习",
            "注意力机制": "用于整合所有编码的描述符，以实现导航的信息丰富表示，帮助代理理解视觉观察与导航行动之间的关系"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 835,
        "title": "Vulnerability-Aware Poisoning Mechanism for Online RL with Unknown Dynamics",
        "html": "https://iclr.cc//virtual/2021/poster/2665",
        "abstract": "Poisoning attacks on Reinforcement Learning (RL) systems could take advantage of RL algorithm’s vulnerabilities and cause failure of the learning. However, prior works on poisoning RL usually either unrealistically assume the attacker knows the underlying Markov Decision Process (MDP), or directly apply the poisoning methods in supervised learning to RL. In this work, we build a generic poisoning framework for online RL via a comprehensive investigation of heterogeneous poisoning models in RL. Without any prior knowledge of the MDP, we propose a strategic poisoning algorithm called Vulnerability-Aware Adversarial Critic Poison (VA2C-P), which works for on-policy deep RL agents, closing the gap that no poisoning method exists for policy-based RL agents. VA2C-P uses a novel metric, stability radius in RL, that measures the vulnerability of RL algorithms. Experiments on multiple deep RL agents and multiple environments show that our poisoning algorithm successfully prevents agents from learning a good policy or teaches the agents to converge to a target policy, with a limited attacking budget.",
        "conference": "ICLR",
        "中文标题": "针对动态未知的在线强化学习的脆弱性感知毒化机制",
        "摘要翻译": "针对强化学习（RL）系统的毒化攻击可能利用RL算法的脆弱性，导致学习失败。然而，先前关于毒化RL的研究通常要么不切实际地假设攻击者知道底层的马尔可夫决策过程（MDP），要么直接将监督学习中的毒化方法应用于RL。在这项工作中，我们通过对RL中异构毒化模型的全面调查，构建了一个通用的在线RL毒化框架。在没有任何MDP先验知识的情况下，我们提出了一种名为脆弱性感知对抗性批评毒化（VA2C-P）的策略毒化算法，该算法适用于基于策略的深度RL代理，填补了目前没有针对基于策略的RL代理的毒化方法的空白。VA2C-P使用了一种新颖的度量标准——RL中的稳定性半径，来衡量RL算法的脆弱性。在多种深度RL代理和多种环境上的实验表明，我们的毒化算法成功地阻止了代理学习一个好的策略，或者教会代理收敛到一个目标策略，且攻击预算有限。",
        "领域": "强化学习安全、对抗性攻击、深度强化学习",
        "问题": "如何在不知道底层马尔可夫决策过程的情况下，有效地对在线强化学习系统进行毒化攻击。",
        "动机": "填补现有研究中缺乏针对基于策略的强化学习代理的毒化方法的空白，并探索强化学习算法的脆弱性。",
        "方法": "提出了一种名为VA2C-P的策略毒化算法，利用稳定性半径度量RL算法的脆弱性，实现对在线RL的有效毒化攻击。",
        "关键词": [
            "强化学习安全",
            "毒化攻击",
            "对抗性批评毒化",
            "稳定性半径",
            "在线强化学习"
        ],
        "涉及的技术概念": {
            "马尔可夫决策过程（MDP）": "用于描述强化学习环境的数学模型，毒化攻击通常假设攻击者知道MDP，但本研究不依赖此假设。",
            "稳定性半径": "一种新颖的度量标准，用于衡量强化学习算法对毒化攻击的脆弱性。",
            "对抗性批评毒化（VA2C-P）": "一种策略毒化算法，专门设计用于针对基于策略的深度强化学习代理，无需MDP的先验知识。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 836,
        "title": "Wandering within a world: Online contextualized few-shot learning",
        "html": "https://iclr.cc//virtual/2021/poster/2534",
        "abstract": "We aim to bridge the gap between typical human and machine-learning environments by extending the standard framework of few-shot learning to an online, continual setting. In this setting, episodes do not have separate training and testing phases, and instead models are evaluated online while learning novel classes. As in the real world, where the presence of spatiotemporal context helps us retrieve learned skills in the past, our online few-shot learning setting also features an underlying context that changes throughout time. Object classes are correlated within a context and inferring the correct context can lead to better performance. Building upon this setting, we propose a new few-shot learning dataset based on large scale indoor imagery that mimics the visual\nexperience of an agent wandering within a world. Furthermore, we convert popular few-shot learning approaches into online versions and we also propose a new model that can make use of spatiotemporal contextual information from the recent past.",
        "conference": "ICLR",
        "中文标题": "漫游于世界之中：在线情境化小样本学习",
        "摘要翻译": "我们旨在通过将小样本学习的标准框架扩展到一个在线、持续的学习环境中，来弥合典型人类学习环境与机器学习环境之间的差距。在这种环境中，学习过程不再分为独立的训练和测试阶段，而是在学习新类别的同时在线评估模型。正如在现实世界中，时空情境的存在帮助我们回忆起过去学到的技能一样，我们的在线小样本学习环境也具备一个随时间变化的基础情境。对象类别在情境中是相互关联的，推断出正确的情境可以带来更好的性能。基于这一环境，我们提出了一个新的基于大规模室内图像的小样本学习数据集，该数据集模拟了一个在世界中漫游的智能体的视觉体验。此外，我们将流行的小样本学习方法转换为在线版本，并提出了一个新模型，该模型可以利用最近过去的时空情境信息。",
        "领域": "小样本学习",
        "问题": "如何在小样本学习环境中实现在线、持续的学习，并利用时空情境信息提升学习效果",
        "动机": "弥合人类学习环境与机器学习环境之间的差距，通过模拟现实世界中的学习过程，提升模型在新类别学习中的性能",
        "方法": "扩展小样本学习框架至在线持续学习环境，构建基于大规模室内图像的新数据集，开发能够利用时空情境信息的模型",
        "关键词": [
            "在线学习",
            "小样本学习",
            "时空情境",
            "持续学习",
            "室内图像"
        ],
        "涉及的技术概念": {
            "在线小样本学习": "将小样本学习扩展到在线持续学习环境，模型在学习新类别的同时进行在线评估",
            "时空情境": "模拟现实世界中的时空变化，帮助模型更好地理解和学习新类别",
            "持续学习": "模型在不断学习新知识的同时，保持对已学知识的记忆和应用能力"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 837,
        "title": "WaNet - Imperceptible Warping-based Backdoor Attack",
        "html": "https://iclr.cc//virtual/2021/poster/3087",
        "abstract": "With the thriving of deep learning and the widespread practice of using pre-trained networks, backdoor attacks have become an increasing security threat drawing many research interests in recent years. A third-party model can be poisoned in training to work well in normal conditions but behave maliciously when a trigger pattern appears. However, the existing backdoor attacks are all built on noise perturbation triggers, making them noticeable to humans. In this paper, we instead propose using warping-based triggers. The proposed backdoor outperforms the previous methods in a human inspection test by a wide margin, proving its stealthiness. To make such models undetectable by machine defenders, we propose a novel training mode, called the ``noise mode. The trained networks successfully attack and bypass the state-ofthe art defense methods on standard classification datasets, including MNIST, CIFAR-10, GTSRB, and CelebA. Behavior analyses show that our backdoors are transparent to network inspection, further proving this novel attack mechanism's efficiency.",
        "conference": "ICLR",
        "中文标题": "WaNet - 基于不易察觉扭曲的后门攻击",
        "摘要翻译": "随着深度学习的蓬勃发展和预训练网络的广泛使用，后门攻击已成为近年来引起广泛研究兴趣的安全威胁。第三方模型可能在训练过程中被下毒，在正常情况下表现良好，但当触发模式出现时会表现出恶意行为。然而，现有的后门攻击都是基于噪声扰动触发的，这使得它们容易被人类察觉。在本文中，我们提出使用基于扭曲的触发器。所提出的后门在人类检查测试中以较大优势优于先前的方法，证明了其隐蔽性。为了使这种模型不被机器防御者检测到，我们提出了一种新的训练模式，称为“噪声模式”。训练成功的网络在标准分类数据集（包括MNIST、CIFAR-10、GTSRB和CelebA）上成功攻击并绕过了最先进的防御方法。行为分析表明，我们的后门对网络检查是透明的，进一步证明了这种新型攻击机制的有效性。",
        "领域": "深度学习安全、后门攻击、图像分类",
        "问题": "解决现有后门攻击因使用噪声扰动触发而易被人类察觉的问题",
        "动机": "提高后门攻击的隐蔽性，使其不易被人类和机器防御者检测",
        "方法": "提出使用基于扭曲的触发器，并引入一种新的训练模式“噪声模式”以提高攻击的隐蔽性",
        "关键词": [
            "后门攻击",
            "扭曲触发器",
            "隐蔽性",
            "深度学习安全",
            "噪声模式"
        ],
        "涉及的技术概念": {
            "基于扭曲的触发器": "用于替代传统的噪声扰动触发器，提高后门攻击的隐蔽性",
            "噪声模式": "一种新的训练模式，旨在使后门攻击不易被机器防御者检测",
            "网络行为分析": "用于评估后门攻击的隐蔽性和有效性，证明其对网络检查的透明性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 838,
        "title": "Wasserstein-2 Generative Networks",
        "html": "https://iclr.cc//virtual/2021/poster/2664",
        "abstract": "We propose a novel end-to-end non-minimax algorithm for training optimal transport mappings for the quadratic cost (Wasserstein-2 distance). The algorithm uses input convex neural networks and a cycle-consistency regularization to approximate Wasserstein-2 distance. In contrast to popular entropic and quadratic regularizers, cycle-consistency does not introduce bias and scales well to high dimensions. From the theoretical side, we estimate the properties of the generative mapping fitted by our algorithm. From the practical side, we evaluate our algorithm on a wide range of tasks: image-to-image color transfer, latent space optimal transport, image-to-image style transfer, and domain adaptation.",
        "conference": "ICLR",
        "中文标题": "Wasserstein-2生成网络",
        "摘要翻译": "我们提出了一种新颖的端到端非极小极大算法，用于训练二次成本（Wasserstein-2距离）的最优传输映射。该算法使用输入凸神经网络和循环一致性正则化来近似Wasserstein-2距离。与流行的熵和二次正则化器相比，循环一致性不会引入偏差，并且在高维度上表现良好。从理论方面，我们估计了由我们的算法拟合的生成映射的性质。从实践方面，我们在广泛的任务上评估了我们的算法：图像到图像的颜色转移、潜在空间最优传输、图像到图像的风格转移以及领域适应。",
        "领域": "生成模型、图像风格迁移、领域适应",
        "问题": "训练最优传输映射以近似Wasserstein-2距离",
        "动机": "开发一种不引入偏差且在高维度上表现良好的算法，以近似Wasserstein-2距离",
        "方法": "使用输入凸神经网络和循环一致性正则化的端到端非极小极大算法",
        "关键词": [
            "Wasserstein-2距离",
            "最优传输",
            "循环一致性",
            "输入凸神经网络",
            "生成模型"
        ],
        "涉及的技术概念": {
            "输入凸神经网络": "用于构建能够保证输出凸性的神经网络，以便于优化传输映射",
            "循环一致性正则化": "用于确保生成映射的双向一致性，避免偏差并提高在高维度上的表现",
            "Wasserstein-2距离": "用于衡量两个概率分布之间的距离，是本研究中优化的目标"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 839,
        "title": "Wasserstein Embedding for Graph Learning",
        "html": "https://iclr.cc//virtual/2021/poster/3182",
        "abstract": "We present Wasserstein Embedding for Graph Learning (WEGL), a novel and fast framework for embedding entire graphs in a vector space, in which various machine learning models are applicable for graph-level prediction tasks. We leverage new insights on defining similarity between graphs as a function of the similarity between their node embedding distributions. Specifically, we use the Wasserstein distance to measure the dissimilarity between node embeddings of different graphs. Unlike prior work, we avoid pairwise calculation of distances between graphs and reduce the computational complexity from quadratic to linear in the number of graphs. WEGL calculates Monge maps from a reference distribution to each node embedding and, based on these maps, creates a fixed-sized vector representation of the graph. We evaluate our new graph embedding approach on various benchmark graph-property prediction tasks, showing state-of-the-art classification performance while having superior computational efficiency. The code is available at https://github.com/navid-naderi/WEGL.",
        "conference": "ICLR",
        "中文标题": "用于图学习的Wasserstein嵌入",
        "摘要翻译": "我们提出了用于图学习的Wasserstein嵌入（WEGL），这是一个新颖且快速的框架，用于将整个图嵌入到向量空间中，在该空间中，各种机器学习模型可应用于图级别的预测任务。我们利用关于将图之间的相似性定义为它们节点嵌入分布相似性的函数的新见解。具体来说，我们使用Wasserstein距离来测量不同图的节点嵌入之间的不相似性。与之前的工作不同，我们避免了图之间距离的成对计算，并将计算复杂度从图的数量的二次方降低到线性。WEGL计算从参考分布到每个节点嵌入的Monge映射，并基于这些映射创建图的固定大小向量表示。我们在各种基准图属性预测任务上评估了我们新的图嵌入方法，展示了最先进的分类性能，同时具有卓越的计算效率。代码可在https://github.com/navid-naderi/WEGL获取。",
        "领域": "图嵌入、图学习、图属性预测",
        "问题": "如何高效地将整个图嵌入到向量空间中以进行图级别的预测任务",
        "动机": "为了克服现有图嵌入方法中计算复杂度高的问题，提出一种新的基于Wasserstein距离的图嵌入框架",
        "方法": "利用Wasserstein距离测量不同图节点嵌入之间的不相似性，避免成对距离计算，通过Monge映射创建固定大小的图向量表示",
        "关键词": [
            "Wasserstein距离",
            "图嵌入",
            "Monge映射",
            "图学习",
            "计算效率"
        ],
        "涉及的技术概念": {
            "Wasserstein距离": "用于测量不同图的节点嵌入分布之间的不相似性，是WEGL框架的核心度量标准",
            "Monge映射": "从参考分布到每个节点嵌入的映射，用于创建图的固定大小向量表示",
            "图嵌入": "将图结构数据转换为向量空间中的表示，以便于机器学习模型处理"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 840,
        "title": "Watch-And-Help: A Challenge for Social Perception and Human-AI Collaboration",
        "html": "https://iclr.cc//virtual/2021/poster/2798",
        "abstract": "In this paper, we introduce Watch-And-Help (WAH), a challenge for testing social intelligence in agents. In WAH, an AI agent needs to help a human-like agent perform a complex household task efficiently. To succeed, the AI agent needs to i) understand the underlying goal of the task by watching a single demonstration of the human-like agent performing the same task (social perception), and ii) coordinate with the human-like agent to solve the task in an unseen environment as fast as possible (human-AI collaboration). For this challenge, we build VirtualHome-Social, a multi-agent household environment, and provide a benchmark including both planning and learning based baselines. We evaluate the performance of AI agents with the human-like agent as well as and with real humans using objective metrics and subjective user ratings. Experimental results demonstrate that our challenge and virtual environment enable a systematic evaluation on the important aspects of machine social intelligence at scale.",
        "conference": "ICLR",
        "中文标题": "观察与协助：社会感知与人类-AI协作的挑战",
        "摘要翻译": "本文介绍了观察与协助（WAH）挑战，旨在测试代理中的社会智能。在WAH中，AI代理需要协助一个类人代理高效完成复杂的家务任务。为了成功，AI代理需要：i）通过观察类人代理执行相同任务的单次演示来理解任务的基本目标（社会感知），以及ii）与类人代理协调，在未见过的环境中尽可能快地解决任务（人类-AI协作）。为此挑战，我们构建了VirtualHome-Social，一个多代理家务环境，并提供了一个包括基于规划和学习的基线的基准。我们使用客观指标和主观用户评分评估了AI代理与类人代理以及真实人类的性能。实验结果表明，我们的挑战和虚拟环境能够对机器社会智能的重要方面进行大规模系统评估。",
        "领域": "社会智能评估、人类-AI协作、多代理系统",
        "问题": "如何评估和提升AI代理在社会感知和与人类协作方面的能力",
        "动机": "开发一个系统性的方法来评估AI代理在社会智能方面的表现，特别是在理解和协助人类完成复杂任务的能力",
        "方法": "构建了一个多代理家务环境VirtualHome-Social，并设计了观察与协助（WAH）挑战，包括基于规划和学习的基线方法，通过客观和主观评估方法评估AI代理的性能",
        "关键词": [
            "社会智能",
            "人类-AI协作",
            "多代理系统",
            "家务任务",
            "VirtualHome-Social"
        ],
        "涉及的技术概念": {
            "社会感知": "AI代理通过观察理解任务的基本目标，是完成协作任务的前提",
            "人类-AI协作": "AI代理与人类或类人代理在未知环境中协调完成任务，测试AI的社会智能和协作能力",
            "VirtualHome-Social": "一个多代理家务环境，用于模拟和评估AI代理在社会感知和协作任务中的表现"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 841,
        "title": "WaveGrad: Estimating Gradients for Waveform Generation",
        "html": "https://iclr.cc//virtual/2021/poster/3220",
        "abstract": "This paper introduces WaveGrad, a conditional model for waveform generation which estimates gradients of the data density. The model is built on prior work on score matching and diffusion probabilistic models. It starts from a Gaussian white noise signal and iteratively refines the signal via a gradient-based sampler conditioned on the mel-spectrogram.\nWaveGrad offers a natural way to trade inference speed for sample quality by adjusting the number of refinement steps, and bridges the gap between non-autoregressive and autoregressive models in terms of audio quality.\nWe find that it can generate high fidelity audio samples using as few as six iterations.\nExperiments reveal WaveGrad to generate high fidelity audio, outperforming adversarial non-autoregressive baselines and matching a strong likelihood-based autoregressive baseline using fewer sequential operations.  Audio samples are available at https://wavegrad.github.io/.",
        "conference": "ICLR",
        "中文标题": "WaveGrad: 用于波形生成的梯度估计",
        "摘要翻译": "本文介绍了WaveGrad，一种用于波形生成的条件模型，该模型估计数据密度的梯度。该模型基于先前在分数匹配和扩散概率模型上的工作构建。它从高斯白噪声信号开始，通过基于梯度的采样器迭代地细化信号，该采样器以梅尔频谱图为条件。WaveGrad通过调整细化步骤的数量，提供了一种自然的方式来权衡推理速度与样本质量，并在音频质量方面弥合了非自回归模型与自回归模型之间的差距。我们发现，它可以使用少至六次迭代生成高保真音频样本。实验显示，WaveGrad能够生成高保真音频，优于对抗性非自回归基线，并在使用更少的顺序操作时匹配了基于似然的强自回归基线。音频样本可在https://wavegrad.github.io/获取。",
        "领域": "语音合成, 音频信号处理, 生成模型",
        "问题": "如何在波形生成中有效地估计数据密度的梯度，以生成高质量的音频样本。",
        "动机": "探索一种能够通过调整细化步骤数量来权衡推理速度与样本质量，同时弥合非自回归与自回归模型在音频质量上差距的波形生成方法。",
        "方法": "基于分数匹配和扩散概率模型，从高斯白噪声信号出发，通过基于梯度的采样器迭代地细化信号，该采样器以梅尔频谱图为条件。",
        "关键词": [
            "WaveGrad",
            "波形生成",
            "梯度估计",
            "音频质量",
            "非自回归模型"
        ],
        "涉及的技术概念": {
            "分数匹配": "用于估计数据密度的梯度，是构建WaveGrad模型的基础技术之一。",
            "扩散概率模型": "提供了一种从噪声信号逐步生成数据的方法，WaveGrad在此基础上进行迭代细化。",
            "梅尔频谱图": "作为条件信息，指导基于梯度的采样器在波形生成过程中的信号细化。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 842,
        "title": "What are the Statistical Limits of Offline RL with Linear Function Approximation?",
        "html": "https://iclr.cc//virtual/2021/poster/2830",
        "abstract": "Offline reinforcement learning seeks to utilize offline (observational) data to guide the learning of (causal) sequential decision making strategies. The hope is that offline reinforcement learning coupled with function approximation methods (to deal with the curse of dimensionality) can provide a means to help alleviate the excessive sample complexity burden in modern sequential decision making problems. However, the extent to which this broader approach can be effective is not well understood, where the literature largely consists of sufficient conditions.\n\nThis work focuses on the basic question of what are necessary representational and distributional conditions that permit provable sample-efficient offline reinforcement learning. Perhaps surprisingly, our main result shows that even if: i) we have realizability in that the true value function of \\emph{every} policy is linear in a given set of features and 2) our off-policy data has good  coverage over all features (under a strong spectral condition), any algorithm still (information-theoretically) requires a number of offline samples that is exponential in the problem horizon to non-trivially estimate the value of \\emph{any} given policy. Our results highlight that sample-efficient offline policy evaluation is not possible unless significantly stronger conditions hold; such conditions include either having low distribution shift (where the offline data distribution is close to the distribution of the policy to be evaluated) or significantly stronger representational conditions (beyond realizability).",
        "conference": "ICLR",
        "中文标题": "离线强化学习与线性函数逼近的统计极限是什么？",
        "摘要翻译": "离线强化学习旨在利用离线（观察性）数据来指导（因果）序列决策策略的学习。希望通过离线强化学习结合函数逼近方法（以应对维度诅咒），能够提供一种手段来帮助减轻现代序列决策问题中过高的样本复杂性负担。然而，这种更广泛方法的有效性程度尚不明确，现有文献主要由充分条件构成。\n\n本研究聚焦于一个基本问题：哪些必要的表示和分布条件允许可证明的样本高效离线强化学习。或许令人惊讶的是，我们的主要结果表明，即使：i）我们实现了真实性，即每个策略的真实价值函数在给定特征集中是线性的；ii）我们的离策略数据在所有特征上具有良好的覆盖（在强谱条件下），任何算法仍然（在信息理论上）需要指数级于问题范围的离线样本数量来非平凡地估计任何给定策略的价值。我们的结果强调，除非满足显著更强的条件，否则样本高效的离线策略评估是不可能的；这些条件包括要么具有低分布偏移（离线数据分布接近待评估策略的分布），要么满足显著更强的表示条件（超越真实性）。",
        "领域": "离线强化学习、函数逼近、序列决策",
        "问题": "探索离线强化学习在结合线性函数逼近时的统计极限，即在何种条件下可以实现样本高效的策略评估。",
        "动机": "理解离线强化学习结合函数逼近方法的有效性边界，以减轻序列决策问题中的样本复杂性负担。",
        "方法": "通过理论分析，研究离线强化学习在满足特定表示和分布条件下的样本效率极限。",
        "关键词": [
            "离线强化学习",
            "线性函数逼近",
            "样本效率",
            "策略评估",
            "统计极限"
        ],
        "涉及的技术概念": {
            "离线强化学习": "利用离线数据学习序列决策策略，无需与环境交互。",
            "线性函数逼近": "使用线性模型来近似价值函数，以处理高维状态空间。",
            "样本效率": "算法在有限样本下达到良好性能的能力，本研究探讨其理论极限。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 843,
        "title": "What Can You Learn From Your Muscles? Learning Visual Representation from Human Interactions",
        "html": "https://iclr.cc//virtual/2021/poster/2586",
        "abstract": "Learning effective representations of visual data that generalize to a variety of downstream tasks has been a long quest for computer vision. Most representation learning approaches rely solely on visual data such as images or videos. In this paper, we explore a novel approach, where we use human interaction and attention cues to investigate whether we can learn better representations compared to visual-only representations. For this study, we collect a dataset of human interactions capturing body part movements and gaze in their daily lives. Our experiments show that our ``'muscly-supervised' representation that encodes interaction and attention cues outperforms a visual-only state-of-the-art method MoCo (He et al.,2020), on a variety of target tasks: scene classification (semantic), action recognition (temporal), depth estimation (geometric), dynamics prediction (physics) and walkable surface estimation (affordance). Our code and dataset are available at: https://github.com/ehsanik/muscleTorch.",
        "conference": "ICLR",
        "中文标题": "你能从肌肉中学到什么？从人类互动中学习视觉表示",
        "摘要翻译": "学习能够泛化到各种下游任务的视觉数据的有效表示一直是计算机视觉领域的长期追求。大多数表示学习方法仅依赖于图像或视频等视觉数据。在本文中，我们探索了一种新颖的方法，利用人类互动和注意力线索来研究是否能够学习到比仅视觉表示更好的表示。为了这项研究，我们收集了一个人类互动数据集，捕捉他们在日常生活中的身体部位运动和视线。我们的实验表明，我们的“肌肉监督”表示，编码了互动和注意力线索，在多种目标任务上优于仅视觉的最先进方法MoCo（He等人，2020）：场景分类（语义）、动作识别（时间）、深度估计（几何）、动态预测（物理）和可走表面估计（可用性）。我们的代码和数据集可在https://github.com/ehsanik/muscleTorch获取。",
        "领域": "视觉表示学习、人类行为理解、多任务学习",
        "问题": "如何利用人类互动和注意力线索来提升视觉表示学习的效果",
        "动机": "探索超越传统仅依赖视觉数据的方法，通过人类互动和注意力线索来学习更有效的视觉表示",
        "方法": "收集人类互动数据集，利用身体部位运动和视线数据，开发“肌肉监督”表示学习方法",
        "关键词": [
            "视觉表示学习",
            "人类互动",
            "注意力线索",
            "多任务学习",
            "肌肉监督"
        ],
        "涉及的技术概念": {
            "肌肉监督表示": "通过编码人类互动和注意力线索来学习视觉表示的方法",
            "多任务学习": "在多种目标任务上评估表示学习的效果，包括场景分类、动作识别等",
            "注意力线索": "利用人类视线数据来增强视觉表示学习中的关键区域关注"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 844,
        "title": "What Makes Instance Discrimination Good for Transfer Learning?",
        "html": "https://iclr.cc//virtual/2021/poster/2828",
        "abstract": "Contrastive visual pretraining based on the instance discrimination pretext task has made significant progress. Notably, recent work on unsupervised pretraining has shown to surpass the supervised counterpart for finetuning downstream applications such as object detection and segmentation.   It comes as a surprise that image annotations would be better left unused for transfer learning.  In this work, we investigate the following problems: What makes instance discrimination pretraining good for transfer learning? What knowledge is actually learned and transferred from these models?  From this understanding of instance discrimination, how can we better exploit human annotation labels for pretraining? Our findings are threefold. First, what truly matters for the transfer is low-level and mid-level representations, not high-level representations.  Second, the intra-category invariance enforced by the traditional supervised model weakens transferability by increasing task misalignment. Finally, supervised pretraining can be strengthened by following an exemplar-based approach without explicit constraints among the instances within the same category.",
        "conference": "ICLR",
        "中文标题": "实例判别为何有利于迁移学习？",
        "摘要翻译": "基于实例判别预任务的对比视觉预训练已取得显著进展。值得注意的是，最近的无监督预训练工作在微调下游应用（如目标检测和分割）方面已超越有监督的对应方法。令人惊讶的是，图像标注在迁移学习中可能不被使用反而效果更佳。在本工作中，我们研究了以下问题：是什么使得实例判别预训练有利于迁移学习？这些模型实际学习并迁移了哪些知识？基于对实例判别的理解，我们如何更好地利用人工标注标签进行预训练？我们的发现有三点。首先，对迁移真正重要的是低层和中层表示，而非高层表示。其次，传统有监督模型强加的类别内不变性通过增加任务不对齐削弱了可迁移性。最后，有监督预训练可以通过遵循基于范例的方法得到加强，而无需在同一类别内的实例间施加显式约束。",
        "领域": "对比学习",
        "问题": "实例判别预训练为何有利于迁移学习，以及如何更有效地利用人工标注进行预训练",
        "动机": "探索实例判别预训练在迁移学习中的有效性及其背后的原因，以及如何改进有监督预训练方法",
        "方法": "分析实例判别预训练中的表示学习特性，提出基于范例的有监督预训练方法",
        "关键词": [
            "实例判别",
            "迁移学习",
            "对比学习",
            "预训练",
            "表示学习"
        ],
        "涉及的技术概念": {
            "实例判别": "作为对比视觉预训练的基础任务，旨在区分不同的图像实例",
            "迁移学习": "研究如何将预训练模型的知识迁移到下游任务",
            "对比学习": "通过比较正负样本来学习有效表示的方法"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 845,
        "title": "What Matters for On-Policy Deep Actor-Critic Methods? A Large-Scale Study",
        "html": "https://iclr.cc//virtual/2021/poster/2527",
        "abstract": "In recent years, reinforcement learning (RL) has been successfully applied to many different continuous control tasks. While RL algorithms are often conceptually simple, their state-of-the-art implementations take numerous low- and high-level design decisions that strongly affect the performance of the resulting agents. Those choices are usually not extensively discussed in the literature, leading to discrepancy between published descriptions of algorithms and their implementations. This makes it hard to attribute progress in RL and slows down overall progress [Engstrom'20]. As a step towards filling that gap, we implement >50 such ``'choices' in a unified on-policy deep actor-critic framework, allowing us to investigate their impact in a large-scale empirical study. We train over 250'000 agents in five continuous control environments of different complexity and provide insights and practical recommendations for the training of on-policy deep actor-critic RL agents.",
        "conference": "ICLR",
        "中文标题": "什么对基于策略的深度行动者-评论家方法至关重要？一项大规模研究",
        "摘要翻译": "近年来，强化学习（RL）已成功应用于许多不同的连续控制任务。虽然RL算法在概念上通常很简单，但它们的最先进实现涉及许多低层次和高层次的设计决策，这些决策强烈影响最终代理的性能。这些选择在文献中通常没有广泛讨论，导致算法发布描述与其实现之间存在差异。这使得难以归因于RL的进展并减缓了整体进展[Engstrom'20]。作为填补这一空白的一步，我们在一个统一的基于策略的深度行动者-评论家框架中实现了超过50种这样的‘选择’，使我们能够在大规模实证研究中调查它们的影响。我们在五个不同复杂度的连续控制环境中训练了超过250,000个代理，并为基于策略的深度行动者-评论家RL代理的训练提供了见解和实用建议。",
        "领域": "强化学习",
        "问题": "探讨在基于策略的深度行动者-评论家方法中，哪些设计决策对性能有重要影响",
        "动机": "由于现有文献中对RL算法实现中的许多设计决策缺乏详细讨论，导致算法描述与实现之间存在差异，这阻碍了RL领域的进展",
        "方法": "在一个统一的框架中实现超过50种设计选择，并在五个不同复杂度的连续控制环境中训练超过250,000个代理，进行大规模实证研究",
        "关键词": [
            "强化学习",
            "深度行动者-评论家方法",
            "连续控制",
            "设计决策",
            "大规模实证研究"
        ],
        "涉及的技术概念": {
            "基于策略的深度行动者-评论家方法": "一种结合了深度学习的行动者-评论家算法，用于连续控制任务",
            "设计决策": "在实现RL算法时所做的低层次和高层次选择，这些选择影响代理的性能",
            "大规模实证研究": "通过大量实验来验证不同设计决策对RL算法性能的影响"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 846,
        "title": "What Should Not Be Contrastive in Contrastive Learning",
        "html": "https://iclr.cc//virtual/2021/poster/2809",
        "abstract": "Recent self-supervised contrastive methods have been able to produce impressive transferable visual representations by learning to be invariant to different data augmentations. However, these methods implicitly assume a particular set of representational invariances (e.g., invariance to color), and can perform poorly when a downstream task violates this assumption (e.g., distinguishing red vs. yellow cars). We introduce a contrastive learning framework which does not require prior knowledge of specific, task-dependent invariances. Our model learns to capture varying and invariant factors for visual representations by constructing separate embedding spaces, each of which is invariant to all but one augmentation. We use a multi-head network with a shared backbone which captures information across each augmentation and alone outperforms all baselines on downstream tasks. We further find that the concatenation of the invariant and varying spaces performs best across all tasks we investigate, including coarse-grained, fine-grained, and few-shot downstream classification tasks, and various data corruptions.",
        "conference": "ICLR",
        "中文标题": "对比学习中不应对比的内容",
        "摘要翻译": "最近的自监督对比学习方法通过学习对不同数据增强保持不变性，已经能够产生具有出色可迁移性的视觉表示。然而，这些方法隐含地假设了一组特定的表示不变性（例如，对颜色的不变性），当下游任务违反这一假设时（例如，区分红色与黄色汽车），这些方法可能表现不佳。我们引入了一个不需要特定任务依赖性不变性先验知识的对比学习框架。我们的模型通过学习为视觉表示构建独立的嵌入空间来捕捉变化和不变的因素，每个空间对所有增强保持不变性，除了一个。我们使用一个具有共享主干的多头网络，该网络在每个增强中捕获信息，并且在下游任务中单独表现优于所有基线。我们进一步发现，不变和变化空间的串联在我们调查的所有任务中表现最佳，包括粗粒度、细粒度和少样本下游分类任务，以及各种数据损坏。",
        "领域": "自监督学习、对比学习、视觉表示学习",
        "问题": "解决现有对比学习方法在下游任务中因假设特定表示不变性而表现不佳的问题",
        "动机": "开发一个不需要特定任务依赖性不变性先验知识的对比学习框架，以提高模型在下游任务中的泛化能力",
        "方法": "通过构建独立的嵌入空间来捕捉变化和不变的因素，使用具有共享主干的多头网络在每个增强中捕获信息",
        "关键词": [
            "自监督学习",
            "对比学习",
            "视觉表示",
            "数据增强",
            "下游任务"
        ],
        "涉及的技术概念": {
            "对比学习": "一种自监督学习方法，通过学习样本间的相似性和差异性来学习表示",
            "数据增强": "通过对原始数据进行变换生成新的训练样本，以增加数据的多样性",
            "多头网络": "一种网络架构，具有多个输出头，可以同时学习多个任务或表示"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 847,
        "title": "What they do when in doubt: a study of inductive biases in seq2seq learners",
        "html": "https://iclr.cc//virtual/2021/poster/3006",
        "abstract": "Sequence-to-sequence (seq2seq) learners are widely used, but we still have only limited knowledge about what inductive biases shape the way they generalize. We address that by investigating how popular seq2seq learners generalize in tasks that have high ambiguity in the training data. We use four new tasks  to study learners' preferences for memorization, arithmetic, hierarchical, and compositional reasoning. Further, we connect to Solomonoff's theory of induction and propose to use description length as a principled and sensitive measure of inductive biases. In our experimental study, we find that LSTM-based learners can learn to perform counting, addition, and multiplication by a constant from a single training example. Furthermore, Transformer and LSTM-based learners show a bias toward the hierarchical induction over the linear one, while CNN-based learners prefer the opposite. The latter also show a bias toward a compositional generalization over memorization. Finally, across all our experiments, description length proved to be a sensitive measure of inductive biases.",
        "conference": "ICLR",
        "中文标题": "疑惑时的行为：序列到序列学习器中归纳偏好的研究",
        "摘要翻译": "序列到序列（seq2seq）学习器被广泛使用，但我们对于塑造它们泛化方式的归纳偏好仍知之甚少。我们通过研究流行的seq2seq学习器在训练数据具有高度模糊性的任务中如何泛化来解决这一问题。我们使用四个新任务来研究学习器对记忆、算术、层次和组合推理的偏好。此外，我们联系所罗门诺夫的归纳理论，并提出使用描述长度作为归纳偏好的原则性和敏感性度量。在我们的实验研究中，我们发现基于LSTM的学习器可以从单个训练示例中学习执行计数、加法和乘以常数的操作。此外，基于Transformer和LSTM的学习器显示出对层次归纳的偏好超过线性归纳，而基于CNN的学习器则偏好相反。后者还显示出对组合泛化的偏好超过记忆。最后，在我们所有的实验中，描述长度被证明是归纳偏好的敏感性度量。",
        "领域": "自然语言处理与视觉结合、序列模型、机器学习理论",
        "问题": "研究序列到序列学习器在训练数据模糊情况下的泛化行为及其归纳偏好。",
        "动机": "探索和量化序列到序列学习器的归纳偏好，以更好地理解其泛化机制。",
        "方法": "通过设计四个新任务来研究学习器的偏好，并使用描述长度作为归纳偏好的度量标准。",
        "关键词": [
            "序列到序列学习",
            "归纳偏好",
            "描述长度",
            "LSTM",
            "Transformer"
        ],
        "涉及的技术概念": {
            "序列到序列学习": "一种将输入序列转换为输出序列的模型架构，广泛应用于机器翻译等任务。",
            "归纳偏好": "学习算法在未见数据上泛化时的偏好或倾向，影响模型的泛化能力。",
            "描述长度": "基于所罗门诺夫的归纳理论，用于量化归纳偏好的原则性度量，反映模型的泛化偏好。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 848,
        "title": "When Do Curricula Work?",
        "html": "https://iclr.cc//virtual/2021/poster/2744",
        "abstract": "Inspired by human learning, researchers have proposed ordering examples during training based on their difficulty. Both curriculum learning, exposing a network to easier examples early in training, and anti-curriculum learning, showing the most difficult examples first, have been suggested as improvements to the standard i.i.d. training. In this work, we set out to investigate the relative benefits of ordered learning. We first investigate the implicit curricula resulting from architectural and optimization bias and find that samples are learned in a highly consistent order. Next, to quantify the benefit of explicit curricula, we conduct extensive experiments over thousands of orderings spanning three kinds of learning: curriculum, anti-curriculum, and random-curriculum -- in which the size of the training dataset is dynamically increased over time, but the examples are randomly ordered. We find that for standard benchmark datasets, curricula have only marginal benefits, and that randomly ordered samples perform as well or better than curricula and anti-curricula, suggesting that any benefit is entirely due to the dynamic training set size. Inspired by common use cases of curriculum learning in practice, we investigate the role of limited training time budget and noisy data in the success of curriculum learning. Our experiments demonstrate that curriculum, but not anti-curriculum or random ordering can indeed improve the performance either with limited training time budget or in the existence of noisy data.",
        "conference": "ICLR",
        "中文标题": "课程学习何时有效？",
        "摘要翻译": "受到人类学习的启发，研究人员提出了在训练过程中根据样本难度排序的方法。课程学习（在训练早期向网络展示较容易的样本）和反课程学习（首先展示最难的样本）都被提出作为对标准独立同分布训练的改进。在这项工作中，我们着手研究有序学习的相对优势。我们首先调查了由架构和优化偏差导致的隐式课程，发现样本是以高度一致的顺序被学习的。接着，为了量化显式课程的益处，我们进行了广泛的实验，涵盖了数千种排序方式，包括三种学习类型：课程、反课程和随机课程——其中训练数据集的大小随时间动态增加，但样本是随机排序的。我们发现，对于标准基准数据集，课程学习仅有边际效益，随机排序的样本表现与课程和反课程相当或更好，这表明任何益处完全归因于动态训练集大小。受到实践中课程学习常见用例的启发，我们调查了有限训练时间预算和噪声数据在课程学习成功中的作用。我们的实验证明，课程学习（而非反课程或随机排序）确实可以在有限的训练时间预算内或在存在噪声数据的情况下提高性能。",
        "领域": "深度学习优化策略",
        "问题": "研究课程学习（包括课程、反课程和随机课程）在深度学习训练中的实际效果和适用条件。",
        "动机": "探索有序学习（如课程学习和反课程学习）是否真的能比标准独立同分布训练带来更好的模型性能，以及在什么条件下这些方法最为有效。",
        "方法": "通过分析隐式课程的影响和进行广泛的实验比较，包括课程、反课程和随机课程学习的效果，特别是在有限训练时间预算和噪声数据条件下的表现。",
        "关键词": [
            "课程学习",
            "反课程学习",
            "随机课程学习",
            "深度学习优化",
            "训练策略"
        ],
        "涉及的技术概念": {
            "课程学习": "在训练过程中按照从易到难的顺序展示样本，旨在模仿人类学习过程，提高学习效率和模型性能。",
            "反课程学习": "与课程学习相反，首先展示最难的样本，旨在测试模型在极端条件下的学习能力。",
            "随机课程学习": "动态增加训练数据集的大小，但样本顺序随机，用于比较有序学习的效果是否真的优于随机排序。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 849,
        "title": "When does preconditioning help or hurt generalization?",
        "html": "https://iclr.cc//virtual/2021/poster/3104",
        "abstract": "While second order optimizers such as natural gradient descent (NGD) often speed up optimization, their effect on generalization has been called into question. This work presents a more nuanced view on how the \\textit{implicit bias} of optimizers affects the comparison of generalization properties. \nWe provide an exact asymptotic bias-variance decomposition of the generalization error of preconditioned ridgeless regression in the overparameterized regime, and consider the inverse population Fisher information matrix (used in NGD) as a particular example. We determine the optimal preconditioner $\\boldsymbol{P}$ for both the bias and variance, and find that the relative generalization performance of different optimizers depends on label noise and ``shape'' of the signal (true parameters): when the labels are noisy, the model is misspecified, or the signal is misaligned with the features, NGD can achieve lower risk; conversely, GD generalizes better under clean labels, a well-specified model, or aligned signal. \nBased on this analysis, we discuss several approaches to manage the bias-variance tradeoff, and the potential benefit of interpolating between first- and second-order updates. We then extend our analysis to regression in the reproducing kernel Hilbert space and demonstrate that preconditioning can lead to more efficient decrease in the population risk. Lastly, we empirically compare the generalization error of first- and second-order optimizers in neural network experiments, and observe robust trends matching our theoretical analysis. ",
        "conference": "ICLR",
        "中文标题": "预条件何时有助于或损害泛化？",
        "摘要翻译": "虽然如自然梯度下降（NGD）这样的二阶优化器常常能加速优化过程，但它们对泛化的影响却受到了质疑。本研究提出了一个更为细致的视角，探讨了优化器的隐式偏差如何影响泛化性能的比较。我们提供了过参数化条件下预条件无岭回归泛化误差的精确渐近偏差-方差分解，并以NGD中使用的逆总体Fisher信息矩阵作为特例。我们确定了偏差和方差的最优预条件矩阵P，并发现不同优化器的相对泛化性能依赖于标签噪声和信号（真实参数）的“形状”：当标签有噪声、模型设定错误或信号与特征不对齐时，NGD能够实现更低的风险；相反，在标签干净、模型设定正确或信号对齐的情况下，GD的泛化性能更好。基于这一分析，我们讨论了几种管理偏差-方差权衡的方法，以及在一阶和二阶更新之间插值的潜在好处。随后，我们将分析扩展到再生核希尔伯特空间中的回归，并证明预条件可以导致总体风险更有效的下降。最后，我们在神经网络实验中实证比较了一阶和二阶优化器的泛化误差，并观察到了与我们的理论分析相匹配的稳健趋势。",
        "领域": "优化算法、机器学习理论、深度学习",
        "问题": "探讨预条件优化器在何种情况下有助于或损害模型的泛化能力",
        "动机": "理解不同优化器对模型泛化性能的影响，特别是在不同数据条件下",
        "方法": "通过偏差-方差分解分析预条件优化器的泛化性能，并在理论和实验上比较一阶和二阶优化器",
        "关键词": [
            "自然梯度下降",
            "泛化误差",
            "偏差-方差分解",
            "预条件优化",
            "再生核希尔伯特空间"
        ],
        "涉及的技术概念": {
            "隐式偏差": "优化器在训练过程中对模型参数选择的偏好，影响模型的泛化性能",
            "偏差-方差分解": "将泛化误差分解为偏差和方差两部分，用于分析不同优化器在不同条件下的表现",
            "再生核希尔伯特空间": "一种函数空间，用于扩展分析到更一般的回归问题，证明预条件优化在降低总体风险上的有效性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 850,
        "title": "When Optimizing  $f$-Divergence is Robust with Label Noise",
        "html": "https://iclr.cc//virtual/2021/poster/2763",
        "abstract": "We show when maximizing a properly defined $f$-divergence measure with respect to a classifier's predictions and the supervised labels is robust with label noise. Leveraging its variational form, we derive a nice decoupling property for a family of $f$-divergence measures when label noise presents, where the divergence is shown to be a linear combination of the variational difference defined on the clean distribution and a bias term introduced due to the noise. The above derivation helps us analyze the robustness of different $f$-divergence functions. With established robustness, this family of $f$-divergence functions arises as useful metrics for the problem of learning with noisy labels, which do not require the specification of the labels' noise rate. When they are possibly not robust, we propose fixes to make them so. In addition to the analytical results, we present thorough experimental evidence. Our code is available at https://github.com/UCSC-REAL/Robust-f-divergence-measures.",
        "conference": "ICLR",
        "中文标题": "优化$f$-散度在标签噪声下的鲁棒性研究",
        "摘要翻译": "我们展示了当相对于分类器的预测和监督标签最大化一个正确定义的$f$-散度度量时，其对标签噪声具有鲁棒性。利用其变分形式，我们推导出在存在标签噪声时，一系列$f$-散度量度的良好解耦性质，其中散度被证明是定义在清洁分布上的变分差异和由于噪声引入的偏差项的线性组合。上述推导帮助我们分析了不同$f$-散度函数的鲁棒性。在确立了鲁棒性之后，这一系列的$f$-散度函数作为学习带有噪声标签问题的有用度量出现，这些度量不需要指定标签的噪声率。当它们可能不具备鲁棒性时，我们提出了修正方法以使其具备鲁棒性。除了分析结果外，我们还提供了详尽的实验证据。我们的代码可在https://github.com/UCSC-REAL/Robust-f-divergence-measures获取。",
        "领域": "深度学习、噪声标签学习、鲁棒性优化",
        "问题": "研究在存在标签噪声的情况下，如何通过优化$f$-散度来提高分类器的鲁棒性。",
        "动机": "为了解决在现实世界数据集中普遍存在的标签噪声问题，提高模型在噪声环境下的性能和稳定性。",
        "方法": "通过理论分析和实验验证，研究了一系列$f$-散度函数在标签噪声下的鲁棒性，并提出了相应的修正方法。",
        "关键词": [
            "$f$-散度",
            "标签噪声",
            "鲁棒性优化",
            "变分形式",
            "噪声率"
        ],
        "涉及的技术概念": {
            "$f$-散度": "用于衡量两个概率分布之间差异的度量，本文中用于分析在标签噪声下的鲁棒性。",
            "变分形式": "通过变分方法将$f$-散度表达为清洁分布和噪声引入偏差的线性组合，便于分析鲁棒性。",
            "噪声率": "标签中错误标签的比例，本文提出的方法不需要预先指定噪声率。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 851,
        "title": "Why Are Convolutional Nets More Sample-Efficient than Fully-Connected Nets?",
        "html": "https://iclr.cc//virtual/2021/poster/3299",
        "abstract": "Convolutional neural networks often dominate fully-connected counterparts in generalization performance, especially on image classification tasks. This is often explained in terms of \\textquotedblleft better inductive bias.\\textquotedblright\\  However, this has not been made mathematically rigorous, and the hurdle is that the sufficiently wide fully-connected net can always simulate the convolutional net. Thus the training algorithm plays a role. The current work describes a natural task on which a provable sample complexity gap can be shown, for standard training algorithms. We construct a single natural distribution on $\\mathbb{R}^d\\times\\{\\pm 1\\}$ on which any orthogonal-invariant algorithm (i.e. fully-connected networks trained with most gradient-based methods from gaussian initialization) requires $\\Omega(d^2)$ samples to generalize while $O(1)$ samples suffice for convolutional architectures. Furthermore, we demonstrate a single target function, learning which on all possible distributions leads to an $O(1)$ vs $\\Omega(d^2/\\varepsilon)$ gap. The proof relies on the fact that SGD on fully-connected network is orthogonal equivariant. Similar results are achieved for $\\ell_2$ regression and adaptive training algorithms, e.g. Adam and AdaGrad, which are only permutation equivariant.",
        "conference": "ICLR",
        "中文标题": "为什么卷积网络比全连接网络更具样本效率？",
        "摘要翻译": "卷积神经网络在泛化性能上通常优于全连接网络，尤其是在图像分类任务中。这一现象常被归因于“更好的归纳偏置”。然而，这一观点尚未得到数学上的严格证明，难点在于足够宽的全连接网络总能模拟卷积网络。因此，训练算法在其中扮演了重要角色。本研究描述了一个自然任务，在该任务上，对于标准的训练算法，可以证明样本复杂度存在差距。我们构建了一个在ℝᵈ×{±1}上的单一自然分布，对于任何正交不变算法（即从高斯初始化开始，使用大多数基于梯度的方法训练的全连接网络），需要Ω(d²)样本才能泛化，而卷积架构仅需O(1)样本即可。此外，我们展示了一个单一目标函数，在所有可能的分布上学习该函数会导致O(1)与Ω(d²/ε)的差距。证明依赖于全连接网络上的随机梯度下降是正交等变的这一事实。对于ℓ₂回归和自适应训练算法（如Adam和AdaGrad），也实现了类似的结果，这些算法仅是置换等变的。",
        "领域": "深度学习理论、图像分类、神经网络架构",
        "问题": "解释和证明卷积神经网络相比全连接网络在样本效率上的优势",
        "动机": "为了数学上严格证明卷积神经网络在样本效率上优于全连接网络的原因，特别是在图像分类任务中",
        "方法": "通过构建特定的数据分布和目标函数，比较卷积架构和全连接网络在不同训练算法下的样本复杂度",
        "关键词": [
            "样本效率",
            "卷积神经网络",
            "全连接网络",
            "训练算法",
            "正交不变性"
        ],
        "涉及的技术概念": {
            "归纳偏置": "卷积神经网络中内置的对空间局部性和平移不变性的偏好，有助于提高样本效率",
            "正交不变算法": "指那些在输入数据的正交变换下保持不变的训练算法，如全连接网络的标准训练方法",
            "样本复杂度": "指学习算法为了达到一定的泛化性能所需的最小样本数量，本研究展示了卷积网络和全连接网络在此方面的差异"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 852,
        "title": "Why resampling outperforms reweighting for correcting sampling bias with stochastic gradients",
        "html": "https://iclr.cc//virtual/2021/poster/3258",
        "abstract": "A data set sampled from a certain population is biased if the subgroups of the population are sampled at proportions that are significantly different from their underlying proportions. Training machine learning models on biased data sets requires correction techniques to compensate for the bias. We consider two commonly-used techniques, resampling and reweighting, that rebalance the proportions of the subgroups to maintain the desired objective function. Though statistically equivalent, it has been observed that resampling outperforms reweighting when combined with stochastic gradient algorithms. By analyzing illustrative examples, we explain the reason behind this phenomenon using tools from dynamical stability and stochastic asymptotics. We also present experiments from regression, classification, and off-policy prediction to demonstrate that this is a general phenomenon. We argue that it is imperative to consider the objective function design and the optimization algorithm together while addressing the sampling bias.\n",
        "conference": "ICLR",
        "中文标题": "为何在纠正采样偏差时重采样优于重新加权——基于随机梯度的分析",
        "摘要翻译": "从某一总体中采样的数据集如果其子群的采样比例与它们的基础比例显著不同，则该数据集是有偏差的。在偏差数据集上训练机器学习模型需要采用校正技术来补偿偏差。我们考虑了两种常用技术：重采样和重新加权，它们重新平衡子群的比例以维持目标函数。尽管在统计上是等效的，但观察到当与随机梯度算法结合使用时，重采样优于重新加权。通过分析示例，我们使用动态稳定性和随机渐近工具解释了这一现象背后的原因。我们还展示了来自回归、分类和离策略预测的实验，以证明这是一个普遍现象。我们认为，在解决采样偏差时，必须同时考虑目标函数的设计和优化算法。",
        "领域": "机器学习偏差校正、随机梯度优化、数据不平衡处理",
        "问题": "在存在采样偏差的数据集上训练机器学习模型时，如何有效校正偏差以维持目标函数的性能",
        "动机": "探索为何在结合随机梯度算法时，重采样技术比重新加权技术更能有效纠正采样偏差",
        "方法": "通过动态稳定性和随机渐近工具分析重采样与重新加权在随机梯度算法中的表现差异，并通过回归、分类和离策略预测实验验证",
        "关键词": [
            "采样偏差",
            "重采样",
            "重新加权",
            "随机梯度",
            "动态稳定性"
        ],
        "涉及的技术概念": {
            "重采样": "通过调整数据集中子群的采样比例来纠正偏差，以维持目标函数的性能",
            "重新加权": "通过调整损失函数中不同子群的权重来纠正偏差，以维持目标函数的性能",
            "随机梯度算法": "一种优化算法，用于在机器学习模型的训练过程中逐步调整模型参数，以最小化损失函数"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 853,
        "title": "Winning the L2RPN Challenge: Power Grid Management via Semi-Markov Afterstate Actor-Critic",
        "html": "https://iclr.cc//virtual/2021/poster/3003",
        "abstract": "Safe and reliable electricity transmission in power grids is crucial for modern society. It is thus quite natural that there has been a growing interest in the automatic management of power grids, exempliﬁed by the Learning to Run a Power Network Challenge (L2RPN), modeling the problem as a reinforcement learning (RL) task. However, it is highly challenging to manage a real-world scale power grid, mostly due to the massive scale of its state and action space. In this paper, we present an off-policy actor-critic approach that effectively tackles the unique challenges in power grid management by RL, adopting the hierarchical policy together with the afterstate representation. Our agent ranked ﬁrst in the latest challenge (L2RPN WCCI 2020), being able to avoid disastrous situations while maintaining the highest level of operational efﬁciency in every test scenarios. This paper provides a formal description of the algorithmic aspect of our approach, as well as further experimental studies on diverse power grids.",
        "conference": "ICLR",
        "中文标题": "赢得L2RPN挑战：通过半马尔可夫后状态演员-评论家实现电网管理",
        "摘要翻译": "电网的安全可靠输电对现代社会至关重要。因此，对电网自动管理的兴趣日益增长，这以“学习运行电力网络挑战”（L2RPN）为例，将问题建模为强化学习（RL）任务。然而，管理现实世界规模的电网极具挑战性，主要是由于其状态和行动空间的巨大规模。在本文中，我们提出了一种离策略演员-评论家方法，通过采用分层策略和后状态表示，有效解决了电网管理中RL面临的独特挑战。我们的代理在最新挑战（L2RPN WCCI 2020）中排名第一，能够在每个测试场景中避免灾难性情况，同时保持最高水平的运行效率。本文提供了我们方法算法方面的正式描述，以及对多样化电网的进一步实验研究。",
        "领域": "强化学习应用、电网管理、自动控制系统",
        "问题": "如何通过强化学习有效管理大规模电网的状态和行动空间，以确保安全可靠的电力传输。",
        "动机": "解决现实世界规模电网管理中由于状态和行动空间巨大带来的挑战，提高电网的运行效率和安全性。",
        "方法": "采用离策略演员-评论家方法，结合分层策略和后状态表示，有效管理电网。",
        "关键词": [
            "强化学习",
            "电网管理",
            "演员-评论家",
            "后状态表示",
            "分层策略"
        ],
        "涉及的技术概念": {
            "离策略演员-评论家": "一种强化学习方法，通过分离行为策略和目标策略，提高学习效率和稳定性。",
            "分层策略": "将复杂的决策过程分解为多个层次，以简化管理和提高效率。",
            "后状态表示": "在动作执行后立即捕获环境状态的表示，有助于更准确地评估动作的效果。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 854,
        "title": "Witches' Brew: Industrial Scale Data Poisoning via Gradient Matching",
        "html": "https://iclr.cc//virtual/2021/poster/2561",
        "abstract": "Data Poisoning attacks modify training data to maliciously control a model trained on such data.\nIn this work, we focus on targeted poisoning attacks which cause a reclassification of an unmodified test image and as such breach model integrity. We consider a\nparticularly malicious poisoning attack that is both ``from scratch' and ``clean label', meaning we analyze an attack that successfully works against new, randomly initialized models, and is nearly imperceptible to humans, all while perturbing only a small fraction of the training data. \nPrevious poisoning attacks against deep neural networks in this setting have been limited in scope and success, working only in simplified settings or being prohibitively expensive for large datasets.\nThe central mechanism of the new attack is matching the gradient direction of malicious examples. We analyze why this works, supplement with practical considerations. and show its threat to real-world practitioners, finding that it is the first poisoning method to cause targeted misclassification in modern deep networks trained from scratch on a full-sized, poisoned ImageNet dataset.\nFinally we demonstrate the limitations of existing defensive strategies against such an attack, concluding that data poisoning is a credible threat, even for large-scale deep learning systems.",
        "conference": "ICLR",
        "中文标题": "巫婆的毒汤：通过梯度匹配实现工业规模的数据投毒",
        "摘要翻译": "数据投毒攻击通过修改训练数据来恶意控制基于这些数据训练的模型。在这项工作中，我们专注于有针对性的投毒攻击，这种攻击会导致未经修改的测试图像被重新分类，从而破坏模型的完整性。我们考虑了一种特别恶意的投毒攻击，它既是‘从头开始’的，也是‘干净标签’的，这意味着我们分析了一种攻击，它能够成功地对抗新的、随机初始化的模型，并且对人类几乎不可察觉，同时仅扰动一小部分训练数据。之前针对深度神经网络在这种情况下的投毒攻击在范围和成功上都有限，仅在简化设置中工作或对大型数据集来说成本过高。新攻击的核心机制是匹配恶意示例的梯度方向。我们分析了这种方法为何有效，补充了实际考虑，并展示了它对现实世界从业者的威胁，发现这是第一种在现代深度网络中从头开始训练于全尺寸、被投毒的ImageNet数据集上导致有针对性的错误分类的投毒方法。最后，我们展示了现有防御策略对此类攻击的局限性，得出结论：数据投毒是一个可信的威胁，即使对于大规模深度学习系统也是如此。",
        "领域": "深度学习安全、对抗性攻击、模型完整性保护",
        "问题": "如何通过数据投毒攻击恶意控制模型，导致特定测试图像被错误分类。",
        "动机": "探索一种新型的数据投毒攻击方法，该方法能够在现代深度网络中实现有针对性的错误分类，同时保持对人类几乎不可察觉和对大型数据集的高效性。",
        "方法": "通过匹配恶意示例的梯度方向，实现对模型训练过程的干扰，导致特定测试图像被错误分类。",
        "关键词": [
            "数据投毒",
            "梯度匹配",
            "对抗性攻击",
            "模型完整性",
            "ImageNet"
        ],
        "涉及的技术概念": {
            "梯度匹配": "攻击者通过调整恶意数据的梯度方向，使其与目标错误分类的梯度方向一致，从而在模型训练过程中引导模型学习错误的分类决策。",
            "干净标签攻击": "一种投毒攻击方法，攻击者在不改变数据标签的情况下，通过细微修改数据本身来影响模型训练，使得攻击对人类观察者几乎不可察觉。",
            "从头开始攻击": "指攻击方法能够成功地对抗新的、随机初始化的模型，不依赖于模型预训练阶段的知识或特定初始化状态。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 855,
        "title": "WrapNet:  Neural Net Inference with Ultra-Low-Precision Arithmetic",
        "html": "https://iclr.cc//virtual/2021/poster/2533",
        "abstract": "Low-precision neural networks represent both weights and activations with few bits, drastically reducing the cost of multiplications. Meanwhile, these products are accumulated using high-precision (typically 32-bit) additions.  Additions dominate the arithmetic complexity of inference in quantized (e.g., binary) nets, and high precision is needed to avoid overflow. To further optimize inference, we propose WrapNet, an architecture that adapts neural networks to use low-precision (8-bit) additions while achieving classification accuracy comparable to their 32-bit counterparts. We achieve resilience to low-precision accumulation by inserting a cyclic activation layer that makes results invariant to overflow. We demonstrate the efficacy of our approach using both software and hardware platforms.",
        "conference": "ICLR",
        "中文标题": "WrapNet：使用超低精度算术进行神经网络推理",
        "摘要翻译": "低精度神经网络使用少量比特表示权重和激活，大幅降低了乘法的成本。同时，这些乘积使用高精度（通常是32位）加法进行累加。在量化（例如，二进制）网络中，加法主导了推理的算术复杂度，并且需要高精度以避免溢出。为了进一步优化推理，我们提出了WrapNet，一种架构，使神经网络适应使用低精度（8位）加法，同时实现与32位对应物相当的分类准确度。我们通过插入一个循环激活层来实现对低精度累加的弹性，该层使结果对溢出不敏感。我们使用软件和硬件平台证明了我们方法的有效性。",
        "领域": "神经网络优化、量化神经网络、硬件加速",
        "问题": "如何在保持神经网络分类准确度的同时，使用低精度加法进一步优化推理过程",
        "动机": "减少神经网络推理过程中的计算复杂度和资源消耗，同时保持高准确度",
        "方法": "提出WrapNet架构，通过引入循环激活层使神经网络适应低精度加法，避免溢出影响",
        "关键词": [
            "低精度算术",
            "神经网络推理",
            "循环激活层",
            "量化网络",
            "硬件加速"
        ],
        "涉及的技术概念": {
            "低精度算术": "在神经网络推理中使用较少比特表示数值，以减少计算复杂度和资源消耗",
            "循环激活层": "一种特殊的网络层，使网络对低精度累加过程中的溢出不敏感，保持结果的准确性",
            "量化网络": "通过减少权重和激活的比特数来优化神经网络，降低计算和存储需求"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 856,
        "title": "X2T: Training an X-to-Text Typing Interface with Online Learning from User Feedback",
        "html": "https://iclr.cc//virtual/2021/poster/3231",
        "abstract": "We aim to help users communicate their intent to machines using flexible, adaptive interfaces that translate arbitrary user input into desired actions. In this work, we focus on assistive typing applications in which a user cannot operate a keyboard, but can instead supply other inputs, such as webcam images that capture eye gaze or neural activity measured by a brain implant. Standard methods train a model on a fixed dataset of user inputs, then deploy a static interface that does not learn from its mistakes; in part, because extracting an error signal from user behavior can be challenging. We investigate a simple idea that would enable such interfaces to improve over time, with minimal additional effort from the user: online learning from user feedback on the accuracy of the interface's actions. In the typing domain, we leverage backspaces as feedback that the interface did not perform the desired action. We propose an algorithm called x-to-text (X2T) that trains a predictive model of this feedback signal, and uses this model to fine-tune any existing, default interface for translating user input into actions that select words or characters. We evaluate X2T through a small-scale online user study with 12 participants who type sentences by gazing at their desired words, a large-scale observational study on handwriting samples from 60 users, and a pilot study with one participant using an electrocorticography-based brain-computer interface. The results show that X2T learns to outperform a non-adaptive default interface, stimulates user co-adaptation to the interface, personalizes the interface to individual users, and can leverage offline data collected from the default interface to improve its initial performance and accelerate online learning.",
        "conference": "ICLR",
        "中文标题": "X2T：通过用户反馈的在线学习训练X到文本的输入界面",
        "摘要翻译": "我们的目标是帮助用户通过灵活、自适应的界面与机器沟通其意图，这些界面能够将任意的用户输入转化为期望的动作。在这项工作中，我们专注于辅助输入应用，其中用户无法操作键盘，但可以提供其他输入，如捕捉眼动的网络摄像头图像或通过脑植入物测量的神经活动。标准方法在固定的用户输入数据集上训练模型，然后部署一个静态界面，该界面不会从错误中学习；部分原因是从用户行为中提取错误信号可能具有挑战性。我们研究了一个简单的想法，使得这样的界面能够随着时间的推移而改进，用户只需付出最少的额外努力：通过用户对界面动作准确性的反馈进行在线学习。在输入领域，我们利用退格键作为反馈，表明界面未执行期望的动作。我们提出了一种名为x-to-text（X2T）的算法，该算法训练一个预测这种反馈信号的模型，并使用该模型对任何现有的、默认的界面进行微调，以将用户输入转化为选择单词或字符的动作。我们通过一个包含12名参与者的小规模在线用户研究（参与者通过凝视他们想要的单词来输入句子）、一个对60名用户手写样本的大规模观察性研究，以及一个使用基于电皮层图的脑机接口的试点研究（一名参与者）来评估X2T。结果表明，X2T学会了超越非自适应的默认界面，刺激用户与界面的共同适应，将界面个性化给个体用户，并可以利用从默认界面收集的离线数据来提高其初始性能和加速在线学习。",
        "领域": "脑机接口、眼动追踪、自适应界面",
        "问题": "如何使无法使用传统键盘的用户通过其他输入方式（如眼动或脑活动）有效输入文本，并让输入界面能够从用户反馈中学习以持续改进。",
        "动机": "开发一种能够从用户反馈中学习并不断改进的自适应输入界面，以帮助无法使用传统键盘的用户更有效地与机器沟通。",
        "方法": "提出X2T算法，通过在线学习用户反馈（如退格键操作）来训练预测模型，并利用该模型对现有输入界面进行微调，实现个性化适配和性能提升。",
        "关键词": [
            "自适应界面",
            "在线学习",
            "脑机接口",
            "眼动追踪",
            "用户反馈"
        ],
        "涉及的技术概念": {
            "在线学习": "算法能够实时从用户反馈中学习，不断调整和优化输入界面的性能。",
            "反馈信号预测模型": "通过预测用户反馈（如退格键操作）来识别界面未满足用户意图的情况，进而指导界面的调整。",
            "个性化适配": "算法能够根据个体用户的使用习惯和反馈，定制化调整输入界面，提高输入效率和用户体验。"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 857,
        "title": "You Only Need Adversarial Supervision for Semantic Image Synthesis",
        "html": "https://iclr.cc//virtual/2021/poster/2686",
        "abstract": "Despite their recent successes, GAN models for semantic image synthesis still suffer from poor image quality when trained with only adversarial supervision. Historically, additionally employing the VGG-based perceptual loss has helped to overcome this issue, significantly improving the synthesis quality, but at the same time limiting the progress of GAN models for semantic image synthesis. In this work, we propose a novel, simplified GAN model, which needs only adversarial supervision to achieve high quality results. We re-design the discriminator as a semantic segmentation network, directly using the given semantic label maps as the ground truth for training. By providing stronger supervision to the discriminator as well as to the generator through spatially- and semantically-aware discriminator feedback, we are able to synthesize images of higher fidelity with better alignment to their input label maps, making the use of the perceptual loss superfluous. Moreover, we enable high-quality multi-modal image synthesis through global and local sampling of a 3D noise tensor injected into the generator, which allows complete or partial image change. We show that images synthesized by our model are more diverse and follow the color and texture distributions of real images more closely. We achieve an average improvement of $6$ FID and $5$ mIoU points over the state of the art across different datasets using only adversarial supervision.",
        "conference": "ICLR",
        "中文标题": "仅需对抗监督的语义图像合成",
        "摘要翻译": "尽管最近取得了成功，但仅通过对抗监督训练的GAN模型在语义图像合成方面仍然存在图像质量不佳的问题。历史上，额外使用基于VGG的感知损失有助于克服这一问题，显著提高了合成质量，但同时也限制了语义图像合成GAN模型的进步。在这项工作中，我们提出了一种新颖、简化的GAN模型，仅需对抗监督即可实现高质量结果。我们重新设计了判别器作为一个语义分割网络，直接使用给定的语义标签图作为训练的真实标签。通过为判别器以及通过空间和语义感知的判别器反馈为生成器提供更强的监督，我们能够合成具有更高保真度且与输入标签图更好对齐的图像，使得感知损失的使用变得多余。此外，我们通过全局和局部采样注入生成器的3D噪声张量，实现了高质量的多模态图像合成，这允许完全或部分改变图像。我们展示了由我们的模型合成的图像更加多样化，并且更紧密地跟随真实图像的颜色和纹理分布。仅使用对抗监督，我们在不同数据集上实现了平均6 FID和5 mIoU点的改进，超越了现有技术。",
        "领域": "语义图像合成",
        "问题": "GAN模型在仅使用对抗监督训练时，语义图像合成的质量不佳",
        "动机": "克服仅使用对抗监督训练的GAN模型在语义图像合成中的质量限制，避免使用感知损失",
        "方法": "重新设计判别器为语义分割网络，直接使用语义标签图作为真实标签，通过空间和语义感知的判别器反馈提高合成质量",
        "关键词": [
            "语义图像合成",
            "对抗监督",
            "GAN模型",
            "语义分割网络",
            "多模态图像合成"
        ],
        "涉及的技术概念": {
            "对抗监督": "用于训练GAN模型的一种监督方式，通过判别器提供反馈以优化生成器",
            "语义分割网络": "重新设计的判别器结构，直接使用语义标签图作为训练的真实标签，提供更强的监督",
            "3D噪声张量": "注入生成器的噪声，通过全局和局部采样实现高质量的多模态图像合成"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 858,
        "title": "Zero-Cost Proxies for Lightweight NAS",
        "html": "https://iclr.cc//virtual/2021/poster/2861",
        "abstract": "Neural Architecture Search (NAS) is quickly becoming the standard methodology to design neural network models. However, NAS is typically compute-intensive because multiple models need to be evaluated before choosing the best one. To reduce the computational power and time needed, a proxy task is often used for evaluating each model instead of full training. In this paper, we evaluate conventional reduced-training proxies and quantify how well they preserve ranking between neural network models during search when compared with the rankings produced by final trained accuracy. We propose a series of zero-cost proxies, based on recent pruning literature, that use just a single minibatch of training data to compute a model's score. Our zero-cost proxies use 3 orders of magnitude less computation but can match and even outperform conventional proxies. For example, Spearman's rank correlation coefficient between final validation accuracy and our best zero-cost proxy on NAS-Bench-201 is 0.82, compared to 0.61 for EcoNAS (a recently proposed reduced-training proxy). Finally, we use these zero-cost proxies to enhance existing NAS search algorithms such as random search, reinforcement learning, evolutionary search and predictor-based search. For all search methodologies and across three different NAS datasets, we are able to significantly improve sample efficiency, and thereby decrease computation, by using our zero-cost proxies. For example on NAS-Bench-101, we achieved the same accuracy 4$\\times$ quicker than the best previous result. Our code is made public at: https://github.com/mohsaied/zero-cost-nas.",
        "conference": "ICLR",
        "中文标题": "轻量级神经架构搜索的零成本代理",
        "摘要翻译": "神经架构搜索（NAS）正迅速成为设计神经网络模型的标准方法。然而，NAS通常计算密集，因为需要在选择最佳模型之前评估多个模型。为了减少所需的计算能力和时间，通常使用代理任务来评估每个模型，而不是进行完整训练。在本文中，我们评估了传统的减少训练代理，并量化了它们在搜索过程中与最终训练准确度产生的排名相比，如何保持神经网络模型之间的排名。我们基于最近的剪枝文献，提出了一系列零成本代理，这些代理仅使用一个训练数据的小批量来计算模型的分数。我们的零成本代理使用的计算量减少了3个数量级，但可以匹配甚至超越传统代理。例如，在NAS-Bench-201上，最终验证准确度与我们最佳零成本代理之间的Spearman等级相关系数为0.82，而EcoNAS（最近提出的减少训练代理）为0.61。最后，我们使用这些零成本代理来增强现有的NAS搜索算法，如随机搜索、强化学习、进化搜索和基于预测器的搜索。对于所有搜索方法和三个不同的NAS数据集，我们能够通过使用我们的零成本代理显著提高样本效率，从而减少计算。例如，在NAS-Bench-101上，我们以比之前最佳结果快4倍的速度达到了相同的准确度。我们的代码已公开在：https://github.com/mohsaied/zero-cost-nas。",
        "领域": "神经架构搜索、模型优化、自动化机器学习",
        "问题": "减少神经架构搜索过程中的计算资源消耗和时间",
        "动机": "为了克服NAS因评估多个模型而导致的高计算成本问题，寻找更高效的模型评估方法",
        "方法": "提出基于剪枝文献的零成本代理，仅需一个训练数据的小批量即可评估模型，显著减少计算量",
        "关键词": [
            "神经架构搜索",
            "零成本代理",
            "模型优化",
            "计算效率",
            "自动化机器学习"
        ],
        "涉及的技术概念": {
            "神经架构搜索（NAS）": "一种自动化设计神经网络模型的方法，通过搜索最优的网络结构来提高模型性能",
            "零成本代理": "仅需极少计算资源即可评估模型性能的方法，用于加速神经架构搜索过程",
            "Spearman等级相关系数": "用于衡量两个变量之间等级相关性的统计量，本文中用于评估代理任务与最终训练准确度之间的一致性"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    },
    {
        "order": 859,
        "title": "Zero-shot Synthesis with Group-Supervised Learning",
        "html": "https://iclr.cc//virtual/2021/poster/3059",
        "abstract": "Visual cognition of primates is superior to that of artificial neural networks in its ability to “envision” a visual object, even a newly-introduced one, in different attributes including pose, position, color, texture, etc.  To aid neural networks to envision objects with different attributes,  we propose a family of objective functions, expressed on groups of examples, as a novel learning framework that we term Group-Supervised Learning (GSL). GSL allows us to decompose inputs into a disentangled representation with swappable components, that can be recombined to synthesize new samples.  For instance, images of red boats & blue cars can be decomposed and recombined to synthesize novel images of red cars.   We propose an implementation based on auto-encoder, termed group-supervised zero-shot synthesis network (GZS-Net) trained with our learning framework, that can produce a high-quality red car even if no such example is witnessed during training. We test our model and learning framework on existing benchmarks, in addition to a new dataset that we open-source. We qualitatively and quantitatively demonstrate that GZS-Net trained with GSL outperforms state-of-the-art methods",
        "conference": "ICLR",
        "中文标题": "零样本合成与群组监督学习",
        "摘要翻译": "灵长类动物的视觉认知在‘想象’视觉对象的能力上优于人工神经网络，即使是新引入的对象，也能在不同的属性中‘想象’，包括姿势、位置、颜色、纹理等。为了帮助神经网络想象具有不同属性的对象，我们提出了一系列基于示例组的客观函数，作为一种新颖的学习框架，我们称之为群组监督学习（GSL）。GSL允许我们将输入分解为具有可交换组件的解耦表示，这些组件可以重新组合以合成新的样本。例如，红色船只和蓝色汽车的图像可以被分解并重新组合，以合成红色汽车的新图像。我们提出了一个基于自动编码器的实现，称为群组监督零样本合成网络（GZS-Net），使用我们的学习框架训练，即使训练期间没有看到这样的例子，也能产生高质量的红色汽车。我们在现有基准测试以及我们开源的新数据集上测试了我们的模型和学习框架。我们定性和定量地证明了使用GSL训练的GZS-Net优于最先进的方法。",
        "领域": "图像生成、零样本学习、解耦表示学习",
        "问题": "如何使神经网络能够像灵长类动物一样‘想象’并合成具有未见属性的新对象图像",
        "动机": "提升神经网络在视觉认知上的能力，特别是在合成具有未见属性组合的新对象图像方面",
        "方法": "提出群组监督学习（GSL）框架和基于自动编码器的群组监督零样本合成网络（GZS-Net），通过分解和重新组合输入的解耦表示来合成新样本",
        "关键词": [
            "零样本合成",
            "群组监督学习",
            "解耦表示",
            "图像生成",
            "自动编码器"
        ],
        "涉及的技术概念": {
            "群组监督学习（GSL）": "一种新颖的学习框架，通过基于示例组的客观函数，使神经网络能够分解输入为解耦表示并重新组合以合成新样本",
            "解耦表示": "将输入数据分解为独立的、可交换的组件，便于重新组合生成新的数据样本",
            "自动编码器": "用于实现GZS-Net的技术，通过编码和解码过程学习输入数据的高效表示，支持零样本合成"
        },
        "success": true,
        "pdf": "https://iclr.cc/Downloads"
    }
]