[
    {
        "order": 0,
        "title": "$\\beta$-Intact-VAE: Identifying and Estimating Causal Effects under Limited Overlap",
        "html": "https://iclr.cc//virtual/2022/poster/6819",
        "abstract": "As an important problem in causal inference, we discuss the identification and estimation of treatment effects (TEs) under limited overlap; that is, when subjects with certain features belong to a single treatment group. We use a latent variable to model a prognostic score which is widely used in biostatistics and sufficient for TEs; i.e., we build a generative prognostic model. We prove that the latent variable recovers a prognostic score, and the model identifies individualized treatment effects. The model is then learned as $\\beta$-Intact-VAE––a new type of variational autoencoder (VAE). We derive the TE error bounds that enable representations balanced for treatment groups conditioned on individualized features. The proposed method is compared with recent methods using (semi-)synthetic datasets. ",
        "conference": "ICLR",
        "中文标题": "β-完整-VAE：在有限重叠下识别和估计因果效应",
        "摘要翻译": "作为因果推断中的一个重要问题，我们讨论了在有限重叠情况下处理效应（TEs）的识别和估计；即当具有某些特征的受试者属于单一处理组时。我们使用一个潜变量来建模预后评分，这在生物统计学中被广泛使用，并且对TEs足够；也就是说，我们建立了一个生成预后模型。我们证明了潜变量能够恢复预后评分，并且该模型能够识别个体化处理效应。该模型随后被学习为β-完整-VAE——一种新型的变分自编码器（VAE）。我们推导了TE误差界限，使得表示在处理组条件下针对个体化特征平衡。所提出的方法与最近使用（半）合成数据集的方法进行了比较。",
        "领域": "因果推断、变分自编码器、个体化治疗效应",
        "问题": "在有限重叠情况下识别和估计处理效应",
        "动机": "解决当受试者特征导致其仅属于单一处理组时，处理效应的识别和估计问题",
        "方法": "使用潜变量建模预后评分，构建生成预后模型，并学习为新型变分自编码器β-Intact-VAE",
        "关键词": [
            "因果推断",
            "变分自编码器",
            "预后评分",
            "个体化治疗效应",
            "有限重叠"
        ],
        "涉及的技术概念": {
            "预后评分": "在生物统计学中广泛使用，用于处理效应的识别和估计",
            "变分自编码器（VAE）": "用于构建生成预后模型的新型方法",
            "个体化治疗效应": "模型能够识别针对个体特征的处理效应"
        },
        "success": true
    },
    {
        "order": 1,
        "title": "$\\mathrm{SO}(2)$-Equivariant Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6798",
        "abstract": "Equivariant neural networks enforce symmetry within the structure of their convolutional layers, resulting in a substantial improvement in sample efficiency when learning an equivariant or invariant function. Such models are applicable to robotic manipulation learning which can often be formulated as a rotationally symmetric problem. This paper studies equivariant model architectures in the context of $Q$-learning and actor-critic reinforcement learning. We identify equivariant and invariant characteristics of the optimal $Q$-function and the optimal policy and propose equivariant DQN and SAC algorithms that leverage this structure. We present experiments that demonstrate that our equivariant versions of DQN and SAC can be significantly more sample efficient than competing algorithms on an important class of robotic manipulation problems.",
        "conference": "ICLR",
        "中文标题": "SO(2)等变强化学习",
        "摘要翻译": "等变神经网络在其卷积层的结构中强制对称性，从而在学习等变或不变函数时显著提高样本效率。此类模型适用于机器人操作学习，后者常可表述为旋转对称问题。本文在Q学习和行动者-评论家强化学习的背景下研究等变模型架构。我们识别了最优Q函数和最优策略的等变和不变特性，并提出了利用这种结构的等变DQN和SAC算法。我们提供的实验表明，我们的等变DQN和SAC版本在一类重要的机器人操作问题上比竞争算法显著更样本高效。",
        "领域": "机器人操作学习",
        "问题": "提高在旋转对称问题中的样本效率",
        "动机": "研究等变神经网络在强化学习中的应用，以提高在机器人操作任务中的样本效率",
        "方法": "提出等变DQN和SAC算法，利用最优Q函数和最优策略的等变和不变特性",
        "关键词": [
            "等变神经网络",
            "强化学习",
            "机器人操作",
            "样本效率",
            "旋转对称"
        ],
        "涉及的技术概念": {
            "等变神经网络": "强制网络结构中的对称性，以提高学习等变或不变函数的样本效率",
            "Q学习": "一种强化学习算法，用于学习最优动作价值函数",
            "行动者-评论家算法": "结合策略梯度和价值函数的强化学习方法，用于连续动作空间的问题"
        },
        "success": true
    },
    {
        "order": 2,
        "title": "$\\pi$BO: Augmenting Acquisition Functions with User Beliefs for Bayesian Optimization",
        "html": "https://iclr.cc//virtual/2022/poster/6843",
        "abstract": "Bayesian optimization (BO) has become an established framework and popular tool for hyperparameter optimization (HPO) of machine learning (ML) algorithms. While known for its sample-efficiency, vanilla BO can not utilize readily available prior beliefs the practitioner has on the potential location of the optimum.  Thus, BO disregards a valuable source of information, reducing its appeal to ML practitioners. To address this issue, we propose $\\pi$BO, an acquisition function generalization which incorporates prior beliefs about the location of the optimum in the form of a probability distribution, provided by the user. In contrast to previous approaches, $\\pi$BO is conceptually simple and can easily be integrated with existing libraries and many acquisition functions. We provide regret bounds when $\\pi$BO is applied to the common Expected Improvement acquisition function and prove convergence at regular rates independently of the prior. Further, our experiments show that $\\pi$BO outperforms competing approaches across a wide suite of benchmarks and prior characteristics. We also demonstrate that $\\pi$BO improves on the state-of-the-art performance for a popular deep learning task, with a $12.5\\times$ time-to-accuracy speedup over prominent BO approaches.",
        "conference": "ICLR",
        "中文标题": "πBO：通过用户信念增强贝叶斯优化的获取函数",
        "摘要翻译": "贝叶斯优化（BO）已成为机器学习（ML）算法超参数优化（HPO）的既定框架和流行工具。虽然以样本效率高著称，但原始的BO无法利用实践者对最优位置潜在位置的现成先验信念。因此，BO忽视了这一宝贵的信息来源，降低了其对ML实践者的吸引力。为了解决这个问题，我们提出了πBO，这是一种获取函数的泛化，它以用户提供的概率分布形式，将关于最优位置的先验信念纳入其中。与之前的方法相比，πBO在概念上简单，可以轻松地与现有库和许多获取函数集成。我们提供了当πBO应用于常见的期望改进获取函数时的遗憾界限，并证明了独立于先验的常规速率收敛。此外，我们的实验表明，πBO在一系列基准测试和先验特性上优于竞争方法。我们还证明，πBO在流行的深度学习任务上改进了最先进的性能，与突出的BO方法相比，实现了12.5倍的准确度时间加速。",
        "领域": "超参数优化",
        "问题": "如何将用户的先验信念有效地整合到贝叶斯优化框架中，以提高超参数优化的效率和吸引力",
        "动机": "原始的贝叶斯优化方法无法利用用户对最优位置的先验信念，忽视了宝贵的信息来源，降低了其对机器学习实践者的吸引力",
        "方法": "提出πBO，一种获取函数的泛化，通过将用户提供的关于最优位置的概率分布形式的先验信念纳入其中，来增强贝叶斯优化",
        "关键词": [
            "贝叶斯优化",
            "超参数优化",
            "获取函数",
            "先验信念",
            "深度学习"
        ],
        "涉及的技术概念": {
            "贝叶斯优化": "一种用于全局优化的概率模型，特别适用于超参数优化",
            "获取函数": "用于决定下一个评估点的策略，以平衡探索和利用",
            "先验信念": "用户对最优位置的概率分布形式的先验知识，用于指导优化过程"
        },
        "success": true
    },
    {
        "order": 3,
        "title": "8-bit Optimizers via Block-wise Quantization",
        "html": "https://iclr.cc//virtual/2022/poster/6210",
        "abstract": "Stateful optimizers maintain gradient statistics over time, e.g., the exponentially smoothed sum (SGD with momentum) or squared sum (Adam) of past gradient values. This state can be used to accelerate optimization significantly, compared to plain stochastic gradient descent, but uses memory that might otherwise be allocated to model parameters, thereby limiting the maximum size of models trained in practice. In this paper, we develop the first optimizers that use 8-bit statistics while maintaining the performance levels of using 32-bit optimizer states. To overcome the resulting computational, quantization, and stability challenges, we develop block-wise dynamic quantization. Block-wise quantization divides input tensors into smaller blocks that are independently quantized. Each block is processed in parallel across cores, yielding faster optimization and high precision quantization. To maintain stability and performance, we combine block-wise quantization with two additional changes: (1) dynamic quantization, a form of non-linear optimization that is precise for both large and small magnitude values, and (2) a stable embedding layer to reduce gradient variance that comes from the highly non-uniform distribution of input tokens in language models. As a result, our 8-bit optimizers maintain 32-bit performance with a small fraction of the memory footprint on a range of tasks, including 1.5B parameter language modeling, GLUE finetuning, ImageNet classification, WMT'14 machine translation, MoCo v2 contrastive ImageNet pretraining+finetuning, and RoBERTa pretraining, without changes to the original optimizer hyperparameters. We open-source our 8-bit optimizers as a drop-in replacement that only requires a two-line code change.",
        "conference": "ICLR",
        "中文标题": "通过块级量化实现的8位优化器",
        "摘要翻译": "状态优化器随时间维护梯度统计信息，例如，过去梯度值的指数平滑和（带动量的SGD）或平方和（Adam）。与普通的随机梯度下降相比，这种状态可以显著加速优化过程，但占用了可能分配给模型参数的内存，从而限制了实践中训练模型的最大规模。在本文中，我们开发了首个使用8位统计信息同时保持使用32位优化器状态性能水平的优化器。为了克服由此产生的计算、量化和稳定性挑战，我们开发了块级动态量化。块级量化将输入张量划分为独立量化的小块。每个块在核心间并行处理，从而实现更快的优化和高精度量化。为了保持稳定性和性能，我们将块级量化与两项额外变化结合起来：（1）动态量化，一种对大小幅度值都精确的非线性优化形式；（2）稳定的嵌入层，以减少来自语言模型中输入令牌高度非均匀分布的梯度方差。因此，我们的8位优化器在一系列任务上保持了32位性能，同时仅占用一小部分内存，包括15亿参数的语言建模、GLUE微调、ImageNet分类、WMT'14机器翻译、MoCo v2对比性ImageNet预训练+微调和RoBERTa预训练，且无需更改原始优化器超参数。我们将8位优化器开源，作为一个只需两行代码更改的即插即用替代方案。",
        "领域": "深度学习优化技术、自然语言处理、计算机视觉",
        "问题": "如何在减少优化器内存占用的同时保持其性能",
        "动机": "减少优化器内存占用，使得可以训练更大规模的模型",
        "方法": "开发块级动态量化技术，结合动态量化和稳定嵌入层以保持性能",
        "关键词": [
            "8位优化器",
            "块级量化",
            "动态量化",
            "内存优化",
            "深度学习"
        ],
        "涉及的技术概念": {
            "块级量化": "将输入张量划分为小块独立量化，以提高并行处理能力和量化精度",
            "动态量化": "一种非线性优化技术，能够精确处理不同大小的数值",
            "稳定嵌入层": "用于减少由于输入令牌分布不均引起的梯度方差，提高训练稳定性"
        },
        "success": true
    },
    {
        "order": 4,
        "title": "Ab-Initio Potential Energy Surfaces by Pairing GNNs with Neural Wave Functions",
        "html": "https://iclr.cc//virtual/2022/poster/7108",
        "abstract": "Solving the Schrödinger equation is key to many quantum mechanical properties. However, an analytical solution is only tractable for single-electron systems. Recently, neural networks succeeded at modelling wave functions of many-electron systems. Together with the variational Monte-Carlo (VMC) framework, this led to solutions on par with the best known classical methods. Still, these neural methods require tremendous amounts of computational resources as one has to train a separate model for each molecular geometry. In this work, we combine a Graph Neural Network (GNN) with a neural wave function to simultaneously solve the Schrödinger equation for multiple geometries via VMC. This enables us to model continuous subsets of the potential energy surface with a single training pass. Compared to existing state-of-the-art networks, our Potential Energy Surface Network (PESNet) speeds up training for multiple geometries by up to 40 times while matching or surpassing their accuracy. This may open the path to accurate and orders of magnitude cheaper quantum mechanical calculations.",
        "conference": "ICLR",
        "中文标题": "通过将图神经网络与神经波函数配对实现从头算势能面",
        "摘要翻译": "求解薛定谔方程是获取许多量子力学性质的关键。然而，解析解仅适用于单电子系统。最近，神经网络成功模拟了多电子系统的波函数。结合变分蒙特卡洛（VMC）框架，这导致了与最著名的经典方法相媲美的解决方案。尽管如此，这些神经方法需要巨大的计算资源，因为必须为每个分子几何结构训练一个单独的模型。在这项工作中，我们将图神经网络（GNN）与神经波函数结合，通过VMC同时求解多个几何结构的薛定谔方程。这使我们能够通过单次训练模拟势能面的连续子集。与现有的最先进网络相比，我们的势能面网络（PESNet）在匹配或超越其精度的同时，将多个几何结构的训练速度提高了多达40倍。这可能为准确且数量级更便宜的量子力学计算开辟道路。",
        "领域": "量子化学计算、图神经网络应用、变分蒙特卡洛方法",
        "问题": "解决多电子系统薛定谔方程求解过程中计算资源消耗巨大的问题",
        "动机": "为了降低量子力学计算中的计算成本，同时保持或提高计算精度",
        "方法": "结合图神经网络（GNN）和神经波函数，通过变分蒙特卡洛（VMC）框架同时求解多个几何结构的薛定谔方程",
        "关键词": [
            "图神经网络",
            "神经波函数",
            "变分蒙特卡洛",
            "势能面",
            "量子力学计算"
        ],
        "涉及的技术概念": {
            "图神经网络（GNN）": "用于处理分子几何结构数据，能够有效捕捉分子间的拓扑关系",
            "神经波函数": "用于模拟多电子系统的波函数，提供量子力学性质的精确描述",
            "变分蒙特卡洛（VMC）": "一种量子力学计算方法，通过随机采样优化波函数参数，以求解薛定谔方程"
        },
        "success": true
    },
    {
        "order": 5,
        "title": "A Biologically Interpretable Graph Convolutional Network to Link Genetic Risk Pathways and Imaging Phenotypes of Disease ",
        "html": "https://iclr.cc//virtual/2022/poster/6978",
        "abstract": "We propose a novel end-to-end framework for whole-brain and whole-genome imaging-genetics. Our genetics network uses hierarchical graph convolution and pooling operations to embed subject-level data onto a low-dimensional latent space. The hierarchical network implicitly tracks the convergence of genetic risk across well-established biological pathways, while an attention mechanism automatically identifies the salient edges of this network at the subject level. In parallel, our imaging network projects multimodal data onto a set of latent embeddings. For interpretability, we implement a Bayesian feature selection strategy to extract the discriminative imaging biomarkers; these feature weights are optimized alongside the other model parameters. We couple the imaging and genetic embeddings with a predictor network, to ensure that the learned representations are linked to phenotype. We evaluate our framework on a schizophrenia dataset that includes two functional MRI paradigms and gene scores derived from Single Nucleotide Polymorphism data. Using repeated 10-fold cross-validation, we show that our imaging-genetics fusion achieves the better classification performance than state-of-the-art baselines. In an exploratory analysis, we further show that the biomarkers identified by our model are reproducible and closely associated with deficits in schizophrenia. ",
        "conference": "ICLR",
        "中文标题": "一种生物可解释的图卷积网络用于连接遗传风险通路与疾病影像表型",
        "摘要翻译": "我们提出了一种新颖的端到端框架，用于全脑和全基因组影像遗传学。我们的遗传学网络使用分层图卷积和池化操作，将受试者水平的数据嵌入到低维潜在空间。分层网络隐式跟踪了遗传风险在已确立的生物通路中的汇聚，而注意力机制自动识别了该网络在受试者水平上的显著边。与此同时，我们的影像网络将多模态数据投影到一组潜在嵌入上。为了可解释性，我们实施了贝叶斯特征选择策略以提取有区分力的影像生物标志物；这些特征权重与其他模型参数一起优化。我们将影像和遗传嵌入与预测网络耦合，以确保学习到的表示与表型相关联。我们在一个包括两种功能MRI范式和源自单核苷酸多态性数据的基因评分的schizophrenia数据集上评估了我们的框架。通过重复的10折交叉验证，我们展示了我们的影像遗传学融合实现了比最先进基线更好的分类性能。在探索性分析中，我们进一步展示了我们的模型识别的生物标志物是可重复的，并且与schizophrenia的缺陷密切相关。",
        "领域": "影像遗传学",
        "问题": "如何有效地将遗传风险通路与疾病影像表型连接起来",
        "动机": "开发一个能够解释遗传风险如何通过生物通路影响疾病影像表型的模型",
        "方法": "使用分层图卷积和池化操作的遗传学网络，结合注意力机制和贝叶斯特征选择策略的影像网络，以及耦合两者的预测网络",
        "关键词": [
            "图卷积网络",
            "影像遗传学",
            "生物标志物",
            "注意力机制",
            "贝叶斯特征选择"
        ],
        "涉及的技术概念": {
            "分层图卷积": "用于处理遗传数据，嵌入到低维潜在空间",
            "注意力机制": "自动识别网络中的显著边，提高模型对关键遗传信息的关注",
            "贝叶斯特征选择": "用于提取有区分力的影像生物标志物，增强模型的可解释性"
        },
        "success": true
    },
    {
        "order": 6,
        "title": "Accelerated Policy Learning with Parallel Differentiable Simulation",
        "html": "https://iclr.cc//virtual/2022/poster/6923",
        "abstract": "Deep reinforcement learning can generate complex control policies, but requires large amounts of training data to work effectively. Recent work has attempted to address this issue by leveraging differentiable simulators. However, inherent problems such as local minima and exploding/vanishing numerical gradients prevent these methods from being generally applied to control tasks with complex contact-rich dynamics, such as humanoid locomotion in classical RL benchmarks. In this work we present a high-performance differentiable simulator and a new policy learning algorithm (SHAC) that can effectively leverage simulation gradients, even in the presence of non-smoothness. Our learning algorithm alleviates problems with local minima through a smooth critic function, avoids vanishing/exploding gradients through a truncated learning window, and allows many physical environments to be run in parallel. We evaluate our method on classical RL control tasks, and show substantial improvements in sample efficiency and wall-clock time over state-of-the-art RL and differentiable simulation-based algorithms. In addition, we demonstrate the scalability of our method by applying it to the challenging high-dimensional problem of muscle-actuated locomotion with a large action space, achieving a greater than $17\\times$ reduction in training time over the best-performing established RL algorithm. More visual results are provided at: https://sites.google.com/view/shac.",
        "conference": "ICLR",
        "中文标题": "加速策略学习的并行可微分模拟",
        "摘要翻译": "深度强化学习可以生成复杂的控制策略，但需要大量的训练数据才能有效工作。最近的研究尝试通过利用可微分模拟器来解决这一问题。然而，局部极小值和爆炸/消失数值梯度等固有问题阻止了这些方法被普遍应用于具有复杂接触丰富动力学的控制任务，如经典RL基准中的人形运动。在这项工作中，我们提出了一个高性能的可微分模拟器和一个新的策略学习算法（SHAC），即使在存在非平滑性的情况下，也能有效利用模拟梯度。我们的学习算法通过平滑的批评函数缓解了局部极小值的问题，通过截断的学习窗口避免了梯度消失/爆炸，并允许多个物理环境并行运行。我们在经典RL控制任务上评估了我们的方法，并显示出在样本效率和实际时间上相对于最先进的RL和基于可微分模拟的算法的显著改进。此外，我们通过将其应用于具有大动作空间的肌肉驱动运动这一具有挑战性的高维问题，展示了我们方法的可扩展性，实现了比表现最佳的已建立RL算法减少超过17倍的训练时间。更多视觉结果请访问：https://sites.google.com/view/shac。",
        "领域": "强化学习",
        "问题": "解决深度强化学习在复杂控制任务中需要大量训练数据的问题",
        "动机": "通过利用可微分模拟器提高策略学习的效率和效果",
        "方法": "提出高性能可微分模拟器和新的策略学习算法SHAC，利用模拟梯度，通过平滑批评函数和截断学习窗口优化学习过程",
        "关键词": [
            "可微分模拟",
            "策略学习",
            "强化学习"
        ],
        "涉及的技术概念": {
            "可微分模拟器": "用于生成训练数据，允许梯度通过模拟过程反向传播",
            "SHAC算法": "新的策略学习算法，有效利用模拟梯度，解决局部极小值和梯度问题",
            "平滑批评函数": "用于缓解学习过程中的局部极小值问题"
        },
        "success": true
    },
    {
        "order": 7,
        "title": "Acceleration of Federated Learning with Alleviated Forgetting in Local Training",
        "html": "https://iclr.cc//virtual/2022/poster/6422",
        "abstract": "Federated learning (FL) enables distributed optimization of machine learning models while protecting privacy by independently training local models on each client and then aggregating parameters on a central server, thereby producing an effective global model. Although a variety of FL algorithms have been proposed, their training efficiency remains low when the data are not independently and identically distributed (non-i.i.d.) across different clients. We observe that the slow convergence rates of the existing methods are (at least partially) caused by the catastrophic forgetting issue during the local training stage on each individual client, which leads to a large increase in the loss function concerning the previous training data provided at other clients. Here, we propose FedReg, an algorithm to accelerate FL with alleviated knowledge forgetting in the local training stage by regularizing locally trained parameters with the loss on generated pseudo data, which encode the knowledge of previous training data learned by the global model. Our comprehensive experiments demonstrate that FedReg not only significantly improves the convergence rate of FL, especially when the neural network architecture is deep and the clients' data are extremely non-i.i.d., but is also able to protect privacy better in classification problems and more robust against gradient inversion attacks.",
        "conference": "ICLR",
        "中文标题": "联邦学习中通过减轻本地训练遗忘的加速方法",
        "摘要翻译": "联邦学习（FL）通过在各个客户端上独立训练本地模型，然后在中央服务器上聚合参数，从而产生一个有效的全局模型，实现了机器学习模型的分布式优化，同时保护了隐私。尽管已经提出了多种FL算法，但当数据在不同客户端之间不是独立同分布（非i.i.d.）时，它们的训练效率仍然较低。我们观察到，现有方法的慢收敛速度（至少部分）是由每个客户端在本地训练阶段的灾难性遗忘问题引起的，这导致了对其他客户端提供的先前训练数据的损失函数大幅增加。在这里，我们提出了FedReg，一种通过在本地训练阶段用生成的伪数据上的损失来正则化本地训练参数，从而减轻知识遗忘以加速FL的算法，这些伪数据编码了全局模型学习的先前训练数据的知识。我们的全面实验表明，FedReg不仅显著提高了FL的收敛速度，特别是当神经网络架构较深且客户端数据极端非i.i.d.时，而且还能在分类问题中更好地保护隐私，并且对梯度反转攻击更加鲁棒。",
        "领域": "联邦学习、深度学习优化、隐私保护机器学习",
        "问题": "解决联邦学习在非独立同分布数据下的训练效率低和灾难性遗忘问题",
        "动机": "提高联邦学习在非i.i.d.数据环境下的收敛速度和保护隐私的能力",
        "方法": "提出FedReg算法，通过在本地训练阶段使用伪数据上的损失正则化参数，减轻知识遗忘",
        "关键词": [
            "联邦学习",
            "灾难性遗忘",
            "非i.i.d.数据",
            "隐私保护",
            "梯度反转攻击"
        ],
        "涉及的技术概念": {
            "联邦学习": "一种分布式机器学习方法，允许多个客户端在不共享原始数据的情况下共同训练模型",
            "灾难性遗忘": "机器学习模型在学习新知识时忘记先前学到的知识的现象",
            "伪数据": "生成的模拟数据，用于在联邦学习中编码和传递全局模型的知识"
        },
        "success": true
    },
    {
        "order": 8,
        "title": "A Class of Short-term Recurrence Anderson Mixing Methods and Their Applications",
        "html": "https://iclr.cc//virtual/2022/poster/5953",
        "abstract": "Anderson mixing (AM) is a powerful acceleration method for fixed-point iterations, but its computation requires storing many historical iterations. The extra memory footprint can be prohibitive when solving high-dimensional problems in a resource-limited machine. To reduce the memory overhead, we propose a novel class of short-term recurrence AM methods (ST-AM). The ST-AM methods only store two previous iterations with cheap corrections. We prove that the basic version of ST-AM is equivalent to the full-memory AM in strongly convex quadratic optimization, and with minor changes it has local linear convergence for solving general nonlinear fixed-point problems. We further analyze the convergence properties of the regularized ST-AM for nonconvex (stochastic) optimization. Finally, we apply ST-AM to several applications including solving root-finding problems and training neural networks. Experimental results show that ST-AM is competitive with the long-memory AM and outperforms many existing optimizers. ",
        "conference": "ICLR",
        "中文标题": "一类短期递归安德森混合方法及其应用",
        "摘要翻译": "安德森混合（AM）是一种强大的定点迭代加速方法，但其计算需要存储许多历史迭代。在资源有限的机器上解决高维问题时，额外的内存占用可能成为障碍。为了减少内存开销，我们提出了一类新颖的短期递归AM方法（ST-AM）。ST-AM方法仅存储两次先前的迭代，并进行廉价修正。我们证明了在强凸二次优化中，ST-AM的基本版本等同于全内存AM，并且通过微小改动，它在解决一般非线性定点问题时具有局部线性收敛性。我们进一步分析了正则化ST-AM在非凸（随机）优化中的收敛性质。最后，我们将ST-AM应用于包括求解根查找问题和训练神经网络在内的多个应用。实验结果表明，ST-AM与长内存AM竞争，并且优于许多现有的优化器。",
        "领域": "优化算法、神经网络训练、非线性问题求解",
        "问题": "减少安德森混合方法在高维问题求解中的内存占用",
        "动机": "在资源有限的机器上解决高维问题时，减少安德森混合方法的内存开销",
        "方法": "提出一类短期递归安德森混合方法（ST-AM），仅存储两次先前的迭代并进行廉价修正",
        "关键词": [
            "安德森混合",
            "短期递归",
            "内存优化",
            "非线性优化",
            "神经网络训练"
        ],
        "涉及的技术概念": {
            "安德森混合（AM）": "一种定点迭代加速方法，通过存储历史迭代来加速收敛",
            "短期递归AM方法（ST-AM）": "仅存储两次先前的迭代并进行廉价修正，以减少内存开销",
            "强凸二次优化": "ST-AM的基本版本在此类优化问题中与全内存AM等效"
        },
        "success": true
    },
    {
        "order": 9,
        "title": "A Comparison of Hamming Errors of Representative Variable Selection Methods",
        "html": "https://iclr.cc//virtual/2022/poster/6651",
        "abstract": "Lasso is a celebrated method for variable selection in linear models, but it faces challenges when the covariates are moderately or strongly correlated. This motivates alternative approaches such as using a non-convex penalty, adding a ridge regularization, or conducting a post-Lasso thresholding. In this paper, we compare Lasso with 5 other methods: Elastic net, SCAD, forward selection, thresholded Lasso, and forward backward selection. We measure their performances theoretically by the expected Hamming error, assuming that the regression coefficients are ${\\it iid}$ drawn from a two-point mixture and that the Gram matrix is block-wise diagonal. By deriving the rates of convergence of Hamming errors and the phase diagrams, we obtain useful conclusions about the pros and cons of different methods.",
        "conference": "ICLR",
        "中文标题": "代表性变量选择方法的汉明误差比较",
        "摘要翻译": "Lasso是线性模型中变量选择的一种著名方法，但当协变量中度或强相关时，它面临挑战。这促使了替代方法的出现，如使用非凸惩罚、添加岭正则化或进行Lasso后阈值处理。在本文中，我们将Lasso与其他5种方法进行比较：弹性网络、SCAD、前向选择、阈值Lasso和前向后向选择。我们通过预期的汉明误差在理论上测量它们的性能，假设回归系数是从两点混合中独立同分布抽取的，且Gram矩阵是块对角的。通过推导汉明误差的收敛速度和相图，我们得出了关于不同方法优缺点有用的结论。",
        "领域": "统计学习",
        "问题": "比较不同变量选择方法在协变量相关情况下的性能",
        "动机": "解决Lasso方法在协变量中度或强相关时面临的挑战",
        "方法": "比较Lasso、弹性网络、SCAD、前向选择、阈值Lasso和前向后向选择方法的汉明误差",
        "关键词": [
            "变量选择",
            "汉明误差",
            "Lasso",
            "弹性网络",
            "SCAD"
        ],
        "涉及的技术概念": {
            "汉明误差": "用于衡量变量选择方法性能的指标，表示错误选择或遗漏的变量数量",
            "Lasso": "一种通过L1正则化进行变量选择和正则化的线性回归方法",
            "弹性网络": "结合L1和L2正则化的方法，用于处理高度相关的预测变量"
        },
        "success": true
    },
    {
        "order": 10,
        "title": "A Conditional Point Diffusion-Refinement Paradigm for 3D Point Cloud Completion",
        "html": "https://iclr.cc//virtual/2022/poster/7026",
        "abstract": "3D point clouds are an important data format that captures 3D information for real world objects.  Since 3D point clouds scanned in the real world are often incomplete, it is important to recover the complete point cloud for many downstreaming applications. Most existing point cloud completion methods use the Chamfer Distance (CD) loss for training. The CD loss estimates correspondences between two point clouds by searching nearest neighbors, which does not capture the overall point distribution on the generated shape, and therefore likely leads to non-uniform point cloud generation. To tackle this problem, we propose a novel Point Diffusion-Refinement (PDR) paradigm for point cloud completion. PDR consists of a Conditional Generation Network (CGNet) and a ReFinement Network (RFNet). The CGNet uses a conditional generative model called the denoising diffusion probabilistic model (DDPM) to generate a coarse completion conditioned on the partial observation. DDPM establishes a one-to-one pointwise mapping between the generated point cloud and the uniform ground truth, and then optimizes the mean squared error loss to realize uniform generation. The RFNet refines the coarse output of the CGNet and further improves quality of the completed point cloud.  In terms of the architecture, we develop a novel dual-path architecture for both networks. The architecture can (1) effectively and efficiently extract multi-level features from partially observed point clouds to guide completion, and (2) accurately manipulate spatial locations of 3D points to obtain smooth surfaces and sharp details. Extensive experimental results on various benchmark datasets show that our PDR paradigm outperforms previous state-of-the-art methods for point cloud completion. In addition, with the help of the RFNet,  we can accelerate the iterative generation process of the DDPM by up to 50 times without much performance drop.",
        "conference": "ICLR",
        "中文标题": "一种用于3D点云补全的条件点扩散-细化范式",
        "摘要翻译": "3D点云是捕捉现实世界物体3D信息的重要数据格式。由于现实世界中扫描的3D点云往往不完整，恢复完整的点云对于许多下游应用非常重要。大多数现有的点云补全方法使用Chamfer距离（CD）损失进行训练。CD损失通过搜索最近邻来估计两个点云之间的对应关系，这不能捕捉生成形状上的整体点分布，因此可能导致非均匀的点云生成。为了解决这个问题，我们提出了一种新颖的点扩散-细化（PDR）范式用于点云补全。PDR由条件生成网络（CGNet）和细化网络（RFNet）组成。CGNet使用一种称为去噪扩散概率模型（DDPM）的条件生成模型，根据部分观察生成粗略的补全。DDPM在生成的点云和均匀地面真实之间建立了一对一的点对点映射，然后优化均方误差损失以实现均匀生成。RFNet对CGNet的粗略输出进行细化，进一步提高补全点云的质量。在架构方面，我们为两个网络开发了一种新颖的双路径架构。该架构可以（1）有效且高效地从部分观察的点云中提取多级特征以指导补全，（2）精确操纵3D点的空间位置以获得平滑的表面和锐利的细节。在各种基准数据集上的大量实验结果表明，我们的PDR范式在点云补全方面优于之前的最先进方法。此外，借助RFNet，我们可以将DDPM的迭代生成过程加速多达50倍，而性能下降不大。",
        "领域": "点云补全",
        "问题": "解决现有方法在点云补全过程中生成的点云分布不均匀的问题",
        "动机": "为了提高点云补全的质量和均匀性，以及加速生成过程",
        "方法": "提出了一种结合条件生成网络和细化网络的双路径架构，利用去噪扩散概率模型（DDPM）实现均匀点云生成，并通过细化网络进一步提高质量",
        "关键词": [
            "点云补全",
            "去噪扩散概率模型",
            "双路径架构"
        ],
        "涉及的技术概念": {
            "去噪扩散概率模型（DDPM）": "用于根据部分观察生成均匀分布的点云，通过建立点对点映射和优化均方误差损失实现",
            "双路径架构": "设计用于有效提取多级特征和精确操纵3D点空间位置的网络架构，以提高补全质量和细节表现",
            "Chamfer距离（CD）损失": "传统方法中用于训练点云补全模型的损失函数，通过搜索最近邻估计点云间对应关系，但可能导致非均匀生成"
        },
        "success": true
    },
    {
        "order": 11,
        "title": "Active Hierarchical Exploration with Stable Subgoal Representation Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6965",
        "abstract": "Goal-conditioned hierarchical reinforcement learning (GCHRL) provides a promising approach to solving long-horizon tasks. Recently, its success has been extended to more general settings by concurrently learning hierarchical policies and subgoal representations. Although GCHRL possesses superior exploration ability by decomposing tasks via subgoals, existing GCHRL methods struggle in temporally extended tasks with sparse external rewards, since the high-level policy learning relies on external rewards. As the high-level policy selects subgoals in an online learned representation space, the dynamic change of the subgoal space severely hinders effective high-level exploration. In this paper, we propose a novel regularization that contributes to both stable and efficient subgoal representation learning. Building upon the stable representation, we design measures of novelty and potential for subgoals, and develop an active hierarchical exploration strategy that seeks out new promising subgoals and states without intrinsic rewards. Experimental results show that our approach significantly outperforms state-of-the-art baselines in continuous control tasks with sparse rewards. ",
        "conference": "ICLR",
        "中文标题": "基于稳定子目标表示学习的主动分层探索",
        "摘要翻译": "目标条件分层强化学习（GCHRL）为解决长视野任务提供了一种有前景的方法。最近，通过同时学习分层策略和子目标表示，其成功已被扩展到更一般的设置。尽管GCHRL通过子目标分解任务具有优越的探索能力，现有的GCHRL方法在具有稀疏外部奖励的时间延长任务中表现不佳，因为高层策略的学习依赖于外部奖励。由于高层策略在在线学习的表示空间中选择子目标，子目标空间的动态变化严重阻碍了有效的高层探索。在本文中，我们提出了一种新颖的正则化方法，有助于稳定和高效的子目标表示学习。基于稳定的表示，我们设计了子目标的新颖性和潜力度量，并开发了一种主动分层探索策略，该策略无需内在奖励即可寻找新的有前景的子目标和状态。实验结果表明，我们的方法在具有稀疏奖励的连续控制任务中显著优于最先进的基线。",
        "领域": "分层强化学习、子目标表示学习、连续控制任务",
        "问题": "解决在稀疏外部奖励环境下，高层策略学习因依赖外部奖励而表现不佳的问题",
        "动机": "提高在稀疏奖励环境下的分层强化学习效率和稳定性",
        "方法": "提出一种新颖的正则化方法以稳定子目标表示学习，并设计子目标的新颖性和潜力度量，开发主动分层探索策略",
        "关键词": [
            "分层强化学习",
            "子目标表示",
            "主动探索",
            "稀疏奖励",
            "连续控制"
        ],
        "涉及的技术概念": {
            "目标条件分层强化学习（GCHRL）": "一种通过分解任务为子目标来解决长视野任务的强化学习方法",
            "子目标表示学习": "学习如何表示子目标，以便高层策略能在表示空间中选择有效的子目标",
            "主动分层探索策略": "一种无需内在奖励即可寻找新的有前景的子目标和状态的探索方法"
        },
        "success": true
    },
    {
        "order": 12,
        "title": "Actor-critic is implicitly biased towards high entropy optimal policies",
        "html": "https://iclr.cc//virtual/2022/poster/6634",
        "abstract": "We show that the simplest actor-critic method — a linear softmax policy updated with TD through interaction with a linear MDP, but featuring no explicit regularization or exploration — does not merely find an optimal policy, but moreover prefers high entropy optimal policies. To demonstrate the strength of this bias, the algorithm not only has no regularization, no projections, and no exploration like $\\epsilon$-greedy, but is moreover trained on a single trajectory with no resets. The key consequence of the high entropy bias is that uniform mixing assumptions on the MDP, which exist in some form in all prior work, can be dropped: the implicit regularization of the high entropy bias is enough to ensure that all chains mix and an optimal policy is reached with high probability. As auxiliary contributions, this work decouples concerns between the actor and critic by writing the actor update as an explicit mirror descent, provides tools to uniformly bound mixing times within KL balls of policy space, and provides a projection-free TD analysis with its own implicit bias which can be run from an unmixed starting distribution.",
        "conference": "ICLR",
        "中文标题": "演员-评论家方法隐式偏向于高熵最优策略",
        "摘要翻译": "我们展示了最简单的演员-评论家方法——一个通过TD学习与线性MDP交互更新的线性softmax策略，且不包含任何显式正则化或探索——不仅找到一个最优策略，而且更倾向于高熵的最优策略。为了证明这种偏见的强度，该算法不仅没有正则化、没有投影、没有像ε-贪婪那样的探索，而且是在没有重置的单一轨迹上训练的。高熵偏见的关键结果是，可以放弃MDP上的均匀混合假设，这在所有先前的工作中以某种形式存在：高熵偏见的隐式正则化足以确保所有链混合，并以高概率达到最优策略。作为辅助贡献，这项工作通过将演员更新写为显式镜像下降，解耦了演员和评论家之间的关注，提供了在策略空间的KL球内统一限制混合时间的工具，并提供了一个无投影的TD分析，其自身的隐式偏见可以从非混合的初始分布运行。",
        "领域": "强化学习、策略优化、马尔可夫决策过程",
        "问题": "研究演员-评论家方法在缺乏显式正则化或探索机制的情况下，为何倾向于选择高熵的最优策略。",
        "动机": "探索演员-评论家方法在没有传统正则化和探索机制的情况下，如何通过其隐式偏好达到高熵最优策略，以及这种偏好对算法性能的影响。",
        "方法": "通过理论分析和实验验证，研究了线性softmax策略在单一轨迹上的TD学习过程，分析了高熵偏见的效应及其对策略优化的影响。",
        "关键词": [
            "演员-评论家方法",
            "高熵策略",
            "隐式偏见",
            "TD学习",
            "策略优化"
        ],
        "涉及的技术概念": {
            "演员-评论家方法": "一种结合策略梯度（演员）和价值函数（评论家）的强化学习方法，用于策略优化。",
            "高熵最优策略": "在策略优化中倾向于选择具有更高熵（即更多随机性）的最优策略。",
            "隐式偏见": "算法在没有显式设计的情况下，自然倾向于某些解决方案的特性。"
        },
        "success": true
    },
    {
        "order": 13,
        "title": "Actor-Critic Policy Optimization in a Large-Scale Imperfect-Information Game",
        "html": "https://iclr.cc//virtual/2022/poster/6627",
        "abstract": "The deep policy gradient method has demonstrated promising results in many large-scale games, where the agent learns purely from its own experience. Yet, policy gradient methods with self-play suffer convergence problems to a Nash Equilibrium (NE) in multi-agent situations. Counterfactual regret minimization (CFR) has a convergence guarantee to a NE in 2-player zero-sum games, but it usually needs domain-specific abstractions to deal with large-scale games.  Inheriting merits from both methods, in this paper we extend the actor-critic algorithm framework in deep reinforcement learning to tackle a large-scale 2-player zero-sum imperfect-information game, 1-on-1 Mahjong, whose information set size and game length are much larger than poker. The proposed algorithm, named Actor-Critic Hedge (ACH), modifies the policy optimization objective from originally maximizing the discounted returns to minimizing a type of weighted cumulative counterfactual regret. This modification is achieved by approximating the regret via a deep neural network and minimizing the regret via generating self-play policies using Hedge. ACH is theoretically justified as it is derived from a neural-based weighted CFR, for which we prove the convergence to a NE under certain conditions. Experimental results on the proposed 1-on-1 Mahjong benchmark and benchmarks from the literature demonstrate that ACH outperforms related state-of-the-art methods. Also, the agent obtained by ACH defeats a human champion in 1-on-1 Mahjong.",
        "conference": "ICLR",
        "中文标题": "大规模不完全信息博弈中的演员-评论家策略优化",
        "摘要翻译": "深度策略梯度方法在许多大规模游戏中展示了令人鼓舞的结果，其中智能体仅从其自身经验中学习。然而，在多智能体情境中，采用自我对弈的策略梯度方法在收敛到纳什均衡（NE）方面存在问题。反事实遗憾最小化（CFR）在两人零和游戏中具有收敛到纳什均衡的保证，但它通常需要领域特定的抽象来处理大规模游戏。继承这两种方法的优点，本文中我们扩展了深度强化学习中的演员-评论家算法框架，以解决一个大规模两人零和不完全信息游戏——一对一麻将，其信息集大小和游戏长度远大于扑克。所提出的算法，名为演员-评论家对冲（ACH），将策略优化目标从最初的最大化折扣回报修改为最小化一种加权累积反事实遗憾。这一修改通过深度神经网络近似遗憾并通过使用对冲生成自我对弈策略来最小化遗憾来实现。ACH在理论上是合理的，因为它源自基于神经网络的加权CFR，我们证明了在一定条件下其收敛到纳什均衡。在所提出的一对一麻将基准和文献中的基准上的实验结果表明，ACH优于相关的最先进方法。此外，通过ACH获得的智能体在一对一麻将中击败了人类冠军。",
        "领域": "强化学习、博弈论、不完全信息博弈",
        "问题": "解决大规模不完全信息博弈中策略梯度方法收敛到纳什均衡的问题",
        "动机": "结合策略梯度方法和反事实遗憾最小化的优点，以解决大规模不完全信息博弈中的收敛问题",
        "方法": "扩展演员-评论家算法框架，修改策略优化目标为最小化加权累积反事实遗憾，通过深度神经网络近似遗憾并使用对冲生成自我对弈策略",
        "关键词": [
            "演员-评论家对冲",
            "不完全信息博弈",
            "反事实遗憾最小化",
            "纳什均衡",
            "深度强化学习"
        ],
        "涉及的技术概念": {
            "演员-评论家对冲（ACH）": "扩展自演员-评论家算法框架，用于最小化加权累积反事实遗憾的策略优化方法",
            "反事实遗憾最小化（CFR）": "用于保证在两人零和游戏中收敛到纳什均衡的技术，ACH通过深度神经网络近似和优化这一概念",
            "纳什均衡（NE）": "在多智能体博弈中，所有玩家策略的最优状态，ACH旨在通过优化策略达到这一状态"
        },
        "success": true
    },
    {
        "order": 14,
        "title": "AdaAug: Learning Class- and Instance-adaptive Data Augmentation Policies",
        "html": "https://iclr.cc//virtual/2022/poster/6420",
        "abstract": "Data augmentation is an effective way to improve the generalization capability of modern deep learning models. However, the underlying augmentation methods mostly rely on handcrafted operations. Moreover, an augmentation policy useful to one dataset may not transfer well to other datasets. Therefore, Automated Data Augmentation (AutoDA) methods, like \\textit{AutoAugment} and \\textit{Population-based Augmentation}, have been proposed recently to automate the process of searching for optimal augmentation policies. However, the augmentation policies found are not adaptive to the dataset used, hindering the effectiveness of these AutoDA methods. In this paper, we propose a novel AutoDA method called \\texttt{AdaAug} to efficiently learn adaptive augmentation policies in a class-dependent and potentially instance-dependent manner. Our experiments show that the adaptive augmentation policies learned by our method transfer well to unseen datasets such as the Oxford Flowers, Oxford-IIT Pets, FGVC Aircraft, and Stanford Cars datasets when compared with other AutoDA baselines. In addition, our method also achieves state-of-the-art performance on the CIFAR-10, CIFAR-100, and SVHN datasets.",
        "conference": "ICLR",
        "中文标题": "AdaAug: 学习类别和实例自适应的数据增强策略",
        "摘要翻译": "数据增强是提高现代深度学习模型泛化能力的有效方法。然而，基础的增强方法大多依赖于手工操作。此外，对一个数据集有用的增强策略可能无法很好地迁移到其他数据集。因此，最近提出了自动数据增强（AutoDA）方法，如AutoAugment和基于群体的增强，以自动化搜索最优增强策略的过程。然而，发现的增强策略并不适应于所使用的数据集，这限制了这些AutoDA方法的有效性。在本文中，我们提出了一种名为AdaAug的新型AutoDA方法，以类别依赖和潜在实例依赖的方式高效学习自适应增强策略。我们的实验表明，与其他AutoDA基线相比，我们的方法学习到的自适应增强策略能够很好地迁移到未见过的数据集，如牛津花卉、牛津-IIT宠物、FGVC飞机和斯坦福汽车数据集。此外，我们的方法在CIFAR-10、CIFAR-100和SVHN数据集上也达到了最先进的性能。",
        "领域": "自动数据增强、深度学习优化、图像分类",
        "问题": "如何自动化和优化数据增强策略，使其能够适应不同的数据集和类别，甚至单个实例。",
        "动机": "现有的自动数据增强方法发现的策略缺乏对数据集的适应性，限制了其效果和迁移能力。",
        "方法": "提出了一种名为AdaAug的新型自动数据增强方法，通过学习类别和实例自适应的增强策略来提高模型的泛化能力和迁移性。",
        "关键词": [
            "自动数据增强",
            "自适应策略",
            "深度学习优化",
            "图像分类",
            "迁移学习"
        ],
        "涉及的技术概念": {
            "自动数据增强（AutoDA）": "自动化搜索最优数据增强策略的技术，旨在提高模型的泛化能力。",
            "类别和实例自适应": "根据数据的类别或单个实例特性调整增强策略，以提高策略的适应性和效果。",
            "迁移学习": "将在一个数据集上学到的知识或策略应用到另一个相关数据集上的技术，以提升模型在新任务上的表现。"
        },
        "success": true
    },
    {
        "order": 15,
        "title": "AdaMatch: A Unified Approach to Semi-Supervised Learning and Domain Adaptation",
        "html": "https://iclr.cc//virtual/2022/poster/6340",
        "abstract": "We extend semi-supervised learning to the problem of domain adaptation to learn significantly higher-accuracy models that train on one data distribution and test on a different one. With the goal of generality, we introduce AdaMatch, a unified solution for unsupervised domain adaptation (UDA), semi-supervised learning (SSL), and semi-supervised domain adaptation (SSDA). In an extensive experimental study, we compare its behavior with respective state-of-the-art techniques from SSL, SSDA, and UDA and find that AdaMatch either matches or significantly exceeds the state-of-the-art in each case using the same hyper-parameters regardless of the dataset or task. For example, AdaMatch nearly doubles the accuracy compared to that of the prior state-of-the-art on the UDA task for DomainNet and even exceeds the accuracy of the prior state-of-the-art obtained with pre-training by 6.4% when AdaMatch is trained completely from scratch. Furthermore, by providing AdaMatch with just one labeled example per class from the target domain (i.e., the SSDA setting), we increase the target accuracy by an additional 6.1%, and with 5 labeled examples, by 13.6%.",
        "conference": "ICLR",
        "中文标题": "AdaMatch：半监督学习与领域适应的统一方法",
        "摘要翻译": "我们将半监督学习扩展到领域适应问题，以学习在一个数据分布上训练并在另一个不同分布上测试的显著更高准确率的模型。为了追求通用性，我们引入了AdaMatch，这是一种针对无监督领域适应（UDA）、半监督学习（SSL）和半监督领域适应（SSDA）的统一解决方案。在一项广泛的实验研究中，我们将其行为与来自SSL、SSDA和UDA的各自最先进技术进行了比较，发现AdaMatch在每种情况下使用相同的超参数，无论数据集或任务如何，都能匹配或显著超越最先进技术。例如，在DomainNet的UDA任务上，AdaMatch的准确率几乎比之前的最先进技术提高了一倍，甚至在AdaMatch完全从头开始训练时，其准确率比之前通过预训练获得的最先进技术高出6.4%。此外，通过仅为AdaMatch提供来自目标域的每个类别的一个标记示例（即SSDA设置），我们将目标准确率再提高了6.1%，而提供5个标记示例时，提高了13.6%。",
        "领域": "半监督学习, 领域适应, 无监督学习",
        "问题": "如何在一个数据分布上训练模型并在另一个不同分布上测试时提高模型的准确率",
        "动机": "为了解决在不同数据分布间迁移学习时模型准确率下降的问题，提出一种统一的解决方案",
        "方法": "引入AdaMatch，一种统一解决无监督领域适应、半监督学习和半监督领域适应的方法",
        "关键词": [
            "AdaMatch",
            "半监督学习",
            "领域适应",
            "无监督学习",
            "模型准确率"
        ],
        "涉及的技术概念": {
            "AdaMatch": "一种统一的解决方案，用于无监督领域适应、半监督学习和半监督领域适应",
            "无监督领域适应（UDA）": "在没有目标域标记数据的情况下，将模型从源域适应到目标域的技术",
            "半监督学习（SSL）": "利用少量标记数据和大量未标记数据进行学习的技术"
        },
        "success": true
    },
    {
        "order": 16,
        "title": "Ada-NETS: Face Clustering via Adaptive Neighbour Discovery in the Structure Space",
        "html": "https://iclr.cc//virtual/2022/poster/6907",
        "abstract": "Face clustering has attracted rising research interest recently to take advantage of massive amounts of face images on the web. State-of-the-art performance has been achieved by Graph Convolutional Networks (GCN) due to their powerful representation capacity. However, existing GCN-based methods build face graphs mainly according to kNN relations in the feature space, which may lead to a lot of noise edges connecting two faces of different classes. The face features will be polluted when messages pass along these noise edges, thus degrading the performance of GCNs. In this paper, a novel algorithm named Ada-NETS is proposed to cluster faces by constructing clean graphs for GCNs. In Ada-NETS, each face is transformed to a new structure space, obtaining robust features by considering face features of the neighbour images. Then, an adaptive neighbour discovery strategy is proposed to determine a proper number of edges connecting to each face image. It significantly reduces the noise edges while maintaining the good ones to build a graph with clean yet rich edges for GCNs to cluster faces. Experiments on multiple public clustering datasets show that Ada-NETS significantly outperforms current state-of-the-art methods, proving its superiority and generalization. Code is available at https://github.com/Thomas-wyh/Ada-NETS.",
        "conference": "ICLR",
        "中文标题": "Ada-NETS：通过结构空间中的自适应邻居发现进行人脸聚类",
        "摘要翻译": "近年来，人脸聚类研究兴趣日益增长，以利用网络上大量的人脸图像。图卷积网络（GCN）因其强大的表示能力，已实现最先进的性能。然而，现有的基于GCN的方法主要根据特征空间中的kNN关系构建人脸图，这可能导致大量噪声边缘连接两个不同类别的人脸。当信息沿着这些噪声边缘传递时，人脸特征将被污染，从而降低GCN的性能。本文提出了一种名为Ada-NETS的新算法，通过为GCN构建干净的图来聚类人脸。在Ada-NETS中，每个人脸被转换到一个新的结构空间，通过考虑邻居图像的人脸特征获得鲁棒特征。然后，提出了一种自适应邻居发现策略，以确定连接到每个人脸图像的适当数量的边缘。它显著减少了噪声边缘，同时保留了良好的边缘，为GCN构建了一个干净而丰富的边缘图以聚类人脸。在多个公共聚类数据集上的实验表明，Ada-NETS显著优于当前最先进的方法，证明了其优越性和泛化能力。代码可在https://github.com/Thomas-wyh/Ada-NETS获取。",
        "领域": "人脸聚类",
        "问题": "解决基于GCN的人脸聚类方法中因噪声边缘导致特征污染的问题",
        "动机": "提高人脸聚类的准确性和鲁棒性，通过构建更干净的图结构来优化GCN的性能",
        "方法": "提出Ada-NETS算法，通过将人脸转换到结构空间并采用自适应邻居发现策略，构建干净而丰富的图结构",
        "关键词": [
            "人脸聚类",
            "图卷积网络",
            "自适应邻居发现",
            "结构空间",
            "噪声边缘"
        ],
        "涉及的技术概念": {
            "图卷积网络（GCN）": "用于处理图结构数据，通过聚合邻居节点的信息来学习节点的表示",
            "自适应邻居发现策略": "动态确定每个节点的邻居数量，以减少噪声边缘并保留有用的连接",
            "结构空间": "将人脸特征转换到的新空间，通过考虑邻居特征来增强特征的鲁棒性"
        },
        "success": true
    },
    {
        "order": 17,
        "title": "Adaptive Wavelet Transformer Network for 3D Shape Representation Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6423",
        "abstract": "We present a novel method for 3D shape representation learning using multi-scale wavelet decomposition. Distinct from previous works that either decompose 3D shapes into complementary components at a single scale, or naively adopt up-/down-sampling to build hierarchies and treat all points or local regions equally, we decompose 3D shapes into sub-bands components at multiple scales and all scales form a decomposition tree in a principled manner rooted in multi-resolution wavelet analysis. Specifically, we propose Adaptive Wavelet Transformer Network (AWT-Net) that firstly generates approximation or detail wavelet coefficients per point, classifying each point into high or low sub bands components, using lifting scheme at multiple scales recursively and hierarchically. Then, AWT-Net exploits Transformer that treats the features from different but complementary components as two integrated representations, and fuses them with the original shape features with different attentions. The wavelet coefficients can be learned without direct supervision on coefficients, and AWT-Net is fully differentiable and can be learned in an end-to-end fashion. Extensive experiments demonstrate that AWT-Net achieves competitive performance on 3D shape classification and segmentation benchmarks.",
        "conference": "ICLR",
        "中文标题": "自适应小波变换网络用于3D形状表示学习",
        "摘要翻译": "我们提出了一种新颖的3D形状表示学习方法，该方法利用多尺度小波分解。与之前的工作不同，这些工作要么在单一尺度上将3D形状分解为互补组件，要么简单地采用上/下采样来构建层次结构并平等对待所有点或局部区域，我们以多分辨率小波分析为基础，将3D形状分解为多个尺度的子带组件，所有尺度以一种有原则的方式形成一个分解树。具体来说，我们提出了自适应小波变换网络（AWT-Net），该网络首先生成每个点的近似或细节小波系数，使用提升方案在多个尺度上递归和分层地将每个点分类为高或低子带组件。然后，AWT-Net利用Transformer将来自不同但互补组件的特征视为两个集成表示，并将它们与原始形状特征以不同的注意力融合。小波系数可以在没有直接监督的情况下学习，AWT-Net是完全可微的，可以以端到端的方式学习。大量实验表明，AWT-Net在3D形状分类和分割基准测试中实现了竞争性的性能。",
        "领域": "3D形状分析, 多尺度表示学习, 几何深度学习",
        "问题": "如何有效地进行3D形状的多尺度表示学习",
        "动机": "解决现有方法在3D形状表示学习中单一尺度分解或平等对待所有点/局部区域的局限性",
        "方法": "提出自适应小波变换网络（AWT-Net），通过多尺度小波分解和Transformer技术融合不同尺度的形状特征",
        "关键词": [
            "3D形状表示",
            "多尺度小波分解",
            "自适应小波变换网络",
            "Transformer",
            "端到端学习"
        ],
        "涉及的技术概念": {
            "多尺度小波分解": "用于将3D形状分解为多个尺度的子带组件，形成分解树",
            "自适应小波变换网络（AWT-Net）": "通过递归和分层的方式生成小波系数，分类点至高或低子带组件",
            "Transformer": "用于融合来自不同但互补组件的特征，与原始形状特征以不同的注意力结合"
        },
        "success": true
    },
    {
        "order": 18,
        "title": "AdaRL: What, Where, and How to Adapt in Transfer Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6988",
        "abstract": "One practical challenge in reinforcement learning (RL) is how to make quick adaptations when faced with new environments. In this paper, we propose a principled framework for adaptive RL, called AdaRL, that adapts reliably and efficiently to changes across domains with a few samples from the target domain, even in partially observable environments. Specifically, we leverage a parsimonious graphical representation that characterizes structural relationships over variables in the RL system. Such graphical representations provide a compact way to encode what and where the changes across domains are, and furthermore inform us with a minimal set of changes that one has to consider for the purpose of policy adaptation. We show that by explicitly leveraging this compact representation to encode changes, we can efficiently adapt the policy to the target domain, in which only a few samples are needed and further policy optimization is avoided. We illustrate the efficacy of AdaRL through a series of experiments that vary factors in the observation, transition and reward functions for Cartpole and Atari games.",
        "conference": "ICLR",
        "中文标题": "AdaRL：迁移强化学习中的适应内容、位置及方法",
        "摘要翻译": "强化学习（RL）面临的一个实际挑战是如何在新环境中快速适应。本文中，我们提出了一个原则性的自适应RL框架，称为AdaRL，它能够可靠且高效地适应跨领域的变化，即使在部分可观察的环境中，也仅需目标领域的少量样本。具体而言，我们利用了一种简洁的图形表示法，该表示法刻画了RL系统中变量间的结构关系。这种图形表示提供了一种紧凑的方式来编码跨领域变化的内容和位置，并进一步告知我们为了策略适应必须考虑的最小变化集。我们表明，通过明确利用这种紧凑表示来编码变化，我们可以高效地将策略适应到目标领域，其中仅需少量样本，且无需进一步的策略优化。我们通过一系列实验说明了AdaRL的有效性，这些实验在Cartpole和Atari游戏中变化了观察、转移和奖励函数的因素。",
        "领域": "迁移学习、强化学习、自适应系统",
        "问题": "如何在面对新环境时快速适应，特别是在部分可观察的环境中。",
        "动机": "解决强化学习在新环境中快速适应的问题，提高策略适应的效率和可靠性。",
        "方法": "提出AdaRL框架，利用简洁的图形表示法编码跨领域变化，实现策略的高效适应。",
        "关键词": [
            "迁移强化学习",
            "自适应系统",
            "图形表示法",
            "策略适应",
            "部分可观察环境"
        ],
        "涉及的技术概念": {
            "图形表示法": "用于刻画RL系统中变量间的结构关系，提供跨领域变化的紧凑编码。",
            "策略适应": "通过编码变化高效调整策略到目标领域，减少样本需求和避免进一步优化。",
            "部分可观察环境": "研究在信息不完全的环境中进行强化学习适应的挑战和解决方案。"
        },
        "success": true
    },
    {
        "order": 19,
        "title": "ADAVI: Automatic Dual Amortized Variational Inference Applied To Pyramidal Bayesian Models",
        "html": "https://iclr.cc//virtual/2022/poster/6309",
        "abstract": "Frequently, population studies feature pyramidally-organized data represented using Hierarchical Bayesian Models (HBM) enriched with plates. These models can become prohibitively large in settings such as neuroimaging, where a sample is composed of a functional MRI signal measured on 300 brain locations, across 4 measurement sessions, and 30 subjects, resulting in around 1 million latent parameters.Such high dimensionality hampers the usage of modern, expressive flow-based techniques.To infer parameter posterior distributions in this challenging class of problems, we designed a novel methodology that automatically produces a variational family dual to a target HBM. This variational family, represented as a neural network, consists in the combination of an attention-based hierarchical encoder feeding summary statistics to a set of normalizing flows. Our automatically-derived neural network exploits exchangeability in the plate-enriched HBM and factorizes its parameter space. The resulting architecture reduces by orders of magnitude its parameterization with respect to that of a typical flow-based representation, while maintaining expressivity.Our method performs inference on the specified HBM in an amortized setup: once trained, it can readily be applied to a new data sample to compute the parameters' full posterior.We demonstrate the capability and scalability of our method on simulated data, as well as a challenging high-dimensional brain parcellation experiment. We also open up several questions that lie at the intersection between normalizing flows, SBI, structured Variational Inference, and inference amortization.",
        "conference": "ICLR",
        "中文标题": "ADAVI：应用于金字塔贝叶斯模型的双自动摊销变分推断",
        "摘要翻译": "在人口研究中，经常遇到以层次贝叶斯模型（HBM）表示的、带有板块的金字塔式组织数据。在诸如神经影像学等场景中，这些模型可能变得异常庞大，例如一个样本包含在300个大脑位置、4次测量会话和30个受试者上测量的功能MRI信号，导致约100万个潜在参数。如此高的维度限制了现代、富有表现力的基于流的技术的使用。为了在这类具有挑战性的问题中推断参数后验分布，我们设计了一种新方法，能自动生成与目标HBM对偶的变分族。这个变分族以神经网络的形式表示，结合了一个基于注意力的层次编码器，将摘要统计信息输入到一组标准化流中。我们自动导出的神经网络利用了板块丰富的HBM中的可交换性，并对其参数空间进行了因子分解。与典型的基于流的表示相比，所得架构在保持表现力的同时，将其参数化减少了几个数量级。我们的方法在摊销设置中对指定的HBM进行推断：一旦训练完成，它可以立即应用于新的数据样本，以计算参数的完整后验。我们在模拟数据和一个具有挑战性的高维大脑分区实验上展示了我们方法的能力和可扩展性。我们还提出了几个位于标准化流、SBI、结构化变分推断和推断摊销交叉点的问题。",
        "领域": "神经影像分析、贝叶斯统计建模、变分推断",
        "问题": "处理高维金字塔式组织数据在层次贝叶斯模型中的参数后验推断问题",
        "动机": "解决在神经影像学等高维数据场景中，传统基于流的技术因模型参数过多而难以应用的问题",
        "方法": "设计了一种自动生成与目标层次贝叶斯模型对偶的变分族的方法，结合基于注意力的层次编码器和标准化流，减少参数化同时保持表现力",
        "关键词": [
            "变分推断",
            "层次贝叶斯模型",
            "标准化流",
            "神经影像分析",
            "摊销推断"
        ],
        "涉及的技术概念": {
            "变分族": "自动生成的与目标层次贝叶斯模型对偶的变分分布族，用于参数后验推断",
            "标准化流": "用于构建富有表现力的概率分布的技术，在本方法中用于参数后验的建模",
            "注意力机制": "在层次编码器中用于有效汇总和传递数据摘要统计信息的技术"
        },
        "success": true
    },
    {
        "order": 20,
        "title": "A Deep Variational Approach to Clustering Survival Data",
        "html": "https://iclr.cc//virtual/2022/poster/6333",
        "abstract": "In this work, we study the problem of clustering survival data — a challenging and so far under-explored task. We introduce a novel semi-supervised probabilistic approach to cluster survival data by leveraging recent advances in stochastic gradient variational inference. In contrast to previous work, our proposed method employs a deep generative model to uncover the underlying distribution of both the explanatory variables and censored survival times. We compare our model to the related work on clustering and mixture models for survival data in comprehensive experiments on a wide range of synthetic, semi-synthetic, and real-world datasets, including medical imaging data. Our method performs better at identifying clusters and is competitive at predicting survival times. Relying on novel generative assumptions, the proposed model offers a holistic perspective on clustering survival data and holds a promise of discovering subpopulations whose survival is regulated by different generative mechanisms.",
        "conference": "ICLR",
        "中文标题": "一种深度变分方法用于生存数据聚类",
        "摘要翻译": "在这项工作中，我们研究了生存数据聚类的问题——这是一项具有挑战性且迄今为止尚未充分探索的任务。我们通过利用随机梯度变分推断的最新进展，引入了一种新颖的半监督概率方法来聚类生存数据。与之前的工作相比，我们提出的方法采用了一个深度生成模型来揭示解释变量和审查生存时间的潜在分布。我们在广泛的合成、半合成和真实世界数据集（包括医学成像数据）上进行了全面实验，将我们的模型与生存数据聚类和混合模型的相关工作进行了比较。我们的方法在识别聚类方面表现更好，并且在预测生存时间方面具有竞争力。依赖于新颖的生成假设，所提出的模型为生存数据聚类提供了一个全面的视角，并有望发现其生存受不同生成机制调节的亚群。",
        "领域": "生存分析、深度学习、医学影像分析",
        "问题": "解决生存数据聚类的挑战性问题，特别是在医学影像等领域的应用。",
        "动机": "探索生存数据聚类的潜力，以发现受不同生成机制调节的亚群，为医学研究提供新的视角。",
        "方法": "采用深度生成模型和随机梯度变分推断技术，提出了一种半监督概率方法，用于聚类生存数据。",
        "关键词": [
            "生存数据聚类",
            "深度生成模型",
            "变分推断",
            "半监督学习",
            "医学影像"
        ],
        "涉及的技术概念": {
            "随机梯度变分推断": "用于优化深度生成模型的训练过程，提高模型对生存数据的聚类能力。",
            "深度生成模型": "用于揭示解释变量和审查生存时间的潜在分布，支持生存数据的聚类分析。",
            "半监督学习": "结合有限的标记数据和大量未标记数据，提高生存数据聚类的准确性和效率。"
        },
        "success": true
    },
    {
        "order": 21,
        "title": "Adversarially Robust Conformal Prediction",
        "html": "https://iclr.cc//virtual/2022/poster/6450",
        "abstract": "Conformal prediction is a model-agnostic tool for constructing prediction sets that are valid under the common i.i.d. assumption, which has been applied to quantify the prediction uncertainty of deep net classifiers. In this paper, we generalize this framework to the case where adversaries exist during inference time, under which the i.i.d. assumption is grossly violated. By combining conformal prediction with randomized smoothing, our proposed method forms a prediction set with finite-sample coverage guarantee that holds for any data distribution with $\\ell_2$-norm bounded adversarial noise, generated by any adversarial attack algorithm. The core idea is to bound the Lipschitz constant of the non-conformity score by smoothing it with Gaussian noise and leverage this knowledge to account for the effect of the unknown adversarial perturbation. We demonstrate the necessity of our method in the adversarial setting and the validity of our theoretical guarantee on three widely used benchmark data sets: CIFAR10, CIFAR100, and ImageNet.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "对抗鲁棒的共形预测",
        "摘要翻译": "共形预测是一种与模型无关的工具，用于构建在常见的独立同分布（i.i.d.）假设下有效的预测集，已被应用于量化深度网络分类器的预测不确定性。在本文中，我们将此框架推广到推理过程中存在对抗攻击的情况，在这种情况下，i.i.d.假设被严重违反。通过将共形预测与随机平滑相结合，我们提出的方法形成一个具有有限样本覆盖保证的预测集，该保证适用于任何具有由任何对抗攻击算法生成的l2范数有界对抗噪声的数据分布。核心思想是通过用高斯噪声平滑非一致性分数来限制其 Lipschitz 常数，并利用这些知识来解释未知对抗扰动的影响。我们在对抗环境中证明了我们方法的必要性，并在三个广泛使用的基准数据集：CIFAR10、CIFAR100和ImageNet上验证了我们理论保证的有效性。",
        "领域": "对抗攻击、不确定性量化、鲁棒性",
        "问题": "在对抗攻击存在的情况下，如何保证深度学习模型预测结果的可靠性和有效性，即如何构建对抗鲁棒的预测集。",
        "动机": "现有的共形预测方法依赖于独立同分布假设，当面临对抗攻击时，该假设不再成立，导致预测结果的可靠性下降。因此，需要一种新的方法来解决对抗环境下的预测不确定性量化问题。",
        "方法": "结合共形预测与随机平滑技术，通过高斯噪声平滑非一致性分数来限制其 Lipschitz 常数，从而应对对抗扰动的影响，构建具有有限样本覆盖保证的预测集。",
        "关键词": [
            "共形预测",
            "对抗鲁棒性",
            "随机平滑",
            "预测集",
            "不确定性量化"
        ],
        "涉及的技术概念": {
            "共形预测": "一种与模型无关的预测方法，用于构建在一定置信水平下包含真实标签的预测集，能够提供预测结果的不确定性度量。",
            "随机平滑": "一种防御对抗攻击的技术，通过对输入数据添加随机噪声来平滑模型的决策边界，提高模型的鲁棒性。"
        }
    },
    {
        "order": 22,
        "title": "Adversarial Retriever-Ranker for Dense Text Retrieval",
        "html": "https://iclr.cc//virtual/2022/poster/6182",
        "abstract": "Current dense text retrieval models face two typical challenges. First, it adopts a siamese dual-encoder architecture to encode query and document independently for fast indexing and searching, whereas neglecting the finer-grained term-wise interactions. This results in a sub-optimal recall performance. Second, it highly relies on a negative sampling technique to build up the negative documents in its contrastive loss. To address these challenges, we present Adversarial Retriever-Ranker (AR2), which consists of a dual-encoder retriever plus a cross-encoder ranker. The two models are jointly optimized according to a minimax adversarial objective: the retriever learns to retrieve negative documents to cheat the ranker, while the ranker learns to rank a collection of candidates including both the ground-truth and the retrieved ones, as well as providing progressive direct feedback to the dual-encoder retriever. Through this adversarial game, the retriever gradually produces harder negative documents to train a better ranker, whereas the cross-encoder ranker provides progressive feedback to improve retriever. We evaluate AR2 on three benchmarks. Experimental results show that AR2 consistently and significantly outperforms existing dense retriever methods and achieves new state-of-the-art results on all of them. This includes the improvements on Natural Questions R@5 to 77.9%(+2.1%), TriviaQA R@5 to 78.2%(+1.4), and MS-MARCO MRR@10 to 39.5%(+1.3%). We will make our code, models, and data publicly available. ",
        "conference": "ICLR",
        "中文标题": "对抗性检索-排序器用于密集文本检索",
        "摘要翻译": "当前的密集文本检索模型面临两个典型挑战。首先，它采用了一种孪生双编码器架构来独立编码查询和文档以实现快速索引和搜索，而忽略了更细粒度的词项间交互。这导致了次优的召回性能。其次，它高度依赖于负采样技术在其对比损失中构建负文档。为了解决这些挑战，我们提出了对抗性检索-排序器（AR2），它由一个双编码器检索器加上一个交叉编码器排序器组成。这两个模型根据一个极小极大对抗目标联合优化：检索器学习检索负文档以欺骗排序器，而排序器学习对包括真实答案和检索到的候选在内的集合进行排序，并向双编码器检索器提供渐进式直接反馈。通过这种对抗游戏，检索器逐渐产生更难的负文档以训练更好的排序器，而交叉编码器排序器提供渐进式反馈以改进检索器。我们在三个基准上评估了AR2。实验结果表明，AR2一致且显著地优于现有的密集检索方法，并在所有这些基准上实现了新的最先进结果。这包括在Natural Questions R@5上提高到77.9%（+2.1%），在TriviaQA R@5上提高到78.2%（+1.4），以及在MS-MARCO MRR@10上提高到39.5%（+1.3%）。我们将公开我们的代码、模型和数据。",
        "领域": "信息检索、自然语言处理、机器学习",
        "问题": "密集文本检索模型在独立编码查询和文档时忽略了词项间交互，以及高度依赖负采样技术构建负文档，导致召回性能不佳。",
        "动机": "通过联合优化检索器和排序器，利用对抗性学习提高密集文本检索的性能。",
        "方法": "提出AR2模型，结合双编码器检索器和交叉编码器排序器，通过对抗性学习联合优化两者，检索器生成更难的负文档训练排序器，排序器提供反馈改进检索器。",
        "关键词": [
            "密集文本检索",
            "对抗性学习",
            "双编码器",
            "交叉编码器",
            "负采样"
        ],
        "涉及的技术概念": {
            "对抗性学习": "通过检索器和排序器之间的对抗游戏，逐步提高模型的性能。",
            "双编码器架构": "独立编码查询和文档以实现快速索引和搜索的架构。",
            "交叉编码器": "用于对候选文档进行排序的模型，能够考虑查询和文档之间的交互。"
        },
        "success": true
    },
    {
        "order": 23,
        "title": "Adversarial Robustness Through the Lens of Causality",
        "html": "https://iclr.cc//virtual/2022/poster/6330",
        "abstract": "The adversarial vulnerability of deep neural networks has attracted signiﬁcant attention in machine learning. As causal reasoning has an instinct for modeling distribution change, it is essential to incorporate causality into analyzing this specific type of distribution change induced by adversarial attacks. However, causal formulations of the intuition of adversarial attacks and the development of robust DNNs are still lacking in the literature. To bridge this gap, we construct a causal graph to model the generation process of adversarial examples and define the adversarial distribution to formalize the intuition of adversarial attacks. From the causal perspective, we study the distinction between the natural and adversarial distribution and conclude that the origin of adversarial vulnerability is the focus of models on spurious correlations. Inspired by the causal understanding, we propose the \\emph{Causal}-inspired \\emph{Adv}ersarial distribution alignment method, CausalAdv, to eliminate the difference between natural and adversarial distributions by considering spurious correlations. Extensive experiments demonstrate the efficacy of the proposed method. Our work is the first attempt towards using causality to understand and mitigate the adversarial vulnerability.",
        "conference": "ICLR",
        "中文标题": "从因果关系的视角看对抗鲁棒性",
        "摘要翻译": "深度神经网络的对抗脆弱性在机器学习领域引起了广泛关注。由于因果推理在建模分布变化方面具有本能，将因果关系纳入分析由对抗攻击引起的这种特定类型的分布变化至关重要。然而，文献中仍缺乏对抗攻击直觉的因果表述和鲁棒深度神经网络的开发。为了填补这一空白，我们构建了一个因果图来模拟对抗样本的生成过程，并定义了对抗分布以形式化对抗攻击的直觉。从因果的角度，我们研究了自然分布和对抗分布之间的区别，并得出结论：对抗脆弱性的根源在于模型对虚假相关性的关注。受因果理解的启发，我们提出了受因果启发的对抗分布对齐方法CausalAdv，通过考虑虚假相关性来消除自然分布和对抗分布之间的差异。大量实验证明了所提方法的有效性。我们的工作是首次尝试使用因果关系来理解和减轻对抗脆弱性。",
        "领域": "对抗机器学习、因果推理、深度神经网络鲁棒性",
        "问题": "深度神经网络在面对对抗攻击时的脆弱性问题",
        "动机": "探索和利用因果关系来理解和减轻深度神经网络的对抗脆弱性",
        "方法": "构建因果图模拟对抗样本生成过程，提出CausalAdv方法通过考虑虚假相关性来对齐自然和对抗分布",
        "关键词": [
            "对抗鲁棒性",
            "因果推理",
            "深度神经网络",
            "虚假相关性",
            "分布对齐"
        ],
        "涉及的技术概念": {
            "因果图": "用于模拟对抗样本生成过程的图形模型，帮助理解对抗攻击的直觉",
            "对抗分布": "形式化对抗攻击直觉的分布，用于分析对抗脆弱性",
            "虚假相关性": "模型在训练过程中可能学到的与真实因果关系无关的特征关联，是导致对抗脆弱性的主要原因"
        },
        "success": true
    },
    {
        "order": 24,
        "title": "Adversarial Support Alignment",
        "html": "https://iclr.cc//virtual/2022/poster/6100",
        "abstract": "We study the problem of aligning the supports of distributions. Compared to the existing work on distribution alignment, support alignment does not require the densities to be matched. We propose symmetric support difference as a divergence measure to quantify the mismatch between supports. We show that select discriminators (e.g. discriminator trained for Jensen-Shannon divergence) are able to map support differences as support differences in their one-dimensional output space. Following this result, our method aligns supports by minimizing a symmetrized relaxed optimal transport cost in the discriminator 1D space via an adversarial process. Furthermore, we show that our approach can be viewed as a limit of existing notions of alignment by increasing transportation assignment tolerance. We quantitatively evaluate the method across domain adaptation tasks with shifts in label distributions. Our experiments show that the proposed method is more robust against these shifts than other alignment-based baselines.",
        "conference": "ICLR",
        "中文标题": "对抗性支持对齐",
        "摘要翻译": "我们研究了分布支持对齐的问题。与现有的分布对齐工作相比，支持对齐不需要匹配密度。我们提出了对称支持差异作为一种散度度量来量化支持之间的不匹配。我们展示了选择的判别器（例如，为Jensen-Shannon散度训练的判别器）能够在其一维输出空间中将支持差异映射为支持差异。基于这一结果，我们的方法通过对抗过程在判别器的一维空间中最小化对称松弛最优传输成本来对齐支持。此外，我们表明，我们的方法可以被视为通过增加传输分配容忍度来对齐现有概念的极限。我们在标签分布变化的领域适应任务中定量评估了该方法。我们的实验表明，与其他基于对齐的基线相比，所提出的方法对这些变化更加鲁棒。",
        "领域": "领域适应、生成对抗网络、最优传输",
        "问题": "分布支持对齐的问题，即在不需要匹配密度的情况下对齐分布的支持。",
        "动机": "现有的分布对齐方法需要匹配密度，而支持对齐提供了一种不需要密度匹配的替代方案，旨在更灵活地处理分布间的差异。",
        "方法": "通过提出对称支持差异作为散度度量，并利用判别器在一维输出空间中对齐支持，通过最小化对称松弛最优传输成本来实现支持对齐。",
        "关键词": [
            "支持对齐",
            "对抗过程",
            "最优传输",
            "领域适应",
            "对称支持差异"
        ],
        "涉及的技术概念": {
            "对称支持差异": "用于量化两个分布支持之间不匹配的散度度量。",
            "对抗过程": "通过对抗性训练在判别器的一维输出空间中对齐分布支持的方法。",
            "最优传输": "在支持对齐中，通过最小化对称松弛最优传输成本来实现分布支持的对齐。"
        },
        "success": true
    },
    {
        "order": 25,
        "title": "Adversarial Unlearning of Backdoors via Implicit Hypergradient",
        "html": "https://iclr.cc//virtual/2022/poster/6180",
        "abstract": "We propose a minimax formulation for removing backdoors from a given poisoned model based on a small set of clean data. This formulation encompasses much of prior work on backdoor removal. We propose the Implicit Backdoor Adversarial Unlearning (I-BAU) algorithm to solve the minimax. Unlike previous work, which breaks down the minimax into separate inner and outer problems, our algorithm utilizes the implicit hypergradient to account for the interdependence between inner and outer optimization. We theoretically analyze its convergence and the generalizability of the robustness gained by solving minimax on clean data to unseen test data. In our evaluation, we compare I-BAU with six state-of-art backdoor defenses on eleven backdoor attacks over two datasets and various attack settings, including the common setting where the attacker targets one class as well as important but underexplored settings where multiple classes are targeted. I-BAU's performance is comparable to and most often significantly better than the best baseline. Particularly, its performance is more robust to the variation on triggers, attack settings, poison ratio, and clean data size. Moreover, I-BAU requires less computation to take effect; particularly, it is more than $13\\times$ faster than the most efficient baseline in the single-target attack setting. Furthermore, it can remain effective in the extreme case where the defender can only access 100 clean samples---a setting where all the baselines fail to produce acceptable results.",
        "conference": "ICLR",
        "中文标题": "通过隐式超梯度对抗性遗忘后门",
        "摘要翻译": "我们提出了一种基于少量干净数据的极小极大化公式，用于从给定的中毒模型中移除后门。这一公式涵盖了之前关于后门移除的大部分工作。我们提出了隐式后门对抗性遗忘（I-BAU）算法来解决这一极小极大化问题。与之前的工作不同，之前的工作将极小极大化问题分解为单独的内部和外部问题，我们的算法利用隐式超梯度来考虑内部和外部优化之间的相互依赖关系。我们从理论上分析了其收敛性以及通过在干净数据上解决极小极大化问题获得的鲁棒性对未见测试数据的泛化能力。在我们的评估中，我们将I-BAU与六种最先进的后门防御方法在两种数据集上的十一种后门攻击及各种攻击设置下进行了比较，包括攻击者针对一个类别的常见设置以及针对多个类别的重要但未被充分探索的设置。I-BAU的性能与最佳基线相当，并且在大多数情况下显著优于最佳基线。特别是，其性能对触发器、攻击设置、毒化比例和干净数据大小的变化更为鲁棒。此外，I-BAU需要更少的计算即可生效；特别是在单目标攻击设置中，它比最高效的基线快了13倍以上。此外，在极端情况下，即防御者只能访问100个干净样本时，它仍然有效——这是所有基线都无法产生可接受结果的设置。",
        "领域": "深度学习安全、对抗性机器学习、后门攻击防御",
        "问题": "如何从中毒模型中有效移除后门，同时保持模型在干净数据上的性能。",
        "动机": "现有的后门移除方法通常将问题分解为独立的内部和外部优化问题，忽略了它们之间的相互依赖关系，导致移除效果不佳。",
        "方法": "提出了一种隐式后门对抗性遗忘（I-BAU）算法，利用隐式超梯度来考虑内部和外部优化之间的相互依赖关系，有效移除后门。",
        "关键词": [
            "后门移除",
            "对抗性遗忘",
            "隐式超梯度",
            "极小极大化",
            "深度学习安全"
        ],
        "涉及的技术概念": {
            "隐式超梯度": "用于考虑内部和外部优化之间相互依赖关系的技术，提高后门移除的效率和效果。",
            "极小极大化": "一种优化框架，用于在给定干净数据的情况下移除模型中的后门。",
            "对抗性遗忘": "一种通过对抗性训练来遗忘或移除模型中特定知识（如后门）的方法。"
        },
        "success": true
    },
    {
        "order": 26,
        "title": "AEVA: Black-box Backdoor Detection Using Adversarial Extreme Value Analysis",
        "html": "https://iclr.cc//virtual/2022/poster/6929",
        "abstract": "Deep neural networks (DNNs) are proved to be vulnerable against backdoor attacks. A backdoor could be embedded in the target DNNs through injecting a backdoor trigger into the training examples,  which can cause the target DNNs misclassify an input attached with the backdoor trigger. Recent backdoor detection methods often require the access to the original poisoned training data, the parameters of the target DNNs, or the predictive confidence for each given input, which are impractical in many real-world applications, e.g., on-device de-ployed DNNs. We address the black-box hard-label backdoor detection problem where the DNN is a fully black-box and only its final output label is accessible. We approach this problem from the optimization perspective and show that the objective of backdoor detection is bounded by an adversarial objective. Further theoretical and empirical studies reveal that this adversarial objective leads to a solution with highly skewed distribution;  a singularity is often observed in the adversarial map of a backdoor-infected example, which we call the adversarial singularity phenomenon. Based on this observation, we propose the adversarial extreme value analysis(AEVA) algorithm to detect backdoors in black-box neural networks. The AEVA algorithm is based on an extreme value analysis on the adversarial map, computed from the monte-carlo gradient estimation due to the black-box hard-label constraint. Evidenced by extensive experiments across three popular tasks and backdoor attacks, our approach is shown effective in detecting backdoor attacks under the black-box hard-label scenarios",
        "conference": "ICLR",
        "中文标题": "AEVA：基于对抗性极值分析的黑盒后门检测",
        "摘要翻译": "深度神经网络（DNNs）已被证明容易受到后门攻击。通过在训练样本中注入后门触发器，可以在目标DNNs中嵌入后门，这会导致目标DNNs对附有后门触发器的输入进行错误分类。近期的后门检测方法通常需要访问原始被污染的训练数据、目标DNNs的参数或对每个给定输入的预测置信度，这在许多实际应用中是不现实的，例如在设备上部署的DNNs。我们解决了黑盒硬标签后门检测问题，其中DNN是一个完全的黑盒，只能访问其最终输出标签。我们从优化的角度来解决这个问题，并表明后门检测的目标受到对抗性目标的限制。进一步的理论和实证研究表明，这种对抗性目标导致了一个分布高度偏斜的解决方案；在后门感染样本的对抗性映射中经常观察到一种奇异性，我们称之为对抗性奇异性现象。基于这一观察，我们提出了对抗性极值分析（AEVA）算法来检测黑盒神经网络中的后门。AEVA算法基于对抗性映射的极值分析，由于黑盒硬标签约束，该映射是通过蒙特卡洛梯度估计计算的。通过跨三个流行任务和后门攻击的广泛实验证明，我们的方法在黑盒硬标签场景下检测后门攻击是有效的。",
        "领域": "深度学习安全、对抗性攻击防御、黑盒模型检测",
        "问题": "解决在黑盒硬标签条件下检测深度神经网络中的后门攻击的问题",
        "动机": "现有的后门检测方法需要访问模型的内部信息或训练数据，这在许多实际应用中不可行，因此需要一种仅依赖模型最终输出标签的黑盒检测方法",
        "方法": "提出基于对抗性极值分析（AEVA）的算法，通过分析对抗性映射中的奇异性现象来检测后门",
        "关键词": [
            "黑盒检测",
            "后门攻击",
            "对抗性极值分析",
            "深度神经网络安全",
            "硬标签场景"
        ],
        "涉及的技术概念": {
            "对抗性极值分析（AEVA）": "一种基于对抗性映射极值分析的算法，用于检测黑盒神经网络中的后门",
            "对抗性奇异性现象": "在后门感染样本的对抗性映射中观察到的奇异性现象，是AEVA算法检测后门的关键依据",
            "蒙特卡洛梯度估计": "由于黑盒硬标签约束，用于计算对抗性映射的技术手段"
        },
        "success": true
    },
    {
        "order": 27,
        "title": "A fast and accurate splitting method for optimal transport: analysis and implementation",
        "html": "https://iclr.cc//virtual/2022/poster/6984",
        "abstract": "We develop a fast and reliable method for solving large-scale optimal transport (OT) problems at an unprecedented combination of speed and accuracy. Built on the celebrated Douglas-Rachford splitting technique, our method tackles the original OT problem directly instead of solving an approximate regularized problem, as many state-of-the-art techniques do. This allows us to provide sparse transport plans and avoid numerical issues of methods that use entropic regularization. The algorithm has the same cost per iteration as the popular Sinkhorn method, and each iteration can be executed efficiently, in parallel. The proposed method enjoys an iteration complexity $O(1/\\epsilon)$ compared to the best-known $O(1/\\epsilon^2)$ of the Sinkhorn method. In addition, we establish a linear convergence rate for our formulation of the OT problem. We detail an efficient GPU implementation of the proposed method that maintains a primal-dual stopping criterion at no extra cost. Substantial experiments demonstrate the effectiveness of our method, both in terms of computation times and robustness.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "一种快速且准确的最优传输分割方法：分析与实现",
        "摘要翻译": "我们开发了一种快速可靠的方法，用于解决大规模最优传输（OT）问题，实现了前所未有的速度和准确性的结合。基于著名的Douglas-Rachford分割技术，我们的方法直接解决原始OT问题，而不是像许多最先进的技术那样解决近似正则化问题。这使我们能够提供稀疏的传输计划，并避免使用熵正则化方法的数值问题。该算法每次迭代的成本与流行的Sinkhorn方法相同，并且每次迭代可以高效并行执行。与Sinkhorn方法的最佳已知复杂度O(1/ε²)相比，所提出的方法享有O(1/ε)的迭代复杂度。此外，我们为OT问题的表述建立了线性收敛速度。我们详细介绍了所提出方法的高效GPU实现，该实现无需额外成本即可保持原始-对偶停止准则。大量实验证明了我们方法的有效性，无论是在计算时间还是鲁棒性方面。",
        "领域": "最优传输理论, 数值优化, 并行计算",
        "问题": "解决大规模最优传输问题在速度和准确性上的挑战",
        "动机": "开发一种能够直接解决原始最优传输问题的方法，避免现有技术中近似正则化带来的数值问题和稀疏性不足",
        "方法": "基于Douglas-Rachford分割技术，开发了一种直接解决原始最优传输问题的算法，实现了高效的并行计算和线性收敛速度",
        "关键词": [
            "最优传输",
            "Douglas-Rachford分割",
            "并行计算",
            "GPU实现",
            "稀疏传输计划"
        ],
        "涉及的技术概念": {
            "Douglas-Rachford分割技术": "用于直接解决原始最优传输问题的核心算法，保证了方法的快速收敛和高效性",
            "熵正则化": "现有技术中常用的方法，但可能导致数值问题和稀疏性不足，本方法避免了其使用",
            "原始-对偶停止准则": "在GPU实现中无需额外成本即可维持的准则，确保了算法的鲁棒性和效率"
        }
    },
    {
        "order": 28,
        "title": "A Fine-Grained Analysis on Distribution Shift",
        "html": "https://iclr.cc//virtual/2022/poster/7002",
        "abstract": "Robustness to distribution shifts is critical for deploying machine learning models in the real world. Despite this necessity, there has been little work in defining the underlying mechanisms that cause these shifts and evaluating the robustness of algorithms across multiple, different distribution shifts. To this end, we introduce a framework that enables fine-grained analysis of various distribution shifts. We provide a holistic analysis of current state-of-the-art methods by evaluating 19 distinct methods grouped into five categories across both synthetic and real-world datasets.  Overall, we train more than 85K models. Our experimental framework can be easily extended to include new methods, shifts, and datasets. We find, unlike previous work (Gulrajani & Lopez-Paz, 2021), that progress has been made over a standard ERM baseline; in particular, pretraining and augmentations (learned or heuristic) offer large gains in many cases. However, the best methods are not consistent over different datasets and shifts. We will open source our experimental framework, allowing future work to evaluate new methods over multiple shifts to obtain a more complete picture of a method's effectiveness. Code is available at github.com/deepmind/distribution_shift_framework.",
        "conference": "ICLR",
        "中文标题": "分布偏移的细粒度分析",
        "摘要翻译": "分布偏移的鲁棒性对于在现实世界中部署机器学习模型至关重要。尽管这一需求迫切，但在定义导致这些偏移的基本机制以及评估算法在多种不同分布偏移下的鲁棒性方面，相关工作却很少。为此，我们引入了一个框架，能够对各种分布偏移进行细粒度分析。我们通过对合成和真实世界数据集中的19种不同方法（分为五类）进行评估，提供了对当前最先进方法的全面分析。总的来说，我们训练了超过85K个模型。我们的实验框架可以轻松扩展，以包含新方法、偏移和数据集。我们发现，与之前的工作（Gulrajani & Lopez-Paz, 2021）不同，相对于标准的ERM基线已经取得了进展；特别是，预训练和增强（学习或启发式）在许多情况下提供了大的增益。然而，最好的方法在不同的数据集和偏移上并不一致。我们将开源我们的实验框架，允许未来的工作在多个偏移上评估新方法，以获得方法有效性的更完整图景。代码可在github.com/deepmind/distribution_shift_framework获取。",
        "领域": "机器学习鲁棒性、分布偏移分析、模型泛化能力",
        "问题": "评估和提高机器学习模型在分布偏移下的鲁棒性",
        "动机": "由于缺乏对分布偏移基本机制的定义和评估算法在多种不同分布偏移下鲁棒性的研究，需要开发一个框架来进行细粒度分析",
        "方法": "引入一个框架，对19种不同方法（分为五类）在合成和真实世界数据集上进行评估，训练超过85K个模型",
        "关键词": [
            "分布偏移",
            "鲁棒性评估",
            "机器学习模型",
            "预训练",
            "数据增强"
        ],
        "涉及的技术概念": {
            "分布偏移": "指模型训练数据和实际应用数据之间的分布差异，影响模型在实际应用中的表现",
            "鲁棒性评估": "评估模型在面对分布偏移等挑战时的表现稳定性",
            "预训练": "在特定任务上预先训练模型，以提高其在目标任务上的表现和鲁棒性"
        },
        "success": true
    },
    {
        "order": 29,
        "title": "A Fine-Tuning Approach to Belief State Modeling",
        "html": "https://iclr.cc//virtual/2022/poster/6730",
        "abstract": "We investigate the challenge of modeling the belief state of a partially observable Markov system, given sample-access to its dynamics model. This problem setting is often approached using parametric sequential generative modeling methods. However, these methods do not leverage any additional computation at inference time to increase their accuracy. Moreover, applying these methods to belief state modeling in certain multi-agent settings would require passing policies into the belief model---at the time of writing, there have been no successful demonstrations of this. Toward addressing these shortcomings, we propose an inference-time improvement framework for parametric sequential generative modeling methods called belief fine-tuning (BFT). BFT leverages approximate dynamic programming in the form of fine-tuning to determine the model parameters at each time step. It can improve the accuracy of the belief model at test time because it specializes the model to the space of local observations. Furthermore, because this specialization occurs after the action or policy has already been decided, BFT does not require the belief model to process it as input. As a result of the latter point, BFT enables, for the first time, approximate public belief state search in imperfect-information games where the number of possible information states is too large to track tabularly. We exhibit these findings on large-scale variants of the benchmark game Hanabi.",
        "conference": "ICLR",
        "中文标题": "一种精细调整的信念状态建模方法",
        "摘要翻译": "我们研究了在给定对其动态模型的样本访问的情况下，建模部分可观察马尔可夫系统的信念状态的挑战。这个问题设置通常使用参数化顺序生成建模方法来处理。然而，这些方法在推理时并未利用任何额外的计算来提高其准确性。此外，将这些方法应用于某些多智能体设置中的信念状态建模将需要将策略传递到信念模型中——在撰写本文时，尚未有成功的演示。为了解决这些不足，我们提出了一个推理时改进框架，称为信念精细调整（BFT），用于参数化顺序生成建模方法。BFT利用近似动态编程的形式进行精细调整，以确定每个时间步的模型参数。它可以在测试时提高信念模型的准确性，因为它使模型专门化于局部观察的空间。此外，由于这种专门化发生在行动或策略已经决定之后，BFT不需要信念模型将其作为输入处理。由于后一点，BFT首次实现了在不完全信息游戏中近似公共信念状态搜索，其中可能的信息状态数量太大，无法以表格形式跟踪。我们在基准游戏Hanabi的大规模变体上展示了这些发现。",
        "领域": "强化学习、多智能体系统、不完全信息博弈",
        "问题": "如何在部分可观察的马尔可夫系统中有效地建模信念状态，尤其是在多智能体设置中。",
        "动机": "现有的参数化顺序生成建模方法在推理时未能利用额外计算提高准确性，且在多智能体设置中应用时需要将策略传递到信念模型中，这尚未有成功案例。",
        "方法": "提出了一个称为信念精细调整（BFT）的推理时改进框架，利用近似动态编程进行精细调整，以确定每个时间步的模型参数。",
        "关键词": [
            "信念状态建模",
            "精细调整",
            "不完全信息博弈",
            "多智能体系统",
            "近似动态编程"
        ],
        "涉及的技术概念": {
            "信念精细调整（BFT）": "一种推理时改进框架，用于参数化顺序生成建模方法，通过近似动态编程进行精细调整，提高信念模型的准确性。",
            "部分可观察马尔可夫系统": "一种系统模型，其中系统的状态不能完全被观察，需要通过信念状态来估计。",
            "近似动态编程": "一种优化技术，用于在无法精确求解的情况下，近似求解动态规划问题。"
        },
        "success": true
    },
    {
        "order": 30,
        "title": "A First-Occupancy Representation for Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6717",
        "abstract": "Both animals and artificial agents benefit from state representations that support rapid transfer of learning across tasks and which enable them to efficiently traverse their environments to reach rewarding states.  The successor representation (SR), which measures the expected cumulative, discounted state occupancy under a fixed policy, enables efficient transfer to different reward structures in an otherwise constant Markovian environment and has been hypothesized to underlie aspects of biological behavior and neural activity.  However, in the real world, rewards may only be available for consumption once, may shift location, or agents may simply aim to reach goal states as rapidly as possible without the constraint of artificially imposed task horizons. In such cases, the most behaviorally-relevant representation would carry information about when the agent was likely to first reach states of interest, rather than how often it should expect to visit them over a potentially infinite time span.  To reflect such demands, we introduce the first-occupancy representation (FR), which measures the expected temporal discount to the first time a state is accessed.  We demonstrate that the FR facilitates exploration, the selection of efficient paths to desired states, allows the agent, under certain conditions, to plan provably optimal trajectories defined by a sequence of subgoals, and induces similar behavior to animals avoiding threatening stimuli.",
        "conference": "ICLR",
        "中文标题": "强化学习中的首次占用表示",
        "摘要翻译": "无论是动物还是人工代理，都能从支持跨任务学习快速转移的状态表示中受益，这种表示使它们能够高效地穿越环境到达有奖励的状态。后继表示（SR）测量了在固定策略下预期的累积、折现状态占用，使得在马尔可夫环境中能够高效地转移到不同的奖励结构，并被假设为生物行为和神经活动的基础。然而，在现实世界中，奖励可能只能消费一次，可能改变位置，或者代理可能仅仅旨在尽可能快地到达目标状态，而不受人为设定的任务范围的限制。在这种情况下，最具行为相关性的表示将携带关于代理首次到达感兴趣状态的预期时间信息，而不是在可能无限的时间跨度内预期访问它们的频率。为了反映这些需求，我们引入了首次占用表示（FR），它测量了首次访问状态的预期时间折现。我们证明了FR促进了探索，选择了到达期望状态的有效路径，允许代理在特定条件下规划由一系列子目标定义的可证明最优轨迹，并诱导类似于动物避免威胁刺激的行为。",
        "领域": "强化学习",
        "问题": "如何在强化学习中更有效地表示状态以支持快速学习转移和高效环境探索",
        "动机": "研究旨在解决在现实世界中，由于奖励的可用性、位置变化或任务目标的快速达成需求，传统的后继表示（SR）可能不足以有效支持代理行为的问题",
        "方法": "引入首次占用表示（FR），测量首次访问状态的预期时间折现，以支持更高效的学习和探索",
        "关键词": [
            "强化学习",
            "状态表示",
            "首次占用表示",
            "探索效率",
            "最优轨迹规划"
        ],
        "涉及的技术概念": {
            "后继表示（SR）": "测量在固定策略下预期的累积、折现状态占用，支持跨任务学习快速转移",
            "首次占用表示（FR）": "测量首次访问状态的预期时间折现，支持更高效的学习和探索",
            "马尔可夫环境": "一种状态转移仅依赖于当前状态和采取的动作的环境模型，为强化学习中的基本假设之一"
        },
        "success": true
    },
    {
        "order": 31,
        "title": "A General Analysis of Example-Selection for Stochastic Gradient Descent",
        "html": "https://iclr.cc//virtual/2022/poster/7168",
        "abstract": "Training example order in SGD has long been known to affect convergence rate. Recent results show that accelerated rates are possible in a variety of cases for permutation-based sample orders, in which each example from the training set is used once before any example is reused. In this paper, we develop a broad condition on the sequence of examples used by SGD that is sufficient to prove tight convergence rates in both strongly convex and non-convex settings. We show that our approach suffices to recover, and in some cases improve upon, previous state-of-the-art analyses for four known example-selection schemes: (1) shuffle once, (2) random reshuffling, (3) random reshuffling with data echoing, and (4) Markov Chain Gradient Descent. Motivated by our theory, we propose two new example-selection approaches. First, using quasi-Monte-Carlo methods, we achieve unprecedented accelerated convergence rates for learning with data augmentation. Second, we greedily choose a fixed scan-order to minimize the metric used in our condition and show that we can obtain more accurate solutions from the same number of epochs of SGD. We conclude by empirically demonstrating the utility of our approach for both convex linear-model and deep learning tasks. Our code is available at: https://github.com/EugeneLYC/qmc-ordering.",
        "conference": "ICLR",
        "中文标题": "随机梯度下降中样本选择的一般性分析",
        "摘要翻译": "长期以来，人们已经知道SGD中训练样本的顺序会影响收敛速度。最近的研究结果表明，在多种情况下，基于排列的样本顺序（即在重用任何样本之前，每个训练集中的样本被使用一次）可以实现加速收敛。在本文中，我们为SGD使用的样本序列开发了一个广泛的条件，这个条件足以证明在强凸和非凸设置下的紧密收敛速度。我们展示了我们的方法足以恢复，并在某些情况下改进，四种已知样本选择方案的最先进分析：（1）单次洗牌，（2）随机重新洗牌，（3）带有数据回响的随机重新洗牌，以及（4）马尔可夫链梯度下降。受我们理论的启发，我们提出了两种新的样本选择方法。首先，使用准蒙特卡洛方法，我们实现了数据增强学习前所未有的加速收敛速度。其次，我们贪婪地选择一个固定的扫描顺序，以最小化我们条件中使用的度量，并展示我们可以从相同数量的SGD周期中获得更准确的解决方案。最后，我们通过实证展示了我们的方法在凸线性模型和深度学习任务中的实用性。我们的代码可在https://github.com/EugeneLYC/qmc-ordering获取。",
        "领域": "优化算法",
        "问题": "如何选择和排序训练样本以优化随机梯度下降（SGD）的收敛速度",
        "动机": "探索和验证不同的样本选择和排序策略对SGD收敛速度的影响，以提高训练效率和模型性能",
        "方法": "开发了一个广泛的条件来评估样本序列对SGD收敛速度的影响，并基于此条件提出了两种新的样本选择方法：使用准蒙特卡洛方法和贪婪选择固定扫描顺序",
        "关键词": [
            "随机梯度下降",
            "样本选择",
            "收敛速度",
            "准蒙特卡洛方法",
            "贪婪算法"
        ],
        "涉及的技术概念": {
            "随机梯度下降（SGD）": "一种优化算法，通过迭代地使用训练数据的子集来更新模型参数，以减少计算成本",
            "准蒙特卡洛方法": "一种数值积分方法，用于生成低差异序列，以提高样本选择的效率，从而加速SGD的收敛",
            "贪婪算法": "一种算法设计策略，通过在每一步选择当前最优的选项来构建解决方案，用于选择固定扫描顺序以优化SGD的性能"
        },
        "success": true
    },
    {
        "order": 32,
        "title": "A generalization of the randomized singular value decomposition",
        "html": "https://iclr.cc//virtual/2022/poster/7116",
        "abstract": "The randomized singular value decomposition (SVD) is a popular and effective algorithm for computing a near-best rank $k$ approximation of a matrix $A$ using matrix-vector products with standard Gaussian vectors. Here, we generalize the theory of randomized SVD to multivariate Gaussian vectors, allowing one to incorporate prior knowledge of $A$ into the algorithm. This enables us to explore the continuous analogue of the randomized SVD for Hilbert--Schmidt (HS) operators using operator-function products with functions drawn from a Gaussian process (GP). We then construct a new covariance kernel for GPs, based on weighted Jacobi polynomials, which allows us to rapidly sample the GP and control the smoothness of the randomly generated functions. Numerical examples on matrices and HS operators demonstrate the applicability of the algorithm.",
        "conference": "ICLR",
        "中文标题": "随机奇异值分解的一种推广",
        "摘要翻译": "随机奇异值分解（SVD）是一种流行且有效的算法，用于通过标准高斯向量的矩阵-向量乘积计算矩阵$A$的近似最佳秩$k$近似。在此，我们将随机SVD的理论推广到多元高斯向量，允许将$A$的先验知识融入算法中。这使我们能够探索使用从高斯过程（GP）中抽取的函数进行算子-函数乘积的随机SVD的连续类比，用于Hilbert--Schmidt（HS）算子。然后，我们基于加权Jacobi多项式为GPs构建了一个新的协方差核，这使我们能够快速采样GP并控制随机生成函数的平滑度。在矩阵和HS算子上的数值例子证明了该算法的适用性。",
        "领域": "数值线性代数、机器学习、信号处理",
        "问题": "如何将随机奇异值分解算法推广到多元高斯向量，并应用于Hilbert--Schmidt算子",
        "动机": "为了将先验知识融入随机SVD算法，并探索其在更广泛算子理论中的应用",
        "方法": "推广随机SVD理论到多元高斯向量，构建基于加权Jacobi多项式的新协方差核以控制生成函数的平滑度",
        "关键词": [
            "随机奇异值分解",
            "多元高斯向量",
            "Hilbert--Schmidt算子",
            "高斯过程",
            "加权Jacobi多项式"
        ],
        "涉及的技术概念": {
            "随机奇异值分解": "一种通过随机采样技术近似计算矩阵奇异值分解的高效算法",
            "多元高斯向量": "推广了标准高斯向量，允许融入先验知识，提高算法的灵活性和适用性",
            "Hilbert--Schmidt算子": "一种在无限维空间中定义的线性算子，随机SVD的连续类比在此类算子上的应用"
        },
        "success": true
    },
    {
        "order": 33,
        "title": "A Generalized Weighted Optimization Method for Computational Learning and Inversion",
        "html": "https://iclr.cc//virtual/2022/poster/7110",
        "abstract": "The generalization capacity of various machine learning models exhibits different phenomena in the under- and over-parameterized regimes. In this paper, we focus on regression models such as feature regression and kernel regression and analyze a generalized weighted least-squares optimization method for computational learning and inversion with noisy data. The highlight of the proposed framework is that we allow weighting in both the parameter space and the data space. The weighting scheme encodes both a priori knowledge on the object to be learned and a strategy to weight the contribution of different data points in the loss function. Here, we characterize the impact of the weighting scheme on the generalization error of the learning method, where we derive explicit generalization errors for the random Fourier feature model in both the under- and over-parameterized regimes. For more general feature maps, error bounds are provided based on the singular values of the feature matrix. We demonstrate that appropriate weighting from prior knowledge can improve the generalization capability of the learned model.",
        "conference": "ICLR",
        "中文标题": "一种用于计算学习和反演的广义加权优化方法",
        "摘要翻译": "各种机器学习模型的泛化能力在欠参数化和过参数化机制下表现出不同的现象。本文中，我们专注于回归模型，如特征回归和核回归，并分析了一种用于含噪声数据的计算学习和反演的广义加权最小二乘优化方法。所提出框架的亮点在于我们允许在参数空间和数据空间中进行加权。加权方案既编码了关于待学习对象的先验知识，也编码了在损失函数中加权不同数据点贡献的策略。在此，我们刻画了加权方案对学习方法泛化误差的影响，其中我们推导出了随机傅里叶特征模型在欠参数化和过参数化机制下的显式泛化误差。对于更一般的特征映射，基于特征矩阵的奇异值提供了误差界限。我们证明了来自先验知识的适当加权可以提高学习模型的泛化能力。",
        "领域": "回归分析, 机器学习理论, 优化方法",
        "问题": "研究在含噪声数据下，如何通过加权优化方法提高回归模型的泛化能力。",
        "动机": "探索加权方案在参数空间和数据空间中的应用，以提升机器学习模型在欠参数化和过参数化机制下的泛化性能。",
        "方法": "提出了一种广义加权最小二乘优化方法，允许在参数空间和数据空间中进行加权，分析了加权方案对泛化误差的影响，并推导了特定模型下的显式泛化误差。",
        "关键词": [
            "加权优化",
            "泛化误差",
            "回归模型",
            "先验知识",
            "特征映射"
        ],
        "涉及的技术概念": {
            "广义加权最小二乘优化方法": "一种允许在参数空间和数据空间中进行加权的优化方法，用于提高模型的泛化能力。",
            "泛化误差": "衡量模型在未见数据上表现的能力，本文分析了加权方案对其的影响。",
            "随机傅里叶特征模型": "一种特定的特征映射方法，本文推导了其在欠参数化和过参数化机制下的显式泛化误差。"
        },
        "success": true
    },
    {
        "order": 34,
        "title": "A global convergence theory for deep ReLU implicit networks via over-parameterization",
        "html": "https://iclr.cc//virtual/2022/poster/6773",
        "abstract": "Implicit deep learning has received increasing attention recently due to the fact that it generalizes the recursive prediction rule of many commonly used neural network architectures. Its prediction rule is provided implicitly based on the solution of an equilibrium equation. Although a line of recent empirical studies has demonstrated its superior performances, the theoretical understanding of implicit neural networks is limited. In general, the equilibrium equation may not be well-posed during the training. As a result, there is no guarantee that a vanilla (stochastic) gradient descent (SGD) training nonlinear implicit neural networks can converge. This paper fills the gap by analyzing the gradient flow of Rectified Linear Unit (ReLU) activated implicit neural networks. For an $m$ width implicit neural network with ReLU activation and $n$ training samples, we show that a randomly initialized gradient descent converges to a global minimum at a linear rate for the square loss function if the implicit neural network is over-parameterized. It is worth noting that, unlike existing works on the convergence of (S)GD on finite-layer over-parameterized neural networks, our convergence results hold for implicit neural networks, where the number of layers is infinite.",
        "conference": "ICLR",
        "中文标题": "通过过参数化实现深度ReLU隐式网络的全局收敛理论",
        "摘要翻译": "隐式深度学习近年来因其能够泛化许多常用神经网络架构的递归预测规则而受到越来越多的关注。其预测规则基于平衡方程的解隐式提供。尽管最近的一系列实证研究已经证明了其卓越的性能，但对隐式神经网络的理论理解仍然有限。通常，平衡方程在训练过程中可能不适定。因此，无法保证普通的（随机）梯度下降（SGD）训练非线性隐式神经网络能够收敛。本文通过分析整流线性单元（ReLU）激活的隐式神经网络的梯度流来填补这一空白。对于一个具有ReLU激活和n个训练样本的m宽度隐式神经网络，我们表明，如果隐式神经网络是过参数化的，随机初始化的梯度下降会以线性速率收敛到平方损失函数的全局最小值。值得注意的是，与现有关于有限层过参数化神经网络上（S）GD收敛的工作不同，我们的收敛结果适用于隐式神经网络，其中层数是无限的。",
        "领域": "深度学习理论、神经网络优化、隐式深度学习",
        "问题": "解决隐式神经网络在训练过程中可能不适定，导致普通梯度下降无法保证收敛的问题。",
        "动机": "为了填补隐式神经网络理论理解的空白，特别是在过参数化条件下，如何保证梯度下降能够收敛到全局最小值。",
        "方法": "通过分析ReLU激活的隐式神经网络的梯度流，证明在过参数化条件下，随机初始化的梯度下降能够以线性速率收敛到全局最小值。",
        "关键词": [
            "隐式深度学习",
            "过参数化",
            "全局收敛",
            "ReLU激活",
            "梯度下降"
        ],
        "涉及的技术概念": {
            "隐式神经网络": "一种预测规则基于平衡方程解的神经网络架构，能够泛化许多常用神经网络的递归预测规则。",
            "过参数化": "指神经网络的参数数量远大于训练样本数，有助于梯度下降找到全局最小值。",
            "梯度流": "用于分析梯度下降动态的连续时间近似，有助于理解优化过程的行为。"
        },
        "success": true
    },
    {
        "order": 35,
        "title": "A Johnson-Lindenstrauss Framework for Randomly Initialized CNNs",
        "html": "https://iclr.cc//virtual/2022/poster/7014",
        "abstract": "How does the geometric representation of a dataset change after the application of each randomly initialized layer of a neural network? The celebrated Johnson-Lindenstrauss lemma answers this question for linear fully-connected neural networks (FNNs), stating that the geometry is essentially preserved. For FNNs with the ReLU activation, the angle between two input contracts according to a known mapping. The question for non-linear convolutional neural networks (CNNs) becomes much more intricate. To answer this question, we introduce a geometric framework. For linear CNNs, we show that the Johnson--Lindenstrauss lemma continues to hold, namely, that the angle between two inputs is preserved. For CNNs with ReLU activation, on the other hand, the behavior is richer: The angle between the outputs contracts, where the level of contraction depends on the nature of the inputs. In particular, after one layer, the geometry of natural images is essentially preserved, whereas for Gaussian correlated inputs, CNNs exhibit the same contracting behavior as FNNs with ReLU activation. ",
        "conference": "ICLR",
        "中文标题": "随机初始化CNNs的Johnson-Lindenstrauss框架",
        "摘要翻译": "数据集在经过神经网络的每一随机初始化层应用后，其几何表示如何变化？著名的Johnson-Lindenstrauss引理为线性全连接神经网络（FNNs）回答了这个问题，指出几何性质基本保持不变。对于带有ReLU激活函数的FNNs，两个输入之间的角度根据已知的映射收缩。对于非线性卷积神经网络（CNNs），这个问题变得复杂得多。为了回答这个问题，我们引入了一个几何框架。对于线性CNNs，我们证明了Johnson-Lindenstrauss引理仍然成立，即两个输入之间的角度保持不变。另一方面，对于带有ReLU激活函数的CNNs，行为更为丰富：输出之间的角度收缩，收缩的程度取决于输入的性质。特别是，经过一层后，自然图像的几何性质基本保持不变，而对于高斯相关输入，CNNs表现出与带有ReLU激活函数的FNNs相同的收缩行为。",
        "领域": "深度学习理论、卷积神经网络、几何深度学习",
        "问题": "研究随机初始化的卷积神经网络（CNNs）在处理数据时如何改变数据集的几何表示。",
        "动机": "探索非线性卷积神经网络（CNNs）与线性全连接神经网络（FNNs）在保持数据几何性质方面的差异，特别是在随机初始化条件下。",
        "方法": "引入一个几何框架来分析线性CNNs和带有ReLU激活函数的CNNs对输入数据几何性质的影响。",
        "关键词": [
            "Johnson-Lindenstrauss引理",
            "随机初始化",
            "卷积神经网络",
            "几何表示",
            "ReLU激活函数"
        ],
        "涉及的技术概念": {
            "Johnson-Lindenstrauss引理": "用于分析高维数据在降维过程中几何性质保持的理论基础。",
            "随机初始化": "神经网络训练前权重初始化的方法，影响网络的初始行为和训练动态。",
            "ReLU激活函数": "一种常用的非线性激活函数，能够引入网络的非线性特性，影响数据的几何变换。"
        },
        "success": true
    },
    {
        "order": 36,
        "title": "Almost Tight L0-norm Certified Robustness of Top-k Predictions against Adversarial Perturbations",
        "html": "https://iclr.cc//virtual/2022/poster/6398",
        "abstract": "Top-$k$ predictions are used in many real-world applications such as machine learning as a service, recommender systems, and web searches. $\\ell_0$-norm adversarial perturbation characterizes an attack that arbitrarily modifies some features of an input such that a classifier makes an incorrect prediction for the perturbed input. $\\ell_0$-norm adversarial perturbation is easy to interpret and can be implemented in the physical world. Therefore, certifying  robustness of top-$k$ predictions against $\\ell_0$-norm adversarial perturbation is important. However, existing studies either focused on certifying $\\ell_0$-norm robustness of top-$1$ predictions or  $\\ell_2$-norm robustness of top-$k$ predictions. In this work, we aim to bridge the gap. Our approach is based on randomized smoothing, which builds a provably robust classifier from an arbitrary classifier via randomizing an input. Our major theoretical contribution is an almost tight $\\ell_0$-norm certified robustness guarantee for top-$k$ predictions. We empirically evaluate our method on CIFAR10 and ImageNet. For instance, our method can build a classifier that achieves a certified top-3 accuracy of 69.2\\% on ImageNet when an attacker can arbitrarily perturb 5 pixels of a testing image. ",
        "conference": "ICLR",
        "中文标题": "针对对抗性扰动的Top-k预测几乎紧致的L0范数认证鲁棒性",
        "摘要翻译": "Top-k预测在许多实际应用中如机器学习即服务、推荐系统和网络搜索中被广泛使用。L0范数对抗性扰动描述了一种攻击，它任意修改输入的某些特征，使得分类器对扰动后的输入做出错误的预测。L0范数对抗性扰动易于解释，并且可以在物理世界中实现。因此，认证Top-k预测对L0范数对抗性扰动的鲁棒性非常重要。然而，现有的研究要么专注于认证Top-1预测的L0范数鲁棒性，要么专注于Top-k预测的L2范数鲁棒性。在这项工作中，我们旨在填补这一空白。我们的方法基于随机平滑，通过随机化输入从任意分类器构建一个可证明鲁棒的分类器。我们的主要理论贡献是为Top-k预测提供了一个几乎紧致的L0范数认证鲁棒性保证。我们在CIFAR10和ImageNet上对我们的方法进行了实证评估。例如，当攻击者可以任意扰动测试图像的5个像素时，我们的方法可以构建一个在ImageNet上实现69.2%认证Top-3准确率的分类器。",
        "领域": "对抗性机器学习、图像分类、安全认证",
        "问题": "如何认证Top-k预测对L0范数对抗性扰动的鲁棒性",
        "动机": "填补现有研究中Top-k预测对L0范数对抗性扰动鲁棒性认证的空白",
        "方法": "基于随机平滑技术，通过随机化输入构建可证明鲁棒的分类器",
        "关键词": [
            "L0范数鲁棒性",
            "Top-k预测",
            "随机平滑",
            "对抗性扰动",
            "安全认证"
        ],
        "涉及的技术概念": {
            "L0范数对抗性扰动": "描述了一种攻击方式，通过修改输入的部分特征来误导分类器，这种扰动易于解释和实现",
            "随机平滑": "一种技术，通过随机化输入来构建鲁棒的分类器，提高模型对抗性扰动的抵抗能力",
            "Top-k预测": "在分类任务中，模型预测的前k个最可能的类别，广泛应用于推荐系统、搜索等领域"
        },
        "success": true
    },
    {
        "order": 37,
        "title": "A Loss Curvature Perspective on Training Instabilities of Deep Learning Models",
        "html": "https://iclr.cc//virtual/2022/poster/6462",
        "abstract": "In this work, we study the evolution of the loss Hessian across many classification tasks in order to understand the effect the curvature of the loss has on the training dynamics. Whereas prior work has focused on how different learning rates affect the loss Hessian observed during training, we also analyze the effects of model initialization, architectural choices, and common training heuristics such as gradient clipping and learning rate warmup. Our results demonstrate that successful model and hyperparameter choices allow the early optimization trajectory to either avoid---or navigate out of---regions of high curvature and into flatter regions that tolerate a higher learning rate. Our results suggest a unifying perspective on how disparate mitigation strategies for training instability ultimately address the same underlying failure mode of neural network optimization, namely poor conditioning. Inspired by the conditioning perspective, we show that learning rate warmup can improve training stability just as much as batch normalization, layer normalization, MetaInit, GradInit, and Fixup initialization.",
        "conference": "ICLR",
        "中文标题": "深度学习模型训练不稳定性的损失曲率视角",
        "摘要翻译": "在本工作中，我们研究了多个分类任务中损失Hessian矩阵的演变，以理解损失曲率对训练动态的影响。尽管先前的工作主要集中在不同学习率如何影响训练期间观察到的损失Hessian矩阵上，我们还分析了模型初始化、架构选择以及常见训练启发式方法（如梯度裁剪和学习率预热）的影响。我们的结果表明，成功的模型和超参数选择允许早期优化轨迹要么避免——要么从高曲率区域导航出来——进入能够容忍更高学习率的平坦区域。我们的结果提出了一个统一的视角，说明不同的训练不稳定性缓解策略最终如何解决神经网络优化的同一基础失败模式，即不良条件。受条件视角的启发，我们展示了学习率预热可以像批归一化、层归一化、MetaInit、GradInit和Fixup初始化一样，显著提高训练稳定性。",
        "领域": "深度学习优化、神经网络训练、超参数调优",
        "问题": "理解损失曲率如何影响深度学习模型的训练动态，并探索缓解训练不稳定性的方法。",
        "动机": "研究不同模型和超参数选择如何通过影响损失曲率来改善训练稳定性，为解决神经网络优化中的不良条件问题提供新视角。",
        "方法": "通过分析损失Hessian矩阵的演变，研究模型初始化、架构选择及训练启发式方法对训练动态的影响，并提出学习率预热作为一种有效的稳定性提升方法。",
        "关键词": [
            "损失曲率",
            "训练不稳定性",
            "学习率预热",
            "Hessian矩阵",
            "优化轨迹"
        ],
        "涉及的技术概念": {
            "损失Hessian矩阵": "用于衡量损失函数的曲率，影响模型训练的稳定性和效率。",
            "学习率预热": "一种训练启发式方法，通过逐步增加学习率来提高训练初期的稳定性。",
            "优化轨迹": "描述模型参数在训练过程中如何变化，影响模型最终性能和训练稳定性。"
        },
        "success": true
    },
    {
        "order": 38,
        "title": "AlphaZero-based Proof Cost Network to Aid Game Solving",
        "html": "https://iclr.cc//virtual/2022/poster/7121",
        "abstract": "The AlphaZero algorithm learns and plays games without hand-crafted expert knowledge. However, since its objective is to play well, we hypothesize that a better objective can be defined for the related but separate task of solving games. This paper proposes a novel approach to solving problems by modifying the training target of the AlphaZero algorithm, such that it prioritizes solving the game quickly, rather than winning. We train a Proof Cost Network (PCN), where proof cost is a heuristic that estimates the amount of work required to solve problems. This matches the general concept of the so-called proof number from proof number search, which has been shown to be well-suited for game solving. We propose two specific training targets. The first finds the shortest path to a solution, while the second estimates the proof cost. We conduct experiments on solving 15x15 Gomoku and 9x9 Killall-Go problems with both MCTS-based and FDFPN solvers. Comparisons between using AlphaZero networks and PCN as heuristics show that PCN can solve more problems.",
        "conference": "ICLR",
        "中文标题": "基于AlphaZero的证明成本网络辅助游戏求解",
        "摘要翻译": "AlphaZero算法无需手工制作的专家知识即可学习和玩游戏。然而，由于其目标是玩得好，我们假设可以为相关但独立的游戏求解任务定义一个更好的目标。本文提出了一种通过修改AlphaZero算法的训练目标来解决问题的新方法，使其优先考虑快速求解游戏，而不是赢得游戏。我们训练了一个证明成本网络（PCN），其中证明成本是一种启发式方法，用于估计解决问题所需的工作量。这与所谓的证明数搜索中的证明数的一般概念相匹配，已被证明非常适合游戏求解。我们提出了两个具体的训练目标。第一个找到解决方案的最短路径，而第二个估计证明成本。我们在15x15的五子棋和9x9的Killall-Go问题上进行了实验，使用了基于MCTS和FDFPN的求解器。使用AlphaZero网络和PCN作为启发式方法的比较表明，PCN可以解决更多问题。",
        "领域": "游戏AI、启发式搜索、强化学习",
        "问题": "如何更有效地求解游戏问题，而不是仅仅优化游戏的玩法。",
        "动机": "AlphaZero算法专注于优化游戏玩法，但在游戏求解任务上可能不是最优的，因此需要一种新的方法来优先考虑快速求解游戏。",
        "方法": "修改AlphaZero算法的训练目标，训练一个证明成本网络（PCN）来估计解决问题所需的工作量，并提出两个具体的训练目标：寻找解决方案的最短路径和估计证明成本。",
        "关键词": [
            "AlphaZero",
            "证明成本网络",
            "游戏求解",
            "启发式搜索",
            "强化学习"
        ],
        "涉及的技术概念": {
            "AlphaZero算法": "一种无需手工制作的专家知识即可学习和玩游戏的算法，本文通过修改其训练目标来优化游戏求解。",
            "证明成本网络（PCN）": "一种启发式方法，用于估计解决问题所需的工作量，与证明数搜索中的证明数概念相匹配。",
            "MCTS和FDFPN求解器": "分别基于蒙特卡洛树搜索和快速深度优先证明数搜索的求解器，用于在实验中评估PCN的效果。"
        },
        "success": true
    },
    {
        "order": 39,
        "title": "Amortized Implicit Differentiation for Stochastic Bilevel Optimization",
        "html": "https://iclr.cc//virtual/2022/poster/6785",
        "abstract": "We study a class of algorithms for solving bilevel optimization problems in both stochastic and deterministic settings when the inner-level objective is strongly convex. Specifically, we consider  algorithms based on inexact implicit differentiation and we exploit a warm-start strategy to amortize the estimation of the exact gradient. We then introduce a unified theoretical framework inspired by the study of singularly perturbed systems to analyze such amortized algorithms. By using this framework, our analysis shows these algorithms to match the computational complexity of oracle methods that have access to an unbiased estimate of the gradient, thus outperforming many existing results for bilevel optimization.We illustrate these findings on synthetic experiments and demonstrate the efficiency of these algorithms on hyper-parameter optimization experiments involving several thousands of variables. ",
        "conference": "ICLR",
        "中文标题": "随机双层优化的摊销隐式微分",
        "摘要翻译": "我们研究了一类算法，用于在内部目标强凸的随机和确定性设置下解决双层优化问题。具体来说，我们考虑基于不精确隐式微分的算法，并利用热启动策略来分摊精确梯度的估计。然后，我们引入了一个受奇异扰动系统研究启发的统一理论框架来分析这些摊销算法。通过使用这个框架，我们的分析表明，这些算法与能够访问梯度无偏估计的oracle方法的计算复杂度相匹配，从而优于许多现有的双层优化结果。我们在合成实验上说明了这些发现，并在涉及数千个变量的超参数优化实验中证明了这些算法的效率。",
        "领域": "优化算法, 机器学习优化, 超参数优化",
        "问题": "解决在内部目标强凸条件下的双层优化问题",
        "动机": "提高双层优化问题的计算效率，特别是在处理大规模数据集时",
        "方法": "基于不精确隐式微分和热启动策略的算法，以及一个受奇异扰动系统启发的理论框架",
        "关键词": [
            "双层优化",
            "隐式微分",
            "热启动策略",
            "计算复杂度",
            "超参数优化"
        ],
        "涉及的技术概念": {
            "隐式微分": "用于在不直接求解内部优化问题的情况下估计梯度",
            "热启动策略": "用于分摊精确梯度的估计，提高计算效率",
            "奇异扰动系统": "启发了分析摊销算法的统一理论框架"
        },
        "success": true
    },
    {
        "order": 40,
        "title": "Amortized Tree Generation for Bottom-up Synthesis Planning and Synthesizable Molecular Design",
        "html": "https://iclr.cc//virtual/2022/poster/6883",
        "abstract": "Molecular design and synthesis planning are two critical steps in the process of molecular discovery that we propose to formulate as a single shared task of conditional synthetic pathway generation. We report an amortized approach to generate synthetic pathways as a Markov decision process conditioned on a target molecular embedding. This approach allows us to conduct synthesis planning in a bottom-up manner and design synthesizable molecules by decoding from optimized conditional codes, demonstrating the potential to solve both problems of design and synthesis simultaneously. The approach leverages neural networks to probabilistically model the synthetic trees, one reaction step at a time, according to reactivity rules encoded in a discrete action space of reaction templates. We train these networks on hundreds of thousands of artificial pathways generated from a pool of purchasable compounds and a list of expert-curated templates. We validate our method with (a) the recovery of molecules using conditional generation, (b) the identification of synthesizable structural analogs, and (c) the optimization of molecular structures given oracle functions relevant to bioactivity and drug discovery.",
        "conference": "ICLR",
        "中文标题": "摊销树生成用于自底向上合成规划与可合成分子设计",
        "摘要翻译": "分子设计与合成规划是分子发现过程中的两个关键步骤，我们提出将其表述为条件合成路径生成的单一共享任务。我们报告了一种摊销方法，将合成路径生成为以目标分子嵌入为条件的马尔可夫决策过程。这种方法允许我们以自底向上的方式进行合成规划，并通过从优化的条件代码解码来设计可合成分子，展示了同时解决设计和合成问题的潜力。该方法利用神经网络根据反应模板离散动作空间中编码的反应性规则，一次一个反应步骤地概率性地建模合成树。我们在由可购买化合物池和专家策划模板列表生成的数十万条人工路径上训练这些网络。我们通过以下方式验证我们的方法：（a）使用条件生成恢复分子，（b）识别可合成的结构类似物，以及（c）给定与生物活性和药物发现相关的预言函数优化分子结构。",
        "领域": "分子设计、合成规划、药物发现",
        "问题": "如何将分子设计与合成规划作为一个统一的任务来处理，以同时解决设计和合成的问题。",
        "动机": "为了更高效地进行分子发现，需要一种能够同时考虑分子设计和合成规划的方法。",
        "方法": "采用摊销方法，将合成路径生成为以目标分子嵌入为条件的马尔可夫决策过程，利用神经网络概率性地建模合成树。",
        "关键词": [
            "摊销树生成",
            "自底向上合成规划",
            "可合成分子设计",
            "马尔可夫决策过程",
            "神经网络建模"
        ],
        "涉及的技术概念": {
            "摊销方法": "用于生成合成路径的技术，允许以目标分子嵌入为条件进行路径生成。",
            "马尔可夫决策过程": "用于建模合成路径的决策过程，每个步骤基于当前状态做出决策。",
            "神经网络建模": "用于概率性地建模合成树，根据反应模板离散动作空间中编码的反应性规则进行。"
        },
        "success": true
    },
    {
        "order": 41,
        "title": "An Agnostic Approach to Federated Learning with Class Imbalance",
        "html": "https://iclr.cc//virtual/2022/poster/6104",
        "abstract": "Federated Learning (FL) has emerged as the tool of choice for training deep models over heterogeneous and decentralized datasets. As a reflection of the experiences from different clients, severe class imbalance issues are observed in real-world FL problems.Moreover, there exists a drastic mismatch between the imbalances from the local and global perspectives, i.e. a local majority class can be the minority of the population. Additionally, the privacy requirement of FL poses an extra challenge, as one should handle class imbalance without identifying the minority class. In this paper we propose a novel agnostic constrained learning formulation to tackle the class imbalance problem in FL, without requiring further information beyond the standard FL objective. A meta algorithm, CLIMB, is designed to solve the target optimization problem, with its convergence property analyzed under certain oracle assumptions. Through an extensive empirical study over various data heterogeneity and class imbalance configurations, we showcase that CLIMB considerably improves the performance in the minority class without compromising the overall accuracy of the classifier, which significantly outperforms previous arts. In fact, we observe the greatest performance boost in the most difficult scenario where every client only holds data from one class. The code can be found here https://github.com/shenzebang/Federated-Learning-Pytorch.",
        "conference": "ICLR",
        "中文标题": "一种联邦学习中类别不平衡问题的不可知论方法",
        "摘要翻译": "联邦学习（FL）已成为在异构和分散数据集上训练深度模型的首选工具。作为不同客户端经验的反映，现实世界的FL问题中观察到了严重的类别不平衡问题。此外，局部和全局视角下的不平衡存在巨大不匹配，即局部多数类可能是全局少数类。此外，FL的隐私要求带来了额外的挑战，因为需要在不确定少数类的情况下处理类别不平衡。本文提出了一种新颖的不可知约束学习公式来解决FL中的类别不平衡问题，无需超出标准FL目标的额外信息。设计了一个元算法CLIMB来解决目标优化问题，并在某些预言机假设下分析了其收敛性。通过对各种数据异构性和类别不平衡配置的广泛实证研究，我们展示了CLIMB在不损害分类器整体准确性的情况下显著提高了少数类的性能，显著优于以往的技术。事实上，在最困难的情况下，即每个客户端仅持有一个类别的数据时，我们观察到了最大的性能提升。代码可以在这里找到：https://github.com/shenzebang/Federated-Learning-Pytorch。",
        "领域": "联邦学习、类别不平衡处理、深度学习优化",
        "问题": "解决联邦学习中的类别不平衡问题，特别是在局部和全局视角下不平衡不匹配及隐私保护要求下的挑战。",
        "动机": "现实世界的联邦学习问题中存在严重的类别不平衡，且局部和全局视角下的不平衡不匹配，加上隐私保护的要求，使得处理这一问题更加复杂。",
        "方法": "提出了一种不可知约束学习公式和元算法CLIMB，用于在不损害整体准确性的情况下提高少数类的性能。",
        "关键词": [
            "联邦学习",
            "类别不平衡",
            "不可知学习",
            "CLIMB算法",
            "隐私保护"
        ],
        "涉及的技术概念": {
            "联邦学习": "一种在分散数据上训练模型的方法，保护数据隐私。",
            "类别不平衡": "数据集中某些类别的样本数量远多于其他类别，影响模型性能。",
            "不可知约束学习": "一种不依赖于特定类别信息的学习方法，用于处理类别不平衡问题。"
        },
        "success": true
    },
    {
        "order": 42,
        "title": "Analytic-DPM: an Analytic Estimate of the Optimal Reverse Variance in Diffusion Probabilistic Models",
        "html": "https://iclr.cc//virtual/2022/poster/7166",
        "abstract": "Diffusion probabilistic models (DPMs) represent a class of powerful generative models. Despite their success, the inference of DPMs is expensive since it generally needs to iterate over thousands of timesteps. A key problem in the inference is to estimate the variance in each timestep of the reverse process. In this work, we present a surprising result that both the optimal reverse variance and the corresponding optimal KL divergence of a DPM have analytic forms w.r.t. its score function. Building upon it, we propose \\textit{Analytic-DPM}, a training-free inference framework that estimates the analytic forms of the variance and KL divergence using the Monte Carlo method and a pretrained score-based model. Further, to correct the potential bias caused by the score-based model, we derive both lower and upper bounds of the optimal variance and clip the estimate for a better result. Empirically, our analytic-DPM improves the log-likelihood of various DPMs, produces high-quality samples, and meanwhile enjoys a $20\\times$ to $80\\times$ speed up.",
        "conference": "ICLR",
        "中文标题": "Analytic-DPM：扩散概率模型中最佳反向方差的解析估计",
        "摘要翻译": "扩散概率模型（DPMs）代表了一类强大的生成模型。尽管它们取得了成功，但DPMs的推理过程成本高昂，因为它通常需要迭代数千个时间步。推理中的一个关键问题是在反向过程的每个时间步中估计方差。在这项工作中，我们提出了一个令人惊讶的结果，即DPM的最佳反向方差和相应的最佳KL散度都有关于其得分函数的解析形式。基于此，我们提出了\textit{Analytic-DPM}，一个无需训练的推理框架，它使用蒙特卡罗方法和预训练的基于得分的模型来估计方差和KL散度的解析形式。此外，为了纠正由基于得分的模型引起的潜在偏差，我们推导了最佳方差的下界和上界，并对估计值进行了裁剪以获得更好的结果。实证上，我们的analytic-DPM提高了各种DPMs的对数似然，生成了高质量的样本，同时享受了20倍到80倍的加速。",
        "领域": "生成模型、扩散模型、概率建模",
        "问题": "扩散概率模型在推理过程中需要估计每个时间步的反向方差，这一过程计算成本高昂。",
        "动机": "为了降低扩散概率模型推理过程中的计算成本，提高效率，同时保持或提升生成样本的质量。",
        "方法": "提出了Analytic-DPM框架，通过解析形式估计最佳反向方差和KL散度，使用蒙特卡罗方法和预训练的基于得分的模型进行估计，并通过推导方差的下界和上界来纠正潜在偏差。",
        "关键词": [
            "扩散概率模型",
            "解析估计",
            "蒙特卡罗方法",
            "得分函数",
            "KL散度"
        ],
        "涉及的技术概念": {
            "扩散概率模型": "一类强大的生成模型，通过逐步添加噪声到数据中，然后学习如何逆转这一过程来生成数据。",
            "得分函数": "在扩散概率模型中，得分函数用于描述数据在噪声添加过程中的梯度，是模型训练和推理的关键。",
            "蒙特卡罗方法": "一种通过随机采样来估计数学期望和方差的计算方法，用于在Analytic-DPM中估计解析形式。"
        },
        "success": true
    },
    {
        "order": 43,
        "title": "Analyzing and Improving the Optimization Landscape of Noise-Contrastive Estimation",
        "html": "https://iclr.cc//virtual/2022/poster/6871",
        "abstract": "Noise-contrastive estimation (NCE) is a statistically consistent method for learning unnormalized probabilistic models. It has been empirically observed that the choice of the noise distribution is crucial for NCE’s performance. However, such observation has never been made formal or quantitative. In fact, it is not even clear whether the difficulties arising from a poorly chosen noise distribution are statistical or algorithmic in nature.In this work, we formally pinpoint reasons for NCE’s poor performance when an inappropriate noise distribution is used. Namely, we prove these challenges arise due to an ill-behaved (more precisely, flat) loss landscape.To address this, we introduce a variant of NCE called \\emph{eNCE} which uses an exponential loss and for which \\emph{normalized gradient descent} addresses the landscape issues \\emph{provably} when the target and noise distributions are in a given exponential family. ",
        "conference": "ICLR",
        "中文标题": "分析与改进噪声对比估计的优化景观",
        "摘要翻译": "噪声对比估计（NCE）是一种统计上一致的学习非归一化概率模型的方法。经验观察表明，噪声分布的选择对NCE的性能至关重要。然而，这种观察从未被正式或定量地表述。事实上，甚至不清楚由于选择不当的噪声分布而产生的困难本质上是统计的还是算法的。在这项工作中，我们正式指出了当使用不适当的噪声分布时NCE性能差的原因。即，我们证明这些挑战是由于行为不良（更准确地说，平坦）的损失景观引起的。为了解决这个问题，我们引入了一种称为eNCE的NCE变体，它使用指数损失，并且当目标和噪声分布处于给定的指数族中时，归一化梯度下降可证明地解决了景观问题。",
        "领域": "概率模型学习、噪声对比估计、优化方法",
        "问题": "噪声对比估计（NCE）在噪声分布选择不当时性能差的问题",
        "动机": "正式识别并解决NCE在不当噪声分布下性能差的原因，特别是由于平坦的损失景观引起的挑战",
        "方法": "引入一种称为eNCE的NCE变体，使用指数损失，并通过归一化梯度下降在目标和噪声分布处于给定指数族时解决景观问题",
        "关键词": [
            "噪声对比估计",
            "优化景观",
            "指数损失",
            "归一化梯度下降",
            "概率模型"
        ],
        "涉及的技术概念": {
            "噪声对比估计（NCE）": "一种统计上一致的学习非归一化概率模型的方法",
            "指数损失": "eNCE变体中使用的损失函数，旨在改善优化景观",
            "归一化梯度下降": "用于解决eNCE中优化景观问题的算法，特别是在目标和噪声分布处于给定指数族时"
        },
        "success": true
    },
    {
        "order": 44,
        "title": "An Autoregressive Flow Model for 3D Molecular Geometry Generation from Scratch",
        "html": "https://iclr.cc//virtual/2022/poster/7066",
        "abstract": "We consider the problem of generating 3D molecular geometries from scratch. While multiple methods have been developed for generating molecular graphs, generating 3D molecular geometries from scratch is largely under-explored. In this work, we propose G-SphereNet, a novel autoregressive flow model for generating 3D molecular geometries. G-SphereNet employs a flexible sequential generation scheme by placing atoms in 3D space step-by-step. Instead of generating 3D coordinates directly, we propose to determine 3D positions of atoms by generating distances, angles and torsion angles, thereby ensuring both invariance and equivariance properties. In addition, we propose to use spherical message passing and attention mechanism for conditional information extraction. Experimental results show that G-SphereNet outperforms previous methods on random molecular geometry generation and targeted molecule discovery tasks. Our code is publicly available as part of the DIG package (https://github.com/divelab/DIG).",
        "conference": "ICLR",
        "中文标题": "一种用于从零开始生成3D分子几何结构的自回归流模型",
        "摘要翻译": "我们考虑从零开始生成3D分子几何结构的问题。虽然已经开发了多种方法来生成分子图，但从零开始生成3D分子几何结构的研究却相对较少。在这项工作中，我们提出了G-SphereNet，一种新颖的自回归流模型，用于生成3D分子几何结构。G-SphereNet采用了一种灵活的逐步生成方案，通过在3D空间中逐步放置原子。我们提出不直接生成3D坐标，而是通过生成距离、角度和扭转角来确定原子的3D位置，从而确保不变性和等变性。此外，我们还提出使用球形消息传递和注意力机制进行条件信息提取。实验结果表明，G-SphereNet在随机分子几何结构生成和目标分子发现任务上优于之前的方法。我们的代码作为DIG包的一部分公开可用（https://github.com/divelab/DIG）。",
        "领域": "分子几何生成、药物发现、计算化学",
        "问题": "从零开始生成3D分子几何结构的问题",
        "动机": "探索和开发能够从零开始生成3D分子几何结构的方法，填补现有研究的空白",
        "方法": "提出G-SphereNet，一种自回归流模型，通过逐步生成距离、角度和扭转角来确定原子的3D位置，并使用球形消息传递和注意力机制进行条件信息提取",
        "关键词": [
            "3D分子几何生成",
            "自回归流模型",
            "球形消息传递",
            "注意力机制",
            "药物发现"
        ],
        "涉及的技术概念": {
            "自回归流模型": "用于逐步生成3D分子几何结构的模型，确保生成过程的不变性和等变性",
            "球形消息传递": "用于在3D空间中有效提取和传递分子结构信息的技术",
            "注意力机制": "用于在生成过程中动态关注重要的分子结构特征，提高生成质量"
        },
        "success": true
    },
    {
        "order": 45,
        "title": "Ancestral protein sequence reconstruction using a tree-structured Ornstein-Uhlenbeck variational autoencoder",
        "html": "https://iclr.cc//virtual/2022/poster/6608",
        "abstract": "We introduce a deep generative model for representation learning of biological sequences that, unlike existing models, explicitly represents the evolutionary process. The model makes use of a tree-structured Ornstein-Uhlenbeck process, obtained from a given phylogenetic tree, as an informative prior for a variational autoencoder. We show the model performs well on the task of ancestral sequence reconstruction of single protein families. Our results and ablation studies indicate that the explicit representation of evolution using a suitable tree-structured prior has the potential to improve representation learning of biological sequences considerably. Finally, we briefly discuss extensions of the model to genomic-scale data sets and the case of a latent phylogenetic tree.",
        "conference": "ICLR",
        "中文标题": "使用树结构Ornstein-Uhlenbeck变分自编码器进行祖先蛋白质序列重建",
        "摘要翻译": "我们介绍了一种用于生物序列表示学习的深度生成模型，与现有模型不同，该模型明确表示了进化过程。该模型利用从给定的系统发育树中获得的树结构Ornstein-Uhlenbeck过程，作为变分自编码器的信息性先验。我们展示了该模型在单个蛋白质家族的祖先序列重建任务上表现良好。我们的结果和消融研究表明，使用合适的树结构先验明确表示进化，有可能显著改善生物序列的表示学习。最后，我们简要讨论了模型对基因组规模数据集的扩展以及潜在系统发育树的情况。",
        "领域": "生物信息学、蛋白质序列分析、进化模型",
        "问题": "如何更有效地重建祖先蛋白质序列",
        "动机": "现有的生物序列表示学习模型未能明确表示进化过程，限制了其在祖先序列重建等任务上的性能",
        "方法": "采用树结构Ornstein-Uhlenbeck过程作为变分自编码器的先验，明确表示进化过程",
        "关键词": [
            "祖先序列重建",
            "变分自编码器",
            "Ornstein-Uhlenbeck过程",
            "系统发育树",
            "表示学习"
        ],
        "涉及的技术概念": {
            "树结构Ornstein-Uhlenbeck过程": "用于模拟进化过程中的随机漂移，作为变分自编码器的先验分布",
            "变分自编码器": "用于学习生物序列的低维表示，同时重建祖先序列",
            "系统发育树": "提供了物种或基因间的进化关系，用于指导模型学习进化过程"
        },
        "success": true
    },
    {
        "order": 46,
        "title": "A Neural Tangent Kernel Perspective of Infinite Tree Ensembles",
        "html": "https://iclr.cc//virtual/2022/poster/7111",
        "abstract": "In practical situations, the tree ensemble is one of the most popular models along with neural networks. A soft tree is a variant of a decision tree. Instead of using a greedy method for searching splitting rules, the soft tree is trained using a gradient method in which the entire splitting operation is formulated in a differentiable form. Although ensembles of such soft trees have been used increasingly in recent years, little theoretical work has been done to understand their behavior. By considering an ensemble of infinite soft trees, this paper introduces and studies the Tree Neural Tangent Kernel (TNTK), which provides new insights into the behavior of the infinite ensemble of soft trees. Using the TNTK, we theoretically identify several non-trivial properties, such as global convergence of the training, the equivalence of the oblivious tree structure, and the degeneracy of the TNTK induced by the deepening of the trees.",
        "conference": "ICLR",
        "中文标题": "无限树集合的神经切线核视角",
        "摘要翻译": "在实际应用中，树集合是与神经网络并列的最受欢迎模型之一。软树是决策树的一种变体。与使用贪婪方法搜索分裂规则不同，软树通过梯度方法进行训练，其中整个分裂操作以可微分的形式表达。尽管近年来这种软树的集合使用越来越多，但对其行为的理论理解却很少。通过考虑无限软树的集合，本文引入并研究了树神经切线核（TNTK），为无限软树集合的行为提供了新的见解。利用TNTK，我们从理论上识别了几个非平凡属性，如训练的全局收敛性、无意识树结构的等价性，以及由树深度增加引起的TNTK退化。",
        "领域": "机器学习理论、决策树算法、梯度提升方法",
        "问题": "理解无限软树集合的行为及其理论性质",
        "动机": "尽管软树集合在实际应用中越来越受欢迎，但缺乏对其行为的深入理论理解，本研究旨在填补这一空白",
        "方法": "通过引入树神经切线核（TNTK）来研究无限软树集合的行为，并理论分析其性质",
        "关键词": [
            "树神经切线核",
            "软树",
            "无限集合",
            "梯度方法",
            "决策树"
        ],
        "涉及的技术概念": {
            "树神经切线核（TNTK）": "用于分析无限软树集合行为的核方法，提供了对模型训练和结构性质的理论见解",
            "软树": "决策树的变体，通过梯度方法训练，分裂操作以可微分形式表达",
            "梯度方法": "用于训练软树的技术，优化过程通过梯度下降进行，使得整个模型可微分"
        },
        "success": true
    },
    {
        "order": 47,
        "title": "A New Perspective on 'How Graph Neural Networks Go Beyond Weisfeiler-Lehman?'",
        "html": "https://iclr.cc//virtual/2022/poster/6436",
        "abstract": "We propose a new perspective on designing powerful Graph Neural Networks (GNNs). In a nutshell, this enables a general solution to inject structural properties of graphs into a message-passing aggregation scheme of GNNs. As a theoretical basis, we develop a new hierarchy of local isomorphism on neighborhood subgraphs. Then, we theoretically characterize how message-passing GNNs can be designed to be more expressive than the Weisfeiler Lehman test. To elaborate this characterization, we propose a novel neural model, called GraphSNN, and prove that this model is strictly more expressive than the Weisfeiler Lehman test in distinguishing graph structures. We empirically verify the strength of our model on different graph learning tasks. It is shown that our model consistently improves the state-of-the-art methods on the benchmark tasks without sacrificing computational simplicity and efficiency.",
        "conference": "ICLR",
        "中文标题": "图神经网络如何超越Weisfeiler-Lehman？的新视角",
        "摘要翻译": "我们提出了一个关于设计强大图神经网络（GNNs）的新视角。简而言之，这提供了一个通用解决方案，将图的结构特性注入到GNNs的消息传递聚合方案中。作为理论基础，我们开发了一个关于邻域子图的局部同构的新层次结构。然后，我们从理论上描述了如何设计消息传递GNNs，使其比Weisfeiler Lehman测试更具表达力。为了详细阐述这一特性，我们提出了一种名为GraphSNN的新型神经模型，并证明该模型在区分图结构方面严格比Weisfeiler Lehman测试更具表达力。我们在不同的图学习任务上实证验证了我们模型的优势。结果表明，我们的模型在不牺牲计算简单性和效率的情况下，持续改进了基准任务上的最先进方法。",
        "领域": "图神经网络、图结构学习、图同构测试",
        "问题": "如何设计比Weisfeiler Lehman测试更具表达力的图神经网络",
        "动机": "探索图神经网络在表达图结构特性方面的潜力，超越现有的Weisfeiler Lehman测试的限制",
        "方法": "开发新的局部同构层次结构理论，提出GraphSNN模型，并通过理论证明和实证验证其优越性",
        "关键词": [
            "图神经网络",
            "Weisfeiler Lehman测试",
            "GraphSNN",
            "图结构学习",
            "消息传递"
        ],
        "涉及的技术概念": {
            "局部同构": "论文中用于描述邻域子图之间相似性的新层次结构，为设计更具表达力的GNNs提供理论基础",
            "消息传递聚合方案": "GNNs中用于聚合邻域信息的机制，论文中通过注入图的结构特性来增强其表达力",
            "GraphSNN": "论文提出的新型神经模型，通过特定的设计在区分图结构方面比Weisfeiler Lehman测试更具表达力"
        },
        "success": true
    },
    {
        "order": 48,
        "title": "An Experimental Design Perspective on Model-Based Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6697",
        "abstract": "In many practical applications of RL, it is expensive to observe state transitions from the environment. For example, in the problem of plasma control for nuclear fusion, computing the next state for a given state-action pair requires querying an expensive transition function which can lead to many hours of computer simulation or dollars of scientific research. Such expensive data collection prohibits application of standard RL algorithms which usually require a large number of observations to learn. In this work, we address the problem of efficiently learning a policy while making a minimal number of state-action queries to the transition function. In particular, we leverage ideas from Bayesian optimal experimental design to guide the selection of state-action queries for efficient learning. We propose an \\emph{acquisition function} that quantifies how much information a state-action pair would provide about the optimal solution to a Markov decision process. At each iteration, our algorithm maximizes this acquisition function, to choose the most informative state-action pair to be queried, thus yielding a data-efficient RL approach. We experiment with a variety of simulated continuous control problems and show that our approach learns an optimal policy with up to $5$ -- $1,000\\times$ less data than model-based RL baselines and $10^3$ -- $10^5\\times$ less data than model-free RL baselines. We also provide several ablated comparisons which point to substantial improvements arising from the principled method of obtaining data.",
        "conference": "ICLR",
        "中文标题": "基于模型强化学习的实验设计视角",
        "摘要翻译": "在许多强化学习（RL）的实际应用中，从环境中观察状态转移是昂贵的。例如，在核聚变的等离子体控制问题中，计算给定状态-动作对的下一状态需要查询一个昂贵的转移函数，这可能导致数小时的计算机模拟或大量的科研费用。这种昂贵的数据收集阻碍了标准RL算法的应用，这些算法通常需要大量观察来学习。在这项工作中，我们解决了在向转移函数提出最少数量的状态-动作查询的同时高效学习策略的问题。特别是，我们利用贝叶斯最优实验设计的理念来指导选择状态-动作查询以实现高效学习。我们提出了一个量化状态-动作对关于马尔可夫决策过程最优解提供多少信息的获取函数。在每次迭代中，我们的算法最大化这个获取函数，选择最有信息量的状态-动作对进行查询，从而产生一种数据高效的RL方法。我们通过一系列模拟连续控制问题进行实验，结果表明，我们的方法学习最优策略所需的数据量比基于模型的RL基线少5到1000倍，比无模型的RL基线少10^3到10^5倍。我们还提供了几项消融比较，指出了从获取数据的原理方法中产生的实质性改进。",
        "领域": "强化学习、连续控制、核聚变等离子体控制",
        "问题": "在状态转移观察成本高昂的环境中，如何高效学习策略",
        "动机": "减少在昂贵数据收集环境中的强化学习应用成本",
        "方法": "利用贝叶斯最优实验设计理念，提出并最大化一个获取函数，选择最有信息量的状态-动作对进行查询",
        "关键词": [
            "强化学习",
            "贝叶斯最优实验设计",
            "数据效率",
            "连续控制",
            "核聚变等离子体控制"
        ],
        "涉及的技术概念": {
            "贝叶斯最优实验设计": "用于指导选择最有信息量的状态-动作对进行查询，以提高学习效率",
            "获取函数": "量化状态-动作对关于马尔可夫决策过程最优解提供的信息量，用于选择查询",
            "马尔可夫决策过程": "强化学习中的数学模型，用于描述环境的状态转移和奖励机制"
        },
        "success": true
    },
    {
        "order": 49,
        "title": "An Explanation of In-context Learning as Implicit Bayesian Inference",
        "html": "https://iclr.cc//virtual/2022/poster/6893",
        "abstract": "Large language models (LMs) such as GPT-3 have the surprising ability to do in-context learning, where the model learns to do a downstream task simply by conditioning on a prompt consisting of input-output examples. The LM learns from these examples without being explicitly pretrained to learn. Thus, it is unclear what enables in-context learning. In this paper, we study how in-context learning can emerge when pretraining documents have long-range coherence. Here, the LM must infer a latent document-level concept to generate coherent next tokens during pretraining. At test time, in-context learning occurs when the LM also infers a shared latent concept between examples in a prompt. We prove when this occurs despite a distribution mismatch between prompts and pretraining data in a setting where the pretraining distribution is a mixture of HMMs. In contrast to messy large-scale datasets used to train LMs capable of in-context learning, we generate a small-scale synthetic dataset (GINC) where Transformers and LSTMs both exhibit in-context learning. Beyond the theory, experiments on GINC mirror real-world phenomena including improved in-context performance with model scaling, sensitivity to example order, and instances where zero-shot is better than few-shot in-context learning.",
        "conference": "ICLR",
        "中文标题": "上下文学习作为隐式贝叶斯推断的解释",
        "摘要翻译": "像GPT-3这样的大型语言模型（LMs）具有令人惊讶的上下文学习能力，模型仅通过基于由输入-输出示例组成的提示进行条件化，就能学会执行下游任务。LM从这些示例中学习，而无需明确地进行预训练以学习。因此，尚不清楚是什么促成了上下文学习。在本文中，我们研究了当预训练文档具有长程连贯性时，上下文学习如何出现。在这里，LM必须推断一个潜在的文档级概念，以便在预训练期间生成连贯的下一个令牌。在测试时，当LM还推断出提示中示例之间的共享潜在概念时，就会发生上下文学习。我们证明了尽管提示和预训练数据之间存在分布不匹配，但在预训练分布是HMMs混合的设置中，这种情况仍会发生。与用于训练能够进行上下文学习的LM的混乱大规模数据集相比，我们生成了一个小规模的合成数据集（GINC），其中Transformers和LSTMs都表现出上下文学习。除了理论之外，GINC上的实验反映了现实世界的现象，包括随着模型规模的扩大而提高的上下文性能、对示例顺序的敏感性，以及零样本优于少样本上下文学习的实例。",
        "领域": "自然语言处理与视觉结合",
        "问题": "理解大型语言模型如何进行上下文学习",
        "动机": "探索上下文学习能力的来源及其在预训练文档长程连贯性条件下的出现机制",
        "方法": "通过理论分析和在合成数据集GINC上的实验，研究上下文学习的出现条件和表现",
        "关键词": [
            "上下文学习",
            "隐式贝叶斯推断",
            "大型语言模型",
            "预训练",
            "合成数据集"
        ],
        "涉及的技术概念": {
            "上下文学习": "模型通过提示中的输入-输出示例学习执行任务，而无需明确预训练",
            "隐式贝叶斯推断": "在预训练和测试时，模型推断潜在概念以生成连贯输出或理解示例间的共享概念",
            "HMMs混合": "预训练数据分布的模型，用于理论分析上下文学习在分布不匹配情况下的出现"
        },
        "success": true
    },
    {
        "order": 50,
        "title": "An Information Fusion Approach to Learning with Instance-Dependent Label Noise",
        "html": "https://iclr.cc//virtual/2022/poster/7088",
        "abstract": "Instance-dependent label noise (IDN) widely exists in real-world datasets and usually misleads the training of deep neural networks. Noise transition matrix (NTM) (i.e., the probability that clean labels flip into noisy labels) is used to characterize the label noise and can be adopted to bridge the gap between clean and noisy underlying data distributions. However, most instances are long-tail, i.e., the number of occurrences of each instance is usually limited, which leads to the gap between the underlying distribution and the empirical distribution. Therefore, the genuine problem caused by IDN is \\emph{empirical}, instead of underlying, \\emph{data distribution mismatch} during training. To directly tackle the empirical distribution mismatch problem, we propose \\emph{posterior transition matrix} (PTM) to posteriorly model label noise given limited observed noisy labels, which achieves \\emph{statistically consistent classifiers}. Note that even if an instance is corrupted by the same NTM, the intrinsic randomness incurs different noisy labels, and thus requires different correction methods. Motivated by this observation, we propose an \\textbf{I}nformation \\textbf{F}usion (IF) approach to fine-tune the NTM based on the estimated PTM. Specifically, we adopt the noisy labels and model predicted probabilities to estimate the PTM and then correct the NTM in \\emph{forward propagation}. Empirical evaluations on synthetic and real-world datasets demonstrate that our method is superior to the state-of-the-art approaches, and achieves more stable training for instance-dependent label noise. ",
        "conference": "ICLR",
        "success": true,
        "中文标题": "一种基于信息融合的方法用于实例依赖标签噪声学习",
        "摘要翻译": "实例依赖标签噪声（IDN）广泛存在于真实世界的数据集中，并且通常会误导深度神经网络的训练。噪声转移矩阵（NTM）（即，干净标签翻转为噪声标签的概率）用于描述标签噪声，并且可以被用来弥合干净和噪声底层数据分布之间的差距。然而，大多数实例是长尾的，即每个实例的出现次数通常是有限的，这导致了底层分布和经验分布之间的差距。因此，由IDN引起的真正问题是训练期间的经验分布而不是底层数据分布不匹配。为了直接解决经验分布不匹配问题，我们提出后验转移矩阵（PTM）以在给定有限的观察到的噪声标签的情况下，对标签噪声进行后验建模，从而实现统计一致的分类器。注意，即使一个实例被相同的NTM破坏，内在的随机性也会导致不同的噪声标签，因此需要不同的校正方法。受此观察的启发，我们提出了一种信息融合（IF）方法，以基于估计的PTM微调NTM。具体来说，我们采用噪声标签和模型预测的概率来估计PTM，然后在正向传播中校正NTM。在合成和真实世界数据集上的经验评估表明，我们的方法优于最先进的方法，并且实现了对实例依赖标签噪声的更稳定的训练。",
        "领域": "噪声标签学习",
        "问题": "如何解决实例依赖标签噪声对深度神经网络训练的误导问题，特别是在长尾数据集中经验分布不匹配的情况下。",
        "动机": "现有的噪声转移矩阵方法在长尾数据集中面临底层分布和经验分布不匹配的问题，导致模型训练不稳定和性能下降。本研究旨在通过直接解决经验分布不匹配问题，提高模型在实例依赖标签噪声下的鲁棒性和准确性。",
        "方法": "提出了一种信息融合（IF）方法，该方法基于估计的后验转移矩阵（PTM）微调噪声转移矩阵（NTM）。利用噪声标签和模型预测概率估计PTM，并在前向传播中校正NTM。",
        "关键词": [
            "实例依赖标签噪声",
            "噪声转移矩阵",
            "后验转移矩阵",
            "信息融合",
            "长尾分布"
        ],
        "涉及的技术概念": {
            "噪声转移矩阵": "用于描述标签噪声的概率模型，表示干净标签翻转为噪声标签的概率，用于弥合干净和噪声数据分布之间的差距。",
            "后验转移矩阵": "在给定有限的观察到的噪声标签的情况下，对标签噪声进行后验建模，用于解决经验分布不匹配问题，实现统计一致的分类器。"
        }
    },
    {
        "order": 51,
        "title": "Anisotropic Random Feature Regression in High Dimensions",
        "html": "https://iclr.cc//virtual/2022/poster/6646",
        "abstract": "In contrast to standard statistical wisdom, modern learning algorithms typically find their best performance in the overparameterized regime in which the model has many more parameters than needed to fit the training data. A growing number of recent works have shown that random feature models can offer a detailed theoretical explanation for this unexpected behavior, but typically these analyses have utilized isotropic distributional assumptions on the underlying data generation process, thereby failing to provide a realistic characterization of real-world models that are designed to identify and harness the structure in natural data. In this work, we examine the high-dimensional asymptotics of random feature regression in the presence of structured data, allowing for arbitrary input correlations and arbitrary alignment between the data and the weights of the target function. We define a partial order on the space of weight-data alignments and prove that generalization performance improves in response to stronger alignment. We also clarify several previous observations in the literature by distinguishing the behavior of the sample-wise and parameter-wise learning curves, finding that sample-wise multiple descent can occur at scales dictated by the eigenstructure of the data covariance, but that parameter-wise multiple descent is limited to double descent, although strong anisotropy can induce additional signatures such as wide plateaus and steep cliffs. Finally, these signatures are related to phase transitions in the spectrum of the feature kernel matrix, and unlike the double descent peak, persist even under optimal regularization.",
        "conference": "ICLR",
        "中文标题": "高维空间中的各向异性随机特征回归",
        "摘要翻译": "与标准统计智慧相反，现代学习算法通常在过参数化区域中找到其最佳性能，即模型的参数数量远多于拟合训练数据所需的数量。最近越来越多的研究表明，随机特征模型可以为这种意外行为提供详细的理论解释，但这些分析通常利用了基础数据生成过程的各向同性分布假设，因此未能提供对旨在识别和利用自然数据结构的现实世界模型的真实描述。在这项工作中，我们研究了在结构化数据存在下随机特征回归的高维渐近性，允许任意输入相关性和数据与目标函数权重之间的任意对齐。我们定义了一个关于权重-数据对齐空间的部分顺序，并证明泛化性能随着对齐强度的增加而提高。我们还通过区分样本级和参数级学习曲线的行为，澄清了文献中的几个先前观察结果，发现样本级的多重下降可以在数据协方差的特征结构所决定的尺度上发生，但参数级的多重下降仅限于双重下降，尽管强各向异性可以诱导额外的特征，如宽平台和陡峭的悬崖。最后，这些特征与特征核矩阵谱中的相变有关，并且与双重下降峰不同，即使在最优正则化下也持续存在。",
        "领域": "机器学习理论、高维统计、随机特征模型",
        "问题": "如何在存在结构化数据的情况下理解和优化随机特征回归模型的高维渐近性能",
        "动机": "探索随机特征模型在结构化数据下的理论性能，以更真实地描述现代学习算法的行为",
        "方法": "分析随机特征回归的高维渐近性，定义权重-数据对齐的部分顺序，研究样本级和参数级学习曲线的行为",
        "关键词": [
            "随机特征回归",
            "高维统计",
            "各向异性数据",
            "学习曲线",
            "正则化"
        ],
        "涉及的技术概念": {
            "随机特征模型": "用于解释现代学习算法在过参数化区域中性能的理论模型",
            "高维渐近性": "研究在高维空间中模型性能的渐近行为",
            "权重-数据对齐": "描述数据与模型权重之间对齐程度的概念，影响模型的泛化性能"
        },
        "success": true
    },
    {
        "order": 52,
        "title": "Anomaly Detection for Tabular Data with Internal Contrastive Learning",
        "html": "https://iclr.cc//virtual/2022/poster/7127",
        "abstract": " We consider the task of finding out-of-class samples in tabular data, where little can be assumed on the structure of the data. In order to capture the structure of the samples of the single training class, we learn mappings that maximize the mutual information between each sample and the part that is masked out. The mappings are learned by employing a contrastive loss, which considers only one sample at a time. Once learned, we can score a test sample by measuring whether the learned mappings lead to a small contrastive loss using the masked parts of this sample. Our experiments show that our method leads by a sizable accuracy gap in comparison to the literature and that the same default set of hyperparameters provides state-of-the-art results across benchmarks.",
        "conference": "ICLR",
        "中文标题": "基于内部对比学习的表格数据异常检测",
        "摘要翻译": "我们考虑在表格数据中找出类别外样本的任务，其中对数据的结构几乎不做任何假设。为了捕捉单一训练类别样本的结构，我们学习了最大化每个样本与被掩盖部分之间互信息的映射。这些映射通过采用对比损失来学习，每次仅考虑一个样本。一旦学习完成，我们可以通过测量使用该样本被掩盖部分的对比损失是否较小来对测试样本进行评分。我们的实验表明，与文献相比，我们的方法在准确性上取得了显著的领先优势，并且相同的默认超参数集在多个基准测试中提供了最先进的结果。",
        "领域": "异常检测",
        "问题": "在表格数据中识别类别外样本",
        "动机": "在缺乏数据结构假设的情况下，有效识别表格数据中的异常样本",
        "方法": "通过学习最大化样本与被掩盖部分互信息的映射，并采用对比损失进行训练",
        "关键词": [
            "表格数据",
            "异常检测",
            "对比学习",
            "互信息",
            "超参数优化"
        ],
        "涉及的技术概念": {
            "对比学习": "通过比较样本与其被掩盖部分来学习数据表示的技术",
            "互信息": "用于衡量两个变量之间相互依赖性的指标，在本研究中用于优化映射学习",
            "超参数优化": "调整模型参数以提高性能的过程，本研究展示了默认超参数集在不同基准测试中的有效性"
        },
        "success": true
    },
    {
        "order": 53,
        "title": "Anomaly Transformer: Time Series Anomaly Detection with Association Discrepancy",
        "html": "https://iclr.cc//virtual/2022/poster/7023",
        "abstract": "Unsupervised detection of anomaly points in time series is a challenging problem, which requires the model to derive a distinguishable criterion. Previous methods tackle the problem mainly through learning pointwise representation or pairwise association, however, neither is sufficient to reason about the intricate dynamics. Recently, Transformers have shown great power in unified modeling of pointwise representation and pairwise association, and we find that the self-attention weight distribution of each time point can embody rich association with the whole series. Our key observation is that due to the rarity of anomalies, it is extremely difficult to build nontrivial associations from abnormal points to the whole series, thereby, the anomalies' associations shall mainly concentrate on their adjacent time points. This adjacent-concentration bias implies an association-based criterion inherently distinguishable between normal and abnormal points, which we highlight through the Association Discrepancy. Technically, we propose the Anomaly Transformer with a new Anomaly-Attention mechanism to compute the association discrepancy. A minimax strategy is devised to amplify the normal-abnormal distinguishability of the association discrepancy. The Anomaly Transformer achieves state-of-the-art results on six unsupervised time series anomaly detection benchmarks of three applications: service monitoring, space & earth exploration, and water treatment.",
        "conference": "ICLR",
        "中文标题": "异常Transformer：基于关联差异的时间序列异常检测",
        "摘要翻译": "时间序列中异常点的无监督检测是一个具有挑战性的问题，它要求模型能够推导出一个可区分的标准。先前的方法主要通过学习点表示或成对关联来解决这一问题，然而，这两种方法都不足以推理复杂的动态。最近，Transformer在统一建模点表示和成对关联方面显示出巨大的能力，我们发现每个时间点的自注意力权重分布可以体现与整个序列的丰富关联。我们的关键观察是，由于异常的稀有性，从异常点到整个序列建立非平凡关联极其困难，因此，异常的关联应主要集中在它们相邻的时间点上。这种相邻集中偏差暗示了一个基于关联的标准，本质上可以区分正常点和异常点，我们通过关联差异来强调这一点。技术上，我们提出了带有新的异常注意力机制的异常Transformer来计算关联差异。设计了一个极小极大策略来放大关联差异的正常-异常区分能力。异常Transformer在三个应用的六个无监督时间序列异常检测基准上实现了最先进的结果：服务监控、空间与地球探索以及水处理。",
        "领域": "时间序列分析、异常检测、自注意力机制",
        "问题": "解决时间序列中异常点的无监督检测问题",
        "动机": "由于异常的稀有性，传统的点表示或成对关联方法难以有效区分正常与异常点，需要一种新的方法来提高检测的准确性",
        "方法": "提出异常Transformer，引入异常注意力机制计算关联差异，并采用极小极大策略增强正常与异常的区分能力",
        "关键词": [
            "时间序列",
            "异常检测",
            "Transformer",
            "自注意力机制",
            "关联差异"
        ],
        "涉及的技术概念": {
            "异常注意力机制": "用于计算时间点之间的关联差异，突出异常点与正常点的区别",
            "关联差异": "作为区分正常点和异常点的标准，通过异常注意力机制计算得出",
            "极小极大策略": "用于优化模型，放大关联差异的正常-异常区分能力"
        },
        "success": true
    },
    {
        "order": 54,
        "title": "A NON-PARAMETRIC REGRESSION VIEWPOINT : GENERALIZATION OF OVERPARAMETRIZED DEEP RELU NETWORK UNDER NOISY OBSERVATIONS",
        "html": "https://iclr.cc//virtual/2022/poster/6935",
        "abstract": "We study the generalization properties of the overparameterized deep neural network (DNN) with Rectified Linear Unit (ReLU) activations.Under the non-parametric regression framework, it is assumed that the ground-truth function is from a reproducing kernel Hilbert space (RKHS) induced by a neural tangent kernel (NTK) of ReLU DNN, and a dataset is given with the noises. Without a delicate adoption of early stopping, we prove that the overparametrized DNN trained by vanilla gradient descent does not recover the ground-truth function. It turns out that the estimated DNN's $L_{2}$ prediction error is bounded away from $0$. As a complement of the above result, we show that the $\\ell_{2}$-regularized gradient descent enables the overparametrized DNN achieve the minimax optimal convergence rate of the $L_{2}$ prediction error, without early stopping. Notably, the rate we obtained is faster than $\\mathcal{O}(n^{-1/2})$ known in the literature.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "非参数回归视角：噪声观测下过参数化深度ReLU网络的泛化",
        "摘要翻译": "我们研究了具有修正线性单元（ReLU）激活函数的过参数化深度神经网络（DNN）的泛化特性。在非参数回归框架下，假设真实函数来自ReLU DNN的神经切线核（NTK）诱导的再生核希尔伯特空间（RKHS），并给出了带有噪声的数据集。在没有精细地采用早停法的情况下，我们证明了通过原始梯度下降训练的过参数化DNN无法恢复真实函数。结果表明，估计的DNN的$L_{2}$预测误差与0存在下界。作为上述结果的补充，我们证明了$\\ell_{2}$-正则化梯度下降使得过参数化DNN能够在没有早停法的情况下实现$L_{2}$预测误差的极小极大最优收敛速度。值得注意的是，我们获得的速度比文献中已知的$\\mathcal{O}(n^{-1/2})$更快。",
        "领域": "深度学习理论、神经网络泛化、非参数回归",
        "问题": "过参数化深度ReLU网络在噪声观测下的泛化性能问题，特别是原始梯度下降训练时无法恢复真实函数，以及如何通过正则化方法实现最优收敛速度。",
        "动机": "研究过参数化深度神经网络的泛化能力是理解和改进深度学习算法的关键。现有的理论研究通常依赖于早停等技巧，而本文旨在探索在没有早停的情况下，如何通过正则化方法提升模型的泛化性能。",
        "方法": "理论分析，采用非参数回归框架，分析ReLU DNN的神经切线核（NTK）诱导的再生核希尔伯特空间（RKHS）的性质，结合梯度下降和ℓ₂-正则化，证明了在噪声观测下，过参数化DNN的泛化误差界。",
        "关键词": [
            "过参数化神经网络",
            "ReLU激活函数",
            "泛化性能",
            "神经切线核",
            "ℓ₂-正则化"
        ],
        "涉及的技术概念": {
            "神经切线核 (NTK)": "用于分析深度神经网络在训练过程中的行为，尤其是在无限宽度极限下，NTK 可以将神经网络的训练简化为核回归问题，从而更容易进行理论分析。",
            "再生核希尔伯特空间 (RKHS)": "一种函数空间，其中的函数具有良好的性质，便于进行理论分析。论文假设真实函数位于由 NTK 诱导的 RKHS 中。"
        }
    },
    {
        "order": 55,
        "title": "An Operator Theoretic View On Pruning Deep Neural Networks",
        "html": "https://iclr.cc//virtual/2022/poster/6940",
        "abstract": "The discovery of sparse subnetworks that are able to perform as well as full models has found broad applied and theoretical interest. While many pruning methods have been developed to this end, the naïve approach of removing parameters based on their magnitude has been found to be as robust as more complex, state-of-the-art algorithms. The lack of theory behind magnitude pruning's success, especially pre-convergence, and its relation to other pruning methods, such as gradient based pruning, are outstanding open questions in the field that are in need of being addressed. We make use of recent advances in dynamical systems theory, namely Koopman operator theory, to define a new class of theoretically motivated pruning algorithms. We show that these algorithms can be equivalent to magnitude and gradient based pruning, unifying these seemingly disparate methods, and find that they can be used to shed light on magnitude pruning's performance during the early part of training.",
        "conference": "ICLR",
        "中文标题": "深度神经网络剪枝的算子理论视角",
        "摘要翻译": "发现能够与完整模型表现相当的稀疏子网络已经引起了广泛的应用和理论兴趣。虽然已经开发了许多剪枝方法来实现这一目标，但基于参数大小进行剪枝的朴素方法已被发现与更复杂的、最先进的算法一样稳健。尤其是收敛前，大小剪枝成功背后的理论缺乏，以及它与其他剪枝方法（如基于梯度的剪枝）的关系，是该领域亟待解决的开放性问题。我们利用动力系统理论的最新进展，即Koopman算子理论，定义了一类新的理论上有动机的剪枝算法。我们展示了这些算法可以与基于大小和梯度的剪枝等效，统一了这些看似不同的方法，并发现它们可以用来揭示训练早期大小剪枝的性能。",
        "领域": "神经网络优化、模型压缩、深度学习理论",
        "问题": "如何理论解释大小剪枝方法的有效性及其与其他剪枝方法的关系",
        "动机": "解决大小剪枝方法在理论上的不足，尤其是在收敛前的表现，以及探索其与其他剪枝方法的联系",
        "方法": "利用Koopman算子理论定义新的剪枝算法，统一大小和梯度剪枝方法，并分析训练早期大小剪枝的表现",
        "关键词": [
            "稀疏子网络",
            "Koopman算子理论",
            "模型剪枝",
            "深度学习理论",
            "神经网络优化"
        ],
        "涉及的技术概念": {
            "稀疏子网络": "在深度神经网络中，通过剪枝得到的参数较少的子网络，能够保持与原网络相近的性能",
            "Koopman算子理论": "一种动力系统理论，用于描述非线性系统的线性演化，本文中用于定义新的剪枝算法",
            "模型剪枝": "通过移除神经网络中的部分参数来减少模型大小和计算量，同时尽量保持模型性能的技术"
        },
        "success": true
    },
    {
        "order": 56,
        "title": "Anti-Concentrated Confidence Bonuses For Scalable Exploration",
        "html": "https://iclr.cc//virtual/2022/poster/6790",
        "abstract": "Intrinsic rewards play a central role in handling the exploration-exploitation tradeoff when designing sequential decision-making algorithms, in both foundational theory and state-of-the-art deep reinforcement learning. The LinUCB algorithm, a centerpiece of the stochastic linear bandits literature, prescribes an elliptical bonus which addresses the challenge of leveraging shared information in large action spaces. This bonus scheme cannot be directly transferred to high-dimensional exploration problems, however, due to the computational cost of maintaining the inverse covariance matrix of action features. We introduce anti-concentrated confidence bounds for efficiently approximating the elliptical bonus, using an ensemble of regressors trained to predict random noise from policy network-derived features. Using this approximation, we obtain stochastic linear bandit algorithms which obtain $\\tilde O(d \\sqrt{T})$ regret bounds for $\\mathsf{poly}(d)$ fixed actions. We develop a practical variant that is competitive with contemporary intrinsic reward heuristics on Atari benchmarks.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "用于可扩展探索的反集中置信度奖励",
        "摘要翻译": "在设计序列决策算法时，无论是基础理论还是最先进的深度强化学习，内在奖励都在处理探索-利用权衡中起着核心作用。LinUCB算法是随机线性bandit文献的核心，它规定了一种椭圆奖励，解决了在大型动作空间中利用共享信息的挑战。然而，由于维护动作特征的逆协方差矩阵的计算成本，这种奖励方案不能直接转移到高维探索问题。我们引入了反集中置信界限，用于有效地近似椭圆奖励，使用一个回归器集成来预测策略网络导出的特征中的随机噪声。使用这种近似，我们获得了随机线性bandit算法，该算法对于fixed actions 获得了的$\\tilde O(d \\sqrt{T})$ regret bounds。我们开发了一个实用的变体，在Atari基准测试中与当代内在奖励启发式方法具有竞争力。",
        "领域": "强化学习、探索策略、bandit算法",
        "问题": "在高维动作空间中，如何有效地进行探索，克服传统LinUCB算法计算逆协方差矩阵的难题。",
        "动机": "传统的LinUCB算法在高维空间中计算代价高昂，限制了其在复杂环境中的应用。因此，研究高效的近似方法至关重要。",
        "方法": "使用反集中置信界限近似椭圆奖励，并使用回归器集成预测策略网络特征中的随机噪声，从而降低计算复杂度。",
        "关键词": [
            "强化学习",
            "探索-利用权衡",
            "LinUCB",
            "反集中置信界限",
            "内在奖励"
        ],
        "涉及的技术概念": {
            "LinUCB算法": "一种基于置信上界的线性bandit算法，用于在探索和利用之间进行权衡，并在动作空间中利用共享信息。",
            "反集中置信界限": "用于高效近似椭圆奖励的一种数学工具，旨在降低计算复杂度，使其适用于高维空间。"
        }
    },
    {
        "order": 57,
        "title": "Anti-Oversmoothing in Deep Vision Transformers via the Fourier Domain Analysis: From Theory to Practice",
        "html": "https://iclr.cc//virtual/2022/poster/6656",
        "abstract": "Vision Transformer (ViT) has recently demonstrated promise in computer vision problems. However, unlike Convolutional Neural Networks (CNN), it is known that the performance of ViT saturates quickly with depth increasing, due to the observed attention collapse or patch uniformity. Despite a couple of empirical solutions, a rigorous framework studying on this scalability issue remains elusive. In this paper, we first establish a  rigorous theory framework to analyze ViT features from the Fourier spectrum domain. We show that the self-attention mechanism inherently amounts to a low-pass filter, which indicates when ViT scales up its depth, excessive low-pass filtering will cause feature maps to only preserve their Direct-Current (DC) component. We then propose two straightforward yet effective techniques to mitigate the undesirable low-pass limitation. The first technique, termed AttnScale, decomposes a self-attention block into low-pass and high-pass components, then rescales and combines these two filters to produce an all-pass self-attention matrix. The second technique, termed FeatScale, re-weights feature maps on separate frequency bands to amplify the high-frequency signals. Both techniques are efficient and hyperparameter-free, while effectively overcoming relevant ViT training artifacts such as attention collapse and patch uniformity. By seamlessly plugging in our techniques to multiple ViT variants, we demonstrate that they consistently help ViTs benefit from deeper architectures, bringing up to 1.1% performance gains 'for free' (e.g., with little parameter overhead). We publicly release our codes and pre-trained models at https://github.com/VITA-Group/ViT-Anti-Oversmoothing.",
        "conference": "ICLR",
        "中文标题": "通过傅里叶域分析防止深度视觉变换器中的过度平滑：从理论到实践",
        "摘要翻译": "视觉变换器（ViT）最近在计算机视觉问题中显示出了潜力。然而，与卷积神经网络（CNN）不同，众所周知，由于观察到的注意力崩溃或补丁均匀性，ViT的性能随着深度的增加而迅速饱和。尽管有一些经验性的解决方案，但研究这一可扩展性问题的严格框架仍然难以捉摸。在本文中，我们首先建立了一个严格的理论框架，从傅里叶谱域分析ViT特征。我们表明，自注意力机制本质上相当于一个低通滤波器，这表明当ViT扩大其深度时，过度的低通滤波将导致特征图仅保留其直流（DC）分量。然后，我们提出了两种简单而有效的技术来缓解不良的低通限制。第一种技术称为AttnScale，将自注意力块分解为低通和高通组件，然后重新缩放并组合这两个滤波器以产生全通自注意力矩阵。第二种技术称为FeatScale，重新加权不同频段的特征图以放大高频信号。这两种技术都是高效且无需超参数的，同时有效克服了相关的ViT训练伪影，如注意力崩溃和补丁均匀性。通过将我们的技术无缝插入多个ViT变体中，我们证明它们始终帮助ViT从更深的架构中受益，带来高达1.1%的性能提升'免费'（例如，几乎没有参数开销）。我们在https://github.com/VITA-Group/ViT-Anti-Oversmoothing上公开了我们的代码和预训练模型。",
        "领域": "视觉变换器优化、深度学习模型可扩展性、图像特征分析",
        "问题": "解决视觉变换器（ViT）在增加深度时性能饱和的问题，特别是由于注意力崩溃或补丁均匀性导致的过度平滑现象。",
        "动机": "研究ViT在深度增加时性能饱和的根本原因，并提出有效的解决方案以提升其可扩展性和性能。",
        "方法": "通过傅里叶域分析ViT特征，提出AttnScale和FeatScale两种技术来缓解低通滤波的限制，从而克服注意力崩溃和补丁均匀性问题。",
        "关键词": [
            "视觉变换器",
            "傅里叶分析",
            "自注意力机制",
            "模型可扩展性",
            "过度平滑"
        ],
        "涉及的技术概念": {
            "傅里叶谱域分析": "用于分析ViT特征的理论框架，揭示了自注意力机制作为低通滤波器的本质。",
            "AttnScale": "一种技术，通过分解自注意力块为低通和高通组件并重新组合，产生全通自注意力矩阵，以缓解低通限制。",
            "FeatScale": "一种技术，通过重新加权不同频段的特征图来放大高频信号，有效克服ViT训练中的伪影问题。"
        },
        "success": true
    },
    {
        "order": 58,
        "title": "An Unconstrained Layer-Peeled Perspective on Neural Collapse",
        "html": "https://iclr.cc//virtual/2022/poster/6209",
        "abstract": "Neural collapse is a highly symmetric geometry of neural networks that emerges during the terminal phase of training, with profound implications on the generalization performance and robustness of the trained networks. To understand how the last-layer features and classifiers exhibit this recently discovered implicit bias, in this paper, we introduce a surrogate model called the unconstrained layer-peeled model (ULPM). We prove that gradient flow on this model converges to critical points of a minimum-norm separation problem exhibiting neural collapse in its global minimizer. Moreover, we show that the ULPM with the cross-entropy loss has a benign global landscape for its loss function, which allows us to prove that all the critical points are strict saddle points except the global minimizers that exhibit the neural collapse phenomenon. Empirically, we show that our results also hold during the training of neural networks in real-world tasks when explicit regularization or weight decay is not used.",
        "conference": "ICLR",
        "中文标题": "无约束层剥离视角下的神经崩溃",
        "摘要翻译": "神经崩溃是神经网络在训练末期出现的一种高度对称的几何结构，对训练网络的泛化性能和鲁棒性具有深远影响。为了理解最后一层特征和分类器如何展现这种最近发现的隐式偏差，本文引入了一个称为无约束层剥离模型（ULPM）的替代模型。我们证明了该模型上的梯度流收敛于展示神经崩溃的全局最小化器的最小范数分离问题的临界点。此外，我们还展示了使用交叉熵损失的ULPM在其损失函数上具有良性的全局景观，这使我们能够证明除了展示神经崩溃现象的全局最小化器外，所有临界点都是严格的鞍点。实证上，我们展示了在不使用显式正则化或权重衰减的情况下，我们的结果在现实世界任务的神经网络训练过程中也成立。",
        "领域": "深度学习理论、神经网络优化、模型泛化",
        "问题": "理解神经网络在训练末期出现的神经崩溃现象及其对模型性能的影响",
        "动机": "探索神经崩溃现象的成因及其在神经网络训练中的作用，以提高模型的泛化能力和鲁棒性",
        "方法": "引入无约束层剥离模型（ULPM），通过理论分析和实证研究探讨神经崩溃现象",
        "关键词": [
            "神经崩溃",
            "无约束层剥离模型",
            "梯度流",
            "交叉熵损失",
            "严格鞍点"
        ],
        "涉及的技术概念": {
            "神经崩溃": "神经网络训练末期出现的一种高度对称的几何结构，影响模型的泛化性能和鲁棒性",
            "无约束层剥离模型（ULPM）": "用于研究神经崩溃现象的替代模型，通过最小范数分离问题展示神经崩溃",
            "梯度流": "在ULPM上应用的优化方法，用于分析神经崩溃现象的收敛行为"
        },
        "success": true
    },
    {
        "order": 59,
        "title": "Anytime Dense Prediction with Confidence Adaptivity",
        "html": "https://iclr.cc//virtual/2022/poster/6376",
        "abstract": "Anytime inference requires a model to make a progression of predictions which might be halted at any time. Prior research on anytime visual recognition has mostly focused on image classification.We propose the first unified and end-to-end approach for anytime dense prediction. A cascade of 'exits' is attached to the model to make multiple predictions. We redesign the exits to account for the depth and spatial resolution of the features for each exit. To reduce total computation, and make full use of prior predictions, we develop a novel spatially adaptive approach to avoid further computation on regions where early predictions are already sufficiently confident. Our full method, named anytime dense prediction with confidence (ADP-C), achieves the same level of final accuracy, and meanwhile significantly reduces total computation. We evaluate our method on Cityscapes semantic segmentation and MPII human pose estimation: ADP-C enables anytime inference without sacrificing accuracy while also reducing the total FLOPs of its base models by 44.4% and 59.1%. We compare with anytime inference by deep equilibrium networks and feature-based stochastic sampling, showing that ADP-C dominates both across the accuracy-computation curve. Our code is available at https://github.com/liuzhuang13/anytime.",
        "conference": "ICLR",
        "中文标题": "具有置信度自适应性的随时密集预测",
        "摘要翻译": "随时推理要求模型能够做出可以被随时中断的一系列预测。先前关于随时视觉识别的研究主要集中在图像分类上。我们提出了第一个统一且端到端的随时密集预测方法。模型中附加了一系列'出口'以做出多次预测。我们重新设计了这些出口，以考虑每个出口特征的深度和空间分辨率。为了减少总计算量，并充分利用先前的预测，我们开发了一种新颖的空间自适应方法，以避免对早期预测已经足够自信的区域进行进一步计算。我们的完整方法，名为具有置信度的随时密集预测（ADP-C），达到了相同的最终准确度水平，同时显著减少了总计算量。我们在Cityscapes语义分割和MPII人体姿态估计上评估了我们的方法：ADP-C实现了不牺牲准确度的随时推理，同时将其基础模型的总FLOPs减少了44.4%和59.1%。我们与通过深度均衡网络和基于特征的随机采样进行的随时推理进行了比较，结果表明ADP-C在准确度-计算曲线上均优于两者。我们的代码可在https://github.com/liuzhuang13/anytime获取。",
        "领域": "语义分割, 人体姿态估计, 密集预测",
        "问题": "如何在保持准确度的同时，实现随时中断的密集预测并减少计算量",
        "动机": "解决现有随时视觉识别研究主要集中在图像分类上，缺乏对密集预测任务的支持，以及如何在保证预测准确度的同时优化计算效率的问题",
        "方法": "通过在模型中附加一系列重新设计的出口来实现多次预测，并开发空间自适应方法以减少对高置信度区域的进一步计算",
        "关键词": [
            "随时推理",
            "密集预测",
            "置信度自适应",
            "语义分割",
            "人体姿态估计"
        ],
        "涉及的技术概念": {
            "随时推理": "模型能够根据需要在任何时刻提供预测结果，适用于计算资源有限或响应时间要求高的场景",
            "密集预测": "对图像中的每个像素或区域进行预测的任务，如语义分割和人体姿态估计",
            "置信度自适应": "根据早期预测的置信度动态调整计算资源分配，避免对高置信度区域进行不必要的计算"
        },
        "success": true
    },
    {
        "order": 60,
        "title": "Approximation and Learning with Deep Convolutional Models: a Kernel Perspective",
        "html": "https://iclr.cc//virtual/2022/poster/6387",
        "abstract": "The empirical success of deep convolutional networks on tasks involving high-dimensional data such as images or audio suggests that they can efficiently approximate certain functions that are well-suited for such tasks. In this paper, we study this through the lens of kernel methods, by considering simple hierarchical kernels with two or three convolution and pooling layers, inspired by convolutional kernel networks. These achieve good empirical performance on standard vision datasets, while providing a precise description of their functional space that yields new insights on their inductive bias. We show that the RKHS consists of additive models of interaction terms between patches, and that its norm encourages spatial similarities between these terms through pooling layers. We then provide generalization bounds which illustrate how pooling and patches yield improved sample complexity guarantees when the target function presents such regularities.",
        "conference": "ICLR",
        "中文标题": "深度卷积模型的近似与学习：核视角",
        "摘要翻译": "深度卷积网络在涉及高维数据（如图像或音频）的任务上的经验成功表明，它们能够有效地近似某些非常适合此类任务的函数。在本文中，我们通过核方法的视角研究这一点，考虑了受卷积核网络启发的具有两到三个卷积和池化层的简单分层核。这些核在标准视觉数据集上实现了良好的经验性能，同时提供了对其功能空间的精确描述，从而对其归纳偏差提供了新的见解。我们展示了RKHS由补丁间交互项的加法模型组成，并且其范数通过池化层鼓励这些项之间的空间相似性。然后，我们提供了泛化界限，说明了当目标函数呈现这种规律性时，池化和补丁如何产生改进的样本复杂度保证。",
        "领域": "卷积神经网络、核方法、图像识别",
        "问题": "深度卷积网络如何有效地近似高维数据中的函数，以及其背后的核方法理论基础。",
        "动机": "探索深度卷积网络在近似高维数据函数方面的有效性，并从核方法的视角提供理论解释。",
        "方法": "通过构建简单的分层核模型，结合卷积和池化层，研究其在标准视觉数据集上的表现，并从核方法的理论框架分析其功能空间和归纳偏差。",
        "关键词": [
            "深度卷积网络",
            "核方法",
            "函数近似",
            "池化层",
            "泛化界限"
        ],
        "涉及的技术概念": {
            "RKHS": "再生核希尔伯特空间，用于描述核方法中的函数空间，本文中用于分析深度卷积网络的功能空间。",
            "池化层": "在卷积神经网络中用于降低数据维度并增强特征的空间不变性，本文中探讨了其对模型归纳偏差的影响。",
            "泛化界限": "用于衡量学习算法在未见数据上的表现，本文中通过核方法的理论框架，分析了深度卷积网络在特定任务上的样本复杂度。"
        },
        "success": true
    },
    {
        "order": 61,
        "title": "A Program to Build E(N)-Equivariant Steerable CNNs ",
        "html": "https://iclr.cc//virtual/2022/poster/6098",
        "abstract": "Equivariance is becoming an increasingly popular design choice to build data efficient neural networks by exploiting prior knowledge about the symmetries of the problem at hand. Euclidean steerable CNNs are one of the most common classes of equivariant networks. While the constraints these architectures need to satisfy are understood, existing approaches are tailored to specific (classes of) groups. No generally applicable method that is practical for implementation has been described so far. In this work, we generalize the Wigner-Eckart theorem proposed in Lang & Weiler (2020), which characterizes general $G$-steerable kernel spaces for compact groups $G$ over their homogeneous spaces, to arbitrary $G$-spaces. This enables us to directly parameterize filters in terms of a band-limited basis on the whole space rather than on $G$'s orbits, but also to easily implement steerable CNNs equivariant to a large number of groups. To demonstrate its generality, we instantiate our method on a variety of isometry groups acting on the Euclidean space $\\mathbb{R}^3$. Our framework allows us to build $E(3)$ and $SE(3)$-steerable CNNs like previous works, but also CNNs with arbitrary $G\\leq O(3)$-steerable kernels. For example, we build 3D CNNs equivariant to the symmetries of platonic solids or choose $G=SO(2)$ when working with 3D data having only azimuthal symmetries. We compare these models on 3D shapes and molecular datasets, observing improved performance by matching the model's symmetries to the ones of the data.",
        "conference": "ICLR",
        "中文标题": "构建E(N)-等变可操纵CNN的程序",
        "摘要翻译": "等变性正成为一种越来越受欢迎的设计选择，通过利用关于问题对称性的先验知识来构建数据高效的神经网络。欧几里得可操纵CNN是最常见的等变网络类别之一。尽管这些架构需要满足的约束条件已被理解，但现有的方法都是针对特定的（类）群体定制的。迄今为止，尚未描述一种普遍适用且便于实施的方法。在这项工作中，我们推广了Lang & Weiler（2020）提出的Wigner-Eckart定理，该定理描述了紧凑群G在其齐次空间上的一般G-可操纵核空间，将其推广到任意的G-空间。这使我们能够直接在整个空间上而非G的轨道上参数化滤波器，基于带限基，同时也便于实现等变于大量群的可操纵CNN。为了证明其普遍性，我们在作用于欧几里得空间R3的各种等距群上实例化了我们的方法。我们的框架允许我们像以前的工作一样构建E(3)和SE(3)-可操纵CNN，也可以构建具有任意G≤O(3)-可操纵核的CNN。例如，我们构建了等变于柏拉图立体对称性的3D CNN，或在处理仅具有方位对称性的3D数据时选择G=SO(2)。我们在3D形状和分子数据集上比较了这些模型，观察到通过将模型的对称性与数据的对称性匹配来提高性能。",
        "领域": "等变神经网络、3D计算机视觉、分子结构分析",
        "问题": "如何构建适用于广泛群组的等变可操纵CNN",
        "动机": "利用对称性先验知识提高神经网络的数据效率，并推广现有方法以适用于更广泛的群组",
        "方法": "推广Wigner-Eckart定理，直接在空间上参数化滤波器，实现等变于多种群组的可操纵CNN",
        "关键词": [
            "等变性",
            "可操纵CNN",
            "Wigner-Eckart定理",
            "3D数据处理",
            "对称性匹配"
        ],
        "涉及的技术概念": {
            "等变性": "神经网络输出随输入变换而相应变换的性质，用于利用对称性先验知识",
            "可操纵CNN": "一种能够根据输入数据的对称性调整其内部表示的卷积神经网络",
            "Wigner-Eckart定理": "在量子力学中描述旋转对称性的定理，本文中推广用于构建等变网络"
        },
        "success": true
    },
    {
        "order": 62,
        "title": "A Reduction-Based Framework for Conservative Bandits and Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2022/poster/7122",
        "abstract": "We study bandits and reinforcement learning (RL) subject to a conservative constraint where the agent is asked to perform at least as well as a given baseline policy. This setting is particular relevant in real-world domains including digital marketing, healthcare, production, finance, etc. In this paper, we present a reduction-based framework for conservative bandits and RL, in which our core technique is to calculate the necessary and sufficient budget obtained from running the baseline policy. For lower bounds, we improve the existing lower bound for conservative multi-armed bandits and obtain new lower bounds for conservative linear bandits, tabular RL and low-rank MDP, through a black-box reduction that turns a certain lower bound in the nonconservative setting into a new lower bound in the conservative setting.  For upper bounds, in multi-armed bandits, linear bandits and tabular RL, our new upper bounds tighten or match existing ones with significantly simpler analyses. We also obtain a new upper bound for conservative low-rank MDP.",
        "conference": "ICLR",
        "中文标题": "基于约简框架的保守型老虎机与强化学习研究",
        "摘要翻译": "我们研究了在保守约束条件下的老虎机问题和强化学习（RL），其中要求智能体的表现至少与给定的基线策略相当。这一设置在包括数字营销、医疗保健、生产、金融等在内的现实世界领域中尤为重要。在本文中，我们提出了一个基于约简的框架，用于保守型老虎机和强化学习，其核心技术是计算从运行基线策略中获得的必要且充分的预算。对于下界，我们改进了现有的保守型多臂老虎机的下界，并通过一个黑盒约简方法，在保守设置中获得了新的下界，这种方法将非保守设置中的某个下界转化为保守设置中的新下界。对于上界，在多臂老虎机、线性老虎机和表格化强化学习中，我们的新上界通过显著简化的分析，收紧或匹配了现有的上界。我们还获得了保守型低秩MDP的新上界。",
        "领域": "强化学习、多臂老虎机问题、低秩MDP",
        "问题": "在保守约束条件下，如何确保智能体的表现至少与给定的基线策略相当。",
        "动机": "在数字营销、医疗保健、生产、金融等现实世界领域中，确保智能体的表现不低于基线策略至关重要。",
        "方法": "提出了一个基于约简的框架，通过计算从运行基线策略中获得的必要且充分的预算，改进和获得了新的上下界。",
        "关键词": [
            "保守型老虎机",
            "强化学习",
            "约简框架",
            "低秩MDP",
            "基线策略"
        ],
        "涉及的技术概念": {
            "约简框架": "用于将非保守设置中的下界转化为保守设置中的新下界的技术框架。",
            "保守约束": "确保智能体的表现至少与给定的基线策略相当的约束条件。",
            "低秩MDP": "一种马尔可夫决策过程，其转移矩阵具有低秩特性，用于简化模型和提高计算效率。"
        },
        "success": true
    },
    {
        "order": 63,
        "title": "A Relational Intervention Approach for Unsupervised Dynamics Generalization in Model-Based Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6135",
        "abstract": "The generalization of model-based reinforcement learning (MBRL) methods to environments with unseen transition dynamics is an important yet challenging problem.Existing methods try to extract environment-specified information $Z$ from past transition segments to make the dynamics prediction model generalizable to different dynamics. However, because environments are not labelled, the extracted information inevitably contains redundant information unrelated to the dynamics in transition segments and thus fails to maintain a crucial property of $Z$: $Z$ should be similar in the same environment and dissimilar in different ones. As a result, the learned dynamics prediction function will deviate from the true one, which undermines the generalization ability. To tackle this problem, we introduce an interventional prediction module to estimate the probability of two estimated $\\hat{z}_i, \\hat{z}_j$ belonging to the same environment.Furthermore, by utilizing the $Z$'s invariance within a single environment, a relational head is proposed to enforce the similarity between $\\hat{{Z}}$ from the same environment. As a result, the redundant information will be reduced in $\\hat{Z}$. We empirically show that $\\hat{{Z}}$ estimated by our method enjoy less redundant information than previous methods, and such $\\hat{{Z}}$  can significantly reduce dynamics prediction errors and improve the performance of model-based RL methods on zero-shot new environments with unseen dynamics. The codes of this method are available at \\url{https://github.com/CR-Gjx/RIA}.",
        "conference": "ICLR",
        "中文标题": "基于关系干预方法的无监督动态泛化在基于模型的强化学习中的应用",
        "摘要翻译": "基于模型的强化学习（MBRL）方法在具有未见过的转移动态的环境中的泛化是一个重要但具有挑战性的问题。现有方法尝试从过去的转移段中提取环境特定信息Z，以使动态预测模型能够泛化到不同的动态。然而，由于环境未被标记，提取的信息不可避免地包含与转移段动态无关的冗余信息，因此无法维持Z的一个关键属性：在同一环境中Z应相似，在不同环境中应不同。结果，学习到的动态预测函数将偏离真实情况，这削弱了泛化能力。为了解决这个问题，我们引入了一个干预预测模块来估计两个估计的z_i, z_j属于同一环境的概率。此外，通过利用Z在单一环境中的不变性，提出了一个关系头来强制来自同一环境的Z之间的相似性。结果，Z中的冗余信息将减少。我们实证表明，通过我们的方法估计的Z比之前的方法含有更少的冗余信息，并且这样的Z可以显著减少动态预测错误，并提高基于模型的强化学习方法在具有未见动态的零射击新环境中的性能。该方法的代码可在https://github.com/CR-Gjx/RIA获取。",
        "领域": "强化学习、动态预测、模型泛化",
        "问题": "解决基于模型的强化学习方法在未见过的转移动态环境中的泛化问题",
        "动机": "现有方法提取的环境特定信息Z含有冗余信息，导致动态预测模型泛化能力不足",
        "方法": "引入干预预测模块和关系头，减少Z中的冗余信息，提高动态预测的准确性和模型的泛化能力",
        "关键词": [
            "强化学习",
            "动态预测",
            "模型泛化",
            "干预预测",
            "关系头"
        ],
        "涉及的技术概念": {
            "干预预测模块": "用于估计两个估计的z_i, z_j属于同一环境的概率，减少冗余信息",
            "关系头": "利用Z在单一环境中的不变性，强制来自同一环境的Z之间的相似性",
            "动态预测模型": "基于模型的强化学习中用于预测环境动态的模型，其准确性直接影响强化学习的性能"
        },
        "success": true
    },
    {
        "order": 64,
        "title": "ARTEMIS: Attention-based Retrieval with Text-Explicit Matching and Implicit Similarity",
        "html": "https://iclr.cc//virtual/2022/poster/6121",
        "abstract": "An intuitive way to search for images is to use queries composed of an example image and a complementary text. While the first provides rich and implicit context for the search, the latter explicitly calls for new traits, or specifies how some elements of the example image should be changed to retrieve the desired target image. Current approaches typically combine the features of each of the two elements of the query into a single representation, which can then be compared to the ones of the potential target images. Our work aims at shedding new light on the task by looking at it through the prism of two familiar and related frameworks: text-to-image and image-to-image retrieval. Taking inspiration from them, we exploit the specific relation of each query element with the targeted image and derive light-weight attention mechanisms which enable to mediate between the two complementary modalities. We validate our approach on several retrieval benchmarks, querying with images and their associated free-form text modifiers. Our method obtains state-of-the-art results without resorting to side information, multi-level features, heavy pre-training nor large architectures as in previous works.",
        "conference": "ICLR",
        "中文标题": "ARTEMIS：基于注意力的检索与文本显式匹配和隐式相似性",
        "摘要翻译": "一种直观的搜索图像方法是使用由示例图像和补充文本组成的查询。前者为搜索提供了丰富且隐含的上下文，而后者则明确要求新的特征，或指定如何更改示例图像的某些元素以检索所需的目标图像。当前的方法通常将查询的两个元素的特征组合成一个单一的表示，然后可以与潜在目标图像的表示进行比较。我们的工作旨在通过从两个熟悉且相关的框架：文本到图像和图像到图像检索的角度来看待这一任务，从而为这一任务带来新的视角。从中汲取灵感，我们利用每个查询元素与目标图像的具体关系，并推导出轻量级的注意力机制，这些机制能够在两种互补模态之间进行调解。我们在几个检索基准上验证了我们的方法，使用图像及其相关的自由形式文本修饰符进行查询。我们的方法在不依赖辅助信息、多层次特征、重型预训练或大型架构的情况下，获得了最先进的结果，这与之前的工作不同。",
        "领域": "图像检索、多模态学习、注意力机制",
        "问题": "如何有效地结合图像和文本信息进行图像检索",
        "动机": "探索通过结合图像和文本信息进行图像检索的新方法，以提高检索的准确性和效率",
        "方法": "利用文本到图像和图像到图像检索的框架，开发轻量级注意力机制来调解图像和文本两种模态之间的关系",
        "关键词": [
            "图像检索",
            "多模态学习",
            "注意力机制",
            "文本修饰符",
            "轻量级模型"
        ],
        "涉及的技术概念": {
            "注意力机制": "用于调解图像和文本两种模态之间的关系，提高检索的准确性和效率",
            "文本修饰符": "用于明确指定如何更改示例图像的某些元素以检索所需的目标图像",
            "轻量级模型": "在不依赖重型预训练或大型架构的情况下实现高效检索"
        },
        "success": true
    },
    {
        "order": 65,
        "title": "AS-MLP: An Axial Shifted MLP Architecture for Vision",
        "html": "https://iclr.cc//virtual/2022/poster/6277",
        "abstract": "An Axial Shifted MLP architecture (AS-MLP) is proposed in this paper. Different from MLP-Mixer, where the global spatial feature is encoded for information flow through matrix transposition and one token-mixing MLP, we pay more attention to the local features interaction. By axially shifting channels of the feature map, AS-MLP is able to obtain the information flow from different axial directions, which captures the local dependencies. Such an operation enables us to utilize a pure MLP architecture to achieve the same local receptive field as CNN-like architecture. We can also design the receptive field size and dilation of blocks of AS-MLP, \\emph{etc}, in the same spirit of  convolutional neural networks. With the proposed AS-MLP architecture, our model obtains 83.3\\% Top-1 accuracy with 88M parameters and 15.2 GFLOPs on the ImageNet-1K dataset. Such a simple yet effective architecture outperforms all MLP-based architectures and achieves competitive performance compared to the transformer-based architectures (\\emph{e.g.}, Swin Transformer) even with slightly lower FLOPs. In addition, AS-MLP is also the first MLP-based architecture to be applied to the downstream tasks (\\emph{e.g.}, object detection and semantic segmentation). The experimental results are also impressive. Our proposed AS-MLP obtains 51.5 mAP on the COCO validation set and 49.5 MS mIoU on the ADE20K dataset, which is competitive compared to the transformer-based architectures. Our AS-MLP establishes a strong baseline of MLP-based architecture. Code is available at \\url{https://github.com/svip-lab/AS-MLP}.",
        "conference": "ICLR",
        "中文标题": "AS-MLP：一种用于视觉的轴向移位MLP架构",
        "摘要翻译": "本文提出了一种轴向移位MLP架构（AS-MLP）。与MLP-Mixer通过矩阵转置和一个令牌混合MLP对全局空间特征进行编码以信息流不同，我们更关注局部特征的交互。通过轴向移位特征图的通道，AS-MLP能够从不同的轴向方向获取信息流，从而捕捉局部依赖性。这样的操作使我们能够利用纯MLP架构实现类似CNN架构的局部感受野。我们还可以按照卷积神经网络的精神设计AS-MLP块的感受野大小和扩张等。采用提出的AS-MLP架构，我们的模型在ImageNet-1K数据集上以88M参数和15.2 GFLOPs获得了83.3%的Top-1准确率。这种简单而有效的架构超越了所有基于MLP的架构，并在FLOPs略低的情况下与基于Transformer的架构（如Swin Transformer）相比具有竞争力。此外，AS-MLP也是第一个应用于下游任务（如目标检测和语义分割）的基于MLP的架构。实验结果同样令人印象深刻。我们提出的AS-MLP在COCO验证集上获得了51.5 mAP，在ADE20K数据集上获得了49.5 MS mIoU，与基于Transformer的架构相比具有竞争力。我们的AS-MLP为基于MLP的架构建立了强大的基线。代码可在https://github.com/svip-lab/AS-MLP获取。",
        "领域": "图像分类, 目标检测, 语义分割",
        "问题": "如何利用纯MLP架构实现类似CNN架构的局部感受野，并提升视觉任务的性能",
        "动机": "探索MLP架构在视觉任务中的应用潜力，特别是在局部特征交互和感受野设计方面，以超越现有MLP架构并与Transformer架构竞争",
        "方法": "提出轴向移位MLP架构（AS-MLP），通过轴向移位特征图的通道来捕捉局部依赖性，设计感受野大小和扩张，实现类似CNN的局部感受野",
        "关键词": [
            "轴向移位",
            "MLP架构",
            "局部感受野",
            "图像分类",
            "下游任务"
        ],
        "涉及的技术概念": {
            "轴向移位": "通过轴向移位特征图的通道，从不同方向获取信息流，捕捉局部依赖性",
            "局部感受野": "设计MLP架构以模拟CNN的局部感受野，增强模型对局部特征的捕捉能力",
            "下游任务应用": "将AS-MLP架构应用于目标检测和语义分割等下游任务，验证其泛化能力和性能"
        },
        "success": true
    },
    {
        "order": 66,
        "title": "Assessing Generalization of SGD via Disagreement",
        "html": "https://iclr.cc//virtual/2022/poster/6300",
        "abstract": "We empirically show that the test error of deep networks can be estimated by training the same architecture on the same training set but with two different runs of Stochastic Gradient Descent (SGD), and then measuring the disagreement rate between the two networks on unlabeled test data. This builds on -- and is a stronger version of -- the observation in Nakkiran&Bansal 20, which requires the runs to be on separate training sets. We further theoretically show that this peculiar phenomenon arises from the well-calibrated nature of ensembles of SGD-trained models. This finding not only provides a simple empirical measure to directly predict the test error using unlabeled test data, but also establishes a new conceptual connection between generalization and calibration.",
        "conference": "ICLR",
        "中文标题": "通过分歧评估随机梯度下降的泛化能力",
        "摘要翻译": "我们通过实验证明，深度网络的测试误差可以通过在同一训练集上使用随机梯度下降（SGD）两次不同的运行训练相同架构的网络，然后测量两个网络在未标记测试数据上的分歧率来估计。这一发现建立在Nakkiran&Bansal 20的观察之上，并且是其更强版本，后者要求运行在不同的训练集上。我们进一步从理论上证明，这一奇特现象源于SGD训练模型集合的良好校准性质。这一发现不仅提供了一种简单的经验方法来直接使用未标记测试数据预测测试误差，而且在泛化与校准之间建立了新的概念联系。",
        "领域": "深度学习理论、模型泛化性研究、机器学习优化方法",
        "问题": "如何评估和预测深度神经网络在未标记测试数据上的泛化误差",
        "动机": "探索深度神经网络泛化能力的评估方法，减少对大量标记测试数据的依赖",
        "方法": "通过在同一训练集上两次运行SGD训练相同架构的网络，测量其在未标记测试数据上的分歧率来估计测试误差",
        "关键词": [
            "随机梯度下降",
            "模型泛化",
            "测试误差估计",
            "未标记数据",
            "模型校准"
        ],
        "涉及的技术概念": {
            "随机梯度下降（SGD）": "论文中用于训练深度网络的核心优化算法，通过两次独立运行产生模型分歧",
            "模型分歧率": "衡量两个模型在未标记数据上预测不一致性的指标，用于间接估计测试误差",
            "模型校准": "指模型预测置信度与实际正确概率的一致性，论文发现SGD训练模型的良好校准性质是解释现象的关键"
        },
        "success": true
    },
    {
        "order": 67,
        "title": "Associated Learning: an Alternative to End-to-End Backpropagation that Works on CNN, RNN, and Transformer",
        "html": "https://iclr.cc//virtual/2022/poster/6458",
        "abstract": "This paper studies Associate Learning (AL), an alternative methodology to the end-to-end backpropagation (BP).  We introduce the workflow to convert a neural network into a proper structure such that AL can be used to learn the weights for various types of neural networks.  We compared AL and BP on some of the most successful types of neural networks -- Convolutional Neural Network (CNN), Recurrent Neural Network (RNN), and Transformer.  Experimental results show that AL consistently outperforms BP on various open datasets.  We discuss possible reasons for AL's success and its limitations.",
        "conference": "ICLR",
        "中文标题": "关联学习：一种适用于CNN、RNN和Transformer的端到端反向传播替代方法",
        "摘要翻译": "本文研究了关联学习（AL），这是一种替代端到端反向传播（BP）的方法论。我们介绍了将神经网络转换为适当结构的工作流程，以便AL可以用于学习各种类型神经网络的权重。我们在一些最成功的神经网络类型——卷积神经网络（CNN）、循环神经网络（RNN）和Transformer上比较了AL和BP。实验结果表明，AL在各种开放数据集上始终优于BP。我们讨论了AL成功的可能原因及其局限性。",
        "领域": "深度学习优化方法、神经网络训练技术、机器学习算法改进",
        "问题": "探索替代端到端反向传播的神经网络训练方法",
        "动机": "反向传播在训练深度神经网络时存在梯度消失或爆炸等问题，关联学习作为一种替代方法，旨在提供更稳定和高效的训练方式",
        "方法": "提出关联学习（AL）方法，通过转换神经网络结构使其适用于AL，进而在CNN、RNN和Transformer上实现权重学习，并与传统BP方法进行对比实验",
        "关键词": [
            "关联学习",
            "反向传播替代",
            "神经网络训练",
            "深度学习优化",
            "权重学习"
        ],
        "涉及的技术概念": {
            "关联学习（AL）": "一种替代传统反向传播的神经网络训练方法，通过特定的网络结构调整实现权重学习",
            "端到端反向传播（BP）": "传统的神经网络训练方法，通过计算梯度并反向传播来更新网络权重",
            "神经网络结构转换": "将标准神经网络结构调整为适合关联学习的格式，以便AL方法能够有效应用"
        },
        "success": true
    },
    {
        "order": 68,
        "title": "A Statistical Framework for Efficient Out of Distribution Detection in Deep Neural Networks",
        "html": "https://iclr.cc//virtual/2022/poster/6384",
        "abstract": "Background.Commonly, Deep Neural Networks (DNNs) generalize well on samples drawn from a distribution similar to that of the training set. However, DNNs' predictions are brittle and unreliable when the test samples are drawn from a dissimilar distribution.This is a major concern for deployment in real-world applications, where such behavior may come at a considerable cost, such as industrial production lines, autonomous vehicles, or healthcare applications.Contributions.We frame Out Of Distribution (OOD) detection in DNNs as a statistical hypothesis testing problem. Tests generated within our proposed framework combine evidence from the entire network.Unlike previous OOD detection heuristics, this framework returns a $p$-value for each test sample. It is guaranteed to maintain the Type I Error (T1E - incorrectly predicting OOD for an actual in-distribution sample) for test data. Moreover, this allows to combine several detectors while maintaining the T1E.Building on this framework, we suggest a novel OOD procedure based on low-order statistics. Our method achieves comparable or better results than state-of-the-art methods on well-accepted OOD benchmarks, without retraining the network parameters or assuming prior knowledge on the test distribution --- and at a fraction of the computational cost.",
        "conference": "ICLR",
        "中文标题": "深度神经网络中高效分布外检测的统计框架",
        "摘要翻译": "背景。通常，深度神经网络（DNNs）在从与训练集相似分布中抽取的样本上表现良好。然而，当测试样本来自不同分布时，DNNs的预测变得脆弱且不可靠。这对于实际应用中的部署是一个主要关切，因为这种行为可能会带来相当大的成本，如工业生产线上、自动驾驶汽车或医疗保健应用中。贡献。我们将DNNs中的分布外（OOD）检测框架化为一个统计假设检验问题。在我们提出的框架内生成的测试结合了整个网络的证据。与之前的OOD检测启发式方法不同，这个框架为每个测试样本返回一个p值。它保证了对测试数据维持类型I错误（T1E - 对实际分布内样本错误预测为OOD）。此外，这允许在维持T1E的同时结合多个检测器。基于这个框架，我们提出了一种基于低阶统计量的新颖OOD程序。我们的方法在公认的OOD基准测试上取得了与最先进方法相当或更好的结果，而无需重新训练网络参数或假设对测试分布的先前知识——并且计算成本仅为一部分。",
        "领域": "异常检测、深度学习安全、统计机器学习",
        "问题": "深度神经网络在面对与训练数据分布不同的测试样本时预测不可靠的问题",
        "动机": "解决DNNs在实际应用中因面对分布外样本而导致的预测不可靠问题，以减少潜在的高成本风险",
        "方法": "将OOD检测框架化为统计假设检验问题，提出基于低阶统计量的新颖OOD检测程序",
        "关键词": [
            "分布外检测",
            "统计假设检验",
            "深度神经网络",
            "类型I错误",
            "低阶统计量"
        ],
        "涉及的技术概念": {
            "统计假设检验": "用于将OOD检测问题形式化，为每个测试样本提供统计显著性的p值",
            "类型I错误（T1E）": "在统计检验中错误地将分布内样本判定为分布外的概率，本框架保证控制这一错误率",
            "低阶统计量": "用于构建新颖OOD检测程序的基础，该方法在不增加显著计算成本的情况下提高检测效率"
        },
        "success": true
    },
    {
        "order": 69,
        "title": "Asymmetry Learning for Counterfactually-invariant Classification in OOD Tasks",
        "html": "https://iclr.cc//virtual/2022/poster/6946",
        "abstract": "Generalizing from observed to new related environments (out-of-distribution) is central to the reliability of classifiers. However, most classifiers fail to predict label $Y$ from input $X$ when the change in environment is due a (stochastic) input transformation $T^\\text{te} \\circ X'$ not observed in training, as in training we observe $T^\\text{tr} \\circ X'$, where $X'$ is a hidden variable. This work argues that when the transformations in train $T^\\text{tr}$ and test $T^\\text{te}$ are (arbitrary) symmetry transformations induced by a collection of known $m$ equivalence relations, the task of finding a robust OOD classifier can be defined as finding the simplest causal model that defines a causal connection between the target labels and the symmetry transformations that are associated with label changes. We then propose a new learning paradigm, asymmetry learning, that identifies which symmetries the classifier must break in order to correctly predict $Y$ in both train and test. Asymmetry learning performs a causal model search that, under certain identifiability conditions, finds classifiers that perform equally well in-distribution and out-of-distribution. Finally, we show how to learn counterfactually-invariant representations with asymmetry learning in two physics tasks.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "非对称学习：用于OOD任务中反事实不变分类",
        "摘要翻译": "从观察到的环境推广到新的相关环境（分布外泛化）对于分类器的可靠性至关重要。然而，当环境的变化是由于训练中未观察到的（随机）输入变换 T^te ∘ X' 引起的时，大多数分类器无法从输入 X 预测标签 Y。在训练中，我们观察到 T^tr ∘ X'，其中 X' 是一个隐藏变量。这项工作认为，当训练 T^tr 和测试 T^te 中的变换是由一组已知的 m 个等价关系引起的（任意）对称变换时，找到鲁棒的 OOD 分类器的任务可以定义为找到最简单的因果模型，该模型定义了目标标签与与标签变化相关的对称变换之间的因果关系。然后，我们提出了一种新的学习范式，即非对称学习，它识别分类器必须打破哪些对称性才能在训练和测试中正确预测 Y。非对称学习执行因果模型搜索，在某些可识别性条件下，找到在分布内和分布外表现同样出色的分类器。最后，我们展示了如何在两个物理任务中通过非对称学习学习反事实不变的表示。",
        "领域": "分布外泛化、因果推理、表示学习",
        "问题": "解决分类器在训练和测试环境存在未观察到的输入变换时，难以进行分布外泛化的问题。",
        "动机": "现有的分类器在面对训练数据中未见过的环境变化时，性能会显著下降。本研究旨在通过识别和打破与标签变化相关的对称性，学习到对环境变化具有鲁棒性的分类器。",
        "方法": "提出了一种新的学习范式，即非对称学习，通过因果模型搜索，找到必须打破的对称性，从而学习反事实不变的表示，提高分类器在分布外环境下的泛化能力。",
        "关键词": [
            "分布外泛化",
            "非对称学习",
            "因果模型",
            "反事实不变性",
            "对称变换"
        ],
        "涉及的技术概念": {
            "分布外泛化 (OOD Generalization)": "指模型在训练数据分布之外的新环境或数据集上保持良好性能的能力。论文旨在解决分类器在OOD场景下的泛化问题。",
            "因果模型搜索 (Causal Model Search)": "一种用于发现变量之间因果关系的方法。论文中使用因果模型搜索来识别目标标签与对称变换之间的因果关系，从而找到更鲁棒的分类器。"
        }
    },
    {
        "order": 70,
        "title": "A Tale of Two Flows: Cooperative Learning of Langevin Flow and Normalizing Flow Toward Energy-Based Model",
        "html": "https://iclr.cc//virtual/2022/poster/6153",
        "abstract": "This paper studies the cooperative learning of two generative flow models, in which the two models are iteratively updated based on the jointly synthesized examples. The first flow model is a normalizing flow that transforms an initial simple density into a target density by applying a sequence of invertible transformations. The second flow model is a Langevin flow that runs finite steps of gradient-based MCMC toward an energy-based model. We start from proposing a generative framework that trains an energy-based model with a normalizing flow as an amortized sampler to initialize the MCMC chains of the energy-based model. In each learning iteration, we generate synthesized examples by using a normalizing flow initialization followed by a short-run Langevin flow revision toward the current energy-based model. Then we treat the synthesized examples as fair samples from the energy-based model and update the model parameters with the maximum likelihood learning gradient, while the normalizing flow directly learns from the synthesized examples by maximizing the tractable likelihood. Under the short-run non-mixing MCMC scenario, the estimation of the energy-based model  is shown to follow the perturbation of maximum likelihood, and the short-run Langevin flow and the normalizing flow form a two-flow generator that we call CoopFlow. We provide an  understating of the CoopFlow algorithm by information geometry and show that it is a valid generator as it converges to a moment matching estimator. We demonstrate that the trained CoopFlow is capable of synthesizing realistic images, reconstructing images, and interpolating between images.",
        "conference": "ICLR",
        "中文标题": "两种流的故事：Langevin流与归一化流在基于能量模型中的协同学习",
        "摘要翻译": "本文研究了两种生成流模型的协同学习，其中两个模型基于联合合成的示例进行迭代更新。第一种流模型是归一化流，它通过应用一系列可逆变换将初始简单密度转换为目标密度。第二种流模型是Langevin流，它运行有限步骤的基于梯度的MCMC，朝向基于能量的模型。我们首先提出一个生成框架，该框架训练一个基于能量的模型，以归一化流作为摊销采样器来初始化基于能量模型的MCMC链。在每个学习迭代中，我们通过使用归一化流初始化后接一个短运行的Langevin流修订来生成合成示例，朝向当前的基于能量模型。然后，我们将这些合成示例视为来自基于能量模型的公平样本，并用最大似然学习梯度更新模型参数，而归一化流直接通过最大化可处理的似然从合成示例中学习。在短运行非混合MCMC情景下，基于能量模型的估计显示遵循最大似然的扰动，短运行的Langevin流和归一化流形成了一个我们称之为CoopFlow的双流生成器。我们通过信息几何提供了对CoopFlow算法的理解，并表明它是一个有效的生成器，因为它收敛到一个矩匹配估计器。我们证明了训练后的CoopFlow能够合成逼真的图像、重建图像以及在图像之间进行插值。",
        "领域": "生成模型、图像合成、概率建模",
        "问题": "如何协同训练归一化流和Langevin流以改进基于能量模型的生成能力",
        "动机": "探索归一化流和Langevin流在生成模型中的协同作用，以提高图像合成和重建的质量",
        "方法": "提出CoopFlow算法，通过迭代更新归一化流和Langevin流，结合最大似然学习和短运行MCMC策略",
        "关键词": [
            "协同学习",
            "归一化流",
            "Langevin流",
            "基于能量模型",
            "图像合成"
        ],
        "涉及的技术概念": {
            "归一化流": "通过一系列可逆变换将简单密度转换为目标密度，用于生成模型的初始化",
            "Langevin流": "基于梯度的MCMC方法，用于从基于能量模型中采样，优化生成过程",
            "基于能量模型": "一种生成模型，通过能量函数定义数据分布，CoopFlow算法旨在优化其生成能力"
        },
        "success": true
    },
    {
        "order": 71,
        "title": "A Theoretical Analysis on Feature Learning in Neural Networks: Emergence from Inputs and Advantage over Fixed Features",
        "html": "https://iclr.cc//virtual/2022/poster/6008",
        "abstract": "An important characteristic of neural networks is their ability to learn representations of the input data with effective features for prediction, which is believed to be a key factor to their superior empirical performance. To better understand the source and benefit of feature learning in neural networks, we consider learning problems motivated by practical data, where the labels are determined by a set of class relevant patterns and the inputs are generated from these along with some background patterns. We prove that neural networks trained by gradient descent can succeed on these problems. The success relies on the emergence and improvement of effective features, which are learned among exponentially many candidates efficiently by exploiting the data (in particular, the structure of the input distribution). In contrast, no linear models on data-independent features of polynomial sizes can learn to as good errors. Furthermore, if the specific input structure is removed, then no polynomial algorithm in the Statistical Query model can learn even weakly. These results provide theoretical evidence showing that feature learning in neural networks depends strongly on the input structure and leads to the superior performance. Our preliminary experimental results on synthetic and real data also provide positive support. ",
        "conference": "ICLR",
        "中文标题": "神经网络中特征学习的理论分析：从输入中涌现及相对于固定特征的优势",
        "摘要翻译": "神经网络的一个重要特性是它们能够学习输入数据的表示，这些表示具有对预测有效的特征，这被认为是它们优越经验性能的关键因素。为了更好地理解神经网络中特征学习的来源和好处，我们考虑了由实际数据驱动的学习问题，其中标签由一组与类别相关的模式决定，而输入则是由这些模式以及一些背景模式生成的。我们证明了通过梯度下降训练的神经网络可以在这些问题上取得成功。这种成功依赖于有效特征的涌现和改进，这些特征是通过利用数据（特别是输入分布的结构）在指数级多的候选中高效学习到的。相比之下，没有多项式大小的数据无关特征的线性模型能够学习到同样好的误差。此外，如果移除特定的输入结构，那么在统计查询模型中没有多项式算法能够即使弱学习。这些结果提供了理论证据，表明神经网络中的特征学习强烈依赖于输入结构，并导致其优越的性能。我们在合成和真实数据上的初步实验结果也提供了积极的支持。",
        "领域": "深度学习理论、特征学习、神经网络优化",
        "问题": "理解神经网络中特征学习的来源和优势，以及其在特定输入结构下的表现。",
        "动机": "探索神经网络为何能够通过特征学习在预测任务中表现出色，以及这种能力与输入结构之间的关系。",
        "方法": "通过理论分析和实验验证，研究神经网络在特定输入结构下通过梯度下降训练时的特征学习能力及其优势。",
        "关键词": [
            "特征学习",
            "梯度下降",
            "输入结构",
            "神经网络理论",
            "统计查询模型"
        ],
        "涉及的技术概念": {
            "特征学习": "神经网络通过训练自动学习输入数据的有效表示，这些表示有助于提高预测性能。",
            "梯度下降": "一种优化算法，用于调整神经网络的参数以最小化损失函数，是实现特征学习的关键方法。",
            "输入结构": "输入数据的特定组织和分布模式，对神经网络的特征学习能力和最终性能有重要影响。"
        },
        "success": true
    },
    {
        "order": 72,
        "title": "A Theory of Tournament Representations",
        "html": "https://iclr.cc//virtual/2022/poster/6952",
        "abstract": "Real-world tournaments are almost always intransitive. Recent works have noted that parametric models which assume  $d$ dimensional node representations can effectively model intransitive tournaments. However, nothing is known about the structure of the class of tournaments that arise out of any fixed $d$ dimensional representations. In this work, we develop a novel theory for understanding parametric tournament representations. Our first contribution is to structurally characterize the class of tournaments that arise out of $d$ dimensional representations. We do this by showing that these tournament classes have forbidden configurations that must necessarily be a union of flip classes, a novel way to partition the set of all tournaments. We further characterize rank $2$ tournaments completely by showing that the associated forbidden flip class contains just $2$ tournaments. Specifically, we show that the rank $2$ tournaments are equivalent to locally transitive tournaments. This insight allows us to show that the minimum feedback arc set problem on this tournament class can be solved using the standard Quicksort procedure. We also exhibit specific forbidden configurations for rank $4$ tournaments. For a general rank $d$ tournament class, we show that the flip class associated with a coned-doubly regular tournament of size $\\mathcal{O}(\\sqrt{d})$ must be a forbidden configuration. To answer a dual question, using a celebrated result of Froster, we show a lower bound of $\\Theta(\\sqrt{n})$ on the minimum dimension needed to represent all tournaments on $n$ nodes. For any given tournament, we show a novel upper bound on the smallest representation dimension that depends on the least size of the number of unique nodes in any feedback arc set of the flip class associated with a tournament. We show how our results also shed light on the upper bound of sign-rank of matrices. ",
        "conference": "ICLR",
        "success": true,
        "中文标题": "锦标赛表示的理论",
        "摘要翻译": "现实世界中的锦标赛几乎总是不传递的。最近的研究表明，假设存在d维节点表示的参数模型可以有效地模拟非传递锦标赛。然而，对于从任何固定的d维表示中产生的锦标赛的结构一无所知。在这项工作中，我们开发了一种新的理论来理解参数锦标赛表示。我们的第一个贡献是结构性地描述从d维表示中产生的锦标赛的类别。我们通过证明这些锦标赛类别具有必须是翻转类并集的禁止配置来实现这一点，这是一种划分所有锦标赛集合的新方法。我们进一步通过证明相关的禁止翻转类仅包含2个锦标赛来完全表征秩2锦标赛。具体来说，我们表明秩2锦标赛等同于局部传递锦标赛。这种洞察力使我们能够证明可以使用标准Quicksort程序解决此锦标赛类上的最小反馈弧集问题。我们还展示了秩4锦标赛的特定禁止配置。对于一般的秩d锦标赛类，我们表明与大小为O(sqrt(d))的锥形双重规则锦标赛相关的翻转类必须是禁止配置。为了回答一个双重问题，使用Froster的著名结果，我们显示了表示n个节点上的所有锦标赛所需的最小维度的下限为Theta(sqrt(n))。对于任何给定的锦标赛，我们展示了最小表示维度的新上限，该上限取决于与锦标赛相关的翻转类的任何反馈弧集中唯一节点的最小大小。我们展示了我们的结果如何阐明矩阵的符号秩的上限。",
        "领域": "图神经网络",
        "问题": "理解和表征非传递锦标赛，以及确定表示锦标赛所需的最小维度。",
        "动机": "现有的参数模型能够有效地模拟非传递锦标赛，但是对于从固定的d维表示中产生的锦标赛结构知之甚少，因此需要深入研究锦标赛表示的理论。",
        "方法": "通过结构化地描述从d维表示中产生的锦标赛类别，并展示这些类别具有必须是翻转类并集的禁止配置来实现。此外，还使用Quicksort程序解决最小反馈弧集问题，并利用Froster的结果来确定表示所有锦标赛所需的最小维度的下限。",
        "关键词": [
            "锦标赛表示",
            "非传递性",
            "反馈弧集",
            "禁止配置",
            "最小维度"
        ],
        "涉及的技术概念": {
            "翻转类": "一种划分所有锦标赛集合的方法，用于结构性地描述锦标赛的类别。",
            "最小反馈弧集": "用于衡量锦标赛接近传递性的程度，也是解决锦标赛排序问题的一个关键概念。"
        }
    },
    {
        "order": 73,
        "title": "Attacking deep networks with surrogate-based adversarial black-box methods is easy",
        "html": "https://iclr.cc//virtual/2022/poster/6599",
        "abstract": "A recent line of work on black-box adversarial attacks has revived the use of transfer from surrogate models by integrating it into query-based search. However, we find that existing approaches of this type underperform their potential, and can be overly complicated besides. Here, we provide a short and simple algorithm which achieves state-of-the-art results through a search which uses the surrogate network's class-score gradients, with no need for other priors or heuristics. The guiding assumption of the algorithm is that the studied networks are in a fundamental sense learning similar functions, and that a transfer attack from one to the other should thus be fairly 'easy'. This assumption is validated by the extremely low query counts and failure rates achieved: e.g. an untargeted attack on a VGG-16 ImageNet network using a ResNet-152 as the surrogate yields a median query count of 6 at a success rate of 99.9%. Code is available at https://github.com/fiveai/GFCS.",
        "conference": "ICLR",
        "中文标题": "使用基于代理的对抗性黑盒方法攻击深度网络是容易的",
        "摘要翻译": "最近一系列关于黑盒对抗攻击的研究通过将代理模型的转移整合到基于查询的搜索中，重新启用了代理模型的使用。然而，我们发现这种类型的现有方法未能充分发挥其潜力，并且可能过于复杂。在这里，我们提供了一个简短而简单的算法，该算法通过使用代理网络的类分数梯度进行搜索，无需其他先验或启发式方法，就能达到最先进的结果。该算法的指导假设是，所研究的网络在基本意义上学习相似的功能，因此从一个网络到另一个网络的转移攻击应该是相当‘容易’的。这一假设通过实现的极低查询计数和失败率得到了验证：例如，使用ResNet-152作为代理对VGG-16 ImageNet网络进行的非目标攻击，在成功率为99.9%的情况下，中位查询计数为6。代码可在https://github.com/fiveai/GFCS获取。",
        "领域": "对抗性攻击、深度学习安全、图像分类",
        "问题": "如何有效地利用代理模型进行黑盒对抗攻击，同时简化现有方法的复杂性",
        "动机": "现有基于代理模型的黑盒对抗攻击方法未能充分发挥潜力且过于复杂，研究旨在提出一种更简单、更有效的方法",
        "方法": "提出了一种使用代理网络类分数梯度进行搜索的简单算法，无需额外先验或启发式方法",
        "关键词": [
            "对抗性攻击",
            "黑盒攻击",
            "代理模型",
            "深度学习安全",
            "图像分类"
        ],
        "涉及的技术概念": {
            "代理模型": "用于生成对抗样本的替代模型，以黑盒方式攻击目标模型",
            "类分数梯度": "代理网络输出的类别分数梯度，用于指导对抗样本的生成",
            "查询计数": "攻击过程中向目标模型发出的查询次数，衡量攻击效率的指标"
        },
        "success": true
    },
    {
        "order": 74,
        "title": "Attention-based Interpretability with Concept Transformers",
        "html": "https://iclr.cc//virtual/2022/poster/5962",
        "abstract": "Attention is a mechanism that has been instrumental in driving remarkable performance gains of deep neural network models in a host of visual, NLP and multimodal tasks.One additional notable aspect of attention is that it conveniently exposes the ``reasoning'' behind each particular output generated by the model.Specifically, attention scores over input regions or intermediate features have been interpreted as a measure of the contribution of the attended element to the model inference.While the debate in regard to the interpretability of attention is still not settled, researchers have pointed out the existence of architectures and scenarios that afford a meaningful interpretation of the attention mechanism.Here we propose the generalization of attention from low-level input features to high-level concepts as a mechanism to ensure the interpretability of attention scores within a given application domain.In particular, we design the ConceptTransformer, a deep learning module that exposes explanations of the output of a model in which it is embedded in terms of attention over user-defined high-level concepts.Such explanations are \\emph{plausible} (i.e.\\ convincing to the human user) and \\emph{faithful} (i.e.\\ truly reflective of the reasoning process of the model).Plausibility of such explanations is obtained by construction by training the attention heads to conform with known relations between inputs, concepts and outputs dictated by domain knowledge.Faithfulness is achieved by design by enforcing a linear relation between the transformer value vectors that represent the concepts and their contribution to the classification log-probabilities.We validate our ConceptTransformer module on established explainability benchmarks and show how it can be used to infuse domain knowledge into classifiers to improve accuracy, and conversely to extract concept-based explanations of classification outputs. Code to reproduce our results is available at: \\url{https://github.com/ibm/concept_transformer}.",
        "conference": "ICLR",
        "中文标题": "基于注意力的概念变换器可解释性研究",
        "摘要翻译": "注意力机制在推动深度神经网络模型在视觉、自然语言处理（NLP）和多模态任务中取得显著性能提升方面发挥了关键作用。注意力的另一个显著特点是，它方便地揭示了模型生成的每个特定输出背后的‘推理’过程。具体来说，对输入区域或中间特征的注意力分数被解释为被关注元素对模型推理贡献的度量。尽管关于注意力可解释性的争论尚未平息，研究人员已经指出存在允许对注意力机制进行有意义解释的架构和场景。在此，我们提出将注意力从低级输入特征推广到高级概念，作为一种确保在给定应用领域内注意力分数可解释性的机制。特别是，我们设计了ConceptTransformer，这是一个深度学习模块，它通过用户定义的高级概念的注意力，揭示了嵌入其中的模型输出的解释。这些解释是‘可信的’（即对人类用户有说服力）和‘忠实的’（即真实反映了模型的推理过程）。通过训练注意力头以符合由领域知识规定的输入、概念和输出之间的已知关系，构造性地获得了这种解释的可信性。通过强制表示概念及其对分类对数概率贡献的变换器值向量之间的线性关系，设计性地实现了忠实性。我们在已建立的可解释性基准上验证了我们的ConceptTransformer模块，并展示了如何利用它将领域知识注入分类器以提高准确性，以及相反地提取基于概念的分类输出解释。重现我们结果的代码可在以下网址获取：https://github.com/ibm/concept_transformer。",
        "领域": "自然语言处理与视觉结合",
        "问题": "如何提高深度学习模型的可解释性，特别是在使用注意力机制时",
        "动机": "探索和验证注意力机制在深度学习模型中的可解释性，特别是在将注意力从低级特征推广到高级概念时",
        "方法": "设计ConceptTransformer模块，通过训练注意力头以符合领域知识规定的输入、概念和输出之间的关系，确保解释的可信性和忠实性",
        "关键词": [
            "注意力机制",
            "可解释性",
            "概念变换器",
            "深度学习",
            "模型推理"
        ],
        "涉及的技术概念": {
            "注意力机制": "用于揭示模型输出背后的推理过程，提高模型的可解释性",
            "ConceptTransformer": "一种深度学习模块，通过用户定义的高级概念的注意力，提供模型输出的可信和忠实解释",
            "领域知识": "用于训练注意力头，确保解释的可信性，通过符合输入、概念和输出之间的已知关系"
        },
        "success": true
    },
    {
        "order": 75,
        "title": "Audio Lottery: Speech Recognition Made Ultra-Lightweight, Noise-Robust, and Transferable",
        "html": "https://iclr.cc//virtual/2022/poster/6428",
        "abstract": "Lightweight speech recognition models have seen explosive demands owing to a growing amount of speech-interactive features on mobile devices. Since designing such systems from scratch is non-trivial, practitioners typically choose to compress large (pre-trained) speech models. Recently, lottery ticket hypothesis reveals the existence of highly sparse subnetworks that can be trained in isolation without sacrificing the performance of the full models. In this paper, we investigate the tantalizing possibility of using lottery ticket hypothesis to discover lightweight speech recognition models, that are (1) robust to various noise existing in speech; (2) transferable to fit the open-world personalization; and 3) compatible with structured sparsity. We conducted extensive experiments on  CNN-LSTM, RNN-Transducer, and Transformer models, and verified the existence of highly sparse winning tickets that can match the full model performance across those backbones. We obtained winning tickets that have less than 20% of full model weights on all backbones, while the most lightweight one only keeps 4.4% weights. Those winning tickets generalize to structured sparsity with no performance loss, and transfer exceptionally from large source datasets to various target datasets. Perhaps most surprisingly, when the training utterances have high background noises, the winning tickets even substantially outperform the full models, showing the extra bonus of noise robustness by inducing sparsity. Codes are available at https://github.com/VITA-Group/Audio-Lottery.",
        "conference": "ICLR",
        "中文标题": "音频彩票：实现超轻量、抗噪声且可迁移的语音识别",
        "摘要翻译": "由于移动设备上语音交互功能的日益增多，轻量级语音识别模型的需求激增。由于从头设计这样的系统并非易事，实践者通常选择压缩大型（预训练的）语音模型。最近，彩票假设揭示了高度稀疏子网络的存在，这些子网络可以独立训练而不牺牲完整模型的性能。在本文中，我们探讨了利用彩票假设发现轻量级语音识别模型的可能性，这些模型（1）对语音中存在的各种噪声具有鲁棒性；（2）可迁移以适应开放世界的个性化需求；以及（3）与结构化稀疏性兼容。我们在CNN-LSTM、RNN-Transducer和Transformer模型上进行了广泛的实验，验证了高度稀疏的获胜彩票的存在，这些彩票可以在这些骨干网络中匹配完整模型的性能。我们获得的获胜彩票在所有骨干网络上的权重不到完整模型的20%，而最轻量级的仅保留4.4%的权重。这些获胜彩票能够泛化到结构化稀疏性而无需性能损失，并且能够从大型源数据集异常迁移到各种目标数据集。也许最令人惊讶的是，当训练话语具有高背景噪声时，获胜彩票甚至大幅超越完整模型，显示出通过引入稀疏性带来的噪声鲁棒性的额外好处。代码可在https://github.com/VITA-Group/Audio-Lottery获取。",
        "领域": "语音识别, 模型压缩, 噪声鲁棒性",
        "问题": "如何在保持语音识别模型性能的同时，实现模型的轻量化、抗噪声和可迁移性。",
        "动机": "探索利用彩票假设发现轻量级语音识别模型的可能性，以满足移动设备上语音交互功能的需求。",
        "方法": "通过彩票假设发现高度稀疏的子网络，这些子网络可以独立训练而不牺牲完整模型的性能，并在CNN-LSTM、RNN-Transducer和Transformer模型上进行实验验证。",
        "关键词": [
            "语音识别",
            "模型压缩",
            "彩票假设",
            "噪声鲁棒性",
            "可迁移性"
        ],
        "涉及的技术概念": {
            "彩票假设": "揭示了高度稀疏子网络的存在，这些子网络可以独立训练而不牺牲完整模型的性能。",
            "结构化稀疏性": "模型压缩的一种方法，通过保持一定的结构稀疏性来减少模型大小，同时保持性能。",
            "噪声鲁棒性": "模型在高背景噪声环境下仍能保持良好性能的能力。"
        },
        "success": true
    },
    {
        "order": 76,
        "title": "Augmented Sliced Wasserstein Distances",
        "html": "https://iclr.cc//virtual/2022/poster/6818",
        "abstract": "While theoretically appealing, the application of the Wasserstein distance to large-scale machine learning problems has been hampered by its prohibitive computational cost. The sliced Wasserstein distance and its variants improve the computational efficiency through the random projection, yet they suffer from low accuracy if the number of projections is not sufficiently large, because the majority of projections result in trivially small values. In this work, we propose a new family of distance metrics, called augmented sliced Wasserstein distances (ASWDs), constructed by first mapping samples to higher-dimensional hypersurfaces parameterized by neural networks. It is derived from a key observation that (random) linear projections of samples residing on these hypersurfaces would translate to much more flexible nonlinear projections in the original sample space, so they can capture complex structures of the data distribution. We show that the hypersurfaces can be optimized by gradient ascent efficiently. We provide the condition under which the ASWD is a valid metric and show that this can be obtained by an injective neural network architecture. Numerical results demonstrate that the ASWD significantly outperforms other Wasserstein variants for both synthetic and real-world problems.",
        "conference": "ICLR",
        "中文标题": "增强切片Wasserstein距离",
        "摘要翻译": "尽管在理论上具有吸引力，Wasserstein距离在大规模机器学习问题中的应用因其高昂的计算成本而受到限制。切片Wasserstein距离及其变体通过随机投影提高了计算效率，但如果投影数量不足，它们会因大多数投影结果微不足道而遭受低准确度的困扰。在这项工作中，我们提出了一种新的距离度量家族，称为增强切片Wasserstein距离（ASWDs），其构建方法是首先将样本映射到由神经网络参数化的高维超曲面。这一方法源于一个关键观察：样本在这些超曲面上的（随机）线性投影会转化为原始样本空间中更为灵活的非线性投影，因此它们能够捕捉数据分布的复杂结构。我们展示了通过梯度上升可以高效地优化这些超曲面。我们提供了ASWD成为有效度量的条件，并表明这可以通过一个单射神经网络架构实现。数值结果表明，ASWD在合成和现实世界问题上均显著优于其他Wasserstein变体。",
        "领域": "生成模型, 概率度量学习, 深度学习优化",
        "问题": "解决Wasserstein距离在大规模机器学习中计算成本高和切片Wasserstein距离在投影数量不足时准确度低的问题。",
        "动机": "提高Wasserstein距离的计算效率和准确度，以更好地应用于大规模机器学习问题。",
        "方法": "提出增强切片Wasserstein距离（ASWDs），通过将样本映射到高维超曲面并利用神经网络参数化，实现更灵活的非线性投影。",
        "关键词": [
            "增强切片Wasserstein距离",
            "神经网络",
            "高维超曲面",
            "梯度上升",
            "概率度量"
        ],
        "涉及的技术概念": {
            "增强切片Wasserstein距离（ASWDs）": "一种新的距离度量家族，通过将样本映射到高维超曲面来提高计算效率和准确度。",
            "高维超曲面": "由神经网络参数化的空间，用于映射样本以实现更灵活的非线性投影。",
            "梯度上升": "用于优化高维超曲面的方法，以提高ASWD的性能。"
        },
        "success": true
    },
    {
        "order": 77,
        "title": "A Unified Contrastive Energy-based Model for Understanding the Generative Ability of Adversarial Training",
        "html": "https://iclr.cc//virtual/2022/poster/6954",
        "abstract": "Adversarial Training (AT) is known as an effective approach to enhance the robustness of deep neural networks. Recently researchers notice that robust models with AT have good generative ability and can synthesize realistic images, while the reason behind it is yet under-explored. In this paper, we demystify this phenomenon by developing a unified probabilistic framework, called Contrastive Energy-based Models (CEM). On the one hand, we provide the first probabilistic characterization of AT through a unified understanding of robustness and generative ability. On the other hand, our unified framework can be extended to the unsupervised scenario, which interprets unsupervised contrastive learning as an important sampling of CEM. Based on these, we propose a principled method to develop adversarial learning and sampling methods. Experiments show that the sampling methods derived from our framework improve the sample quality in both supervised and unsupervised learning. Notably, our unsupervised adversarial sampling method achieves an Inception score of 9.61 on CIFAR-10, which is superior to previous energy-based models and comparable to state-of-the-art generative models.",
        "conference": "ICLR",
        "中文标题": "理解对抗训练生成能力的统一对比能量模型",
        "摘要翻译": "对抗训练（AT）被认为是增强深度神经网络鲁棒性的有效方法。最近，研究人员注意到，通过AT训练的鲁棒模型具有良好的生成能力，可以合成逼真的图像，但其背后的原因尚未深入探索。在本文中，我们通过开发一个称为对比能量模型（CEM）的统一概率框架，来揭示这一现象。一方面，我们首次通过统一理解鲁棒性和生成能力，对AT进行了概率特性描述。另一方面，我们的统一框架可以扩展到无监督场景，将无监督对比学习解释为CEM的重要采样。基于这些，我们提出了一种原则性方法来开发对抗学习和采样方法。实验表明，从我们的框架中导出的采样方法在监督和无监督学习中均提高了样本质量。值得注意的是，我们的无监督对抗采样方法在CIFAR-10上实现了9.61的初始分数，优于以前的能量模型，并与最先进的生成模型相当。",
        "领域": "对抗学习、生成模型、无监督学习",
        "问题": "探索对抗训练（AT）为何能同时增强模型的鲁棒性和生成能力，并开发一个统一的理论框架来解释这一现象。",
        "动机": "对抗训练不仅能提高模型的鲁棒性，还能意外地赋予模型生成逼真图像的能力，这一现象背后的机制尚未被充分理解。",
        "方法": "开发了一个称为对比能量模型（CEM）的统一概率框架，首次对AT的鲁棒性和生成能力进行了概率特性描述，并将无监督对比学习解释为CEM的重要采样。",
        "关键词": [
            "对抗训练",
            "对比能量模型",
            "生成能力",
            "无监督学习",
            "鲁棒性"
        ],
        "涉及的技术概念": {
            "对抗训练（AT）": "一种通过引入对抗样本来增强模型鲁棒性的训练方法，本文发现其还能提升模型的生成能力。",
            "对比能量模型（CEM）": "本文提出的统一概率框架，用于解释AT的鲁棒性和生成能力，并能扩展到无监督学习场景。",
            "无监督对比学习": "在无监督学习场景下，通过对比学习方法来提取数据特征，本文将其解释为CEM的重要采样过程。"
        },
        "success": true
    },
    {
        "order": 78,
        "title": "A Unified Wasserstein Distributional Robustness Framework for Adversarial Training",
        "html": "https://iclr.cc//virtual/2022/poster/6448",
        "abstract": "It is well-known that deep neural networks (DNNs) are susceptible to adversarial attacks, exposing a severe fragility of deep learning systems. As the result, adversarial training (AT) method, by incorporating adversarial examples during training, represents a natural and effective approach to strengthen the robustness of a DNN-based classifier. However, most AT-based methods, notably PGD-AT and TRADES, typically seek a pointwise adversary that generates the worst-case adversarial example by independently perturbing each data sample, as a way to ``probe'' the vulnerability of the classifier. Arguably, there are unexplored benefits in considering such adversarial effects from an entire distribution. To this end, this paper presents a unified framework that connects Wasserstein distributional robustness with current state-of-the-art AT methods. We introduce a new Wasserstein cost function and a new series of risk functions, with which we show that standard AT methods are special cases of their counterparts in our framework. This connection leads to an intuitive relaxation and generalization of existing AT methods and facilitates the development of a new family of distributional robustness AT-based algorithms. Extensive experiments show that our distributional robustness AT algorithms robustify further their standard AT counterparts in various settings.",
        "conference": "ICLR",
        "中文标题": "统一的Wasserstein分布鲁棒性对抗训练框架",
        "摘要翻译": "众所周知，深度神经网络（DNNs）容易受到对抗攻击的影响，这暴露了深度学习系统的严重脆弱性。因此，通过在训练中融入对抗样本，对抗训练（AT）方法成为了一种自然而有效的途径，用以增强基于DNN的分类器的鲁棒性。然而，大多数基于AT的方法，特别是PGD-AT和TRADES，通常寻求一种点对点的对抗方式，即通过独立扰动每个数据样本来生成最坏情况的对抗样本，以此来“探测”分类器的脆弱性。可以说，从整个分布的角度考虑这种对抗效应还有未被探索的好处。为此，本文提出了一个统一的框架，将Wasserstein分布鲁棒性与当前最先进的AT方法联系起来。我们引入了一个新的Wasserstein成本函数和一系列新的风险函数，通过这些，我们展示了标准AT方法是我们框架中对应方法的特例。这种联系导致了对现有AT方法的直观放松和泛化，并促进了基于分布鲁棒性的新AT算法家族的发展。大量实验表明，我们的分布鲁棒性AT算法在各种设置下进一步强化了其标准AT对应物的鲁棒性。",
        "领域": "对抗训练、深度学习鲁棒性、分布鲁棒性优化",
        "问题": "深度神经网络在面对对抗攻击时的脆弱性问题",
        "动机": "探索从整个数据分布角度考虑对抗效应，以增强深度神经网络的鲁棒性",
        "方法": "提出一个统一的框架，结合Wasserstein分布鲁棒性与对抗训练方法，引入新的成本函数和风险函数，泛化现有AT方法",
        "关键词": [
            "Wasserstein分布鲁棒性",
            "对抗训练",
            "深度学习鲁棒性",
            "分布优化",
            "对抗攻击"
        ],
        "涉及的技术概念": {
            "Wasserstein分布鲁棒性": "用于衡量和优化模型在整个数据分布上的鲁棒性，而不仅仅是单个样本点",
            "对抗训练（AT）": "通过在训练过程中引入对抗样本来增强模型的鲁棒性",
            "风险函数": "新引入的一系列函数，用于在框架内泛化和放松现有的对抗训练方法"
        },
        "success": true
    },
    {
        "order": 79,
        "title": "Automated Self-Supervised Learning for Graphs",
        "html": "https://iclr.cc//virtual/2022/poster/6334",
        "abstract": "Graph self-supervised learning has gained increasing attention due to its capacity to learn expressive node representations. Many pretext tasks, or loss functions have been designed from distinct perspectives. However, we observe that different pretext tasks affect downstream tasks differently cross datasets, which suggests that searching pretext tasks is crucial for graph self-supervised learning.  Different from existing works focusing on designing single pretext tasks, this work aims to investigate how to automatically leverage multiple pretext tasks effectively. Nevertheless, evaluating representations derived from multiple pretext tasks without direct access to ground truth labels makes this problem challenging. To address this obstacle, we make use of a key principle of many real-world graphs, i.e., homophily, or the principle that ``like attracts like,'' as the guidance to effectively search various self-supervised pretext tasks. We provide theoretical understanding and empirical evidence to justify the flexibility of homophily in this  search task. Then we propose the AutoSSL framework which can automatically search over combinations of various self-supervised tasks. By evaluating the framework on 7 real-world datasets, our experimental results show that AutoSSL can significantly boost the performance on downstream tasks including node clustering and node classification compared with training under individual tasks. ",
        "conference": "ICLR",
        "中文标题": "图的自监督学习自动化",
        "摘要翻译": "图的自监督学习因其能够学习表达性节点表示而受到越来越多的关注。许多前置任务或损失函数从不同的角度被设计出来。然而，我们观察到不同的前置任务在不同数据集上对下游任务的影响不同，这表明搜索前置任务对于图的自监督学习至关重要。与现有工作专注于设计单一前置任务不同，本研究旨在探讨如何自动有效地利用多个前置任务。然而，在没有直接访问真实标签的情况下评估来自多个前置任务的表示使得这一问题具有挑战性。为了解决这一障碍，我们利用许多现实世界图的一个关键原则，即同质性，或“物以类聚”的原则，作为有效搜索各种自监督前置任务的指导。我们提供了理论理解和实证证据来证明同质性在这一搜索任务中的灵活性。然后，我们提出了AutoSSL框架，可以自动搜索各种自监督任务的组合。通过在7个真实世界数据集上评估该框架，我们的实验结果表明，与在单个任务下训练相比，AutoSSL可以显著提高包括节点聚类和节点分类在内的下游任务的性能。",
        "领域": "图神经网络、自监督学习、节点表示学习",
        "问题": "如何自动有效地利用多个前置任务以提升图的自监督学习性能",
        "动机": "现有方法多专注于设计单一前置任务，而不同前置任务在不同数据集上对下游任务的影响不同，因此需要一种方法来自动搜索和组合多个前置任务。",
        "方法": "利用图的同质性原则作为指导，提出AutoSSL框架自动搜索和组合多种自监督任务。",
        "关键词": [
            "图自监督学习",
            "自动任务搜索",
            "同质性",
            "节点表示学习",
            "AutoSSL"
        ],
        "涉及的技术概念": {
            "同质性": "图中相似节点倾向于连接的原理，用于指导自监督任务的搜索。",
            "AutoSSL框架": "自动搜索和组合多种自监督任务的框架，旨在提升下游任务的性能。",
            "前置任务": "自监督学习中用于预训练模型的任务，其设计对学习有效的节点表示至关重要。"
        },
        "success": true
    },
    {
        "order": 80,
        "title": "Automatic Loss Function Search for Predict-Then-Optimize Problems with Strong Ranking Property",
        "html": "https://iclr.cc//virtual/2022/poster/6648",
        "abstract": "Combinatorial optimization problems with parameters to be predicted from side information are commonly seen in a variety of problems during the paradigm shift from reactive decision making to proactive decision making. Due to the misalignment between the continuous prediction results and the discrete decisions in optimization problems, it is hard to achieve a satisfactory prediction result with the ordinary $l_2$ loss in the prediction phase. To properly connect the prediction loss with the optimization goal, in this paper we propose a total group preorder (TGP) loss and its differential version called approximated total group preorder (ATGP) loss for predict-then-optimize (PTO) problems with strong ranking property. These new losses are provably more robust than the usual $l_2$ loss in a linear regression setting and have great potential to extend to other settings. We also propose an automatic searching algorithm that adapts the ATGP loss to PTO problems with different combinatorial structures. Extensive experiments on the ranking problem, the knapsack problem, and the shortest path problem have demonstrated that our proposed method can achieve a significant performance compared to the other methods designed for PTO problems.",
        "conference": "ICLR",
        "中文标题": "具有强排序属性的预测后优化问题的自动损失函数搜索",
        "摘要翻译": "在从反应式决策向主动式决策的范式转变过程中，常见于各种问题中的是需要从侧面信息预测参数的组合优化问题。由于连续预测结果与优化问题中离散决策之间的不对齐，在预测阶段使用普通的l2损失很难获得满意的预测结果。为了正确地将预测损失与优化目标联系起来，本文针对具有强排序属性的预测后优化（PTO）问题，提出了一种总群预序（TGP）损失及其微分版本，称为近似总群预序（ATGP）损失。在线性回归设置中，这些新损失被证明比通常的l2损失更稳健，并且有很大的潜力扩展到其他设置。我们还提出了一种自动搜索算法，使ATGP损失适应于具有不同组合结构的PTO问题。在排序问题、背包问题和最短路径问题上的大量实验表明，与其他为PTO问题设计的方法相比，我们提出的方法可以实现显著的性能。",
        "领域": "组合优化、机器学习优化、预测后优化",
        "问题": "解决预测阶段连续预测结果与优化问题中离散决策之间的不对齐问题",
        "动机": "为了正确地将预测损失与优化目标联系起来，提高预测后优化问题的性能",
        "方法": "提出总群预序（TGP）损失及其微分版本近似总群预序（ATGP）损失，并开发自动搜索算法以适应不同组合结构的PTO问题",
        "关键词": [
            "预测后优化",
            "损失函数",
            "组合优化",
            "自动搜索算法",
            "强排序属性"
        ],
        "涉及的技术概念": {
            "总群预序（TGP）损失": "用于预测后优化问题的新型损失函数，旨在更好地将预测损失与优化目标对齐",
            "近似总群预序（ATGP）损失": "TGP损失的微分版本，适用于线性回归等设置，提供更稳健的性能",
            "自动搜索算法": "一种算法，用于自动调整ATGP损失以适应不同组合结构的预测后优化问题"
        },
        "success": true
    },
    {
        "order": 81,
        "title": "Autonomous Learning of Object-Centric Abstractions for High-Level Planning",
        "html": "https://iclr.cc//virtual/2022/poster/7202",
        "abstract": "We propose a method for autonomously learning an object-centric representation of a continuous and high-dimensional environment that is suitable for planning. Such representations can immediately be transferred between tasks that share the same types of objects, resulting in agents that require fewer samples to learn a model of a new task. We first demonstrate our approach on a 2D crafting domain consisting of numerous objects where the agent learns a compact, lifted representation that generalises across objects. We then apply it to a series of Minecraft tasks to learn object-centric representations and object types - directly from pixel data - that can be leveraged to solve new tasks quickly. The resulting learned representations enable the use of a task-level planner, resulting in an agent capable of transferring learned representations to form complex, long-term plans.",
        "conference": "ICLR",
        "中文标题": "面向高层规划的对象中心抽象自主学习方法",
        "摘要翻译": "我们提出了一种自主学习方法，用于学习适合规划的连续高维环境的对象中心表示。这种表示可以立即在共享相同类型对象的任务之间转移，从而使代理需要更少的样本来学习新任务的模型。我们首先在一个由众多对象组成的2D制作领域展示了我们的方法，其中代理学习了一个紧凑的提升表示，该表示能够跨对象泛化。然后，我们将其应用于一系列Minecraft任务，以直接从像素数据中学习对象中心表示和对象类型，这些表示和类型可以用来快速解决新任务。最终学习到的表示使得任务级规划器的使用成为可能，从而形成一个能够将学习到的表示转移以形成复杂长期计划的代理。",
        "领域": "强化学习、计算机视觉与游戏AI结合、自主机器人规划",
        "问题": "如何在连续高维环境中自主地学习适合规划的对象中心表示，以加速新任务的学习和规划。",
        "动机": "为了开发能够快速适应新任务并形成长期规划的智能代理，需要一种能够从高维输入（如像素数据）中直接学习对象中心表示的方法。",
        "方法": "提出了一种自主学习方法，该方法能够从连续高维环境中学习对象中心的抽象表示，支持跨任务的知识转移，并在2D制作和Minecraft任务中验证了其有效性。",
        "关键词": [
            "对象中心表示",
            "自主学习",
            "高层规划",
            "知识转移",
            "Minecraft任务"
        ],
        "涉及的技术概念": {
            "对象中心表示": "一种将环境表示为对象及其关系的抽象方式，便于规划和学习。",
            "自主学习": "代理在没有明确监督的情况下，从环境中自主地学习表示和策略。",
            "高层规划": "基于抽象表示进行的长期和复杂任务规划，能够跨任务转移知识。"
        },
        "success": true
    },
    {
        "order": 82,
        "title": "Autonomous Reinforcement Learning: Formalism and Benchmarking",
        "html": "https://iclr.cc//virtual/2022/poster/7153",
        "abstract": "Reinforcement learning (RL) provides a naturalistic framing for learning through trial and error, which is appealing both because of its simplicity and effectiveness and because of its resemblance to how humans and animals acquire skills through experience. However, real-world embodied learning, such as that performed by humans and animals, is situated in a continual, non-episodic world, whereas common benchmark tasks in RL are episodic, with the environment resetting between trials to provide the agent with multiple attempts. This discrepancy presents a major challenge when we attempt to take RL algorithms developed for episodic simulated environments and run  them on real-world platforms, such as robots. In this paper, we aim to address this discrepancy by laying out a framework for Autonomous Reinforcement Learning (ARL): reinforcement learning where the agent not only learns through its own experience, but also contends with lack of human supervision to reset between trials. We introduce a simulated benchmark EARL based on this framework, containing a set of diverse and challenging simulated tasks reflective of the hurdles introduced to learning when only a minimal reliance on extrinsic intervention can be assumed. We show that standard approaches to episodic RL and existing approaches struggle as interventions are minimized, underscoring the need for developing new algorithms for reinforcement learning with a greater focus on autonomy.",
        "conference": "ICLR",
        "中文标题": "自主强化学习：形式化与基准测试",
        "摘要翻译": "强化学习（RL）为通过试错学习提供了一个自然主义的框架，这既因其简单性和有效性而吸引人，也因其与人类和动物通过经验获取技能的方式相似。然而，现实世界中的实体学习，如人类和动物所进行的，是处于一个连续、非片段化的世界中，而RL中常见的基准任务是片段化的，环境在试验之间重置，为代理提供多次尝试。当我们尝试将针对片段化模拟环境开发的RL算法运行在现实世界平台上，如机器人时，这种差异带来了重大挑战。在本文中，我们旨在通过为自主强化学习（ARL）建立一个框架来解决这一差异：强化学习中，代理不仅通过自身经验学习，还要应对试验之间缺乏人类监督重置的问题。我们基于这一框架引入了一个模拟基准EARL，包含一组多样且具有挑战性的模拟任务，反映了在学习过程中当只能假设对外部干预有最小依赖时引入的障碍。我们展示了标准的片段化RL方法和现有方法在干预最小化时表现不佳，强调了开发新算法以更注重自主性的强化学习的必要性。",
        "领域": "强化学习、机器人学习、自主系统",
        "问题": "解决强化学习在连续、非片段化现实世界环境中的应用问题",
        "动机": "现实世界中的学习是连续和非片段化的，而现有的强化学习基准和算法主要针对片段化环境设计，这限制了强化学习在现实世界中的应用。",
        "方法": "提出了自主强化学习（ARL）框架，并基于此框架开发了一个模拟基准EARL，用于评估在最小外部干预下的学习算法性能。",
        "关键词": [
            "自主强化学习",
            "连续学习",
            "基准测试",
            "机器人学习",
            "非片段化环境"
        ],
        "涉及的技术概念": {
            "自主强化学习（ARL）": "一种强化学习框架，代理在缺乏人类监督重置的情况下通过自身经验学习。",
            "EARL基准": "基于ARL框架开发的模拟基准，用于评估在最小外部干预下的学习算法性能。",
            "非片段化环境": "指学习环境是连续进行的，不进行试验之间的重置，更贴近现实世界的学习场景。"
        },
        "success": true
    },
    {
        "order": 83,
        "title": "Autoregressive Diffusion Models",
        "html": "https://iclr.cc//virtual/2022/poster/6228",
        "abstract": "We introduce Autoregressive Diffusion Models (ARDMs), a model class encompassing and generalizing order-agnostic autoregressive models (Uria et al., 2014) and absorbing discrete diffusion (Austin et al., 2021), which we show are special cases of ARDMs under mild assumptions. ARDMs are simple to implement and easy to train. Unlike standard ARMs, they do not require causal masking of model representations, and can be trained using an efficient objective similar to modern probabilistic diffusion models that scales favourably to highly-dimensional data. At test time, ARDMs support parallel generation which can be adapted to fit any given generation budget. We find that ARDMs require significantly fewer steps than discrete diffusion models to attain the same performance. Finally, we apply ARDMs to lossless compression, and show that they are uniquely suited to this task. Contrary to existing approaches based on bits-back coding, ARDMs obtain compelling results not only on complete datasets, but also on compressing single data points. Moreover, this can be done using a modest number of network calls for (de)compression due to the model's adaptable parallel generation.",
        "conference": "ICLR",
        "中文标题": "自回归扩散模型",
        "摘要翻译": "我们介绍了自回归扩散模型（ARDMs），这是一个包含并推广了顺序无关自回归模型（Uria等人，2014年）和吸收离散扩散（Austin等人，2021年）的模型类别，我们在温和的假设下展示了它们是ARDMs的特殊情况。ARDMs实现简单，易于训练。与标准的ARMs不同，它们不需要对模型表示进行因果掩码，并且可以使用类似于现代概率扩散模型的高效目标进行训练，该目标对高维数据具有良好的扩展性。在测试时，ARDMs支持并行生成，可以适应任何给定的生成预算。我们发现，ARDMs需要比离散扩散模型少得多的步骤来达到相同的性能。最后，我们将ARDMs应用于无损压缩，并显示它们特别适合这项任务。与现有的基于比特回编码的方法相反，ARDMs不仅在完整的数据集上获得了令人信服的结果，而且在压缩单个数据点时也是如此。此外，由于模型的可适应并行生成，这可以通过适度的网络调用来完成（解）压缩。",
        "领域": "生成模型, 无损压缩, 概率模型",
        "问题": "如何高效地实现高维数据的生成和无损压缩",
        "动机": "探索一种既简单又高效的模型，能够在不牺牲性能的情况下减少生成步骤，并适用于无损压缩任务",
        "方法": "提出自回归扩散模型（ARDMs），通过去除因果掩码需求和使用高效的训练目标，实现高维数据的快速生成和压缩",
        "关键词": [
            "自回归扩散模型",
            "无损压缩",
            "并行生成",
            "高维数据",
            "概率扩散模型"
        ],
        "涉及的技术概念": {
            "自回归扩散模型（ARDMs）": "一种结合自回归模型和扩散模型特点的新型模型，用于高效的数据生成和压缩",
            "顺序无关自回归模型": "ARDMs的一个特殊情况，允许模型不考虑数据的生成顺序",
            "吸收离散扩散": "ARDMs的另一个特殊情况，专注于离散数据的扩散过程"
        },
        "success": true
    },
    {
        "order": 84,
        "title": "Autoregressive Quantile Flows for Predictive Uncertainty Estimation",
        "html": "https://iclr.cc//virtual/2022/poster/6671",
        "abstract": "Numerous applications of machine learning involve representing probability distributions over high-dimensional data. We propose autoregressive quantile flows, a flexible class of normalizing flow models trained using a novel objective based on proper scoring rules. Our objective does not require calculating computationally expensive determinants of Jacobians during training and supports new types of neural architectures, such as neural autoregressive flows from which it is easy to sample.     We leverage these models in quantile flow regression, an approach that parameterizes predictive conditional distributions with flows, resulting in improved probabilistic predictions on tasks such as time series forecasting and object detection.    Our novel objective functions and neural flow parameterizations also yield improvements on popular generation and density estimation tasks, and represent a step beyond maximum likelihood learning of flows.",
        "conference": "ICLR",
        "中文标题": "自回归分位数流用于预测不确定性估计",
        "摘要翻译": "机器学习的众多应用涉及表示高维数据的概率分布。我们提出了自回归分位数流，这是一种灵活的正规化流模型类别，通过基于适当评分规则的新目标进行训练。我们的目标在训练过程中不需要计算计算成本高昂的雅可比行列式，并支持新型神经架构，如易于采样的神经自回归流。我们在分位数流回归中利用这些模型，这是一种用流参数化预测条件分布的方法，从而在时间序列预测和目标检测等任务上改进了概率预测。我们的新目标函数和神经流参数化也在流行的生成和密度估计任务上带来了改进，并代表了超越流的极大似然学习的一步。",
        "领域": "概率深度学习, 时间序列预测, 目标检测",
        "问题": "如何在高维数据中有效表示和预测概率分布",
        "动机": "改进机器学习中概率分布的表示和预测能力，特别是在高维数据和时间序列预测等任务中",
        "方法": "提出自回归分位数流模型，使用基于适当评分规则的新目标进行训练，避免计算雅可比行列式，并支持新型神经架构",
        "关键词": [
            "自回归分位数流",
            "概率预测",
            "正规化流",
            "时间序列预测",
            "目标检测"
        ],
        "涉及的技术概念": {
            "自回归分位数流": "一种灵活的正规化流模型，用于表示高维数据的概率分布",
            "适当评分规则": "用于训练模型的新目标，不需要计算雅可比行列式",
            "神经自回归流": "一种新型神经架构，易于采样，用于改进概率预测"
        },
        "success": true
    },
    {
        "order": 85,
        "title": "Auto-scaling Vision Transformers without Training",
        "html": "https://iclr.cc//virtual/2022/poster/5995",
        "abstract": "This work targets automated designing and scaling of Vision Transformers (ViTs). The motivation comes from two pain spots: 1) the lack of efficient and principled methods for designing and scaling ViTs; 2) the tremendous computational cost of training ViT that is much heavier than its convolution counterpart. To tackle these issues, we propose As-ViT, an auto-scaling framework for ViTs without training, which automatically discovers and scales up ViTs in an efficient and principled manner. Specifically, we first design a 'seed' ViT topology by leveraging a training-free search process. This extremely fast search is fulfilled by a comprehensive study of ViT's network complexity, yielding a strong Kendall-tau correlation with ground-truth accuracies. Second, starting from the 'seed' topology, we automate the scaling rule for ViTs by growing widths/depths to different ViT layers. This results in a series of architectures with different numbers of parameters in a single run. Finally, based on the observation that ViTs can tolerate coarse tokenization in early training stages, we propose a progressive tokenization strategy to train ViTs faster and cheaper. As a unified framework, As-ViT achieves strong performance on classification (83.5% top1 on ImageNet-1k) and detection (52.7% mAP on COCO) without any manual crafting nor scaling of ViT architectures: the end-to-end model design and scaling process costs only 12 hours on one V100 GPU. Our code is available at https://github.com/VITA-Group/AsViT.",
        "conference": "ICLR",
        "中文标题": "无需训练的视觉变换器自动缩放",
        "摘要翻译": "本工作旨在自动化设计和缩放视觉变换器（ViTs）。动机源于两个痛点：1）缺乏高效且有原则的方法来设计和缩放ViTs；2）训练ViT的巨大计算成本远高于其卷积对应物。为解决这些问题，我们提出了As-ViT，一个无需训练的ViT自动缩放框架，它以高效且有原则的方式自动发现并放大ViTs。具体来说，我们首先通过利用无需训练的搜索过程设计了一个'种子'ViT拓扑。这一极其快速的搜索通过全面研究ViT的网络复杂性实现，与真实准确率产生了强Kendall-tau相关性。其次，从'种子'拓扑出发，我们通过向不同ViT层增加宽度/深度自动化了ViTs的缩放规则。这导致在一次运行中产生了一系列具有不同参数数量的架构。最后，基于ViTs在早期训练阶段可以容忍粗糙标记化的观察，我们提出了一种渐进式标记化策略，以更快更便宜地训练ViTs。作为一个统一框架，As-ViT在分类（ImageNet-1k上83.5%的top1准确率）和检测（COCO上52.7%的mAP）上实现了强劲性能，无需任何手动设计或缩放ViT架构：端到端的模型设计和缩放过程仅在一台V100 GPU上花费12小时。我们的代码可在https://github.com/VITA-Group/AsViT获取。",
        "领域": "视觉变换器设计、模型缩放、自动化机器学习",
        "问题": "自动化设计和缩放视觉变换器（ViTs）的高效且有原则的方法缺乏，以及训练ViT的巨大计算成本问题。",
        "动机": "解决设计和缩放ViTs缺乏高效方法的问题，以及降低训练ViT的高计算成本。",
        "方法": "提出As-ViT框架，通过无需训练的搜索过程设计'种子'ViT拓扑，自动化缩放规则，并采用渐进式标记化策略加速训练。",
        "关键词": [
            "视觉变换器",
            "自动缩放",
            "无需训练",
            "模型设计",
            "渐进式标记化"
        ],
        "涉及的技术概念": {
            "视觉变换器（ViTs）": "一种基于自注意力机制的视觉模型架构，用于图像分类和检测任务。",
            "自动缩放框架": "无需人工干预，自动调整模型宽度和深度以优化性能的框架。",
            "渐进式标记化": "在训练初期使用粗糙标记化，逐步细化以加速训练和降低成本的技术。"
        },
        "success": true
    },
    {
        "order": 86,
        "title": "Auto-Transfer: Learning to Route Transferable Representations",
        "html": "https://iclr.cc//virtual/2022/poster/6166",
        "abstract": "Knowledge transfer between heterogeneous source and target networks and tasks has received a lot of attention in recent times as large amounts of quality labeled data can be difficult to obtain in many applications. Existing approaches typically constrain the target deep neural network (DNN) feature representations to be close to the source DNNs feature representations, which can be limiting. We, in this paper, propose a novel adversarial multi-armed bandit approach that automatically learns to route source representations to appropriate target representations following which they are combined in meaningful ways to produce accurate target models. We see upwards of 5\\% accuracy improvements compared with the state-of-the-art knowledge transfer methods on four benchmark (target) image datasets CUB200, Stanford Dogs, MIT67, and Stanford40 where the source dataset is ImageNet. We qualitatively analyze the goodness of our transfer scheme by showing individual examples of the important features focused on by our target network at different layers compared with the (closest) competitors. We also observe that our improvement over other methods is higher for smaller target datasets making it an effective tool for small data applications that may benefit from transfer learning.",
        "conference": "ICLR",
        "中文标题": "自动迁移：学习路由可迁移表示",
        "摘要翻译": "近年来，由于在许多应用中难以获取大量高质量的标注数据，异构源网络和目标网络及任务之间的知识迁移受到了广泛关注。现有方法通常限制目标深度神经网络（DNN）的特征表示接近源DNN的特征表示，这可能存在局限性。本文中，我们提出了一种新颖的对抗性多臂老虎机方法，该方法自动学习将源表示路由到适当的目标表示，随后以有意义的方式组合它们以产生准确的目标模型。在四个基准（目标）图像数据集CUB200、Stanford Dogs、MIT67和Stanford40上，与最先进的知识迁移方法相比，我们看到了超过5%的准确率提升，其中源数据集为ImageNet。我们通过展示目标网络在不同层上关注的重要特征的个别例子，与（最接近的）竞争对手相比，定性分析了我们迁移方案的优点。我们还观察到，对于较小的目标数据集，我们相对于其他方法的改进更高，这使其成为可能受益于迁移学习的小数据应用的有效工具。",
        "领域": "迁移学习",
        "问题": "如何有效地在异构源和目标网络及任务之间进行知识迁移",
        "动机": "解决现有方法在限制目标DNN特征表示接近源DNN特征表示时的局限性",
        "方法": "提出了一种对抗性多臂老虎机方法，自动学习将源表示路由到适当的目标表示，并以有意义的方式组合它们",
        "关键词": [
            "知识迁移",
            "对抗性多臂老虎机",
            "异构网络"
        ],
        "涉及的技术概念": {
            "对抗性多臂老虎机": "用于自动学习将源表示路由到适当目标表示的方法",
            "深度神经网络": "用于特征表示和知识迁移的基础模型架构",
            "知识迁移": "从源任务或数据集向目标任务或数据集传递知识的过程"
        },
        "success": true
    },
    {
        "order": 87,
        "title": "Axiomatic Explanations for Visual Search, Retrieval, and Similarity Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6983",
        "abstract": "Visual search, recommendation, and contrastive similarity learning power technologies that impact billions of users worldwide. Modern model architectures can be complex and difficult to interpret, and there are several competing techniques one can use to explain a search engine's behavior. We show that the theory of fair credit assignment provides a unique axiomatic solution that generalizes several existing recommendation- and metric-explainability techniques in the literature. Using this formalism, we show when existing approaches violate 'fairness' and derive methods that sidestep these shortcomings and naturally handle counterfactual information. More specifically, we show existing approaches implicitly approximate second-order Shapley-Taylor indices and extend CAM, GradCAM, LIME, SHAP, SBSM, and other methods to search engines. These extensions can extract pairwise correspondences between images from trained opaque-box models. We also introduce a fast kernel-based method for estimating Shapley-Taylor indices that require orders of magnitude fewer function evaluations to converge. Finally, we show that these game-theoretic measures yield more consistent explanations for image similarity architectures. ",
        "conference": "ICLR",
        "中文标题": "视觉搜索、检索与相似性学习的公理解释",
        "摘要翻译": "视觉搜索、推荐和对比相似性学习技术影响着全球数十亿用户。现代模型架构可能复杂且难以解释，且有多种竞争性技术可用于解释搜索引擎的行为。我们表明，公平信用分配理论提供了一个独特的公理解决方案，该方案概括了文献中现有的几种推荐和度量可解释性技术。利用这一形式化方法，我们展示了现有方法何时违反‘公平性’，并推导出绕过这些缺点并自然处理反事实信息的方法。更具体地说，我们展示了现有方法隐式地近似二阶Shapley-Taylor指数，并将CAM、GradCAM、LIME、SHAP、SBSM等方法扩展到搜索引擎。这些扩展可以从训练好的黑盒模型中提取图像间的成对对应关系。我们还介绍了一种基于内核的快速方法，用于估计Shapley-Taylor指数，该方法需要的函数评估次数少得多即可收敛。最后，我们展示了这些博弈论度量为图像相似性架构提供了更一致的解释。",
        "领域": "视觉搜索、推荐系统、相似性学习",
        "问题": "解释现代复杂模型在视觉搜索、推荐和相似性学习中的行为，并解决现有解释技术中的公平性问题。",
        "动机": "由于现代模型架构的复杂性和难以解释性，以及现有解释技术可能违反公平性原则，研究旨在提供一种公理解释方法，以更公平、一致地解释模型行为。",
        "方法": "利用公平信用分配理论，提出一种公理解释方法，扩展现有解释技术（如CAM、GradCAM、LIME等）到搜索引擎，并引入基于内核的快速方法估计Shapley-Taylor指数。",
        "关键词": [
            "公理解释",
            "公平信用分配",
            "Shapley-Taylor指数",
            "视觉搜索",
            "相似性学习"
        ],
        "涉及的技术概念": {
            "公平信用分配理论": "用于提供一种独特的公理解决方案，概括现有推荐和度量可解释性技术。",
            "Shapley-Taylor指数": "用于量化模型中各个特征的贡献，提供更一致的解释。",
            "基于内核的快速方法": "用于高效估计Shapley-Taylor指数，减少所需的函数评估次数。"
        },
        "success": true
    },
    {
        "order": 88,
        "title": "A Zest of LIME: Towards Architecture-Independent Model Distances",
        "html": "https://iclr.cc//virtual/2022/poster/6094",
        "abstract": "Definitions of the distance between two machine learning models either characterize the similarity of the models' predictions or of their weights. While similarity of weights is attractive because it implies similarity of predictions in the limit, it suffers from being inapplicable to comparing models with different architectures. On the other hand, the similarity of predictions is broadly applicable but depends heavily on the choice of model inputs during comparison. In this paper, we instead propose to compute distance between black-box models by comparing their Local Interpretable Model-Agnostic Explanations (LIME). To compare two models, we take a reference dataset, and locally approximate the models on each reference point with linear models trained by LIME. We then compute the cosine distance between the concatenated weights of the linear models. This yields an approach that is both architecture-independent and possesses the benefits of comparing models in weight space. We empirically show that our method, which we call Zest, can be applied to two problems that require measurements of model similarity: detecting model stealing and machine unlearning.",
        "conference": "ICLR",
        "中文标题": "LIME的精华：迈向架构无关的模型距离",
        "摘要翻译": "机器学习模型之间距离的定义要么表征模型预测的相似性，要么表征它们权重的相似性。虽然权重的相似性因为其在极限情况下意味着预测的相似性而具有吸引力，但它存在无法比较不同架构模型的缺点。另一方面，预测的相似性虽然适用范围广，但在比较过程中高度依赖于模型输入的选择。在本文中，我们提出通过比较它们的局部可解释模型无关解释（LIME）来计算黑盒模型之间的距离。为了比较两个模型，我们采用一个参考数据集，并在每个参考点上用LIME训练的线性模型局部近似模型。然后，我们计算线性模型连接权重的余弦距离。这产生了一种既架构无关又具有在权重空间比较模型优势的方法。我们通过实验表明，我们称之为Zest的方法可以应用于需要模型相似性测量的两个问题：检测模型窃取和机器遗忘。",
        "领域": "模型解释性、模型安全、模型比较",
        "问题": "如何定义和计算不同架构机器学习模型之间的距离",
        "动机": "为了解决现有模型距离定义在比较不同架构模型时的局限性，以及预测相似性对输入选择的依赖性",
        "方法": "通过比较模型的局部可解释模型无关解释（LIME）来计算距离，具体包括在参考数据集上局部近似模型并计算线性模型权重的余弦距离",
        "关键词": [
            "模型距离",
            "LIME",
            "架构无关",
            "模型窃取检测",
            "机器遗忘"
        ],
        "涉及的技术概念": {
            "局部可解释模型无关解释（LIME）": "用于局部近似黑盒模型的线性模型，以便于比较不同架构模型",
            "余弦距离": "用于衡量两个线性模型权重之间的相似性",
            "模型窃取检测": "应用模型距离测量来识别模型是否被未经授权复制"
        },
        "success": true
    },
    {
        "order": 89,
        "title": "Back2Future: Leveraging Backfill Dynamics for Improving Real-time Predictions in Future",
        "html": "https://iclr.cc//virtual/2022/poster/6343",
        "abstract": "For real-time forecasting in domains like public health and macroeconomics, data collection is a non-trivial and demanding task. Often after being initially released, it undergoes several revisions later (maybe due to human or technical constraints) - as a result, it may take weeks until the data reaches a stable value. This so-called ‘backfill’ phenomenon and its effect on model performance have been barely addressed in the prior literature. In this paper, we introduce the multi-variate backfill problem using COVID-19 as the motivating example. We construct a detailed dataset composed of relevant signals over the past year of the pandemic. We then systematically characterize several patterns in backfill dynamics and leverage our observations for formulating a novel problem and neural framework, Back2Future, that aims to refines a given model's predictions in real-time. Our extensive experiments demonstrate that our method refines the performance of the diverse set of top models for COVID-19 forecasting and GDP growth forecasting. Specifically, we show that Back2Future refined top COVID-19 models by 6.65% to 11.24% and yield an 18% improvement over non-trivial baselines. In addition, we show that our model improves model evaluation too; hence policy-makers can better understand the true accuracy of forecasting models in real-time.",
        "conference": "ICLR",
        "中文标题": "回归未来：利用回填动态提升实时预测能力",
        "摘要翻译": "在公共卫生和宏观经济学等领域进行实时预测时，数据收集是一项既非微不足道又要求苛刻的任务。数据在最初发布后，往往会经历多次修订（可能是由于人为或技术限制），因此可能需要数周时间数据才能达到稳定值。这种所谓的‘回填’现象及其对模型性能的影响在之前的文献中几乎没有被提及。在本文中，我们以COVID-19为例，介绍了多变量回填问题。我们构建了一个详细的数据集，包含了过去一年大流行期间的相关信号。然后，我们系统地描述了回填动态中的几种模式，并利用我们的观察结果来制定一个新问题和神经框架——Back2Future，旨在实时优化给定模型的预测。我们的大量实验表明，我们的方法优化了用于COVID-19预测和GDP增长预测的多种顶级模型的性能。具体来说，我们展示了Back2Future将顶级COVID-19模型的性能提升了6.65%到11.24%，并且比非平凡基线提高了18%。此外，我们还展示了我们的模型也改进了模型评估；因此，政策制定者可以更好地理解预测模型在实时中的真实准确性。",
        "领域": "时间序列预测, 公共卫生数据分析, 宏观经济预测",
        "问题": "解决数据回填现象对实时预测模型性能的影响",
        "动机": "探索并利用数据回填动态，以提升实时预测模型的准确性和可靠性",
        "方法": "构建包含回填动态的数据集，系统分析回填模式，并提出Back2Future神经框架以优化实时预测",
        "关键词": [
            "数据回填",
            "实时预测",
            "COVID-19预测",
            "GDP增长预测",
            "模型优化"
        ],
        "涉及的技术概念": {
            "多变量回填问题": "指在数据收集和发布过程中，由于后续修订导致的多变量数据动态变化问题",
            "Back2Future框架": "一种旨在利用回填动态实时优化预测模型性能的神经框架",
            "模型评估改进": "通过Back2Future框架，不仅优化了预测性能，还提高了模型评估的准确性，使政策制定者能够更准确地理解预测模型的实时表现"
        },
        "success": true
    },
    {
        "order": 90,
        "title": "Backdoor Defense via Decoupling the Training Process",
        "html": "https://iclr.cc//virtual/2022/poster/6519",
        "abstract": "Recent studies have revealed that deep neural networks (DNNs) are vulnerable to backdoor attacks, where attackers embed hidden backdoors in the DNN model by poisoning a few training samples. The attacked model behaves normally on benign samples, whereas its prediction will be maliciously changed when the backdoor is activated. We reveal that poisoned samples tend to cluster together in the feature space of the attacked DNN model, which is mostly due to the end-to-end supervised training paradigm. Inspired by this observation, we propose a novel backdoor defense via decoupling the original end-to-end training process into three stages. Specifically, we first learn the backbone of a DNN model via \\emph{self-supervised learning} based on training samples without their labels. The learned backbone will map samples with the same ground-truth label to similar locations in the feature space. Then, we freeze the parameters of the learned backbone and train the remaining fully connected layers via standard training with all (labeled) training samples. Lastly, to further alleviate side-effects of poisoned samples in the second stage, we remove labels of some `low-credible' samples determined based on the learned model and conduct a \\emph{semi-supervised fine-tuning} of the whole model. Extensive experiments on multiple benchmark datasets and DNN models verify that the proposed defense is effective in reducing backdoor threats while preserving high accuracy in predicting benign samples. Our code is available at \\url{https://github.com/SCLBD/DBD}.",
        "conference": "ICLR",
        "中文标题": "通过解耦训练过程实现后门防御",
        "摘要翻译": "最近的研究表明，深度神经网络（DNNs）容易受到后门攻击，攻击者通过毒害少量训练样本在DNN模型中嵌入隐藏的后门。被攻击的模型在良性样本上表现正常，但当后门被激活时，其预测会被恶意改变。我们发现，毒害样本在被攻击DNN模型的特征空间中倾向于聚集在一起，这主要是由于端到端的监督训练范式。受此观察启发，我们提出了一种新颖的后门防御方法，通过将原始的端到端训练过程解耦为三个阶段。具体来说，我们首先通过基于无标签训练样本的自我监督学习来学习DNN模型的主干。学习到的主干会将具有相同真实标签的样本映射到特征空间中的相似位置。然后，我们冻结学习到的主干的参数，并通过标准训练使用所有（标记的）训练样本训练剩余的完全连接层。最后，为了进一步减轻第二阶段中毒害样本的副作用，我们根据学习到的模型移除一些‘低可信度’样本的标签，并对整个模型进行半监督微调。在多个基准数据集和DNN模型上的大量实验验证了所提出的防御方法在减少后门威胁的同时，保持了预测良性样本的高准确率。我们的代码可在https://github.com/SCLBD/DBD获取。",
        "领域": "深度学习安全、后门攻击防御、自我监督学习",
        "问题": "深度神经网络模型容易受到后门攻击，攻击者通过毒害训练样本嵌入隐藏的后门，影响模型在特定条件下的预测行为。",
        "动机": "揭示毒害样本在特征空间中的聚集现象，并提出通过解耦训练过程来防御后门攻击，以保持模型在良性样本上的高准确率。",
        "方法": "将端到端训练过程解耦为三个阶段：自我监督学习主干、冻结主干并训练完全连接层、半监督微调整个模型。",
        "关键词": [
            "后门防御",
            "解耦训练",
            "自我监督学习",
            "半监督微调",
            "深度学习安全"
        ],
        "涉及的技术概念": {
            "自我监督学习": "用于学习DNN模型的主干，无需标签信息，将相同标签的样本映射到特征空间中的相似位置。",
            "半监督微调": "在移除低可信度样本标签后，对整个模型进行微调，以减轻毒害样本的副作用。",
            "端到端训练解耦": "将传统的端到端训练过程分解为多个阶段，以减少后门攻击的影响。"
        },
        "success": true
    },
    {
        "order": 91,
        "title": "BadPre: Task-agnostic Backdoor Attacks to Pre-trained NLP Foundation Models",
        "html": "https://iclr.cc//virtual/2022/poster/6220",
        "abstract": "Pre-trained Natural Language Processing (NLP) models, which can be adapted to a variety of downstream language tasks via fine-tuning, highly accelerate the learning progress of NLP models. However, NLP models have been shown to be vulnerable to backdoor attacks. Previous NLP backdoor attacks mainly focus on one specific task. This limitation makes existing solutions less applicable to different NLP models which have been widely used in various tasks.In this work, we propose BadPre, the first backdoor attack against various downstream models built based on pre-trained NLP models. BadPre can launch trojan attacks against different language tasks with the same trigger.The key insight of our approach is that downstream models can inherit the security characteristics from the pre-trained models. Specifically, we leverage data posing to the pre-trained NLP models and then inference the downstream models with sentences embedded triggers. Furthermore, to fool backdoor detectors, we design a novel adversarial attack method to generate a more robust trigger.Experimental results indicate that our approach can effectively attack a wide range of downstream NLP tasks and exhibit significant robustness against backdoor detectors.",
        "conference": "ICLR",
        "中文标题": "BadPre：针对预训练NLP基础模型的任务无关后门攻击",
        "摘要翻译": "预训练的自然语言处理（NLP）模型通过微调可以适应各种下游语言任务，极大地加速了NLP模型的学习进程。然而，NLP模型已被证明容易受到后门攻击。以往的NLP后门攻击主要集中在某一特定任务上。这一限制使得现有解决方案难以广泛应用于各种任务中的不同NLP模型。在本工作中，我们提出了BadPre，这是第一个针对基于预训练NLP模型构建的各种下游模型的后门攻击。BadPre能够使用相同的触发器对不同语言任务发起木马攻击。我们方法的关键洞察是下游模型可以从预训练模型中继承安全特性。具体来说，我们利用数据对预训练NLP模型进行投毒，然后使用嵌入触发器的句子对下游模型进行推理。此外，为了欺骗后门检测器，我们设计了一种新颖的对抗攻击方法以生成更健壮的触发器。实验结果表明，我们的方法能够有效攻击广泛的下游NLP任务，并对后门检测器表现出显著的鲁棒性。",
        "领域": "自然语言处理安全、后门攻击、模型鲁棒性",
        "问题": "如何设计一种任务无关的后门攻击方法，能够针对基于预训练NLP模型构建的各种下游模型进行有效攻击。",
        "动机": "现有的NLP后门攻击主要集中在特定任务上，难以广泛应用于各种任务中的不同NLP模型，因此需要一种更通用的攻击方法。",
        "方法": "通过数据投毒预训练NLP模型，并设计一种新颖的对抗攻击方法生成健壮的触发器，以攻击下游模型。",
        "关键词": [
            "后门攻击",
            "预训练模型",
            "NLP安全",
            "对抗攻击",
            "任务无关"
        ],
        "涉及的技术概念": {
            "数据投毒": "通过向预训练模型中注入恶意数据，使得下游模型继承这些不安全特性。",
            "对抗攻击": "设计特定的输入（触发器）以欺骗模型，使其产生错误的输出。",
            "触发器": "嵌入在输入数据中的特定模式或序列，用于激活后门攻击。"
        },
        "success": true
    },
    {
        "order": 92,
        "title": "Bag of Instances Aggregation Boosts Self-supervised Distillation",
        "html": "https://iclr.cc//virtual/2022/poster/5909",
        "abstract": "Recent advances in self-supervised learning have experienced remarkable progress, especially for contrastive learning based methods, which regard each image as well as its augmentations as an individual class and try to distinguish them from all other images. However, due to the large quantity of exemplars, this kind of pretext task intrinsically suffers from slow convergence and is hard for optimization. This is especially true for small-scale models, in which we find the performance drops dramatically comparing with its supervised counterpart. In this paper, we propose a simple but effective distillation strategy for unsupervised learning. The highlight is that the relationship among similar samples counts and can be seamlessly transferred to the student to boost the performance. Our method, termed as BINGO, which is short for Bag of InstaNces aGgregatiOn, targets at transferring the relationship learned by the teacher to the student. Here bag of instances indicates a set of similar samples constructed by the teacher and are grouped within a bag, and the goal of distillation is to aggregate compact representations over the student with respect to instances in a bag. Notably, BINGO achieves new state-of-the-art performance on small-scale models, i.e., 65.5% and 68.9% top-1 accuracies with linear evaluation on ImageNet, using ResNet-18 and ResNet-34 as the backbones respectively, surpassing baselines (52.5% and 57.4% top-1 accuracies) by a significant margin. The code is available at https://github.com/haohang96/bingo.",
        "conference": "ICLR",
        "中文标题": "实例集合聚合提升自监督蒸馏",
        "摘要翻译": "自监督学习的最新进展取得了显著进步，特别是基于对比学习的方法，这些方法将每张图像及其增强视为一个独立的类别，并试图将它们与其他所有图像区分开来。然而，由于样本数量庞大，这种预训练任务本质上收敛缓慢且难以优化。对于小规模模型尤其如此，我们发现其性能与有监督的对应模型相比显著下降。在本文中，我们提出了一种简单但有效的无监督学习蒸馏策略。其亮点在于，相似样本之间的关系至关重要，并且可以无缝地转移到学生模型以提升性能。我们的方法，称为BINGO，即实例集合聚合的缩写，旨在将教师模型学习到的关系转移到学生模型。这里的实例集合指的是由教师模型构建的一组相似样本，它们被分组在一个集合中，蒸馏的目标是聚合学生模型关于集合中实例的紧凑表示。值得注意的是，BINGO在小规模模型上实现了新的最先进性能，即使用ResNet-18和ResNet-34作为骨干网络，在ImageNet上的线性评估分别达到了65.5%和68.9%的top-1准确率，显著超过了基线（52.5%和57.4%的top-1准确率）。代码可在https://github.com/haohang96/bingo获取。",
        "领域": "自监督学习、模型蒸馏、小规模模型优化",
        "问题": "解决自监督学习中由于样本数量庞大导致的收敛慢和优化难的问题，特别是在小规模模型上性能显著下降的问题。",
        "动机": "通过利用相似样本之间的关系，提升小规模模型在自监督学习中的性能。",
        "方法": "提出了一种称为BINGO的蒸馏策略，通过聚合教师模型构建的实例集合中的紧凑表示，将学习到的关系转移到学生模型。",
        "关键词": [
            "自监督学习",
            "模型蒸馏",
            "实例集合聚合",
            "小规模模型",
            "性能提升"
        ],
        "涉及的技术概念": {
            "实例集合聚合": "通过将相似样本分组到一个集合中，聚合学生模型关于这些实例的紧凑表示，以提升性能。",
            "自监督蒸馏": "一种无监督学习策略，通过将教师模型学习到的知识转移到学生模型，以提升学生模型的性能。",
            "对比学习": "一种自监督学习方法，通过将每张图像及其增强视为一个独立的类别，并试图将它们与其他所有图像区分开来。"
        },
        "success": true
    },
    {
        "order": 93,
        "title": "BAM: Bayes with Adaptive Memory",
        "html": "https://iclr.cc//virtual/2022/poster/6508",
        "abstract": "Online learning via Bayes' theorem allows new data to be continuously integrated into an agent's current beliefs. However, a naive application of Bayesian methods in non-stationary environments leads to slow adaptation and results in state estimates that may converge confidently to the wrong parameter value. A common solution when learning in changing environments is to discard/downweight past data; however, this simple mechanism of 'forgetting' fails to account for the fact that many real-world environments involve revisiting similar states. We propose a new framework, Bayes with Adaptive Memory (BAM), that takes advantage of past experience by allowing the agent to choose which past observations to remember and which to forget. We demonstrate that BAM generalizes many popular Bayesian update rules for non-stationary environments. Through a variety of experiments, we demonstrate the ability of BAM to continuously adapt in an ever-changing world.",
        "conference": "ICLR",
        "中文标题": "BAM：具有自适应记忆的贝叶斯方法",
        "摘要翻译": "通过贝叶斯定理进行在线学习允许新数据不断整合到智能体的当前信念中。然而，在非平稳环境中天真地应用贝叶斯方法会导致适应缓慢，并且状态估计可能会自信地收敛到错误的参数值。在变化环境中学习时，一个常见的解决方案是丢弃/降低过去数据的权重；然而，这种简单的'遗忘'机制未能考虑到许多现实世界环境涉及重新访问相似状态的事实。我们提出了一个新框架，具有自适应记忆的贝叶斯方法（BAM），它通过允许智能体选择记住哪些过去的观察和忘记哪些过去的观察来利用过去的经验。我们证明BAM概括了许多流行的非平稳环境贝叶斯更新规则。通过各种实验，我们展示了BAM在不断变化的世界中持续适应的能力。",
        "领域": "在线学习、非平稳环境适应、贝叶斯方法",
        "问题": "在非平稳环境中，传统的贝叶斯方法适应缓慢且可能收敛到错误的参数值。",
        "动机": "为了解决在非平稳环境中传统贝叶斯方法适应慢和可能错误收敛的问题，同时利用过去经验中的有用信息。",
        "方法": "提出了具有自适应记忆的贝叶斯方法（BAM），允许智能体选择性地记住或忘记过去的观察，以优化学习过程。",
        "关键词": [
            "自适应记忆",
            "贝叶斯方法",
            "非平稳环境",
            "在线学习",
            "状态估计"
        ],
        "涉及的技术概念": {
            "贝叶斯定理": "用于在线学习，允许新数据不断整合到智能体的当前信念中。",
            "非平稳环境": "指环境状态随时间变化，传统的学习方法难以适应。",
            "自适应记忆": "BAM框架的核心，允许智能体选择性地记住或忘记过去的观察，以优化学习过程。"
        },
        "success": true
    },
    {
        "order": 94,
        "title": "Bandit Learning with Joint Effect of Incentivized Sampling, Delayed Sampling Feedback, and Self-Reinforcing User Preferences",
        "html": "https://iclr.cc//virtual/2022/poster/7025",
        "abstract": "In this paper, we consider a new multi-armed bandit (MAB) framework motivated by three common complications in online recommender systems in practice: (i) the platform (learning agent) cannot sample an intended product directly and has to incentivize customers to select this product (e.g., promotions and coupons); (ii) customer feedbacks are often received later than their selection times; and (iii) customer preferences among products are influenced and reinforced by historical feedbacks. From the platform's perspective, the goal of the MAB framework is to maximize total reward without incurring excessive incentive costs. A major challenge of this MAB framework is that the loss of information caused by feedback delay complicates both user preference evolution and arm incentivizing decisions, both of which are already highly non-trivial even by themselves. Toward this end, we first propose a policy called ``UCB-Filtering-with-Delayed-Feedback'' (UCB-FDF) policy for this new MAB framework. In our analysis, we consider delayed feedbacks that can have either arm-independent or arm-dependent distributions. In both cases, we allow unbounded support for the random delays, i.e., the random delay can be infinite. We show that the delay impacts in both cases can still be upper bounded by an additive penalty on both the regret and total incentive costs. This further implies that logarithmic regret and incentive cost growth rates are achievable under this new MAB framework. Experimental results corroborate our theoretical analysis on both regret and incentive costs.",
        "conference": "ICLR",
        "中文标题": "激励采样、延迟采样反馈与自我强化用户偏好联合效应下的老虎机学习",
        "摘要翻译": "本文考虑了一种新的多臂老虎机（MAB）框架，该框架受到在线推荐系统中三个常见复杂情况的启发：（i）平台（学习代理）无法直接采样目标产品，而需要通过激励（如促销和优惠券）来促使顾客选择该产品；（ii）顾客的反馈往往在其选择时间之后才收到；（iii）顾客对产品的偏好受到历史反馈的影响和强化。从平台的角度来看，MAB框架的目标是在不产生过高激励成本的情况下最大化总奖励。这一MAB框架的一个主要挑战是，反馈延迟导致的信息损失使得用户偏好演变和臂激励决策都变得更加复杂，这两者即使单独考虑也已经非常不简单。为此，我们首先为这一新的MAB框架提出了一种名为‘带延迟反馈的UCB过滤’（UCB-FDF）的策略。在我们的分析中，我们考虑了延迟反馈可以具有臂独立或臂依赖的分布。在这两种情况下，我们都允许随机延迟具有无界支持，即随机延迟可以是无限的。我们展示了在这两种情况下，延迟的影响仍然可以通过在遗憾和总激励成本上添加一个附加惩罚来上界。这进一步表明，在这一新的MAB框架下，可以实现对数级的遗憾和激励成本增长率。实验结果证实了我们对遗憾和激励成本的理论分析。",
        "领域": "在线推荐系统、多臂老虎机问题、激励学习",
        "问题": "解决在线推荐系统中因激励采样、延迟反馈和用户偏好自我强化导致的复杂多臂老虎机问题",
        "动机": "研究如何在不产生过高激励成本的情况下，最大化在线推荐系统的总奖励",
        "方法": "提出了一种名为‘带延迟反馈的UCB过滤’（UCB-FDF）的策略，分析了延迟反馈对用户偏好演变和臂激励决策的影响",
        "关键词": [
            "多臂老虎机",
            "在线推荐系统",
            "延迟反馈",
            "激励学习",
            "用户偏好"
        ],
        "涉及的技术概念": {
            "多臂老虎机（MAB）": "用于在线推荐系统中，通过选择不同的‘臂’（即推荐选项）来最大化总奖励的框架",
            "延迟反馈": "顾客反馈在其选择时间之后才收到，影响学习代理的决策过程",
            "UCB-FDF策略": "一种针对带有延迟反馈的多臂老虎机问题的策略，旨在优化遗憾和激励成本"
        },
        "success": true
    },
    {
        "order": 95,
        "title": "Bayesian Framework for Gradient Leakage",
        "html": "https://iclr.cc//virtual/2022/poster/6934",
        "abstract": "Federated learning is an established method for training machine learning models without sharing training data. However, recent work has shown that it cannot guarantee data privacy as shared gradients can still leak sensitive information. To formalize the problem of gradient leakage, we propose a theoretical framework that enables, for the first time, analysis of the Bayes optimal adversary phrased as an optimization problem. We demonstrate that existing leakage attacks can be seen as approximations of this optimal adversary with different assumptions on the probability distributions of the input data and gradients. Our experiments confirm the effectiveness of the Bayes optimal adversary when it has knowledge of the underlying distribution. Further, our experimental evaluation shows that several existing heuristic defenses are not effective against stronger attacks, especially early in the training process. Thus, our findings indicate that the construction of more effective defenses and their evaluation remains an open problem.",
        "conference": "ICLR",
        "中文标题": "梯度泄漏的贝叶斯框架",
        "摘要翻译": "联邦学习是一种在不共享训练数据的情况下训练机器学习模型的既定方法。然而，最近的研究表明，它不能保证数据隐私，因为共享的梯度仍然可能泄露敏感信息。为了形式化梯度泄漏的问题，我们提出了一个理论框架，首次使得分析贝叶斯最优对手成为可能，该对手被表述为一个优化问题。我们证明，现有的泄漏攻击可以被视为这种最优对手在不同输入数据和梯度概率分布假设下的近似。我们的实验证实，当贝叶斯最优对手了解底层分布时，其有效性。此外，我们的实验评估显示，几种现有的启发式防御措施对更强的攻击无效，尤其是在训练过程的早期。因此，我们的研究结果表明，构建更有效的防御措施及其评估仍然是一个未解决的问题。",
        "领域": "联邦学习、数据隐私保护、对抗性攻击",
        "问题": "联邦学习中共享梯度可能导致敏感信息泄露的问题",
        "动机": "为了解决联邦学习中梯度泄漏导致的数据隐私问题，并分析最优对手的行为",
        "方法": "提出了一个理论框架来分析贝叶斯最优对手，并通过实验评估现有防御措施的有效性",
        "关键词": [
            "联邦学习",
            "梯度泄漏",
            "贝叶斯最优对手",
            "数据隐私",
            "对抗性攻击"
        ],
        "涉及的技术概念": {
            "贝叶斯最优对手": "在给定数据分布的情况下，能够最有效地从梯度中推断出原始数据的理论对手模型",
            "梯度泄漏": "在联邦学习中，通过分析共享的梯度信息来推断出原始训练数据的隐私泄露问题",
            "联邦学习": "一种分布式机器学习方法，允许多个参与方共同训练模型而不直接共享原始数据"
        },
        "success": true
    },
    {
        "order": 96,
        "title": "Bayesian Modeling and Uncertainty Quantification for Learning to Optimize: What, Why, and How",
        "html": "https://iclr.cc//virtual/2022/poster/6796",
        "abstract": "Optimizing an objective function with uncertainty awareness is well-known to improve the accuracy and confidence of optimization solutions. Meanwhile, another relevant but very different question remains yet open: how to model and quantify the uncertainty of an optimization algorithm (a.k.a., optimizer) itself? To close such a gap, the prerequisite is to consider the optimizers as sampled from a distribution, rather than a few prefabricated and fixed update rules. We first take the novel angle to consider the algorithmic space of optimizers, and provide definitions for the optimizer prior and likelihood, that intrinsically determine the posterior and therefore uncertainty. We then leverage the recent advance of learning to optimize (L2O) for the space parameterization, with the end-to-end training pipeline built via variational inference, referred to as uncertainty-aware L2O (UA-L2O). Our study represents the first effort to recognize and quantify the uncertainty of the optimization algorithm. The extensive numerical results show that, UA-L2O achieves superior uncertainty calibration with accurate confidence estimation and tight confidence intervals, suggesting the improved posterior estimation thanks to considering optimizer uncertainty. Intriguingly, UA-L2O even improves optimization performances for two out of three test functions, the loss function in data privacy attack, and four of five cases of the energy function in protein docking. Our codes are released at https://github.com/Shen-Lab/Bayesian-L2O.",
        "conference": "ICLR",
        "中文标题": "贝叶斯建模与不确定性量化在学习优化中的应用：是什么、为什么及如何做",
        "摘要翻译": "具有不确定性意识的优化目标函数被广泛认为可以提高优化解决方案的准确性和置信度。与此同时，另一个相关但非常不同的问题仍然开放：如何建模和量化优化算法（即优化器）本身的不确定性？为了填补这一空白，前提是将优化器视为从分布中采样，而不是几个预制和固定的更新规则。我们首先从新颖的角度考虑优化器的算法空间，并为优化器先验和似然提供定义，这些定义本质上决定了后验和因此的不确定性。然后，我们利用学习优化（L2O）的最新进展进行空间参数化，通过变分推断构建端到端训练流程，称为不确定性感知L2O（UA-L2O）。我们的研究代表了识别和量化优化算法不确定性的首次努力。广泛的数值结果表明，UA-L2O实现了卓越的不确定性校准，具有准确的置信估计和紧密的置信区间，这表明由于考虑了优化器的不确定性，后验估计得到了改善。有趣的是，UA-L2O甚至在三项测试函数中的两项、数据隐私攻击中的损失函数以及蛋白质对接中能量函数的五个案例中的四个中提高了优化性能。我们的代码发布于https://github.com/Shen-Lab/Bayesian-L2O。",
        "领域": "优化算法、机器学习、贝叶斯方法",
        "问题": "如何建模和量化优化算法本身的不确定性",
        "动机": "填补优化算法不确定性建模和量化的研究空白",
        "方法": "通过变分推断构建端到端训练流程，利用学习优化（L2O）进行空间参数化",
        "关键词": [
            "不确定性量化",
            "学习优化",
            "贝叶斯建模",
            "变分推断",
            "优化算法"
        ],
        "涉及的技术概念": {
            "优化器先验": "定义了优化器在算法空间中的先验分布，为不确定性量化提供基础",
            "变分推断": "用于构建端到端训练流程，实现不确定性感知的学习优化",
            "不确定性感知L2O（UA-L2O）": "结合了学习优化和不确定性量化的方法，旨在提高优化性能和不确定性校准"
        },
        "success": true
    },
    {
        "order": 97,
        "title": "Bayesian Neural Network Priors Revisited",
        "html": "https://iclr.cc//virtual/2022/poster/6955",
        "abstract": "Isotropic Gaussian priors are the de facto standard for modern Bayesian neural network inference. However, it is unclear whether these priors accurately reflect our true beliefs about the weight distributions or give optimal performance. To find better priors, we study summary statistics of neural network weights in networks trained using stochastic gradient descent (SGD). We find that convolutional neural network (CNN) and ResNet weights display strong spatial correlations, while fully connected networks (FCNNs) display heavy-tailed weight distributions. We show that building these observations into priors can lead to improved performance on a variety of image classification datasets. Surprisingly, these priors mitigate the cold posterior effect in FCNNs, but slightly increase the cold posterior effect in ResNets.",
        "conference": "ICLR",
        "中文标题": "贝叶斯神经网络先验再探",
        "摘要翻译": "各向同性高斯先验是现代贝叶斯神经网络推理的事实标准。然而，尚不清楚这些先验是否准确反映了我们对权重分布的真实信念，或是否提供了最佳性能。为了寻找更好的先验，我们研究了使用随机梯度下降（SGD）训练的网络中神经网络权重的摘要统计量。我们发现卷积神经网络（CNN）和ResNet权重显示出强烈的空间相关性，而全连接网络（FCNNs）显示出重尾权重分布。我们表明，将这些观察结果纳入先验可以在一系列图像分类数据集上带来性能提升。令人惊讶的是，这些先验减轻了FCNNs中的冷后效应，但在ResNets中略微增加了冷后效应。",
        "领域": "贝叶斯深度学习、图像分类、神经网络优化",
        "问题": "探索和优化贝叶斯神经网络中的先验分布，以提高模型性能和准确反映权重分布的真实信念。",
        "动机": "现有的各向同性高斯先验可能无法准确反映神经网络权重的真实分布或提供最佳性能，因此需要研究更合适的先验分布。",
        "方法": "通过分析使用随机梯度下降（SGD）训练的神经网络权重的摘要统计量，研究卷积神经网络（CNN）、ResNet和全连接网络（FCNNs）的权重特性，并将这些特性融入先验分布设计中。",
        "关键词": [
            "贝叶斯神经网络",
            "先验分布",
            "随机梯度下降",
            "图像分类",
            "冷后效应"
        ],
        "涉及的技术概念": {
            "各向同性高斯先验": "现代贝叶斯神经网络推理中常用的先验分布，假设权重分布为各向同性的高斯分布。",
            "随机梯度下降（SGD）": "一种优化算法，用于训练神经网络，通过迭代更新权重以最小化损失函数。",
            "冷后效应": "在贝叶斯神经网络中，后验分布比先验分布更集中于某些区域的现象，可能影响模型的泛化能力。"
        },
        "success": true
    },
    {
        "order": 98,
        "title": "BDDM: Bilateral Denoising Diffusion Models for Fast and High-Quality Speech Synthesis",
        "html": "https://iclr.cc//virtual/2022/poster/6010",
        "abstract": "Diffusion probabilistic models (DPMs) and their extensions have emerged as competitive generative models yet confront challenges of efficient sampling. We propose a new bilateral denoising diffusion model (BDDM) that parameterizes both the forward and reverse processes with a schedule network and a score network, which can train with a novel bilateral modeling objective. We show that the new surrogate objective can achieve a lower bound of the log marginal likelihood tighter than a conventional surrogate. We also find that BDDM allows inheriting pre-trained score network parameters from any DPMs and consequently enables speedy and stable learning of the schedule network and optimization of a noise schedule for sampling. Our experiments demonstrate that BDDMs can generate high-fidelity audio samples with as few as three sampling steps. Moreover, compared to other state-of-the-art diffusion-based neural vocoders, BDDMs produce comparable or higher quality samples indistinguishable from human speech, notably with only seven sampling steps (143x faster than WaveGrad and 28.6x faster than DiffWave).",
        "conference": "ICLR",
        "中文标题": "BDDM：用于快速高质量语音合成的双边去噪扩散模型",
        "摘要翻译": "扩散概率模型（DPMs）及其扩展已成为具有竞争力的生成模型，但仍面临高效采样的挑战。我们提出了一种新的双边去噪扩散模型（BDDM），该模型通过一个调度网络和一个分数网络参数化了前向和反向过程，能够用一个新的双边建模目标进行训练。我们展示了新的替代目标可以实现比传统替代目标更紧密的对数边际似然下界。我们还发现，BDDM允许从任何DPMs继承预训练的分数网络参数，从而能够快速稳定地学习调度网络和优化用于采样的噪声调度。我们的实验表明，BDDMs可以仅用三个采样步骤生成高保真音频样本。此外，与其他基于扩散的最先进神经声码器相比，BDDMs产生与人类语音无法区分的高质量样本，仅需七个采样步骤（比WaveGrad快143倍，比DiffWave快28.6倍）。",
        "领域": "语音合成, 生成模型, 神经声码器",
        "问题": "解决扩散概率模型在语音合成中采样效率低下的问题",
        "动机": "提高扩散模型在语音合成中的采样效率，同时保持或提高生成语音的质量",
        "方法": "提出双边去噪扩散模型（BDDM），通过调度网络和分数网络参数化前向和反向过程，使用双边建模目标进行训练",
        "关键词": [
            "语音合成",
            "扩散模型",
            "双边去噪",
            "高效采样",
            "神经声码器"
        ],
        "涉及的技术概念": {
            "双边去噪扩散模型（BDDM）": "一种新的扩散模型，通过参数化前向和反向过程来提高采样效率",
            "调度网络": "用于优化噪声调度，实现快速稳定的学习",
            "分数网络": "用于参数化扩散过程，可以从任何预训练的扩散概率模型继承参数"
        },
        "success": true
    },
    {
        "order": 99,
        "title": "BEiT: BERT Pre-Training of Image Transformers",
        "html": "https://iclr.cc//virtual/2022/poster/6323",
        "abstract": "We introduce a self-supervised vision representation model BEiT, which stands for Bidirectional Encoder representation from Image Transformers. Following BERT developed in the natural language processing area, we propose a masked image modeling task to pretrain vision Transformers. Specifically, each image has two views in our pre-training, i.e., image patches (such as 16 x 16 pixels), and visual tokens (i.e., discrete tokens). We first ``tokenize'' the original image into visual tokens. Then we randomly mask some image patches and fed them into the backbone Transformer. The pre-training objective is to recover the original visual tokens based on the corrupted image patches. After pre-training BEiT, we directly fine-tune the model parameters on downstream tasks by appending task layers upon the pretrained encoder. Experimental results on image classification and semantic segmentation show that our model achieves competitive results with previous pre-training methods.",
        "conference": "ICLR",
        "中文标题": "BEiT：图像变换器的BERT预训练",
        "摘要翻译": "我们介绍了一种自监督视觉表示模型BEiT，全称为来自图像变换器的双向编码器表示。遵循自然语言处理领域开发的BERT，我们提出了一种掩码图像建模任务来预训练视觉变换器。具体来说，在我们的预训练中，每张图像有两个视图，即图像块（如16x16像素）和视觉标记（即离散标记）。我们首先将原始图像‘标记化’为视觉标记。然后我们随机掩码一些图像块并将它们输入到骨干变换器中。预训练的目标是基于损坏的图像块恢复原始视觉标记。预训练BEiT后，我们通过在预训练编码器上附加任务层，直接在下游任务上微调模型参数。图像分类和语义分割的实验结果表明，我们的模型与之前的预训练方法相比取得了竞争性的结果。",
        "领域": "自监督学习、图像分类、语义分割",
        "问题": "如何有效地预训练视觉变换器以提升下游视觉任务的性能",
        "动机": "借鉴自然语言处理中的BERT模型，开发适用于视觉任务的自监督预训练方法",
        "方法": "提出掩码图像建模任务，通过恢复被掩码的图像块来预训练视觉变换器",
        "关键词": [
            "自监督学习",
            "视觉变换器",
            "掩码图像建模",
            "图像分类",
            "语义分割"
        ],
        "涉及的技术概念": {
            "自监督学习": "无需人工标注数据，通过设计预测任务从数据本身学习表示",
            "视觉变换器": "将变换器架构应用于视觉任务，处理图像块序列",
            "掩码图像建模": "通过预测被掩码的图像块内容来预训练模型，类似于BERT中的掩码语言建模"
        },
        "success": true
    },
    {
        "order": 100,
        "title": "Benchmarking the Spectrum of Agent Capabilities",
        "html": "https://iclr.cc//virtual/2022/poster/6250",
        "abstract": "Evaluating the general abilities of intelligent agents requires complex simulation environments. Existing benchmarks typically evaluate only one narrow task per environment, requiring researchers to perform expensive training runs on many different environments. We introduce Crafter, an open world survival game with visual inputs that evaluates a wide range of general abilities within a single environment. Agents either learn from the provided reward signal or through intrinsic objectives and are evaluated by semantically meaningful achievements that can be unlocked during each episode, such as discovering resources and crafting tools. Consistently unlocking all achievements requires strong generalization, deep exploration, and long-term reasoning. We experimentally verify that Crafter is of appropriate difficulty to drive future research and provide baselines scores of reward agents and unsupervised agents. Furthermore, we observe sophisticated behaviors emerging from maximizing the reward signal, such as building tunnel systems, bridges, houses, and plantations. We hope that Crafter will accelerate research progress by quickly evaluating a wide spectrum of abilities.",
        "conference": "ICLR",
        "中文标题": "评估智能代理能力的全面基准",
        "摘要翻译": "评估智能代理的通用能力需要复杂的模拟环境。现有的基准测试通常每个环境仅评估一个狭窄的任务，要求研究人员在许多不同的环境中进行昂贵的训练运行。我们介绍了Crafter，这是一个具有视觉输入的开放世界生存游戏，可以在单一环境中评估广泛的通用能力。代理要么从提供的奖励信号中学习，要么通过内在目标学习，并通过可以在每个情节中解锁的语义上有意义的成就进行评估，例如发现资源和制作工具。持续解锁所有成就需要强大的泛化能力、深度探索和长期推理。我们通过实验验证了Crafter的难度适中，足以推动未来的研究，并提供了奖励代理和无监督代理的基线分数。此外，我们观察到通过最大化奖励信号而出现的复杂行为，如建造隧道系统、桥梁、房屋和种植园。我们希望Crafter能够通过快速评估广泛的能力范围来加速研究进展。",
        "领域": "智能代理评估、开放世界游戏、强化学习",
        "问题": "如何在单一环境中全面评估智能代理的多种能力，避免在多个环境中进行昂贵训练的问题。",
        "动机": "为了解决现有基准测试局限于单一任务评估的问题，提供一个能够评估智能代理广泛能力的统一环境。",
        "方法": "开发了一个名为Crafter的开放世界生存游戏，通过视觉输入和成就系统评估代理的多种能力，包括奖励学习和无监督学习。",
        "关键词": [
            "智能代理",
            "开放世界游戏",
            "能力评估",
            "强化学习",
            "成就系统"
        ],
        "涉及的技术概念": {
            "开放世界生存游戏": "作为评估智能代理能力的平台，提供丰富的任务和环境交互。",
            "成就系统": "用于评估代理在游戏中的表现，通过解锁特定成就来衡量其能力。",
            "奖励信号": "代理学习的目标，通过最大化奖励来引导代理行为，实现复杂任务的完成。"
        },
        "success": true
    },
    {
        "order": 101,
        "title": "Better Supervisory Signals by Observing Learning Paths",
        "html": "https://iclr.cc//virtual/2022/poster/6630",
        "abstract": "Better-supervised models might have better performance. In this paper, we first clarify what makes for good supervision for a classification problem, and then explain two existing label refining methods, label smoothing and knowledge distillation, in terms of our proposed criterion. To further answer why and how better supervision emerges, we observe the learning path, i.e., the trajectory of the model's predictions during training, for each training sample. We find that the model can spontaneously refine 'bad' labels through a 'zig-zag' learning path, which occurs on both toy and real datasets. Observing the learning path not only provides a new perspective for understanding knowledge distillation, overfitting, and learning dynamics, but also reveals that the supervisory signal of a teacher network can be very unstable near the best points in training on real tasks. Inspired by this, we propose a new knowledge distillation scheme, Filter-KD, which improves downstream classification performance in various settings.",
        "conference": "ICLR",
        "中文标题": "通过观察学习路径获得更好的监督信号",
        "摘要翻译": "更好的监督模型可能会有更好的性能。在本文中，我们首先明确了对于一个分类问题来说，什么构成了好的监督，然后根据我们提出的标准解释了两种现有的标签精炼方法：标签平滑和知识蒸馏。为了进一步回答为什么以及如何出现更好的监督，我们观察了每个训练样本的学习路径，即模型在训练过程中预测的轨迹。我们发现，模型可以通过‘之字形’学习路径自发地精炼‘坏’标签，这种现象在玩具数据集和真实数据集上都会发生。观察学习路径不仅为理解知识蒸馏、过拟合和学习动态提供了新的视角，而且还揭示了在真实任务训练的最佳点附近，教师网络的监督信号可能非常不稳定。受此启发，我们提出了一种新的知识蒸馏方案——Filter-KD，它在各种设置下提高了下游分类任务的性能。",
        "领域": "知识蒸馏",
        "问题": "如何通过观察学习路径来改进监督信号，从而提高分类模型的性能",
        "动机": "探索更好的监督信号生成方法，以提升模型的学习效率和性能",
        "方法": "通过观察和分析模型在学习过程中的预测轨迹（学习路径），提出了一种新的知识蒸馏方案Filter-KD",
        "关键词": [
            "学习路径",
            "知识蒸馏",
            "监督信号",
            "标签精炼",
            "分类性能"
        ],
        "涉及的技术概念": {
            "学习路径": "模型在训练过程中预测的轨迹，用于分析模型如何自发地精炼‘坏’标签",
            "知识蒸馏": "一种模型压缩技术，通过教师网络指导学生网络的学习，以提高学生网络的性能",
            "监督信号": "在训练过程中指导模型学习的信号，其质量直接影响模型的学习效果和最终性能"
        },
        "success": true
    },
    {
        "order": 102,
        "title": "Beyond ImageNet Attack: Towards Crafting Adversarial Examples for Black-box Domains",
        "html": "https://iclr.cc//virtual/2022/poster/6469",
        "abstract": "Adversarial examples have posed a severe threat to deep neural networks due to their transferable nature. Currently, various works have paid great efforts to enhance the cross-model transferability, which mostly assume the substitute model is trained in the same domain as the target model.However, in reality, the relevant information of the deployed model is unlikely to leak.Hence, it is vital to build a more practical black-box threat model to overcome this limitation and evaluate the vulnerability of deployed models.In this paper, with only the knowledge of the ImageNet domain, we propose a Beyond ImageNet Attack (BIA) to investigate the transferability towards black-box domains (unknown classification tasks). Specifically, we leverage a generative model to learn the adversarial function for disrupting low-level features of input images. Based on this framework, we further propose two variants to narrow the gap between the source and target domains from the data and model perspectives, respectively. Extensive experiments on coarse-grained and fine-grained domains demonstrate the effectiveness of our proposed methods. Notably,our methods outperform state-of-the-art approaches by up to 7.71\\% (towards coarse-grained domains) and 25.91\\% (towards fine-grained domains) on average. Our code is available at \\url{https://github.com/Alibaba-AAIG/Beyond-ImageNet-Attack}.",
        "conference": "ICLR",
        "中文标题": "超越ImageNet攻击：面向黑盒领域制作对抗样本",
        "摘要翻译": "对抗样本由于其可转移性对深度神经网络构成了严重威胁。目前，各种研究致力于增强跨模型的可转移性，这些研究大多假设替代模型与目标模型在同一领域训练。然而，实际上，部署模型的相关信息不太可能泄露。因此，建立一个更实用的黑盒威胁模型以克服这一限制并评估部署模型的脆弱性至关重要。在本文中，仅利用ImageNet领域的知识，我们提出了一种超越ImageNet攻击（BIA）来研究对黑盒领域（未知分类任务）的可转移性。具体来说，我们利用生成模型学习破坏输入图像低级特征的对抗函数。基于这一框架，我们进一步提出了两种变体，分别从数据和模型的角度缩小源领域和目标领域之间的差距。在粗粒度和细粒度领域的大量实验证明了我们提出方法的有效性。值得注意的是，我们的方法在粗粒度领域和细粒度领域上平均分别比最先进的方法高出7.71%和25.91%。我们的代码可在https://github.com/Alibaba-AAIG/Beyond-ImageNet-Attack获取。",
        "领域": "对抗样本生成、黑盒攻击、跨域迁移",
        "问题": "如何在实际应用中，当目标模型的信息不可知时，生成有效的对抗样本以评估模型的脆弱性。",
        "动机": "现有的对抗样本生成方法大多假设替代模型与目标模型在同一领域训练，这与实际情况不符，因此需要开发一种更实用的黑盒威胁模型。",
        "方法": "提出了一种超越ImageNet攻击（BIA），利用生成模型学习破坏输入图像低级特征的对抗函数，并进一步提出了两种变体以缩小源领域和目标领域之间的差距。",
        "关键词": [
            "对抗样本",
            "黑盒攻击",
            "跨域迁移",
            "生成模型",
            "模型脆弱性评估"
        ],
        "涉及的技术概念": {
            "对抗样本": "通过微小扰动使深度神经网络产生错误输出的输入样本，用于评估模型的鲁棒性。",
            "生成模型": "用于学习数据分布并生成新数据样本的模型，本文中用于学习破坏图像低级特征的对抗函数。",
            "跨域迁移": "将在一个领域（如ImageNet）学到的知识或技术应用到另一个不同但相关的领域（未知分类任务）的过程。"
        },
        "success": true
    },
    {
        "order": 103,
        "title": "BiBERT: Accurate Fully Binarized BERT",
        "html": "https://iclr.cc//virtual/2022/poster/6006",
        "abstract": "The large pre-trained BERT has achieved remarkable performance on Natural Language Processing (NLP) tasks but is also computation and memory expensive. As one of the powerful compression approaches, binarization extremely reduces the computation and memory consumption by utilizing 1-bit parameters and bitwise operations. Unfortunately, the full binarization of BERT (i.e., 1-bit weight, embedding, and activation) usually suffer a significant performance drop, and there is rare study addressing this problem. In this paper, with the theoretical justification and empirical analysis, we identify that the severe performance drop can be mainly attributed to the information degradation and optimization direction mismatch respectively in the forward and backward propagation, and propose BiBERT, an accurate fully binarized BERT, to eliminate the performance bottlenecks. Specifically, BiBERT introduces an efficient Bi-Attention structure for maximizing representation information statistically and a Direction-Matching Distillation (DMD) scheme to optimize the full binarized BERT accurately. Extensive experiments show that BiBERT outperforms both the straightforward baseline and existing state-of-the-art quantized BERTs with ultra-low bit activations by convincing margins on the NLP benchmark. As the first fully binarized BERT, our method yields impressive 56.3 times and 31.2 times saving on FLOPs and model size, demonstrating the vast advantages and potential of the fully binarized BERT model in real-world resource-constrained scenarios.",
        "conference": "ICLR",
        "中文标题": "BiBERT：精确全二值化的BERT",
        "摘要翻译": "大型预训练的BERT在自然语言处理（NLP）任务上取得了显著的性能，但其计算和内存消耗也很大。作为一种强大的压缩方法，二值化通过使用1位参数和位操作极大地减少了计算和内存消耗。不幸的是，BERT的全二值化（即1位权重、嵌入和激活）通常会遭受显著的性能下降，且很少有研究解决这一问题。在本文中，通过理论证明和实证分析，我们确定性能严重下降的主要原因可以分别归因于前向和后向传播中的信息退化和优化方向不匹配，并提出了BiBERT，一种精确全二值化的BERT，以消除性能瓶颈。具体来说，BiBERT引入了一种高效的Bi-Attention结构，用于统计上最大化表示信息，以及一个方向匹配蒸馏（DMD）方案，以准确优化全二值化的BERT。大量实验表明，BiBERT在NLP基准测试中，以令人信服的差距优于直接基线和现有的具有超低位激活的量化BERT。作为第一个全二值化的BERT，我们的方法在FLOPs和模型大小上分别实现了令人印象深刻的56.3倍和31.2倍的节省，展示了全二值化BERT模型在现实世界资源受限场景中的巨大优势和潜力。",
        "领域": "自然语言处理模型压缩",
        "问题": "解决BERT模型全二值化导致的性能下降问题",
        "动机": "减少BERT模型的计算和内存消耗，同时保持其性能",
        "方法": "引入Bi-Attention结构和方向匹配蒸馏（DMD）方案",
        "关键词": [
            "BERT",
            "二值化",
            "模型压缩",
            "自然语言处理",
            "注意力机制"
        ],
        "涉及的技术概念": {
            "Bi-Attention结构": "用于在统计上最大化表示信息，解决前向传播中的信息退化问题",
            "方向匹配蒸馏（DMD）": "用于准确优化全二值化的BERT，解决后向传播中的优化方向不匹配问题",
            "全二值化": "将BERT模型的权重、嵌入和激活全部二值化为1位，以减少计算和内存消耗"
        },
        "success": true
    },
    {
        "order": 104,
        "title": "Bi-linear Value Networks for Multi-goal Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6669",
        "abstract": "Universal value functions are a core component of off-policy multi-goal reinforcement learning. The de-facto paradigm is to approximate Q(s, a, g) using monolithic neural networks which lack inductive biases to produce complex interactions between the state s and the goal g. In this work, we propose a bilinear decomposition that represents the Q-value via a low-rank approximation in the form of a dot product between two vector fields. The first vector field, f(s, a), captures the environment's local dynamics at the state s; whereas the second component, ϕ(s, g), captures the global relationship between the current state and the goal.We show that our bilinear decomposition scheme improves sample efficiency over the original monolithic value approximators, and transfer better to unseen goals. We demonstrate significant learning speed-up over a variety of tasks on a simulated robot arm, and the challenging task of dexterous manipulation with a Shadow hand.",
        "conference": "ICLR",
        "中文标题": "双线性价值网络在多目标强化学习中的应用",
        "摘要翻译": "通用价值函数是离策略多目标强化学习的核心组成部分。当前的主流范式是使用单一神经网络来近似Q(s, a, g)，这种方法缺乏归纳偏差，难以产生状态s和目标g之间的复杂交互。在这项工作中，我们提出了一种双线性分解方法，通过两个向量场之间的点积形式，以低秩近似表示Q值。第一个向量场f(s, a)捕捉了状态s处环境的局部动态；而第二个组件ϕ(s, g)则捕捉了当前状态与目标之间的全局关系。我们展示了我们的双线性分解方案相比原始单一价值近似器提高了样本效率，并且能更好地迁移到未见过的目标。我们在模拟机器人手臂的各种任务以及使用Shadow手进行灵巧操作的挑战性任务上，证明了显著的学习加速效果。",
        "领域": "强化学习、机器人控制、多目标优化",
        "问题": "解决单一神经网络在多目标强化学习中缺乏归纳偏差，难以有效捕捉状态与目标之间复杂交互的问题",
        "动机": "提高多目标强化学习中的样本效率和目标迁移能力",
        "方法": "提出了一种双线性分解方法，通过两个向量场的点积低秩近似表示Q值，分别捕捉局部动态和全局关系",
        "关键词": [
            "双线性分解",
            "多目标强化学习",
            "样本效率",
            "目标迁移",
            "机器人控制"
        ],
        "涉及的技术概念": {
            "双线性分解": "通过两个向量场的点积形式低秩近似表示Q值，分别捕捉局部动态和全局关系",
            "通用价值函数": "用于离策略多目标强化学习的核心组件，能够评估在特定目标下的行动价值",
            "低秩近似": "通过减少参数数量的方式近似表示复杂函数，提高模型的效率和泛化能力"
        },
        "success": true
    },
    {
        "order": 105,
        "title": "Blaschke Product Neural Networks (BPNN): A Physics-Infused Neural Network for Phase Retrieval of Meromorphic Functions",
        "html": "https://iclr.cc//virtual/2022/poster/7089",
        "abstract": "Numerous physical systems are described by ordinary or partial differential equations whose solutions are given by holomorphic or meromorphic functions in the complex domain. In many cases, only the magnitude of these functions are observed on various points on the purely imaginary $j\\omega$-axis since coherent measurement of their phases is often expensive.  However, it is desirable to retrieve the lost phases from the magnitudes when possible. To this end, we propose a physics-infused deep neural network based on the Blaschke products for phase retrieval. Inspired by the Helson and Sarason Theorem,  we recover coefficients of a rational function of Blaschke products using a Blaschke Product Neural Network (BPNN), based upon the magnitude observations as input. The resulting rational function is then used for phase retrieval. We compare the BPNN to conventional deep neural networks (NNs) on several phase retrieval problems, comprising both synthetic and contemporary real-world problems (e.g., metamaterials for which data collection requires substantial expertise and is time consuming). On each phase retrieval problem, we compare against a population of conventional NNs of varying size and hyperparameter settings. Even without any hyper-parameter search, we find that BPNNs consistently outperform the population of optimized NNs in scarce data scenarios, and do so despite being much smaller models. The results can in turn be applied to calculate the refractive index of metamaterials, which is an important problem in emerging areas of material science.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "Blaschke乘积神经网络（BPNN）：一种用于亚纯函数相位检索的物理融合神经网络",
        "摘要翻译": "许多物理系统由常微分方程或偏微分方程描述，其解在复域中由全纯或亚纯函数给出。在许多情况下，由于相干相位测量的成本较高，只能在纯虚数$jω$轴上的各个点观察到这些函数的幅度。然而，在可能的情况下，从幅度中恢复丢失的相位是可取的。为此，我们提出了一种基于Blaschke乘积的物理融合深度神经网络用于相位检索。受Helson和Sarason定理的启发，我们使用Blaschke乘积神经网络（BPNN）基于幅度观测作为输入，恢复Blaschke乘积有理函数的系数。然后，所得的有理函数用于相位检索。我们在几个相位检索问题上将BPNN与传统深度神经网络（NNs）进行了比较，包括合成问题和当代现实世界问题（例如，超材料，其数据收集需要大量专业知识且耗时）。在每个相位检索问题上，我们与不同大小和超参数设置的传统NNs群体进行了比较。即使没有任何超参数搜索，我们发现BPNN在数据稀缺的情况下始终优于优化的NNs群体，并且尽管模型规模小得多。结果可以反过来用于计算超材料的折射率，这是新兴材料科学领域中的一个重要问题。",
        "领域": "相位检索、超材料、复变函数",
        "问题": "从幅度观测中恢复亚纯函数的相位",
        "动机": "解决在物理系统中由于相位测量成本高而只能获取幅度信息的问题，从而恢复丢失的相位信息",
        "方法": "提出了一种基于Blaschke乘积的物理融合深度神经网络（BPNN），用于从幅度观测中恢复相位",
        "关键词": [
            "相位检索",
            "Blaschke乘积",
            "物理融合神经网络",
            "超材料",
            "复变函数"
        ],
        "涉及的技术概念": {
            "Blaschke乘积": "用于构建有理函数，作为相位检索的基础",
            "物理融合神经网络": "结合物理原理的深度学习方法，提高相位检索的准确性和效率",
            "Helson和Sarason定理": "为BPNN的设计提供了理论依据，指导了网络的结构和训练方法"
        }
    },
    {
        "order": 106,
        "title": "Boosted Curriculum Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6802",
        "abstract": "Curriculum value-based reinforcement learning (RL) solves a complex target task by reusing action-values across a tailored sequence of related tasks of increasing difficulty. However, finding an exact way of reusing action-values in this setting is still a poorly understood problem. In this paper, we introduce the concept of boosting to curriculum value-based RL, by approximating the action-value function as a sum of residuals trained on each task. This approach, which we refer to as boosted curriculum reinforcement learning (BCRL), has the benefit of naturally increasing the representativeness of the functional space by adding a new residual each time a new task is presented. This procedure allows reusing previous action-values while promoting expressiveness of the action-value function. We theoretically study BCRL as an approximate value iteration algorithm, discussing advantages over regular curriculum RL in terms of approximation accuracy and convergence to the optimal action-value function. Finally, we provide detailed empirical evidence of the benefits of BCRL in problems requiring curricula for accurate action-value estimation and targeted exploration.",
        "conference": "ICLR",
        "中文标题": "增强课程强化学习",
        "摘要翻译": "基于价值的课程强化学习（RL）通过在一系列难度递增的相关任务中重复使用动作值来解决复杂的目标任务。然而，在这种设置中找到重复使用动作值的准确方法仍然是一个理解不足的问题。在本文中，我们通过将动作值函数近似为在每个任务上训练的残差之和，将增强的概念引入基于价值的课程RL中。这种方法，我们称之为增强课程强化学习（BCRL），具有通过每次呈现新任务时添加新残差来自然增加功能空间代表性的好处。这一过程允许重复使用先前的动作值，同时促进动作值函数的表达能力。我们从理论上将BCRL作为一种近似值迭代算法进行研究，讨论了在近似准确性和收敛到最优动作值函数方面优于常规课程RL的优势。最后，我们提供了详细的实证证据，证明BCRL在需要课程以准确估计动作值和目标探索的问题中的益处。",
        "领域": "强化学习、课程学习、值函数近似",
        "问题": "如何在课程强化学习中有效地重复使用动作值以提高学习效率和性能",
        "动机": "解决在课程强化学习中重复使用动作值的准确方法理解不足的问题，以提高学习效率和性能",
        "方法": "引入增强概念，将动作值函数近似为在每个任务上训练的残差之和，通过添加新残差增加功能空间代表性",
        "关键词": [
            "增强学习",
            "课程学习",
            "值函数近似",
            "残差学习",
            "目标探索"
        ],
        "涉及的技术概念": {
            "课程强化学习": "通过一系列难度递增的任务序列来逐步解决复杂问题的方法",
            "值函数近似": "用于估计动作值函数的技术，以支持在大状态空间中的决策",
            "残差学习": "通过训练残差来逐步改进模型预测能力的方法，有助于提高模型的表达能力和学习效率"
        },
        "success": true
    },
    {
        "order": 107,
        "title": "Boosting Randomized Smoothing with Variance Reduced Classifiers",
        "html": "https://iclr.cc//virtual/2022/poster/6327",
        "abstract": "Randomized Smoothing (RS) is a promising method for obtaining robustness certiﬁcates by evaluating a base model under noise. In this work, we: (i) theoretically motivate why ensembles are a particularly suitable choice as base models for RS, and (ii) empirically conﬁrm this choice, obtaining state-of-the-art results in multiple settings. The key insight of our work is that the reduced variance of ensembles over the perturbations introduced in RS leads to signiﬁcantly more consistent classiﬁcations for a given input. This, in turn, leads to substantially increased certiﬁable radii for samples close to the decision boundary. Additionally, we introduce key optimizations which enable an up to 55-fold decrease in sample complexity of RS for predetermined radii, thus drastically reducing its computational overhead. Experimentally, we show that ensembles of only 3 to 10 classiﬁers consistently improve on their strongest constituting model with respect to their average certiﬁed radius (ACR) by 5% to 21% on both CIFAR10 and ImageNet, achieving a new state-of-the-art ACR of 0.86 and 1.11, respectively. We release all code and models required to reproduce our results at https://github.com/eth-sri/smoothing-ensembles.",
        "conference": "ICLR",
        "中文标题": "通过方差减少分类器提升随机平滑",
        "摘要翻译": "随机平滑（RS）是一种通过在有噪声的情况下评估基础模型来获得鲁棒性证书的有前途的方法。在这项工作中，我们：（i）从理论上阐述了为什么集成模型特别适合作为RS的基础模型，（ii）通过实验证实了这一选择，在多种设置中获得了最先进的结果。我们工作的关键见解是，集成模型在RS引入的扰动上的方差减少，导致对于给定输入的分类结果显著更加一致。这反过来又大大增加了接近决策边界的样本的可证明半径。此外，我们引入了关键优化，使得对于预定半径的RS样本复杂度最多减少了55倍，从而大幅降低了其计算开销。实验上，我们展示了仅由3到10个分类器组成的集成模型，在CIFAR10和ImageNet上，相对于它们最强的构成模型，其平均认证半径（ACR）持续提高了5%到21%，分别达到了新的最先进ACR 0.86和1.11。我们发布了所有重现我们结果所需的代码和模型，可在https://github.com/eth-sri/smoothing-ensembles获取。",
        "领域": "深度学习安全、模型鲁棒性、集成学习",
        "问题": "提高随机平滑方法在对抗性攻击下的模型鲁棒性认证效率和效果",
        "动机": "探索和验证集成学习作为随机平滑基础模型的优势，以提高模型在对抗性环境下的鲁棒性认证",
        "方法": "理论分析集成模型在随机平滑中的优势，并通过实验验证其效果，引入优化减少计算开销",
        "关键词": [
            "随机平滑",
            "集成学习",
            "模型鲁棒性",
            "方差减少",
            "对抗性防御"
        ],
        "涉及的技术概念": {
            "随机平滑": "一种通过在输入数据上添加噪声并评估基础模型的输出来提供鲁棒性证书的技术",
            "集成学习": "使用多个模型的预测结果来减少方差，提高分类一致性和鲁棒性",
            "方差减少": "通过集成学习减少模型预测的方差，从而提高随机平滑方法的效果和效率"
        },
        "success": true
    },
    {
        "order": 108,
        "title": "Boosting the Certified Robustness of L-infinity Distance Nets",
        "html": "https://iclr.cc//virtual/2022/poster/6543",
        "abstract": "Recently, Zhang et al. (2021) developed a new neural network architecture based on $\\ell_\\infty$-distance functions, which naturally possesses certified $\\ell_\\infty$ robustness by its construction. Despite the novel design and theoretical foundation, so far the model only achieved comparable performance to conventional networks. In this paper, we make the following two contributions: $\\mathrm{(i)}$ We demonstrate that $\\ell_\\infty$-distance nets enjoy a fundamental advantage in certified robustness over conventional networks (under typical certification approaches); $\\mathrm{(ii)}$ With an improved training process we are able to significantly boost the certified accuracy of $\\ell_\\infty$-distance nets. Our training approach largely alleviates the optimization problem that arose in the previous training scheme, in particular, the unexpected large Lipschitz constant due to the use of a crucial trick called \\textit{$\\ell_p$-relaxation}. The core of our training approach is a novel objective function that combines scaled cross-entropy loss and clipped hinge loss with a decaying mixing coefficient. Experiments show that using the proposed training strategy, the certified accuracy of $\\ell_\\infty$-distance net can be dramatically improved from 33.30% to 40.06% on CIFAR-10 ($\\epsilon=8/255$), meanwhile outperforming other approaches in this area by a large margin. Our results clearly demonstrate the effectiveness and potential of $\\ell_\\infty$-distance net for certified robustness. Codes are available at https://github.com/zbh2047/L_inf-dist-net-v2.",
        "conference": "ICLR",
        "中文标题": "提升L无穷距离网络的认证鲁棒性",
        "摘要翻译": "最近，张等人（2021年）开发了一种基于L无穷距离函数的新神经网络架构，其构造自然具有认证的L无穷鲁棒性。尽管设计新颖且理论基础扎实，但迄今为止，该模型仅实现了与传统网络相当的性能。在本文中，我们做出了以下两点贡献：（i）我们证明了L无穷距离网络在认证鲁棒性方面比传统网络具有根本优势（在典型的认证方法下）；（ii）通过改进的训练过程，我们能够显著提升L无穷距离网络的认证准确率。我们的训练方法在很大程度上缓解了先前训练方案中出现的优化问题，特别是由于使用了一种称为L_p松弛的关键技巧而导致的意外大的Lipschitz常数。我们训练方法的核心是一个新颖的目标函数，它结合了缩放交叉熵损失和剪裁铰链损失，以及一个衰减的混合系数。实验表明，使用提出的训练策略，L无穷距离网络在CIFAR-10（ε=8/255）上的认证准确率可以从33.30%显著提高到40.06%，同时在该领域大幅领先其他方法。我们的结果清楚地展示了L无穷距离网络在认证鲁棒性方面的有效性和潜力。代码可在https://github.com/zbh2047/L_inf-dist-net-v2获取。",
        "领域": "深度学习安全、对抗性机器学习、神经网络鲁棒性",
        "问题": "提升L无穷距离网络在对抗性攻击下的认证鲁棒性和准确率",
        "动机": "尽管L无穷距离网络具有理论上的鲁棒性优势，但其实际性能与传统网络相比并无显著提升，研究旨在通过改进训练方法解决这一问题",
        "方法": "提出了一种结合缩放交叉熵损失和剪裁铰链损失的新颖目标函数，并采用衰减的混合系数来优化训练过程",
        "关键词": [
            "L无穷距离网络",
            "认证鲁棒性",
            "对抗性训练",
            "深度学习安全",
            "神经网络优化"
        ],
        "涉及的技术概念": {
            "L无穷距离网络": "一种基于L无穷距离函数的神经网络架构，设计上具有认证的L无穷鲁棒性",
            "L_p松弛": "一种用于优化L无穷距离网络训练的技巧，可能导致Lipschitz常数异常增大",
            "缩放交叉熵损失和剪裁铰链损失": "论文中提出的新型目标函数，用于改进L无穷距离网络的训练过程和提升认证准确率"
        },
        "success": true
    },
    {
        "order": 109,
        "title": "Bootstrapped Meta-Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6252",
        "abstract": "Meta-learning empowers artificial intelligence to increase its efficiency by learning how to learn. Unlocking this potential involves overcoming a challenging meta-optimisation problem. We propose an algorithm that tackles this problem by letting the meta-learner teach itself. The algorithm first bootstraps a target from the meta-learner, then optimises the meta-learner by minimising the distance to that target under a chosen (pseudo-)metric. Focusing on meta-learning with gradients, we establish conditions that guarantee performance improvements and show that metric can be used to control meta-optimisation. Meanwhile, the bootstrapping mechanism can extend the effective meta-learning horizon without requiring backpropagation through all updates. We achieve a new state-of-the art for model-free agents on the Atari ALE benchmark and demonstrate that it yields both performance and efficiency gains in multi-task meta-learning. Finally, we explore how bootstrapping opens up new possibilities and find that it can meta-learn efficient exploration in an epsilon-greedy Q-learning agent - without backpropagating through the update rule.",
        "conference": "ICLR",
        "中文标题": "自举元学习",
        "摘要翻译": "元学习通过学会如何学习，增强了人工智能的效率。释放这一潜力需要克服一个具有挑战性的元优化问题。我们提出了一种算法，通过让元学习器自我教学来解决这一问题。该算法首先从元学习器中自举出一个目标，然后通过最小化与所选（伪）度量下的该目标的距离来优化元学习器。专注于基于梯度的元学习，我们建立了保证性能改进的条件，并展示了如何使用度量来控制元优化。同时，自举机制可以在不需要通过所有更新进行反向传播的情况下，扩展有效的元学习视野。我们在Atari ALE基准测试中为无模型代理实现了新的最先进水平，并证明了它在多任务元学习中既提高了性能又提高了效率。最后，我们探索了自举如何开辟新的可能性，并发现它可以在不通过更新规则进行反向传播的情况下，元学习ε-贪婪Q学习代理中的高效探索。",
        "领域": "元学习、强化学习、多任务学习",
        "问题": "解决元学习中的元优化问题",
        "动机": "提高人工智能的学习效率和性能",
        "方法": "通过自举机制让元学习器自我教学，优化元学习器与自举目标之间的距离",
        "关键词": [
            "元学习",
            "自举",
            "元优化",
            "多任务学习",
            "强化学习"
        ],
        "涉及的技术概念": {
            "元学习": "通过学会如何学习来提高人工智能的效率",
            "自举机制": "从元学习器中生成目标，用于优化元学习器",
            "元优化": "通过最小化与自举目标的距离来优化元学习器的过程"
        },
        "success": true
    },
    {
        "order": 110,
        "title": "Bootstrapping Semantic Segmentation with Regional Contrast",
        "html": "https://iclr.cc//virtual/2022/poster/6375",
        "abstract": "We present ReCo, a contrastive learning framework designed at a regional level to assist learning in semantic segmentation. ReCo performs pixel-level contrastive learning on a sparse set of hard negative pixels, with minimal additional memory footprint. ReCo is easy to implement, being built on top of off-the-shelf segmentation networks, and consistently improves performance, achieving more accurate segmentation boundaries and faster convergence. The strongest effect is in semi-supervised learning with very few labels. With ReCo, we achieve high quality semantic segmentation model, requiring only 5 examples of each semantic class. ",
        "conference": "ICLR",
        "中文标题": "基于区域对比的语义分割自举方法",
        "摘要翻译": "我们提出了ReCo，一种在区域级别设计的对比学习框架，旨在辅助语义分割的学习。ReCo在一组稀疏的困难负像素上执行像素级对比学习，额外内存占用极小。ReCo易于实现，构建于现成分割网络之上，持续提升性能，实现更准确的分割边界和更快的收敛速度。在半监督学习中，使用极少量标签时效果最为显著。借助ReCo，我们实现了高质量的语义分割模型，每个语义类别仅需5个示例。",
        "领域": "语义分割、半监督学习、对比学习",
        "问题": "如何在少量标注数据的情况下提高语义分割的准确性和效率",
        "动机": "解决语义分割任务中标注数据稀缺时的学习效率问题，通过对比学习提升模型性能",
        "方法": "提出ReCo框架，在区域级别进行对比学习，特别关注困难负像素，以减少内存占用并提升分割精度和收敛速度",
        "关键词": [
            "语义分割",
            "对比学习",
            "半监督学习",
            "区域对比",
            "困难负样本"
        ],
        "涉及的技术概念": {
            "对比学习": "在ReCo框架中用于通过比较正负样本来学习更有区分性的特征表示",
            "困难负像素": "在对比学习中难以区分的负样本，ReCo特别关注这些像素以提升模型性能",
            "半监督学习": "ReCo特别适用于标注数据稀缺的场景，通过利用未标注数据提升模型性能"
        },
        "success": true
    },
    {
        "order": 111,
        "title": "Bregman Gradient Policy Optimization",
        "html": "https://iclr.cc//virtual/2022/poster/6662",
        "abstract": "In the paper, we design a novel Bregman gradient policy optimization framework for reinforcement learning based on Bregman divergences and momentum techniques. Specifically, we propose a Bregman gradient policy optimization (BGPO) algorithm based on the basic momentum technique and mirror descent iteration. Meanwhile, we further propose an accelerated Bregman gradient policy optimization (VR-BGPO) algorithm based on the variance reduced technique. Moreover, we provide a convergence analysis framework for our Bregman gradient policy optimization under the nonconvex setting. We prove that our BGPO achieves a  sample complexity of $O(\\epsilon^{-4})$ for finding $\\epsilon$-stationary policy only requiring one trajectory at each iteration, and our VR-BGPO reaches the best known sample complexity of $O(\\epsilon^{-3})$, which also only requires one trajectory at each iteration. In particular, by using different Bregman divergences, our BGPO framework unifies many existing policy optimization algorithms such as the existing (variance reduced) policy gradient algorithms such as natural policy gradient algorithm. Extensive experimental results on multiple reinforcement learning tasks demonstrate the efficiency of our new algorithms. ",
        "conference": "ICLR",
        "中文标题": "布雷格曼梯度策略优化",
        "摘要翻译": "在本文中，我们设计了一种基于布雷格曼散度和动量技术的强化学习新框架——布雷格曼梯度策略优化。具体而言，我们提出了一种基于基本动量技术和镜像下降迭代的布雷格曼梯度策略优化（BGPO）算法。同时，我们进一步提出了一种基于方差减少技术的加速布雷格曼梯度策略优化（VR-BGPO）算法。此外，我们在非凸设置下为我们的布雷格曼梯度策略优化提供了收敛性分析框架。我们证明了我们的BGPO在每次迭代仅需一条轨迹的情况下，达到寻找ε-平稳策略的样本复杂度为O(ε−4)，而我们的VR-BGPO达到了已知最佳的样本复杂度O(ε−3)，同样每次迭代仅需一条轨迹。特别是，通过使用不同的布雷格曼散度，我们的BGPO框架统一了许多现有的策略优化算法，如现有的（方差减少）策略梯度算法，如自然策略梯度算法。在多个强化学习任务上的广泛实验结果证明了我们新算法的效率。",
        "领域": "强化学习、策略优化、梯度下降",
        "问题": "如何在强化学习中更高效地优化策略",
        "动机": "开发一种新的策略优化框架，以提高强化学习算法的效率和性能",
        "方法": "基于布雷格曼散度和动量技术设计新的策略优化算法，包括BGPO和VR-BGPO，并在非凸设置下进行收敛性分析",
        "关键词": [
            "布雷格曼梯度策略优化",
            "强化学习",
            "策略优化",
            "方差减少",
            "镜像下降"
        ],
        "涉及的技术概念": {
            "布雷格曼散度": "用于衡量两个概率分布之间的差异，是BGPO算法的核心组成部分",
            "动量技术": "用于加速梯度下降过程，提高算法的收敛速度",
            "方差减少技术": "用于减少梯度估计的方差，提高VR-BGPO算法的样本效率"
        },
        "success": true
    },
    {
        "order": 112,
        "title": "Bridging Recommendation and Marketing via Recurrent Intensity Modeling",
        "html": "https://iclr.cc//virtual/2022/poster/6924",
        "abstract": "This paper studies some unexplored connections between personalized recommendation and marketing systems. Obviously, the two systems are different, in two main ways. Firstly, personalized item-recommendation (ItemRec) is user-centric, whereas marketing recommends the best user-state segments (UserRec) on behalf of its item providers. (We treat different temporal states of the same user as separate marketing opportunities.) To overcome this difference, we realize a novel connection to Marked-Temporal Point Processes (MTPPs), where we view both problems as different projections from a unified temporal intensity model for all user-item pairs. In this way, we derive Recurrent Intensity Models (RIMs) as unifying extensions from recurrent ItemRec models, though the connection can be more general. The second difference is in the temporal domains where they operate. While recommendation happens in real-time as each user appears, marketers often aim to reach a certain percentage of audience in the distribution of all user-states in a period of time. We formulate both considerations into a constrained optimization problem we call online match (OnlnMtch) and derive a Dual algorithm based on dual decomposition. Dual allows us to make ItemRec decisions in real time, while satisfying long-term marketing constraints in expectation. Finally, our connections between recommendation and marketing lead to novel applications. We run experiments where we use marketing as an alternative to cold-start item exploration, by setting a positive minimal-exposure constraint for every item over the user-state distribution in a future period of time. Our experiments are scalable to infinite streams of user-states and open-sourced.",
        "conference": "ICLR",
        "中文标题": "通过循环强度建模桥接推荐与营销",
        "摘要翻译": "本文研究了个性化推荐与营销系统之间一些未被探索的联系。显然，这两个系统在两个主要方面有所不同。首先，个性化物品推荐（ItemRec）是以用户为中心的，而营销则是代表物品提供者推荐最佳用户状态片段（UserRec）。（我们将同一用户的不同时间状态视为独立的营销机会。）为了克服这一差异，我们实现了一种与标记时间点过程（MTPPs）的新颖连接，将这两个问题视为从所有用户-物品对的统一时间强度模型的不同投影。通过这种方式，我们从循环ItemRec模型中推导出循环强度模型（RIMs）作为统一扩展，尽管这种连接可以更为普遍。第二个差异在于它们运作的时间领域。推荐是在每个用户出现时实时发生的，而营销者通常旨在在一段时间内达到所有用户状态分布中的一定比例受众。我们将这两种考虑制定为一个我们称之为在线匹配（OnlnMtch）的约束优化问题，并基于对偶分解推导出一个对偶算法。对偶算法使我们能够实时做出ItemRec决策，同时满足长期营销约束的期望。最后，我们关于推荐与营销之间的联系导致了新的应用。我们进行了实验，通过为未来一段时间内用户状态分布中的每个物品设置一个最小曝光约束，将营销用作冷启动物品探索的替代方案。我们的实验可扩展到无限用户状态流，并且已经开源。",
        "领域": "个性化推荐系统、营销技术、时间序列分析",
        "问题": "如何桥接个性化推荐系统与营销系统之间的差异，实现两者的统一建模与应用。",
        "动机": "探索个性化推荐与营销系统之间未被充分研究的联系，克服两者在用户中心性和时间运作域上的差异，实现统一的时间强度模型。",
        "方法": "通过标记时间点过程（MTPPs）建立推荐与营销的统一模型，提出循环强度模型（RIMs）作为扩展，并开发对偶算法解决在线匹配问题。",
        "关键词": [
            "循环强度模型",
            "在线匹配",
            "对偶分解",
            "冷启动探索",
            "时间点过程"
        ],
        "涉及的技术概念": {
            "标记时间点过程（MTPPs）": "用于统一建模推荐与营销系统中的时间强度，将两者视为不同投影。",
            "循环强度模型（RIMs）": "作为从循环ItemRec模型推导出的统一扩展，用于桥接推荐与营销。",
            "对偶分解": "用于开发对偶算法，解决在线匹配问题，实现实时推荐决策同时满足长期营销约束。"
        },
        "success": true
    },
    {
        "order": 113,
        "title": "Bridging the Gap: Providing Post-Hoc Symbolic Explanations for Sequential Decision-Making Problems with Inscrutable Representations",
        "html": "https://iclr.cc//virtual/2022/poster/7046",
        "abstract": "As increasingly complex AI systems are introduced into our daily lives, it becomes important for such systems to be capable of explaining the rationale for their decisions and allowing users to contest these decisions. A significant hurdle to allowing for such explanatory dialogue could be the {\\em vocabulary mismatch} between the user and the AI system. This paper introduces methods for providing contrastive explanations in terms of user-specified concepts for sequential decision-making settings where the system's model of the task may be best represented as an inscrutable model. We do this by building partial symbolic models of a local approximation of the task that can be leveraged to answer the user queries. We test these methods on a popular Atari game (Montezuma's Revenge) and variants of Sokoban (a well-known planning benchmark) and report the results of user studies to evaluate whether people find explanations generated in this form useful.",
        "conference": "ICLR",
        "中文标题": "弥合鸿沟：为具有难以理解表示的序列决策问题提供事后符号解释",
        "摘要翻译": "随着日益复杂的人工智能系统被引入我们的日常生活，这些系统能够解释其决策的理由并允许用户对这些决策提出质疑变得非常重要。允许这种解释性对话的一个重大障碍可能是用户与AI系统之间的词汇不匹配。本文介绍了在序列决策设置中，以用户指定的概念提供对比解释的方法，其中系统的任务模型可能最好被表示为一个难以理解的模型。我们通过构建任务局部近似的部分符号模型来实现这一点，这些模型可以用来回答用户的查询。我们在一个流行的Atari游戏（蒙特祖玛的复仇）和Sokoban的变体（一个著名的规划基准）上测试了这些方法，并报告了用户研究的结果，以评估人们是否认为以这种形式生成的解释有用。",
        "领域": "可解释人工智能、序列决策、人机交互",
        "问题": "解决AI系统决策过程难以理解的问题，提供用户可理解的解释",
        "动机": "随着AI系统在日常生活中的应用越来越广泛，用户需要理解并能够质疑AI的决策过程，但目前存在用户与AI系统之间的词汇不匹配问题",
        "方法": "构建任务局部近似的部分符号模型，以用户指定的概念提供对比解释",
        "关键词": [
            "可解释AI",
            "序列决策",
            "符号模型",
            "用户研究",
            "对比解释"
        ],
        "涉及的技术概念": {
            "词汇不匹配": "用户与AI系统之间的沟通障碍，因为双方使用的词汇和概念不一致",
            "部分符号模型": "用于近似AI决策过程的模型，能够以符号形式解释决策",
            "对比解释": "通过比较不同决策选项来解释AI的决策过程，帮助用户理解"
        },
        "success": true
    },
    {
        "order": 114,
        "title": "Bundle Networks: Fiber Bundles, Local Trivializations, and a Generative Approach to Exploring Many-to-one Maps",
        "html": "https://iclr.cc//virtual/2022/poster/6976",
        "abstract": "Many-to-one maps are ubiquitous in machine learning, from the image recognition model that assigns a multitude of distinct images to the concept of “cat” to the time series forecasting model which assigns a range of distinct time-series to a single scalar regression value. While the primary use of such models is naturally to associate correct output to each input, in many problems it is also useful to be able to explore, understand, and sample from a model's fibers, which are the set of input values $x$ such that $f(x) = y,$ for fixed $y$ in the output space. In this paper we show that popular generative architectures are ill-suited to such tasks. Motivated by this, we introduce a novel generative architecture, Bundle Networks, based on the concept of a fiber bundle from (differential) topology. BundleNets exploit the idea of a local trivialization wherein a space can be locally decomposed into a product space that cleanly encodes the many-to-one nature of the map. By enforcing this decomposition in BundleNets and by utilizing state-of-the-art invertible components, investigating a network's fibers becomes natural.",
        "conference": "ICLR",
        "中文标题": "束网络：纤维束、局部平凡化及探索多对一映射的生成方法",
        "摘要翻译": "多对一映射在机器学习中无处不在，从将大量不同的图像分配到“猫”这一概念的图像识别模型，到将一系列不同的时间序列分配到单一标量回归值的时间序列预测模型。虽然这类模型的主要用途自然是正确地将输出与每个输入关联起来，但在许多问题中，能够探索、理解并从模型的纤维中采样也是非常有用的，纤维是指对于输出空间中的固定y，满足f(x) = y的输入值x的集合。在本文中，我们展示了流行的生成架构不适合此类任务。受此启发，我们引入了一种基于（微分）拓扑学中纤维束概念的新型生成架构——束网络。束网络利用局部平凡化的思想，其中空间可以局部分解为一个乘积空间，该乘积空间清晰地编码了映射的多对一性质。通过在束网络中强制执行这种分解并利用最先进的可逆组件，研究网络的纤维变得自然而然。",
        "领域": "生成模型、图像识别、时间序列预测",
        "问题": "探索和理解多对一映射的纤维，即对于固定输出y，所有满足f(x) = y的输入x的集合",
        "动机": "现有的生成架构不适合探索和理解多对一映射的纤维，因此需要一种新的方法来有效地进行这种探索",
        "方法": "引入基于纤维束概念的束网络架构，利用局部平凡化和最先进的可逆组件来探索多对一映射的纤维",
        "关键词": [
            "束网络",
            "纤维束",
            "局部平凡化",
            "多对一映射",
            "可逆组件"
        ],
        "涉及的技术概念": {
            "纤维束": "在微分拓扑中，纤维束是一种将空间局部表示为乘积空间的结构，用于清晰地编码多对一映射的性质",
            "局部平凡化": "一种将空间局部分解为乘积空间的技术，使得多对一映射的结构更加清晰和易于处理",
            "可逆组件": "在束网络中使用的技术，允许网络在探索纤维时保持信息的可逆性，从而有效地进行采样和理解"
        },
        "success": true
    },
    {
        "order": 115,
        "title": "Byzantine-Robust Learning on Heterogeneous Datasets via Bucketing",
        "html": "https://iclr.cc//virtual/2022/poster/6400",
        "abstract": "In Byzantine robust distributed or federated learning, a central server wants to train a machine learning model over data distributed across multiple workers. However, a fraction of these workers may deviate from the prescribed algorithm and send arbitrary messages. While this problem has received significant attention recently, most current defenses assume that the workers have identical data. For realistic cases when the data across workers are heterogeneous (non-iid), we design new attacks which circumvent current defenses, leading to significant loss of performance. We then propose a simple bucketing scheme that adapts existing robust algorithms to heterogeneous datasets at a negligible computational cost. We also theoretically and experimentally validate our approach, showing that combining bucketing with existing robust algorithms is effective against challenging attacks. Our work is the first to establish guaranteed convergence for the non-iid Byzantine robust problem under realistic assumptions.",
        "conference": "ICLR",
        "中文标题": "通过分桶实现异构数据集上的拜占庭鲁棒学习",
        "摘要翻译": "在拜占庭鲁棒的分布式或联邦学习中，中央服务器希望利用分布在多个工作者上的数据训练一个机器学习模型。然而，这些工作者中的一部分可能会偏离规定的算法并发送任意消息。尽管这个问题最近受到了显著关注，但大多数当前的防御措施假设工作者拥有相同的数据。针对工作者间数据异构（非独立同分布）的现实情况，我们设计了新的攻击方法，这些方法能够绕过当前的防御措施，导致性能显著下降。随后，我们提出了一种简单的分桶方案，该方案以可忽略的计算成本将现有的鲁棒算法适应于异构数据集。我们还从理论上和实验上验证了我们的方法，表明将分桶与现有的鲁棒算法结合使用，能够有效应对挑战性攻击。我们的工作是第一个在实际假设下为非独立同分布拜占庭鲁棒问题建立保证收敛性的研究。",
        "领域": "联邦学习, 分布式机器学习, 鲁棒学习",
        "问题": "解决在数据异构（非独立同分布）环境下，现有拜占庭鲁棒防御措施被新型攻击绕过的问题。",
        "动机": "针对现实世界中数据分布不均的情况，设计能够有效抵抗拜占庭攻击的学习方法。",
        "方法": "提出一种简单的分桶方案，将现有的鲁棒算法适应于异构数据集，并通过理论和实验验证其有效性。",
        "关键词": [
            "拜占庭鲁棒",
            "异构数据集",
            "分桶方案",
            "联邦学习",
            "分布式机器学习"
        ],
        "涉及的技术概念": {
            "拜占庭鲁棒": "在分布式或联邦学习中，抵抗部分工作者发送任意消息的能力。",
            "异构数据集": "指数据在不同工作者间分布不均，不满足独立同分布假设的情况。",
            "分桶方案": "一种将数据分组处理的技术，用于适应异构数据集，提高算法的鲁棒性。"
        },
        "success": true
    },
    {
        "order": 116,
        "title": "CADDA: Class-wise Automatic Differentiable Data Augmentation for EEG Signals",
        "html": "https://iclr.cc//virtual/2022/poster/7154",
        "abstract": "Data augmentation is a key element of deep learning pipelines, as it informs the network during training about transformations of the input data that keep the label unchanged. Manually finding adequate augmentation methods and parameters for a given pipeline is however rapidly cumbersome. In particular, while intuition can guide this decision for images, the design and choice of augmentation policies remains unclear for more complex types of data, such as neuroscience signals. Besides, class-dependent augmentation strategies have been surprisingly unexplored in the literature, although it is quite intuitive: changing the color of a car image does not change the object class to be predicted, but doing the same to the picture of an orange does. This paper investigates gradient-based automatic data augmentation algorithms  amenable to class-wise policies with exponentially larger search spaces. Motivated by supervised learning applications using EEG signals for which good augmentation policies are mostly unknown, we propose a new differentiable relaxation of the problem. In the class-agnostic setting, results show that our new relaxation leads to optimal performance with faster training than competing gradient-based methods, while also outperforming gradient-free methods in the class-wise setting. This work proposes also novel differentiable augmentation operations relevant for sleep stage classification.",
        "conference": "ICLR",
        "中文标题": "CADDA：面向脑电信号的类自动可微分数据增强方法",
        "摘要翻译": "数据增强是深度学习流程中的关键要素，因为它能在训练过程中告知网络输入数据的哪些变换不会改变标签。然而，手动为给定流程寻找合适的数据增强方法和参数很快变得繁琐。特别是，虽然对于图像数据，直觉可以指导这一决策，但对于更复杂的数据类型，如神经科学信号，增强策略的设计和选择仍然不明确。此外，尽管类依赖的增强策略在直觉上相当明显：改变汽车图像的颜色不会改变待预测的对象类别，但对橙子的图片做同样的改变则会，这类策略在文献中却出人意料地未被探索。本文研究了基于梯度的自动数据增强算法，这些算法适用于具有指数级更大搜索空间的类策略。受到使用脑电信号的监督学习应用的启发，对于这些应用，良好的增强策略大多未知，我们提出了问题的一个新的可微分松弛。在类无关设置中，结果表明，我们的新松弛在训练速度上优于基于梯度的竞争方法，同时在类策略设置中也优于无梯度方法，达到了最优性能。这项工作还提出了与睡眠阶段分类相关的新型可微分增强操作。",
        "领域": "脑电信号处理, 自动数据增强, 睡眠阶段分类",
        "问题": "如何自动化和优化脑电信号数据增强策略，特别是在类依赖的情况下",
        "动机": "解决在复杂数据类型（如脑电信号）中手动设计数据增强策略的困难，探索类依赖增强策略的潜力",
        "方法": "提出了一种新的可微分松弛方法，用于基于梯度的自动数据增强算法，支持类策略，并引入了针对脑电信号的新型可微分增强操作",
        "关键词": [
            "自动数据增强",
            "脑电信号",
            "可微分增强",
            "类策略",
            "睡眠阶段分类"
        ],
        "涉及的技术概念": {
            "可微分数据增强": "允许通过梯度下降自动优化增强策略的数据增强方法",
            "类策略": "针对不同类别数据采用不同的增强策略，以更好地保持或改变数据的语义信息",
            "梯度基优化": "利用梯度信息自动搜索和优化数据增强策略的参数，以提高模型性能"
        },
        "success": true
    },
    {
        "order": 117,
        "title": "Can an Image Classifier Suffice For Action Recognition?",
        "html": "https://iclr.cc//virtual/2022/poster/6047",
        "abstract": "We explore a new perspective on video understanding by casting the video recognition problem as an image recognition task. Our approach rearranges input video frames into super images, which allow for training an image classifier directly to fulfill the task of action recognition, in exactly the same way as image classification. With such a simple idea, we show that transformer-based image classifiers alone can suffice for action recognition. In particular, our approach demonstrates strong and promising performance against SOTA methods on several public datasets including Kinetics400, Moments In Time, Something-Something V2 (SSV2), Jester and Diving48. We also experiment with the prevalent ResNet image classifiers in computer vision to further validate our idea. The results on both Kinetics400 and SSV2 are comparable to some of the best-performed CNN approaches based on spatio-temporal modeling. Our source codes and models are available at \\url{https://github.com/IBM/sifar-pytorch}.",
        "conference": "ICLR",
        "中文标题": "图像分类器能否胜任动作识别任务？",
        "摘要翻译": "我们通过将视频识别问题转化为图像识别任务，探索了视频理解的新视角。我们的方法将输入视频帧重新排列成超级图像，这使得可以直接训练一个图像分类器来完成动作识别任务，其方式与图像分类完全相同。通过这样一个简单的想法，我们展示了仅基于变换器的图像分类器就足以胜任动作识别。特别是，我们的方法在包括Kinetics400、Moments In Time、Something-Something V2（SSV2）、Jester和Diving48在内的多个公共数据集上，与SOTA方法相比展现出了强大且有前景的性能。我们还尝试了计算机视觉中普遍使用的ResNet图像分类器，以进一步验证我们的想法。在Kinetics400和SSV2上的结果与一些基于时空建模的最佳CNN方法相当。我们的源代码和模型可在https://github.com/IBM/sifar-pytorch获取。",
        "领域": "动作识别、视频理解、图像分类",
        "问题": "探索是否可以通过将视频识别问题转化为图像识别任务，使用图像分类器来完成动作识别。",
        "动机": "研究动机是简化动作识别的复杂性，通过将视频帧转换为超级图像，直接应用图像分类技术进行动作识别。",
        "方法": "将视频帧重新排列成超级图像，直接使用基于变换器的图像分类器进行动作识别，并在多个数据集上验证方法的有效性。",
        "关键词": [
            "动作识别",
            "图像分类器",
            "超级图像",
            "变换器",
            "ResNet"
        ],
        "涉及的技术概念": {
            "超级图像": "通过重新排列视频帧生成的图像，使得可以直接应用图像分类技术进行动作识别。",
            "变换器": "用于图像分类的模型架构，本文中直接应用于动作识别任务。",
            "ResNet": "一种深度卷积神经网络架构，用于验证将视频识别问题转化为图像识别任务的普遍适用性。"
        },
        "success": true
    },
    {
        "order": 118,
        "title": "Capacity of Group-invariant Linear Readouts from Equivariant Representations: How Many Objects can be Linearly Classified Under All Possible Views?",
        "html": "https://iclr.cc//virtual/2022/poster/6767",
        "abstract": "Equivariance has emerged as a desirable property of representations of objects subject to identity-preserving transformations that constitute a group, such as translations and rotations. However, the expressivity of a representation constrained by group equivariance is still not fully understood. We address this gap by providing a generalization of Cover's Function Counting Theorem that quantifies the number of linearly separable and group-invariant binary dichotomies that can be assigned to equivariant representations of objects. We find that the fraction of separable dichotomies is determined by the dimension of the space that is fixed by the group action. We show how this relation extends to operations such as convolutions, element-wise nonlinearities, and global and local pooling. While other operations do not change the fraction of separable dichotomies, local pooling decreases the fraction, despite being a highly nonlinear operation. Finally, we test our theory on intermediate representations of randomly initialized and fully trained convolutional neural networks and find perfect agreement.",
        "conference": "ICLR",
        "中文标题": "从等变表示中提取群不变线性读出能力的容量：在所有可能视角下，多少对象可以被线性分类？",
        "摘要翻译": "等变性已成为受身份保持变换（如平移和旋转）构成群的物体表示的一种理想属性。然而，受群等变性约束的表示的表达能力仍未完全被理解。我们通过提供Cover函数计数定理的泛化来填补这一空白，该定理量化了可以分配给物体等变表示的线性可分和群不变的二分法的数量。我们发现可分二分法的比例由群作用固定的空间的维度决定。我们展示了这种关系如何扩展到诸如卷积、元素非线性以及全局和局部池化等操作。虽然其他操作不会改变可分二分法的比例，但局部池化会降低这一比例，尽管它是一种高度非线性的操作。最后，我们在随机初始化和完全训练的卷积神经网络的中间表示上测试了我们的理论，并发现了完美的一致性。",
        "领域": "群等变表示学习、卷积神经网络理论、图像分类",
        "问题": "量化在群等变约束下，线性分类器能够分类的对象数量上限",
        "动机": "理解群等变性约束下表示的线性分类能力，为设计更高效的群等变神经网络提供理论基础",
        "方法": "通过泛化Cover函数计数定理，理论分析群等变表示的线性可分性，并在卷积神经网络中进行实验验证",
        "关键词": [
            "群等变性",
            "线性分类",
            "Cover定理",
            "卷积神经网络",
            "表示学习"
        ],
        "涉及的技术概念": {
            "群等变性": "表示在群变换下保持不变的属性，用于处理如平移和旋转等变换下的物体识别问题",
            "Cover函数计数定理": "用于量化线性可分二分法数量的理论工具，本文中泛化以适用于群等变表示",
            "局部池化": "一种非线性操作，用于降低特征图的空间维度，本文发现它会减少可分二分法的比例"
        },
        "success": true
    },
    {
        "order": 119,
        "title": "Capturing Structural Locality in Non-parametric Language Models",
        "html": "https://iclr.cc//virtual/2022/poster/6544",
        "abstract": "Structural locality is a ubiquitous feature of real-world datasets, wherein data points are organized into local hierarchies. Some examples include topical clusters in text or project hierarchies in source code repositories. In this paper, we explore utilizing this structural locality within non-parametric language models, which generate sequences that reference retrieved examples from an external source. We propose a simple yet effective approach for adding locality information into such models by adding learned parameters that improve the likelihood of retrieving examples from local neighborhoods. Experiments on two different domains, Java source code and Wikipedia text, demonstrate that locality features improve model efficacy over models without access to these features, with interesting differences. We also perform an analysis of how and where locality features contribute to improving performance and why the traditionally used contextual similarity metrics alone are not enough to grasp the locality structure.",
        "conference": "ICLR",
        "中文标题": "捕捉非参数语言模型中的结构局部性",
        "摘要翻译": "结构局部性是现实世界数据集的一个普遍特征，其中数据点被组织成局部层次结构。一些例子包括文本中的主题集群或源代码仓库中的项目层次结构。在本文中，我们探索在非参数语言模型中利用这种结构局部性，这些模型生成的序列参考了来自外部源的检索示例。我们提出了一种简单而有效的方法，通过添加学习参数来改进从局部邻域检索示例的可能性，从而将局部性信息添加到此类模型中。在Java源代码和维基百科文本两个不同领域的实验表明，局部性特征提高了模型的效果，与没有这些特征的模型相比，存在有趣的差异。我们还分析了局部性特征如何以及在何处有助于提高性能，以及为什么传统上使用的上下文相似性度量本身不足以把握局部性结构。",
        "领域": "自然语言处理与视觉结合、源代码分析、文本挖掘",
        "问题": "如何在非参数语言模型中有效利用数据中的结构局部性以提高模型性能",
        "动机": "现实世界数据中的结构局部性普遍存在，但传统非参数语言模型未能充分利用这一特性以提高检索和生成的质量",
        "方法": "通过在学习过程中添加参数来增强模型对局部邻域示例的检索能力，从而利用结构局部性",
        "关键词": [
            "非参数语言模型",
            "结构局部性",
            "检索增强生成",
            "Java源代码",
            "维基百科文本"
        ],
        "涉及的技术概念": {
            "非参数语言模型": "不依赖于固定参数集的模型，通过检索外部示例来生成序列",
            "结构局部性": "数据点被组织成局部层次结构的特性，如文本中的主题集群或代码中的项目层次",
            "检索增强生成": "通过检索相关示例来辅助序列生成的方法，提高生成的相关性和质量"
        },
        "success": true
    },
    {
        "order": 120,
        "title": "Case-based reasoning for better generalization in textual reinforcement learning",
        "html": "https://iclr.cc//virtual/2022/poster/6875",
        "abstract": "Text-based games (TBG) have emerged as promising environments for driving research in grounded language understanding and studying problems like generalization and sample efficiency. Several deep reinforcement learning (RL) methods with varying architectures and learning schemes have been proposed for TBGs. However, these methods fail to generalize efficiently, especially under distributional shifts. In a departure from deep RL approaches, in this paper, we propose a general method inspired by case-based reasoning to train agents and generalize out of the training distribution. The case-based reasoner collects instances of positive experiences from the agent's interaction with the world and later reuses the collected experiences to act efficiently. The method can be used in conjunction with any existing on-policy neural agent introduced in the literature for TBGs. Our experiments show that the proposed approach consistently improves existing methods, obtains good out-of-distribution generalization and achieves new state-of-the-art results on widely used environments.",
        "conference": "ICLR",
        "中文标题": "基于案例推理的文本强化学习泛化能力提升",
        "摘要翻译": "基于文本的游戏（TBG）已成为推动基础语言理解研究和研究泛化及样本效率等问题的有前景的环境。针对TBG，已经提出了几种具有不同架构和学习方案的深度强化学习（RL）方法。然而，这些方法在泛化方面效率不高，特别是在分布变化的情况下。与深度RL方法不同，本文提出了一种受案例推理启发的通用方法，用于训练代理并在训练分布之外进行泛化。案例推理器从代理与世界的互动中收集积极经验的实例，随后再利用这些收集到的经验来高效行动。该方法可以与文献中为TBG提出的任何现有的基于策略的神经代理结合使用。我们的实验表明，所提出的方法持续改进了现有方法，获得了良好的分布外泛化能力，并在广泛使用的环境中实现了新的最先进结果。",
        "领域": "自然语言处理与视觉结合、强化学习、游戏AI",
        "问题": "解决基于文本的游戏（TBG）中深度强化学习方法在分布变化下泛化能力不足的问题。",
        "动机": "提高代理在基于文本的游戏中的泛化能力，特别是在面对训练数据分布之外的场景时。",
        "方法": "提出了一种基于案例推理的方法，通过收集和再利用代理的积极经验来提升泛化能力和行动效率。",
        "关键词": [
            "案例推理",
            "文本强化学习",
            "泛化能力",
            "基于文本的游戏",
            "分布外泛化"
        ],
        "涉及的技术概念": {
            "案例推理": "从代理的互动中收集积极经验并再利用，以提高行动效率和泛化能力。",
            "深度强化学习": "用于训练代理在基于文本的游戏中进行决策和学习的方法。",
            "分布外泛化": "指代理在面对与训练数据分布不同的新场景时仍能有效工作的能力。"
        },
        "success": true
    },
    {
        "order": 121,
        "title": "Causal Contextual Bandits with Targeted Interventions",
        "html": "https://iclr.cc//virtual/2022/poster/6917",
        "abstract": "We study a contextual bandit setting where the learning agent has the ability to perform interventions on targeted subsets of the population, apart from possessing qualitative causal side-information. This novel formalism captures intricacies in real-world scenarios such as software product experimentation where targeted experiments can be conducted. However, this fundamentally changes the set of options that the agent has, compared to standard contextual bandit settings, necessitating new techniques. This is also the first work that integrates causal side-information in a contextual bandit setting, where the agent aims to learn a policy that maps contexts to arms (as opposed to just identifying one best arm). We propose a new algorithm, which we show empirically performs better than baselines on experiments that use purely synthetic data and on real world-inspired experiments. We also prove a bound on regret that theoretically guards performance.",
        "conference": "ICLR",
        "中文标题": "具有定向干预的因果上下文赌博机",
        "摘要翻译": "我们研究了一种上下文赌博机设置，其中学习代理有能力对目标人群子集进行干预，同时拥有定性的因果侧信息。这种新颖的形式化捕捉了现实世界场景中的复杂性，例如可以进行定向实验的软件产品实验。然而，与标准的上下文赌博机设置相比，这从根本上改变了代理拥有的选项集，需要新的技术。这也是第一个在上下文赌博机设置中整合因果侧信息的工作，其中代理旨在学习一个将上下文映射到臂的策略（而不仅仅是识别一个最佳臂）。我们提出了一种新算法，通过实验证明，在使用纯合成数据和受现实世界启发的实验中，其性能优于基线。我们还证明了遗憾的界限，理论上保证了性能。",
        "领域": "强化学习、因果推理、在线学习",
        "问题": "在具有定向干预能力和因果侧信息的上下文赌博机设置中，如何学习一个有效的策略来映射上下文到臂。",
        "动机": "解决在现实世界场景中，如软件产品实验，进行定向干预时，如何有效利用因果侧信息来优化决策策略的问题。",
        "方法": "提出了一种新算法，该算法在纯合成数据和受现实世界启发的实验中表现优于基线，并提供了理论上的遗憾界限以保证性能。",
        "关键词": [
            "因果上下文赌博机",
            "定向干预",
            "因果侧信息",
            "策略学习",
            "遗憾界限"
        ],
        "涉及的技术概念": {
            "因果上下文赌博机": "一种结合了因果推理和上下文赌博机的框架，用于在具有因果关系的环境中做出决策。",
            "定向干预": "在特定的人群子集上实施干预，以观察或改变其行为或结果。",
            "因果侧信息": "关于变量之间因果关系的额外信息，用于指导决策过程。"
        },
        "success": true
    },
    {
        "order": 122,
        "title": "CDTrans: Cross-domain Transformer for Unsupervised Domain Adaptation",
        "html": "https://iclr.cc//virtual/2022/poster/6251",
        "abstract": "Unsupervised domain adaptation (UDA) aims to transfer knowledge learned from a labeled source domain to a different unlabeled target domain. Most existing UDA methods focus on learning domain-invariant feature representation, either from the domain level or category level, using convolution neural networks (CNNs)-based frameworks. One fundamental problem for the category level based UDA is the production of pseudo labels for samples in target domain, which are usually too noisy for accurate domain alignment, inevitably compromising the UDA performance.  With the success of Transformer in various tasks, we find that the cross-attention in Transformer is robust to the noisy input pairs for better feature alignment, thus in this paper Transformer is adopted for the challenging UDA task. Specifically, to generate accurate input pairs, we design a two-way center-aware labeling algorithm to produce pseudo labels for target samples. Along with the pseudo labels, a weight-sharing triple-branch transformer framework is proposed to apply self-attention and cross-attention for source/target feature learning and source-target domain alignment, respectively. Such design explicitly enforces the framework to learn discriminative domain-specific and domain-invariant representations simultaneously. The proposed method is dubbed CDTrans (cross-domain transformer), and it provides one of the first attempts to solve UDA tasks with a pure transformer solution. Experiments show that our proposed method achieves the best performance on public UDA datasets, e.g. VisDA-2017 and DomainNet. Code and models are available at https://github.com/CDTrans/CDTrans.",
        "conference": "ICLR",
        "中文标题": "CDTrans：用于无监督域适应的跨域Transformer",
        "摘要翻译": "无监督域适应（UDA）旨在将从有标签的源域学到的知识转移到不同的无标签目标域。大多数现有的UDA方法专注于使用基于卷积神经网络（CNNs）的框架，从域级别或类别级别学习域不变的特征表示。基于类别级别的UDA的一个基本问题是为目标域中的样本生成伪标签，这些伪标签通常噪声太大，无法实现准确的域对齐，不可避免地影响了UDA的性能。随着Transformer在各种任务中的成功，我们发现Transformer中的交叉注意力对于噪声输入对具有更好的特征对齐鲁棒性，因此在本文中，我们采用Transformer来解决具有挑战性的UDA任务。具体来说，为了生成准确的输入对，我们设计了一种双向中心感知标签算法为目标样本生成伪标签。与伪标签一起，我们提出了一个权重共享的三分支Transformer框架，分别应用自注意力和交叉注意力进行源/目标特征学习和源-目标域对齐。这样的设计明确地强制框架同时学习有区别的域特定和域不变表示。所提出的方法被称为CDTrans（跨域Transformer），它提供了用纯Transformer解决方案解决UDA任务的首次尝试之一。实验表明，我们提出的方法在公共UDA数据集上实现了最佳性能，例如VisDA-2017和DomainNet。代码和模型可在https://github.com/CDTrans/CDTrans获取。",
        "领域": "无监督域适应、跨域学习、Transformer应用",
        "问题": "解决无监督域适应中伪标签噪声大导致的域对齐不准确问题",
        "动机": "利用Transformer的交叉注意力机制对噪声输入对的鲁棒性，提高无监督域适应的性能",
        "方法": "设计双向中心感知标签算法生成伪标签，并提出权重共享的三分支Transformer框架进行特征学习和域对齐",
        "关键词": [
            "无监督域适应",
            "跨域Transformer",
            "伪标签生成",
            "特征对齐",
            "权重共享"
        ],
        "涉及的技术概念": {
            "交叉注意力": "用于提高模型对噪声输入对的鲁棒性，实现更好的特征对齐",
            "双向中心感知标签算法": "为目标样本生成准确的伪标签，减少噪声影响",
            "权重共享的三分支Transformer框架": "通过共享权重，同时学习域特定和域不变的特征表示"
        },
        "success": true
    },
    {
        "order": 123,
        "title": "Certified Robustness for Deep Equilibrium Models via Interval Bound Propagation",
        "html": "https://iclr.cc//virtual/2022/poster/6631",
        "abstract": "Deep equilibrium layers (DEQs) have demonstrated promising performance and are competitive with standard explicit models on many benchmarks. However, little is known about certifying robustness for these models. Inspired by interval bound propagation (IBP), we propose the IBP-MonDEQ layer, a DEQ layer whose robustness can be verified by computing upper and lower interval bounds on the output. Our key insights are that these interval bounds can be obtained as the fixed-point solution to an IBP-inspired equilibrium equation, and furthermore, that this solution always exists and is unique when the layer obeys a certain parameterization. This fixed point can be interpreted as the result of applying IBP to an infinitely deep, weight-tied neural network, which may be of independent interest, as IBP bounds are typically unstable for deeper networks. Our empirical comparison reveals that models with IBP-MonDEQ layers can achieve comparable $\\ell_{\\infty}$ certified robustness to similarly-sized fully explicit networks.",
        "conference": "ICLR",
        "中文标题": "通过区间边界传播为深度平衡模型提供认证鲁棒性",
        "摘要翻译": "深度平衡层（DEQs）在许多基准测试中表现出了有前景的性能，并且与标准的显式模型具有竞争力。然而，关于这些模型的鲁棒性认证知之甚少。受区间边界传播（IBP）的启发，我们提出了IBP-MonDEQ层，这是一种DEQ层，其鲁棒性可以通过计算输出的上下区间边界来验证。我们的关键见解是，这些区间边界可以作为IBP启发的平衡方程的固定点解获得，而且当层遵循某种参数化时，这个解总是存在且唯一。这个固定点可以解释为将IBP应用于一个无限深、权重绑定的神经网络的结果，这可能具有独立的意义，因为IBP边界对于更深的网络通常是不稳定的。我们的实证比较显示，带有IBP-MonDEQ层的模型可以实现与类似大小的完全显式网络相当的ℓ∞认证鲁棒性。",
        "领域": "深度学习鲁棒性认证、神经网络验证、对抗性防御",
        "问题": "如何为深度平衡模型提供认证鲁棒性",
        "动机": "深度平衡层在多个基准测试中表现优异，但其鲁棒性认证尚未得到充分研究，需要一种方法来验证这些模型的鲁棒性。",
        "方法": "提出IBP-MonDEQ层，通过区间边界传播（IBP）技术计算输出的上下区间边界，以验证模型的鲁棒性。",
        "关键词": [
            "深度平衡模型",
            "区间边界传播",
            "认证鲁棒性",
            "神经网络验证",
            "对抗性防御"
        ],
        "涉及的技术概念": {
            "深度平衡层（DEQs）": "一种通过寻找固定点来隐式定义深度学习的模型，避免了显式的前向传播。",
            "区间边界传播（IBP）": "一种用于计算神经网络输出区间边界的技术，用于验证模型的鲁棒性。",
            "固定点解": "在IBP-MonDEQ层中，通过平衡方程获得的解，用于验证模型的鲁棒性。"
        },
        "success": true
    },
    {
        "order": 124,
        "title": "Chaos is a Ladder: A New Theoretical Understanding of Contrastive Learning via Augmentation Overlap",
        "html": "https://iclr.cc//virtual/2022/poster/6659",
        "abstract": "Recently, contrastive learning has risen to be a promising approach for large-scale self-supervised learning. However, theoretical understanding of how it works is still unclear. In this paper, we propose a new guarantee on the downstream performance without resorting to the conditional independence assumption that is widely adopted in previous work but hardly holds in practice. Our new theory hinges on the insight that the support of different intra-class samples will become more overlapped under aggressive data augmentations, thus simply aligning the positive samples (augmented views of the same sample) could make contrastive learning cluster intra-class samples together. Based on this augmentation overlap perspective, theoretically, we obtain asymptotically closed bounds for downstream performance under weaker assumptions, and empirically, we propose an unsupervised model selection metric ARC that aligns well with downstream accuracy. Our theory suggests an alternative understanding of contrastive learning: the role of aligning positive samples is more like a surrogate task than an ultimate goal, and the overlapped augmented views (i.e., the chaos) create a ladder for contrastive learning to gradually learn class-separated representations. The code for computing ARC is available at https://github.com/zhangq327/ARC.",
        "conference": "ICLR",
        "中文标题": "混沌即阶梯：通过增强重叠对比学习的新理论理解",
        "摘要翻译": "近年来，对比学习已成为大规模自监督学习的一种有前景的方法。然而，关于其工作原理的理论理解仍不清晰。在本文中，我们提出了一种新的下游性能保证，而不依赖于先前工作中广泛采用但在实践中很少成立的独立性假设。我们的新理论基于这样一个见解：在激进的数据增强下，不同类内样本的支持将变得更加重叠，因此简单地对齐正样本（同一样本的增强视图）可以使对比学习将类内样本聚集在一起。基于这种增强重叠的视角，理论上，我们在较弱的假设下获得了下游性能的渐近闭合界限；实证上，我们提出了一种无监督模型选择指标ARC，该指标与下游准确性良好对齐。我们的理论提出了对比学习的另一种理解：对齐正样本的作用更像是替代任务而非终极目标，而重叠的增强视图（即混沌）为对比学习逐步学习类别分离的表示创造了阶梯。计算ARC的代码可在https://github.com/zhangq327/ARC获取。",
        "领域": "自监督学习、对比学习、深度学习理论",
        "问题": "对比学习在理论上的工作原理不清晰，特别是在不依赖强假设条件下如何保证下游性能的问题。",
        "动机": "为了深入理解对比学习的工作机制，特别是在激进数据增强下类内样本重叠增加的现象，以及这种现象如何促进对比学习的效果。",
        "方法": "提出了一种基于增强重叠视角的新理论框架，该框架在不依赖强假设的条件下，提供了对比学习下游性能的理论保证，并开发了一种无监督模型选择指标ARC。",
        "关键词": [
            "对比学习",
            "自监督学习",
            "数据增强",
            "模型选择",
            "理论分析"
        ],
        "涉及的技术概念": {
            "增强重叠": "指在激进的数据增强下，不同类内样本的支持区域变得更加重叠的现象，这是理解对比学习效果的关键。",
            "ARC指标": "一种无监督模型选择指标，用于评估对比学习模型的下游性能，与实际的分类准确性高度相关。",
            "类内样本聚集": "对比学习通过对齐正样本（同一原始样本的不同增强视图）来实现的，使得属于同一类别的样本在表示空间中更加接近。"
        },
        "success": true
    },
    {
        "order": 125,
        "title": "Charformer: Fast Character Transformers via Gradient-based Subword Tokenization",
        "html": "https://iclr.cc//virtual/2022/poster/6303",
        "abstract": "State-of-the-art models in natural language processing rely on separate rigid subword tokenization algorithms, which limit their generalization ability and adaptation to new settings. In this paper, we propose a new model inductive bias that learns a subword tokenization end-to-end as part of the model. To this end, we introduce a soft gradient-based subword tokenization module (GBST) that automatically learns latent subword representations from characters in a data-driven fashion. Concretely, GBST enumerates candidate subword blocks and learns to score them in a position-wise fashion using a block scoring network. We additionally introduce Charformer, a deep Transformer model that integrates GBST and operates on the character level. Via extensive experiments on English GLUE, multilingual, and noisy text datasets, we show that Charformer outperforms a series of competitive character-level baselines while generally performing on par and sometimes outperforming subword-based models. Additionally, Charformer is fast, improving the speed of vanilla character-level Transformers by up to  while maintaining quality. We believe this work paves the way for highly performant token-free models that are trained completely end-to-end.",
        "conference": "ICLR",
        "中文标题": "Charformer：基于梯度的子词分词快速字符Transformer",
        "摘要翻译": "自然语言处理中的最先进模型依赖于独立的刚性子词分词算法，这限制了它们的泛化能力和对新环境的适应。在本文中，我们提出了一种新的模型归纳偏差，它学习端到端的子词分词作为模型的一部分。为此，我们引入了一个基于梯度的软子词分词模块（GBST），该模块以数据驱动的方式自动从字符中学习潜在的子词表示。具体来说，GBST列举候选子词块，并使用块评分网络以位置方式学习评分它们。我们还引入了Charformer，这是一个深度Transformer模型，集成了GBST并在字符级别上操作。通过在英语GLUE、多语言和噪声文本数据集上的广泛实验，我们表明Charformer优于一系列竞争性的字符级基线，同时通常与基于子词的模型表现相当，有时甚至超越。此外，Charformer速度快，将普通字符级Transformer的速度提高了多达，同时保持质量。我们相信这项工作为完全端到端训练的高性能无分词模型铺平了道路。",
        "领域": "自然语言处理与视觉结合、文本表示学习、Transformer模型优化",
        "问题": "解决现有自然语言处理模型因依赖刚性子词分词算法而导致的泛化能力有限和适应新环境困难的问题。",
        "动机": "为了提高模型在自然语言处理任务中的泛化能力和适应性，研究提出了一种能够端到端学习子词分词的新方法。",
        "方法": "提出了一种基于梯度的软子词分词模块（GBST），并开发了Charformer模型，该模型集成了GBST并在字符级别上操作，以实现高效的端到端学习。",
        "关键词": [
            "子词分词",
            "字符级Transformer",
            "端到端学习",
            "梯度基分词",
            "模型优化"
        ],
        "涉及的技术概念": {
            "GBST（梯度基子词分词模块）": "一种能够自动从字符中学习潜在子词表示的模块，通过枚举和评分候选子词块来实现。",
            "Charformer": "一种深度Transformer模型，集成了GBST模块，直接在字符级别上操作，提高了处理速度和模型性能。",
            "端到端学习": "模型直接从原始输入学习到最终输出，无需手动设计中间步骤或特征，提高了模型的适应性和泛化能力。"
        },
        "success": true
    },
    {
        "order": 126,
        "title": "Chemical-Reaction-Aware Molecule Representation Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6246",
        "abstract": "Molecule representation learning (MRL) methods aim to embed molecules into a real vector space. However, existing SMILES-based (Simplified Molecular-Input Line-Entry System) or GNN-based (Graph Neural Networks) MRL methods either take SMILES strings as input that have difficulty in encoding molecule structure information, or over-emphasize the importance of GNN architectures but neglect their generalization ability. Here we propose using chemical reactions to assist learning molecule representation. The key idea of our approach is to preserve the equivalence of molecules with respect to chemical reactions in the embedding space, i.e., forcing the sum of reactant embeddings and the sum of product embeddings to be equal for each chemical equation. This constraint is proven effective to 1) keep the embedding space well-organized and 2) improve the generalization ability of molecule embeddings. Moreover, our model can use any GNN as the molecule encoder and is thus agnostic to GNN architectures. Experimental results demonstrate that our method achieves state-of-the-art performance in a variety of downstream tasks, e.g., reaction product prediction, molecule property prediction, reaction classification, and graph-edit-distance prediction. The code is available at https://github.com/hwwang55/MolR.",
        "conference": "ICLR",
        "中文标题": "化学反应感知的分子表示学习",
        "摘要翻译": "分子表示学习（MRL）方法旨在将分子嵌入到实数向量空间中。然而，现有的基于SMILES（简化分子输入线性系统）或基于GNN（图神经网络）的MRL方法要么将SMILES字符串作为输入，难以编码分子结构信息，要么过分强调GNN架构的重要性而忽视了其泛化能力。在此，我们提出利用化学反应来辅助学习分子表示。我们方法的关键思想是在嵌入空间中保持分子相对于化学反应的等价性，即强制每个化学方程的反应物嵌入之和与产物嵌入之和相等。这一约束被证明能有效：1）保持嵌入空间的有序性；2）提高分子嵌入的泛化能力。此外，我们的模型可以使用任何GNN作为分子编码器，因此对GNN架构不敏感。实验结果表明，我们的方法在各种下游任务中实现了最先进的性能，例如反应产物预测、分子性质预测、反应分类和图编辑距离预测。代码可在https://github.com/hwwang55/MolR获取。",
        "领域": "分子表示学习、化学反应预测、图神经网络应用",
        "问题": "现有分子表示学习方法难以有效编码分子结构信息或忽视模型的泛化能力。",
        "动机": "通过利用化学反应信息来提升分子表示的有序性和泛化能力。",
        "方法": "提出一种化学反应感知的分子表示学习方法，通过在嵌入空间中保持化学反应物和产物的等价性约束，优化分子嵌入。",
        "关键词": [
            "分子表示学习",
            "化学反应感知",
            "图神经网络",
            "泛化能力",
            "嵌入空间"
        ],
        "涉及的技术概念": {
            "分子表示学习": "将分子结构信息嵌入到实数向量空间中的技术，用于下游化学信息学任务。",
            "化学反应感知": "利用化学反应信息来指导和优化分子表示学习过程，提高嵌入的有序性和泛化能力。",
            "图神经网络": "用于处理图结构数据的深度学习模型，在本研究中作为分子编码器的基础架构。"
        },
        "success": true
    },
    {
        "order": 127,
        "title": "Chunked Autoregressive GAN for Conditional Waveform Synthesis",
        "html": "https://iclr.cc//virtual/2022/poster/6816",
        "abstract": "Conditional waveform synthesis models learn a distribution of audio waveforms given conditioning such as text, mel-spectrograms, or MIDI. These systems employ deep generative models that model the waveform via either sequential (autoregressive) or parallel (non-autoregressive) sampling. Generative adversarial networks (GANs) have become a common choice for non-autoregressive waveform synthesis. However, state-of-the-art GAN-based models produce artifacts when performing mel-spectrogram inversion. In this paper, we demonstrate that these artifacts correspond with an inability for the generator to learn accurate pitch and periodicity. We show that simple pitch and periodicity conditioning is insufficient for reducing this error relative to using autoregression. We discuss the inductive bias that autoregression provides for learning the relationship between instantaneous frequency and phase, and show that this inductive bias holds even when autoregressively sampling large chunks of the waveform during each forward pass. Relative to prior state-of-the-art GAN-based models, our proposed model, Chunked Autoregressive GAN (CARGAN) reduces pitch error by 40-60%, reduces training time by 58%, maintains a fast inference speed suitable for real-time or interactive applications, and maintains or improves subjective quality.",
        "conference": "ICLR",
        "中文标题": "分块自回归GAN用于条件波形合成",
        "摘要翻译": "条件波形合成模型学习给定条件（如文本、梅尔频谱图或MIDI）下的音频波形分布。这些系统采用深度生成模型，通过顺序（自回归）或并行（非自回归）采样来建模波形。生成对抗网络（GANs）已成为非自回归波形合成的常见选择。然而，基于GAN的最先进模型在进行梅尔频谱图反转时会产生伪影。在本文中，我们证明这些伪影与生成器无法学习准确的音高和周期性有关。我们展示了简单的音高和周期性条件相对于使用自回归来说，不足以减少这种误差。我们讨论了自回归为学习瞬时频率和相位之间关系提供的归纳偏置，并表明即使在每次前向传递时自回归采样大块波形时，这种归纳偏置仍然有效。相对于之前基于GAN的最先进模型，我们提出的模型——分块自回归GAN（CARGAN）将音高误差减少了40-60%，训练时间减少了58%，保持了适合实时或交互应用的快速推理速度，并保持或提高了主观质量。",
        "领域": "音频合成, 生成对抗网络, 自回归模型",
        "问题": "解决基于GAN的波形合成模型在梅尔频谱图反转时产生的音高和周期性伪影问题",
        "动机": "提高波形合成的音高准确性和周期性，减少伪影，同时保持或提高合成速度和主观质量",
        "方法": "提出分块自回归GAN（CARGAN），通过自回归采样大块波形来学习瞬时频率和相位之间的关系，减少音高误差和训练时间",
        "关键词": [
            "波形合成",
            "生成对抗网络",
            "自回归模型",
            "音高准确性",
            "梅尔频谱图反转"
        ],
        "涉及的技术概念": {
            "生成对抗网络（GANs）": "用于非自回归波形合成的深度生成模型，通过对抗训练提高波形质量",
            "自回归模型": "通过顺序采样建模波形，提供学习瞬时频率和相位关系的归纳偏置",
            "梅尔频谱图反转": "将梅尔频谱图转换回音频波形的过程，CARGAN在此过程中减少了音高和周期性伪影"
        },
        "success": true
    },
    {
        "order": 128,
        "title": "Churn Reduction via Distillation",
        "html": "https://iclr.cc//virtual/2022/poster/6348",
        "abstract": "In real-world systems, models are frequently updated as more data becomes available, and in addition to achieving high accuracy, the goal is to also maintain a low difference in predictions compared to the base model (i.e. predictive churn). If model retraining results in vastly different behavior, then it could cause negative effects in downstream systems, especially if this churn can be avoided with limited impact on model accuracy. In this paper, we show an equivalence between training with distillation using the base model as the teacher and training with an explicit constraint on the predictive churn. We then show that distillation performs strongly for low churn training against a number of recent baselines on a wide range of datasets and model architectures, including fully-connected networks, convolutional networks, and transformers.",
        "conference": "ICLR",
        "中文标题": "通过蒸馏减少预测变动",
        "摘要翻译": "在现实世界的系统中，随着更多数据的可用，模型会频繁更新，除了实现高准确性外，目标还包括保持与基础模型预测的低差异（即预测变动）。如果模型重新训练导致行为大不相同，那么它可能会对下游系统产生负面影响，特别是如果这种变动可以通过对模型准确性有限的影响来避免。在本文中，我们展示了使用基础模型作为教师进行蒸馏训练与对预测变动施加显式约束训练之间的等价性。然后，我们展示了在广泛的数据集和模型架构（包括全连接网络、卷积网络和变换器）上，蒸馏对于低变动训练相对于一些最近的基线表现强劲。",
        "领域": "模型蒸馏、预测一致性维护、深度学习模型更新",
        "问题": "如何在模型更新过程中减少预测变动，同时保持高准确性",
        "动机": "减少模型更新带来的预测变动，避免对下游系统产生负面影响",
        "方法": "使用基础模型作为教师进行蒸馏训练，与对预测变动施加显式约束训练相结合",
        "关键词": [
            "模型蒸馏",
            "预测变动",
            "模型更新",
            "深度学习",
            "预测一致性"
        ],
        "涉及的技术概念": {
            "模型蒸馏": "通过使用基础模型作为教师模型来训练新模型，以减少预测变动",
            "预测变动": "模型更新前后预测结果的差异，本文旨在减少这种差异",
            "显式约束": "在训练过程中直接对预测变动施加限制，以保持预测一致性"
        },
        "success": true
    },
    {
        "order": 129,
        "title": "CKConv: Continuous Kernel Convolution For Sequential Data",
        "html": "https://iclr.cc//virtual/2022/poster/6393",
        "abstract": "Conventional neural architectures for sequential data present important limitations. Recurrent neural networks suffer from exploding and vanishing gradients, small effective memory horizons, and must be trained sequentially. Convolutional neural networks cannot handle sequences of unknown size and their memory horizon must be defined a priori. In this work, we show that these problems can be solved by formulating the convolutional kernels of CNNs as continuous functions. The resulting Continuous Kernel Convolution (CKConv) handles arbitrarily long sequences in a parallel manner, within a single operation, and without relying on any form of recurrence. We show that Continuous Kernel Convolutional Networks (CKCNNs) obtain state-of-the-art results in multiple datasets, e.g., permuted MNIST, and, thanks to their continuous nature, are able to handle non-uniformly sampled datasets and irregularly-sampled data natively. CKCNNs match or perform better than neural ODEs designed for these purposes in a faster and simpler manner.",
        "conference": "ICLR",
        "中文标题": "CKConv: 面向序列数据的连续核卷积",
        "摘要翻译": "传统的序列数据神经网络架构存在重要限制。循环神经网络遭受梯度爆炸和消失、有效记忆范围小的问题，且必须顺序训练。卷积神经网络无法处理未知大小的序列，其记忆范围必须事先定义。在这项工作中，我们展示了通过将卷积神经网络的卷积核公式化为连续函数可以解决这些问题。由此产生的连续核卷积（CKConv）以并行方式处理任意长度的序列，在单一操作内完成，且不依赖任何形式的循环。我们展示了连续核卷积网络（CKCNNs）在多个数据集中获得了最先进的结果，例如排列的MNIST，并且由于其连续性质，能够原生处理非均匀采样数据集和不规则采样数据。CKCNNs以更快更简单的方式匹配或优于为这些目的设计的神经ODE。",
        "领域": "序列建模、时间序列分析、深度学习架构",
        "问题": "解决传统神经网络在处理序列数据时的梯度问题、记忆范围限制和训练效率问题",
        "动机": "克服循环神经网络和卷积神经网络在处理序列数据时的固有缺陷，提供更高效、更灵活的解决方案",
        "方法": "通过将卷积核公式化为连续函数，开发连续核卷积（CKConv）技术，实现并行处理任意长度序列",
        "关键词": [
            "连续核卷积",
            "序列数据",
            "深度学习架构",
            "并行处理",
            "非均匀采样"
        ],
        "涉及的技术概念": {
            "连续核卷积（CKConv）": "将卷积核视为连续函数，允许处理任意长度的序列数据，无需预先定义记忆范围",
            "并行处理": "CKConv技术能够在单一操作内并行处理序列，提高训练和推理效率",
            "非均匀采样数据处理": "由于CKConv的连续性质，能够原生处理非均匀采样和不规则采样的数据，无需额外预处理"
        },
        "success": true
    },
    {
        "order": 130,
        "title": "Clean Images are Hard to Reblur: Exploiting the Ill-Posed Inverse Task for Dynamic Scene Deblurring",
        "html": "https://iclr.cc//virtual/2022/poster/6155",
        "abstract": "The goal of dynamic scene deblurring is to remove the motion blur in a given image. Typical learning-based approaches implement their solutions by minimizing the L1 or L2 distance between the output and the reference sharp image. Recent attempts adopt visual recognition features in training to improve the perceptual quality. However, those features are primarily designed to capture high-level contexts rather than low-level structures such as blurriness. Instead, we propose a more direct way to make images sharper by exploiting the inverse task of deblurring, namely, reblurring. Reblurring amplifies the remaining blur to rebuild the original blur, however, a well-deblurred clean image with zero-magnitude blur is hard to reblur. Thus, we design two types of reblurring loss functions for better deblurring. The supervised reblurring loss at training stage compares the amplified blur between the deblurred and the sharp images. The self-supervised reblurring loss at inference stage inspects if noticeable blur remains in the deblurred. Our experimental results on large-scale benchmarks and real images demonstrate the effectiveness of the reblurring losses in improving the perceptual quality of the deblurred images in terms of NIQE and LPIPS scores as well as visual sharpness.",
        "conference": "ICLR",
        "中文标题": "清晰图像难以再模糊：利用不适定逆任务进行动态场景去模糊",
        "摘要翻译": "动态场景去模糊的目标是去除给定图像中的运动模糊。典型的基于学习的方法通过最小化输出与参考清晰图像之间的L1或L2距离来实现其解决方案。最近的尝试在训练中采用视觉识别特征以提高感知质量。然而，这些特征主要是为捕捉高级上下文而非低级结构（如模糊度）而设计的。相反，我们提出了一种更直接的方法，通过利用去模糊的逆任务——即再模糊——来使图像更清晰。再模糊通过放大剩余的模糊来重建原始模糊，然而，一个去模糊良好的零幅度模糊的清晰图像难以再模糊。因此，我们设计了两种类型的再模糊损失函数以更好地去模糊。训练阶段的监督再模糊损失比较了去模糊图像与清晰图像之间的放大模糊。推理阶段的自监督再模糊损失检查去模糊图像中是否仍有明显的模糊。我们在大型基准和真实图像上的实验结果表明，再模糊损失在提高去模糊图像的感知质量方面，在NIQE和LPIPS分数以及视觉清晰度方面均显示出有效性。",
        "领域": "动态场景去模糊",
        "问题": "如何更有效地去除动态场景图像中的运动模糊，提高图像的清晰度和感知质量",
        "动机": "现有的基于学习的方法主要关注于最小化输出与参考图像之间的距离，而忽略了直接利用去模糊的逆任务（再模糊）来提升图像清晰度的潜力",
        "方法": "设计了两种再模糊损失函数：训练阶段的监督再模糊损失和推理阶段的自监督再模糊损失，通过比较和检查模糊程度来优化去模糊效果",
        "关键词": [
            "动态场景去模糊",
            "再模糊损失",
            "感知质量",
            "监督学习",
            "自监督学习"
        ],
        "涉及的技术概念": {
            "再模糊损失": "通过放大剩余模糊来重建原始模糊，用于优化去模糊过程",
            "监督再模糊损失": "在训练阶段比较去模糊图像与清晰图像之间的放大模糊，用于指导模型学习",
            "自监督再模糊损失": "在推理阶段检查去模糊图像中是否仍有明显的模糊，用于进一步提升图像质量"
        },
        "success": true
    },
    {
        "order": 131,
        "title": "CLEVA-Compass: A Continual Learning Evaluation Assessment Compass to Promote Research Transparency and Comparability",
        "html": "https://iclr.cc//virtual/2022/poster/6188",
        "abstract": "What is the state of the art in continual machine learning? Although a natural question for predominant static benchmarks, the notion to train systems in a lifelong manner entails a plethora of additional challenges with respect to set-up and evaluation.  The latter have recently sparked a growing amount of critiques on prominent algorithm-centric perspectives and evaluation protocols being too narrow, resulting in several attempts at constructing guidelines in favor of specific desiderata or arguing against the validity of prevalent assumptions.  In this work, we depart from this mindset and argue that the goal of a precise formulation of desiderata is an ill-posed one, as diverse applications may always warrant distinct scenarios. Instead, we introduce the Continual Learning EValuation Assessment Compass: the CLEVA-Compass. The compass provides the visual means to both identify how approaches are practically reported and how works can simultaneously be contextualized in the broader literature landscape.  In addition to promoting compact specification in the spirit of recent replication trends, it thus provides an intuitive chart to understand the priorities of individual systems, where they resemble each other, and what elements are missing towards a fair comparison.  ",
        "conference": "ICLR",
        "中文标题": "CLEVA指南针：促进研究透明度和可比性的持续学习评估指南针",
        "摘要翻译": "持续机器学习的最新技术是什么？虽然对于主要的静态基准测试来说这是一个自然的问题，但以终身学习的方式训练系统的概念在设置和评估方面带来了一系列额外的挑战。后者最近引发了越来越多对以算法为中心的突出观点和评估协议过于狭窄的批评，导致了几次尝试构建指南以支持特定的期望或反对普遍假设的有效性。在这项工作中，我们摆脱了这种思维模式，认为精确制定期望的目标是一个不适定的问题，因为不同的应用可能总是需要不同的场景。相反，我们引入了持续学习评估评估指南针：CLEVA指南针。该指南针提供了视觉手段，既可以识别方法是如何实际报告的，又可以同时将工作置于更广泛的文献背景中进行情境化。除了促进符合最近复制趋势精神的紧凑规范外，它还提供了一个直观的图表，以理解个别系统的优先级，它们在哪里相似，以及为了实现公平比较缺少哪些元素。",
        "领域": "持续学习、机器学习评估、研究透明度",
        "问题": "如何评估和比较持续学习算法的性能，以促进研究的透明度和可比性。",
        "动机": "当前持续学习领域的评估方法和协议存在局限性，缺乏统一和透明的标准来比较不同算法的性能。",
        "方法": "引入CLEVA指南针，一种视觉工具，用于识别和情境化持续学习方法，促进研究的透明度和可比性。",
        "关键词": [
            "持续学习",
            "评估指南针",
            "研究透明度",
            "算法比较",
            "终身学习"
        ],
        "涉及的技术概念": {
            "持续学习": "一种机器学习范式，旨在使模型能够从连续的数据流中学习，而不会忘记之前学到的知识。",
            "评估协议": "用于评估机器学习算法性能的标准和方法，确保结果的可比性和可重复性。",
            "视觉工具": "一种图形化表示方法，用于直观地展示和比较不同算法或研究的特性和结果。"
        },
        "success": true
    },
    {
        "order": 132,
        "title": "ClimateGAN: Raising Climate Change Awareness by Generating Images of Floods",
        "html": "https://iclr.cc//virtual/2022/poster/6224",
        "abstract": "Climate change is a major threat to humanity and the actions required to prevent its catastrophic consequences include changes in both policy-making and individual behaviour. However, taking action requires understanding its seemingly abstract and distant consequences. Projecting the potential impacts of extreme climate events such as flooding in familiar places can help make the impacts of climate change more concrete and encourage action. As part of a larger initiative to build a website (https://thisclimatedoesnotexist.com) that projects extreme climate events onto user-chosen photos, we present our solution to simulate photo-realistic floods on authentic images. To address this complex task in the absence of suitable data, we propose ClimateGAN, a model that leverages both simulated and real data through unsupervised domain adaptation and conditional image generation. In this paper, we describe the details of our framework, thoroughly evaluate the main components of our architecture and demonstrate that our model is capable of robustly generating photo-realistic flooding on street images.",
        "conference": "ICLR",
        "中文标题": "ClimateGAN：通过生成洪水图像提高气候变化意识",
        "摘要翻译": "气候变化是人类面临的主要威胁，防止其灾难性后果所需的行动包括政策制定和个人行为的改变。然而，采取行动需要理解其看似抽象且遥远的后果。在熟悉的地方预测极端气候事件（如洪水）的潜在影响，可以帮助使气候变化的影响更加具体，并鼓励采取行动。作为构建一个网站（https://thisclimatedoesnotexist.com）的大型倡议的一部分，该网站将极端气候事件投射到用户选择的照片上，我们提出了在真实图像上模拟逼真洪水的解决方案。为了解决在没有合适数据的情况下这一复杂任务，我们提出了ClimateGAN，一个通过无监督域适应和条件图像生成利用模拟和真实数据的模型。在本文中，我们详细描述了我们的框架，全面评估了我们架构的主要组成部分，并证明了我们的模型能够在街道图像上稳健地生成逼真的洪水。",
        "领域": "图像生成、无监督学习、环境视觉化",
        "问题": "在缺乏合适数据的情况下，如何生成逼真的洪水图像以提高对气候变化影响的认识",
        "动机": "通过将极端气候事件的潜在影响视觉化，使气候变化的影响更加具体，从而鼓励采取行动",
        "方法": "提出ClimateGAN模型，结合无监督域适应和条件图像生成技术，利用模拟和真实数据生成逼真的洪水图像",
        "关键词": [
            "ClimateGAN",
            "无监督域适应",
            "条件图像生成",
            "气候变化视觉化",
            "洪水模拟"
        ],
        "涉及的技术概念": {
            "无监督域适应": "用于在没有标签数据的情况下，将模拟数据中的知识迁移到真实数据中，以生成逼真的洪水图像",
            "条件图像生成": "根据特定条件（如洪水）生成图像的技术，用于在用户选择的照片上模拟洪水",
            "ClimateGAN": "本文提出的模型，结合无监督域适应和条件图像生成技术，旨在生成逼真的气候变化影响图像"
        },
        "success": true
    },
    {
        "order": 133,
        "title": "Closed-form Sample Probing for Learning Generative Models in Zero-shot Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6138",
        "abstract": "Generative model based approaches have led to significant advances in zero-shot learning (ZSL) over the past few years. These approaches typically aim to learn a conditional generator that synthesizes training samples of classes conditioned on class definitions. The final zero-shot learning model is then obtained by training a supervised classification model over the real and/or synthesized training samples of seen and unseen classes, combined. Therefore, naturally, the generative model needs to produce not only relevant samples, but also those that are sufficiently rich for classifier training purposes, which is handled by various heuristics in existing works. In this paper, we introduce a principled approach for training generative models {\\em directly} for training data generation purposes. Our main observation is that the use of closed-form models opens doors to end-to-end training thanks to the differentiability of the solvers. In our approach, at each generative model update step, we fit a task-specific closed-form ZSL model from generated samples, and measure its loss on novel samples all within the compute graph, a procedure that we refer to as {\\em sample probing}. In this manner, the generator receives feedback directly based on the value of its samples for model training purposes. Our experimental results show that the proposed sample probing approach improves the ZSL results even when integrated into state-of-the-art generative models.",
        "conference": "ICLR",
        "中文标题": "零样本学习中学习生成模型的闭式样本探测",
        "摘要翻译": "基于生成模型的方法在过去几年中推动了零样本学习（ZSL）领域的显著进展。这些方法通常旨在学习一个条件生成器，该生成器根据类定义合成类的训练样本。然后，通过在真实和/或合成的已见和未见类训练样本上训练一个监督分类模型，结合这些样本，获得最终的零样本学习模型。因此，生成模型不仅需要产生相关样本，还需要产生足够丰富以用于分类器训练目的的样本，这在现有工作中通过各种启发式方法处理。在本文中，我们介绍了一种原则性的方法，用于直接为训练数据生成目的训练生成模型。我们的主要观察是，闭式模型的使用由于求解器的可微分性，为端到端训练打开了大门。在我们的方法中，在每个生成模型更新步骤，我们从生成的样本中拟合一个任务特定的闭式ZSL模型，并在计算图中测量其对新颖样本的损失，这一过程我们称之为样本探测。通过这种方式，生成器直接基于其样本对模型训练目的的价值接收反馈。我们的实验结果表明，即使集成到最先进的生成模型中，所提出的样本探测方法也能提高ZSL的结果。",
        "领域": "零样本学习",
        "问题": "如何直接为训练数据生成目的训练生成模型，以提高零样本学习的性能",
        "动机": "现有生成模型在零样本学习中生成样本的丰富性和相关性不足，需要一种更直接的方法来优化生成模型以提升分类器训练效果",
        "方法": "提出一种闭式样本探测方法，通过在生成模型更新步骤中拟合任务特定的闭式ZSL模型并测量其损失，直接优化生成模型",
        "关键词": [
            "零样本学习",
            "生成模型",
            "闭式样本探测",
            "端到端训练",
            "分类器训练"
        ],
        "涉及的技术概念": {
            "闭式模型": "在本文中用于实现端到端训练，由于其求解器的可微分性，使得直接优化生成模型成为可能",
            "样本探测": "指在每个生成模型更新步骤中，从生成的样本中拟合任务特定的闭式ZSL模型并测量其损失的过程，用于直接评估生成样本对模型训练的价值",
            "端到端训练": "通过闭式模型和样本探测方法实现，使得生成模型能够直接基于其对分类器训练效果的贡献进行优化"
        },
        "success": true
    },
    {
        "order": 134,
        "title": "CoBERL: Contrastive BERT for Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2022/poster/7114",
        "abstract": "Many reinforcement learning (RL) agents require a large amount of experience to solve tasks. We propose Contrastive BERT for RL (COBERL), an agent that combines a new contrastive loss and a hybrid LSTM-transformer architecture to tackle the challenge of improving data efficiency. COBERL enables efficient and robust learning from pixels across a wide variety of domains. We use bidirectional masked prediction in combination with a generalization of a recent contrastive method to learn better representations for RL, without the need of hand engineered data augmentations. We find that COBERL consistently improves data efficiency across the full Atari suite, a set of control tasks and a challenging 3D environment, and often it also increases final score performance.",
        "conference": "ICLR",
        "中文标题": "CoBERL：用于强化学习的对比BERT",
        "摘要翻译": "许多强化学习（RL）智能体需要大量经验来解决任务。我们提出了用于强化学习的对比BERT（COBERL），这是一种结合了新的对比损失和混合LSTM-transformer架构的智能体，旨在解决提高数据效率的挑战。COBERL能够在多种领域中从像素进行高效且稳健的学习。我们结合双向掩码预测和最近对比方法的泛化，来学习更好的RL表示，而无需手工设计的数据增强。我们发现，COBERL在整个Atari套件、一组控制任务和一个具有挑战性的3D环境中持续提高了数据效率，并且通常也提高了最终得分性能。",
        "领域": "强化学习、深度学习、计算机视觉",
        "问题": "提高强化学习智能体的数据效率",
        "动机": "解决强化学习智能体需要大量经验才能解决任务的问题，提高学习效率",
        "方法": "结合新的对比损失和混合LSTM-transformer架构，使用双向掩码预测和对比方法的泛化来学习更好的表示",
        "关键词": [
            "强化学习",
            "对比学习",
            "BERT",
            "数据效率",
            "LSTM-transformer"
        ],
        "涉及的技术概念": {
            "对比损失": "用于提高模型对数据效率的学习能力，通过对比学习优化表示",
            "LSTM-transformer架构": "结合了LSTM和transformer的优势，用于处理序列数据和提高模型性能",
            "双向掩码预测": "用于学习更全面的数据表示，提高模型对数据的理解能力"
        },
        "success": true
    },
    {
        "order": 135,
        "title": "CodeTrek: Flexible Modeling of Code using an Extensible Relational Representation",
        "html": "https://iclr.cc//virtual/2022/poster/6737",
        "abstract": "Designing a suitable representation for code-reasoning tasks is challenging in aspects such as the kinds of program information to model, how to combine them, and how much context to consider. We propose CodeTrek, a deep learning approach that addresses these challenges by representing codebases as databases that conform to rich relational schemas. The relational representation not only allows CodeTrek to uniformly represent diverse kinds of program information, but also to leverage program-analysis queries to derive new semantic relations, which can be readily incorporated without further architectural engineering. CodeTrek embeds this relational representation using a set of walks that can traverse different relations in an unconstrained fashion, and incorporates all relevant attributes along the way. We evaluate CodeTrek on four diverse and challenging Python tasks: variable misuse, exception prediction, unused definition, and variable shadowing. CodeTrek achieves an accuracy of 91%, 63%, 98%, and 94% on these tasks respectively, and outperforms state-of-the-art neural models by 2-19% points.",
        "conference": "ICLR",
        "中文标题": "CodeTrek：使用可扩展关系表示对代码进行灵活建模",
        "摘要翻译": "为代码推理任务设计合适的表示方法在多个方面具有挑战性，例如需要建模的程序信息种类、如何组合这些信息以及考虑多少上下文。我们提出了CodeTrek，这是一种深度学习方法，通过将代码库表示为符合丰富关系模式的数据库来应对这些挑战。关系表示不仅允许CodeTrek统一表示各种程序信息，还能利用程序分析查询来推导新的语义关系，这些关系可以轻松整合而无需进一步的架构工程。CodeTrek通过一组可以不受限制地遍历不同关系的游走嵌入这种关系表示，并沿途整合所有相关属性。我们在四个多样且具有挑战性的Python任务上评估了CodeTrek：变量误用、异常预测、未使用定义和变量遮蔽。CodeTrek在这些任务上的准确率分别达到91%、63%、98%和94%，并且比最先进的神经模型高出2-19个百分点。",
        "领域": "程序分析、深度学习、代码表示学习",
        "问题": "如何设计一个能够统一表示多样程序信息并能够灵活扩展的代码表示方法",
        "动机": "解决代码推理任务中程序信息表示、组合和上下文考虑的挑战",
        "方法": "提出CodeTrek方法，将代码库表示为符合关系模式的数据库，利用程序分析查询推导新语义关系，并通过游走机制嵌入关系表示",
        "关键词": [
            "代码表示",
            "关系数据库",
            "程序分析",
            "深度学习",
            "Python任务"
        ],
        "涉及的技术概念": {
            "关系表示": "将代码库表示为符合关系模式的数据库，统一表示多样程序信息",
            "程序分析查询": "用于推导新的语义关系，增强代码表示的能力",
            "游走机制": "通过不受限制地遍历不同关系来嵌入关系表示，整合所有相关属性"
        },
        "success": true
    },
    {
        "order": 136,
        "title": "Coherence-based Label Propagation over Time Series for Accelerated Active Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6012",
        "abstract": "Time-series data are ubiquitous these days, but lack of the labels in time-series data is regarded as a hurdle for its broad applicability. Meanwhile, active learning has been successfully adopted to reduce the labeling efforts in various tasks. Thus, this paper addresses an important issue, time-series active learning. Inspired by the temporal coherence in time-series data, where consecutive data points tend to have the same label, our label propagation framework, called TCLP, automatically assigns a queried label to the data points within an accurately estimated time-series segment, thereby significantly boosting the impact of an individual query. Compared with traditional time-series active learning, TCLP is shown to improve the classification accuracy by up to 7.1 times when only 0.8% of data points in the entire time series are queried for their labels.",
        "conference": "ICLR",
        "中文标题": "基于时间序列连贯性的标签传播加速主动学习",
        "摘要翻译": "时间序列数据在当今无处不在，但缺乏标签被视为其广泛应用的一个障碍。与此同时，主动学习已成功应用于减少各种任务中的标注努力。因此，本文解决了一个重要问题，即时间序列的主动学习。受时间序列数据中时间连贯性的启发，即连续的数据点往往具有相同的标签，我们的标签传播框架TCLP自动将查询到的标签分配给准确估计的时间序列段内的数据点，从而显著提升单个查询的影响。与传统的时间序列主动学习相比，当整个时间序列中仅有0.8%的数据点被查询其标签时，TCLP显示可以将分类准确率提高多达7.1倍。",
        "领域": "时间序列分析, 主动学习, 数据标注",
        "问题": "解决时间序列数据中标签缺乏的问题，通过主动学习减少标注努力。",
        "动机": "利用时间序列数据中的时间连贯性，提高主动学习在时间序列数据分类中的效率和准确性。",
        "方法": "提出了一种基于时间连贯性的标签传播框架TCLP，自动将查询到的标签分配给时间序列段内的数据点。",
        "关键词": [
            "时间序列分析",
            "主动学习",
            "标签传播",
            "TCLP",
            "数据标注"
        ],
        "涉及的技术概念": {
            "时间连贯性": "指时间序列数据中连续数据点倾向于具有相同标签的特性，用于指导标签传播。",
            "标签传播框架TCLP": "本文提出的框架，利用时间连贯性自动分配标签，减少标注努力。",
            "主动学习": "一种机器学习方法，通过选择最有信息量的样本进行标注，以提高学习效率。"
        },
        "success": true
    },
    {
        "order": 137,
        "title": "Cold Brew: Distilling Graph Node Representations with Incomplete or Missing Neighborhoods",
        "html": "https://iclr.cc//virtual/2022/poster/7094",
        "abstract": "Graph Neural Networks (GNNs) have achieved state-of-the-art performance in node classification, regression, and recommendation tasks. GNNs work well when rich and high-quality connections are available. However, their effectiveness is often jeopardized in many real-world graphs in which node degrees have power-law distributions. The extreme case of this situation, where a node may have no neighbors, is called Strict Cold Start (SCS). SCS forces the prediction to rely completely on the node's own features. We propose Cold Brew, a teacher-student distillation approach to address the SCS and noisy-neighbor challenges for GNNs. We also introduce feature contribution ratio (FCR), a metric to quantify the behavior of inductive GNNs to solve SCS. We experimentally show that FCR disentangles the contributions of different graph data components and helps select the best architecture for SCS generalization. We further demonstrate the superior performance of Cold Brew on several public benchmark and proprietary e-commerce datasets, where many nodes have either very few or noisy connections. Our source code is available at https://github.com/amazon-research/gnn-tail-generalization.",
        "conference": "ICLR",
        "中文标题": "冷萃：在不完整或缺失邻域的情况下蒸馏图节点表示",
        "摘要翻译": "图神经网络（GNNs）在节点分类、回归和推荐任务中实现了最先进的性能。当存在丰富且高质量的连接时，GNNs表现良好。然而，在许多现实世界的图中，节点度具有幂律分布，它们的有效性常常受到威胁。这种情况的极端案例，即一个节点可能没有任何邻居，被称为严格冷启动（SCS）。SCS迫使预测完全依赖于节点自身的特征。我们提出了Cold Brew，一种师生蒸馏方法，以解决GNNs面临的SCS和噪声邻居挑战。我们还引入了特征贡献比（FCR），一个量化归纳GNNs解决SCS行为的度量。我们通过实验表明，FCR解开了不同图数据组件的贡献，并帮助选择最佳架构以实现SCS泛化。我们进一步展示了Cold Brew在几个公共基准和专有电子商务数据集上的卓越性能，其中许多节点具有非常少或噪声连接。我们的源代码可在https://github.com/amazon-research/gnn-tail-generalization获取。",
        "领域": "图神经网络、节点分类、推荐系统",
        "问题": "解决图神经网络在严格冷启动（SCS）和噪声邻居情况下的性能问题",
        "动机": "提高图神经网络在节点度分布不均或邻居信息缺失情况下的泛化能力和预测准确性",
        "方法": "提出了一种师生蒸馏方法Cold Brew和特征贡献比（FCR）度量，以优化GNNs在SCS和噪声邻居条件下的表现",
        "关键词": [
            "图神经网络",
            "严格冷启动",
            "师生蒸馏",
            "特征贡献比",
            "节点分类"
        ],
        "涉及的技术概念": {
            "严格冷启动（SCS）": "指图中节点没有任何邻居的极端情况，迫使预测完全依赖于节点自身的特征",
            "师生蒸馏": "一种知识转移方法，通过训练一个复杂的教师模型来指导一个更简单的学生模型，以提高学生模型的性能",
            "特征贡献比（FCR）": "一种度量，用于量化归纳GNNs中不同图数据组件对解决SCS问题的贡献，帮助选择最佳模型架构"
        },
        "success": true
    },
    {
        "order": 138,
        "title": "Collapse by Conditioning: Training Class-conditional GANs with Limited Data",
        "html": "https://iclr.cc//virtual/2022/poster/6764",
        "abstract": "Class-conditioning offers a direct means to control a Generative Adversarial Network (GAN) based on a discrete input variable. While necessary in many applications, the additional information provided by the class labels could even be expected to benefit the training of the GAN itself. On the contrary, we observe that class-conditioning causes mode collapse in limited data settings, where unconditional learning leads to satisfactory generative ability. Motivated by this observation, we propose a training strategy for class-conditional GANs (cGANs) that effectively prevents the observed mode-collapse by leveraging unconditional learning. Our training strategy starts with an unconditional GAN and gradually injects the class conditioning into the generator and the objective function. The proposed method for training cGANs with limited data results not only in stable training but also in generating high-quality images, thanks to the early-stage exploitation of the shared information across classes. We analyze the observed mode collapse problem in comprehensive experiments on four datasets. Our approach demonstrates outstanding results compared with state-of-the-art methods and established baselines. The code is available at https://github.com/mshahbazi72/transitional-cGAN",
        "conference": "ICLR",
        "中文标题": "通过条件化导致的崩溃：在有限数据下训练类别条件生成对抗网络",
        "摘要翻译": "类别条件化为基于离散输入变量控制生成对抗网络（GAN）提供了一种直接手段。虽然在许多应用中必不可少，但类别标签提供的额外信息甚至可能被认为有利于GAN本身的训练。然而，我们观察到，在有限数据设置下，类别条件化会导致模式崩溃，而无条件学习则能带来令人满意的生成能力。基于这一观察，我们提出了一种针对类别条件生成对抗网络（cGANs）的训练策略，该策略通过利用无条件学习有效防止了观察到的模式崩溃。我们的训练策略从一个无条件GAN开始，逐渐将类别条件化注入生成器和目标函数中。所提出的在有限数据下训练cGANs的方法不仅实现了稳定的训练，还生成了高质量的图像，这得益于早期阶段对跨类别共享信息的利用。我们在四个数据集上进行了全面的实验，分析了观察到的模式崩溃问题。与最先进的方法和已建立的基线相比，我们的方法展示了卓越的结果。代码可在https://github.com/mshahbazi72/transitional-cGAN获取。",
        "领域": "生成对抗网络、图像生成、模式崩溃",
        "问题": "在有限数据条件下，类别条件化导致生成对抗网络出现模式崩溃的问题",
        "动机": "解决在有限数据环境下，类别条件生成对抗网络训练过程中出现的模式崩溃问题，提升生成图像的质量和训练稳定性",
        "方法": "提出一种训练策略，从无条件GAN开始，逐步引入类别条件化，以利用跨类别共享信息，防止模式崩溃",
        "关键词": [
            "类别条件生成对抗网络",
            "模式崩溃",
            "有限数据",
            "无条件学习",
            "图像生成"
        ],
        "涉及的技术概念": {
            "类别条件生成对抗网络": "一种能够根据离散类别标签生成特定类别图像的生成对抗网络",
            "模式崩溃": "生成模型在训练过程中仅能生成有限几种模式的数据，无法覆盖全部数据分布的现象",
            "无条件学习": "在生成对抗网络的训练初期不引入类别条件化，以利用跨类别的共享信息，提升模型的生成能力和训练稳定性"
        },
        "success": true
    },
    {
        "order": 139,
        "title": "Communication-Efficient Actor-Critic Methods for Homogeneous Markov Games",
        "html": "https://iclr.cc//virtual/2022/poster/6817",
        "abstract": "Recent success in cooperative multi-agent reinforcement learning (MARL) relies on centralized training and policy sharing. Centralized training eliminates the issue of non-stationarity MARL yet induces large communication costs, and policy sharing is empirically crucial to efficient learning in certain tasks yet lacks theoretical justification. In this paper, we formally characterize a subclass of cooperative Markov games where agents exhibit a certain form of homogeneity such that policy sharing provably incurs no suboptimality. This enables us to develop the first consensus-based decentralized actor-critic method where the consensus update is applied to both the actors and the critics while ensuring convergence. We also develop practical algorithms based on our decentralized actor-critic method to reduce the communication cost during training, while still yielding policies comparable with centralized training.",
        "conference": "ICLR",
        "中文标题": "高效通信的演员-评论家方法用于同质马尔可夫博弈",
        "摘要翻译": "近年来，合作型多智能体强化学习（MARL）的成功依赖于集中式训练和策略共享。集中式训练消除了MARL中的非平稳性问题，但带来了较大的通信成本；而策略共享在某些任务中对高效学习至关重要，但缺乏理论依据。本文正式刻画了一类合作型马尔可夫博弈的子类，其中智能体表现出某种形式的同质性，使得策略共享理论上不会导致次优性。这使我们能够开发出第一个基于共识的去中心化演员-评论家方法，其中共识更新同时应用于演员和评论家，同时确保收敛。我们还基于我们的去中心化演员-评论家方法开发了实用算法，以减少训练期间的通信成本，同时仍能产生与集中式训练相当的策略。",
        "领域": "多智能体强化学习、马尔可夫决策过程、分布式优化",
        "问题": "如何在保证学习效率的同时，减少多智能体强化学习中的通信成本",
        "动机": "解决集中式训练带来的高通信成本和策略共享缺乏理论依据的问题",
        "方法": "开发基于共识的去中心化演员-评论家方法，并在演员和评论家中应用共识更新",
        "关键词": [
            "多智能体强化学习",
            "演员-评论家方法",
            "共识算法",
            "通信效率",
            "马尔可夫博弈"
        ],
        "涉及的技术概念": {
            "同质马尔可夫博弈": "一类合作型马尔可夫博弈的子类，智能体表现出同质性，使得策略共享理论上不会导致次优性",
            "共识算法": "用于在去中心化环境中达成一致的算法，本文中应用于演员和评论家的更新",
            "演员-评论家方法": "一种结合了策略梯度（演员）和价值函数（评论家）的强化学习方法，用于在马尔可夫决策过程中学习策略"
        },
        "success": true
    },
    {
        "order": 140,
        "title": "Comparing Distributions by Measuring Differences that Affect Decision Making",
        "html": "https://iclr.cc//virtual/2022/poster/6695",
        "abstract": "Measuring the discrepancy between two probability distributions is a fundamental problem in machine learning and statistics. We propose a new class of discrepancies based on the optimal loss for a decision task -- two distributions are different if the optimal decision loss is higher on their mixture than on each individual distribution. By suitably choosing the decision task, this generalizes the Jensen-Shannon divergence and the maximum mean discrepancy family. We apply our approach to two-sample tests, and on various benchmarks, we achieve superior test power compared to competing methods. In addition, a modeler can directly specify their preferences when comparing distributions through the decision loss. We apply this property to understanding the effects of climate change on different social and economic activities, evaluating sample quality, and selecting features targeting different decision tasks.",
        "conference": "ICLR",
        "中文标题": "通过衡量影响决策的差异来比较分布",
        "摘要翻译": "衡量两个概率分布之间的差异是机器学习和统计学中的一个基本问题。我们提出了一类新的差异度量方法，基于决策任务的最优损失——如果两个分布在它们的混合分布上的最优决策损失高于各自单独分布上的损失，则认为这两个分布是不同的。通过适当选择决策任务，这种方法可以推广到Jensen-Shannon散度和最大均值差异家族。我们将我们的方法应用于双样本测试，并在各种基准测试中，与竞争方法相比，我们实现了更高的测试功效。此外，建模者可以通过决策损失直接指定他们在比较分布时的偏好。我们利用这一特性来理解气候变化对不同社会和经济活动的影响，评估样本质量，以及选择针对不同决策任务的特征。",
        "领域": "统计机器学习、概率分布比较、决策理论",
        "问题": "如何有效地衡量和比较两个概率分布之间的差异，特别是在决策任务中。",
        "动机": "为了提供一种更灵活和有效的方法来比较概率分布，特别是在决策任务中，使得模型能够根据具体的决策损失来优化分布比较。",
        "方法": "提出了一种基于决策任务最优损失的新差异度量方法，通过比较混合分布和单独分布上的最优决策损失来定义分布差异，并应用于双样本测试和其他应用场景。",
        "关键词": [
            "概率分布比较",
            "决策损失",
            "双样本测试",
            "Jensen-Shannon散度",
            "最大均值差异"
        ],
        "涉及的技术概念": {
            "最优决策损失": "用于定义两个分布差异的基础，通过比较在混合分布和单独分布上的最优决策损失来判断分布是否不同。",
            "Jensen-Shannon散度": "一种衡量两个概率分布相似度的方法，本文的方法可以视为其推广。",
            "最大均值差异": "一种在再生核希尔伯特空间中衡量两个分布差异的方法，本文的方法也与之相关。"
        },
        "success": true
    },
    {
        "order": 141,
        "title": "ComPhy: Compositional Physical Reasoning of Objects and Events from Videos",
        "html": "https://iclr.cc//virtual/2022/poster/6457",
        "abstract": "Objects' motions in nature are governed by complex interactions and their properties. While some properties, such as shape and material, can be identified via the object's visual appearances, others like mass and electric charge are not directly visible. The compositionality between the visible and hidden properties poses unique challenges for AI models to reason from the physical world, whereas humans can effortlessly infer them with limited observations. Existing studies on video reasoning mainly focus on visually observable elements such as object appearance, movement, and contact interaction. In this paper, we take an initial step to highlight the importance of inferring the hidden physical properties not directly observable from visual appearances, by introducing the Compositional Physical Reasoning (ComPhy) dataset. For a given set of objects, ComPhy includes few videos of them moving and interacting under different initial conditions. The model is evaluated based on its capability to unravel the compositional hidden properties, such as mass and charge, and use this knowledge to answer a set of questions posted on one of the videos. Evaluation results of several state-of-the-art video reasoning models on ComPhy show unsatisfactory performance as they fail to capture these hidden properties. We further propose an oracle neural-symbolic framework named Compositional Physics Learner (CPL), combining visual perception, physical property learning, dynamic prediction, and symbolic execution into a unified framework. CPL can effectively identify objects' physical properties from their interactions and predict their dynamics to answer questions. ",
        "conference": "ICLR",
        "中文标题": "ComPhy：从视频中对物体和事件进行组合物理推理",
        "摘要翻译": "自然界中物体的运动受复杂相互作用及其属性的支配。虽然一些属性，如形状和材质，可以通过物体的视觉外观来识别，但其他如质量和电荷则不能直接观察到。可见与隐藏属性之间的组合性为AI模型从物理世界进行推理带来了独特的挑战，而人类却能在有限的观察下轻松推断出这些属性。现有的视频推理研究主要关注视觉可观察的元素，如物体外观、运动和接触交互。在本文中，我们通过引入组合物理推理（ComPhy）数据集，初步强调了推断不能直接从视觉外观观察到的隐藏物理属性的重要性。对于给定的一组物体，ComPhy包含了它们在各种初始条件下移动和交互的几个视频。模型的评估基于其解开组合隐藏属性（如质量和电荷）的能力，并利用这些知识回答关于其中一个视频提出的一系列问题。在ComPhy上对几种最先进的视频推理模型的评估结果显示，它们的表现不尽如人意，因为它们未能捕捉到这些隐藏属性。我们进一步提出了一个名为组合物理学习器（CPL）的预言神经符号框架，将视觉感知、物理属性学习、动态预测和符号执行结合到一个统一的框架中。CPL能够有效地从物体的交互中识别其物理属性，并预测其动态以回答问题。",
        "领域": "视频理解、物理推理、神经符号学习",
        "问题": "如何从视频中推断物体的隐藏物理属性（如质量和电荷）并进行组合物理推理",
        "动机": "解决AI模型在从视觉观察中推断隐藏物理属性方面的不足，模仿人类轻松进行物理推理的能力",
        "方法": "引入ComPhy数据集评估模型性能，并提出组合物理学习器（CPL）框架，结合视觉感知、物理属性学习、动态预测和符号执行",
        "关键词": [
            "组合物理推理",
            "隐藏物理属性",
            "神经符号框架",
            "视频理解",
            "动态预测"
        ],
        "涉及的技术概念": {
            "组合物理推理": "从视频中推断物体的隐藏物理属性（如质量和电荷）并进行组合分析",
            "神经符号框架": "结合神经网络和符号逻辑的框架，用于物理属性的学习和推理",
            "动态预测": "基于物体的物理属性和当前状态预测其未来运动或交互"
        },
        "success": true
    },
    {
        "order": 142,
        "title": "Complete Verification via Multi-Neuron Relaxation Guided Branch-and-Bound",
        "html": "https://iclr.cc//virtual/2022/poster/6097",
        "abstract": "State-of-the-art neural network verifiers are fundamentally based on one of two paradigms: either encoding the whole verification problem via tight multi-neuron convex relaxations or applying a Branch-and-Bound (BaB) procedure leveraging imprecise but fast bounding methods on a large number of easier subproblems. The former can capture complex multi-neuron dependencies but sacrifices completeness due to the inherent limitations of convex relaxations. The latter enables complete verification but becomes increasingly ineffective on larger and more challenging networks. In this work, we present a novel complete verifier which combines the strengths of both paradigms: it leverages multi-neuron relaxations to drastically reduce the number of subproblems generated during the BaB process and an efficient GPU-based dual optimizer to solve the remaining ones. An extensive evaluation demonstrates that our verifier achieves a new state-of-the-art on both established benchmarks as well as networks with significantly higher accuracy than previously considered. The latter result (up to 28% certification gains) indicates meaningful progress towards creating verifiers that can handle practically relevant networks.",
        "conference": "ICLR",
        "中文标题": "通过多神经元松弛引导的分支定界实现完整验证",
        "摘要翻译": "最先进的神经网络验证器基本上基于两种范式之一：要么通过紧密的多神经元凸松弛对整个验证问题进行编码，要么在大量更简单的子问题上应用分支定界（BaB）程序，利用不精确但快速的边界方法。前者可以捕捉复杂的多神经元依赖关系，但由于凸松弛的固有局限性而牺牲了完整性。后者能够实现完整验证，但在更大和更具挑战性的网络上变得越来越无效。在这项工作中，我们提出了一种新颖的完整验证器，它结合了两种范式的优势：利用多神经元松弛大幅减少BaB过程中生成的子问题数量，并利用基于GPU的高效双优化器解决剩余的子问题。广泛的评估表明，我们的验证器在既定基准以及具有比之前考虑的网络显著更高准确度的网络上实现了新的最先进水平。后一结果（高达28%的认证增益）表明在创建能够处理实际相关网络的验证器方面取得了有意义的进展。",
        "领域": "神经网络验证、深度学习安全、形式化方法",
        "问题": "解决现有神经网络验证方法在完整性和效率上的局限性",
        "动机": "结合多神经元松弛和分支定界方法的优势，以提高神经网络验证的完整性和效率",
        "方法": "利用多神经元松弛减少分支定界过程中的子问题数量，并使用基于GPU的双优化器高效解决剩余子问题",
        "关键词": [
            "神经网络验证",
            "多神经元松弛",
            "分支定界",
            "GPU优化",
            "完整性验证"
        ],
        "涉及的技术概念": {
            "多神经元松弛": "用于捕捉神经元间的复杂依赖关系，减少验证问题的复杂性",
            "分支定界（BaB）": "一种通过分割问题空间并逐步排除不可能解的区域来寻找最优解的方法",
            "GPU-based双优化器": "利用GPU并行计算能力高效解决优化问题，加速验证过程"
        },
        "success": true
    },
    {
        "order": 143,
        "title": "Compositional Attention: Disentangling Search and Retrieval",
        "html": "https://iclr.cc//virtual/2022/poster/6496",
        "abstract": "Multi-head, key-value attention is the backbone of transformer-like model architectures which have proven to be widely successful in recent years. This attention mechanism uses multiple parallel key-value attention blocks (called heads), each performing two fundamental computations: (1) search - selection of a relevant entity from a set via query-key interaction, and (2) retrieval - extraction of relevant features from the selected entity via a value matrix. Standard attention heads learn a rigid mapping between search and retrieval. In this work, we first highlight how this static nature of the pairing can potentially: (a) lead to learning of redundant parameters in certain tasks, and (b) hinder generalization. To alleviate this problem, we propose a novel attention mechanism,  called Compositional Attention, that replaces the standard head structure. The proposed mechanism  disentangles search and retrieval and composes them in a dynamic, flexible and context-dependent manner. Through a series of numerical experiments, we show that it outperforms standard multi-head attention on a variety of tasks, including some out-of-distribution settings. Through our qualitative analysis, we demonstrate that Compositional Attention leads to dynamic specialization based on the type of retrieval needed. Our proposed mechanism generalizes multi-head attention, allows independent scaling of search and retrieval and is easy to implement in a variety of established network architectures.",
        "conference": "ICLR",
        "中文标题": "组合注意力：解耦搜索与检索",
        "摘要翻译": "多头键值注意力是近年来被证明广泛成功的类Transformer模型架构的支柱。这种注意力机制使用多个并行的键值注意力块（称为头），每个头执行两个基本计算：（1）搜索 - 通过查询-键交互从一组中选择相关实体，（2）检索 - 通过值矩阵从所选实体中提取相关特征。标准注意力头学习搜索和检索之间的固定映射。在这项工作中，我们首先强调了这种配对的静态性质可能如何：（a）导致在某些任务中学习冗余参数，（b）阻碍泛化。为了缓解这个问题，我们提出了一种称为组合注意力的新型注意力机制，它取代了标准的头结构。所提出的机制解耦了搜索和检索，并以动态、灵活和上下文相关的方式组合它们。通过一系列数值实验，我们表明它在各种任务上优于标准多头注意力，包括一些分布外设置。通过我们的定性分析，我们证明了组合注意力根据所需的检索类型导致动态专业化。我们提出的机制泛化了多头注意力，允许独立扩展搜索和检索，并且易于在各种已建立的网络架构中实现。",
        "领域": "自然语言处理与视觉结合, 注意力机制研究, 深度学习模型优化",
        "问题": "标准多头注意力机制中搜索与检索的静态配对可能导致参数冗余和泛化能力受限",
        "动机": "提高注意力机制的灵活性和效率，减少冗余参数，增强模型在不同任务上的泛化能力",
        "方法": "提出组合注意力机制，动态解耦和组合搜索与检索过程，实现更灵活的注意力分配",
        "关键词": [
            "组合注意力",
            "多头注意力",
            "动态解耦",
            "模型泛化",
            "Transformer架构"
        ],
        "涉及的技术概念": {
            "多头键值注意力": "基础注意力机制，通过多个并行的键值注意力块处理信息",
            "组合注意力": "新型注意力机制，动态解耦搜索与检索过程，提高灵活性和效率",
            "动态专业化": "根据任务需求动态调整检索策略，优化模型性能"
        },
        "success": true
    },
    {
        "order": 144,
        "title": "Compositional Training for End-to-End Deep AUC Maximization",
        "html": "https://iclr.cc//virtual/2022/poster/6071",
        "abstract": "Recently, deep AUC maximization (DAM) has achieved great success in different domains (e.g., medical image classification). However, the end-to-end training for deep AUC maximization still remains a challenging problem. Previous studies employ an ad-hoc  two-stage approach that first trains the network by optimizing a traditional  loss (e.g., cross-entropy loss) and then finetunes the network by optimizing an AUC loss. This is because that training a deep neural network from scratch by maximizing an AUC loss usually does not yield a satisfactory performance. This phenomenon can be attributed to the degraded feature representations learned by maximizing the AUC loss from scratch. To address this issue, we propose a novel compositional training framework for end-to-end DAM, namely compositional DAM. The key idea of compositional training is to minimize a compositional objective function, where the outer function corresponds to an AUC loss and the inner function represents  a gradient descent step for minimizing a traditional loss, e.g., the cross-entropy (CE) loss. To optimize the non-standard compositional objective, we propose an efficient and provable stochastic optimization algorithm. The proposed algorithm enhances the capabilities  of  both robust feature learning and robust classifier learning  by alternatively taking a gradient descent step for the CE loss and for the AUC loss in a systematic way.  We conduct extensive empirical studies on imbalanced benchmark and medical image datasets, which unanimously verify the effectiveness of the proposed method.  Our results show that the compositional training approach dramatically improves both the feature representations and the testing AUC score compared with traditional deep learning approaches, and yields better performance than the two-stage approaches for DAM as well. The proposed method is implemented in our open-sourced library LibAUC (https://www.libauc.org) and code is available at https://github.com/Optimization-AI/LibAUC.",
        "conference": "ICLR",
        "中文标题": "端到端深度AUC最大化的组合训练",
        "摘要翻译": "近年来，深度AUC最大化（DAM）在不同领域（如医学图像分类）取得了巨大成功。然而，端到端的深度AUC最大化训练仍然是一个具有挑战性的问题。先前的研究采用了一种临时的两阶段方法，首先通过优化传统损失（如交叉熵损失）训练网络，然后通过优化AUC损失对网络进行微调。这是因为从零开始通过最大化AUC损失训练深度神经网络通常不会产生令人满意的性能。这种现象可以归因于通过从零开始最大化AUC损失学习到的退化特征表示。为了解决这个问题，我们提出了一种新颖的端到端DAM组合训练框架，即组合DAM。组合训练的关键思想是最小化一个组合目标函数，其中外部函数对应于AUC损失，内部函数代表用于最小化传统损失（如交叉熵（CE）损失）的梯度下降步骤。为了优化这个非标准的组合目标，我们提出了一种高效且可证明的随机优化算法。所提出的算法通过系统地交替采取CE损失和AUC损失的梯度下降步骤，增强了鲁棒特征学习和鲁棒分类器学习的能力。我们在不平衡的基准和医学图像数据集上进行了广泛的实证研究，这些研究一致验证了所提出方法的有效性。我们的结果表明，与传统深度学习方法相比，组合训练方法显著改善了特征表示和测试AUC分数，并且比DAM的两阶段方法表现更好。所提出的方法已在我们的开源库LibAUC（https://www.libauc.org）中实现，代码可在https://github.com/Optimization-AI/LibAUC获取。",
        "领域": "医学图像分类",
        "问题": "解决端到端深度AUC最大化训练中的性能不佳问题",
        "动机": "由于从零开始通过最大化AUC损失训练深度神经网络通常不会产生令人满意的性能，因此需要一种新的训练方法来改善特征表示和测试AUC分数",
        "方法": "提出了一种组合训练框架，通过最小化一个组合目标函数，其中外部函数对应于AUC损失，内部函数代表用于最小化传统损失的梯度下降步骤，并开发了一种高效的随机优化算法来优化这个组合目标",
        "关键词": [
            "深度AUC最大化",
            "组合训练",
            "医学图像分类",
            "随机优化算法",
            "特征表示"
        ],
        "涉及的技术概念": {
            "组合训练": "通过最小化一个组合目标函数来同时优化AUC损失和传统损失，以改善特征表示和分类性能",
            "随机优化算法": "用于高效优化非标准的组合目标函数，通过交替采取不同损失的梯度下降步骤来增强模型的学习能力",
            "AUC损失": "用于衡量模型在不同阈值下的分类性能，特别是在不平衡数据集上的表现"
        },
        "success": true
    },
    {
        "order": 145,
        "title": "CoMPS: Continual Meta Policy Search",
        "html": "https://iclr.cc//virtual/2022/poster/6693",
        "abstract": "We develop a new continual meta-learning method to address challenges in sequential multi-task learning. In this setting, the agent's goal is to achieve high reward over any sequence of tasks quickly. Prior meta-reinforcement learning algorithms have demonstrated promising results in accelerating the acquisition of new tasks. However, they require access to all tasks during training. Beyond simply transferring past experience to new tasks, our goal is to devise continual reinforcement learning algorithms that learn to learn, using their experience on previous tasks to learn new tasks more quickly. We introduce a new method, continual meta-policy search (CoMPS), that removes this limitation by meta-training in an incremental fashion, over each task in a sequence, without revisiting prior tasks. CoMPS continuously repeats two subroutines: learning a new task using RL and using the experience from RL to perform completely offline meta-learning to prepare for subsequent task learning. We find that CoMPS outperforms prior continual learning and off-policy meta-reinforcement methods on several sequences of challenging continuous control tasks.",
        "conference": "ICLR",
        "中文标题": "CoMPS: 持续元策略搜索",
        "摘要翻译": "我们开发了一种新的持续元学习方法，以解决顺序多任务学习中的挑战。在这种设置下，智能体的目标是快速在任何任务序列上实现高奖励。先前的元强化学习算法在加速新任务获取方面已经展示了有希望的结果。然而，这些算法在训练时需要访问所有任务。除了简单地将过去的经验转移到新任务外，我们的目标是设计持续强化学习算法，这些算法能够学习如何学习，利用它们在先前任务上的经验来更快地学习新任务。我们引入了一种新方法，持续元策略搜索（CoMPS），通过以增量方式进行元训练，在任务序列中的每个任务上进行，而不需要重新访问先前的任务，从而消除了这一限制。CoMPS持续重复两个子程序：使用强化学习学习新任务，以及使用来自强化学习的经验进行完全离线的元学习，为后续任务学习做准备。我们发现，在几个具有挑战性的连续控制任务序列上，CoMPS优于先前的持续学习和离策略元强化方法。",
        "领域": "元学习、强化学习、连续控制",
        "问题": "解决在顺序多任务学习中，智能体如何快速适应新任务的问题",
        "动机": "设计能够利用先前任务经验来加速新任务学习的持续强化学习算法",
        "方法": "引入持续元策略搜索（CoMPS）方法，通过增量式元训练和离线元学习来准备后续任务学习",
        "关键词": [
            "持续元学习",
            "强化学习",
            "多任务学习",
            "连续控制",
            "元策略搜索"
        ],
        "涉及的技术概念": {
            "持续元学习": "在顺序任务中持续学习，利用先前任务的经验加速新任务的学习",
            "强化学习": "用于学习新任务的方法，通过与环境的交互来优化策略",
            "元策略搜索": "一种元学习方法，专注于搜索和优化策略以适应新任务"
        },
        "success": true
    },
    {
        "order": 146,
        "title": "Concurrent Adversarial Learning for Large-Batch Training",
        "html": "https://iclr.cc//virtual/2022/poster/6365",
        "abstract": "Large-batch training has become a commonly used technique when training neural networks with a large number of GPU/TPU processors. As batch size increases, stochastic optimizers tend to converge to sharp local minima, leading to degraded test performance. Current methods usually use extensive data augmentation to increase the batch size, but we found the performance gain with data augmentation decreases as batch size increases, and data augmentation will become insufficient after certain point. In this paper, we propose to use adversarial learning to increase the batch size in large-batch training. Despite being a natural choice for smoothing the decision surface and biasing towards a flat region, adversarial learning has not been successfully applied in large-batch training since it requires at least two sequential gradient computations at each step, which will at least double the running time compared with vanilla training even with a large number of processors. To overcome this issue, we propose a novel Concurrent Adversarial Learning (ConAdv) method that decouple the sequential gradient computations in adversarial learning by utilizing staled parameters. Experimental results demonstrate that ConAdv can successfully  increase the batch size on both ResNet-50 and EfficientNet training on ImageNet while maintaining high accuracy. In particular, we show ConAdv along can achieve 75.3\\% top-1 accuracy on ImageNet ResNet-50 training with 96K batch size, and the accuracy can be further improved to 76.2\\% when combining ConAdv with data augmentation. This is the first work successfully scales ResNet-50 training batch size to 96K. ",
        "conference": "ICLR",
        "中文标题": "并发对抗学习用于大批量训练",
        "摘要翻译": "大批量训练已成为在使用大量GPU/TPU处理器训练神经网络时常用的技术。随着批量大小的增加，随机优化器倾向于收敛到尖锐的局部最小值，导致测试性能下降。当前方法通常使用广泛的数据增强来增加批量大小，但我们发现随着批量大小的增加，数据增强带来的性能增益会减少，并且在某一点之后数据增强将变得不足。在本文中，我们提出使用对抗学习来增加大批量训练中的批量大小。尽管对抗学习是平滑决策表面并偏向平坦区域的自然选择，但由于它需要在每一步至少进行两次顺序梯度计算，即使有大量处理器，与普通训练相比，运行时间至少会翻倍，因此对抗学习尚未成功应用于大批量训练。为了克服这个问题，我们提出了一种新颖的并发对抗学习（ConAdv）方法，该方法通过利用过时参数解耦对抗学习中的顺序梯度计算。实验结果表明，ConAdv可以成功地在ImageNet上的ResNet-50和EfficientNet训练中增加批量大小，同时保持高准确率。特别是，我们展示了仅使用ConAdv就可以在96K批量大小的ImageNet ResNet-50训练中达到75.3%的top-1准确率，并且当ConAdv与数据增强结合使用时，准确率可以进一步提高到76.2%。这是首次成功将ResNet-50训练的批量大小扩展到96K的工作。",
        "领域": "深度学习优化、对抗学习、大规模神经网络训练",
        "问题": "大批量训练中随机优化器收敛到尖锐局部最小值导致测试性能下降的问题",
        "动机": "探索在大批量训练中有效使用对抗学习以提高模型性能的方法",
        "方法": "提出并发对抗学习（ConAdv）方法，通过利用过时参数解耦对抗学习中的顺序梯度计算，以减少运行时间",
        "关键词": [
            "大批量训练",
            "对抗学习",
            "并发优化",
            "深度学习优化",
            "ImageNet训练"
        ],
        "涉及的技术概念": {
            "对抗学习": "用于平滑决策表面并偏向平坦区域，以提高模型在大批量训练中的性能",
            "顺序梯度计算": "传统对抗学习方法中需要至少两次顺序梯度计算，增加了运行时间",
            "过时参数": "在ConAdv方法中用于解耦顺序梯度计算，以减少对抗学习的运行时间"
        },
        "success": true
    },
    {
        "order": 147,
        "title": "Conditional Contrastive Learning with Kernel",
        "html": "https://iclr.cc//virtual/2022/poster/6076",
        "abstract": "Conditional contrastive learning frameworks consider the conditional sampling procedure that constructs positive or negative data pairs conditioned on specific variables. Fair contrastive learning constructs negative pairs, for example, from the same gender (conditioning on sensitive information), which in turn reduces undesirable information from the learned representations; weakly supervised contrastive learning constructs positive pairs with similar annotative attributes (conditioning on auxiliary information), which in turn are incorporated into the representations. Although conditional contrastive learning enables many applications, the conditional sampling procedure can be challenging if we cannot obtain sufficient data pairs for some values of the conditioning variable. This paper presents Conditional Contrastive Learning with Kernel (CCL-K) that converts existing conditional contrastive objectives into alternative forms that mitigate the insufficient data problem. Instead of sampling data according to the value of the conditioning variable, CCL-K uses the Kernel Conditional Embedding Operator that samples data from all available data and assigns weights to each sampled data given the kernel similarity between the values of the conditioning variable. We conduct experiments using weakly supervised, fair, and hard negatives contrastive learning, showing CCL-K outperforms state-of-the-art baselines.",
        "conference": "ICLR",
        "中文标题": "基于核的条件对比学习",
        "摘要翻译": "条件对比学习框架考虑了基于特定变量构建正或负数据对的条件采样过程。公平对比学习例如从同一性别（基于敏感信息）构建负对，从而减少学习表示中的不良信息；弱监督对比学习构建具有相似注释属性（基于辅助信息）的正对，这些属性随后被纳入表示中。尽管条件对比学习支持许多应用，但如果对于条件变量的某些值无法获得足够的数据对，条件采样过程可能会具有挑战性。本文提出了基于核的条件对比学习（CCL-K），它将现有的条件对比目标转换为缓解数据不足问题的替代形式。CCL-K不是根据条件变量的值采样数据，而是使用核条件嵌入算子，该算子从所有可用数据中采样数据，并根据条件变量值之间的核相似性为每个采样数据分配权重。我们使用弱监督、公平和硬负对比学习进行实验，显示CCL-K优于最先进的基线。",
        "领域": "弱监督学习, 公平机器学习, 对比学习",
        "问题": "解决在条件对比学习中，由于条件变量的某些值数据不足导致的采样挑战",
        "动机": "为了在条件对比学习中更有效地利用有限的数据，提高模型在各种条件下的学习效率和表现",
        "方法": "提出基于核的条件对比学习（CCL-K），通过核条件嵌入算子从所有可用数据中采样并加权，以缓解数据不足问题",
        "关键词": [
            "条件对比学习",
            "核方法",
            "弱监督学习",
            "公平机器学习",
            "数据采样"
        ],
        "涉及的技术概念": {
            "条件对比学习": "一种考虑特定变量构建数据对的对比学习方法，旨在学习更有效的表示",
            "核条件嵌入算子": "用于从所有可用数据中采样并根据条件变量值之间的核相似性分配权重的技术，以解决数据不足问题",
            "弱监督对比学习": "利用相似注释属性构建正对的对比学习方法，旨在将辅助信息纳入学习表示中"
        },
        "success": true
    },
    {
        "order": 148,
        "title": "Conditional Image Generation by Conditioning Variational Auto-Encoders",
        "html": "https://iclr.cc//virtual/2022/poster/6145",
        "abstract": "We present a conditional variational auto-encoder (VAE) which, to avoid the substantial cost of training from scratch, uses an architecture and training objective capable of leveraging a foundation model in the form of a pretrained unconditional VAE. To train the conditional VAE, we only need to train an artifact to perform amortized inference over the unconditional VAE's latent variables given a conditioning input. We demonstrate our approach on tasks including image inpainting, for which it outperforms state-of-the-art GAN-based approaches at faithfully representing the inherent uncertainty. We conclude by describing a possible application of our inpainting model, in which it is used to perform Bayesian experimental design for the purpose of guiding a sensor.",
        "conference": "ICLR",
        "中文标题": "条件变分自编码器的条件图像生成",
        "摘要翻译": "我们提出了一种条件变分自编码器（VAE），为了避免从头训练的高成本，该模型采用了一种能够利用预训练无条件VAE作为基础模型的架构和训练目标。为了训练条件VAE，我们只需要训练一个工具，以给定的条件输入对无条件VAE的潜在变量进行摊销推断。我们在包括图像修复在内的任务上展示了我们的方法，在这些任务中，它在忠实表示内在不确定性方面优于基于GAN的最先进方法。最后，我们描述了我们的修复模型的一个可能应用，即用于执行贝叶斯实验设计以指导传感器。",
        "领域": "图像生成、图像修复、深度学习模型优化",
        "问题": "如何高效利用预训练的无条件VAE进行条件图像生成，避免从头训练的高成本",
        "动机": "减少条件图像生成模型的训练成本，同时保持或提高生成图像的质量和多样性",
        "方法": "利用预训练的无条件VAE作为基础模型，通过训练一个摊销推断工具来实现条件图像生成",
        "关键词": [
            "条件变分自编码器",
            "图像修复",
            "贝叶斯实验设计",
            "摊销推断",
            "预训练模型"
        ],
        "涉及的技术概念": {
            "条件变分自编码器": "在变分自编码器的基础上引入条件输入，实现条件图像生成",
            "摊销推断": "通过训练一个网络来近似潜在变量的后验分布，减少推断过程中的计算成本",
            "贝叶斯实验设计": "利用贝叶斯方法优化实验设计，这里用于指导传感器的数据采集策略"
        },
        "success": true
    },
    {
        "order": 149,
        "title": "Conditional Object-Centric Learning from Video",
        "html": "https://iclr.cc//virtual/2022/poster/7059",
        "abstract": "Object-centric representations are a promising path toward more systematic generalization by providing flexible abstractions upon which compositional world models can be built. Recent work on simple 2D and 3D datasets has shown that models with object-centric inductive biases can learn to segment and represent meaningful objects from the statistical structure of the data alone without the need for any supervision. However, such fully-unsupervised methods still fail to scale to diverse realistic data, despite the use of increasingly complex inductive biases such as priors for the size of objects or the 3D geometry of the scene. In this paper, we instead take a weakly-supervised approach and focus on how 1) using the temporal dynamics of video data in the form of optical flow and 2) conditioning the model on simple object location cues can be used to enable segmenting and tracking objects in significantly more realistic synthetic data. We introduce a sequential extension to Slot Attention which we train to predict optical flow for realistic looking synthetic scenes and show that conditioning the initial state of this model on a small set of hints, such as center of mass of objects in the first frame, is sufficient to significantly improve instance segmentation. These benefits generalize beyond the training distribution to novel objects, novel backgrounds, and to longer video sequences. We also find that such initial-state-conditioning can be used during inference as a flexible interface to query the model for specific objects or parts of objects, which could pave the way for a range of weakly-supervised approaches and allow more effective interaction with trained models.",
        "conference": "ICLR",
        "中文标题": "基于视频的条件性物体中心学习",
        "摘要翻译": "物体中心表示通过提供灵活的抽象，为构建组合世界模型铺平了道路，是实现更系统泛化的有希望路径。最近在简单2D和3D数据集上的研究表明，具有物体中心归纳偏置的模型能够仅从数据的统计结构中学习分割和表示有意义的物体，无需任何监督。然而，尽管使用了越来越复杂的归纳偏置，如物体大小的先验或场景的3D几何，这种完全无监督的方法仍然难以扩展到多样化的现实数据。在本文中，我们采取了一种弱监督的方法，重点关注如何1)利用视频数据的时间动态性，以光流的形式，和2)对模型进行简单物体位置线索的条件化，以实现在更真实的合成数据中分割和跟踪物体。我们引入了对Slot Attention的顺序扩展，训练其预测真实感合成场景的光流，并展示了将模型的初始状态条件化为一小组提示（如第一帧中物体的质心）足以显著改善实例分割。这些好处泛化到了训练分布之外，包括新物体、新背景和更长的视频序列。我们还发现，这种初始状态条件化可以在推理过程中用作灵活的接口，查询模型特定的物体或物体部分，这可能为一系列弱监督方法铺平道路，并允许与训练模型进行更有效的交互。",
        "领域": "实例分割、视频理解、弱监督学习",
        "问题": "如何在更真实的合成数据中实现物体的分割和跟踪",
        "动机": "解决完全无监督方法在多样化现实数据上难以扩展的问题",
        "方法": "采用弱监督方法，结合光流和物体位置线索条件化模型",
        "关键词": [
            "物体中心学习",
            "弱监督学习",
            "光流",
            "实例分割",
            "Slot Attention"
        ],
        "涉及的技术概念": {
            "物体中心表示": "提供灵活的抽象，用于构建组合世界模型",
            "Slot Attention": "一种顺序扩展方法，用于预测光流和改善实例分割",
            "弱监督学习": "利用有限的监督信息（如物体位置线索）来训练模型"
        },
        "success": true
    },
    {
        "order": 150,
        "title": "Conditioning Sequence-to-sequence Networks with Learned Activations",
        "html": "https://iclr.cc//virtual/2022/poster/5916",
        "abstract": "Conditional neural networks play an important role in a number of sequence-to-sequence modeling tasks, including personalized sound enhancement (PSE), speaker dependent automatic speech recognition (ASR), and generative modeling such as text-to-speech synthesis. In conditional neural networks, the output of a model is often influenced by a conditioning vector, in addition to the input. Common approaches of conditioning include input concatenation or modulation with the conditioning vector, which comes at a cost of increased model size. In this work, we introduce a novel approach of neural network conditioning by learning intermediate layer activations based on the conditioning vector. We systematically explore and show that learned activation functions can produce conditional models with comparable or better quality, while decreasing model sizes, thus making them ideal candidates for resource-efficient on-device deployment. As exemplary target use-cases we consider (i) the task of PSE as a pre-processing technique for improving telephony or pre-trained ASR performance under noise, and (ii) personalized ASR in single speaker scenarios. We find that conditioning via activation function learning is an effective modeling strategy, suggesting a broad applicability of the proposed technique across a number of application domains.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "使用学习到的激活函数条件化序列到序列网络",
        "摘要翻译": "条件神经网络在多个序列到序列建模任务中扮演着重要角色，包括个性化声音增强（PSE）、说话者依赖的自动语音识别（ASR）以及生成建模如文本到语音合成。在条件神经网络中，模型的输出除了输入外，还经常受到一个条件向量的影响。常见的条件化方法包括输入连接或与条件向量的调制，这会增加模型的大小。在这项工作中，我们介绍了一种新颖的神经网络条件化方法，即基于条件向量学习中间层激活函数。我们系统地探索并表明，学习到的激活函数可以产生质量相当或更好的条件模型，同时减少模型大小，因此它们是资源高效设备上部署的理想候选。作为示例性目标用例，我们考虑了（i）PSE作为提高电话或预训练ASR在噪声下性能的预处理技术，以及（ii）单说话者场景中的个性化ASR。我们发现，通过激活函数学习进行条件化是一种有效的建模策略，表明所提出的技术在多个应用领域具有广泛的适用性。",
        "领域": "个性化声音增强,自动语音识别,文本到语音合成",
        "问题": "如何在减少模型大小的同时，保持或提高条件神经网络在序列到序列建模任务中的性能",
        "动机": "探索一种新的神经网络条件化方法，以减少模型大小并保持或提高性能，适用于资源有限的设备部署",
        "方法": "基于条件向量学习中间层激活函数，以产生质量相当或更好的条件模型，同时减少模型大小",
        "关键词": [
            "条件神经网络",
            "激活函数学习",
            "序列到序列建模",
            "个性化声音增强",
            "自动语音识别"
        ],
        "涉及的技术概念": {
            "条件神经网络": "在模型中引入条件向量以影响输出，用于处理如个性化声音增强等任务",
            "激活函数学习": "通过学习中间层激活函数来实现条件化，减少模型大小同时保持或提高性能",
            "序列到序列建模": "处理输入序列到输出序列的转换任务，如自动语音识别和文本到语音合成"
        }
    },
    {
        "order": 151,
        "title": "ConFeSS: A Framework for Single Source Cross-Domain Few-Shot Learning",
        "html": "https://iclr.cc//virtual/2022/poster/5975",
        "abstract": "Most current few-shot learning methods train a model from abundantly labeled base category data and then transfer and adapt the model to sparsely labeled novel category data. These methods mostly generalize well on novel categories from the same domain as the base categories but perform poorly for distant domain categories. In this paper, we propose a framework for few-shot learning coined as ConFeSS (Contrastive Learning and Feature Selection System) that tackles large domain shift between base and novel categories. The first step of our framework trains a feature extracting backbone with the contrastive loss on the base category data. Since the contrastive loss does not use supervision, the features can generalize better to distant target domains. For the second step, we train a masking module to select relevant features that are more suited to target domain classification. Finally, a classifier is fine-tuned along with the backbone such that the backbone produces features similar to the relevant ones. To evaluate our framework, we tested it on a recently introduced cross-domain few-shot learning benchmark. Experimental results demonstrate that our framework outperforms all meta-learning approaches and produces competitive results against recent cross-domain methods. Additional analyses are also performed to better understand our framework.",
        "conference": "ICLR",
        "中文标题": "ConFeSS：一种单源跨域少样本学习框架",
        "摘要翻译": "当前大多数少样本学习方法通过大量标记的基础类别数据训练模型，然后将模型迁移并适应于标记稀疏的新类别数据。这些方法在基础类别同一域的新类别上通常表现良好，但在远域类别上表现不佳。本文提出了一种名为ConFeSS（对比学习与特征选择系统）的少样本学习框架，旨在解决基础类别与新类别之间的大域偏移问题。我们框架的第一步使用对比损失在基础类别数据上训练特征提取主干。由于对比损失不使用监督，特征能够更好地泛化到远域目标。第二步，我们训练一个掩码模块来选择更适合目标域分类的相关特征。最后，分类器与主干网络一起进行微调，使得主干网络生成的特征与相关特征相似。为了评估我们的框架，我们在最近引入的跨域少样本学习基准上进行了测试。实验结果表明，我们的框架在所有元学习方法中表现最优，并与最近的跨域方法相比具有竞争力。此外，我们还进行了额外的分析以更好地理解我们的框架。",
        "领域": "少样本学习",
        "问题": "解决基础类别与新类别之间的大域偏移问题",
        "动机": "提高模型在远域类别上的泛化能力",
        "方法": "使用对比学习训练特征提取主干，训练掩码模块选择相关特征，最后微调分类器与主干网络",
        "关键词": [
            "少样本学习",
            "跨域学习",
            "对比学习",
            "特征选择",
            "域适应"
        ],
        "涉及的技术概念": {
            "对比学习": "在基础类别数据上使用对比损失训练特征提取主干，以提高特征的泛化能力",
            "特征选择": "通过训练掩码模块选择更适合目标域分类的相关特征",
            "域适应": "通过微调分类器与主干网络，使得生成的特征与目标域的相关特征相似，以适应远域类别"
        },
        "success": true
    },
    {
        "order": 152,
        "title": "Connectome-constrained Latent Variable Model of Whole-Brain Neural Activity",
        "html": "https://iclr.cc//virtual/2022/poster/6591",
        "abstract": "The availability of both anatomical connectivity and brain-wide neural activity measurements in C. elegans make the worm a promising system for learning detailed, mechanistic models of an entire nervous system in a data-driven way. However, one faces several challenges when constructing such a model. We often do not have direct experimental access to important modeling details such as single-neuron dynamics and the signs and strengths of the synaptic connectivity. Further, neural activity can only be measured in a subset of neurons, often indirectly via calcium imaging, and significant trial-to-trial variability has been observed. To address these challenges, we introduce a connectome-constrained latent variable model (CC-LVM) of the unobserved voltage dynamics of the entire C. elegans nervous system and the observed calcium signals. We used the framework of variational autoencoders to fit parameters of the mechanistic simulation constituting the generative model of the LVM to calcium imaging observations. A variational approximate posterior distribution over latent voltage traces for all neurons is efficiently inferred using an inference network, and constrained by a prior distribution given by the biophysical simulation of neural dynamics. We applied this model to an experimental whole-brain dataset, and found that connectomic constraints enable our LVM to predict the activity of neurons whose activity were withheld significantly better than models unconstrained by a connectome. We explored models with different degrees of biophysical detail, and found that models with realistic conductance-based synapses provide markedly better predictions than current-based synapses for this system.",
        "conference": "ICLR",
        "中文标题": "连接组约束的全脑神经活动潜变量模型",
        "摘要翻译": "在秀丽隐杆线虫中，解剖连接性和全脑神经活动测量的可用性使得这一系统成为以数据驱动方式学习整个神经系统详细机制模型的有希望的系统。然而，在构建这样的模型时，我们面临着几个挑战。我们通常无法直接实验获取重要的建模细节，如单神经元动态以及突触连接的正负和强度。此外，神经活动只能在一部分神经元中测量，通常是通过钙成像间接测量的，并且已经观察到了显著的试验间变异性。为了应对这些挑战，我们引入了一个连接组约束的潜变量模型（CC-LVM），用于模拟整个秀丽隐杆线虫神经系统中未观察到的电压动态和观察到的钙信号。我们使用变分自编码器的框架来拟合构成LVM生成模型的机制模拟参数到钙成像观察。一个变分近似后验分布对所有神经元的潜在电压轨迹进行了高效推断，并通过由神经动态的生物物理模拟给出的先验分布进行约束。我们将此模型应用于一个实验性全脑数据集，发现连接组约束使我们的LVM能够预测那些活动被保留的神经元的活动，显著优于不受连接组约束的模型。我们探索了具有不同生物物理细节程度的模型，发现对于这一系统，具有现实电导基础的突触模型比电流基础的突触模型提供了明显更好的预测。",
        "领域": "神经科学计算模型、全脑神经活动分析、生物物理模拟",
        "问题": "构建一个能够准确模拟全脑神经活动的机制模型，面临实验数据不完整和神经元活动变异性大的挑战。",
        "动机": "利用秀丽隐杆线虫的解剖连接性和神经活动数据，开发一个数据驱动的全脑神经活动模型，以克服直接实验获取建模细节的限制。",
        "方法": "引入连接组约束的潜变量模型（CC-LVM），结合变分自编码器框架和生物物理模拟，对全脑神经活动进行建模和预测。",
        "关键词": [
            "连接组约束",
            "潜变量模型",
            "全脑神经活动",
            "变分自编码器",
            "生物物理模拟"
        ],
        "涉及的技术概念": {
            "连接组约束的潜变量模型（CC-LVM）": "用于模拟全脑神经活动中未观察到的电压动态和观察到的钙信号的模型，通过连接组数据约束提高预测准确性。",
            "变分自编码器": "用于拟合机制模拟参数到钙成像观察的框架，高效推断潜在电压轨迹的变分近似后验分布。",
            "生物物理模拟": "提供先验分布，约束潜变量模型的推断过程，模拟神经动态的生物物理细节。"
        },
        "success": true
    },
    {
        "order": 153,
        "title": "Consistent Counterfactuals for Deep Models",
        "html": "https://iclr.cc//virtual/2022/poster/6992",
        "abstract": "Counterfactual examples are one of the most commonly-cited methods for explaining the predictions of machine learning models in key areas such as finance and medical diagnosis. Counterfactuals are often discussed under the assumption that the model on which they will be used is static, but in deployment models may be periodically retrained or fine-tuned. This paper studies the consistency of model prediction on counterfactual examples in deep networks under small changes to initial training conditions, such as weight initialization and leave-one-out variations in data, as often occurs during model deployment. We demonstrate experimentally that counterfactual examples for deep models are often inconsistent across such small changes, and that increasing the cost of the counterfactual, a stability-enhancing mitigation suggested by prior work in the context of simpler models, is not a reliable heuristic in deep networks. Rather, our analysis shows that a model's Lipschitz continuity around the counterfactual, along with confidence of its prediction, is key to its consistency across related models. To this end, we propose Stable Neighbor Search as a way to generate more consistent counterfactual explanations, and illustrate the effectiveness of this approach on several benchmark datasets.",
        "conference": "ICLR",
        "中文标题": "深度模型的一致性反事实解释",
        "摘要翻译": "反事实示例是解释机器学习模型在金融和医疗诊断等关键领域预测的最常用方法之一。反事实通常是在假设模型静态的情况下讨论的，但在实际部署中，模型可能会定期重新训练或微调。本文研究了在初始训练条件（如权重初始化和数据中的留一法变化）发生微小变化时，深度网络中对反事实示例的模型预测一致性，这种情况在模型部署过程中经常发生。我们通过实验证明，深度模型的反事实示例在此类微小变化下往往不一致，并且增加反事实的成本（先前在更简单模型背景下提出的稳定性增强缓解措施）在深度网络中并不是一个可靠的启发式方法。相反，我们的分析表明，模型在反事实周围的Lipschitz连续性及其预测的置信度是其在相关模型中保持一致性的关键。为此，我们提出了稳定邻居搜索作为生成更一致反事实解释的方法，并在几个基准数据集上说明了这种方法的有效性。",
        "领域": "可解释性人工智能、深度学习、模型稳定性分析",
        "问题": "深度模型在微小初始条件变化下对反事实示例的预测不一致性问题",
        "动机": "研究旨在解决深度模型在部署过程中因微小变化导致的反事实解释不一致问题，以提高模型解释的可靠性。",
        "方法": "通过分析模型的Lipschitz连续性和预测置信度，提出稳定邻居搜索方法来生成更一致的反事实解释。",
        "关键词": [
            "反事实解释",
            "模型稳定性",
            "Lipschitz连续性",
            "深度网络",
            "可解释性"
        ],
        "涉及的技术概念": {
            "反事实示例": "用于解释模型预测的假设性示例，展示如何改变输入特征以改变模型决策。",
            "Lipschitz连续性": "衡量模型输出对输入变化敏感度的数学概念，用于评估模型在反事实周围的稳定性。",
            "稳定邻居搜索": "一种新提出的方法，旨在通过考虑模型的局部稳定性来生成更一致的反事实解释。"
        },
        "success": true
    },
    {
        "order": 154,
        "title": "Constrained Physical-Statistics Models for Dynamical System Identification and Prediction",
        "html": "https://iclr.cc//virtual/2022/poster/6791",
        "abstract": "Modeling dynamical systems combining prior physical knowledge and machine learning (ML) is promising in scientific problems when the underlying processes are not fully understood, e.g. when the dynamics is partially known. A common practice to identify the respective parameters of the physical and ML components is to formulate the problem as supervised learning on observed trajectories. However, this formulation leads to an infinite number of possible decompositions. To solve this ill-posedness, we reformulate the learning problem by introducing an upper bound on the prediction error of a physical-statistical model. This allows us to control the contribution of both the physical and statistical components to the overall prediction. This framework generalizes several existing hybrid schemes proposed in the literature. We provide theoretical guarantees on the well-posedness of our formulation along with a proof of convergence in a simple affine setting. For more complex dynamics, we validate our framework experimentally.",
        "conference": "ICLR",
        "中文标题": "动态系统识别与预测的约束物理统计模型",
        "摘要翻译": "结合先验物理知识和机器学习（ML）对动态系统进行建模，在科学问题中显示出巨大潜力，尤其是当底层过程未被完全理解时，例如动态部分已知的情况。识别物理和机器学习组件各自参数的常见做法是将问题表述为对观察到的轨迹进行监督学习。然而，这种表述导致了无限可能的分解。为了解决这种不适定性，我们通过引入物理统计模型预测误差的上限来重新表述学习问题。这使我们能够控制物理和统计组件对整体预测的贡献。该框架概括了文献中提出的几种现有混合方案。我们提供了关于我们表述的适定性的理论保证，并在简单的仿射设置中提供了收敛性证明。对于更复杂的动态，我们通过实验验证了我们的框架。",
        "领域": "动态系统建模、机器学习与物理结合、预测模型",
        "问题": "解决动态系统建模中物理和机器学习组件参数识别的不适定性问题",
        "动机": "在动态系统部分已知的情况下，结合物理知识和机器学习进行建模，以提高预测的准确性和解释性",
        "方法": "通过引入物理统计模型预测误差的上限，重新表述学习问题，控制物理和统计组件的贡献",
        "关键词": [
            "动态系统建模",
            "物理统计模型",
            "机器学习",
            "预测误差上限",
            "参数识别"
        ],
        "涉及的技术概念": {
            "物理统计模型": "结合物理知识和统计方法构建的模型，用于动态系统的识别和预测",
            "预测误差上限": "用于控制物理和统计组件对预测贡献的技术，确保模型的适定性",
            "监督学习": "用于识别物理和机器学习组件参数的方法，基于观察到的轨迹进行学习"
        },
        "success": true
    },
    {
        "order": 155,
        "title": "Constrained Policy Optimization via Bayesian World Models",
        "html": "https://iclr.cc//virtual/2022/poster/6499",
        "abstract": "Improving sample-efficiency and safety are crucial challenges when deploying reinforcement learning in high-stakes real world applications. We propose LAMBDA, a novel model-based approach for policy optimization in safety critical tasks modeled via constrained Markov decision processes. Our approach utilizes Bayesian world models, and harnesses the resulting uncertainty to maximize optimistic upper bounds on the task objective, as well as pessimistic upper bounds on the safety constraints. We demonstrate LAMBDA's state of the art performance on the Safety-Gym benchmark suite in terms of sample efficiency and constraint violation.",
        "conference": "ICLR",
        "中文标题": "通过贝叶斯世界模型实现约束策略优化",
        "摘要翻译": "在将强化学习应用于高风险现实世界应用时，提高样本效率和安全性是至关重要的挑战。我们提出了LAMBDA，一种新颖的基于模型的方法，用于在通过约束马尔可夫决策过程建模的安全关键任务中进行策略优化。我们的方法利用贝叶斯世界模型，并利用由此产生的不确定性来最大化任务目标的乐观上界，以及安全约束的悲观上界。我们在Safety-Gym基准测试套件上展示了LAMBDA在样本效率和约束违反方面的最先进性能。",
        "领域": "强化学习、安全关键系统、模型优化",
        "问题": "在安全关键任务中提高强化学习的样本效率和安全性",
        "动机": "为了在现实世界的高风险应用中安全有效地部署强化学习，需要一种能够同时优化任务目标和遵守安全约束的方法。",
        "方法": "提出了一种基于贝叶斯世界模型的新方法LAMBDA，通过利用模型不确定性来优化任务目标的上界和安全约束的下界。",
        "关键词": [
            "强化学习",
            "贝叶斯世界模型",
            "安全关键任务",
            "约束优化",
            "样本效率"
        ],
        "涉及的技术概念": {
            "贝叶斯世界模型": "用于建模环境动态，提供对不确定性的量化，帮助在策略优化中考虑安全约束。",
            "约束马尔可夫决策过程": "用于建模安全关键任务，明确将安全约束纳入决策过程。",
            "乐观上界与悲观上界": "分别用于最大化任务目标和最小化安全约束违反的策略优化技术。"
        },
        "success": true
    },
    {
        "order": 156,
        "title": "Constraining Linear-chain CRFs to Regular Languages",
        "html": "https://iclr.cc//virtual/2022/poster/6325",
        "abstract": "A major challenge in structured prediction is to represent the interdependencies within output structures.  When outputs are structured as sequences, linear-chain conditional random fields (CRFs) are a widely used model class which can learn local dependencies in the output. However, the CRF's Markov assumption makes it impossible for CRFs to represent distributions with nonlocal dependencies, and standard CRFs are unable to respect nonlocal constraints of the data (such as global arity constraints on output labels).  We present a generalization of CRFs that can enforce a broad class of constraints, including nonlocal ones, by specifying the space of possible output structures as a regular language $\\mathcal{L}$.  The resulting regular-constrained CRF (RegCCRF) has the same formal properties as a standard CRF, but assigns zero probability to all label sequences not in $\\mathcal{L}$.  Notably, RegCCRFs can incorporate their constraints during training, while related models only enforce constraints during decoding.  We prove that constrained training is never worse than constrained decoding, and show empirically that it can be substantially better in practice.  Additionally, we demonstrate a practical benefit on downstream tasks by incorporating a RegCCRF into a deep neural model for semantic role labeling, exceeding state-of-the-art results on a standard dataset.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "使用正则语言约束线性链条件随机场",
        "摘要翻译": "结构化预测中的一个主要挑战是表示输出结构中的相互依赖关系。当输出被构造为序列时，线性链条件随机场（CRF）是一种广泛使用的模型类别，可以学习输出中的局部依赖关系。然而，CRF的马尔可夫假设使得CRF无法表示具有非局部依赖关系的分布，并且标准CRF无法遵守数据的非局部约束（例如输出标签上的全局元数约束）。我们提出了一种CRF的泛化，可以通过将可能的输出结构空间指定为正则语言L来强制执行广泛的约束，包括非局部约束。由此产生的正则约束CRF（RegCCRF）具有与标准CRF相同的形式属性，但将所有不在L中的标签序列的概率分配为零。值得注意的是，RegCCRF可以在训练期间合并其约束，而相关模型仅在解码期间强制执行约束。我们证明了约束训练永远不会比约束解码更差，并且在实践中可以明显更好。此外，我们通过将RegCCRF合并到用于语义角色标记的深度神经模型中，证明了在下游任务中的实际益处，从而在标准数据集上超过了最先进的结果。",
        "领域": "序列标注, 自然语言处理, 结构化预测",
        "问题": "传统的线性链条件随机场(CRF)由于其马尔可夫假设，无法有效处理输出序列中存在的非局部依赖和全局约束问题。",
        "动机": "研究的目的是扩展CRF的能力，使其能够处理输出序列中的非局部依赖关系和全局约束，从而提高序列标注等任务的性能。",
        "方法": "提出了一种新的正则约束条件随机场(RegCCRF)，通过将可能的输出结构空间定义为正则语言，从而在训练过程中强制执行包括非局部约束在内的多种约束。",
        "关键词": [
            "条件随机场",
            "正则语言",
            "结构化预测",
            "序列标注",
            "非局部约束"
        ],
        "涉及的技术概念": {
            "条件随机场（CRF）": "一种概率图模型，用于对序列数据进行建模，并预测序列中每个元素的标签。",
            "正则语言": "一种形式语言，用于定义可以接受的输出序列的集合，从而可以对CRF的输出进行约束。"
        }
    },
    {
        "order": 157,
        "title": "Constructing a Good Behavior Basis for Transfer using Generalized Policy Updates",
        "html": "https://iclr.cc//virtual/2022/poster/6493",
        "abstract": "We study the problem of learning a good set of policies, so that when combined together, they can solve a wide variety of unseen reinforcement learning tasks with no or very little new data. Specifically, we consider the framework of generalized policy evaluation and improvement, in which the rewards for all tasks of interest are assumed to be expressible as a linear combination of a fixed set of features. We show theoretically that, under certain assumptions, having access to a specific set of diverse policies, which we call a set of independent policies, can allow for instantaneously achieving high-level performance on all possible downstream tasks which are typically more complex than the ones on which the agent was trained. Based on this theoretical analysis, we propose a simple algorithm that iteratively constructs this set of policies. In addition to empirically validating our theoretical results, we compare our approach with recently proposed diverse policy set construction methods and show that, while others fail, our approach is able to build a behavior basis that enables instantaneous transfer to all possible downstream tasks. We also show empirically that having access to a set of independent policies can better bootstrap the learning process on downstream tasks where the new reward function cannot be described as a linear combination of the features. Finally, we demonstrate how this policy set can be useful in a lifelong reinforcement learning setting.",
        "conference": "ICLR",
        "中文标题": "利用广义策略更新构建迁移学习中的良好行为基础",
        "摘要翻译": "我们研究了学习一组良好策略的问题，这些策略在组合使用时，能够解决各种未见过的强化学习任务，而无需或仅需极少量的新数据。具体而言，我们考虑了广义策略评估和改进的框架，其中所有感兴趣任务的奖励被假定为可以表示为固定特征集的线性组合。我们从理论上证明，在某些假设下，拥有一组特定的多样化策略（我们称之为独立策略集）可以即时在所有可能的下游任务上实现高性能，这些任务通常比代理训练的任务更为复杂。基于这一理论分析，我们提出了一种简单的算法，迭代地构建这组策略。除了通过实验验证我们的理论结果外，我们还将我们的方法与最近提出的多样化策略集构建方法进行了比较，结果表明，尽管其他方法失败了，但我们的方法能够构建一个行为基础，使得能够即时迁移到所有可能的下游任务。我们还通过实验证明，拥有一组独立策略可以更好地引导学习过程，在新的奖励函数不能描述为特征的线性组合的下游任务上。最后，我们展示了这组策略在终身强化学习环境中的实用性。",
        "领域": "强化学习",
        "问题": "如何构建一组策略，使其能够无需或仅需极少量的新数据即可解决各种未见过的强化学习任务",
        "动机": "研究如何通过构建一组多样化策略来提高强化学习模型在新任务上的迁移能力和性能",
        "方法": "提出了一种基于广义策略评估和改进框架的算法，迭代地构建一组独立策略，以实现即时迁移到所有可能的下游任务",
        "关键词": [
            "强化学习",
            "策略迁移",
            "广义策略更新",
            "独立策略集",
            "终身学习"
        ],
        "涉及的技术概念": {
            "广义策略评估和改进": "用于评估和改进策略的框架，假设任务奖励可以表示为固定特征集的线性组合",
            "独立策略集": "一组特定的多样化策略，能够在未见过的下游任务上实现高性能",
            "终身强化学习": "一种学习范式，旨在使代理能够在不断遇到的新任务中持续学习和适应"
        },
        "success": true
    },
    {
        "order": 158,
        "title": "Constructing Orthogonal Convolutions in an Explicit Manner",
        "html": "https://iclr.cc//virtual/2022/poster/6994",
        "abstract": "Convolutions with orthogonal input-output Jacobian matrix, i.e., orthogonal convolution,  have recently attracted substantial attention.  A convolution layer with an orthogonal Jacobian matrix is 1-Lipschitz  in the  2-norm, making the output robust to the perturbation in input. Meanwhile, an orthogonal Jacobian matrix preserves the gradient norm in back-propagation, which is critical for stable training deep networks. Nevertheless,  existing orthogonal convolutions are burdened by high computational costs for preserving orthogonality.In this work, we exploit the relation between the singular values of the convolution layer's  Jacobian and the structure of the convolution kernel.  To achieve orthogonality, we explicitly construct the convolution kernel for enforcing all singular values of the convolution layer's Jacobian to be $1$s.   After training,  the explicitly constructed orthogonal (ECO) convolution is constructed only once, and their weights are stored. Then,  in evaluation, we only need to load the stored weights of the trained  ECO convolution, and the computational cost of ECO convolution is the same as the standard dilated convolution. It is more efficient than the recent state-of-the-art approach, skew orthogonal convolution (SOC) in evaluation.    Experiments on CIFAR-10 and CIFAR-100  demonstrate that the proposed ECO convolution is faster than SOC in evaluation while leading to competitive standard and certified robust accuracies. ",
        "conference": "ICLR",
        "中文标题": "以显式方式构建正交卷积",
        "摘要翻译": "具有正交输入-输出雅可比矩阵的卷积，即正交卷积，最近引起了广泛关注。具有正交雅可比矩阵的卷积层在2-范数下是1-Lipschitz的，使得输出对输入中的扰动具有鲁棒性。同时，正交雅可比矩阵在反向传播中保持梯度范数，这对于稳定训练深度网络至关重要。然而，现有的正交卷积因保持正交性而承担了高计算成本。在这项工作中，我们利用了卷积层雅可比矩阵的奇异值与卷积核结构之间的关系。为了实现正交性，我们显式地构建了卷积核，以强制卷积层雅可比矩阵的所有奇异值为1。训练后，显式构建的正交（ECO）卷积仅构建一次，其权重被存储。然后，在评估时，我们只需要加载训练好的ECO卷积的存储权重，ECO卷积的计算成本与标准扩张卷积相同。它比最近的最先进方法——斜交正交卷积（SOC）在评估时更高效。在CIFAR-10和CIFAR-100上的实验表明，所提出的ECO卷积在评估时比SOC更快，同时导致竞争性的标准和认证鲁棒准确度。",
        "领域": "深度学习、计算机视觉、卷积神经网络",
        "问题": "如何高效地构建和实现正交卷积以减少计算成本",
        "动机": "正交卷积因其在保持梯度范数和提高模型鲁棒性方面的优势而受到关注，但现有方法计算成本高",
        "方法": "通过显式构建卷积核来强制雅可比矩阵的奇异值为1，实现正交性，减少计算成本",
        "关键词": [
            "正交卷积",
            "显式构建",
            "计算效率",
            "鲁棒性",
            "深度学习"
        ],
        "涉及的技术概念": {
            "正交卷积": "一种具有正交输入-输出雅可比矩阵的卷积，能够保持梯度范数，提高模型的鲁棒性",
            "1-Lipschitz": "在2-范数下，卷积层的输出对输入扰动的敏感性被限制，增强了模型的稳定性",
            "显式构建": "直接构造卷积核以确保雅可比矩阵的奇异值为1，从而在训练后只需存储权重，减少评估时的计算成本"
        },
        "success": true
    },
    {
        "order": 159,
        "title": "Contact Points Discovery for Soft-Body Manipulations with Differentiable Physics",
        "html": "https://iclr.cc//virtual/2022/poster/6125",
        "abstract": "Differentiable physics has recently been shown as a powerful tool for solving soft-body manipulation tasks. However, the differentiable physics solver often gets stuck when the initial contact points of the end effectors are sub-optimal or when performing multi-stage tasks that require contact point switching, which often leads to local minima.To address this challenge, we propose a  contact point discovery approach (CPDeform) that guides the stand-alone differentiable physics solver to deform various soft-body plasticines. The key idea of our approach is to integrate optimal transport-based contact points discovery into the differentiable physics solver to overcome the local minima from initial contact points or contact switching.On single-stage tasks, our method can automatically find suitable initial contact points based on transport priorities. On complex multi-stage tasks, we can iteratively switch the contact points of end-effectors based on transport priorities. To evaluate the effectiveness of our method, we introduce PlasticineLab-M that extends the existing differentiable physics benchmark PlasticineLab to seven new challenging multi-stage soft-body manipulation tasks. Extensive experimental results suggest that: 1) on multi-stage tasks that are infeasible for the vanilla differentiable physics solver, our approach discovers contact points that efficiently guide the solver to completion; 2) on tasks where the vanilla solver performs sub-optimally or near-optimally, our contact point discovery method performs better than or on par with the manipulation performance obtained with handcrafted contact points.",
        "conference": "ICLR",
        "中文标题": "可微分物理中软体操作接触点发现方法",
        "摘要翻译": "可微分物理最近被证明是解决软体操作任务的有力工具。然而，当末端执行器的初始接触点不理想或执行需要接触点切换的多阶段任务时，可微分物理求解器往往会陷入局部最小值。为了应对这一挑战，我们提出了一种接触点发现方法（CPDeform），该方法指导独立可微分物理求解器变形各种软体塑料。我们方法的关键思想是将基于最优传输的接触点发现集成到可微分物理求解器中，以克服初始接触点或接触切换带来的局部最小值。在单阶段任务上，我们的方法可以根据传输优先级自动找到合适的初始接触点。在复杂的多阶段任务上，我们可以根据传输优先级迭代切换末端执行器的接触点。为了评估我们方法的有效性，我们引入了PlasticineLab-M，它将现有的可微分物理基准PlasticineLab扩展到七个新的具有挑战性的多阶段软体操作任务。大量实验结果表明：1）在对于普通可微分物理求解器不可行的多阶段任务上，我们的方法发现的接触点有效地指导求解器完成任务；2）在普通求解器表现不佳或接近最佳的任务上，我们的接触点发现方法表现优于或等同于手工设计接触点获得的操作性能。",
        "领域": "软体机器人操作、可微分物理、最优传输",
        "问题": "解决可微分物理求解器在软体操作任务中因初始接触点不理想或需要接触点切换而陷入局部最小值的问题",
        "动机": "提高可微分物理求解器在软体操作任务中的效率和效果，特别是在需要复杂接触点管理的场景",
        "方法": "提出了一种结合最优传输的接触点发现方法（CPDeform），集成到可微分物理求解器中，以自动发现和切换接触点",
        "关键词": [
            "可微分物理",
            "软体操作",
            "接触点发现",
            "最优传输",
            "多阶段任务"
        ],
        "涉及的技术概念": {
            "可微分物理": "用于模拟和优化物理过程的技术，允许通过梯度下降等方法直接优化物理参数",
            "最优传输": "一种数学框架，用于在两个分布之间找到最优的传输方案，在本研究中用于发现有效的接触点",
            "接触点发现": "识别和优化操作过程中与软体交互的关键点，以提高操作效率和效果"
        },
        "success": true
    },
    {
        "order": 160,
        "title": "Context-Aware Sparse Deep Coordination Graphs",
        "html": "https://iclr.cc//virtual/2022/poster/6580",
        "abstract": "Learning sparse coordination graphs adaptive to the coordination dynamics among agents is a long-standing problem in cooperative multi-agent learning. This paper studies this problem and proposes a novel method using the variance of payoff functions to construct context-aware sparse coordination topologies. We theoretically consolidate our method by proving that the smaller the variance of payoff functions is, the less likely action selection will change after removing the corresponding edge. Moreover, we propose to learn action representations to effectively reduce the influence of payoff functions' estimation errors on graph construction. To empirically evaluate our method, we present the Multi-Agent COordination (MACO) benchmark by collecting classic coordination problems in the literature, increasing their difficulty, and classifying them into different types. We carry out a case study and experiments on the MACO and StarCraft II micromanagement benchmark to demonstrate the dynamics of sparse graph learning, the influence of graph sparseness, and the learning performance of our method.",
        "conference": "ICLR",
        "中文标题": "上下文感知的稀疏深度协调图",
        "摘要翻译": "学习适应于智能体间协调动态的稀疏协调图是合作多智能体学习中的一个长期存在的问题。本文研究了这一问题，并提出了一种利用收益函数方差构建上下文感知稀疏协调拓扑的新方法。我们通过理论证明，收益函数的方差越小，移除相应边后动作选择改变的可能性就越小，从而巩固了我们的方法。此外，我们提出学习动作表示以有效减少收益函数估计误差对图构建的影响。为了实证评估我们的方法，我们通过收集文献中的经典协调问题、增加其难度并将其分类为不同类型，提出了多智能体协调（MACO）基准。我们在MACO和星际争霸II微管理基准上进行了案例研究和实验，以展示稀疏图学习的动态性、图稀疏性的影响以及我们方法的学习性能。",
        "领域": "多智能体系统、强化学习、协调学习",
        "问题": "如何在多智能体系统中学习适应协调动态的稀疏协调图",
        "动机": "解决多智能体系统中因协调动态变化导致的稀疏协调图学习难题",
        "方法": "利用收益函数方差构建上下文感知稀疏协调拓扑，并通过学习动作表示减少估计误差",
        "关键词": [
            "稀疏协调图",
            "多智能体学习",
            "收益函数方差",
            "动作表示",
            "MACO基准"
        ],
        "涉及的技术概念": {
            "稀疏协调图": "用于表示多智能体系统中智能体间协调关系的图结构，其稀疏性有助于提高学习效率",
            "收益函数方差": "用于衡量收益函数变化程度的指标，本文中用于指导稀疏协调图的构建",
            "动作表示学习": "通过学习智能体动作的有效表示，减少收益函数估计误差对协调图构建的影响"
        },
        "success": true
    },
    {
        "order": 161,
        "title": "Contextualized Scene Imagination for Generative Commonsense Reasoning",
        "html": "https://iclr.cc//virtual/2022/poster/6866",
        "abstract": "Humans use natural language to compose common concepts from their environment into plausible, day-to-day scene descriptions. However, such generative commonsense reasoning (GCSR) skills are lacking in state-of-the-art text generation methods. Descriptive sentences about arbitrary concepts generated by neural text generation models (e.g., pre-trained text-to-text Transformers) are often grammatically fluent but may not correspond to human common sense, largely due to their lack of mechanisms to capture concept relations, to identify implicit concepts, and to perform generalizable reasoning about unseen concept compositions. In this paper, we propose an Imagine-and-Verbalize (I\\&V) method, which learns to imagine a relational scene knowledge graph (SKG) with relations between the input concepts, and leverage the SKG as a constraint when generating a plausible scene description. We collect and harmonize a set of knowledge resources from different domains and modalities, providing a rich auxiliary supervision signal for I\\&V. The experiments demonstrate the effectiveness of I\\&V in improving language models on both concept-to-sentence and concept-to-story generation tasks, while enabling the model to learn well from fewer task examples and generate SKGs that make common sense to human annotators.",
        "conference": "ICLR",
        "中文标题": "情境化场景想象用于生成式常识推理",
        "摘要翻译": "人类使用自然语言将环境中的常见概念组合成合理的日常场景描述。然而，这种生成式常识推理（GCSR）技能在最新的文本生成方法中尚不具备。由神经文本生成模型（例如，预训练的文本到文本转换器）生成的关于任意概念的描述性句子通常在语法上流畅，但可能不符合人类常识，这主要是由于它们缺乏捕捉概念关系、识别隐含概念以及对未见概念组合进行泛化推理的机制。在本文中，我们提出了一种想象与言语化（I&V）方法，该方法学习想象一个与输入概念之间具有关系的场景知识图（SKG），并在生成合理的场景描述时利用SKG作为约束。我们从不同领域和模态收集并协调了一组知识资源，为I&V提供了丰富的辅助监督信号。实验证明了I&V在改进语言模型在概念到句子和概念到故事生成任务上的有效性，同时使模型能够从较少的任务示例中学习，并生成对人类注释者来说具有常识意义的SKGs。",
        "领域": "自然语言处理与视觉结合、文本生成、常识推理",
        "问题": "解决神经文本生成模型在生成描述性句子时缺乏捕捉概念关系、识别隐含概念及对未见概念组合进行泛化推理的能力，导致生成的句子不符合人类常识的问题。",
        "动机": "提升文本生成模型在生成描述性句子时的常识推理能力，使其生成的句子不仅语法流畅，而且符合人类常识。",
        "方法": "提出想象与言语化（I&V）方法，通过想象一个与输入概念之间具有关系的场景知识图（SKG），并在生成描述时利用SKG作为约束，以提高生成句子的常识合理性。",
        "关键词": [
            "生成式常识推理",
            "场景知识图",
            "想象与言语化",
            "文本生成",
            "常识推理"
        ],
        "涉及的技术概念": {
            "生成式常识推理（GCSR）": "指模型在生成文本时能够基于常识进行推理，确保生成的描述符合人类日常经验。",
            "场景知识图（SKG）": "一种表示概念间关系的图结构，用于在文本生成过程中作为约束，确保生成的描述具有常识合理性。",
            "想象与言语化（I&V）": "一种结合场景想象和文本生成的方法，旨在通过想象概念间的关系来指导文本生成，提高生成文本的常识性。"
        },
        "success": true
    },
    {
        "order": 162,
        "title": "Continual Learning with Filter Atom Swapping",
        "html": "https://iclr.cc//virtual/2022/poster/6027",
        "abstract": "Continual learning has been widely studied in recent years to resolve the catastrophic forgetting of deep neural networks. In this paper, we first enforce a low-rank filter subspace by decomposing convolutional filters within each network layer over a small set of filter atoms. Then, we perform continual learning with filter atom swapping. In other words, we learn for each task a new filter subspace for each convolutional layer, i.e., hundreds of parameters as filter atoms, but keep subspace coefficients shared across tasks. By maintaining a small footprint memory of filter atoms, we can easily archive models for past tasks to avoid forgetting. The effectiveness of this simple scheme for continual learning is illustrated both empirically and theoretically. The proposed atom swapping framework further enables flexible and efficient model ensemble with members selected within a task or across tasks to improve the performance in different continual learning settings. Being validated on multiple benchmark datasets with different convolutional network structures, the proposed method outperforms the state-of-the-art methods in both accuracy and scalability.",
        "conference": "ICLR",
        "中文标题": "通过滤波器原子交换进行持续学习",
        "摘要翻译": "近年来，持续学习被广泛研究以解决深度神经网络的灾难性遗忘问题。在本文中，我们首先通过将每个网络层内的卷积滤波器分解为一小组滤波器原子来强制实施低秩滤波器子空间。然后，我们通过滤波器原子交换进行持续学习。换句话说，我们为每个任务学习每个卷积层的新滤波器子空间，即数百个参数作为滤波器原子，但保持子空间系数在任务间共享。通过维护滤波器原子的小足迹内存，我们可以轻松存档过去任务的模型以避免遗忘。这种简单的持续学习方案的有效性在实证和理论上都得到了说明。提出的原子交换框架进一步实现了灵活高效的模型集成，成员在任务内或跨任务选择，以提高不同持续学习设置中的性能。通过在多个基准数据集和不同的卷积网络结构上进行验证，所提出的方法在准确性和可扩展性方面均优于最先进的方法。",
        "领域": "持续学习、卷积神经网络、模型集成",
        "问题": "解决深度神经网络在持续学习过程中的灾难性遗忘问题",
        "动机": "通过维护一个小的滤波器原子内存来避免遗忘，同时实现模型的高效集成",
        "方法": "通过分解卷积滤波器为滤波器原子，并在任务间共享子空间系数，实现持续学习",
        "关键词": [
            "持续学习",
            "滤波器原子交换",
            "灾难性遗忘",
            "模型集成",
            "卷积神经网络"
        ],
        "涉及的技术概念": {
            "滤波器原子": "将卷积滤波器分解为一小组基础滤波器，用于构建低秩子空间",
            "低秩子空间": "通过限制滤波器的秩来减少参数数量，同时保持模型性能",
            "模型集成": "通过选择不同任务或跨任务的模型成员，提高持续学习的性能和灵活性"
        },
        "success": true
    },
    {
        "order": 163,
        "title": "Continual Learning with Recursive Gradient Optimization",
        "html": "https://iclr.cc//virtual/2022/poster/6560",
        "abstract": "Learning multiple tasks sequentially without forgetting previous knowledge, called Continual Learning(CL), remains a long-standing challenge for neural networks. Most existing methods rely on additional network capacity or data replay. In contrast, we introduce a novel approach which we refer to as Recursive Gradient Optimization(RGO). RGO is composed of an iteratively updated optimizer that modifies the gradient to minimize forgetting without data replay and a virtual Feature Encoding Layer(FEL) that represents different long-term structures with only task descriptors. Experiments demonstrate that RGO has significantly better performance on popular continual classification benchmarks when compared to the baselines and achieves new state-of-the-art performance on 20-split-CIFAR100(82.22%) and 20-split-miniImageNet(72.63%). With higher average accuracy than Single-Task Learning(STL), this method is flexible and reliable to provide continual learning capabilities for learning models that rely on gradient descent.",
        "conference": "ICLR",
        "中文标题": "递归梯度优化的持续学习",
        "摘要翻译": "在不忘记先前知识的情况下顺序学习多个任务，称为持续学习(CL)，这仍然是神经网络面临的一个长期挑战。大多数现有方法依赖于额外的网络容量或数据回放。相比之下，我们引入了一种新方法，我们称之为递归梯度优化(RGO)。RGO由一个迭代更新的优化器组成，该优化器修改梯度以最小化遗忘而无需数据回放，以及一个虚拟特征编码层(FEL)，该层仅用任务描述符表示不同的长期结构。实验表明，与基线相比，RGO在流行的持续分类基准测试中表现显著更好，并在20-split-CIFAR100(82.22%)和20-split-miniImageNet(72.63%)上实现了新的最先进性能。与单任务学习(STL)相比，这种方法具有更高的平均准确率，灵活可靠，为依赖梯度下降的学习模型提供持续学习能力。",
        "领域": "持续学习",
        "问题": "解决神经网络在顺序学习多个任务时遗忘先前知识的问题",
        "动机": "探索一种不依赖额外网络容量或数据回放的方法来实现持续学习",
        "方法": "引入递归梯度优化(RGO)方法，包括迭代更新的优化器和虚拟特征编码层(FEL)，以最小化遗忘并实现高效学习",
        "关键词": [
            "持续学习",
            "递归梯度优化",
            "特征编码层"
        ],
        "涉及的技术概念": {
            "递归梯度优化(RGO)": "一种迭代更新的优化器，通过修改梯度来最小化遗忘，无需数据回放",
            "虚拟特征编码层(FEL)": "仅用任务描述符表示不同的长期结构，帮助模型高效学习",
            "持续学习(CL)": "在不忘记先前知识的情况下顺序学习多个任务的能力"
        },
        "success": true
    },
    {
        "order": 164,
        "title": "Continual Normalization: Rethinking Batch Normalization for Online Continual Learning",
        "html": "https://iclr.cc//virtual/2022/poster/5912",
        "abstract": "Existing continual learning methods use Batch Normalization (BN) to facilitate training and improve generalization across tasks. However, the non-i.i.d and non-stationary nature of continual learning data, especially in the online setting, amplify the discrepancy between training and testing in BN and hinder the performance of older tasks. In this work, we study the cross-task normalization effect of BN in online continual learning where BN normalizes the testing data using moments biased towards the current task, resulting in higher catastrophic forgetting. This limitation motivates us to propose a simple yet effective method that we call Continual Normalization (CN) to facilitate training similar to BN while mitigating its negative effect. Extensive experiments on different continual learning algorithms and online scenarios show that CN is a direct replacement for BN and can provide substantial performance improvements. Our implementation will be made publicly available upon acceptance.",
        "conference": "ICLR",
        "中文标题": "持续归一化：重新思考在线持续学习中的批量归一化",
        "摘要翻译": "现有的持续学习方法使用批量归一化（BN）来促进训练并提高跨任务的泛化能力。然而，持续学习数据的非独立同分布和非平稳特性，特别是在在线设置中，放大了BN中训练和测试之间的差异，并阻碍了旧任务的性能。在这项工作中，我们研究了在线持续学习中BN的跨任务归一化效应，其中BN使用偏向当前任务的时刻来归一化测试数据，导致更高的灾难性遗忘。这一限制促使我们提出了一种简单而有效的方法，我们称之为持续归一化（CN），以类似于BN的方式促进训练，同时减轻其负面影响。在不同持续学习算法和在线场景上的大量实验表明，CN可以直接替代BN，并能提供显著的性能改进。我们的实现将在接受后公开提供。",
        "领域": "在线持续学习、深度学习优化、神经网络训练",
        "问题": "在线持续学习环境中批量归一化（BN）导致的训练与测试数据分布不一致问题",
        "动机": "解决BN在非独立同分布和非平稳数据环境下导致的灾难性遗忘问题",
        "方法": "提出持续归一化（CN）方法，作为BN的直接替代，以减轻其负面影响并提升性能",
        "关键词": [
            "持续归一化",
            "在线持续学习",
            "批量归一化",
            "灾难性遗忘",
            "深度学习优化"
        ],
        "涉及的技术概念": {
            "批量归一化（BN）": "用于促进训练并提高模型泛化能力的技术，但在非独立同分布数据下表现不佳",
            "持续归一化（CN）": "提出的新方法，旨在减轻BN在持续学习中的负面影响，同时保持其促进训练的优点",
            "灾难性遗忘": "在持续学习过程中，模型在学习新任务时忘记旧任务知识的问题"
        },
        "success": true
    },
    {
        "order": 165,
        "title": "Continuously Discovering Novel Strategies via Reward-Switching Policy Optimization",
        "html": "https://iclr.cc//virtual/2022/poster/6050",
        "abstract": "We present Reward-Switching Policy Optimization (RSPO), a paradigm to discover diverse strategies in complex RL environments by iteratively finding novel policies that are both locally optimal and sufficiently different from existing ones. To encourage the learning policy to consistently converge towards a previously undiscovered local optimum, RSPO switches between extrinsic and intrinsic rewards via a trajectory-based novelty measurement during the optimization process. When a sampled trajectory is sufficiently distinct, RSPO performs standard policy optimization with extrinsic rewards.  For trajectories with high likelihood under existing policies, RSPO utilizes an intrinsic diversity reward to promote exploration. Experiments show that RSPO is able to discover a wide spectrum of strategies in a variety of domains, ranging from single-agent particle-world tasks and MuJoCocontinuous control to multi-agent stag-hunt games and StarCraftII challenges.",
        "conference": "ICLR",
        "中文标题": "通过奖励切换策略优化持续发现新策略",
        "摘要翻译": "我们提出了奖励切换策略优化（RSPO），这是一种在复杂强化学习环境中通过迭代发现既局部最优又与现有策略足够不同的新策略来发现多样策略的范式。为了鼓励学习策略持续收敛于之前未发现的局部最优解，RSPO在优化过程中通过基于轨迹的新颖性测量在外在和内在奖励之间切换。当采样的轨迹足够独特时，RSPO执行带有外在奖励的标准策略优化。对于在现有策略下具有高可能性的轨迹，RSPO利用内在多样性奖励来促进探索。实验表明，RSPO能够在多种领域中发现广泛的策略，从单智能体粒子世界任务和MuJoCo连续控制到多智能体stag-hunt游戏和StarCraftII挑战。",
        "领域": "强化学习、多智能体系统、连续控制",
        "问题": "在复杂强化学习环境中发现多样且局部最优的策略",
        "动机": "为了解决在复杂环境中发现多样策略的挑战，特别是在需要策略既局部最优又与现有策略足够不同的情况下",
        "方法": "通过在外在和内在奖励之间切换，基于轨迹的新颖性测量来优化策略，以促进探索和发现新策略",
        "关键词": [
            "奖励切换",
            "策略优化",
            "多样性探索",
            "强化学习",
            "局部最优"
        ],
        "涉及的技术概念": {
            "奖励切换策略优化（RSPO）": "一种在优化过程中通过在外在和内在奖励之间切换来发现多样策略的范式",
            "轨迹新颖性测量": "用于评估采样轨迹与现有策略的差异程度，以决定是否切换奖励类型",
            "内在多样性奖励": "用于在策略优化过程中促进探索，特别是在遇到与现有策略高度相似的轨迹时"
        },
        "success": true
    },
    {
        "order": 166,
        "title": "Continuous-Time Meta-Learning with Forward Mode Differentiation",
        "html": "https://iclr.cc//virtual/2022/poster/6055",
        "abstract": "Drawing inspiration from gradient-based meta-learning methods with infinitely small gradient steps, we introduce Continuous-Time Meta-Learning (COMLN), a meta-learning algorithm where adaptation follows the dynamics of a gradient vector field. Specifically, representations of the inputs are meta-learned such that a task-specific linear classifier is obtained as a solution of an ordinary differential equation (ODE). Treating the learning process as an ODE offers the notable advantage that the length of the trajectory is now continuous, as opposed to a fixed and discrete number of gradient steps. As a consequence, we can optimize the amount of adaptation necessary to solve a new task using stochastic gradient descent, in addition to learning the initial conditions as is standard practice in gradient-based meta-learning. Importantly, in order to compute the exact meta-gradients required for the outer-loop updates, we  devise an efficient algorithm based on forward mode differentiation, whose memory requirements do not scale with the length of the learning trajectory, thus allowing longer adaptation in constant memory. We provide analytical guarantees for the stability of COMLN, we show empirically its efficiency in terms of runtime and memory usage, and we illustrate its effectiveness on a range of few-shot image classification problems.",
        "conference": "ICLR",
        "中文标题": "基于前向模式微分的连续时间元学习",
        "摘要翻译": "受到基于梯度的元学习方法中无限小梯度步长的启发，我们引入了连续时间元学习（COMLN），这是一种元学习算法，其中适应遵循梯度向量场的动态。具体来说，输入的表示被元学习，使得任务特定的线性分类器作为常微分方程（ODE）的解获得。将学习过程视为ODE提供了显著的优点，即轨迹的长度现在是连续的，而不是固定和离散的梯度步数。因此，除了像基于梯度的元学习中的标准实践那样学习初始条件外，我们还可以使用随机梯度下降来优化解决新任务所需的适应量。重要的是，为了计算外环更新所需的精确元梯度，我们设计了一种基于前向模式微分的高效算法，其内存需求不随学习轨迹的长度而扩展，从而允许在恒定内存中进行更长时间的适应。我们为COMLN的稳定性提供了分析保证，我们通过实验展示了其在运行时和内存使用方面的效率，并在少量样本图像分类问题上展示了其有效性。",
        "领域": "元学习、少量样本学习、图像分类",
        "问题": "如何在连续时间内高效地进行元学习，以适应新任务",
        "动机": "受到基于梯度的元学习方法中无限小梯度步长的启发，旨在通过连续时间动态优化适应过程，提高元学习的效率和适应性",
        "方法": "引入连续时间元学习（COMLN），将适应过程建模为梯度向量场的动态，使用前向模式微分计算元梯度，优化适应量和初始条件",
        "关键词": [
            "连续时间元学习",
            "前向模式微分",
            "少量样本学习",
            "图像分类",
            "常微分方程"
        ],
        "涉及的技术概念": {
            "连续时间元学习（COMLN）": "一种元学习算法，通过将适应过程建模为梯度向量场的动态，实现在连续时间内的高效学习",
            "前向模式微分": "用于高效计算元梯度的算法，其内存需求不随学习轨迹的长度而扩展",
            "常微分方程（ODE）": "用于描述学习过程的数学模型，使得轨迹的长度连续，优化适应过程"
        },
        "success": true
    },
    {
        "order": 167,
        "title": "Contrastive Clustering to Mine Pseudo Parallel Data for Unsupervised Translation",
        "html": "https://iclr.cc//virtual/2022/poster/6424",
        "abstract": "Modern unsupervised machine translation systems mostly train their models by generating synthetic parallel training data from large unlabeled monolingual corpora of different languages through various means, such as iterative back-translation. However, there may exist small amount of actual parallel data hidden in the sea of unlabeled data, which has not been exploited. We develop a new fine-tuning objective, called Language-Agnostic Constraint for SwAV loss, or LAgSwAV, which enables a pre-trained model to extract such pseudo-parallel data from the monolingual corpora in a fully unsupervised manner. We then propose an effective strategy to utilize the obtained synthetic data to augment unsupervised machine translation. Our method achieves the state of the art in the WMT'14 English-French, WMT'16 German-English and English-Romanian bilingual unsupervised translation tasks, with 40.2, 36.8, 37.0 BLEU, respectively. We also achieve substantial improvements in the FLoRes low-resource English-Nepali and English-Sinhala unsupervised tasks with 5.3 and 5.4 BLEU, respectively.",
        "conference": "ICLR",
        "中文标题": "对比聚类挖掘伪平行数据用于无监督翻译",
        "摘要翻译": "现代无监督机器翻译系统主要通过从不同语言的大型未标记单语语料库中通过各种方式（如迭代回译）生成合成的平行训练数据来训练其模型。然而，在未标记数据的海洋中可能隐藏着少量的实际平行数据，这些数据尚未被利用。我们开发了一种新的微调目标，称为SwAV损失的语言无关约束（LAgSwAV），使预训练模型能够以完全无监督的方式从单语语料库中提取此类伪平行数据。然后，我们提出了一种有效策略，利用获得的合成数据来增强无监督机器翻译。我们的方法在WMT'14英语-法语、WMT'16德语-英语和英语-罗马尼亚双语无监督翻译任务中达到了最先进的水平，BLEU分数分别为40.2、36.8、37.0。在FLoRes低资源英语-尼泊尔语和英语-僧伽罗语无监督任务中，我们也分别实现了5.3和5.4 BLEU分数的显著提升。",
        "领域": "无监督机器翻译、对比学习、低资源语言处理",
        "问题": "如何从未标记的单语语料库中挖掘和利用隐藏的伪平行数据以增强无监督机器翻译的性能",
        "动机": "利用未标记数据中隐藏的伪平行数据来提升无监督机器翻译系统的性能",
        "方法": "开发了一种新的微调目标LAgSwAV，用于无监督地从单语语料库中提取伪平行数据，并提出了一种策略来利用这些数据增强翻译模型",
        "关键词": [
            "无监督机器翻译",
            "对比聚类",
            "伪平行数据",
            "语言无关约束",
            "低资源语言"
        ],
        "涉及的技术概念": {
            "对比聚类": "用于从未标记数据中挖掘伪平行数据的技术",
            "SwAV损失": "一种用于对比学习的损失函数，本文中通过语言无关约束进行改进",
            "BLEU分数": "用于评估机器翻译质量的指标，本文中用于展示方法的有效性"
        },
        "success": true
    },
    {
        "order": 168,
        "title": "Contrastive Fine-grained Class Clustering via Generative Adversarial Networks",
        "html": "https://iclr.cc//virtual/2022/poster/7164",
        "abstract": "Unsupervised fine-grained class clustering is a practical yet challenging task due to the difficulty of feature representations learning of subtle object details. We introduce C3-GAN, a method that leverages the categorical inference power of InfoGAN with contrastive learning. We aim to learn feature representations that encourage a dataset to form distinct cluster boundaries in the embedding space, while also maximizing the mutual information between the latent code and its image observation. Our approach is to train a discriminator, which is also used for inferring clusters, to optimize the contrastive loss, where image-latent pairs that maximize the mutual information are considered as positive pairs and the rest as negative pairs. Specifically, we map the input of a generator, which was sampled from the categorical distribution, to the embedding space of the discriminator and let them act as a cluster centroid. In this way, C3-GAN succeeded in learning a clustering-friendly embedding space where each cluster is distinctively separable. Experimental results show that C3-GAN achieved the state-of-the-art clustering performance on four fine-grained image datasets, while also alleviating the mode collapse phenomenon. Code is available at https://github.com/naver-ai/c3-gan.",
        "conference": "ICLR",
        "中文标题": "通过生成对抗网络进行对比细粒度类别聚类",
        "摘要翻译": "无监督细粒度类别聚类是一项实用但具有挑战性的任务，原因在于难以学习到细微物体细节的特征表示。我们介绍了C3-GAN，这是一种利用InfoGAN的类别推断能力与对比学习相结合的方法。我们的目标是学习特征表示，鼓励数据集在嵌入空间中形成明显的聚类边界，同时最大化潜在代码与其图像观察之间的互信息。我们的方法是训练一个判别器（也用于推断聚类）以优化对比损失，其中最大化互信息的图像-潜在对被视为正对，其余为负对。具体来说，我们将从类别分布中采样的生成器输入映射到判别器的嵌入空间，并让它们充当聚类中心。通过这种方式，C3-GAN成功学习到了一个聚类友好的嵌入空间，其中每个聚类都是明显可分离的。实验结果表明，C3-GAN在四个细粒度图像数据集上实现了最先进的聚类性能，同时也缓解了模式崩溃现象。代码可在https://github.com/naver-ai/c3-gan获取。",
        "领域": "细粒度图像分类, 生成对抗网络, 无监督学习",
        "问题": "解决无监督细粒度类别聚类中特征表示学习的挑战",
        "动机": "通过学习特征表示鼓励数据集在嵌入空间中形成明显的聚类边界，同时最大化潜在代码与其图像观察之间的互信息",
        "方法": "结合InfoGAN的类别推断能力与对比学习，训练判别器优化对比损失，将生成器输入映射到判别器的嵌入空间作为聚类中心",
        "关键词": [
            "细粒度类别聚类",
            "生成对抗网络",
            "对比学习",
            "无监督学习",
            "特征表示学习"
        ],
        "涉及的技术概念": {
            "InfoGAN": "利用InfoGAN的类别推断能力，帮助模型在无监督条件下学习到有意义的潜在表示",
            "对比学习": "通过对比损失优化，鼓励正样本对之间的相似性高于负样本对，从而学习到更好的特征表示",
            "模式崩溃": "生成对抗网络中常见的问题，指生成器只能生成有限多样性的样本，C3-GAN通过特定方法缓解了这一问题"
        },
        "success": true
    },
    {
        "order": 169,
        "title": "Controlling Directions Orthogonal to a Classifier",
        "html": "https://iclr.cc//virtual/2022/poster/6557",
        "abstract": "We propose to identify directions invariant to a given classifier so that these directions can be controlled in tasks such as style transfer. While orthogonal decomposition is directly identifiable when the given classifier is linear, we formally define a notion of orthogonality in the non-linear case. We also provide a surprisingly simple method for constructing the orthogonal classifier (a classifier utilizing directions other than those of the given classifier). Empirically, we present three use cases where controlling orthogonal variation is important: style transfer, domain adaptation, and fairness. The orthogonal classifier enables desired style transfer when domains vary in multiple aspects, improves domain adaptation with label shifts and mitigates the unfairness as a predictor. The code is available at https://github.com/Newbeeer/orthogonal_classifier",
        "conference": "ICLR",
        "中文标题": "控制与分类器正交的方向",
        "摘要翻译": "我们提出了一种方法来识别对给定分类器不变的方向，以便在诸如风格迁移等任务中控制这些方向。虽然当给定分类器是线性时，正交分解可以直接识别，但我们正式定义了非线性情况下的正交性概念。我们还提供了一个出奇简单的方法来构建正交分类器（一个利用给定分类器方向之外的方向的分类器）。实证上，我们提出了三个控制正交变化重要的用例：风格迁移、领域适应和公平性。正交分类器在领域在多个方面变化时实现了所需的风格迁移，通过标签偏移改善了领域适应，并作为预测器减轻了不公平性。代码可在https://github.com/Newbeeer/orthogonal_classifier获取。",
        "领域": "风格迁移, 领域适应, 公平性",
        "问题": "如何在风格迁移、领域适应和公平性等任务中控制与分类器正交的方向",
        "动机": "为了在多个应用场景中有效控制与分类器正交的方向，以实现更好的风格迁移、领域适应和公平性",
        "方法": "提出了一种识别对给定分类器不变的方向的方法，并定义了非线性情况下的正交性概念，以及构建正交分类器的简单方法",
        "关键词": [
            "正交分类器",
            "风格迁移",
            "领域适应",
            "公平性",
            "非线性正交性"
        ],
        "涉及的技术概念": {
            "正交分类器": "利用给定分类器方向之外的方向的分类器，用于控制与分类器正交的方向",
            "非线性正交性": "在非线性情况下定义的正交性概念，扩展了正交分解的应用范围",
            "风格迁移": "通过控制与分类器正交的方向，实现不同风格之间的转换"
        },
        "success": true
    },
    {
        "order": 170,
        "title": "Controlling the Complexity and Lipschitz Constant improves Polynomial Nets",
        "html": "https://iclr.cc//virtual/2022/poster/5906",
        "abstract": "While the class of Polynomial Nets demonstrates comparable performance to neural networks (NN), it currently has neither theoretical generalization characterization nor robustness guarantees. To this end, we derive new complexity bounds for the set of Coupled CP-Decomposition (CCP) and Nested Coupled CP-decomposition (NCP) models of Polynomial Nets in terms of the $\\ell_\\infty$-operator-norm and the $\\ell_2$-operator norm. In addition, we derive bounds on the Lipschitz constant for both models to establish a theoretical certificate for their robustness. The theoretical results enable us to propose a principled regularization scheme that we also evaluate experimentally and show that it improves the accuracy as well as the robustness of the models to adversarial perturbations. We showcase how this regularization can be combined with adversarial training, resulting in further improvements.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "控制复杂度和 Lipschitz 常数提升多项式网络性能",
        "摘要翻译": "虽然多项式网络在性能上与神经网络 (NN) 具有可比性，但目前既没有理论泛化特性，也没有鲁棒性保证。为此，我们根据 $\\\\ell_\\\\infty$-算子范数和 $\\\\ell_2$-算子范数，推导出多项式网络的耦合 CP 分解 (CCP) 和嵌套耦合 CP 分解 (NCP) 模型集合的新的复杂度界限。此外，我们推导出两种模型的 Lipschitz 常数的界限，从而为其鲁棒性建立理论证书。理论结果使我们能够提出一种基于原则的正则化方案，我们还通过实验对其进行评估，结果表明，该方案提高了模型的准确性以及对对抗性扰动的鲁棒性。我们展示了如何将这种正则化与对抗训练相结合，从而进一步改进性能。",
        "领域": "模型复杂度控制, 对抗鲁棒性, 正则化方法",
        "问题": "多项式网络缺乏理论泛化保证和对抗鲁棒性，限制了其应用。",
        "动机": "为了提升多项式网络的泛化能力和对抗鲁棒性，需要从理论上分析其复杂度和 Lipschitz 常数，并设计有效的正则化方法。",
        "方法": "通过推导耦合 CP 分解和嵌套耦合 CP 分解多项式网络的复杂度界限和 Lipschitz 常数界限，提出一种基于原则的正则化方案，并结合对抗训练进行优化。",
        "关键词": [
            "多项式网络",
            "复杂度控制",
            "Lipschitz 常数",
            "对抗鲁棒性",
            "正则化"
        ],
        "涉及的技术概念": {
            "复杂度界限": "通过分析模型的复杂度，为模型的泛化能力提供理论保证。",
            "Lipschitz 常数": "用于衡量模型的鲁棒性，Lipschitz 常数越小，模型对输入的扰动越不敏感。"
        }
    },
    {
        "order": 171,
        "title": "Convergent and Efficient Deep Q Learning Algorithm",
        "html": "https://iclr.cc//virtual/2022/poster/7160",
        "abstract": "Despite the empirical success of the deep Q network (DQN) reinforcement learning algorithm and its variants, DQN is still not well understood and it does not guarantee convergence. In this work, we show that DQN can indeed diverge and cease to operate in realistic settings. Although there exist gradient-based convergent methods, we show that they actually have inherent problems in learning dynamics which cause them to fail even for simple tasks. To overcome these problems, we propose a convergent DQN algorithm (C-DQN) that is guaranteed to converge and can work with large discount factors (0.9998). It learns robustly in difficult settings and can learn several difficult games in the Atari 2600 benchmark that DQN fails to solve.",
        "conference": "ICLR",
        "中文标题": "收敛且高效的深度Q学习算法",
        "摘要翻译": "尽管深度Q网络（DQN）强化学习算法及其变体在实证上取得了成功，但DQN仍然没有得到很好的理解，并且不保证收敛。在这项工作中，我们展示了DQN在现实设置中确实可能发散并停止工作。尽管存在基于梯度的收敛方法，但我们展示了它们在学习动态上实际上存在固有问题，这些问题导致它们即使在简单任务上也会失败。为了克服这些问题，我们提出了一种保证收敛的DQN算法（C-DQN），它能够与大折扣因子（0.9998）一起工作。它在困难设置中稳健学习，并且可以学习Atari 2600基准测试中DQN无法解决的几个困难游戏。",
        "领域": "强化学习、深度Q学习、游戏AI",
        "问题": "解决深度Q网络（DQN）算法在现实设置中可能发散和不收敛的问题",
        "动机": "DQN算法及其变体虽然在实证上成功，但缺乏理论上的收敛保证，且在现实设置中可能失效",
        "方法": "提出了一种新的保证收敛的深度Q学习算法（C-DQN），能够处理大折扣因子并在困难设置中稳健学习",
        "关键词": [
            "深度Q学习",
            "强化学习",
            "收敛算法",
            "Atari 2600",
            "游戏AI"
        ],
        "涉及的技术概念": {
            "深度Q网络（DQN）": "一种结合深度学习和Q学习的强化学习算法，用于处理高维状态空间",
            "收敛算法": "保证在有限步骤内达到稳定解的算法，本文提出的C-DQN算法具有这一特性",
            "折扣因子": "在强化学习中用于平衡即时奖励和未来奖励的重要性，本文算法能够处理接近1的大折扣因子"
        },
        "success": true
    },
    {
        "order": 172,
        "title": "Convergent Graph Solvers",
        "html": "https://iclr.cc//virtual/2022/poster/6360",
        "abstract": "We propose the convergent graph solver (CGS), a deep learning method that learns iterative mappings to predict the properties of a graph system at its stationary state (fixed point) with guaranteed convergence. The forward propagation of CGS proceeds in three steps: (1) constructing the input-dependent linear contracting iterative maps, (2) computing the fixed points of the iterative maps, and (3) decoding the fixed points to estimate the properties. The contractivity of the constructed linear maps guarantees the existence and uniqueness of the fixed points following the Banach fixed point theorem. To train CGS efficiently, we also derive a tractable analytical expression for its gradient by leveraging the implicit function theorem. We evaluate the performance of CGS by applying it to various network-analytic and graph benchmark problems. The results indicate that CGS has competitive capabilities for predicting the stationary properties of graph systems,  irrespective of whether the target systems are linear or non-linear. CGS also shows high performance for graph classification problems where the existence or the meaning of a fixed point is hard to be clearly defined, which highlights the potential of CGS as a general graph neural network architecture.",
        "conference": "ICLR",
        "中文标题": "收敛图求解器",
        "摘要翻译": "我们提出了收敛图求解器（CGS），这是一种深度学习方法，通过学习迭代映射来预测图系统在其稳态（固定点）时的属性，并保证收敛。CGS的前向传播分为三个步骤：（1）构建依赖于输入的线性收缩迭代映射，（2）计算迭代映射的固定点，（3）解码固定点以估计属性。构建的线性映射的收缩性保证了根据Banach固定点定理固定点的存在性和唯一性。为了高效训练CGS，我们还利用隐函数定理推导出了其梯度的可处理解析表达式。我们通过将CGS应用于各种网络分析和图基准问题来评估其性能。结果表明，无论目标系统是线性还是非线性，CGS在预测图系统的稳态属性方面都具有竞争能力。CGS在图分类问题上也表现出高性能，其中固定点的存在或意义难以明确定义，这突出了CGS作为通用图神经网络架构的潜力。",
        "领域": "图神经网络、网络分析、图分类",
        "问题": "如何有效预测图系统在稳态时的属性，并保证方法的收敛性",
        "动机": "开发一种能够保证收敛性并有效预测图系统稳态属性的深度学习方法",
        "方法": "通过构建线性收缩迭代映射、计算固定点并解码固定点来预测图系统属性，利用隐函数定理高效训练模型",
        "关键词": [
            "收敛图求解器",
            "图神经网络",
            "稳态预测",
            "网络分析",
            "图分类"
        ],
        "涉及的技术概念": {
            "线性收缩迭代映射": "用于构建保证收敛的迭代过程，确保固定点的存在性和唯一性",
            "Banach固定点定理": "保证构建的线性映射存在唯一固定点的理论基础",
            "隐函数定理": "用于推导模型梯度的解析表达式，实现高效训练"
        },
        "success": true
    },
    {
        "order": 173,
        "title": "Coordination Among Neural Modules Through a Shared Global Workspace",
        "html": "https://iclr.cc//virtual/2022/poster/6382",
        "abstract": " Deep learning has seen a movement away from representing examples with a monolithic hidden state towards a richly structured state. For example, Transformers segment by position, and object-centric architectures decompose images into entities. In all these architectures, interactions between different elements are modeled via pairwise interactions: Transformers make use of self-attention to incorporate information from other positions and object-centric architectures make use of graph neural networks to model interactions among entities.  We consider how to improve on pairwise interactions in terms of global coordination and a coherent, integrated representation that can be used for downstream tasks. In cognitive science, a global workspace architecture has been proposed in which functionally  specialized  components share information through a common, bandwidth-limited communication channel. We explore the use of such a communication channel in the context of deep learning for modeling the structure of complex environments. The proposed method includes a shared workspace through which communication among different specialist modules takes place but due to limits on the communication bandwidth, specialist modules must compete for access. We show that capacity limitations have  a rational basis in that (1) they encourage specialization and compositionality and (2) they facilitate the synchronization of otherwise  independent specialists.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "通过共享全局工作空间实现神经模块间的协调",
        "摘要翻译": "深度学习已经从使用单一隐藏状态表示示例转向了具有丰富结构的状态。例如，Transformers通过位置进行分割，而对象为中心的架构将图像分解为实体。在这些架构中，不同元素之间的交互是通过成对交互来建模的：Transformers利用自注意力机制来整合来自其他位置的信息，对象为中心的架构则利用图神经网络来建模实体间的交互。我们考虑了如何在全局协调和可用于下游任务的连贯、集成表示方面改进成对交互。在认知科学中，提出了一个全局工作空间架构，其中功能专门化的组件通过一个共同的、带宽有限的通信通道共享信息。我们探索了在深度学习中用于建模复杂环境结构的这种通信通道的使用。所提出的方法包括一个共享工作空间，通过它不同专家模块之间进行通信，但由于通信带宽的限制，专家模块必须竞争访问权限。我们表明，容量限制有一个合理的基础，因为（1）它们鼓励专业化和组合性，（2）它们促进了原本独立的专家之间的同步。",
        "领域": "神经网络架构设计, 深度学习模型优化, 认知科学与人工智能结合",
        "问题": "如何改进深度学习模型中模块间的成对交互方式，以实现更有效的全局协调和集成表示。",
        "动机": "探索在深度学习中引入全局工作空间架构，以模拟人类认知系统中的信息共享机制，提升模型处理复杂环境的能力。",
        "方法": "提出了一种共享全局工作空间的方法，允许不同专家模块通过带宽有限的通信通道进行交互，促进专业化和同步。",
        "关键词": [
            "全局工作空间",
            "神经模块协调",
            "深度学习架构",
            "带宽限制通信",
            "专家模块同步"
        ],
        "涉及的技术概念": {
            "全局工作空间": "在深度学习中模拟认知科学的全局工作空间概念，用于不同专家模块间的信息共享和协调。",
            "自注意力机制": "Transformers中用于整合来自不同位置信息的技术，本文中用于对比成对交互的局限性。",
            "图神经网络": "对象为中心架构中用于建模实体间交互的技术，本文中探讨其与全局工作空间架构的结合潜力。"
        }
    },
    {
        "order": 174,
        "title": "CoordX: Accelerating Implicit Neural Representation with a Split MLP Architecture",
        "html": "https://iclr.cc//virtual/2022/poster/7142",
        "abstract": "Implicit neural representations with multi-layer perceptrons (MLPs) have recently gained prominence for a wide variety of tasks such as novel view synthesis and 3D object representation and rendering. However, a significant challenge with these representations is that both training and inference with an MLP over a large number of input coordinates to learn and represent an image, video, or 3D object, require large amounts of computation and incur long processing times. In this work, we aim to accelerate inference and training of coordinate-based MLPs for implicit neural representations by proposing a new split MLP architecture, CoordX. With CoordX, the initial layers are split to learn each dimension of the input coordinates separately. The intermediate features are then fused by the last layers to generate the learned signal at the corresponding coordinate point. This significantly reduces the amount of computation required and leads to large speedups in training and inference, while achieving similar accuracy as the baseline MLP. This approach thus aims at first learning functions that are a decomposition of the original signal and then fusing them to generate the learned signal. Our proposed architecture can be generally used for many implicit neural representation tasks with no additional memory overheads. We demonstrate a speedup of up to 2.92x compared to the baseline model for image, video, and 3D shape representation and rendering tasks.",
        "conference": "ICLR",
        "中文标题": "CoordX：通过分割MLP架构加速隐式神经表示",
        "摘要翻译": "近年来，使用多层感知机（MLPs）的隐式神经表示在多种任务中变得突出，如新视角合成、3D物体表示和渲染。然而，这些表示面临的一个重大挑战是，无论是训练还是推理，使用MLP处理大量输入坐标以学习和表示图像、视频或3D物体，都需要大量的计算并导致长时间的处理。在这项工作中，我们旨在通过提出一种新的分割MLP架构CoordX，来加速基于坐标的MLPs在隐式神经表示中的推理和训练。CoordX将初始层分割以分别学习输入坐标的每个维度。然后，中间特征通过最后一层融合，以在相应的坐标点生成学习到的信号。这显著减少了所需的计算量，并在训练和推理中实现了大幅加速，同时达到了与基线MLP相似的准确度。因此，这种方法首先旨在学习作为原始信号分解的函数，然后融合它们以生成学习到的信号。我们提出的架构可以普遍用于许多隐式神经表示任务，无需额外的内存开销。我们展示了在图像、视频和3D形状表示及渲染任务中，与基线模型相比，速度提升最高可达2.92倍。",
        "领域": "隐式神经表示、3D渲染、新视角合成",
        "问题": "加速基于坐标的多层感知机在隐式神经表示中的训练和推理过程",
        "动机": "解决隐式神经表示中因处理大量输入坐标而导致的计算量大和处理时间长的问题",
        "方法": "提出一种分割MLP架构CoordX，通过分割初始层分别学习输入坐标的每个维度，然后融合中间特征以减少计算量",
        "关键词": [
            "隐式神经表示",
            "多层感知机",
            "坐标分割",
            "加速训练",
            "3D渲染"
        ],
        "涉及的技术概念": {
            "隐式神经表示": "用于表示图像、视频或3D物体的技术，通过神经网络隐式地学习信号",
            "多层感知机（MLP）": "一种前馈人工神经网络模型，用于学习和表示复杂的非线性关系",
            "坐标分割": "将输入坐标的每个维度分开处理的技术，以减少计算量并加速训练和推理过程"
        },
        "success": true
    },
    {
        "order": 175,
        "title": "COPA: Certifying Robust Policies for Offline Reinforcement Learning against Poisoning Attacks",
        "html": "https://iclr.cc//virtual/2022/poster/6853",
        "abstract": "As reinforcement learning (RL) has achieved near human-level performance in a variety of tasks, its robustness has raised great attention. While a vast body of research has explored test-time (evasion) attacks in RL and corresponding defenses, its robustness against training-time (poisoning) attacks remains largely unanswered. In this work, we focus on certifying the robustness of ofﬂine RL in the presence of poisoning attacks, where a subset of training trajectories could be arbitrarily manipulated. We propose the ﬁrst certiﬁcation framework, COPA, to certify the number of poisoning trajectories that can be tolerated regarding different certiﬁcation criteria. Given the complex structure of RL, we propose two certiﬁcation criteria: per-state action stability and cumulative reward bound. To further improve the certiﬁcation, we propose new partition and aggregation protocols to train robust policies. We further prove that some of the proposed certiﬁcation methods are theoretically tight and some are NP-Complete problems. We leverage COPA to certify three RL environments trained with different algorithms and conclude: (1) The proposed robust aggregation protocols such as temporal aggregation can signiﬁcantly improve the certiﬁcations; (2) Our certiﬁcations for both per-state action stability and cumulative reward bound are efﬁcient and tight; (3) The certiﬁcation for different training algorithms and environments are different, implying their intrinsic robustness properties. All experimental results are available at https://copa-leaderboard.github.io.",
        "conference": "ICLR",
        "中文标题": "COPA：针对离线强化学习中投毒攻击的鲁棒策略认证",
        "摘要翻译": "随着强化学习（RL）在各种任务中达到接近人类水平的性能，其鲁棒性引起了极大关注。尽管大量研究探索了RL中的测试时（规避）攻击及相应防御措施，但其对训练时（投毒）攻击的鲁棒性仍大多未解。在这项工作中，我们专注于认证离线RL在存在投毒攻击时的鲁棒性，其中一部分训练轨迹可能被任意操纵。我们提出了首个认证框架COPA，以认证关于不同认证标准可容忍的投毒轨迹数量。鉴于RL的复杂结构，我们提出了两个认证标准：每状态动作稳定性和累积奖励界限。为了进一步提高认证，我们提出了新的分割和聚合协议来训练鲁棒策略。我们进一步证明，所提出的一些认证方法在理论上是紧的，而有些则是NP完全问题。我们利用COPA认证了用不同算法训练的三种RL环境，并得出结论：（1）提出的鲁棒聚合协议如时间聚合可以显著提高认证；（2）我们对每状态动作稳定性和累积奖励界限的认证既高效又紧；（3）不同训练算法和环境的认证不同，暗示了它们内在的鲁棒性特性。所有实验结果可在https://copa-leaderboard.github.io查看。",
        "领域": "离线强化学习、鲁棒性认证、投毒攻击防御",
        "问题": "认证离线强化学习策略在投毒攻击下的鲁棒性",
        "动机": "探索强化学习在训练时对抗投毒攻击的鲁棒性，填补现有研究的空白",
        "方法": "提出COPA认证框架，包括两个认证标准和新的分割与聚合协议，以训练鲁棒策略",
        "关键词": [
            "离线强化学习",
            "投毒攻击",
            "鲁棒性认证",
            "时间聚合",
            "NP完全问题"
        ],
        "涉及的技术概念": {
            "每状态动作稳定性": "用于认证在投毒攻击下，策略对每个状态的动作选择是否稳定",
            "累积奖励界限": "用于认证在投毒攻击下，策略的累积奖励是否能够保持在一定范围内",
            "时间聚合": "一种鲁棒聚合协议，通过时间维度上的聚合提高策略对投毒攻击的抵抗能力"
        },
        "success": true
    },
    {
        "order": 176,
        "title": "COptiDICE: Offline Constrained Reinforcement Learning via Stationary Distribution Correction Estimation",
        "html": "https://iclr.cc//virtual/2022/poster/6824",
        "abstract": "We consider the offline constrained reinforcement learning (RL) problem, in which the agent aims to compute a policy that maximizes expected return while satisfying given cost constraints, learning only from a pre-collected dataset. This problem setting is appealing in many real-world scenarios, where direct interaction with the environment is costly or risky, and where the resulting policy should comply with safety constraints. However, it is challenging to compute a policy that guarantees satisfying the cost constraints in the offline RL setting, since the off-policy evaluation inherently has an estimation error. In this paper, we present an offline constrained RL algorithm that optimizes the policy in the space of the stationary distribution. Our algorithm, COptiDICE, directly estimates the stationary distribution corrections of the optimal policy with respect to returns, while constraining the cost upper bound, with the goal of yielding a cost-conservative policy for actual constraint satisfaction. Experimental results show that COptiDICE attains better policies in terms of constraint satisfaction and return-maximization, outperforming baseline algorithms.",
        "conference": "ICLR",
        "中文标题": "COptiDICE：通过稳态分布修正估计的离线约束强化学习",
        "摘要翻译": "我们考虑离线约束强化学习（RL）问题，在该问题中，智能体的目标是计算一个策略，该策略在满足给定成本约束的同时最大化预期回报，仅从预先收集的数据集中学习。这一问题设置在许多现实世界场景中具有吸引力，其中直接与环境交互成本高昂或存在风险，并且所得策略应遵守安全约束。然而，在离线RL设置中计算一个保证满足成本约束的策略是具有挑战性的，因为离策略评估本质上存在估计误差。在本文中，我们提出了一种离线约束RL算法，该算法在稳态分布的空间中优化策略。我们的算法COptiDICE直接估计最优策略相对于回报的稳态分布修正，同时约束成本上限，旨在为实际约束满足产生一个成本保守的策略。实验结果表明，COptiDICE在约束满足和回报最大化方面获得了更好的策略，优于基线算法。",
        "领域": "强化学习、安全约束学习、离线学习",
        "问题": "在仅使用预先收集的数据集的情况下，如何计算一个既最大化预期回报又满足给定成本约束的策略。",
        "动机": "解决在直接与环境交互成本高昂或存在风险的情况下，如何安全有效地学习遵守约束的策略的问题。",
        "方法": "提出了一种离线约束RL算法COptiDICE，通过在稳态分布的空间中优化策略，直接估计最优策略的稳态分布修正，并约束成本上限。",
        "关键词": [
            "离线强化学习",
            "约束优化",
            "稳态分布修正",
            "成本保守策略",
            "安全约束"
        ],
        "涉及的技术概念": {
            "稳态分布修正": "用于直接估计最优策略相对于回报的修正，以优化策略。",
            "成本约束": "在策略优化过程中，确保策略满足预定的安全或成本限制。",
            "离线强化学习": "仅从预先收集的数据集中学习策略，不与环境直接交互。"
        },
        "success": true
    },
    {
        "order": 177,
        "title": "cosFormer: Rethinking Softmax In Attention",
        "html": "https://iclr.cc//virtual/2022/poster/6040",
        "abstract": "Transformer has shown great successes in natural language processing, computer vision, and audio processing. As one of its core components, the softmax attention helps to capture long-range dependencies yet prohibits its scale-up due to the quadratic space and time complexity to the sequence length. Kernel methods are often adopted to reduce the complexity by approximating the softmax operator. Nevertheless, due to the approximation errors, their performances vary in different tasks/corpus and suffer crucial performance drops when compared with the vanilla softmax attention. In this paper, we propose a linear transformer called cosFormer that can achieve comparable or better accuracy to the vanilla transformer in both casual and cross attentions. cosFormer is based on two key properties of softmax attention: i). non-negativeness of the attention matrix; ii). a non-linear re-weighting scheme that can concentrate the distribution of the attention matrix. As its linear substitute, cosFormer fulfills these properties with a linear operator and a cosine-based distance re-weighting mechanism. Extensive experiments on language modeling and text understanding tasks demonstrate the effectiveness of our method. We further examine our method on long sequences and achieve state-of-the-art performance on the Long-Range Arena benchmark. The source code is available at https://github.com/OpenNLPLab/cosFormer.",
        "conference": "ICLR",
        "中文标题": "cosFormer：重新思考注意力机制中的Softmax",
        "摘要翻译": "Transformer在自然语言处理、计算机视觉和音频处理领域取得了巨大成功。作为其核心组件之一，softmax注意力机制有助于捕捉长距离依赖关系，但由于其与序列长度的二次空间和时间复杂度，限制了其扩展性。通常采用核方法来通过近似softmax操作符来降低复杂度。然而，由于近似误差，它们在不同任务/语料库中的表现各异，并且与原始softmax注意力相比，性能有显著下降。在本文中，我们提出了一种名为cosFormer的线性Transformer，它可以在因果注意力和交叉注意力中实现与原始Transformer相当或更好的准确性。cosFormer基于softmax注意力的两个关键属性：i) 注意力矩阵的非负性；ii) 可以集中注意力矩阵分布的非线性重加权方案。作为其线性替代品，cosFormer通过线性操作符和基于余弦的距离重加权机制实现了这些属性。在语言建模和文本理解任务上的大量实验证明了我们方法的有效性。我们进一步在长序列上检验了我们的方法，并在Long-Range Arena基准测试中取得了最先进的性能。源代码可在https://github.com/OpenNLPLab/cosFormer获取。",
        "领域": "自然语言处理与视觉结合",
        "问题": "解决softmax注意力机制在长序列处理中的高计算复杂度问题",
        "动机": "为了降低Transformer模型在处理长序列时的计算复杂度，同时保持或提升模型性能",
        "方法": "提出cosFormer，一种基于线性操作符和余弦距离重加权机制的线性Transformer，以替代传统的softmax注意力机制",
        "关键词": [
            "线性Transformer",
            "注意力机制",
            "长序列处理",
            "余弦距离",
            "计算效率"
        ],
        "涉及的技术概念": {
            "线性Transformer": "通过线性操作符替代softmax，降低计算复杂度",
            "余弦距离重加权机制": "用于集中注意力矩阵的分布，保持注意力机制的关键属性",
            "Long-Range Arena基准测试": "用于评估模型在长序列处理任务上的性能"
        },
        "success": true
    },
    {
        "order": 178,
        "title": "CoST: Contrastive Learning of Disentangled Seasonal-Trend Representations for Time Series Forecasting",
        "html": "https://iclr.cc//virtual/2022/poster/6829",
        "abstract": "Deep learning has been actively studied for time series forecasting, and the mainstream paradigm is based on the end-to-end training of neural network architectures, ranging from classical LSTM/RNNs to more recent TCNs and Transformers. Motivated by the recent success of representation learning in computer vision and natural language processing, we argue that a more promising paradigm for time series forecasting, is to first learn disentangled feature representations, followed by a simple regression fine-tuning step -- we justify such a paradigm from a causal perspective. Following this principle, we propose a new time series representation learning framework for long sequence time series forecasting named CoST, which applies contrastive learning methods to learn disentangled seasonal-trend representations. CoST comprises both time domain and frequency domain contrastive losses to learn discriminative trend and seasonal representations, respectively. Extensive experiments on real-world datasets show that CoST consistently outperforms the state-of-the-art methods by a considerable margin, achieving a 21.3% improvement in MSE on multivariate benchmarks. It is also robust to various choices of backbone encoders, as well as downstream regressors. Code is available at https://github.com/salesforce/CoST.",
        "conference": "ICLR",
        "中文标题": "CoST：时间序列预测中解耦季节-趋势表示的对比学习",
        "摘要翻译": "深度学习在时间序列预测领域得到了积极研究，主流范式基于从经典LSTM/RNN到更近期的TCN和Transformer等神经网络架构的端到端训练。受到计算机视觉和自然语言处理中表示学习近期成功的启发，我们认为时间序列预测的一个更有前景的范式是首先学习解耦的特征表示，然后进行简单的回归微调步骤——我们从因果关系的角度论证了这一范式的合理性。遵循这一原则，我们提出了一个名为CoST的新时间序列表示学习框架，用于长序列时间序列预测，该框架应用对比学习方法来学习解耦的季节-趋势表示。CoST包括时间域和频率域对比损失，分别用于学习区分性趋势和季节性表示。在真实世界数据集上的大量实验表明，CoST始终以相当大的优势优于最先进的方法，在多元基准测试中实现了MSE 21.3%的改进。它对各种骨干编码器以及下游回归器的选择也具有鲁棒性。代码可在https://github.com/salesforce/CoST获取。",
        "领域": "时间序列预测、表示学习、对比学习",
        "问题": "如何有效地解耦时间序列中的季节性和趋势性特征以提升预测性能",
        "动机": "受到计算机视觉和自然语言处理中表示学习成功的启发，探索通过解耦特征表示提升时间序列预测性能的新范式",
        "方法": "提出CoST框架，应用时间域和频率域的对比学习方法学习解耦的季节-趋势表示，后进行回归微调",
        "关键词": [
            "时间序列预测",
            "解耦表示",
            "对比学习",
            "季节性-趋势分解",
            "表示学习"
        ],
        "涉及的技术概念": {
            "对比学习": "用于学习区分性季节和趋势表示的技术，通过时间域和频率域的对比损失实现",
            "解耦表示": "将时间序列数据分解为季节性和趋势性两部分，分别进行特征学习和预测",
            "时间序列预测": "预测未来时间点的数据值，CoST框架通过解耦和对比学习提升预测准确性和鲁棒性"
        },
        "success": true
    },
    {
        "order": 179,
        "title": "Counterfactual Plans under Distributional Ambiguity",
        "html": "https://iclr.cc//virtual/2022/poster/6806",
        "abstract": "Counterfactual explanations are attracting significant attention due to the flourishing applications of machine learning models in consequential domains. A counterfactual plan consists of multiple possibilities to modify a given instance so that the model's prediction will be altered. As the predictive model can be updated subject to the future arrival of new data, a counterfactual plan may become ineffective or infeasible, with respect to the future values of the model parameters. In this work, we study the counterfactual plans under model uncertainty, in which the distribution of the model parameters is partially prescribed using only the first- and second-moment information. First, we propose an uncertainty quantification tool to compute the lower and upper bounds of the probability of feasibility for any given counterfactual plan. We then provide corrective methods to adjust the counterfactual plan to improve the feasibility measure. The numerical experiments validate our bounds and demonstrate that our correction increases the robustness of the counterfactual plans in different real-world datasets.",
        "conference": "ICLR",
        "中文标题": "分布模糊性下的反事实计划",
        "摘要翻译": "由于机器学习模型在重要领域的广泛应用，反事实解释正受到极大关注。一个反事实计划包含多种修改给定实例的可能性，从而改变模型的预测。由于预测模型可能会随着新数据的到来而更新，反事实计划可能会变得无效或不可行，这取决于模型参数的未来值。在这项工作中，我们研究了模型不确定性下的反事实计划，其中模型参数的分布仅通过一阶和二阶矩信息部分规定。首先，我们提出了一种不确定性量化工具，用于计算任何给定反事实计划可行性的概率上下界。然后，我们提供了纠正方法，以调整反事实计划，提高可行性度量。数值实验验证了我们的界限，并证明了我们的纠正方法在不同真实世界数据集中增加了反事实计划的鲁棒性。",
        "领域": "机器学习解释性、模型不确定性分析、反事实推理",
        "问题": "研究在模型参数分布不完全确定的情况下，如何评估和调整反事实计划的可行性。",
        "动机": "由于机器学习模型在重要决策领域的应用日益增多，确保反事实解释的鲁棒性和有效性变得尤为重要。",
        "方法": "提出了一种基于一阶和二阶矩信息的不确定性量化工具，以及纠正方法来调整反事实计划以提高其可行性。",
        "关键词": [
            "反事实解释",
            "模型不确定性",
            "可行性分析",
            "鲁棒性调整",
            "机器学习解释性"
        ],
        "涉及的技术概念": {
            "反事实计划": "包含多种修改实例以改变模型预测可能性的计划，用于解释模型决策。",
            "模型不确定性": "指模型参数未来值的不确定性，影响反事实计划的有效性。",
            "一阶和二阶矩信息": "用于部分描述模型参数分布的信息，包括均值和方差，帮助量化不确定性。"
        },
        "success": true
    },
    {
        "order": 180,
        "title": "C-Planning: An Automatic Curriculum for Learning Goal-Reaching Tasks",
        "html": "https://iclr.cc//virtual/2022/poster/6882",
        "abstract": "Goal-conditioned reinforcement learning (RL) has shown great success recently at solving a wide range of tasks(e.g., navigation, robotic manipulation). However, learning to reach distant goals remains a central challenge to the field, and the task is particularly hard without any offline data, expert demonstrations, and reward shaping. In this paper, we propose to solve the distant goal-reaching task by using search at training time to generate a curriculum of intermediate states.  Specifically, we introduce the algorithm Classifier-Planning (C-Planning) by framing the learning of the goal-conditioned policies as variational inference. C-Planning naturally follows expectation maximization (EM): the E-step corresponds to planning an optimal sequence of waypoints using graph search, while the M-step aims to learn a goal-conditioned policy to reach those waypoints. One essential difficulty of designing such an algorithm is accurately modeling the distribution over way-points to sample from. In C-Planning, we propose to sample the waypoints using contrastive methods to learn a value function. Unlike prior methods that combine goal-conditioned RL with graph search, ours performs search only during training and not testing, significantly decreasing the compute costs of deploying the learned policy.  Empirically,  we demonstrate that our method not only improves the sample efficiency of prior methods but also successfully solves temporally extended navigation and manipulation tasks,  where prior goal-conditioned RL methods (including those based on graph search) fail to solve.",
        "conference": "ICLR",
        "中文标题": "C-规划：学习目标达成任务的自动课程",
        "摘要翻译": "目标条件强化学习（RL）最近在解决广泛的任务（例如导航、机器人操作）方面取得了巨大成功。然而，学习达到远距离目标仍然是该领域的核心挑战，特别是在没有任何离线数据、专家演示和奖励塑造的情况下，这项任务尤其困难。在本文中，我们提出通过在训练时使用搜索来生成中间状态的课程，以解决远距离目标达成任务。具体来说，我们通过将目标条件策略的学习框架化为变分推理，引入了分类器-规划（C-Planning）算法。C-Planning自然地遵循期望最大化（EM）：E步骤对应于使用图搜索规划最优路径点序列，而M步骤旨在学习一个目标条件策略以达到这些路径点。设计这种算法的一个基本困难是准确建模从中采样的路径点分布。在C-Planning中，我们提出使用对比方法来采样路径点以学习价值函数。与之前将目标条件RL与图搜索相结合的方法不同，我们的方法仅在训练时进行搜索，而不在测试时进行，这大大降低了部署学习策略的计算成本。实证上，我们证明了我们的方法不仅提高了先前方法的样本效率，而且成功解决了时间扩展的导航和操作任务，这些任务先前的目标条件RL方法（包括基于图搜索的方法）未能解决。",
        "领域": "机器人操作、导航算法、强化学习",
        "问题": "解决在无离线数据、专家演示和奖励塑造条件下，学习达到远距离目标的挑战。",
        "动机": "提高目标条件强化学习在远距离目标达成任务中的效率和成功率。",
        "方法": "通过在训练时使用图搜索生成中间状态的课程，并采用变分推理框架学习目标条件策略。",
        "关键词": [
            "目标条件强化学习",
            "自动课程学习",
            "变分推理",
            "图搜索",
            "对比学习"
        ],
        "涉及的技术概念": {
            "变分推理": "用于框架化目标条件策略的学习，将问题转化为概率模型的优化问题。",
            "期望最大化（EM）": "算法遵循的优化框架，E步进行路径点规划，M步学习达到路径点的策略。",
            "对比学习": "用于采样路径点以学习价值函数，帮助准确建模路径点分布。"
        },
        "success": true
    },
    {
        "order": 181,
        "title": "Creating Training Sets via Weak Indirect Supervision",
        "html": "https://iclr.cc//virtual/2022/poster/6191",
        "abstract": "Creating labeled training sets has become one of the major roadblocks in machine learning. To address this, recent Weak Supervision (WS) frameworks synthesize training labels from multiple potentially noisy supervision sources. However, existing frameworks are restricted to supervision sources that share the same output space as the target task. To extend the scope of usable sources, we formulate Weak Indirect Supervision (WIS), a new research problem for automatically synthesizing training labels based on indirect supervision sources that have different output label spaces. To overcome the challenge of mismatched output spaces, we develop a probabilistic modeling approach, PLRM, which uses user-provided label relations to model and leverage indirect supervision sources. Moreover, we provide a theoretically-principled test of the distinguishability of PLRM for unseen labels, along with an generalization bound. On both image and text classification tasks as well as an industrial advertising application, we demonstrate the advantages of PLRM by outperforming baselines by a margin of 2%-9%.",
        "conference": "ICLR",
        "中文标题": "通过弱间接监督创建训练集",
        "摘要翻译": "创建标记的训练集已成为机器学习中的主要障碍之一。为了解决这个问题，近期的弱监督（WS）框架从多个可能含有噪声的监督源中合成训练标签。然而，现有的框架仅限于与目标任务共享相同输出空间的监督源。为了扩展可用源的范围，我们提出了弱间接监督（WIS），这是一个新的研究问题，旨在基于具有不同输出标签空间的间接监督源自动合成训练标签。为了克服输出空间不匹配的挑战，我们开发了一种概率建模方法PLRM，该方法使用用户提供的标签关系来建模和利用间接监督源。此外，我们提供了PLRM对于未见标签的可区分性的理论原理测试，以及一个泛化边界。在图像和文本分类任务以及一个工业广告应用上，我们通过比基线高出2%-9%的优势展示了PLRM的优点。",
        "领域": "弱监督学习、图像分类、文本分类",
        "问题": "如何利用输出空间不同的间接监督源自动合成训练标签",
        "动机": "解决现有弱监督框架局限于与目标任务共享相同输出空间的监督源的问题，扩展可用监督源的范围",
        "方法": "开发了一种概率建模方法PLRM，利用用户提供的标签关系来建模和利用间接监督源，并提供了理论原理测试和泛化边界",
        "关键词": [
            "弱间接监督",
            "概率建模",
            "标签关系",
            "图像分类",
            "文本分类"
        ],
        "涉及的技术概念": {
            "弱间接监督（WIS）": "一种新的研究问题，旨在基于具有不同输出标签空间的间接监督源自动合成训练标签",
            "概率建模方法PLRM": "使用用户提供的标签关系来建模和利用间接监督源的方法",
            "泛化边界": "为PLRM提供的理论保证，确保其在未见数据上的性能"
        },
        "success": true
    },
    {
        "order": 182,
        "title": "Critical Points in Quantum Generative Models",
        "html": "https://iclr.cc//virtual/2022/poster/6777",
        "abstract": "One of the most important properties of neural networks is the clustering of local minima of the loss function near the global minimum, enabling efficient training. Though generative models implemented on quantum computers are known to be more expressive than their traditional counterparts, it has empirically been observed that these models experience a transition in the quality of their local minima. Namely, below some critical number of parameters, all local minima are far from the global minimum in function value; above this critical parameter count, all local minima are good approximators of the global minimum. Furthermore, for a certain class of quantum generative models, this transition has empirically been observed to occur at parameter counts exponentially large in the problem size, meaning practical training of these models is out of reach. Here, we give the first proof of this transition in trainability, specializing to this latter class of quantum generative model. We use techniques inspired by those used to study the loss landscapes of classical neural networks. We also verify that our analytic results hold experimentally even at modest model sizes.",
        "conference": "ICLR",
        "中文标题": "量子生成模型中的临界点",
        "摘要翻译": "神经网络最重要的特性之一是损失函数的局部最小值在全局最小值附近聚集，这使得训练变得高效。尽管已知在量子计算机上实现的生成模型比传统模型更具表达力，但经验观察发现，这些模型的局部最小值质量会经历一个转变。具体来说，在参数数量低于某个临界值时，所有局部最小值在函数值上都远离全局最小值；超过这个临界参数数量后，所有局部最小值都是全局最小值的良好近似。此外，对于某一类量子生成模型，经验观察表明这一转变发生在参数数量随问题规模指数级增长的情况下，这意味着这些模型的实际训练是不可行的。在此，我们首次证明了这种训练能力的转变，专门针对后一类量子生成模型。我们采用了受研究经典神经网络损失景观技术启发的方法。我们还验证了我们的分析结果在适度模型大小下也成立。",
        "领域": "量子机器学习、生成模型、神经网络优化",
        "问题": "量子生成模型在参数数量变化时局部最小值质量的转变问题",
        "动机": "理解量子生成模型训练能力转变的机制，以指导模型设计和训练策略",
        "方法": "采用受经典神经网络损失景观研究启发的技术，分析量子生成模型的训练能力转变",
        "关键词": [
            "量子生成模型",
            "局部最小值",
            "训练能力转变",
            "临界参数数量",
            "损失函数"
        ],
        "涉及的技术概念": {
            "量子生成模型": "在量子计算机上实现的生成模型，比传统模型更具表达力",
            "局部最小值": "损失函数中的局部最优解，其质量影响模型的训练效果",
            "训练能力转变": "模型在参数数量达到临界值时，局部最小值质量发生的显著变化"
        },
        "success": true
    },
    {
        "order": 183,
        "title": "CROP: Certifying Robust Policies for Reinforcement Learning through Functional Smoothing",
        "html": "https://iclr.cc//virtual/2022/poster/6676",
        "abstract": "As reinforcement learning (RL) has achieved great success and been even adopted in safety-critical domains such as autonomous vehicles, a range of empirical studies have been conducted to improve its robustness against adversarial attacks. However, how to certify its robustness with theoretical guarantees still remains challenging. In this paper, we present the ﬁrst uniﬁed framework CROP (Certifying Robust Policies for RL) to provide robustness certiﬁcation on both action and reward levels. In particular, we propose two robustness certiﬁcation criteria: robustness of per-state actions and lower bound of cumulative rewards. We then develop a local smoothing algorithm for policies derived from Q-functions to guarantee the robustness of actions taken along the trajectory; we also develop a global smoothing algorithm for certifying the lower bound of a ﬁnite-horizon cumulative reward, as well as a novel local smoothing algorithm to perform adaptive search in order to obtain tighter reward certiﬁcation. Empirically, we apply CROP to evaluate several existing empirically robust RL algorithms, including adversarial training and different robust regularization, in four environments (two representative Atari games, Highway, and CartPole). Furthermore, by evaluating these algorithms against adversarial attacks, we demonstrate that our certiﬁcations are often tight. All experiment results are available at website https://crop-leaderboard.github.io.",
        "conference": "ICLR",
        "中文标题": "CROP：通过功能平滑为强化学习认证稳健策略",
        "摘要翻译": "随着强化学习（RL）取得巨大成功，甚至被应用于自动驾驶等安全关键领域，一系列实证研究已经开展以提高其对抗对抗性攻击的鲁棒性。然而，如何通过理论保证来认证其鲁棒性仍然具有挑战性。在本文中，我们提出了第一个统一框架CROP（为RL认证稳健策略），以在动作和奖励级别上提供鲁棒性认证。具体而言，我们提出了两个鲁棒性认证标准：每状态动作的鲁棒性和累积奖励的下界。然后，我们为从Q函数导出的策略开发了一个局部平滑算法，以保证沿轨迹采取的动作的鲁棒性；我们还开发了一个全局平滑算法来认证有限视野累积奖励的下界，以及一个新颖的局部平滑算法来执行自适应搜索，以获得更严格的奖励认证。实证上，我们将CROP应用于评估几种现有的实证鲁棒RL算法，包括对抗性训练和不同的鲁棒正则化，在四个环境中（两个代表性的Atari游戏，Highway和CartPole）。此外，通过评估这些算法对抗对抗性攻击，我们证明了我们的认证往往是严格的。所有实验结果可在网站https://crop-leaderboard.github.io上获取。",
        "领域": "强化学习安全、对抗性攻击防御、自动驾驶策略优化",
        "问题": "如何在强化学习中提供理论保证的鲁棒性认证",
        "动机": "强化学习在安全关键领域的应用需要确保其策略对对抗性攻击的鲁棒性，但目前缺乏理论保证的认证方法",
        "方法": "提出了一个统一框架CROP，包括局部和全局平滑算法，用于认证动作和奖励级别的鲁棒性",
        "关键词": [
            "强化学习",
            "鲁棒性认证",
            "对抗性攻击",
            "功能平滑",
            "自动驾驶"
        ],
        "涉及的技术概念": {
            "功能平滑": "用于提高策略对输入微小变化的鲁棒性，确保在对抗性攻击下的稳定性",
            "Q函数": "用于评估在给定状态下采取特定动作的长期奖励，是策略优化的基础",
            "对抗性训练": "通过在训练过程中引入对抗性样本，提高模型对对抗性攻击的抵抗能力"
        },
        "success": true
    },
    {
        "order": 184,
        "title": "CrossBeam: Learning to Search in Bottom-Up Program Synthesis",
        "html": "https://iclr.cc//virtual/2022/poster/7036",
        "abstract": "Many approaches to program synthesis perform a search within an enormous space of programs to find one that satisfies a given specification. Prior works have used neural models to guide combinatorial search algorithms, but such approaches still explore a huge portion of the search space and quickly become intractable as the size of the desired program increases. To tame the search space blowup, we propose training a neural model to learn a hands-on search policy for bottom-up synthesis, instead of relying on a combinatorial search algorithm. Our approach, called CrossBeam, uses the neural model to choose how to combine previously-explored programs into new programs, taking into account the search history and partial program executions. Motivated by work in structured prediction on learning to search, CrossBeam is trained on-policy using data extracted from its own bottom-up searches on training tasks. We evaluate CrossBeam in two very different domains, string manipulation and logic programming. We observe that CrossBeam learns to search efficiently, exploring much smaller portions of the program space compared to the state-of-the-art.",
        "conference": "ICLR",
        "中文标题": "CrossBeam：学习在自底向上程序综合中进行搜索",
        "摘要翻译": "许多程序综合方法在一个巨大的程序空间内进行搜索，以找到一个满足给定规范的程序。先前的工作已经使用神经模型来指导组合搜索算法，但这种方法仍然探索了搜索空间的很大一部分，并且随着所需程序规模的增加，很快变得难以处理。为了控制搜索空间的爆炸性增长，我们提出训练一个神经模型来学习自底向上综合的实际搜索策略，而不是依赖组合搜索算法。我们的方法，称为CrossBeam，使用神经模型来选择如何将之前探索过的程序组合成新程序，同时考虑搜索历史和部分程序的执行。受到结构化预测中学习搜索工作的启发，CrossBeam通过从其在训练任务上的自底向上搜索中提取的数据进行策略上的训练。我们在两个非常不同的领域，字符串操作和逻辑编程中评估CrossBeam。我们观察到，CrossBeam学会了高效搜索，与现有技术相比，探索了程序空间的更小部分。",
        "领域": "程序综合、机器学习、自动化编程",
        "问题": "如何在巨大的程序空间中高效地搜索满足给定规范的程序",
        "动机": "解决现有组合搜索算法在程序综合中探索空间过大、随着程序规模增加变得难以处理的问题",
        "方法": "训练神经模型学习自底向上综合的实际搜索策略，替代组合搜索算法",
        "关键词": [
            "程序综合",
            "神经模型",
            "自底向上搜索",
            "结构化预测",
            "搜索策略"
        ],
        "涉及的技术概念": {
            "自底向上程序综合": "一种程序构建方法，从基础组件开始逐步构建更复杂的程序",
            "神经模型": "用于学习和预测搜索策略的机器学习模型",
            "结构化预测": "一种机器学习方法，用于预测结构化输出，如程序"
        },
        "success": true
    },
    {
        "order": 185,
        "title": "Cross-Domain Imitation Learning via Optimal Transport",
        "html": "https://iclr.cc//virtual/2022/poster/6198",
        "abstract": "Cross-domain imitation learning studies how to leverage expert demonstrations of one agent to train an imitation agent with a different embodiment or morphology. Comparing trajectories and stationary distributions between the expert and imitation agents is challenging because they live on different systems that may not even have the same dimensionality. We propose Gromov-Wasserstein Imitation Learning (GWIL), a method for cross-domain imitation that uses the Gromov-Wasserstein distance to align and compare states between the different spaces of the agents. Our theory formally characterizes the scenarios where GWIL preserves optimality, revealing its possibilities and limitations. We demonstrate the effectiveness of GWIL in non-trivial continuous control domains ranging from simple rigid transformation of the expert domain to arbitrary transformation of the state-action space.",
        "conference": "ICLR",
        "中文标题": "基于最优传输的跨域模仿学习",
        "摘要翻译": "跨域模仿学习研究如何利用一个智能体的专家演示来训练具有不同体现或形态的模仿智能体。由于专家和模仿智能体存在于不同的系统中，这些系统甚至可能不具有相同的维度，因此比较它们之间的轨迹和稳态分布具有挑战性。我们提出了Gromov-Wasserstein模仿学习（GWIL），这是一种用于跨域模仿的方法，它使用Gromov-Wasserstein距离来对齐和比较智能体不同空间之间的状态。我们的理论正式描述了GWIL保持最优性的场景，揭示了其可能性和局限性。我们在从专家域的简单刚性变换到状态-动作空间的任意变换的非平凡连续控制领域中展示了GWIL的有效性。",
        "领域": "模仿学习、最优传输、连续控制",
        "问题": "如何在不同体现或形态的智能体之间进行有效的模仿学习",
        "动机": "解决跨域模仿学习中由于智能体体现或形态不同导致的轨迹和稳态分布比较难题",
        "方法": "使用Gromov-Wasserstein距离对齐和比较不同智能体空间之间的状态",
        "关键词": [
            "跨域模仿学习",
            "最优传输",
            "Gromov-Wasserstein距离",
            "连续控制",
            "状态对齐"
        ],
        "涉及的技术概念": {
            "Gromov-Wasserstein距离": "用于对齐和比较不同空间之间的状态，解决跨域模仿学习中的状态对齐问题",
            "最优传输": "提供了一种理论基础，用于在不同概率分布之间找到最优的传输方案，应用于跨域模仿学习中的状态对齐",
            "连续控制": "研究领域，涉及在连续状态和动作空间中控制智能体的行为，GWIL方法在此领域展示了有效性"
        },
        "success": true
    },
    {
        "order": 186,
        "title": "CrossFormer: A Versatile Vision Transformer Hinging on Cross-scale Attention",
        "html": "https://iclr.cc//virtual/2022/poster/6267",
        "abstract": "Transformers have made great progress in dealing with computer vision tasks. However, existing vision transformers have not yet possessed the ability of building the interactions among features of different scales, which is perceptually important to visual inputs. The reasons are two-fold: (1) Input embeddings of each layer are equal-scale, so no cross-scale feature can be extracted; (2) to lower the computational cost, some vision transformers merge adjacent embeddings inside the self-attention module, thus sacrificing small-scale (fine-grained) features of the embeddings and also disabling the cross-scale interactions. To this end, we propose Cross-scale Embedding Layer (CEL) and Long Short Distance Attention (LSDA). On the one hand, CEL blends each embedding with multiple patches of different scales, providing the self-attention module itself with cross-scale features. On the other hand, LSDA splits the self-attention module into a short-distance one and a long-distance counterpart, which not only reduces the computational burden but also keeps both small-scale and large-scale features in the embeddings. Through the above two designs, we achieve cross-scale attention. Besides, we put forward a dynamic position bias for vision transformers to make the popular relative position bias apply to variable-sized images. Hinging on the cross-scale attention module, we construct a versatile vision architecture, dubbed CrossFormer, which accommodates variable-sized inputs. Extensive experiments show that CrossFormer outperforms the other vision transformers on image classification, object detection, instance segmentation, and semantic segmentation tasks.",
        "conference": "ICLR",
        "中文标题": "CrossFormer：一种基于跨尺度注意力的多功能视觉Transformer",
        "摘要翻译": "Transformer在处理计算机视觉任务方面取得了巨大进展。然而，现有的视觉Transformer尚未具备在不同尺度特征之间建立交互的能力，这对于视觉输入感知上非常重要。原因有二：（1）每一层的输入嵌入是等尺度的，因此无法提取跨尺度特征；（2）为了降低计算成本，一些视觉Transformer在自注意力模块内部合并相邻的嵌入，从而牺牲了嵌入的小尺度（细粒度）特征，同时也禁用了跨尺度交互。为此，我们提出了跨尺度嵌入层（CEL）和长短距离注意力（LSDA）。一方面，CEL将每个嵌入与不同尺度的多个补丁混合，为自注意力模块本身提供跨尺度特征。另一方面，LSDA将自注意力模块分为短距离和长距离两部分，不仅减少了计算负担，还保留了嵌入中的小尺度和大尺度特征。通过上述两种设计，我们实现了跨尺度注意力。此外，我们还为视觉Transformer提出了动态位置偏置，使得流行的相对位置偏置适用于可变大小的图像。基于跨尺度注意力模块，我们构建了一个多功能的视觉架构，称为CrossFormer，它适应可变大小的输入。大量实验表明，CrossFormer在图像分类、目标检测、实例分割和语义分割任务上优于其他视觉Transformer。",
        "领域": "图像分类, 目标检测, 语义分割",
        "问题": "现有视觉Transformer无法在不同尺度特征之间建立有效的交互",
        "动机": "提升视觉Transformer在处理不同尺度特征时的交互能力，以更好地适应视觉输入的需求",
        "方法": "提出跨尺度嵌入层（CEL）和长短距离注意力（LSDA），通过混合不同尺度的特征和分割自注意力模块来实现跨尺度注意力",
        "关键词": [
            "跨尺度注意力",
            "视觉Transformer",
            "动态位置偏置"
        ],
        "涉及的技术概念": {
            "跨尺度嵌入层（CEL）": "将每个嵌入与不同尺度的多个补丁混合，为自注意力模块提供跨尺度特征",
            "长短距离注意力（LSDA）": "将自注意力模块分为短距离和长距离两部分，减少计算负担同时保留不同尺度的特征",
            "动态位置偏置": "使相对位置偏置适用于可变大小的图像，增强模型对不同尺寸输入的适应性"
        },
        "success": true
    },
    {
        "order": 187,
        "title": "Cross-Lingual Transfer with Class-Weighted Language-Invariant Representations",
        "html": "https://iclr.cc//virtual/2022/poster/6898",
        "abstract": "Recent advances in neural modeling have produced deep multilingual language models capable of extracting cross-lingual knowledge from non-parallel texts and enabling zero-shot downstream transfer. While their success is often attributed to shared representations, quantitative analyses are limited. Towards a better understanding, through empirical analyses, we show that the invariance of feature representations across languages—an effect of shared representations—strongly correlates with transfer performance. We also observe that distributional shifts in class priors between source and target language task data negatively affect performance, a largely overlooked issue that could cause negative transfer with existing unsupervised approaches. Based on these findings, we propose and evaluate a method for unsupervised transfer, called importance-weighted domain alignment (IWDA), that performs representation alignment with prior shift estimation and correction using unlabeled target language task data. Experiments demonstrate its superiority under large prior shifts, and show further performance gains when combined with existing semi-supervised learning techniques.",
        "conference": "ICLR",
        "中文标题": "跨语言迁移与类别加权的语言不变表示",
        "摘要翻译": "神经建模的最新进展已经产生了能够从非平行文本中提取跨语言知识并实现零样本下游迁移的深度多语言语言模型。虽然它们的成功常归因于共享表示，但定量分析有限。为了更好地理解，通过实证分析，我们展示了跨语言特征表示的不变性——共享表示的一个效应——与迁移性能密切相关。我们还观察到，源语言和目标语言任务数据之间类别先验的分布偏移会对性能产生负面影响，这是一个很大程度上被忽视的问题，可能导致现有无监督方法的负迁移。基于这些发现，我们提出并评估了一种名为重要性加权领域对齐（IWDA）的无监督迁移方法，该方法利用未标记的目标语言任务数据进行表示对齐，同时进行先验偏移估计和校正。实验证明，在先验偏移较大的情况下，IWDA具有优越性，并且在与现有的半监督学习技术结合时，显示出进一步的性能提升。",
        "领域": "自然语言处理与视觉结合, 跨语言学习, 无监督学习",
        "问题": "解决跨语言迁移中由于类别先验分布偏移导致的性能下降问题",
        "动机": "探索跨语言迁移性能与特征表示不变性之间的关系，并提出解决类别先验分布偏移的方法",
        "方法": "提出重要性加权领域对齐（IWDA）方法，通过表示对齐和先验偏移估计与校正来优化跨语言迁移",
        "关键词": [
            "跨语言迁移",
            "类别加权",
            "语言不变表示",
            "无监督学习",
            "领域对齐"
        ],
        "涉及的技术概念": {
            "跨语言特征表示的不变性": "共享表示的一个效应，与迁移性能密切相关",
            "类别先验的分布偏移": "源语言和目标语言任务数据之间的分布差异，影响迁移性能",
            "重要性加权领域对齐（IWDA）": "一种无监督迁移方法，通过表示对齐和先验偏移估计与校正来优化性能"
        },
        "success": true
    },
    {
        "order": 188,
        "title": "CrossMatch: Cross-Classifier Consistency Regularization for Open-Set Single Domain Generalization",
        "html": "https://iclr.cc//virtual/2022/poster/6139",
        "abstract": "Single domain generalization (SDG) is a challenging scenario of domain generalization, where only one source domain is available to train the model. Typical SDG methods are based on the adversarial data augmentation strategy, which complements the diversity of source domain to learn a robust model. Existing SDG methods require the source and target domains to have the same label space. However, as target domains may contain novel categories unseen in source label space, this assumption is not practical in many real-world applications. In this paper, we propose a challenging and untouched problem: \\textit{Open-Set Single Domain Generalization} (OS-SDG), where target domains include unseen categories out of source label space. The goal of OS-SDG is to learn a model, with only one source domain, to classify a target sample with correct class if it belongs to source label space, or assign it to unknown classes. We design a \\textit{CrossMatch} approach to improve the performance of SDG methods on identifying unknown classes by leveraging a multi-binary classifier. CrossMatch generates auxiliary samples out of source label space by using an adversarial data augmentation strategy. We also adopt a consistency regularization on generated auxiliary samples between multi-binary classifiers and the model trained by SDG methods, to improve the model’s capability on unknown class identification. Experimental results on benchmark datasets prove the effectiveness of CrossMatch on enhancing the performance of SDG methods in the OS-SDG setting.",
        "conference": "ICLR",
        "中文标题": "CrossMatch：用于开放集单域泛化的跨分类器一致性正则化",
        "摘要翻译": "单域泛化（SDG）是域泛化中的一个具有挑战性的场景，其中仅有一个源域可用于训练模型。典型的SDG方法基于对抗性数据增强策略，该策略补充了源域的多样性以学习一个鲁棒的模型。现有的SDG方法要求源域和目标域具有相同的标签空间。然而，由于目标域可能包含源标签空间中未见的新类别，这一假设在许多实际应用中并不实用。在本文中，我们提出了一个具有挑战性且尚未触及的问题：开放集单域泛化（OS-SDG），其中目标域包括源标签空间之外的未见类别。OS-SDG的目标是学习一个模型，仅使用一个源域，如果目标样本属于源标签空间，则将其分类为正确的类别，否则将其分配到未知类别。我们设计了一种CrossMatch方法，通过利用多二元分类器来提高SDG方法在识别未知类别上的性能。CrossMatch通过使用对抗性数据增强策略生成源标签空间之外的辅助样本。我们还采用了在生成的辅助样本上多二元分类器与SDG方法训练的模型之间的一致性正则化，以提高模型在未知类别识别上的能力。基准数据集上的实验结果证明了CrossMatch在OS-SDG设置中增强SDG方法性能的有效性。",
        "领域": "开放集识别、单域泛化、对抗性学习",
        "问题": "解决在单域泛化场景下，目标域包含源标签空间未见类别时的分类问题。",
        "动机": "现有的单域泛化方法假设源域和目标域具有相同的标签空间，这在现实应用中不切实际，因为目标域可能包含未见类别。",
        "方法": "提出CrossMatch方法，通过多二元分类器和对抗性数据增强策略生成辅助样本，并采用一致性正则化提高未知类别的识别能力。",
        "关键词": [
            "开放集识别",
            "单域泛化",
            "对抗性学习",
            "一致性正则化",
            "多二元分类器"
        ],
        "涉及的技术概念": {
            "对抗性数据增强": "用于生成源标签空间之外的辅助样本，增加模型的泛化能力。",
            "多二元分类器": "用于提高模型在识别未知类别上的性能。",
            "一致性正则化": "在生成的辅助样本上应用，以提高模型在未知类别识别上的能力。"
        },
        "success": true
    },
    {
        "order": 189,
        "title": "Cross-Trajectory Representation Learning for Zero-Shot Generalization in RL",
        "html": "https://iclr.cc//virtual/2022/poster/6350",
        "abstract": "A highly desirable property of a reinforcement learning (RL) agent -- and a major difficulty for deep RL approaches -- is the ability to generalize policies learned on a few tasks over a high-dimensional observation space to similar tasks not seen during training. Many promising approaches to this challenge consider RL as a process of training two functions simultaneously: a complex nonlinear encoder that maps high-dimensional observations to a latent representation space, and a simple linear policy over this space. We posit that a superior encoder for zero-shot generalization in RL can be trained by using solely an auxiliary SSL objective if the training process encourages the encoder to map behaviorally similar observations to similar representations, as reward-based signal can cause overfitting in the encoder (Raileanu et al., 2021). We propose Cross-Trajectory Representation Learning (CTRL), a method that runs within an RL agent and conditions its encoder to recognize behavioral similarity in observations by applying a novel SSL objective to pairs of trajectories from the agent's policies. CTRL can be viewed as having the same effect as inducing a pseudo-bisimulation metric but, crucially, avoids the use of rewards and associated overfitting risks. Our experiments ablate various components of CTRL and demonstrate that in combination with PPO it achieves better generalization performance on the challenging Procgen benchmark suite (Cobbe et al., 2020).  ",
        "conference": "ICLR",
        "中文标题": "跨轨迹表示学习用于强化学习中的零样本泛化",
        "摘要翻译": "强化学习（RL）代理的一个非常理想的属性——也是深度RL方法的一个主要难点——是能够将在高维观察空间上学习的少数任务策略泛化到训练期间未见过的类似任务。针对这一挑战，许多有前景的方法将RL视为同时训练两个函数的过程：一个复杂的非线性编码器，将高维观察映射到潜在表示空间，以及一个在这个空间上的简单线性策略。我们认为，如果训练过程鼓励编码器将行为相似的观察映射到相似的表示，那么仅通过辅助自监督学习（SSL）目标就可以训练出用于RL中零样本泛化的优秀编码器，因为基于奖励的信号可能导致编码器过拟合（Raileanu等人，2021）。我们提出了跨轨迹表示学习（CTRL），这是一种在RL代理内部运行的方法，通过对其编码器应用新颖的SSL目标到来自代理策略的轨迹对，使其能够识别观察中的行为相似性。CTRL可以被视为具有诱导伪双模拟度量的相同效果，但关键的是，它避免了使用奖励和相关的过拟合风险。我们的实验消融了CTRL的各种组件，并证明与PPO结合使用时，在具有挑战性的Procgen基准套件（Cobbe等人，2020）上实现了更好的泛化性能。",
        "领域": "强化学习、自监督学习、零样本学习",
        "问题": "如何在高维观察空间中实现强化学习策略的零样本泛化",
        "动机": "解决深度强化学习在高维观察空间中泛化能力不足的问题，避免因依赖奖励信号导致的编码器过拟合",
        "方法": "提出跨轨迹表示学习（CTRL）方法，通过自监督学习目标训练编码器识别行为相似的观察，避免使用奖励信号",
        "关键词": [
            "跨轨迹表示学习",
            "零样本泛化",
            "自监督学习",
            "强化学习",
            "Procgen基准"
        ],
        "涉及的技术概念": {
            "跨轨迹表示学习（CTRL）": "一种在强化学习代理内部运行的方法，通过自监督学习目标训练编码器识别行为相似的观察",
            "自监督学习（SSL）": "用于训练编码器的辅助目标，避免依赖奖励信号导致的过拟合",
            "伪双模拟度量": "CTRL方法的效果类似于诱导这种度量，但避免了使用奖励和相关的过拟合风险"
        },
        "success": true
    },
    {
        "order": 190,
        "title": "CrowdPlay: Crowdsourcing Human Demonstrations for Offline Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6086",
        "abstract": "Crowdsourcing has been instrumental for driving AI advances that rely on large-scale data. At the same time, reinforcement learning has seen rapid progress through  benchmark environments that strike a balance between tractability and real-world complexity, such as ALE and OpenAI Gym. In this paper, we aim to fill a gap at the intersection of these two: The use of crowdsourcing to generate large-scale human demonstration data in the support of advancing research into imitation learning and offline learning.To this end, we present CrowdPlay, a complete crowdsourcing pipeline for any standard RL environment including OpenAI Gym (made available under an open-source license); a large-scale publicly available crowdsourced dataset of human gameplay demonstrations in Atari 2600 games, including multimodal behavior and human-human and human-AI multiagent data; offline learning benchmarks with extensive human data evaluation; and a detailed study of incentives, including real-time feedback to drive high quality data.We hope that this will drive the improvement in design of algorithms that  account for the complexity of human, behavioral data and thereby enable a step forward in direction of effective learning for real-world settings. Our code and dataset are available at https://mgerstgrasser.github.io/crowdplay/.",
        "conference": "ICLR",
        "中文标题": "CrowdPlay：众包人类示范数据以支持离线学习",
        "摘要翻译": "众包在推动依赖大规模数据的AI进步方面发挥了关键作用。与此同时，通过如ALE和OpenAI Gym这样在可处理性和现实世界复杂性之间取得平衡的基准环境，强化学习取得了快速进展。在本文中，我们旨在填补这两者之间的一个空白：利用众包生成大规模人类示范数据，以支持模仿学习和离线学习的研究进展。为此，我们提出了CrowdPlay，一个适用于包括OpenAI Gym在内的任何标准RL环境的完整众包流程（以开源许可证提供）；一个大规模公开可用的众包数据集，包含Atari 2600游戏中的人类游戏示范，包括多模态行为以及人-人和人-AI多智能体数据；带有广泛人类数据评估的离线学习基准；以及关于激励措施的详细研究，包括实时反馈以驱动高质量数据。我们希望这将推动算法的设计改进，考虑到人类行为数据的复杂性，从而在有效学习现实世界设置的方向上迈出一步。我们的代码和数据集可在https://mgerstgrasser.github.io/crowdplay/获取。",
        "领域": "模仿学习, 离线学习, 多智能体系统",
        "问题": "如何利用众包生成大规模人类示范数据以支持模仿学习和离线学习的研究",
        "动机": "填补众包与强化学习之间的空白，推动算法的设计改进，考虑到人类行为数据的复杂性",
        "方法": "提出了CrowdPlay，一个完整的众包流程，包括开源许可证下的标准RL环境支持、大规模公开可用的众包数据集、离线学习基准和激励措施研究",
        "关键词": [
            "众包",
            "模仿学习",
            "离线学习",
            "多智能体系统",
            "Atari 2600"
        ],
        "涉及的技术概念": {
            "众包": "用于生成大规模人类示范数据的技术，支持模仿学习和离线学习的研究",
            "模仿学习": "通过观察和模仿人类行为来训练模型的方法",
            "离线学习": "在不需要与环境交互的情况下，利用已有数据训练模型的方法"
        },
        "success": true
    },
    {
        "order": 191,
        "title": "Crystal Diffusion Variational Autoencoder for Periodic Material Generation",
        "html": "https://iclr.cc//virtual/2022/poster/7063",
        "abstract": "Generating the periodic structure of stable materials is a long-standing challenge for the material design community. This task is difficult because stable materials only exist in a low-dimensional subspace of all possible periodic arrangements of atoms: 1) the coordinates must lie in the local energy minimum defined by quantum mechanics, and 2) global stability also requires the structure to follow the complex, yet specific bonding preferences between different atom types. Existing methods fail to incorporate these factors and often lack proper invariances. We propose a Crystal Diffusion Variational Autoencoder (CDVAE) that captures the physical inductive bias of material stability. By learning from the data distribution of stable materials, the decoder generates materials in a diffusion process that moves atomic coordinates towards a lower energy state and updates atom types to satisfy bonding preferences between neighbors. Our model also explicitly encodes interactions across periodic boundaries and respects permutation, translation, rotation, and periodic invariances. We significantly outperform past methods in three tasks: 1) reconstructing the input structure, 2) generating valid, diverse, and realistic materials, and 3) generating materials that optimize a specific property. We also provide several standard datasets and evaluation metrics for the broader machine learning community.",
        "conference": "ICLR",
        "中文标题": "晶体扩散变分自编码器用于周期性材料生成",
        "摘要翻译": "生成稳定材料的周期性结构是材料设计界长期面临的挑战。这一任务之所以困难，是因为稳定材料仅存在于所有可能的原子周期性排列的低维子空间中：1)坐标必须位于量子力学定义的局部能量最小值处，2)全局稳定性还要求结构遵循不同类型原子之间复杂而特定的键合偏好。现有方法未能纳入这些因素，且往往缺乏适当的不变性。我们提出了一种晶体扩散变分自编码器（CDVAE），它捕捉了材料稳定性的物理归纳偏差。通过学习稳定材料的数据分布，解码器在扩散过程中生成材料，该过程将原子坐标移向较低能量状态，并更新原子类型以满足邻居之间的键合偏好。我们的模型还明确编码了跨周期边界的相互作用，并尊重排列、平移、旋转和周期不变性。在三个任务中，我们显著优于过去的方法：1)重建输入结构，2)生成有效、多样且真实的材料，3)生成优化特定属性的材料。我们还为更广泛的机器学习社区提供了几个标准数据集和评估指标。",
        "领域": "材料生成、变分自编码器、扩散模型",
        "问题": "生成稳定材料的周期性结构",
        "动机": "解决现有方法在生成稳定材料时未能考虑量子力学定义的局部能量最小值和原子间键合偏好的问题",
        "方法": "提出晶体扩散变分自编码器（CDVAE），通过学习稳定材料的数据分布，在扩散过程中生成材料，同时考虑原子坐标和类型的更新以满足稳定性要求",
        "关键词": [
            "晶体扩散",
            "变分自编码器",
            "材料生成",
            "周期性结构",
            "稳定性"
        ],
        "涉及的技术概念": {
            "晶体扩散变分自编码器（CDVAE）": "一种结合了扩散过程和变分自编码器的方法，用于生成稳定的周期性材料结构",
            "物理归纳偏差": "指模型在学习过程中捕捉到的关于材料稳定性的物理规律和约束",
            "周期性不变性": "模型在处理周期性材料结构时保持的对称性，包括排列、平移、旋转和周期边界条件的不变性"
        },
        "success": true
    },
    {
        "order": 192,
        "title": "Curriculum learning as a tool to uncover learning principles in the brain ",
        "html": "https://iclr.cc//virtual/2022/poster/6678",
        "abstract": "We present a novel approach to use curricula to identify principles by which a system learns. Previous work in curriculum learning has focused on how curricula can be designed to improve learning of a model on particular tasks. We consider the inverse problem: what can a curriculum tell us about how a learning system acquired a task? Using recurrent neural networks (RNNs) and models of common experimental neuroscience tasks, we demonstrate that curricula can be used to differentiate learning principles using target-based and a representation-based loss functions as use cases. In particular, we compare the performance of RNNs using target-based learning rules versus those using representational learning rules on three different curricula in the context of two tasks. We show that the learned state-space trajectories of RNNs trained by these two learning rules under all curricula tested are indistinguishable. However, by comparing learning times during different curricula, we can disambiguate the learning rules and challenge traditional approaches of interrogating learning systems. Although all animals in neuroscience lab settings are trained by curriculum-based procedures called shaping, almost no behavioral or neural data are collected or published on the relative successes or training times under different curricula. Our results motivate the systematic collection and curation of data during shaping by demonstrating curriculum learning in RNNs as a tool to probe and differentiate learning principles used by biological systems, over conventional statistical analyses of learned state spaces.",
        "conference": "ICLR",
        "中文标题": "课程学习作为揭示大脑学习原理的工具",
        "摘要翻译": "我们提出了一种新颖的方法，利用课程来识别系统学习的原则。以往关于课程学习的研究主要集中在如何设计课程以提高模型在特定任务上的学习效果。我们考虑的是相反的问题：课程能告诉我们学习系统是如何掌握任务的吗？通过使用循环神经网络（RNNs）和常见的实验神经科学任务模型，我们证明了课程可以用来区分学习原理，以基于目标和基于表示的损失函数为例。特别是，我们在两个任务的背景下，比较了使用基于目标的学习规则和基于表示的学习规则的RNNs在三种不同课程上的表现。我们发现，在所有测试的课程下，这两种学习规则训练的RNNs学习到的状态空间轨迹是无法区分的。然而，通过比较不同课程下的学习时间，我们可以消除学习规则的歧义，并挑战传统的学习系统研究方法。尽管在神经科学实验室环境中，所有动物都是通过称为塑造的基于课程的程序进行训练的，但几乎没有关于不同课程下相对成功或训练时间的行为或神经数据被收集或发表。我们的结果通过展示在RNNs中的课程学习作为一种工具来探测和区分生物系统使用的学习原理，超越了传统的学习状态空间的统计分析，激励了在塑造过程中系统地收集和管理数据。",
        "领域": "神经科学计算模型、循环神经网络、机器学习",
        "问题": "如何利用课程学习揭示学习系统掌握任务的原理",
        "动机": "探索课程学习作为工具，以区分和理解生物系统使用的学习原理，超越传统的状态空间分析方法",
        "方法": "使用循环神经网络和实验神经科学任务模型，通过比较基于目标和基于表示的损失函数在不同课程下的表现，分析学习时间和状态空间轨迹",
        "关键词": [
            "课程学习",
            "循环神经网络",
            "学习原理",
            "神经科学任务",
            "损失函数"
        ],
        "涉及的技术概念": {
            "课程学习": "一种通过逐步增加任务难度来训练学习系统的方法，用于揭示学习原理",
            "循环神经网络": "一种能够处理序列数据的神经网络结构，用于模拟学习过程",
            "损失函数": "用于评估模型预测与真实值之间差异的函数，基于目标和基于表示的损失函数用于区分不同的学习规则"
        },
        "success": true
    },
    {
        "order": 193,
        "title": "CURVATURE-GUIDED DYNAMIC SCALE NETWORKS FOR MULTI-VIEW  STEREO",
        "html": "https://iclr.cc//virtual/2022/poster/6520",
        "abstract": "Multi-view stereo (MVS) is a crucial task for precise 3D reconstruction. Most recent studies tried to improve the performance of matching cost volume in MVS by introducing a skilled design to cost formulation or cost regularization. In this paper, we focus on learning robust feature extraction to enhance the performance of matching costs, without need of heavy computation in the other steps. In particular, we present a dynamic scale feature extraction network, namely, CDSFNet. It is composed of multiple novel convolution layers, each of which can select a proper patch scale for each pixel guided by the normal curvature of image surface. As a result, CDFSNet can estimate the optimal patch scales to learn discriminative features for accurate matching computation between reference and source images. By combining the robust extracted features with an appropriate cost formulation strategy, our final MVS architecture can estimate depth maps more precisely. Extensive experiments showed that the proposed method outperforms other state-of-the-art methods on complex outdoor scenes. It significantly improves the completeness of reconstructed models. Moreover, the method can process the high resolution with faster run-time and lower memory compared to the other MVS methods. ",
        "conference": "ICLR",
        "中文标题": "曲率引导的动态尺度网络用于多视角立体视觉",
        "摘要翻译": "多视角立体视觉（MVS）是实现精确三维重建的关键任务。最近的大多数研究试图通过引入巧妙设计的成本公式或成本正则化来提高MVS中匹配成本体积的性能。在本文中，我们专注于学习鲁棒的特征提取以增强匹配成本的性能，而无需在其他步骤中进行大量计算。特别是，我们提出了一种动态尺度特征提取网络，即CDSFNet。它由多个新颖的卷积层组成，每个层可以根据图像表面的法线曲率为每个像素选择合适的补丁尺度。因此，CDFSNet可以估计最佳补丁尺度，以学习区分性特征，用于参考图像和源图像之间的准确匹配计算。通过将鲁棒提取的特征与适当的成本公式策略相结合，我们的最终MVS架构可以更精确地估计深度图。大量实验表明，所提出的方法在复杂的户外场景中优于其他最先进的方法。它显著提高了重建模型的完整性。此外，与其他MVS方法相比，该方法可以以更快的运行时间和更低的内存处理高分辨率。",
        "领域": "多视角立体视觉",
        "问题": "提高多视角立体视觉中匹配成本体积的性能",
        "动机": "通过鲁棒的特征提取增强匹配成本的性能，减少计算负担",
        "方法": "提出动态尺度特征提取网络CDSFNet，根据图像表面的法线曲率选择补丁尺度，结合适当的成本公式策略",
        "关键词": [
            "多视角立体视觉",
            "动态尺度特征提取",
            "曲率引导"
        ],
        "涉及的技术概念": {
            "动态尺度特征提取网络": "根据图像表面的法线曲率为每个像素选择合适的补丁尺度，以学习区分性特征",
            "法线曲率": "用于指导选择每个像素的补丁尺度，以优化特征提取",
            "成本公式策略": "与鲁棒提取的特征相结合，以更精确地估计深度图"
        },
        "success": true
    },
    {
        "order": 194,
        "title": "CycleMLP: A MLP-like Architecture for Dense Prediction",
        "html": "https://iclr.cc//virtual/2022/poster/6273",
        "abstract": "This paper presents a simple MLP-like architecture, CycleMLP, which is a versatile backbone for visual recognition and dense predictions. As compared to modern MLP architectures, e.g. , MLP-Mixer, ResMLP, and gMLP, whose architectures are correlated to image size and thus are infeasible in object detection and segmentation, CycleMLP has two advantages compared to modern approaches. (1) It can copewith various image sizes. (2) It achieves linear computational complexity to image size by using local windows. In contrast, previous MLPs have $O(N^2)$ computations due to fully spatial connections. We build a family of models which surpass existing MLPs and even state-of-the-art Transformer-based models, e.g. Swin Transformer, while using fewer parameters and FLOPs. We expand the MLP-like models’ applicability, making them a versatile backbone for dense prediction tasks. CycleMLP achieves competitive results on object detection, instance segmentation, and semantic segmentation. In particular, CycleMLP-Tiny outperforms Swin-Tiny by 1.3% mIoU on ADE20K dataset with fewer FLOPs. Moreover, CycleMLP also shows excellent zero-shot robustness on ImageNet-C dataset.",
        "conference": "ICLR",
        "中文标题": "CycleMLP：一种用于密集预测的类MLP架构",
        "摘要翻译": "本文提出了一种简单的类MLP架构CycleMLP，它是视觉识别和密集预测的多功能骨干网络。与现代MLP架构（如MLP-Mixer、ResMLP和gMLP）相比，这些架构与图像大小相关，因此在目标检测和分割中不可行，CycleMLP相比现代方法有两个优势。（1）它能够处理各种图像尺寸。（2）通过使用局部窗口，它对图像尺寸实现了线性计算复杂度。相比之下，以前的MLP由于完全的空间连接而具有O(N^2)的计算量。我们构建了一系列模型，这些模型超越了现有的MLP甚至基于Transformer的最先进模型（如Swin Transformer），同时使用更少的参数和FLOPs。我们扩展了类MLP模型的适用性，使其成为密集预测任务的多功能骨干网络。CycleMLP在目标检测、实例分割和语义分割上取得了竞争性的结果。特别是，CycleMLP-Tiny在ADE20K数据集上以更少的FLOPs比Swin-Tiny高出1.3%的mIoU。此外，CycleMLP在ImageNet-C数据集上也显示出优秀的零样本鲁棒性。",
        "领域": "目标检测, 实例分割, 语义分割",
        "问题": "解决现代MLP架构在目标检测和分割任务中因与图像尺寸相关而不可行的问题",
        "动机": "开发一种能够处理各种图像尺寸且计算复杂度与图像尺寸成线性关系的MLP架构，以扩展MLP在密集预测任务中的应用",
        "方法": "提出CycleMLP架构，通过使用局部窗口实现线性计算复杂度，构建超越现有MLP和Transformer模型的系列模型",
        "关键词": [
            "CycleMLP",
            "密集预测",
            "线性计算复杂度",
            "局部窗口",
            "多功能骨干网络"
        ],
        "涉及的技术概念": {
            "CycleMLP": "一种类MLP架构，用于视觉识别和密集预测，能够处理各种图像尺寸并实现线性计算复杂度",
            "局部窗口": "CycleMLP中用于减少计算复杂度的技术，通过限制空间连接的范围来实现",
            "线性计算复杂度": "CycleMLP相比传统MLP架构的一个关键优势，使其能够高效处理大尺寸图像"
        },
        "success": true
    },
    {
        "order": 195,
        "title": "DAB-DETR: Dynamic Anchor Boxes are Better Queries for DETR",
        "html": "https://iclr.cc//virtual/2022/poster/7150",
        "abstract": "We present in this paper a novel query formulation using dynamic anchor boxes for DETR and offer a deeper understanding of the role of queries in DETR. This new formulation directly uses box coordinates as queries in Transformer decoders and dynamically updates them layer-by-layer. Using box coordinates not only helps using explicit positional priors to improve the query-to-feature similarity measure and eliminate the slow training convergence issue in DETR, but also allows us to modulate the positional attention map using the box width and height information. Such a design makes it clear that queries in DETR can be implemented as performing soft ROI pooling layer-by-layer in a cascade manner. As a result, it leads to the best performance among the DETR-like detection models under the same setting, e.g. AP 45.7\\% using R50 as backbone trained in 50 epochs. We also conducted extensive experiments to confirm our analysis and verify the effectiveness of our methods. Code will be released soon.",
        "conference": "ICLR",
        "中文标题": "DAB-DETR：动态锚框是DETR更好的查询方式",
        "摘要翻译": "本文提出了一种使用动态锚框作为DETR查询的新颖方法，并深入理解了查询在DETR中的作用。这种新方法直接在Transformer解码器中使用框坐标作为查询，并逐层动态更新它们。使用框坐标不仅有助于利用显式的位置先验来改进查询到特征的相似性度量，并消除DETR中训练收敛慢的问题，而且还允许我们使用框的宽度和高度信息来调节位置注意力图。这样的设计清楚地表明，DETR中的查询可以以级联方式逐层执行软ROI池化。因此，在相同设置下，它在类似DETR的检测模型中表现最佳，例如使用R50作为骨干网络训练50个周期时AP达到45.7%。我们还进行了大量实验来证实我们的分析并验证我们方法的有效性。代码即将发布。",
        "领域": "目标检测",
        "问题": "改进DETR模型中的查询机制以提高检测性能和训练效率",
        "动机": "解决DETR模型中查询机制导致的训练收敛慢和性能不足的问题",
        "方法": "提出使用动态锚框作为查询，逐层更新框坐标，并利用框尺寸信息调节注意力图",
        "关键词": [
            "动态锚框",
            "DETR",
            "目标检测",
            "Transformer",
            "注意力机制"
        ],
        "涉及的技术概念": {
            "动态锚框": "作为查询直接使用框坐标，逐层动态更新，以提高查询效率和性能",
            "Transformer解码器": "用于处理动态锚框查询，实现目标检测任务",
            "软ROI池化": "通过级联方式逐层执行，优化目标检测的准确性和效率"
        },
        "success": true
    },
    {
        "order": 196,
        "title": "DARA: Dynamics-Aware Reward Augmentation in Offline Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2022/poster/5934",
        "abstract": "Offline reinforcement learning algorithms promise to be applicable in settings where a fixed dataset is available and no new experience can be acquired. However, such formulation is inevitably offline-data-hungry and, in practice, collecting a large offline dataset for one specific task over one specific environment is also costly and laborious. In this paper, we thus 1) formulate the offline dynamics adaptation by using (source) offline data collected from another dynamics to relax the requirement for the extensive (target) offline data, 2) characterize the dynamics shift problem in which prior offline methods do not scale well, and 3) derive a simple dynamics-aware reward augmentation (DARA) framework from both model-free and model-based offline settings. Specifically, DARA emphasizes learning from those source transition pairs that are adaptive for the target environment and mitigates the offline dynamics shift by characterizing state-action-next-state pairs instead of the typical state-action distribution sketched by prior offline RL methods. The experimental evaluation demonstrates that DARA, by augmenting rewards in the source offline dataset, can acquire an adaptive policy for the target environment and yet significantly reduce the requirement of target offline data. With only modest amounts of target offline data, our performance consistently outperforms the prior offline RL methods in both simulated and real-world tasks. ",
        "conference": "ICLR",
        "中文标题": "DARA：离线强化学习中的动态感知奖励增强",
        "摘要翻译": "离线强化学习算法承诺适用于固定数据集可用且无法获取新经验的环境。然而，这样的设定不可避免地需要大量离线数据，并且在实践中，为一个特定任务在一个特定环境中收集大量离线数据集也是成本高昂且费力的。因此，在本文中，我们1）通过使用从另一个动态收集的（源）离线数据来制定离线动态适应，以放宽对广泛（目标）离线数据的需求，2）描述了先前离线方法无法很好扩展的动态偏移问题，以及3）从无模型和基于模型的离线设置中推导出一个简单的动态感知奖励增强（DARA）框架。具体来说，DARA强调从那些对目标环境具有适应性的源转移对中学习，并通过描述状态-动作-下一状态对而不是先前离线RL方法所描绘的典型状态-动作分布来缓解离线动态偏移。实验评估表明，DARA通过增强源离线数据集中的奖励，可以为目标环境获取一个适应性策略，同时显著减少目标离线数据的需求。仅需适量的目标离线数据，我们的性能在模拟和现实世界任务中均一致优于先前的离线RL方法。",
        "领域": "离线强化学习",
        "问题": "解决在固定数据集下，如何减少对目标环境离线数据的需求，同时提高策略的适应性。",
        "动机": "减少离线强化学习中收集大量特定任务数据的成本和努力，同时提高算法在新环境中的适应性。",
        "方法": "提出动态感知奖励增强（DARA）框架，通过强调学习对目标环境具有适应性的源转移对，并描述状态-动作-下一状态对来缓解动态偏移问题。",
        "关键词": [
            "离线强化学习",
            "动态适应",
            "奖励增强"
        ],
        "涉及的技术概念": {
            "动态感知奖励增强（DARA）": "一种通过增强源离线数据集中的奖励来适应目标环境的框架。",
            "动态偏移问题": "描述了在动态变化的环境中，先前离线方法无法很好扩展的问题。",
            "状态-动作-下一状态对": "用于描述环境动态的关键元素，替代了传统的状态-动作分布，以更好地适应动态变化。"
        },
        "success": true
    },
    {
        "order": 197,
        "title": "Data-Driven Offline Optimization for Architecting Hardware Accelerators",
        "html": "https://iclr.cc//virtual/2022/poster/6616",
        "abstract": "To attain higher efficiency, the industry has gradually reformed towards application-specific hardware accelerators. While such a paradigm shift is already starting to show promising results, designers need to spend considerable manual effort and perform large number of time-consuming simulations to find accelerators that can accelerate multiple target applications while obeying design constraints. Moreover, such a simulation-driven approach must be re-run from scratch every time the set of target applications or design constraints change. An alternative paradigm is to use a data-driven, offline approach that utilizes logged simulation data, to architect hardware accelerators, without needing any form of simulations. Such an approach not only alleviates the need to run time-consuming simulation, but also enables data reuse and applies even when set of target applications changes. In this paper, we develop such a data-driven offline optimization method for designing hardware accelerators, dubbed PRIME, that enjoys all of these properties. Our approach learns a conservative, robust estimate of the desired cost function, utilizes infeasible points and optimizes the design against this estimate without any additional simulator queries during optimization. PRIME architects accelerators---tailored towards both single- and multi-applications---improving performance upon stat-of-the-art simulation-driven methods by about 1.54x and 1.20x, while considerably reducing the required total simulation time by 93% and 99%, respectively. In addition, PRIME also architects effective accelerators for unseen applications in a zero-shot setting, outperforming simulation-based methods by 1.26x.",
        "conference": "ICLR",
        "中文标题": "数据驱动的离线优化用于硬件加速器架构设计",
        "摘要翻译": "为了提高效率，工业界已逐渐转向应用特定的硬件加速器。尽管这种范式转变已开始显示出有希望的结果，但设计师需要投入大量手动努力并进行大量耗时的模拟，以找到能够加速多个目标应用同时遵守设计约束的加速器。此外，每当目标应用集或设计约束发生变化时，这种模拟驱动的方法必须从头开始重新运行。另一种范式是使用数据驱动的离线方法，利用记录的模拟数据来架构硬件加速器，而无需任何形式的模拟。这种方法不仅减轻了运行耗时模拟的需求，还实现了数据的重用，并且即使目标应用集发生变化也适用。在本文中，我们开发了这样一种数据驱动的离线优化方法，名为PRIME，用于设计硬件加速器，它享有所有这些特性。我们的方法学习了对所需成本函数的保守、稳健估计，利用了不可行点，并在优化过程中无需任何额外的模拟器查询的情况下针对这一估计优化设计。PRIME架构的加速器——针对单应用和多应用定制——将性能比最先进的模拟驱动方法提高了约1.54倍和1.20倍，同时显著减少了所需的总体模拟时间，分别减少了93%和99%。此外，PRIME还在零射击设置下为未见过的应用架构了有效的加速器，性能比基于模拟的方法高出1.26倍。",
        "领域": "硬件加速器设计、性能优化、多应用加速",
        "问题": "如何高效设计能够加速多个目标应用同时遵守设计约束的硬件加速器，而无需进行大量耗时的模拟。",
        "动机": "减少设计硬件加速器时的手动努力和模拟时间，提高设计效率和应用适应性。",
        "方法": "开发了一种名为PRIME的数据驱动的离线优化方法，该方法学习成本函数的保守估计，利用不可行点进行优化，无需额外模拟。",
        "关键词": [
            "硬件加速器",
            "数据驱动优化",
            "离线方法",
            "性能提升",
            "模拟时间减少"
        ],
        "涉及的技术概念": {
            "数据驱动的离线优化": "利用记录的模拟数据进行硬件加速器设计，无需实时模拟，提高效率和适应性。",
            "保守稳健的成本函数估计": "在优化过程中学习并利用对成本函数的保守估计，以确保设计的稳健性。",
            "零射击设置下的加速器设计": "为未见过的应用设计有效的加速器，展示了方法的广泛适用性和高效性。"
        },
        "success": true
    },
    {
        "order": 198,
        "title": "Data-Efficient Graph Grammar Learning for Molecular Generation",
        "html": "https://iclr.cc//virtual/2022/poster/7011",
        "abstract": "The problem of molecular generation has received significant attention recently. Existing methods are typically based on deep neural networks and require training on large datasets with tens of thousands of samples. In practice, however, the size of class-specific chemical datasets is usually limited (e.g., dozens of samples) due to labor-intensive experimentation and data collection. Another major challenge is to generate only physically synthesizable molecules. This is a non-trivial task for neural network-based generative models since the relevant chemical knowledge can only be extracted and generalized from the limited training data. In this work, we propose a data-efficient generative model that can be learned from datasets with orders of magnitude smaller sizes than common benchmarks. At the heart of this method is a learnable graph grammar that generates molecules from a sequence of production rules. Without any human assistance, these production rules are automatically constructed from training data. Furthermore, additional chemical knowledge can be incorporated into the model by further grammar optimization. Our learned graph grammar yields state-of-the-art results on generating high-quality molecules for three monomer datasets that contain only ${\\sim}20$ samples each. Our approach also achieves remarkable performance in a challenging polymer generation task with $only$ $117$ training samples and is competitive against existing methods using $81$k data points.",
        "conference": "ICLR",
        "中文标题": "数据高效的图语法学习用于分子生成",
        "摘要翻译": "分子生成问题最近受到了广泛关注。现有的方法通常基于深度神经网络，并且需要在包含数万个样本的大型数据集上进行训练。然而，在实践中，由于实验和数据收集的劳动密集型特性，特定类别的化学数据集的大小通常有限（例如，几十个样本）。另一个主要挑战是仅生成物理上可合成的分子。这对于基于神经网络的生成模型来说是一项非平凡的任务，因为相关的化学知识只能从有限的训练数据中提取和概括。在这项工作中，我们提出了一种数据高效的生成模型，该模型可以从比常见基准小几个数量级的数据集中学习。该方法的核心是一个可学习的图语法，它通过一系列生产规则生成分子。在没有任何人工帮助的情况下，这些生产规则是从训练数据中自动构建的。此外，通过进一步的语法优化，可以将额外的化学知识纳入模型中。我们学习的图语法在三个每个仅包含约20个样本的单体数据集上生成了高质量的分子，取得了最先进的结果。我们的方法在一个仅包含117个训练样本的具有挑战性的聚合物生成任务中也取得了显著的性能，并且与使用81k数据点的现有方法相比具有竞争力。",
        "领域": "分子生成、化学信息学、图神经网络",
        "问题": "在数据量有限的情况下生成物理上可合成的分子",
        "动机": "解决在有限数据集上训练生成模型以及生成物理上可合成分子的挑战",
        "方法": "提出了一种基于可学习图语法的数据高效生成模型，自动从训练数据中构建生产规则，并通过语法优化纳入额外化学知识",
        "关键词": [
            "分子生成",
            "图语法",
            "数据高效",
            "化学知识",
            "小样本学习"
        ],
        "涉及的技术概念": {
            "图语法": "用于从一系列生产规则生成分子的可学习语法，自动从训练数据中构建",
            "数据高效生成模型": "能够在比常见基准小几个数量级的数据集上学习的生成模型",
            "语法优化": "通过优化图语法，将额外的化学知识纳入模型中，以提高生成分子的质量和可合成性"
        },
        "success": true
    },
    {
        "order": 199,
        "title": "Data Efficient Language-Supervised Zero-Shot Recognition with Optimal Transport Distillation",
        "html": "https://iclr.cc//virtual/2022/poster/6582",
        "abstract": "Traditional computer vision models are trained to predict a fixed set of predefined categories. Recently, natural language has been shown to be a broader and richer source of supervision that provides finer descriptions to visual concepts than supervised 'gold' labels. Previous works, such as CLIP, use InfoNCE loss to train a model to predict the pairing between images and text captions. CLIP, however, is data hungry and requires more than 400M image-text pairs for training. The inefficiency can be \\textit{partially} attributed to the fact that the image-text pairs are noisy. To address this, we propose OTTER (Optimal TransporT distillation for Efficient zero-shot Recognition), which uses online entropic optimal transport to find a soft image-text match as labels for contrastive learning. Based on pretrained image and text encoders, models trained with OTTER achieve strong performance with only 3M image text pairs. Compared with InfoNCE loss, label smoothing, and knowledge distillation, OTTER consistently outperforms these baselines in zero-shot evaluation on Google Open Images (19,958 classes) and multi-labeled ImageNet 10K (10032 classes) from Tencent ML-Images. Over 42 evaluations on 7 different dataset/architecture settings x 6 metrics, OTTER outperforms (32) or ties (2) all baselines in 34 of them. Our source code is open sourced at https://github.com/facebookresearch/OTTER.",
        "conference": "ICLR",
        "中文标题": "数据高效的语言监督零样本识别与最优传输蒸馏",
        "摘要翻译": "传统的计算机视觉模型被训练来预测一组固定的预定义类别。最近，自然语言被证明是一种更广泛、更丰富的监督来源，它为视觉概念提供了比监督'黄金'标签更精细的描述。先前的工作，如CLIP，使用InfoNCE损失来训练模型以预测图像和文本标题之间的配对。然而，CLIP对数据的需求量大，需要超过4亿个图像-文本对进行训练。这种低效可以部分归因于图像-文本对的噪声。为了解决这个问题，我们提出了OTTER（高效零样本识别的最优传输蒸馏），它使用在线熵最优传输来找到软图像-文本匹配作为对比学习的标签。基于预训练的图像和文本编码器，使用OTTER训练的模型仅需300万个图像文本对就能实现强大的性能。与InfoNCE损失、标签平滑和知识蒸馏相比，OTTER在Google Open Images（19,958个类别）和腾讯ML-Images的多标签ImageNet 10K（10032个类别）的零样本评估中始终优于这些基线。在7种不同的数据集/架构设置x6指标上的42次评估中，OTTER在34次评估中优于（32）或与所有基线持平（2）。我们的源代码已在https://github.com/facebookresearch/OTTER开源。",
        "领域": "零样本学习, 自然语言处理与视觉结合, 图像文本匹配",
        "问题": "解决传统计算机视觉模型在零样本识别任务中数据效率低下的问题",
        "动机": "利用自然语言作为更丰富的监督来源，减少对大量标注数据的依赖，提高模型在零样本识别任务中的性能",
        "方法": "提出OTTER方法，使用在线熵最优传输来优化图像和文本之间的匹配，作为对比学习的标签，从而提高数据效率",
        "关键词": [
            "零样本学习",
            "最优传输",
            "对比学习",
            "自然语言监督",
            "数据高效"
        ],
        "涉及的技术概念": {
            "最优传输": "用于在图像和文本之间找到最优的匹配，作为对比学习的软标签，提高模型的训练效率和性能",
            "对比学习": "通过比较正负样本对来学习表示，OTTER利用最优传输生成的软标签来优化这一过程",
            "零样本识别": "模型在没有直接训练样本的情况下识别新类别的能力，OTTER通过自然语言监督和最优传输蒸馏来提高这一能力"
        },
        "success": true
    },
    {
        "order": 200,
        "title": "Data Poisoning Won’t Save You From Facial Recognition",
        "html": "https://iclr.cc//virtual/2022/poster/7006",
        "abstract": "Data poisoning has been proposed as a compelling defense against facial recognition models trained on Web-scraped pictures. Users can perturb images they post online, so that models will misclassify future (unperturbed) pictures.   We demonstrate that this strategy provides a false sense of security, as it ignores an inherent asymmetry between the parties: users' pictures are perturbed once and for all before being published (at which point they are scraped) and must thereafter fool all future models---including models trained adaptively against the users' past attacks, or models that use new technologies discovered after the attack.  We evaluate two systems for poisoning attacks against large-scale facial recognition, Fawkes (500,000+ downloads) and LowKey. We demonstrate how an 'oblivious' model trainer can simply wait for future developments in computer vision to nullify the protection of pictures collected in the past. We further show that an adversary with black-box access to the attack can (i) train a robust model that resists the perturbations of collected pictures and (ii) detect poisoned pictures uploaded online.  We caution that facial recognition poisoning will not admit an 'arms race' between attackers and defenders. Once perturbed pictures are scraped, the attack cannot be changed so any future successful defense irrevocably undermines users' privacy.",
        "conference": "ICLR",
        "中文标题": "数据投毒无法保护你免受面部识别的侵害",
        "摘要翻译": "数据投毒被提出作为一种对抗基于网络抓取图片训练的面部识别模型的有效防御手段。用户可以扰动他们发布在网上的图片，使得模型会错误分类未来的（未扰动的）图片。我们证明这种策略给人一种虚假的安全感，因为它忽视了各方之间固有的不对称性：用户的图片在被发布（此时被抓取）之前被一次性扰动，之后必须欺骗所有未来的模型——包括针对用户过去攻击自适应训练的模型，或使用攻击后发现的新技术的模型。我们评估了针对大规模面部识别的两种投毒攻击系统，Fawkes（下载量超过50万次）和LowKey。我们展示了‘不知情’的模型训练者如何简单地等待计算机视觉的未来发展来使过去收集的图片的保护失效。我们进一步表明，拥有对攻击的黑盒访问权限的对手可以（i）训练一个抵抗收集图片扰动的鲁棒模型和（ii）检测上传到网上的被投毒图片。我们警告说，面部识别投毒不会在攻击者和防御者之间引发‘军备竞赛’。一旦扰动的图片被抓取，攻击就无法改变，因此任何未来的成功防御都会不可逆转地损害用户的隐私。",
        "领域": "人脸识别",
        "问题": "数据投毒作为防御面部识别模型的有效性",
        "动机": "探讨数据投毒策略在长期对抗面部识别模型中的实际效果和局限性",
        "方法": "评估Fawkes和LowKey两种投毒攻击系统，分析模型训练者如何通过未来技术发展使投毒防御失效，以及对手如何训练鲁棒模型和检测投毒图片",
        "关键词": [
            "数据投毒",
            "面部识别",
            "隐私保护",
            "对抗攻击",
            "模型鲁棒性"
        ],
        "涉及的技术概念": {
            "数据投毒": "一种通过扰动训练数据来影响模型行为的攻击方法，用于防御面部识别模型",
            "对抗攻击": "旨在通过微小扰动输入数据来欺骗机器学习模型的技术",
            "模型鲁棒性": "模型抵抗对抗攻击或其他形式扰动的能力，确保在扰动条件下仍能正确分类"
        },
        "success": true
    },
    {
        "order": 201,
        "title": "D-CODE: Discovering Closed-form ODEs from Observed Trajectories",
        "html": "https://iclr.cc//virtual/2022/poster/7157",
        "abstract": "For centuries, scientists have manually designed closed-form ordinary differential equations (ODEs) to model dynamical systems. An automated tool to distill closed-form ODEs from observed trajectories would accelerate the modeling process. Traditionally, symbolic regression is used to uncover a closed-form prediction function $a=f(b)$ with label-feature pairs $(a_i, b_i)$ as training examples. However, an ODE models the time derivative $\\dot{x}(t)$ of a dynamical system, e.g. $\\dot{x}(t) = f(x(t),t)$, and the 'label' $\\dot{x}(t)$ is usually *not* observed. The existing ways to bridge this gap only perform well for a narrow range of settings with low measurement noise, frequent sampling, and non-chaotic dynamics. In this work, we propose the Discovery of Closed-form ODE framework (D-CODE), which advances symbolic regression beyond the paradigm of supervised learning. D-CODE leverages a novel objective function based on the variational formulation of ODEs to bypass the unobserved time derivative. For formal justification, we prove that this objective is a valid proxy for the estimation error of the true (but unknown) ODE. In the experiments, D-CODE successfully discovered the governing equations of a diverse range of dynamical systems under challenging measurement settings with high noise and infrequent sampling.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "D-CODE: 从观测轨迹中发现闭合形式的常微分方程",
        "摘要翻译": "几个世纪以来，科学家们手动设计闭合形式的常微分方程（ODE）来模拟动力系统。如果有一个自动化工具能够从观测轨迹中提取闭合形式的ODE，将会加速建模过程。传统上，符号回归被用于发现闭合形式的预测函数 a=f(b)，其中标签-特征对 (a_i, b_i) 作为训练样本。然而，ODE模拟的是动力系统的时间导数 ẋ(t)，例如 ẋ(t) = f(x(t),t)，并且“标签”ẋ(t) 通常是*未被*观测到的。现有的弥补这一差距的方法仅在低测量噪声、频繁采样和非混沌动力学的狭窄范围内表现良好。在这项工作中，我们提出了闭合形式ODE发现框架（D-CODE），它将符号回归推进到监督学习的范式之外。D-CODE利用基于ODE变分公式的新颖目标函数来绕过未观测到的时间导数。为了进行形式上的论证，我们证明了该目标函数是真实（但未知）ODE估计误差的有效代理。在实验中，D-CODE成功地发现了各种动力系统在具有高噪声和不频繁采样的具有挑战性的测量设置下的控制方程。",
        "领域": "动力系统建模、符号回归、常微分方程",
        "问题": "如何从观测到的轨迹数据中自动发现闭合形式的常微分方程，特别是在存在高噪声和不频繁采样的情况下，由于时间导数不可直接观测，传统的符号回归方法难以应用。",
        "动机": "现有的方法在解决从观测轨迹中发现常微分方程的问题时，通常在低噪声、高采样率和非混沌动力学等理想条件下才能表现良好，而实际应用中往往面临高噪声和低采样率的挑战。因此，需要一种更鲁棒的方法来应对这些挑战，加速动力系统的建模过程。",
        "方法": "提出了闭合形式ODE发现框架（D-CODE），该框架采用基于ODE变分公式的新颖目标函数，以绕过未观测到的时间导数问题，并将符号回归推进到监督学习的范式之外。同时，证明了该目标函数是真实（但未知）ODE估计误差的有效代理。",
        "关键词": [
            "常微分方程发现",
            "符号回归",
            "动力系统建模",
            "变分公式",
            "轨迹数据"
        ],
        "涉及的技术概念": {
            "符号回归": "一种用于发现变量之间数学关系的机器学习技术，通过搜索数学表达式空间来拟合数据，从而找到最能描述数据关系的公式。",
            "常微分方程（ODE）": "描述一个或多个函数关于一个独立变量（通常是时间）的导数的方程，用于建模随时间变化的动态系统。"
        }
    },
    {
        "order": 202,
        "title": "Dealing with Non-Stationarity in MARL via Trust-Region Decomposition",
        "html": "https://iclr.cc//virtual/2022/poster/6464",
        "abstract": "Non-stationarity is one thorny issue in cooperative multi-agent reinforcement learning (MARL). One of the reasons is the policy changes of agents during the learning process. Some existing works have discussed various consequences caused by non-stationarity with several kinds of measurement indicators. This makes the objectives or goals of existing algorithms are inevitably inconsistent and disparate. In this paper, we introduce a novel notion, the $\\delta$-$stationarity$ measurement, to explicitly measure the non-stationarity of a policy sequence, which can be further proved to be bounded by the KL-divergence of consecutive joint policies. A straightforward but highly non-trivial way is to control the joint policies' divergence, which is difficult to estimate accurately by imposing the trust-region constraint on the joint policy. Although it has lower computational complexity to decompose the joint policy and impose trust-region constraints on the factorized policies, simple policy factorization like mean-field approximation will lead to more considerable policy divergence, which can be considered as the trust-region decomposition dilemma. We model the joint policy as a pairwise Markov random field and propose a trust-region decomposition network (TRD-Net) based on message passing to estimate the joint policy divergence more accurately. The Multi-Agent Mirror descent policy algorithm with Trust region decomposition, called MAMT, is established by adjusting the trust-region of the local policies adaptively in an end-to-end manner. MAMT can approximately constrain the consecutive joint policies' divergence to satisfy $\\delta$-stationarity and alleviate the non-stationarity problem. Our method can bring noticeable and stable performance improvement compared with baselines in cooperative tasks of different complexity.",
        "conference": "ICLR",
        "中文标题": "通过信任域分解处理多智能体强化学习中的非平稳性问题",
        "摘要翻译": "非平稳性是合作多智能体强化学习（MARL）中的一个棘手问题。其中一个原因是智能体在学习过程中的策略变化。一些现有工作已经讨论了非平稳性引起的各种后果，并使用了多种测量指标。这使得现有算法的目标或目的不可避免地不一致和分散。在本文中，我们引入了一个新概念，即δ-平稳性测量，以明确测量策略序列的非平稳性，这可以进一步证明是由连续联合策略的KL散度所限定的。一个直接但高度非平凡的方法是控制联合策略的散度，这通过将信任域约束施加于联合策略上难以准确估计。尽管分解联合策略并对分解后的策略施加信任域约束具有较低的计算复杂度，但像平均场近似这样的简单策略分解会导致更大的策略散度，这可以被视为信任域分解困境。我们将联合策略建模为成对马尔可夫随机场，并提出了一种基于消息传递的信任域分解网络（TRD-Net），以更准确地估计联合策略散度。通过自适应地调整局部策略的信任域，以端到端的方式建立了带有信任域分解的多智能体镜像下降策略算法，称为MAMT。MAMT可以近似约束连续联合策略的散度以满足δ-平稳性，并缓解非平稳性问题。与基线相比，我们的方法在不同复杂度的合作任务中都能带来显著且稳定的性能提升。",
        "领域": "多智能体强化学习、策略优化、信任域方法",
        "问题": "解决合作多智能体强化学习中的非平稳性问题",
        "动机": "现有方法在处理非平稳性问题时目标不一致，需要一种新的测量和控制方法",
        "方法": "引入δ-平稳性测量，提出信任域分解网络（TRD-Net）和MAMT算法，通过自适应调整信任域约束策略散度",
        "关键词": [
            "多智能体强化学习",
            "非平稳性",
            "信任域分解",
            "策略优化",
            "马尔可夫随机场"
        ],
        "涉及的技术概念": {
            "δ-平稳性测量": "用于明确测量策略序列的非平稳性，由连续联合策略的KL散度限定",
            "信任域分解网络（TRD-Net）": "基于消息传递的网络，用于更准确地估计联合策略散度",
            "多智能体镜像下降策略算法（MAMT）": "通过自适应调整局部策略的信任域，以端到端方式约束策略散度，满足δ-平稳性"
        },
        "success": true
    },
    {
        "order": 203,
        "title": "Decentralized Learning for Overparameterized Problems: A Multi-Agent Kernel Approximation Approach",
        "html": "https://iclr.cc//virtual/2022/poster/6887",
        "abstract": "This work develops a novel framework for communication-efficient distributed learning where the models to be learned are overparameterized. We focus on a class of kernel learning problems (which includes the popular neural tangent kernel (NTK) learning as a special case) and propose a novel {\\it multi-agent kernel approximation} technique that allows the agents to distributedly estimate the full kernel function, and subsequently perform decentralized optimization, without directly exchanging any local data or parameters. The proposed framework is a significant departure from the classical consensus-based approaches, because the agents do not exchange problem parameters, and no consensus is required. We analyze the optimization and the generalization performance of the proposed framework for the $\\ell_2$ loss. We show that with $M$ agents and $N$ total samples when certain generalized inner-product kernels (resp. the random features kernel) are used, each agent needs to communicate $\\mathcal{O}\\big({N^2}/{M}\\big)$ bits (resp. $\\mathcal{O}\\big(N \\sqrt{N}/M \\big)$ real values) to achieve minimax optimal generalization performance. We validate the theoretical results on 90 UCI benchmarking datasets (with average data size $N \\approx 1000$) and show that each agent needs to share a total of $200N/M$ bits (resp. $3N/M$ real values) to closely match the performance of the centralized algorithms, and these numbers are independent of parameter and feature dimensions. ",
        "conference": "ICLR",
        "中文标题": "过参数化问题的去中心化学习：一种多代理核近似方法",
        "摘要翻译": "本研究开发了一种新颖的通信效率高的分布式学习框架，用于学习过参数化模型。我们专注于一类核学习问题（其中包括流行的神经切线核（NTK）学习作为特例），并提出了一种新颖的多代理核近似技术，该技术允许代理分布式估计完整的核函数，并随后执行去中心化优化，而无需直接交换任何本地数据或参数。所提出的框架与经典的基于共识的方法有显著不同，因为代理不交换问题参数，也不需要共识。我们分析了所提出框架对于ℓ2损失的优化和泛化性能。我们表明，当使用某些广义内积核（或随机特征核）时，对于M个代理和N个总样本，每个代理需要通信O(N²/M)位（或O(N√N/M)实数值）以达到极小极大最优的泛化性能。我们在90个UCI基准数据集（平均数据大小N≈1000）上验证了理论结果，并显示每个代理需要共享总共200N/M位（或3N/M实数值）以紧密匹配集中式算法的性能，并且这些数字与参数和特征维度无关。",
        "领域": "分布式学习、核方法、优化算法",
        "问题": "解决在过参数化模型下的分布式学习中通信效率低下的问题",
        "动机": "为了提高分布式学习中的通信效率，减少代理间的数据交换，同时保持或提升模型的泛化性能",
        "方法": "提出了一种多代理核近似技术，允许代理分布式估计核函数并执行去中心化优化，无需直接交换本地数据或参数",
        "关键词": [
            "去中心化学习",
            "过参数化问题",
            "多代理核近似",
            "分布式优化",
            "通信效率"
        ],
        "涉及的技术概念": {
            "多代理核近似": "一种技术，允许代理分布式估计完整的核函数，而无需直接交换本地数据或参数",
            "神经切线核（NTK）": "一种特殊的核方法，用于分析深度学习模型的训练动态",
            "ℓ2损失": "用于衡量模型预测值与真实值之间差异的平方损失函数，本研究中用于分析优化和泛化性能"
        },
        "success": true
    },
    {
        "order": 204,
        "title": "Declarative nets that are equilibrium models",
        "html": "https://iclr.cc//virtual/2022/poster/7155",
        "abstract": "Implicit layers are computational modules that output the solution to some problem depending on the input and the layer parameters. Deep equilibrium models (DEQs) output a solution to a fixed point equation. Deep declarative networks (DDNs) solve an optimisation problem in their forward pass, an arguably more intuitive, interpretable problem than finding a fixed point. We show that solving a kernelised regularised maximum likelihood estimate as an inner problem in a DDN yields a large class of DEQ architectures. Our proof uses the exponential family in canonical form, and provides a closed-form expression for the DEQ parameters in terms of the kernel. The activation functions have interpretations in terms of the derivative of the log partition function. Building on existing literature, we interpret DEQs as fine-tuned, unrolled classical algorithms, giving an intuitive justification for why DEQ models are sensible. We use our theoretical result to devise an initialisation scheme for DEQs that allows them to solve kGLMs in their forward pass at initialisation. We empirically show that this initialisation scheme improves training stability and performance over random initialisation.",
        "conference": "ICLR",
        "中文标题": "声明式网络即平衡模型",
        "摘要翻译": "隐式层是依赖于输入和层参数输出某个问题解决方案的计算模块。深度平衡模型（DEQs）输出一个固定点方程的解决方案。深度声明式网络（DDNs）在其前向传递中解决一个优化问题，这比寻找固定点更直观、更可解释。我们展示了在DDN中解决一个核化正则化最大似然估计作为内部问题，可以产生一大类DEQ架构。我们的证明使用了规范形式的指数族，并提供了DEQ参数关于核的闭式表达式。激活函数在log配分函数的导数方面有解释。基于现有文献，我们将DEQs解释为经过微调的、展开的经典算法，为DEQ模型的合理性提供了直观的论证。我们利用我们的理论结果为DEQs设计了一个初始化方案，使得它们在前向传递中能够解决kGLMs。我们通过实验表明，与随机初始化相比，这种初始化方案提高了训练稳定性和性能。",
        "领域": "深度学习理论、优化算法、神经网络架构",
        "问题": "如何通过深度声明式网络（DDNs）解决优化问题，并展示其与深度平衡模型（DEQs）之间的关系。",
        "动机": "探索深度声明式网络（DDNs）和深度平衡模型（DEQs）之间的联系，提供一种更直观、可解释的模型架构，并改进DEQs的初始化方案以提高训练效果。",
        "方法": "通过在深度声明式网络（DDNs）中解决核化正则化最大似然估计问题，展示其与深度平衡模型（DEQs）的等价性，并基于此设计DEQs的初始化方案。",
        "关键词": [
            "深度声明式网络",
            "深度平衡模型",
            "核化正则化最大似然估计",
            "初始化方案",
            "训练稳定性"
        ],
        "涉及的技术概念": {
            "深度声明式网络（DDNs）": "一种在前向传递中解决优化问题的神经网络架构，提供更直观、可解释的问题解决方案。",
            "深度平衡模型（DEQs）": "输出固定点方程解决方案的模型，通过本文展示的方法可以与DDNs等价。",
            "核化正则化最大似然估计": "在DDNs中作为内部问题解决的技术，用于建立与DEQs的联系，并提供DEQ参数的闭式表达式。"
        },
        "success": true
    },
    {
        "order": 205,
        "title": "Deconstructing the Inductive Biases of Hamiltonian Neural Networks",
        "html": "https://iclr.cc//virtual/2022/poster/6095",
        "abstract": "Physics-inspired neural networks (NNs), such as Hamiltonian or Lagrangian NNs, dramatically outperform other learned dynamics models by leveraging strong inductive biases. These models, however, are challenging to apply to many real world systems, such as those that don’t conserve energy or contain contacts, a common setting for robotics and reinforcement learning. In this paper, we examine the inductive biases that make physics-inspired models successful in practice. We show that, contrary to conventional wisdom, the improved generalization of HNNs is the result of modeling acceleration directly and avoiding artificial complexity from the coordinate system, rather than symplectic structure or energy conservation. We show that by relaxing the inductive biases of these models, we can match or exceed performance on energy-conserving systems while dramatically improving performance on practical, non-conservative systems. We extend this approach to constructing transition models for common Mujoco environments, showing that our model can appropriately balance inductive biases with the flexibility required for model-based control. ",
        "conference": "ICLR",
        "中文标题": "解构哈密尔顿神经网络的归纳偏置",
        "摘要翻译": "受物理学启发的神经网络（NNs），如哈密尔顿或拉格朗日NNs，通过利用强归纳偏置，显著优于其他学习到的动力学模型。然而，这些模型难以应用于许多现实世界系统，如那些不守恒能量或包含接触的系统，这在机器人和强化学习中是一个常见场景。在本文中，我们研究了使物理学启发模型在实践中成功的归纳偏置。我们表明，与传统智慧相反，HNNs改进的泛化能力是直接建模加速度和避免坐标系中的人工复杂性的结果，而不是辛结构或能量守恒。我们展示，通过放松这些模型的归纳偏置，我们可以在能量守恒系统上匹配或超越性能，同时在实际的非保守系统上显著提高性能。我们将这种方法扩展到为常见的Mujoco环境构建过渡模型，显示我们的模型可以适当平衡归纳偏置与基于模型的控制所需的灵活性。",
        "领域": "强化学习、机器人控制、动力学建模",
        "问题": "物理学启发的神经网络在非保守系统中的应用限制",
        "动机": "探索并改进物理学启发神经网络在现实世界系统中的应用，特别是在不守恒能量或包含接触的场景中。",
        "方法": "通过放松模型的归纳偏置，直接建模加速度并避免坐标系中的人工复杂性，以提高在非保守系统中的性能。",
        "关键词": [
            "哈密尔顿神经网络",
            "归纳偏置",
            "动力学建模",
            "非保守系统",
            "模型控制"
        ],
        "涉及的技术概念": {
            "归纳偏置": "模型在学习过程中对解空间的偏好或假设，本文中探讨了如何调整这些偏置以提高模型性能。",
            "哈密尔顿神经网络": "一种受物理学启发的神经网络，用于建模动力学系统，本文研究了其成功的关键因素。",
            "动力学建模": "构建能够预测系统状态随时间变化的模型，本文专注于改进在非保守系统中的建模方法。"
        },
        "success": true
    },
    {
        "order": 206,
        "title": "Decoupled Adaptation for Cross-Domain Object Detection",
        "html": "https://iclr.cc//virtual/2022/poster/6215",
        "abstract": "Cross-domain object detection is more challenging than object classification since multiple objects exist in an image and the location of each object is unknown in the unlabeled target domain. As a result, when we adapt features of different objects to enhance the transferability of the detector, the features of the foreground and the background are easy to be confused, which may hurt the discriminability of the detector. Besides, previous methods focused on category adaptation but ignored another important part for object detection, i.e., the adaptation on bounding box regression. To this end, we propose D-adapt, namely Decoupled Adaptation, to decouple the adversarial adaptation and the training of the detector. Besides, we fill the blank of regression domain adaptation in object detection by introducing a bounding box adaptor. Experiments show that \\textit{D-adapt} achieves state-of-the-art results on four cross-domain object detection tasks and yields 17\\%  and 21\\% relative improvement on benchmark datasets Clipart1k and Comic2k in particular.",
        "conference": "ICLR",
        "中文标题": "解耦适应用于跨领域目标检测",
        "摘要翻译": "跨领域目标检测比目标分类更具挑战性，因为在一张图像中存在多个目标，并且在未标记的目标领域中每个目标的位置是未知的。因此，当我们适应不同目标的特征以增强检测器的可转移性时，前景和背景的特征容易被混淆，这可能会损害检测器的区分能力。此外，先前的方法侧重于类别适应，但忽略了目标检测的另一个重要部分，即边界框回归的适应。为此，我们提出了D-adapt，即解耦适应，以解耦对抗适应和检测器的训练。此外，我们通过引入边界框适配器填补了目标检测中回归领域适应的空白。实验表明，D-adapt在四个跨领域目标检测任务上取得了最先进的结果，特别是在基准数据集Clipart1k和Comic2k上分别实现了17%和21%的相对改进。",
        "领域": "跨领域目标检测",
        "问题": "解决跨领域目标检测中前景和背景特征混淆以及边界框回归适应不足的问题",
        "动机": "提升检测器在跨领域场景下的可转移性和区分能力，填补回归领域适应的空白",
        "方法": "提出解耦适应方法（D-adapt），分离对抗适应和检测器训练，并引入边界框适配器进行回归领域适应",
        "关键词": [
            "跨领域目标检测",
            "解耦适应",
            "边界框适配器",
            "对抗适应",
            "回归领域适应"
        ],
        "涉及的技术概念": {
            "解耦适应": "分离对抗适应和检测器训练的技术，旨在提升检测器的可转移性和区分能力",
            "边界框适配器": "用于目标检测中回归领域适应的技术，填补了先前方法在此方面的空白",
            "对抗适应": "一种通过对抗训练来减少源领域和目标领域之间分布差异的技术"
        },
        "success": true
    },
    {
        "order": 207,
        "title": "Deep Attentive Variational Inference",
        "html": "https://iclr.cc//virtual/2022/poster/5923",
        "abstract": "Stochastic Variational Inference is a powerful framework for learning large-scale probabilistic latent variable models. However, typical assumptions on the factorization or independence  of the latent variables can substantially restrict its capacity for inference and generative modeling. A major line of active research aims at building more expressive variational models by designing deep hierarchies of interdependent latent variables. Although these models exhibit superior performance and enable richer latent representations, we show that they incur diminishing returns: adding more stochastic layers to an already very deep model yields small predictive improvement while substantially increasing the inference and training time. Moreover, the architecture for this class of models favors local interactions among the latent variables between neighboring layers when designing the conditioning factors of the involved distributions. This is the first work that proposes attention mechanisms to build more expressive variational distributions in deep probabilistic models by explicitly modeling both local and global interactions in the latent space. Specifically, we propose deep attentive variational autoencoder and test it on a variety of established datasets. We show it achieves state-of-the-art log-likelihoods while using fewer latent layers and requiring less  training time than existing models. The proposed non-local inference reduces computational footprint by alleviating the need for deep hierarchies.",
        "conference": "ICLR",
        "中文标题": "深度注意力变分推断",
        "摘要翻译": "随机变分推断是学习大规模概率潜在变量模型的一个强大框架。然而，对潜在变量的因子化或独立性的典型假设可能极大地限制其推断和生成建模的能力。一项主要的活跃研究旨在通过设计相互依赖的潜在变量的深层层次结构，来构建更具表现力的变分模型。尽管这些模型表现出卓越的性能并实现了更丰富的潜在表示，但我们表明它们带来了收益递减：在已经非常深的模型中添加更多的随机层只会带来小的预测改进，同时显著增加推断和训练时间。此外，这类模型的架构在设计涉及分布的条件因素时，倾向于在相邻层之间的潜在变量之间进行局部交互。这是首次提出使用注意力机制在深度概率模型中构建更具表现力的变分分布的工作，通过在潜在空间中明确建模局部和全局交互。具体来说，我们提出了深度注意力变分自编码器，并在多种已建立的数据集上进行了测试。我们表明，与现有模型相比，它实现了最先进的对数似然，同时使用更少的潜在层并需要更少的训练时间。所提出的非局部推断通过减轻对深层层次结构的需求，减少了计算足迹。",
        "领域": "变分自编码器、概率图模型、深度学习",
        "问题": "如何在不显著增加模型复杂度和训练时间的情况下，提高变分推断模型的表达能力和推断效率",
        "动机": "解决现有变分推断模型在增加深度时面临的收益递减问题，以及局部交互限制模型表达能力的问题",
        "方法": "提出深度注意力变分自编码器，利用注意力机制在潜在空间中建模局部和全局交互，减少对深层层次结构的需求",
        "关键词": [
            "变分自编码器",
            "注意力机制",
            "非局部推断",
            "概率潜在变量模型",
            "深度学习"
        ],
        "涉及的技术概念": {
            "注意力机制": "用于在潜在空间中建模局部和全局交互，提高模型的表达能力",
            "变分自编码器": "一种结合深度学习和概率图模型的生成模型，用于学习数据的潜在表示",
            "非局部推断": "通过减少对深层层次结构的需求，降低计算复杂度，提高推断效率"
        },
        "success": true
    },
    {
        "order": 208,
        "title": "Deep AutoAugment",
        "html": "https://iclr.cc//virtual/2022/poster/6657",
        "abstract": "While recent automated data augmentation methods lead to state-of-the-art results, their design spaces and the derived data augmentation strategies still incorporate strong human priors. In this work, instead of fixing a set of hand-picked default augmentations alongside the searched data augmentations, we propose a fully automated approach for data augmentation search named Deep AutoAugment (DeepAA). DeepAA progressively builds a multi-layer data augmentation pipeline from scratch by stacking augmentation layers one at a time until reaching convergence. For each augmentation layer, the policy is optimized to maximize the cosine similarity between the gradients of the original and augmented data along the direction with low variance. Our experiments show that even without default augmentations, we can learn an augmentation policy that achieves strong performance with that of previous works. Extensive ablation studies show that the regularized gradient matching is an effective search method for data augmentation policies. Our code is available at: https://github.com/MSU-MLSys-Lab/DeepAA .",
        "conference": "ICLR",
        "中文标题": "深度自动增强",
        "摘要翻译": "尽管最近的自动数据增强方法取得了最先进的结果，但它们的设计空间和衍生的数据增强策略仍然包含了强烈的人类先验。在这项工作中，我们提出了一种名为深度自动增强（DeepAA）的全自动数据增强搜索方法，而不是固定一组手工挑选的默认增强与搜索到的数据增强。DeepAA通过一次堆叠一个增强层，直到达到收敛，从而从零开始逐步构建一个多层数据增强管道。对于每个增强层，策略被优化以最大化原始数据和增强数据梯度在低方差方向上的余弦相似性。我们的实验表明，即使没有默认增强，我们也可以学习到一个与之前工作相媲美的增强策略。大量的消融研究表明，正则化梯度匹配是一种有效的数据增强策略搜索方法。我们的代码可在以下网址获取：https://github.com/MSU-MLSys-Lab/DeepAA。",
        "领域": "数据增强、深度学习优化、计算机视觉",
        "问题": "如何减少数据增强策略设计中的人类先验影响，实现完全自动化的数据增强策略搜索。",
        "动机": "现有的自动数据增强方法虽然有效，但仍依赖于人类设计的先验知识，限制了策略的多样性和潜在性能。",
        "方法": "提出DeepAA方法，通过逐步构建多层数据增强管道，并优化每一层的策略以最大化原始与增强数据梯度在低方差方向上的余弦相似性，实现完全自动化的数据增强策略搜索。",
        "关键词": [
            "自动数据增强",
            "梯度匹配",
            "深度学习优化"
        ],
        "涉及的技术概念": {
            "多层数据增强管道": "通过逐步堆叠增强层构建的数据增强策略，每一层都经过优化以提高模型性能。",
            "余弦相似性": "用于衡量原始数据和增强数据梯度方向一致性的指标，优化目标是最大化这一相似性。",
            "正则化梯度匹配": "一种搜索数据增强策略的方法，通过正则化处理确保梯度匹配的有效性和稳定性。"
        },
        "success": true
    },
    {
        "order": 209,
        "title": "Deep Ensembling with No Overhead for either Training or Testing: The All-Round Blessings of Dynamic Sparsity",
        "html": "https://iclr.cc//virtual/2022/poster/6299",
        "abstract": "The success of deep ensembles on improving predictive performance, uncertainty estimation, and out-of-distribution robustness has been extensively studied in the machine learning literature. Albeit the promising results, naively training multiple deep neural networks and combining their predictions at inference leads to prohibitive computational costs and memory requirements. Recently proposed efficient ensemble approaches reach the performance of the traditional deep ensembles with significantly lower costs. However, the training resources required by these approaches are still at least the same as training a single dense model. In this work, we draw a unique connection between sparse neural network training and deep ensembles, yielding a novel efficient ensemble learning framework called $FreeTickets$. Instead of training multiple dense networks and averaging them, we directly train sparse subnetworks from scratch and extract diverse yet accurate subnetworks during this efficient, sparse-to-sparse training. Our framework, $FreeTickets$, is defined as the ensemble of these relatively cheap sparse subnetworks. Despite being an ensemble method, $FreeTickets$ has even fewer parameters and training FLOPs than a single dense model. This seemingly counter-intuitive outcome is due to the ultra training/inference efficiency of dynamic sparse training. $FreeTickets$ surpasses the dense baseline in all the following criteria: prediction accuracy, uncertainty estimation, out-of-distribution (OoD) robustness, as well as efficiency for both training and inference. Impressively, $FreeTickets$ outperforms the naive deep ensemble with ResNet50 on ImageNet using around only $1/5$ of the training FLOPs required by the latter. We have released our source code at https://github.com/VITA-Group/FreeTickets.",
        "conference": "ICLR",
        "中文标题": "无需额外训练或测试开销的深度集成：动态稀疏性的全方位优势",
        "摘要翻译": "深度学习集成在提升预测性能、不确定性估计以及分布外鲁棒性方面的成功已在机器学习文献中得到广泛研究。尽管结果令人鼓舞，但简单地训练多个深度神经网络并在推理时合并它们的预测会导致计算成本和内存需求过高。最近提出的高效集成方法以显著更低的成本达到了传统深度集成的性能。然而，这些方法所需的训练资源仍然至少与训练单个密集模型相同。在这项工作中，我们在稀疏神经网络训练和深度集成之间建立了独特的联系，产生了一种名为$FreeTickets$的新型高效集成学习框架。我们不是训练多个密集网络并平均它们，而是直接从零开始训练稀疏子网络，并在这个高效的稀疏到稀疏训练过程中提取多样而准确的子网络。我们的框架$FreeTickets$被定义为这些相对便宜的稀疏子网络的集成。尽管是一种集成方法，$FreeTickets$的参数和训练FLOPs甚至比单个密集模型还要少。这一看似违反直觉的结果归功于动态稀疏训练的超高训练/推理效率。$FreeTickets$在以下所有标准上都超越了密集基线：预测准确性、不确定性估计、分布外（OoD）鲁棒性，以及训练和推理的效率。令人印象深刻的是，$FreeTickets$在使用仅约为后者1/5的训练FLOPs的情况下，在ImageNet上使用ResNet50超越了朴素深度集成。我们已在https://github.com/VITA-Group/FreeTickets发布了我们的源代码。",
        "领域": "深度学习集成、稀疏神经网络、计算机视觉",
        "问题": "如何在不增加训练和测试开销的情况下，实现高效的深度集成学习",
        "动机": "解决传统深度集成方法计算成本和内存需求过高的问题",
        "方法": "通过动态稀疏训练直接从零开始训练稀疏子网络，并集成这些子网络",
        "关键词": [
            "深度集成",
            "动态稀疏训练",
            "高效学习",
            "稀疏子网络",
            "ImageNet"
        ],
        "涉及的技术概念": {
            "动态稀疏训练": "在训练过程中动态调整网络的稀疏性，以提高训练和推理的效率",
            "稀疏子网络": "在训练过程中从稀疏网络中提取的子网络，用于构建高效的集成模型",
            "FLOPs": "浮点运算次数，用于衡量模型训练和推理的计算成本"
        },
        "success": true
    },
    {
        "order": 210,
        "title": "Deep Learning without Shortcuts: Shaping the Kernel with Tailored Rectifiers",
        "html": "https://iclr.cc//virtual/2022/poster/6162",
        "abstract": "Training very deep neural networks is still an extremely challenging task. The common solution is to use shortcut connections and normalization layers, which are both crucial ingredients in the popular ResNet architecture. However, there is strong evidence to suggest that ResNets behave more like ensembles of shallower networks than truly deep ones. Recently, it was shown that deep vanilla networks (i.e.~networks without normalization layers or shortcut connections) can be trained as fast as ResNets by applying certain transformations to their activation functions. However, this method (called Deep Kernel Shaping) isn't fully compatible with ReLUs, and produces networks that overfit significantly more than ResNets on ImageNet. In this work, we rectify this situation by developing a new type of transformation that is fully compatible with a variant of ReLUs -- Leaky ReLUs. We show in experiments that our method, which introduces negligible extra computational cost, achieves validation accuracies with deep vanilla networks that are competitive with ResNets (of the same width/depth), and significantly higher than those obtained with the Edge of Chaos (EOC) method. And unlike with EOC, the validation accuracies we obtain do not get worse with depth.",
        "conference": "ICLR",
        "中文标题": "无捷径的深度学习：通过定制整流器塑造内核",
        "摘要翻译": "训练非常深的神经网络仍然是一项极具挑战性的任务。常见的解决方案是使用捷径连接和归一化层，这两者都是流行的ResNet架构中的关键组成部分。然而，有强有力的证据表明，ResNets更像是浅层网络的集合，而非真正的深层网络。最近，研究表明，通过对其激活函数应用某些变换，可以像训练ResNets一样快速地训练深度普通网络（即没有归一化层或捷径连接的网络）。然而，这种方法（称为深度内核塑造）与ReLUs不完全兼容，并且在ImageNet上产生的网络比ResNets过拟合显著更多。在这项工作中，我们通过开发一种新型变换来纠正这种情况，该变换完全兼容ReLUs的一个变体——Leaky ReLUs。我们在实验中展示，我们的方法引入了可忽略的额外计算成本，使用深度普通网络实现的验证准确性与ResNets（相同宽度/深度）相当，并且显著高于通过边缘混沌（EOC）方法获得的结果。与EOC不同，我们获得的验证准确性不会随着深度的增加而变差。",
        "领域": "深度学习优化、神经网络架构设计、激活函数研究",
        "问题": "解决深度普通网络训练速度慢和过拟合问题",
        "动机": "探索不依赖捷径连接和归一化层的深度神经网络训练方法，以实现更高效的训练和更好的泛化能力",
        "方法": "开发一种新型变换方法，与Leaky ReLUs完全兼容，用于深度普通网络的训练",
        "关键词": [
            "深度普通网络",
            "Leaky ReLUs",
            "深度内核塑造",
            "过拟合",
            "训练效率"
        ],
        "涉及的技术概念": {
            "深度内核塑造": "一种通过变换激活函数来训练深度普通网络的方法，旨在提高训练速度和网络性能",
            "Leaky ReLUs": "ReLU激活函数的一个变体，允许小的负激活值，有助于解决ReLU神经元死亡问题",
            "边缘混沌方法": "一种早期的深度网络训练方法，通过调整网络参数使其处于混沌边缘来优化性能，但可能随着深度增加而性能下降"
        },
        "success": true
    },
    {
        "order": 211,
        "title": "Deep Point Cloud Reconstruction",
        "html": "https://iclr.cc//virtual/2022/poster/6776",
        "abstract": "Point cloud obtained from 3D scanning is often sparse, noisy, and irregular. To cope with these issues, recent studies have been separately conducted to densify, denoise, and complete inaccurate point cloud. In this paper, we advocate that jointly solving these tasks leads to significant improvement for point cloud reconstruction. To this end, we propose a deep point cloud reconstruction network consisting of two stages: 1) a 3D sparse stacked-hourglass network as for the initial densification and denoising, 2) a refinement via transformers converting the discrete voxels into continuous 3D points. In particular, we further improve the performance of the transformers by a newly proposed module called amplified positional encoding. This module has been designed to differently amplify the magnitude of positional encoding vectors based on the points' distances for adaptive refinements. Extensive experiments demonstrate that our network achieves state-of-the-art performance among the recent studies in the ScanNet, ICL-NUIM, and ShapeNet datasets. Moreover, we underline the ability of our network to generalize toward real-world and unmet scenes.",
        "conference": "ICLR",
        "中文标题": "深度点云重建",
        "摘要翻译": "从3D扫描获得的点云通常是稀疏的、有噪声的且不规则的。为了应对这些问题，最近的研究分别进行了点云的增密、去噪和补全。在本文中，我们主张联合解决这些任务可以显著改善点云重建的效果。为此，我们提出了一个深度点云重建网络，该网络由两个阶段组成：1）一个3D稀疏堆叠沙漏网络用于初始的增密和去噪，2）通过变换器将离散的体素转换为连续的3D点进行细化。特别是，我们通过一个新提出的称为放大位置编码的模块进一步提高了变换器的性能。该模块设计用于根据点的距离不同地放大位置编码向量的大小，以实现自适应细化。大量实验证明，我们的网络在ScanNet、ICL-NUIM和ShapeNet数据集上的最新研究中达到了最先进的性能。此外，我们强调了我们的网络对现实世界和未见过场景的泛化能力。",
        "领域": "点云处理、3D重建、深度学习",
        "问题": "解决点云稀疏、噪声和不规则的问题，提高点云重建的质量。",
        "动机": "联合解决点云的增密、去噪和补全任务，以显著改善点云重建的效果。",
        "方法": "提出一个两阶段的深度点云重建网络，包括使用3D稀疏堆叠沙漏网络进行初始增密和去噪，以及通过变换器进行细化，并引入放大位置编码模块以提高变换器的性能。",
        "关键词": [
            "点云重建",
            "3D稀疏堆叠沙漏网络",
            "变换器",
            "放大位置编码",
            "自适应细化"
        ],
        "涉及的技术概念": {
            "3D稀疏堆叠沙漏网络": "用于点云的初始增密和去噪，通过堆叠的沙漏结构处理3D稀疏数据。",
            "变换器": "将离散的体素转换为连续的3D点，用于点云的细化。",
            "放大位置编码": "根据点的距离不同地放大位置编码向量的大小，以实现自适应的点云细化。"
        },
        "success": true
    },
    {
        "order": 212,
        "title": "Deep ReLU Networks Preserve Expected Length",
        "html": "https://iclr.cc//virtual/2022/poster/6660",
        "abstract": "Assessing the complexity of functions computed by a neural network helps us understand how the network will learn and generalize. One natural measure of complexity is how the network distorts length - if the network takes a unit-length curve as input, what is the length of the resulting curve of outputs? It has been widely believed that this length grows exponentially in network depth. We prove that in fact this is not the case: the expected length distortion does not grow with depth, and indeed shrinks slightly, for ReLU networks with standard random initialization. We also generalize this result by proving upper bounds both for higher moments of the length distortion and for the distortion of higher-dimensional volumes. These theoretical results are corroborated by our experiments.",
        "conference": "ICLR",
        "中文标题": "深度ReLU网络保持期望长度",
        "摘要翻译": "评估神经网络计算函数的复杂性有助于我们理解网络如何学习和泛化。一个自然的复杂性度量是网络如何扭曲长度——如果网络将单位长度曲线作为输入，输出曲线的长度是多少？人们普遍认为，这种长度随着网络深度的增加呈指数增长。我们证明事实并非如此：对于具有标准随机初始化的ReLU网络，期望的长度扭曲不会随着深度的增加而增长，实际上会略微缩小。我们还通过证明长度扭曲的高阶矩和高维体积扭曲的上界来推广这一结果。这些理论结果得到了我们实验的证实。",
        "领域": "深度学习理论、神经网络分析、函数复杂性度量",
        "问题": "理解神经网络如何扭曲输入数据的长度，以及这种扭曲如何随着网络深度的变化而变化。",
        "动机": "挑战关于神经网络深度与长度扭曲之间关系的普遍误解，提供更准确的理论分析。",
        "方法": "通过理论分析和实验验证，研究ReLU网络在标准随机初始化下对输入长度的影响。",
        "关键词": [
            "ReLU网络",
            "长度扭曲",
            "神经网络深度",
            "函数复杂性",
            "高维体积扭曲"
        ],
        "涉及的技术概念": {
            "ReLU网络": "使用修正线性单元(ReLU)作为激活函数的神经网络，论文中用于研究其对输入长度的影响。",
            "长度扭曲": "衡量神经网络对输入曲线长度改变的程度，论文中作为评估网络复杂性的一个指标。",
            "高维体积扭曲": "扩展了长度扭曲的概念，用于衡量神经网络对高维输入体积的改变，论文中通过理论分析提供了其上界。"
        },
        "success": true
    },
    {
        "order": 213,
        "title": "Defending Against Image Corruptions Through Adversarial Augmentations",
        "html": "https://iclr.cc//virtual/2022/poster/6715",
        "abstract": "Modern neural networks excel at image classification, yet they remain vulnerable to common image corruptions such as blur, speckle noise or fog. Recent methods that focus on this problem, such as AugMix and DeepAugment, introduce defenses that operate in expectation over a distribution of image corruptions. In contrast, the literature on Lp-norm bounded perturbations focuses on defenses against worst-case corruptions. In this work, we reconcile both approaches by proposing AdversarialAugment, a technique which optimizes the parameters of image-to-image models to generate adversarially corrupted augmented images. We theoretically motivate our method and give sufficient conditions for the consistency of its idealized version as well as that of DeepAugment. Our classifiers improve upon the state-of-the-art on common image corruption benchmarks conducted in expectation on CIFAR-10-C and improve worst-case performance against Lp-norm bounded perturbations on both CIFAR-10 and ImageNet.",
        "conference": "ICLR",
        "中文标题": "通过对抗性增强防御图像损坏",
        "摘要翻译": "现代神经网络在图像分类方面表现出色，但它们仍然容易受到模糊、斑点噪声或雾等常见图像损坏的影响。最近针对这一问题的研究方法，如AugMix和DeepAugment，引入了在图像损坏分布上期望操作的防御机制。相比之下，关于Lp范数有界扰动的文献则专注于防御最坏情况的损坏。在这项工作中，我们通过提出AdversarialAugment技术来调和这两种方法，该技术优化了图像到图像模型的参数，以生成对抗性损坏的增强图像。我们从理论上激励了我们的方法，并给出了其理想化版本以及DeepAugment一致性的充分条件。我们的分类器在CIFAR-10-C上进行的常见图像损坏基准测试中，在期望上改进了现有技术，并在CIFAR-10和ImageNet上针对Lp范数有界扰动的最坏情况性能也有所提升。",
        "领域": "图像分类鲁棒性、对抗性防御、图像增强",
        "问题": "提高神经网络对常见图像损坏（如模糊、斑点噪声、雾）和最坏情况Lp范数有界扰动的鲁棒性。",
        "动机": "现有方法要么专注于在图像损坏分布上的期望防御，要么专注于最坏情况的防御，缺乏一种能够同时应对这两种情况的统一方法。",
        "方法": "提出AdversarialAugment技术，通过优化图像到图像模型的参数来生成对抗性损坏的增强图像，从而在期望和最坏情况下提高分类器的鲁棒性。",
        "关键词": [
            "对抗性增强",
            "图像分类鲁棒性",
            "Lp范数有界扰动",
            "图像损坏防御",
            "深度神经网络"
        ],
        "涉及的技术概念": {
            "对抗性增强": "通过优化图像到图像模型的参数生成对抗性损坏的增强图像，以提高模型对图像损坏的鲁棒性。",
            "Lp范数有界扰动": "一种限制扰动大小的度量方法，用于定义和防御最坏情况的图像损坏。",
            "图像分类鲁棒性": "指神经网络在面对图像损坏或对抗性攻击时，仍能保持高分类准确率的能力。"
        },
        "success": true
    },
    {
        "order": 214,
        "title": "DEGREE: Decomposition Based Explanation for Graph Neural Networks",
        "html": "https://iclr.cc//virtual/2022/poster/6059",
        "abstract": "Graph Neural Networks (GNNs) are gaining extensive attention for their application in graph data. However, the black-box nature of GNNs prevents users from understanding and trusting the models, thus hampering their applicability. Whereas explaining GNNs remains a challenge, most existing methods fall into approximation based and perturbation based approaches with suffer from faithfulness problems and unnatural artifacts respectively. To tackle these problems, we propose DEGREE (Decomposition based Explanation for GRaph nEural nEtworks) to provide a faithful explanation for GNN predictions. By decomposing the information generation and aggregation mechanism of GNNs, DEGREE allows tracking the contributions of specific components of the input graph to the final prediction. Based on this, we further design a subgraph level interpretation algorithm to reveal complex interactions between graph nodes that are overlooked by previous methods. The efficiency of our algorithm can be further improved by utilizing GNN characteristics. Finally, we conduct quantitative and qualitative experiments on synthetic and real-world datasets to demonstrate the effectiveness of DEGREE on node classification and graph classification tasks.",
        "conference": "ICLR",
        "中文标题": "DEGREE：基于分解的图神经网络解释方法",
        "摘要翻译": "图神经网络（GNNs）因其在图数据中的应用而受到广泛关注。然而，GNNs的黑箱特性阻碍了用户理解和信任这些模型，从而限制了它们的适用性。尽管解释GNNs仍然是一个挑战，大多数现有方法要么基于近似，要么基于扰动，分别存在忠实性问题和人为痕迹。为了解决这些问题，我们提出了DEGREE（基于分解的图神经网络解释方法），为GNN预测提供忠实解释。通过分解GNNs的信息生成和聚合机制，DEGREE能够追踪输入图特定组成部分对最终预测的贡献。基于此，我们进一步设计了一种子图级解释算法，以揭示先前方法忽视的图节点间复杂交互。利用GNN特性可以进一步提高我们算法的效率。最后，我们在合成和真实世界数据集上进行了定量和定性实验，以证明DEGREE在节点分类和图分类任务上的有效性。",
        "领域": "图神经网络解释性、节点分类、图分类",
        "问题": "解决图神经网络的黑箱特性，提供忠实且自然的模型解释",
        "动机": "提高用户对图神经网络模型的理解和信任，克服现有解释方法在忠实性和人为痕迹上的不足",
        "方法": "提出基于分解的图神经网络解释方法DEGREE，通过分解信息生成和聚合机制追踪输入图组成部分的贡献，并设计子图级解释算法揭示节点间复杂交互",
        "关键词": [
            "图神经网络",
            "模型解释性",
            "分解方法",
            "子图级解释",
            "节点分类"
        ],
        "涉及的技术概念": {
            "信息生成和聚合机制": "DEGREE通过分解这一机制来追踪输入图组成部分对预测的贡献",
            "子图级解释算法": "设计用于揭示图节点间复杂交互的算法，弥补先前方法的不足",
            "忠实解释": "提供准确反映模型决策过程的解释，克服近似和扰动方法的问题"
        },
        "success": true
    },
    {
        "order": 215,
        "title": "Delaunay Component Analysis for Evaluation of Data Representations",
        "html": "https://iclr.cc//virtual/2022/poster/6421",
        "abstract": "Advanced representation learning techniques require reliable and general evaluation methods. Recently, several algorithms based on the common idea of geometric and topological analysis of a manifold approximated from the learned data representations have been proposed. In this work, we introduce Delaunay Component Analysis (DCA) -- an evaluation algorithm which approximates the data manifold using a more suitable neighbourhood graph called Delaunay graph. This provides a reliable manifold estimation even for challenging geometric arrangements of representations such as clusters with varying shape and density as well as outliers, which is where existing methods often fail. Furthermore, we exploit the nature of Delaunay graphs and introduce a framework for assessing the quality of individual novel data representations.  We experimentally validate the proposed DCA method on representations obtained from neural networks trained with contrastive objective, supervised and generative models, and demonstrate various use cases of our extended single point evaluation framework.",
        "conference": "ICLR",
        "中文标题": "用于数据表示评估的Delaunay组件分析",
        "摘要翻译": "先进的表示学习技术需要可靠且通用的评估方法。最近，提出了几种基于从学习到的数据表示中近似流形的几何和拓扑分析的算法。在这项工作中，我们介绍了Delaunay组件分析（DCA）——一种评估算法，它使用一种更合适的邻域图（称为Delaunay图）来近似数据流形。这为具有挑战性的表示几何排列（如形状和密度各异的聚类以及异常值）提供了可靠的流形估计，而这些正是现有方法常常失败的地方。此外，我们利用Delaunay图的特性，引入了一个评估单个新数据表示质量的框架。我们通过实验验证了所提出的DCA方法在通过对比目标、监督和生成模型训练的神经网络获得的表示上的有效性，并展示了我们扩展的单点评估框架的各种用例。",
        "领域": "表示学习评估、几何数据分析、拓扑数据分析",
        "问题": "如何可靠且通用地评估先进表示学习技术产生的数据表示",
        "动机": "现有评估方法在处理具有挑战性的几何排列（如形状和密度各异的聚类以及异常值）时常常失败，需要一种更可靠的评估方法",
        "方法": "引入Delaunay组件分析（DCA），使用Delaunay图近似数据流形，并开发一个评估单个新数据表示质量的框架",
        "关键词": [
            "Delaunay组件分析",
            "表示学习评估",
            "Delaunay图",
            "流形估计",
            "单点评估"
        ],
        "涉及的技术概念": {
            "Delaunay图": "用于近似数据流形的邻域图，提供更可靠的流形估计",
            "流形估计": "通过几何和拓扑分析从数据表示中近似流形，用于评估表示的质量",
            "单点评估框架": "用于评估单个新数据表示质量的框架，扩展了DCA的应用范围"
        },
        "success": true
    },
    {
        "order": 216,
        "title": "DemoDICE: Offline Imitation Learning with Supplementary Imperfect Demonstrations",
        "html": "https://iclr.cc//virtual/2022/poster/6025",
        "abstract": "We consider offline imitation learning (IL), which aims to mimic the expert's behavior from its demonstration without further interaction with the environment. One of the main challenges in offline IL is to deal with the narrow support of the data distribution exhibited by the expert demonstrations that cover only a small fraction of the state and the action spaces. As a result, offline IL algorithms that rely only on expert demonstrations are very unstable since the situation easily deviates from those in the expert demonstrations. In this paper, we assume additional demonstration data of unknown degrees of optimality, which we call imperfect demonstrations. Under this setting, we propose DemoDICE, which effectively utilizes imperfect demonstrations by matching the stationary distribution of a policy with experts' distribution while penalizing its deviation from the overall demonstrations. Compared with the recent IL algorithms that adopt adversarial minimax training objectives, we substantially stabilize overall learning process by reducing minimax optimization to a direct convex optimization in a principled manner. Using extensive tasks, we show that DemoDICE achieves promising results in the offline IL from expert and imperfect demonstrations.",
        "conference": "ICLR",
        "中文标题": "DemoDICE：利用补充不完美演示的离线模仿学习",
        "摘要翻译": "我们考虑离线模仿学习（IL），其目的是在不与环境进一步交互的情况下模仿专家的行为演示。离线IL的主要挑战之一是处理专家演示所展示的数据分布的狭窄支持，这些演示仅覆盖状态和动作空间的一小部分。因此，仅依赖专家演示的离线IL算法非常不稳定，因为情况很容易偏离专家演示中的情况。在本文中，我们假设有额外未知最优程度演示数据，我们称之为不完美演示。在此设置下，我们提出了DemoDICE，它通过将策略的稳态分布与专家的分布匹配，同时惩罚其与整体演示的偏差，从而有效利用不完美演示。与最近采用对抗性极小极大训练目标的IL算法相比，我们通过以原则性方式将极小极大优化减少为直接凸优化，大大稳定了整个学习过程。通过大量任务，我们展示了DemoDICE在从专家和不完美演示中进行离线IL时取得了有希望的结果。",
        "领域": "模仿学习、强化学习、行为克隆",
        "问题": "处理离线模仿学习中专家演示数据分布狭窄导致的学习不稳定问题",
        "动机": "通过利用不完美演示数据来扩展学习范围，提高离线模仿学习的稳定性和效果",
        "方法": "提出DemoDICE算法，通过匹配策略的稳态分布与专家分布，并惩罚与整体演示的偏差，有效利用不完美演示数据",
        "关键词": [
            "离线模仿学习",
            "不完美演示",
            "稳态分布匹配",
            "凸优化",
            "行为克隆"
        ],
        "涉及的技术概念": {
            "离线模仿学习": "在不与环境交互的情况下，通过专家演示学习模仿行为的技术",
            "稳态分布匹配": "通过匹配策略的稳态分布与专家分布来优化学习过程的技术",
            "凸优化": "将学习过程中的优化问题转化为凸优化问题，以提高学习稳定性和效率的技术"
        },
        "success": true
    },
    {
        "order": 217,
        "title": "Demystifying Batch Normalization in ReLU Networks: Equivalent Convex Optimization Models and Implicit Regularization",
        "html": "https://iclr.cc//virtual/2022/poster/7099",
        "abstract": "Batch Normalization (BN) is a commonly used technique to accelerate and stabilize training of deep neural networks. Despite its empirical success, a full theoretical understanding of BN is yet to be developed. In this work, we analyze BN through the lens of convex optimization. We introduce an analytic framework based on convex duality to obtain exact convex representations of weight-decay regularized ReLU networks with BN, which can be trained in polynomial-time. Our analyses also show that optimal layer weights can be obtained as simple closed-form formulas in the high-dimensional and/or overparameterized regimes. Furthermore, we find that Gradient Descent provides an algorithmic bias effect on the standard non-convex BN network, and we design an approach to explicitly encode this implicit regularization into the convex objective. Experiments with CIFAR image classification highlight the effectiveness of this explicit regularization for mimicking and substantially improving the performance of standard BN networks. ",
        "conference": "ICLR",
        "中文标题": "揭秘ReLU网络中的批量归一化：等效凸优化模型与隐式正则化",
        "摘要翻译": "批量归一化（BN）是一种常用的技术，用于加速和稳定深度神经网络的训练。尽管其实证成功，对BN的完整理论理解仍有待发展。在这项工作中，我们通过凸优化的视角分析BN。我们引入了一个基于凸对偶性的分析框架，以获得带有BN的权重衰减正则化ReLU网络的精确凸表示，这些网络可以在多项式时间内训练。我们的分析还表明，在高维和/或过参数化机制下，最优层权重可以作为简单的闭式公式获得。此外，我们发现梯度下降在标准的非凸BN网络上提供了算法偏差效应，我们设计了一种方法，将这种隐式正则化明确编码到凸目标中。CIFAR图像分类的实验突出了这种显式正则化在模仿和显著提高标准BN网络性能方面的有效性。",
        "领域": "深度学习优化、神经网络理论、图像分类",
        "问题": "深入理解批量归一化（BN）在ReLU网络中的作用机制及其优化特性",
        "动机": "尽管批量归一化在实践中显示出加速和稳定深度神经网络训练的效果，但其理论基础尚未完全建立，本研究旨在填补这一空白。",
        "方法": "通过凸优化的视角，引入基于凸对偶性的分析框架，获得BN网络的精确凸表示，并设计方法将梯度下降的隐式正则化效应显式编码到优化目标中。",
        "关键词": [
            "批量归一化",
            "凸优化",
            "ReLU网络",
            "隐式正则化",
            "图像分类"
        ],
        "涉及的技术概念": {
            "批量归一化（BN）": "用于加速和稳定深度神经网络训练的技术，通过规范化每层的输入来实现。",
            "凸对偶性": "用于将非凸优化问题转化为凸问题，以便于分析和求解的技术。",
            "隐式正则化": "指优化算法（如梯度下降）在训练过程中自然引入的正则化效应，本研究通过显式编码来利用这一效应。"
        },
        "success": true
    },
    {
        "order": 218,
        "title": "Demystifying Limited Adversarial Transferability in Automatic Speech Recognition Systems",
        "html": "https://iclr.cc//virtual/2022/poster/5930",
        "abstract": "The targeted transferability of adversarial samples enables attackers to exploit black-box models in the real-world. The most popular method to produce these adversarial samples is optimization attacks, which have been shown to achieve a high level of transferability in some domains. However, recent research has demonstrated that these attack samples fail to transfer when applied to Automatic Speech Recognition Systems (ASRs). In this paper, we investigate factors preventing this transferability via exhaustive experimentation. To do so, we perform an ablation study on each stage of the ASR pipeline. We discover and quantify six factors (i.e., input type, MFCC, RNN, output type, and vocabulary and sequence sizes) that impact the targeted transferability of optimization attacks against ASRs. Future research can leverage our findings to build ASRs that are more robust to other transferable attack types (e.g., signal processing attacks), or to modify architectures in other domains to reduce their exposure to targeted transferability of optimization attacks.",
        "conference": "ICLR",
        "中文标题": "揭秘自动语音识别系统中有限的对抗性可转移性",
        "摘要翻译": "对抗样本的目标可转移性使得攻击者能够在现实世界中利用黑盒模型。产生这些对抗样本的最流行方法是优化攻击，这些攻击在某些领域已被证明能够实现高度的可转移性。然而，最近的研究表明，当这些攻击样本应用于自动语音识别系统（ASRs）时，它们无法转移。在本文中，我们通过详尽的实验研究了阻碍这种可转移性的因素。为此，我们对ASR流程的每个阶段进行了消融研究。我们发现并量化了六个影响针对ASRs的优化攻击目标可转移性的因素（即输入类型、MFCC、RNN、输出类型、词汇量和序列大小）。未来的研究可以利用我们的发现来构建对其他可转移攻击类型（例如信号处理攻击）更鲁棒的ASRs，或者修改其他领域的架构以减少它们对优化攻击目标可转移性的暴露。",
        "领域": "语音识别安全、对抗性攻击、深度学习安全",
        "问题": "研究自动语音识别系统中对抗样本的可转移性受限的原因",
        "动机": "理解并解决优化攻击在自动语音识别系统中可转移性失败的问题，以提高系统安全性",
        "方法": "通过对ASR流程各阶段的消融研究，识别并量化影响对抗样本可转移性的关键因素",
        "关键词": [
            "对抗性攻击",
            "自动语音识别",
            "可转移性",
            "优化攻击",
            "系统安全"
        ],
        "涉及的技术概念": {
            "对抗样本": "在输入数据上添加微小扰动以欺骗机器学习模型的样本",
            "优化攻击": "一种通过优化方法生成对抗样本的技术，旨在实现高度的可转移性",
            "消融研究": "通过系统地移除或修改系统的某些部分来研究其对整体性能影响的方法"
        },
        "success": true
    },
    {
        "order": 219,
        "title": "Denoising Likelihood Score Matching for Conditional Score-based Data Generation",
        "html": "https://iclr.cc//virtual/2022/poster/6444",
        "abstract": "Many existing conditional score-based data generation methods utilize Bayes' theorem to decompose the gradients of a log posterior density into a mixture of scores. These methods facilitate the training procedure of conditional score models, as a mixture of scores can be separately estimated using a score model and a classifier. However, our analysis indicates that the training objectives for the classifier in these methods may lead to a serious score mismatch issue, which corresponds to the situation that the estimated scores deviate from the true ones. Such an issue causes the samples to be misled by the deviated scores during the diffusion process, resulting in a degraded sampling quality. To resolve it, we theoretically formulate a novel training objective, called Denoising Likelihood Score Matching (DLSM) loss, for the classifier to match the gradients of the true log likelihood density. Our experimental evidences show that the proposed method outperforms the previous methods on both Cifar-10 and Cifar-100 benchmarks noticeably in terms of several key evaluation metrics. We thus conclude that, by adopting DLSM, the conditional scores can be accurately modeled, and the effect of the score mismatch issue is alleviated.",
        "conference": "ICLR",
        "中文标题": "基于条件评分数据生成的去噪似然评分匹配",
        "摘要翻译": "许多现有的基于条件评分的数据生成方法利用贝叶斯定理将对数后验密度的梯度分解为评分的混合。这些方法简化了条件评分模型的训练过程，因为评分的混合可以分别使用评分模型和分类器来估计。然而，我们的分析表明，这些方法中分类器的训练目标可能导致严重的评分不匹配问题，即估计的评分偏离真实评分。这种问题会导致样本在扩散过程中被偏离的评分误导，从而降低采样质量。为了解决这个问题，我们从理论上为分类器制定了一个新的训练目标，称为去噪似然评分匹配（DLSM）损失，以匹配真实对数似然密度的梯度。我们的实验证据表明，所提出的方法在Cifar-10和Cifar-100基准测试中，在几个关键评估指标上明显优于之前的方法。因此，我们得出结论，通过采用DLSM，可以准确建模条件评分，并减轻评分不匹配问题的影响。",
        "领域": "生成模型、图像生成、条件数据生成",
        "问题": "解决基于条件评分的数据生成方法中评分不匹配问题，以提高采样质量",
        "动机": "现有的条件评分数据生成方法在训练分类器时可能导致评分不匹配，影响样本质量，需要新的训练目标来解决这一问题",
        "方法": "提出了一种新的训练目标——去噪似然评分匹配（DLSM）损失，用于分类器以匹配真实对数似然密度的梯度",
        "关键词": [
            "条件评分生成",
            "去噪似然评分匹配",
            "评分不匹配",
            "图像生成",
            "DLSM损失"
        ],
        "涉及的技术概念": {
            "条件评分生成": "利用条件信息生成数据的评分模型，用于指导数据生成过程",
            "去噪似然评分匹配（DLSM）": "一种新的训练目标，旨在通过匹配真实对数似然密度的梯度来减少评分不匹配",
            "评分不匹配": "估计的评分与真实评分之间的偏差，影响数据生成的质量"
        },
        "success": true
    },
    {
        "order": 220,
        "title": "DEPTS: Deep Expansion Learning for Periodic Time Series Forecasting",
        "html": "https://iclr.cc//virtual/2022/poster/7105",
        "abstract": "Periodic time series (PTS) forecasting plays a crucial role in a variety of industries to foster critical tasks, such as early warning, pre-planning, resource scheduling, etc. However, the complicated dependencies of the PTS signal on its inherent periodicity as well as the sophisticated composition of various periods hinder the performance of PTS forecasting. In this paper, we introduce a deep expansion learning framework, DEPTS, for PTS forecasting. DEPTS starts with a decoupled formulation by introducing the periodic state as a hidden variable, which stimulates us to make two dedicated modules to tackle the aforementioned two challenges. First, we develop an expansion module on top of residual learning to perform a layer-by-layer expansion of those complicated dependencies. Second, we introduce a periodicity module with a parameterized periodic function that holds sufficient capacity to capture diversified periods. Moreover, our two customized modules also have certain interpretable capabilities, such as attributing the forecasts to either local momenta or global periodicity and characterizing certain core periodic properties, e.g., amplitudes and frequencies. Extensive experiments on both synthetic data and real-world data demonstrate the effectiveness of DEPTS on handling PTS. In most cases, DEPTS achieves significant improvements over the best baseline. Specifically, the error reduction can even reach up to 20% for a few cases. All codes for this paper are publicly available.",
        "conference": "ICLR",
        "中文标题": "DEPTS：用于周期性时间序列预测的深度扩展学习",
        "摘要翻译": "周期性时间序列（PTS）预测在多个行业中对于促进关键任务如早期预警、预先规划、资源调度等起着至关重要的作用。然而，PTS信号对其固有周期性的复杂依赖以及各种周期的复杂组合阻碍了PTS预测的性能。本文中，我们介绍了一种用于PTS预测的深度扩展学习框架DEPTS。DEPTS从引入周期性状态作为隐藏变量的解耦公式开始，这激励我们开发两个专用模块以解决上述两个挑战。首先，我们在残差学习的基础上开发了一个扩展模块，以逐层扩展那些复杂的依赖关系。其次，我们引入了一个带有参数化周期函数的周期性模块，该模块具有足够的容量来捕捉多样化的周期。此外，我们的两个定制模块还具有一定的可解释能力，例如将预测归因于局部动量或全局周期性，并表征某些核心周期性属性，如振幅和频率。在合成数据和真实世界数据上的大量实验证明了DEPTS在处理PTS方面的有效性。在大多数情况下，DEPTS相比最佳基线实现了显著的改进。具体来说，对于少数情况，误差减少甚至可以达到20%。本文的所有代码均已公开。",
        "领域": "时间序列预测、深度学习应用、周期性数据分析",
        "问题": "解决周期性时间序列预测中复杂依赖性和多样化周期组合带来的性能挑战",
        "动机": "提高周期性时间序列预测的准确性和可解释性，以支持早期预警、资源调度等关键任务",
        "方法": "开发了一个深度扩展学习框架DEPTS，包括一个用于扩展复杂依赖关系的扩展模块和一个捕捉多样化周期的周期性模块",
        "关键词": [
            "周期性时间序列预测",
            "深度扩展学习",
            "残差学习",
            "参数化周期函数",
            "可解释性"
        ],
        "涉及的技术概念": {
            "深度扩展学习": "一种结合深度学习和扩展学习的方法，用于处理周期性时间序列中的复杂依赖关系",
            "残差学习": "用于构建扩展模块，通过逐层扩展来学习时间序列中的复杂模式",
            "参数化周期函数": "周期性模块中的核心技术，能够灵活捕捉和表征时间序列中的多样化周期性特征"
        },
        "success": true
    },
    {
        "order": 221,
        "title": "DeSKO: Stability-Assured Robust Control with a Deep Stochastic Koopman Operator",
        "html": "https://iclr.cc//virtual/2022/poster/7057",
        "abstract": "The Koopman operator theory linearly describes nonlinear dynamical systems in a high-dimensional functional space and it allows to apply linear control methods to highly nonlinear systems. However, the Koopman operator does not account for any uncertainty in dynamical systems, causing it to perform poorly in real-world applications.Therefore, we propose a deep stochastic Koopman operator (DeSKO) model in a robust learning control framework to guarantee stability of nonlinear stochastic systems. The DeSKO model captures a dynamical system's uncertainty by inferring a distribution of observables. We use the inferred distribution to design a robust, stabilizing closed-loop controller for a dynamical system. Modeling and control experiments on several advanced control benchmarks show that our framework is more robust and scalable than state-of-the-art deep Koopman operators and reinforcement learning methods. Tested control benchmarks include a soft robotic arm, a legged robot, and a biological gene regulatory network. We also demonstrate that this robust control method resists previously unseen uncertainties, such as external disturbances, with a magnitude of up to five times the maximum control input. Our approach opens up new possibilities in learning control for high-dimensional nonlinear systems while robustly managing internal or external uncertainty.",
        "conference": "ICLR",
        "中文标题": "DeSKO：基于深度随机Koopman算子的稳定性保证鲁棒控制",
        "摘要翻译": "Koopman算子理论在高维函数空间中线性描述非线性动态系统，并允许将线性控制方法应用于高度非线性系统。然而，Koopman算子没有考虑动态系统中的任何不确定性，导致其在现实世界应用中表现不佳。因此，我们提出了一个在鲁棒学习控制框架中的深度随机Koopman算子（DeSKO）模型，以保证非线性随机系统的稳定性。DeSKO模型通过推断可观测量分布来捕捉动态系统的不确定性。我们利用推断出的分布为动态系统设计一个鲁棒的、稳定的闭环控制器。在几个先进控制基准上的建模和控制实验表明，我们的框架比最先进的深度Koopman算子和强化学习方法更加鲁棒和可扩展。测试的控制基准包括一个软体机械臂、一个腿式机器人和一个生物基因调控网络。我们还证明了这种鲁棒控制方法能够抵抗之前未见的不确定性，如外部干扰，其幅度可达最大控制输入的五倍。我们的方法为高维非线性系统的学习控制开辟了新的可能性，同时鲁棒地管理内部或外部的不确定性。",
        "领域": "非线性系统控制、机器人控制、生物系统建模",
        "问题": "解决Koopman算子在处理动态系统不确定性方面的不足，提高非线性随机系统的控制稳定性。",
        "动机": "Koopman算子理论虽然能够线性描述非线性动态系统，但在实际应用中由于未考虑系统不确定性，导致控制效果不佳。",
        "方法": "提出深度随机Koopman算子（DeSKO）模型，通过推断可观测量分布捕捉系统不确定性，并设计鲁棒的闭环控制器。",
        "关键词": [
            "深度随机Koopman算子",
            "鲁棒控制",
            "非线性系统",
            "稳定性保证",
            "动态系统不确定性"
        ],
        "涉及的技术概念": {
            "Koopman算子理论": "用于在高维函数空间中线性描述非线性动态系统，使得线性控制方法可以应用于非线性系统。",
            "深度随机Koopman算子（DeSKO）": "扩展了传统Koopman算子，通过推断可观测量分布来捕捉和应对动态系统中的不确定性。",
            "鲁棒闭环控制器": "基于DeSKO模型设计的控制器，能够在存在内部或外部不确定性的情况下，保证系统的稳定性。"
        },
        "success": true
    },
    {
        "order": 222,
        "title": "DictFormer: Tiny Transformer with Shared Dictionary",
        "html": "https://iclr.cc//virtual/2022/poster/6092",
        "abstract": "We introduce DictFormer with the efficient shared dictionary to provide a compact, fast, and accurate transformer model. DictFormer significantly reduces the redundancy in the transformer's parameters by replacing the prior transformer's parameters with a compact, shared dictionary, few unshared coefficients, and indices. Also, DictFormer enables faster computations since expensive weights multiplications are converted into cheap shared look-ups on dictionary and few linear projections. Training dictionary and coefficients are not trivial since indices used for looking up dictionary are not differentiable. We adopt a sparse-constraint training with $l_1\\,\\,norm$ relaxation to learn coefficients and indices in DictFormer. DictFormer is flexible to support different model sizes by dynamically changing dictionary size. Compared to existing lightweight Transformers, DictFormer consistently reduces model size over Transformer on multiple tasks, e.g., machine translation, abstractive summarization, and language modeling. Extensive experiments show that DictFormer reduces $3.6\\times$ to $8.9\\times$ model size with similar accuracy over multiple tasks, compared to Transformer.   ",
        "conference": "ICLR",
        "中文标题": "DictFormer：共享字典的微型Transformer",
        "摘要翻译": "我们介绍了DictFormer，它通过高效的共享字典提供了一个紧凑、快速且准确的Transformer模型。DictFormer通过用一个紧凑的共享字典、少量非共享系数和索引替换原有Transformer的参数，显著减少了Transformer参数中的冗余。此外，DictFormer实现了更快的计算，因为昂贵的权重乘法被转换为在字典上进行廉价的共享查找和少量线性投影。训练字典和系数并不简单，因为用于查找字典的索引是不可微的。我们采用带有l1范数松弛的稀疏约束训练来学习DictFormer中的系数和索引。DictFormer通过动态改变字典大小灵活支持不同的模型规模。与现有的轻量级Transformer相比，DictFormer在多个任务（如机器翻译、抽象摘要和语言建模）上持续减少了相对于Transformer的模型大小。大量实验表明，与Transformer相比，DictFormer在多个任务上以相似的准确度减少了3.6倍到8.9倍的模型大小。",
        "领域": "自然语言处理与视觉结合, 机器翻译, 语言建模",
        "问题": "减少Transformer模型的参数冗余和计算成本，同时保持或提高模型的准确性和效率。",
        "动机": "为了解决传统Transformer模型在参数冗余和计算成本方面的问题，提出一种更紧凑、快速且准确的模型。",
        "方法": "采用共享字典、少量非共享系数和索引替换原有Transformer的参数，结合稀疏约束训练和l1范数松弛来学习系数和索引。",
        "关键词": [
            "共享字典",
            "微型Transformer",
            "稀疏约束训练",
            "模型压缩",
            "高效计算"
        ],
        "涉及的技术概念": {
            "共享字典": "用于替换传统Transformer参数，减少模型冗余，提高计算效率。",
            "稀疏约束训练": "用于学习DictFormer中的系数和索引，解决索引不可微的问题。",
            "l1范数松弛": "在稀疏约束训练中采用，帮助模型学习更有效的系数和索引。"
        },
        "success": true
    },
    {
        "order": 223,
        "title": "Differentiable DAG Sampling",
        "html": "https://iclr.cc//virtual/2022/poster/7113",
        "abstract": "We propose a new differentiable probabilistic model over DAGs (DP-DAG). DP-DAG allows fast and differentiable DAG sampling suited to continuous optimization. To this end, DP-DAG samples a DAG by successively (1) sampling a linear ordering of the node and (2) sampling edges consistent with the sampled linear ordering. We further propose VI-DP-DAG, a new method for DAG learning from observational data which combines DP-DAG with variational inference. Hence,VI-DP-DAG approximates the posterior probability over DAG edges given the observed data. VI-DP-DAG is guaranteed to output a valid DAG at any time during training and does not require any complex augmented Lagrangian optimization scheme in contrast to existing differentiable DAG learning approaches. In our extensive experiments, we compare VI-DP-DAG to other differentiable DAG learning baselines on synthetic and real datasets. VI-DP-DAG significantly improves DAG structure and causal mechanism learning while training faster than competitors.",
        "conference": "ICLR",
        "中文标题": "可微DAG采样",
        "摘要翻译": "我们提出了一种新的可微概率模型DP-DAG（可微DAG概率模型）。DP-DAG允许快速且可微的DAG采样，适用于连续优化。为此，DP-DAG通过连续（1）采样节点的线性排序和（2）采样与采样线性排序一致的边来采样DAG。我们进一步提出了VI-DP-DAG，这是一种结合了DP-DAG与变分推理的从观测数据中学习DAG的新方法。因此，VI-DP-DAG近似于给定观测数据的DAG边的后验概率。与现有的可微DAG学习方法相比，VI-DP-DAG在训练过程中的任何时候都能保证输出有效的DAG，并且不需要任何复杂的增广拉格朗日优化方案。在我们的大量实验中，我们在合成和真实数据集上将VI-DP-DAG与其他可微DAG学习基线进行了比较。VI-DP-DAG显著改善了DAG结构和因果机制学习，同时训练速度比竞争对手快。",
        "领域": "因果推理、图神经网络、概率图模型",
        "问题": "如何在连续优化中实现快速且可微的DAG采样，以及如何从观测数据中有效学习DAG结构。",
        "动机": "现有的可微DAG学习方法需要复杂的增广拉格朗日优化方案，且在训练过程中不能保证始终输出有效的DAG。",
        "方法": "提出DP-DAG模型实现快速可微DAG采样，结合变分推理提出VI-DP-DAG方法从观测数据中学习DAG结构。",
        "关键词": [
            "可微DAG采样",
            "变分推理",
            "因果推理",
            "图神经网络",
            "概率图模型"
        ],
        "涉及的技术概念": {
            "可微DAG采样": "通过连续采样节点的线性排序和边来实现DAG的快速且可微采样，适用于连续优化。",
            "变分推理": "用于近似给定观测数据的DAG边的后验概率，结合DP-DAG提出VI-DP-DAG方法。",
            "增广拉格朗日优化": "现有的可微DAG学习方法需要复杂的增广拉格朗日优化方案，而VI-DP-DAG不需要。"
        },
        "success": true
    },
    {
        "order": 224,
        "title": "Differentiable Expectation-Maximization for Set Representation Learning",
        "html": "https://iclr.cc//virtual/2022/poster/5927",
        "abstract": "We tackle the set2vec problem, the task of extracting a vector representation from an input set comprised of a variable number of feature vectors. Although recent approaches based on self attention such as (Set)Transformers were very successful due to the capability of capturing complex interaction between set elements, the  computational overhead is the well-known downside. The inducing-point attention and the latest optimal transport kernel embedding (OTKE) are promising remedies that attain comparable or better performance with reduced computational cost, by incorporating a fixed number of learnable queries in attention. In this paper we approach the set2vec problem from a completely different perspective. The elements of an input set are considered as i.i.d.~samples from a mixture distribution, and we define our set embedding feed-forward network as the  maximum-a-posterior (MAP) estimate of the mixture which is approximately attained by a few Expectation-Maximization (EM) steps. The whole MAP-EM steps are differentiable operations with a fixed number of mixture parameters, allowing efficient auto-diff back-propagation for any given downstream task. Furthermore, the proposed mixture set data fitting framework allows unsupervised set representation learning naturally via marginal likelihood maximization aka the empirical Bayes. Interestingly, we also find that OTKE can be seen as a special case of our framework, specifically a single-step EM with extra balanced assignment constraints on the E-step. Compared to OTKE, our approach provides more flexible set embedding as well as prior-induced model regularization. We evaluate our approach on various tasks demonstrating improved performance over the state-of-the-arts.",
        "conference": "ICLR",
        "中文标题": "可微分期望最大化在集合表示学习中的应用",
        "摘要翻译": "我们解决了set2vec问题，即从由可变数量的特征向量组成的输入集合中提取向量表示的任务。尽管基于自注意力机制的近期方法（如(Set)Transformers）由于能够捕捉集合元素之间复杂的相互作用而非常成功，但计算开销是其众所周知的缺点。诱导点注意力和最新的最优传输核嵌入（OTKE）通过将固定数量的可学习查询纳入注意力中，以降低的计算成本实现了相当或更好的性能，是有希望的补救措施。在本文中，我们从完全不同的角度处理set2vec问题。输入集合的元素被视为来自混合分布的独立同分布样本，我们将我们的集合嵌入前馈网络定义为混合分布的最大后验（MAP）估计，该估计通过几个期望最大化（EM）步骤近似实现。整个MAP-EM步骤是具有固定数量混合参数的可微分操作，允许对任何给定的下游任务进行高效的自动微分反向传播。此外，提出的混合集合数据拟合框架通过边际似然最大化（即经验贝叶斯）自然地允许无监督的集合表示学习。有趣的是，我们还发现OTKE可以被视为我们框架的一个特例，具体来说，是在E步骤上具有额外平衡分配约束的单步EM。与OTKE相比，我们的方法提供了更灵活的集合嵌入以及先验诱导的模型正则化。我们在各种任务上评估了我们的方法，展示了优于现有技术的性能。",
        "领域": "集合表示学习",
        "问题": "如何从可变数量的特征向量组成的输入集合中高效提取向量表示",
        "动机": "解决现有基于自注意力机制的方法在计算开销上的不足，同时保持或提升性能",
        "方法": "将输入集合的元素视为来自混合分布的独立同分布样本，通过可微分的期望最大化步骤近似实现最大后验估计，进行集合表示学习",
        "关键词": [
            "集合表示学习",
            "可微分期望最大化",
            "最大后验估计",
            "无监督学习",
            "最优传输核嵌入"
        ],
        "涉及的技术概念": {
            "期望最大化（EM）": "用于近似实现混合分布的最大后验估计，是可微分操作，支持高效的反向传播",
            "最大后验（MAP）估计": "定义集合嵌入前馈网络的目标，通过EM步骤近似实现",
            "最优传输核嵌入（OTKE）": "作为本文方法的一个特例，展示了方法的广泛适用性和灵活性"
        },
        "success": true
    },
    {
        "order": 225,
        "title": "Differentiable Gradient Sampling for Learning Implicit 3D Scene Reconstructions from a Single Image",
        "html": "https://iclr.cc//virtual/2022/poster/6075",
        "abstract": "Implicit shape models are promising 3D representations for modeling arbitrary locations, with Signed Distance Functions (SDFs) particularly suitable for clear mesh surface reconstruction. Existing approaches for single object reconstruction impose supervision signals based on the loss of the signed distance value from all locations in a scene, posing difficulties when extending to real-world scenarios. The spatial gradient of the signed distance field, rather than the SDF value itself, has not been typically employed as a source of supervision for single-view reconstruction, in part due to the difficulties of differentiable sampling a spatial gradient from the feature map. In this study, we derive a novel closed-form gradient sampling solution for Differentialble Gradient Sampling (DGS) that enables backpropagation of the loss of the spatial gradient back to the feature map pixels, thus allowing the imposition of the loss efficiently on the spatial gradient. As a result, we achieve high-quality single view indoor scene reconstruction results learning directly from a real-world scanned dataset (e.g. ScannetV2). Our model also performs well when generalizing to unseen images downloaded directly from the internet (Fig. 1). We comfortably advanced the state-of-the-art results with several established datasets including ShapeNet and ScannetV2; extensive quantitative analysis confirmed that our proposed DGS module plays an essential role in achieving this performance improvement. Full codes are available in MaskedURL.",
        "conference": "ICLR",
        "中文标题": "可微分梯度采样用于从单张图像学习隐式3D场景重建",
        "摘要翻译": "隐式形状模型是建模任意位置的有前景的3D表示方法，其中符号距离函数（SDFs）特别适合于清晰的网格表面重建。现有的单物体重建方法基于场景中所有位置的符号距离值的损失施加监督信号，这在扩展到现实世界场景时存在困难。符号距离场的空间梯度，而非SDF值本身，通常未被用作单视图重建的监督来源，部分原因在于从特征图中可微分采样空间梯度的困难。在本研究中，我们推导了一种新颖的封闭形式梯度采样解决方案，用于可微分梯度采样（DGS），使得空间梯度的损失能够反向传播回特征图像素，从而允许在空间梯度上高效施加损失。因此，我们直接从现实世界扫描的数据集（例如ScannetV2）学习，实现了高质量的单视图室内场景重建结果。我们的模型在泛化到直接从互联网下载的未见图像时也表现良好（图1）。我们在包括ShapeNet和ScannetV2在内的多个已建立的数据集上轻松推进了最先进的结果；广泛的定量分析证实，我们提出的DGS模块在实现这一性能改进中发挥了关键作用。完整代码可在MaskedURL获取。",
        "领域": "3D重建、深度学习、计算机视觉",
        "问题": "如何从单张图像高效学习隐式3D场景重建",
        "动机": "解决现有方法在扩展到现实世界场景时遇到的困难，以及利用符号距离场的空间梯度作为监督来源的挑战",
        "方法": "提出了一种新颖的封闭形式梯度采样解决方案（DGS），使得空间梯度的损失能够反向传播回特征图像素",
        "关键词": [
            "可微分梯度采样",
            "隐式3D重建",
            "符号距离函数",
            "单视图重建",
            "空间梯度"
        ],
        "涉及的技术概念": {
            "符号距离函数（SDFs）": "用于表示3D形状的隐式模型，特别适合于清晰的网格表面重建",
            "可微分梯度采样（DGS）": "一种新颖的封闭形式梯度采样解决方案，使得空间梯度的损失能够反向传播回特征图像素",
            "空间梯度": "符号距离场的梯度，作为监督信号用于提高重建质量"
        },
        "success": true
    },
    {
        "order": 226,
        "title": "Differentiable Prompt Makes Pre-trained Language Models Better Few-shot Learners",
        "html": "https://iclr.cc//virtual/2022/poster/6259",
        "abstract": "Large-scale pre-trained language models have contributed significantly to natural language processing by demonstrating remarkable abilities as few-shot learners. However, their effectiveness depends mainly on scaling the model parameters and prompt design, hindering their implementation in most real-world applications. This study proposes a novel pluggable, extensible, and efficient approach named DifferentiAble pRompT (DART), which can convert small language models into better few-shot learners. The main principle behind this approach involves reformulating potential natural language processing tasks into the task of a pre-trained language model and differentially optimizing the prompt template as well as the target label with backpropagation. Furthermore, the proposed approach can be: (i) Plugged to any pre-trained language models; (ii) Extended to widespread classification tasks. A comprehensive evaluation of standard NLP tasks demonstrates that the proposed approach achieves a better few-shot performance.",
        "conference": "ICLR",
        "中文标题": "可微分提示使预训练语言模型成为更好的少样本学习者",
        "摘要翻译": "大规模预训练语言模型通过展示作为少样本学习者的卓越能力，对自然语言处理领域做出了显著贡献。然而，它们的有效性主要依赖于模型参数的规模和提示设计，这阻碍了在大多数现实世界应用中的实施。本研究提出了一种新颖的可插拔、可扩展且高效的方法，名为可微分提示（DART），它可以将小型语言模型转化为更好的少样本学习者。该方法背后的主要原理包括将潜在的自然语言处理任务重新表述为预训练语言模型的任务，并通过反向传播对提示模板和目标标签进行微分优化。此外，所提出的方法可以：（i）插入到任何预训练语言模型中；（ii）扩展到广泛的分类任务。对标准自然语言处理任务的全面评估表明，所提出的方法实现了更好的少样本性能。",
        "领域": "自然语言处理与视觉结合, 少样本学习, 预训练语言模型优化",
        "问题": "如何提高预训练语言模型在少样本学习场景下的效率和效果",
        "动机": "解决预训练语言模型在少样本学习中对大规模参数和精心设计提示的依赖，使其更适用于现实世界应用",
        "方法": "提出了一种名为DART的可插拔、可扩展方法，通过微分优化提示模板和目标标签，将小型语言模型转化为更好的少样本学习者",
        "关键词": [
            "可微分提示",
            "少样本学习",
            "预训练语言模型",
            "自然语言处理",
            "反向传播优化"
        ],
        "涉及的技术概念": {
            "可微分提示": "通过微分优化提示模板和目标标签，提高模型在少样本学习中的表现",
            "少样本学习": "在有限样本下训练模型，使其能够快速适应新任务",
            "反向传播优化": "利用反向传播算法优化模型参数和提示设计，提升学习效率和效果"
        },
        "success": true
    },
    {
        "order": 227,
        "title": "Differentiable Scaffolding Tree for Molecule Optimization",
        "html": "https://iclr.cc//virtual/2022/poster/6701",
        "abstract": "The structural design of functional molecules, also called molecular optimization, is an essential chemical science and engineering task with important applications, such as drug discovery. Deep generative models and combinatorial optimization methods achieve initial success but still struggle with directly modeling discrete chemical structures and often heavily rely on brute-force enumeration. The challenge comes from the discrete and non-differentiable nature of molecule structures. To address this, we propose differentiable scaffolding tree (DST) that utilizes a learned knowledge network to convert discrete chemical structures to locally differentiable ones. DST enables a gradient-based optimization on a chemical graph structure by back-propagating the derivatives from the target properties through a graph neural network (GNN). Our empirical studies show the gradient-based molecular optimizations are both effective and sample efficient (in terms of oracle calling number). Furthermore, the learned graph parameters can also provide an explanation that helps domain experts understand the model output. The code repository (including processed data, trained model, demonstration, molecules with the highest property) is available at https://github.com/futianfan/DST.",
        "conference": "ICLR",
        "中文标题": "可微分支架树用于分子优化",
        "摘要翻译": "功能分子的结构设计，也称为分子优化，是化学科学与工程中的一项基本任务，具有重要的应用价值，如药物发现。深度生成模型和组合优化方法虽然取得了初步成功，但在直接建模离散化学结构方面仍存在困难，且往往严重依赖于暴力枚举。这一挑战源于分子结构的离散性和不可微分性。为了解决这一问题，我们提出了可微分支架树（DST），它利用学习到的知识网络将离散的化学结构转换为局部可微分的结构。DST通过图神经网络（GNN）从目标属性反向传播导数，实现了对化学图结构的基于梯度的优化。我们的实证研究表明，基于梯度的分子优化既有效又样本高效（就oracle调用次数而言）。此外，学习到的图参数还可以提供解释，帮助领域专家理解模型输出。代码仓库（包括处理过的数据、训练好的模型、演示、具有最高属性的分子）可在https://github.com/futianfan/DST获取。",
        "领域": "分子优化、药物发现、图神经网络",
        "问题": "如何有效地优化分子结构，克服离散性和不可微分性带来的挑战",
        "动机": "解决分子优化中直接建模离散化学结构的困难，减少对暴力枚举的依赖",
        "方法": "提出可微分支架树（DST），利用知识网络将离散化学结构转换为局部可微分结构，通过图神经网络实现基于梯度的优化",
        "关键词": [
            "可微分支架树",
            "分子优化",
            "图神经网络",
            "药物发现",
            "梯度优化"
        ],
        "涉及的技术概念": {
            "可微分支架树（DST）": "将离散的化学结构转换为局部可微分的结构，便于基于梯度的优化",
            "图神经网络（GNN）": "用于从目标属性反向传播导数，实现对化学图结构的优化",
            "梯度优化": "通过反向传播导数，有效且样本高效地优化分子结构"
        },
        "success": true
    },
    {
        "order": 228,
        "title": "Differentially Private Fine-tuning of Language Models",
        "html": "https://iclr.cc//virtual/2022/poster/7161",
        "abstract": "We give simpler, sparser, and faster algorithms for differentially private fine-tuning of large-scale pre-trained language models, which achieve the state-of-the-art privacy versus utility tradeoffs on many standard NLP tasks. We propose a meta-framework for this problem, inspired by the recent success of highly parameter-efficient methods for fine-tuning. Our experiments show that differentially private adaptations of these approaches outperform previous private algorithms in three important dimensions: utility, privacy, and the computational and memory cost of private training. On many commonly studied datasets, the utility of private models approaches that of non-private models. For example, on the MNLI dataset we achieve an accuracy of $87.8\\%$ using RoBERTa-Large and $83.5\\%$ using RoBERTa-Base with a privacy budget of $\\epsilon = 6.7$. In comparison, absent privacy constraints, RoBERTa-Large achieves an accuracy of $90.2\\%$. Our findings are similar for natural language generation when privately fine-tuning GPT-2. Our experiments also show that larger models are better suited for private fine-tuning: while they are well known to achieve superior accuracy non-privately, we find that they also better maintain their accuracy when privacy is introduced.",
        "conference": "ICLR",
        "中文标题": "语言模型的差分隐私微调",
        "摘要翻译": "我们提出了更简单、更稀疏、更快速的算法，用于大规模预训练语言模型的差分隐私微调，这些算法在许多标准NLP任务上实现了隐私与效用之间的最先进权衡。受最近高度参数高效的微调方法成功的启发，我们为这一问题提出了一个元框架。我们的实验表明，这些方法的差分隐私适应在三个重要维度上优于以前的隐私算法：效用、隐私以及私有训练的计算和内存成本。在许多常用研究的数据集上，私有模型的效用接近非私有模型。例如，在MNLI数据集上，我们使用RoBERTa-Large实现了87.8%的准确率，使用RoBERTa-Base实现了83.5%的准确率，隐私预算为ε=6.7。相比之下，在没有隐私约束的情况下，RoBERTa-Large的准确率为90.2%。我们在自然语言生成方面对GPT-2进行私有微调时也发现了类似的发现。我们的实验还表明，较大的模型更适合私有微调：虽然众所周知它们在非私有情况下实现了更高的准确率，但我们发现它们在引入隐私时也能更好地保持其准确率。",
        "领域": "自然语言处理与隐私保护、模型微调技术、差分隐私应用",
        "问题": "如何在保证差分隐私的前提下，高效地对大规模预训练语言模型进行微调，以达到与非私有模型相近的性能。",
        "动机": "为了解决在隐私保护要求下，大规模语言模型微调过程中面临的效用、隐私和计算资源消耗之间的平衡问题。",
        "方法": "提出一个元框架，采用高度参数高效的微调方法，实现差分隐私下的模型微调，优化隐私与效用的权衡。",
        "关键词": [
            "差分隐私",
            "语言模型微调",
            "参数高效",
            "隐私保护",
            "NLP任务"
        ],
        "涉及的技术概念": {
            "差分隐私": "在模型训练过程中引入噪声，确保模型输出不会泄露个体数据信息，保护用户隐私。",
            "参数高效微调": "通过仅更新模型的一小部分参数来适应新任务，减少计算和内存消耗，同时保持模型性能。",
            "隐私预算": "量化隐私保护的强度，ε值越小表示隐私保护越强，但可能影响模型效用。"
        },
        "success": true
    },
    {
        "order": 229,
        "title": "Differentially Private Fractional Frequency Moments Estimation with Polylogarithmic Space",
        "html": "https://iclr.cc//virtual/2022/poster/6971",
        "abstract": "We prove that $\\mathbb{F}_p$ sketch, a well-celebrated streaming algorithm for frequency moments estimation, is differentially private as is when $p\\in(0, 1]$. $\\mathbb{F}_p$ sketch uses only polylogarithmic space, exponentially better than existing DP baselines and only worse than the optimal non-private baseline by a logarithmic factor. The evaluation shows that $\\mathbb{F}_p$ sketch can achieve reasonable accuracy with strong privacy guarantees. The code for evaluation is included in the supplementary material.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "具有Polylogarithmic空间复杂度的差分隐私分数频率矩估计",
        "摘要翻译": "我们证明了著名的频率矩估计算法$\\mathbb{F}_p$ sketch在$p\\in(0, 1]$时具有差分隐私性。$\\mathbb{F}_p$ sketch仅使用polylogarithmic空间，比现有的差分隐私基线算法在空间复杂度上呈指数级提升，仅比最优的非隐私基线算法差一个对数因子。评估结果表明，$\\mathbb{F}_p$ sketch可以在保证强隐私性的前提下实现合理的准确性。评估代码包含在补充材料中。",
        "领域": "隐私保护机器学习, 流数据分析, 频率估计",
        "问题": "在保证差分隐私的前提下，如何高效地进行分数频率矩估计，降低空间复杂度。",
        "动机": "现有的差分隐私频率矩估计算法空间复杂度高，而直接使用非隐私算法会泄露敏感信息。因此，需要开发一种在保证隐私性的同时，空间复杂度低的频率矩估计算法。",
        "方法": "证明了现有的频率矩估计算法$\\mathbb{F}_p$ sketch在特定条件下具有差分隐私性。并实验验证了该方法在保证强隐私性的前提下，能够达到合理的准确性。",
        "关键词": [
            "差分隐私",
            "频率矩估计",
            "流算法",
            "隐私保护",
            "Polylogarithmic空间"
        ],
        "涉及的技术概念": {
            "差分隐私": "一种保护数据集中个体隐私的技术，通过在算法中引入随机性，使得攻击者难以推断出个体的信息。",
            "频率矩估计": "估计数据集中不同元素出现频率的矩，是数据分析和挖掘中的重要任务。"
        }
    },
    {
        "order": 230,
        "title": "DiffSkill: Skill Abstraction from Differentiable Physics for Deformable Object Manipulations with Tools",
        "html": "https://iclr.cc//virtual/2022/poster/6554",
        "abstract": "We consider the problem of sequential robotic manipulation of deformable objects using tools.Previous works have shown that differentiable physics simulators provide gradients to the environment state and help trajectory optimization to converge orders of magnitude faster than model-free reinforcement learning algorithms for deformable object manipulation. However, such gradient-based trajectory optimization typically requires access to the full simulator states and can only solve short-horizon, single-skill tasks due to local optima. In this work, we propose a novel framework, named DiffSkill, that uses a differentiable physics simulator for skill abstraction to solve long-horizon deformable object manipulation tasks from sensory observations. In particular, we first obtain short-horizon skills using individual tools from a gradient-based optimizer, using the full state information in a differentiable simulator; we then learn a neural skill abstractor from the demonstration trajectories which takes RGBD images as input. Finally, we plan over the skills by finding the intermediate goals and then solve long-horizon tasks. We show the advantages of our method in a new set of sequential deformable object manipulation tasks compared to previous reinforcement learning algorithms and compared to the trajectory optimizer. ",
        "conference": "ICLR",
        "中文标题": "DiffSkill：从可微分物理中抽象技能以使用工具进行可变形物体操作",
        "摘要翻译": "我们考虑使用工具对可变形物体进行顺序机器人操作的问题。先前的工作表明，可微分物理模拟器为环境状态提供了梯度，并帮助轨迹优化比无模型强化学习算法在可变形物体操作上收敛速度快几个数量级。然而，这种基于梯度的轨迹优化通常需要访问完整的模拟器状态，并且由于局部最优，只能解决短视界、单一技能的任务。在这项工作中，我们提出了一个名为DiffSkill的新框架，该框架使用可微分物理模拟器进行技能抽象，以从感官观察中解决长视界的可变形物体操作任务。具体来说，我们首先使用梯度优化器从可微分模拟器中获取完整状态信息，使用单个工具获得短视界技能；然后，我们从演示轨迹中学习一个神经技能抽象器，该抽象器以RGBD图像作为输入。最后，我们通过找到中间目标来规划技能，然后解决长视界任务。我们在一系列新的顺序可变形物体操作任务中展示了我们的方法相比于先前强化学习算法和轨迹优化器的优势。",
        "领域": "机器人操作、可微分物理模拟、强化学习",
        "问题": "解决长视界、多技能的可变形物体顺序操作任务",
        "动机": "克服基于梯度的轨迹优化在长视界任务中的局限性，提高操作效率和灵活性",
        "方法": "结合可微分物理模拟器和神经技能抽象器，通过技能规划和中间目标设定解决长视界任务",
        "关键词": [
            "可微分物理模拟",
            "技能抽象",
            "长视界操作",
            "机器人操作",
            "强化学习"
        ],
        "涉及的技术概念": {
            "可微分物理模拟器": "用于提供环境状态的梯度，加速轨迹优化的收敛",
            "神经技能抽象器": "从演示轨迹中学习，将RGBD图像作为输入，抽象出操作技能",
            "轨迹优化": "用于在短视界任务中快速找到有效的操作策略"
        },
        "success": true
    },
    {
        "order": 231,
        "title": "Diffusion-Based Voice Conversion with Fast Maximum Likelihood Sampling Scheme",
        "html": "https://iclr.cc//virtual/2022/poster/6240",
        "abstract": "Voice conversion is a common speech synthesis task which can be solved in different ways depending on a particular real-world scenario. The most challenging one often referred to as one-shot many-to-many voice conversion consists in copying target voice from only one reference utterance in the most general case when both source and target speakers do not belong to the training dataset. We present a scalable high-quality solution based on diffusion probabilistic modeling and demonstrate its superior quality compared to state-of-the-art one-shot voice conversion approaches. Moreover, focusing on real-time applications, we investigate general principles which can make diffusion models faster while keeping synthesis quality at a high level. As a result, we develop a novel Stochastic Differential Equations solver suitable for various diffusion model types and generative tasks as shown through empirical studies and justify it by theoretical analysis.",
        "conference": "ICLR",
        "中文标题": "基于扩散模型的语音转换与快速最大似然采样方案",
        "摘要翻译": "语音转换是一种常见的语音合成任务，可以根据特定的现实场景以不同的方式解决。最具挑战性的任务通常被称为一次性多对多语音转换，其核心在于在最一般的情况下，即当源说话者和目标说话者都不属于训练数据集时，仅从一个参考话语中复制目标声音。我们提出了一种基于扩散概率建模的可扩展高质量解决方案，并展示了其与最先进的一次性语音转换方法相比的卓越质量。此外，针对实时应用，我们研究了可以使扩散模型更快同时保持合成质量在高水平的通用原则。因此，我们开发了一种适用于各种扩散模型类型和生成任务的新型随机微分方程求解器，并通过实证研究和理论分析证明了其有效性。",
        "领域": "语音合成",
        "问题": "解决一次性多对多语音转换中的挑战，即在源和目标说话者均未出现在训练数据中的情况下，仅凭一个参考话语实现高质量的语音转换。",
        "动机": "探索并实现一种在保持高质量语音合成的同时，提高扩散模型处理速度的方法，以满足实时应用的需求。",
        "方法": "采用基于扩散概率建模的方法，开发了一种新型的随机微分方程求解器，适用于多种扩散模型和生成任务，通过实证和理论分析验证其有效性。",
        "关键词": [
            "语音转换",
            "扩散模型",
            "随机微分方程",
            "实时应用",
            "最大似然采样"
        ],
        "涉及的技术概念": {
            "扩散概率建模": "用于构建高质量的语音转换模型，通过模拟数据从噪声到清晰语音的扩散过程。",
            "随机微分方程求解器": "开发的新型求解器旨在加速扩散模型的推理过程，同时保持合成语音的高质量。",
            "最大似然采样": "一种采样策略，用于在扩散模型中高效地生成语音样本，优化模型的生成效率和质量。"
        },
        "success": true
    },
    {
        "order": 232,
        "title": "Direct then Diffuse: Incremental Unsupervised Skill Discovery for State Covering and Goal Reaching",
        "html": "https://iclr.cc//virtual/2022/poster/6977",
        "abstract": "Learning meaningful behaviors in the absence of reward is a difficult problem in reinforcement learning. A desirable and challenging unsupervised objective is to learn a set of diverse skills that provide a thorough coverage of the state space while being directed, i.e., reliably reaching distinct regions of the environment. In this paper, we build on the mutual information framework for skill discovery and introduce UPSIDE, which addresses the coverage-directedness trade-off in the following ways: 1) We design policies with a decoupled structure of a directed skill, trained to reach a specific region, followed by a diffusing part that induces a local coverage. 2) We optimize policies by  maximizing their number under the constraint that each of them reaches distinct regions of the environment (i.e., they are sufficiently discriminable) and prove that this serves as a lower bound to the original mutual information objective. 3) Finally, we compose the learned directed skills into a growing tree that adaptively covers the environment. We illustrate in several navigation and control environments how the skills learned by UPSIDE solve sparse-reward downstream tasks better than existing baselines.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "先定向后扩散：用于状态覆盖和目标达成的增量无监督技能发现",
        "摘要翻译": "在没有奖励的情况下学习有意义的行为是强化学习中的一个难题。一个理想且具有挑战性的无监督目标是学习一组多样化的技能，这些技能能够全面覆盖状态空间，同时具有定向性，即能够可靠地到达环境的不同区域。在本文中，我们基于技能发现的互信息框架，引入了UPSIDE，它通过以下方式解决了覆盖与定向性之间的权衡问题：1）我们设计了具有解耦结构的策略，包括一个定向技能，训练用于到达特定区域，随后是一个扩散部分，诱导局部覆盖。2）我们通过最大化策略数量来优化策略，约束条件是每个策略都能到达环境的不同区域（即它们足够可区分），并证明这可以作为原始互信息目标的下界。3）最后，我们将学习到的定向技能组合成一个不断增长的树，自适应地覆盖环境。我们在几个导航和控制环境中展示了UPSIDE学习的技能如何比现有基线更好地解决稀疏奖励的下游任务。",
        "领域": "强化学习, 无监督学习, 技能发现",
        "问题": "在无奖励环境下学习多样化且能全面覆盖状态空间并具有定向性的技能",
        "动机": "解决强化学习在无监督条件下学习有意义行为的难题，特别是如何平衡技能的覆盖范围和定向性",
        "方法": "设计解耦结构的策略，优化策略数量以覆盖不同环境区域，并将技能组合成自适应覆盖的树结构",
        "关键词": [
            "无监督学习",
            "技能发现",
            "强化学习",
            "状态覆盖",
            "目标达成"
        ],
        "涉及的技术概念": {
            "互信息框架": "用于技能发现的框架，通过最大化策略间的互信息来促进多样化技能的学习",
            "解耦结构策略": "策略由定向技能和扩散部分组成，前者负责到达特定区域，后者负责局部覆盖",
            "自适应覆盖树": "将学习到的定向技能组合成树结构，以实现对环境的高效和自适应覆盖"
        }
    },
    {
        "order": 233,
        "title": "DISCOVERING AND EXPLAINING THE REPRESENTATION BOTTLENECK OF DNNS",
        "html": "https://iclr.cc//virtual/2022/poster/6622",
        "abstract": "This paper explores the bottleneck of feature representations of deep neural networks (DNNs), from the perspective of the complexity of interactions between input variables encoded in DNNs. To this end, we focus on the multi-order interaction between input variables, where the order represents the complexity of interactions. We discover that a DNN is more likely to encode both too simple and too complex interactions, but usually fails to learn interactions of intermediate complexity. Such a phenomenon is widely shared by different DNNs for different tasks. This phenomenon indicates a cognition gap between DNNs and humans, and we call it a representation bottleneck. We theoretically prove the underlying reason for the representation bottleneck. Furthermore, we propose losses to encourage/penalize the learning of interactions of specific complexities, and analyze the representation capacities of interactions of different complexities. The code is available at https://github.com/Nebularaid2000/bottleneck.",
        "conference": "ICLR",
        "中文标题": "发现并解释深度神经网络的表示瓶颈",
        "摘要翻译": "本文从深度神经网络（DNNs）编码输入变量间交互复杂度的角度，探讨了DNNs特征表示的瓶颈。为此，我们聚焦于输入变量间的多阶交互，其中阶数代表交互的复杂度。我们发现，DNN更倾向于编码过于简单和过于复杂的交互，但通常难以学习中等复杂度的交互。这种现象在不同任务的不同DNN中广泛存在，表明DNN与人类之间存在认知差距，我们称之为表示瓶颈。我们从理论上证明了表示瓶颈的潜在原因。此外，我们提出了损失函数来鼓励/惩罚特定复杂度交互的学习，并分析了不同复杂度交互的表示能力。代码可在https://github.com/Nebularaid2000/bottleneck获取。",
        "领域": "深度学习理论、神经网络优化、特征表示学习",
        "问题": "深度神经网络在特征表示上存在瓶颈，难以学习中等复杂度的输入变量交互。",
        "动机": "揭示DNNs与人类在认知上的差距，即DNNs倾向于学习过于简单或复杂的交互，而忽略中等复杂度交互，从而理解并解决这一表示瓶颈。",
        "方法": "通过分析输入变量间的多阶交互复杂度，理论证明表示瓶颈的存在，并提出特定损失函数来调整交互学习。",
        "关键词": [
            "表示瓶颈",
            "多阶交互",
            "深度学习理论",
            "神经网络优化",
            "特征表示"
        ],
        "涉及的技术概念": {
            "多阶交互": "描述输入变量间交互的复杂度，阶数越高代表交互越复杂。",
            "表示瓶颈": "指DNNs在学习输入变量交互时，倾向于忽略中等复杂度交互的现象。",
            "损失函数": "用于调整DNNs学习特定复杂度交互的策略，通过鼓励或惩罚不同复杂度的交互来优化模型。"
        },
        "success": true
    },
    {
        "order": 234,
        "title": "Discovering Invariant Rationales for Graph Neural Networks",
        "html": "https://iclr.cc//virtual/2022/poster/6555",
        "abstract": "Intrinsic interpretability of graph neural networks (GNNs) is to find a small subset of the input graph's features --- rationale --- which guides the model prediction. Unfortunately, the leading rationalization models often rely on data biases, especially shortcut features, to compose rationales and make predictions without probing the critical and causal patterns. Moreover, such data biases easily change outside the training distribution. As a result, these models suffer from a huge drop in interpretability and predictive performance on out-of-distribution data. In this work, we propose a new strategy of discovering invariant rationale (DIR) to construct intrinsically interpretable GNNs. It conducts interventions on the training distribution to create multiple interventional distributions. Then it approaches the causal rationales that are invariant across different distributions while filtering out the spurious patterns that are unstable. Experiments on both synthetic and real-world datasets validate the superiority of our DIR in terms of interpretability and generalization ability on graph classification over the leading baselines. Code and datasets are available at https://github.com/Wuyxin/DIR-GNN.",
        "conference": "ICLR",
        "中文标题": "发现图神经网络的不变理性",
        "摘要翻译": "图神经网络（GNNs）的内在可解释性在于找到输入图特征的一个小子集——理性——它指导模型的预测。不幸的是，领先的理性化模型往往依赖于数据偏差，特别是捷径特征，来组成理性并做出预测，而没有探究关键和因果模式。此外，这种数据偏差在训练分布之外很容易改变。因此，这些模型在分布外数据上的可解释性和预测性能大幅下降。在这项工作中，我们提出了一种发现不变理性（DIR）的新策略，以构建内在可解释的GNNs。它对训练分布进行干预，以创建多个干预分布。然后，它接近在不同分布间不变的那些因果理性，同时过滤掉不稳定的虚假模式。在合成和真实世界数据集上的实验验证了我们的DIR在图分类的可解释性和泛化能力方面优于领先的基线。代码和数据集可在https://github.com/Wuyxin/DIR-GNN获取。",
        "领域": "图神经网络、可解释人工智能、图分类",
        "问题": "解决图神经网络在分布外数据上可解释性和预测性能下降的问题",
        "动机": "提高图神经网络的内在可解释性，使其能够识别并依赖于关键的因果模式，而非数据偏差",
        "方法": "提出发现不变理性（DIR）策略，通过干预训练分布创建多个干预分布，筛选出跨分布不变的因果理性",
        "关键词": [
            "图神经网络",
            "可解释性",
            "不变理性",
            "因果模式",
            "图分类"
        ],
        "涉及的技术概念": {
            "不变理性（DIR）": "一种新策略，用于构建内在可解释的GNNs，通过干预训练分布来发现跨分布不变的因果理性",
            "数据偏差": "模型在训练过程中可能依赖的非因果特征，导致在分布外数据上性能下降",
            "干预分布": "通过对训练分布进行干预创建的多个分布，用于筛选出不变的因果理性"
        },
        "success": true
    },
    {
        "order": 235,
        "title": "Discovering Latent Concepts Learned in BERT",
        "html": "https://iclr.cc//virtual/2022/poster/6838",
        "abstract": "A large number of studies that analyze deep neural network models and their ability to encode various linguistic and non-linguistic concepts provide an interpretation of the inner mechanics of these models. The scope of the analyses is limited to pre-defined concepts that reinforce the traditional linguistic knowledge and do not reflect on how novel concepts are learned by the model. We address this limitation by discovering and analyzing latent concepts learned in neural network models in an unsupervised fashion and provide interpretations from the model's perspective. In this work, we study: i) what latent concepts exist in the pre-trained BERT model, ii) how the discovered latent concepts align or diverge from classical linguistic hierarchy and iii) how the latent concepts evolve across layers. Our findings show: i) a model learns novel concepts (e.g. animal categories and demographic groups), which do not strictly adhere to any pre-defined categorization (e.g. POS, semantic tags), ii) several latent concepts are based on multiple properties which may include semantics, syntax, and  morphology, iii) the lower layers in the model dominate in learning shallow lexical concepts while the higher layers learn semantic relations and iv) the discovered  latent concepts highlight potential biases learned in the model. We also release a novel BERT ConceptNet dataset consisting of 174 concept labels and 1M annotated instances.",
        "conference": "ICLR",
        "中文标题": "发现BERT中学习的潜在概念",
        "摘要翻译": "大量研究分析了深度神经网络模型及其编码各种语言和非语言概念的能力，为这些模型的内部机制提供了解释。这些分析的范围仅限于预定义的概念，这些概念强化了传统的语言知识，并未反映模型如何学习新概念。我们通过以无监督的方式发现和分析神经网络模型中学习的潜在概念，并从模型的角度提供解释，来解决这一限制。在这项工作中，我们研究了：i)预训练的BERT模型中存在哪些潜在概念，ii)发现的潜在概念如何与经典语言层次结构对齐或分歧，以及iii)潜在概念如何跨层演变。我们的发现表明：i)模型学习了新概念（例如动物类别和人口统计群体），这些概念并不严格遵循任何预定义的分类（例如词性、语义标签），ii)几个潜在概念基于多种属性，可能包括语义、句法和形态，iii)模型的较低层在学习浅层词汇概念方面占主导地位，而较高层学习语义关系，以及iv)发现的潜在概念突出了模型中学习的潜在偏见。我们还发布了一个新颖的BERT ConceptNet数据集，包含174个概念标签和100万个注释实例。",
        "领域": "自然语言处理与视觉结合",
        "问题": "分析深度神经网络模型如何学习新概念，以及这些概念如何与传统的语言知识对齐或分歧。",
        "动机": "解决现有研究局限于预定义概念，未能反映模型如何学习新概念的问题。",
        "方法": "以无监督的方式发现和分析神经网络模型中学习的潜在概念，并从模型的角度提供解释。",
        "关键词": [
            "潜在概念",
            "BERT模型",
            "无监督学习"
        ],
        "涉及的技术概念": {
            "潜在概念": "模型在学习过程中自动发现的新概念，不依赖于预定义的分类。",
            "无监督学习": "用于发现和分析模型中学习的潜在概念，无需预先标记的数据。",
            "BERT模型": "预训练的深度神经网络模型，用于研究潜在概念的学习和演变。"
        },
        "success": true
    },
    {
        "order": 236,
        "title": "Discovering Nonlinear PDEs from Scarce Data with Physics-encoded Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6855",
        "abstract": "There have been growing interests in leveraging experimental measurements to discover the underlying partial differential equations (PDEs) that govern complex physical phenomena. Although past research attempts have achieved great success in data-driven PDE discovery, the robustness of the existing methods cannot be guaranteed when dealing with low-quality measurement data. To overcome this challenge, we propose a novel physics-encoded discrete learning framework for discovering spatiotemporal PDEs from scarce and noisy data. The general idea is to (1) firstly introduce a novel deep convolutional-recurrent networks, which can encode prior physics knowledge (e.g., known terms, assumed PDE structure, initial/boundary conditions, etc.) while remaining flexible on representation capability, to accurately reconstruct high-fidelity data, and (2) then perform sparse regression with the reconstructed data to identify the analytical form of the governing PDEs. We validate our proposed framework on three high-dimensional PDE systems. The effectiveness and superiority of the proposed method over baselines are demonstrated.",
        "conference": "ICLR",
        "中文标题": "通过物理编码学习从稀缺数据中发现非线性偏微分方程",
        "摘要翻译": "近年来，利用实验测量数据来发现控制复杂物理现象的潜在偏微分方程（PDEs）的兴趣日益增长。尽管过去的研究尝试在数据驱动的PDE发现方面取得了巨大成功，但在处理低质量测量数据时，现有方法的鲁棒性无法得到保证。为了克服这一挑战，我们提出了一种新颖的物理编码离散学习框架，用于从稀缺和噪声数据中发现时空PDEs。总体思路是：（1）首先引入一种新颖的深度卷积-循环网络，该网络可以编码先前的物理知识（例如，已知项、假设的PDE结构、初始/边界条件等），同时在表示能力上保持灵活性，以准确重建高保真数据；（2）然后利用重建的数据进行稀疏回归，以识别控制PDEs的解析形式。我们在三个高维PDE系统上验证了我们提出的框架。证明了所提出方法相对于基线方法的有效性和优越性。",
        "领域": "偏微分方程发现、深度学习与物理结合、时空数据分析",
        "问题": "如何在稀缺和噪声数据条件下，鲁棒地发现控制复杂物理现象的非线性偏微分方程。",
        "动机": "现有方法在处理低质量测量数据时鲁棒性不足，需要一种能够从稀缺和噪声数据中发现PDEs的新方法。",
        "方法": "提出一种物理编码的离散学习框架，结合深度卷积-循环网络和稀疏回归技术，从稀缺和噪声数据中发现PDEs。",
        "关键词": [
            "物理编码学习",
            "偏微分方程发现",
            "深度学习",
            "稀疏回归",
            "时空数据分析"
        ],
        "涉及的技术概念": {
            "深度卷积-循环网络": "用于编码先前的物理知识并准确重建高保真数据的网络结构。",
            "稀疏回归": "用于从重建的数据中识别控制PDEs的解析形式的技术。",
            "物理编码学习": "一种结合物理知识和深度学习的方法，用于提高从稀缺和噪声数据中发现PDEs的鲁棒性。"
        },
        "success": true
    },
    {
        "order": 237,
        "title": "Discrepancy-Based Active Learning for Domain Adaptation",
        "html": "https://iclr.cc//virtual/2022/poster/6378",
        "abstract": "The goal of the paper is to design active learning strategies which lead to domain adaptation under an assumption of Lipschitz functions. Building on previous work by Mansour et al. (2009) we adapt the concept of discrepancy distance between source and target distributions to restrict the maximization over the hypothesis class to a localized class of functions which are performing accurate labeling on the source domain. We derive generalization error bounds for such active learning strategies in terms of Rademacher average and localized discrepancy for general loss functions which satisfy a regularity condition. A practical K-medoids algorithm that can address the case of large data set is inferred from the theoretical bounds. Our numerical experiments show that the proposed algorithm is competitive against other state-of-the-art active learning techniques in the context of domain adaptation, in particular on large data sets of around one hundred thousand images.",
        "conference": "ICLR",
        "中文标题": "基于差异的领域自适应主动学习",
        "摘要翻译": "本文的目标是设计一种主动学习策略，该策略在Lipschitz函数的假设下实现领域自适应。基于Mansour等人（2009年）的先前工作，我们调整了源分布和目标分布之间差异距离的概念，以将假设类的最大化限制于在源域上执行准确标记的局部函数类。我们针对满足正则条件的一般损失函数，以Rademacher平均和局部差异为术语，推导了此类主动学习策略的泛化误差界限。从理论界限中推断出一种实用的K-medoids算法，该算法可以处理大数据集的情况。我们的数值实验表明，在领域自适应的背景下，特别是在大约十万张图像的大数据集上，所提出的算法与其他最先进的主动学习技术相比具有竞争力。",
        "领域": "领域自适应、主动学习、图像分类",
        "问题": "设计在Lipschitz函数假设下实现领域自适应的主动学习策略",
        "动机": "为了在源域和目标域之间实现有效的知识迁移，特别是在大数据集上，需要开发更高效的主动学习策略。",
        "方法": "通过调整源和目标分布之间的差异距离概念，限制假设类的最大化到局部函数类，并推导泛化误差界限，提出一种K-medoids算法处理大数据集。",
        "关键词": [
            "领域自适应",
            "主动学习",
            "K-medoids算法",
            "Lipschitz函数",
            "Rademacher平均"
        ],
        "涉及的技术概念": {
            "差异距离": "用于衡量源分布和目标分布之间的差异，限制假设类的最大化到局部函数类。",
            "Rademacher平均": "用于推导主动学习策略的泛化误差界限，评估学习算法的复杂性。",
            "K-medoids算法": "一种实用的聚类算法，用于处理大数据集，实现领域自适应。"
        },
        "success": true
    },
    {
        "order": 238,
        "title": "Discrete Representations Strengthen Vision Transformer Robustness",
        "html": "https://iclr.cc//virtual/2022/poster/6647",
        "abstract": "Vision Transformer (ViT) is emerging as the state-of-the-art architecture for image recognition. While recent studies suggest that ViTs are more robust than their convolutional counterparts, our experiments find that ViTs are overly reliant on local features (\\eg, nuisances and texture) and fail to make adequate use of global context (\\eg, shape and structure). As a result, ViTs fail to generalize to out-of-distribution, real-world data. To address this deficiency, we present a simple and effective architecture modification to ViT's input layer by adding discrete tokens produced by a vector-quantized encoder. Different from the standard continuous pixel tokens, discrete tokens are invariant under small perturbations and contain less information individually, which promote ViTs to learn global information that is invariant. Experimental results demonstrate that adding discrete representation on four architecture variants strengthens ViT robustness by up to 12\\% across seven ImageNet robustness benchmarks while maintaining the performance on ImageNet.",
        "conference": "ICLR",
        "中文标题": "离散表示增强视觉Transformer的鲁棒性",
        "摘要翻译": "视觉Transformer（ViT）正逐渐成为图像识别领域的最先进架构。尽管最近的研究表明ViT比其卷积对应物更具鲁棒性，但我们的实验发现ViT过度依赖局部特征（例如，干扰和纹理），未能充分利用全局上下文（例如，形状和结构）。因此，ViT无法泛化到分布外的真实世界数据。为了解决这一不足，我们提出了一种简单有效的架构修改，通过添加由向量量化编码器产生的离散标记来改进ViT的输入层。与标准的连续像素标记不同，离散标记在小扰动下保持不变，并且单独包含的信息较少，这促使ViT学习不变的全局信息。实验结果表明，在四种架构变体上添加离散表示，在七个ImageNet鲁棒性基准测试中，ViT的鲁棒性提高了高达12%，同时在ImageNet上保持了性能。",
        "领域": "图像识别、深度学习模型鲁棒性、视觉Transformer",
        "问题": "视觉Transformer（ViT）在图像识别中过度依赖局部特征，未能充分利用全局上下文，导致在分布外的真实世界数据上泛化能力不足。",
        "动机": "提升ViT模型在真实世界数据上的泛化能力和鲁棒性，使其不仅依赖于局部特征，还能有效利用全局上下文信息。",
        "方法": "通过在ViT的输入层添加由向量量化编码器产生的离散标记，促使模型学习不变的全局信息，从而提高模型的鲁棒性。",
        "关键词": [
            "视觉Transformer",
            "离散表示",
            "模型鲁棒性",
            "向量量化编码器",
            "全局上下文"
        ],
        "涉及的技术概念": {
            "视觉Transformer（ViT）": "一种基于自注意力机制的图像识别架构，本文的研究对象。",
            "离散表示": "由向量量化编码器产生的标记，用于增强ViT模型的鲁棒性，促使模型学习全局信息。",
            "向量量化编码器": "用于生成离散标记的技术，通过量化连续输入到离散空间，减少信息量并提高模型对扰动的鲁棒性。"
        },
        "success": true
    },
    {
        "order": 239,
        "title": "Discriminative Similarity for Data Clustering",
        "html": "https://iclr.cc//virtual/2022/poster/6248",
        "abstract": "Similarity-based clustering methods separate data into clusters according to the pairwise similarity between the data, and the pairwise similarity is crucial for their performance. In this paper, we propose {\\em Clustering by  Discriminative Similarity (CDS)}, a novel method which learns discriminative similarity for data clustering. CDS learns an unsupervised similarity-based classifier from each data partition, and searches for the optimal partition of the data by minimizing the generalization error of the learnt classifiers associated with the data partitions. By generalization analysis via Rademacher complexity, the generalization error bound for the unsupervised similarity-based classifier is expressed as the sum of discriminative similarity between the data from different classes. It is proved that the derived discriminative similarity can also be induced by the integrated squared error bound for kernel density classification. In order to evaluate the performance of the proposed discriminative similarity, we propose a new clustering method using a kernel as the similarity function, CDS via unsupervised kernel classification (CDSK), with its effectiveness demonstrated by experimental results.",
        "conference": "ICLR",
        "中文标题": "判别性相似度用于数据聚类",
        "摘要翻译": "基于相似度的聚类方法根据数据间的成对相似度将数据分离到不同的簇中，而成对相似度对这些方法的性能至关重要。本文提出了一种新颖的方法——通过判别性相似度进行聚类（CDS），该方法学习用于数据聚类的判别性相似度。CDS从每个数据分区中学习一个无监督的基于相似度的分类器，并通过最小化与数据分区相关联的学习分类器的泛化误差来搜索数据的最优分区。通过Rademacher复杂度的泛化分析，无监督基于相似度的分类器的泛化误差界限被表达为来自不同类别的数据之间的判别性相似度之和。证明了所得到的判别性相似度也可以通过核密度分类的积分平方误差界限诱导出来。为了评估所提出的判别性相似度的性能，我们提出了一种新的聚类方法，使用核作为相似度函数，即通过无监督核分类的CDS（CDSK），其实验结果证明了其有效性。",
        "领域": "数据聚类",
        "问题": "如何提高基于相似度的聚类方法的性能",
        "动机": "研究动机是开发一种能够学习判别性相似度的方法，以提高数据聚类的准确性和效率。",
        "方法": "提出了一种名为CDS的新方法，该方法通过学习无监督的基于相似度的分类器，并最小化这些分类器的泛化误差来优化数据分区。",
        "关键词": [
            "判别性相似度",
            "数据聚类",
            "无监督学习",
            "核方法",
            "泛化误差"
        ],
        "涉及的技术概念": {
            "判别性相似度": "用于区分不同类别数据之间的相似度，是提高聚类性能的关键。",
            "Rademacher复杂度": "用于分析无监督学习分类器的泛化误差，帮助理解模型的泛化能力。",
            "核密度分类": "一种利用核方法进行密度估计和分类的技术，本文中用于诱导判别性相似度。"
        },
        "success": true
    },
    {
        "order": 240,
        "title": "Disentanglement Analysis with Partial Information Decomposition",
        "html": "https://iclr.cc//virtual/2022/poster/6465",
        "abstract": "We propose a framework to analyze how multivariate representations disentangle ground-truth generative factors. A quantitative analysis of disentanglement has been based on metrics designed to compare how one variable explains each generative factor. Current metrics, however, may fail to detect entanglement that involves more than two variables, e.g., representations that duplicate and rotate generative factors in high dimensional spaces. In this work, we establish a framework to analyze information sharing in a multivariate representation with Partial Information Decomposition and propose a new disentanglement metric. This framework enables us to understand disentanglement in terms of uniqueness, redundancy, and synergy. We develop an experimental protocol to assess how increasingly entangled representations are evaluated with each metric and confirm that the proposed metric correctly responds to entanglement. Through experiments on variational autoencoders, we find that models with similar disentanglement scores have a variety of characteristics in entanglement, for each of which a distinct strategy may be required to obtain a disentangled representation.",
        "conference": "ICLR",
        "中文标题": "基于部分信息分解的解缠分析",
        "摘要翻译": "我们提出了一个框架，用于分析多元表示如何解缠真实生成因素。解缠的定量分析基于设计用于比较一个变量如何解释每个生成因素的度量标准。然而，当前的度量标准可能无法检测到涉及两个以上变量的纠缠，例如在高维空间中复制和旋转生成因素的表示。在这项工作中，我们建立了一个框架，通过部分信息分解来分析多元表示中的信息共享，并提出了一种新的解缠度量标准。这一框架使我们能够从独特性、冗余性和协同性的角度理解解缠。我们开发了一个实验协议，以评估每种度量标准如何评估日益纠缠的表示，并确认所提出的度量标准能够正确响应纠缠。通过对变分自编码器的实验，我们发现具有相似解缠分数的模型在纠缠方面具有多种特性，每种特性可能需要不同的策略来获得解缠表示。",
        "领域": "表示学习、生成模型、信息论",
        "问题": "当前解缠度量标准无法有效检测涉及多个变量的复杂纠缠模式",
        "动机": "为了更全面地理解和量化多元表示中的信息共享和解缠状态",
        "方法": "提出基于部分信息分解的框架和新解缠度量标准，通过实验验证其有效性",
        "关键词": [
            "解缠分析",
            "部分信息分解",
            "变分自编码器",
            "信息共享",
            "生成模型"
        ],
        "涉及的技术概念": {
            "部分信息分解": "用于分析多元变量间信息共享的框架，将信息分解为独特性、冗余性和协同性",
            "解缠度量标准": "新提出的度量标准，能够检测复杂纠缠模式，优于现有方法",
            "变分自编码器": "实验中使用的生成模型，用于验证解缠度量标准的有效性"
        },
        "success": true
    },
    {
        "order": 241,
        "title": "DISSECT: Disentangled Simultaneous Explanations via Concept Traversals",
        "html": "https://iclr.cc//virtual/2022/poster/6367",
        "abstract": "Explaining deep learning model inferences is a promising venue for scientific understanding, improving safety, uncovering hidden biases, evaluating fairness, and beyond, as argued by many scholars. One of the principal benefits of counterfactual explanations is allowing users to explore 'what-if' scenarios through what does not and cannot exist in the data, a quality that many other forms of explanation such as heatmaps and influence functions are inherently incapable of doing. However, most previous work on generative explainability cannot disentangle important concepts effectively, produces unrealistic examples, or fails to retain relevant information. We propose a novel approach, DISSECT, that jointly trains a generator, a discriminator, and a concept disentangler to overcome such challenges using little supervision. DISSECT generates Concept Traversals (CTs), defined as a sequence of generated examples with increasing degrees of concepts that influence a classifier's decision. By training a generative model from a classifier's signal, DISSECT offers a way to discover a classifier's inherent 'notion' of distinct concepts automatically rather than rely on user-predefined concepts. We show that DISSECT produces CTs that (1) disentangle several concepts, (2) are influential to a classifier's decision and are coupled to its reasoning due to joint training (3), are realistic, (4) preserve relevant information, and (5) are stable across similar inputs. We validate DISSECT on several challenging synthetic and realistic datasets where previous methods fall short of satisfying desirable criteria for interpretability and show that it performs consistently well. Finally, we present experiments showing applications of DISSECT for detecting potential biases of a classifier and identifying spurious artifacts that impact predictions.",
        "conference": "ICLR",
        "中文标题": "解构：通过概念遍历实现解耦的同步解释",
        "摘要翻译": "解释深度学习模型的推断是促进科学理解、提升安全性、揭示隐藏偏见、评估公平性等多方面的有前景的途径，正如许多学者所论证的那样。反事实解释的一个主要好处是允许用户通过数据中不存在和不可能存在的情景探索'假设'场景，这是热图和影响函数等其他解释形式所固有的无法做到的品质。然而，大多数先前关于生成可解释性的工作无法有效解耦重要概念，产生不现实的例子，或未能保留相关信息。我们提出了一种新方法DISSECT，它联合训练一个生成器、一个鉴别器和一个概念解耦器，以克服这些挑战，使用少量监督。DISSECT生成概念遍历（CTs），定义为一系列生成的例子，其中包含影响分类器决策的概念的递增程度。通过从分类器的信号训练生成模型，DISSECT提供了一种自动发现分类器对不同概念的固有'概念'的方法，而不是依赖用户预定义的概念。我们展示了DISSECT产生的CTs（1）解耦了几个概念，（2）对分类器的决策有影响，并且由于联合训练而与其推理耦合，（3）是现实的，（4）保留了相关信息，以及（5）在类似输入中保持稳定。我们在几个具有挑战性的合成和现实数据集上验证了DISSECT，在这些数据集上先前的方法未能满足可解释性的理想标准，并表明它表现一致良好。最后，我们展示了DISSECT在检测分类器的潜在偏见和识别影响预测的虚假伪影方面的应用实验。",
        "领域": "深度学习可解释性、生成对抗网络、计算机视觉",
        "问题": "解决深度学习模型解释中概念解耦不足、生成例子不现实及信息保留不完整的问题",
        "动机": "通过提供一种能够自动发现分类器对不同概念的固有理解的方法，提升模型解释的质量和实用性",
        "方法": "联合训练生成器、鉴别器和概念解耦器，生成概念遍历（CTs）以影响分类器决策",
        "关键词": [
            "概念遍历",
            "解耦解释",
            "生成对抗网络",
            "模型可解释性",
            "反事实解释"
        ],
        "涉及的技术概念": {
            "概念遍历（CTs）": "一系列生成的例子，展示影响分类器决策的概念递增程度，用于解释模型决策",
            "生成对抗网络（GANs）": "用于生成现实例子，同时与分类器联合训练以提高解释的相关性和现实性",
            "概念解耦器": "用于分离和识别影响分类器决策的关键概念，提高解释的清晰度和有效性"
        },
        "success": true
    },
    {
        "order": 242,
        "title": "Distilling GANs with Style-Mixed Triplets for X2I Translation with Limited Data",
        "html": "https://iclr.cc//virtual/2022/poster/6708",
        "abstract": "Conditional image synthesis is an integral part of many X2I translation systems, including image-to-image, text-to-image and audio-to-image translation systems. Training these large systems generally requires huge amounts of training data. Therefore, we investigate knowledge distillation to transfer knowledge from a high-quality unconditioned generative model (e.g., StyleGAN) to a conditioned synthetic image generation modules in a variety of systems. To initialize the conditional and reference branch (from a unconditional GAN)  we exploit the style mixing characteristics of high-quality GANs to generate an infinite supply of style-mixed triplets to perform the knowledge distillation. Extensive experimental results in a number of image generation tasks (i.e., image-to-image, semantic segmentation-to-image, text-to-image and audio-to-image) demonstrate qualitatively and quantitatively that our method successfully transfers knowledge to the synthetic image generation modules, resulting in more realistic images than previous methods as confirmed by a significant drop in the FID. ",
        "conference": "ICLR",
        "中文标题": "利用风格混合三元组蒸馏GANs以实现有限数据下的X2I转换",
        "摘要翻译": "条件图像合成是许多X2I转换系统（包括图像到图像、文本到图像和音频到图像转换系统）的重要组成部分。训练这些大型系统通常需要大量的训练数据。因此，我们研究了知识蒸馏技术，以将知识从高质量的无条件生成模型（如StyleGAN）转移到各种系统中的条件合成图像生成模块。为了初始化条件分支和参考分支（来自无条件GAN），我们利用高质量GAN的风格混合特性生成无限供应的风格混合三元组来执行知识蒸馏。在多种图像生成任务（即图像到图像、语义分割到图像、文本到图像和音频到图像）中的大量实验结果定性和定量地表明，我们的方法成功地将知识转移到合成图像生成模块，产生比之前方法更真实的图像，这一点通过FID的显著下降得到了证实。",
        "领域": "图像生成、知识蒸馏、条件图像合成",
        "问题": "在有限数据条件下，如何有效地进行X2I（如文本到图像、音频到图像等）转换任务",
        "动机": "解决在训练数据有限的情况下，如何利用高质量的无条件生成模型（如StyleGAN）的知识，提升条件合成图像生成模块的性能，以生成更真实的图像",
        "方法": "利用高质量GAN的风格混合特性生成风格混合三元组，通过知识蒸馏技术将知识从无条件生成模型转移到条件合成图像生成模块",
        "关键词": [
            "知识蒸馏",
            "风格混合",
            "X2I转换",
            "条件图像合成",
            "StyleGAN"
        ],
        "涉及的技术概念": {
            "知识蒸馏": "一种技术，用于将大型模型（教师模型）的知识转移到小型模型（学生模型），以提升小型模型的性能",
            "风格混合": "利用生成对抗网络（GAN）的特性，混合不同风格的特征以生成多样化的图像",
            "FID": "Frechet Inception Distance，一种评估生成图像质量的指标，值越低表示生成的图像质量越高"
        },
        "success": true
    },
    {
        "order": 243,
        "title": "Distributionally Robust Fair Principal Components via Geodesic Descents",
        "html": "https://iclr.cc//virtual/2022/poster/6615",
        "abstract": "Principal component analysis is a simple yet useful dimensionality reduction technique in modern machine learning pipelines. In consequential domains such as college admission, healthcare and credit approval, it is imperative to take into account emerging criteria such as the fairness and the robustness of the learned projection. In this paper, we propose a distributionally robust optimization problem for principal component analysis which internalizes a fairness criterion in the objective function. The learned projection thus balances the trade-off between the total reconstruction error and the reconstruction error gap between subgroups, taken in the min-max sense over all distributions in a moment-based ambiguity set. The resulting optimization problem over the Stiefel manifold can be efficiently solved by a Riemannian subgradient descent algorithm with a sub-linear convergence rate. Our experimental results on real-world datasets show the merits of our proposed method over state-of-the-art baselines. ",
        "conference": "ICLR",
        "中文标题": "通过测地下降实现分布鲁棒公平主成分",
        "摘要翻译": "主成分分析是现代机器学习流程中一种简单而有用的降维技术。在大学录取、医疗保健和信贷审批等重要领域，必须考虑到学习投影的公平性和鲁棒性等新兴标准。在本文中，我们提出了一个主成分分析的分布鲁棒优化问题，该问题在目标函数中内化了公平性标准。因此，学习的投影在基于矩的模糊集中所有分布的最小-最大意义上，平衡了总重构误差与子组间重构误差差距之间的权衡。由此产生的Stiefel流形上的优化问题可以通过具有次线性收敛速率的黎曼次梯度下降算法有效解决。我们在真实世界数据集上的实验结果表明，我们提出的方法优于最先进的基线方法。",
        "领域": "机器学习公平性、降维技术、鲁棒优化",
        "问题": "如何在主成分分析中同时考虑公平性和鲁棒性",
        "动机": "解决在重要应用领域中主成分分析技术的公平性和鲁棒性问题",
        "方法": "提出一个分布鲁棒优化问题，内化公平性标准，并使用黎曼次梯度下降算法求解",
        "关键词": [
            "分布鲁棒优化",
            "公平性",
            "主成分分析",
            "黎曼优化",
            "降维"
        ],
        "涉及的技术概念": {
            "分布鲁棒优化": "用于在不确定性下优化性能，确保模型在各种分布下的鲁棒性",
            "公平性标准": "确保模型对不同子组的处理是公平的，减少偏差",
            "黎曼次梯度下降": "在Stiefel流形上优化问题的有效算法，保证次线性收敛速率"
        },
        "success": true
    },
    {
        "order": 244,
        "title": "Distributionally Robust Models with Parametric Likelihood Ratios",
        "html": "https://iclr.cc//virtual/2022/poster/6425",
        "abstract": "As machine learning models are deployed ever more broadly, it becomes increasingly important that they are not only able to perform well on their training distribution, but also yield accurate predictions when confronted with distribution shift. The Distributionally Robust Optimization (DRO) framework proposes to address this issue by training models to minimize their expected risk under a collection of distributions, to imitate test-time shifts. This is most commonly achieved by instance-level re-weighting of the training objective to emulate the likelihood ratio with possible test distributions, which allows for estimating their empirical risk via importance sampling (assuming that they are subpopulations of the training distribution). However, re-weighting schemes in the literature are usually limited due to the difficulty of keeping the optimization problem tractable and the complexity of enforcing normalization constraints. In this paper, we show that three simple ideas -- mini-batch level normalization, a KL penalty and simultaneous gradient updates -- allow us to train models with DRO using a broader class of parametric likelihood ratios. In a series of experiments on both image and text classification benchmarks, we find that models trained with the resulting parametric adversaries are consistently more robust to subpopulation shifts when compared to other DRO approaches, and that the method performs reliably well with little hyper-parameter tuning.",
        "conference": "ICLR",
        "中文标题": "具有参数化似然比的分布鲁棒模型",
        "摘要翻译": "随着机器学习模型被越来越广泛地部署，确保它们不仅能在训练分布上表现良好，而且能在面对分布变化时做出准确预测变得尤为重要。分布鲁棒优化（DRO）框架提出通过训练模型在一系列分布下最小化其预期风险来模拟测试时的变化，以此来解决这一问题。这通常通过实例级重新加权训练目标来实现，以模拟与可能的测试分布的似然比，从而允许通过重要性采样估计它们的经验风险（假设它们是训练分布的子群体）。然而，由于保持优化问题可处理的难度和强制执行归一化约束的复杂性，文献中的重新加权方案通常受到限制。在本文中，我们展示了三个简单的想法——小批量级归一化、KL惩罚和同步梯度更新——使我们能够使用更广泛的参数化似然比类别来训练DRO模型。在一系列关于图像和文本分类基准的实验中，我们发现，与其他DRO方法相比，使用由此产生的参数化对手训练的模型对子群体变化始终表现出更强的鲁棒性，并且该方法在几乎没有超参数调整的情况下表现可靠。",
        "领域": "机器学习鲁棒性、分布鲁棒优化、深度学习",
        "问题": "如何在面对分布变化时保持机器学习模型的准确预测能力",
        "动机": "提高机器学习模型在分布变化下的鲁棒性和泛化能力",
        "方法": "采用小批量级归一化、KL惩罚和同步梯度更新来训练具有更广泛参数化似然比的DRO模型",
        "关键词": [
            "分布鲁棒优化",
            "参数化似然比",
            "机器学习鲁棒性",
            "子群体变化",
            "重要性采样"
        ],
        "涉及的技术概念": {
            "分布鲁棒优化（DRO）": "一种通过在一系列分布下最小化预期风险来模拟测试时变化的方法",
            "参数化似然比": "用于模拟与可能的测试分布的似然比，允许通过重要性采样估计经验风险",
            "KL惩罚": "用于在训练过程中施加归一化约束，保持优化问题的可处理性"
        },
        "success": true
    },
    {
        "order": 245,
        "title": "Distributional Reinforcement Learning with Monotonic Splines",
        "html": "https://iclr.cc//virtual/2022/poster/6650",
        "abstract": "Distributional Reinforcement Learning (RL) differs from traditional RL by estimating the distribution over returns to capture the intrinsic uncertainty of MDPs. One key challenge in distributional RL lies in how to parameterize the quantile function when minimizing the Wasserstein metric of temporal differences. Existing algorithms use step functions or piecewise linear functions. In this paper, we propose to learn smooth continuous quantile functions represented by monotonic rational-quadratic splines, which also naturally solve the quantile crossing problem. Experiments in stochastic environments show that a dense estimation for quantile functions enhances distributional RL in terms of faster empirical convergence and higher rewards in most cases.",
        "conference": "ICLR",
        "中文标题": "单调样条在分布强化学习中的应用",
        "摘要翻译": "分布强化学习（RL）与传统RL的不同之处在于，它通过估计回报的分布来捕捉MDPs的内在不确定性。分布强化学习中的一个关键挑战在于如何在最小化时间差异的Wasserstein度量时参数化分位数函数。现有算法使用阶跃函数或分段线性函数。在本文中，我们提出学习由单调有理二次样条表示的光滑连续分位数函数，这也自然地解决了分位数交叉问题。在随机环境中的实验表明，对分位数函数的密集估计在大多数情况下通过更快的经验收敛和更高的奖励增强了分布强化学习。",
        "领域": "强化学习、机器学习优化、概率建模",
        "问题": "如何在分布强化学习中有效地参数化分位数函数以最小化Wasserstein度量",
        "动机": "解决现有分布强化学习算法在参数化分位数函数时使用阶跃函数或分段线性函数所面临的限制，提高算法的性能和效率",
        "方法": "提出使用单调有理二次样条来学习光滑连续的分位数函数，以解决分位数交叉问题并提高分布强化学习的性能",
        "关键词": [
            "分布强化学习",
            "单调样条",
            "分位数函数",
            "Wasserstein度量",
            "概率建模"
        ],
        "涉及的技术概念": {
            "分布强化学习": "一种通过估计回报的分布来捕捉MDPs内在不确定性的强化学习方法",
            "单调有理二次样条": "用于表示光滑连续分位数函数的数学工具，解决了分位数交叉问题",
            "Wasserstein度量": "用于衡量两个概率分布之间差异的度量，本文中用于最小化时间差异"
        },
        "success": true
    },
    {
        "order": 246,
        "title": "Distribution Compression in Near-Linear Time",
        "html": "https://iclr.cc//virtual/2022/poster/7193",
        "abstract": "In distribution compression, one aims to accurately summarize a probability distribution $\\mathbb{P}$ using a small number of representative points. Near-optimal thinning procedures achieve this goal by sampling $n$ points from a Markov chain and identifying $\\sqrt{n}$ points with $\\widetilde{\\mathcal{O}}(1/\\sqrt{n})$ discrepancy to $\\mathbb{P}$. Unfortunately, these algorithms suffer from quadratic or super-quadratic runtime in the sample size $n$. To address this deficiency, we introduce Compress++, a simple meta-procedure for speeding up any thinning algorithm while suffering at most a factor of $4$ in error. When combined with the quadratic-time kernel halving and kernel thinning algorithms of Dwivedi and Mackey (2021), Compress++ delivers $\\sqrt{n}$ points with $\\mathcal{O}(\\sqrt{\\log n/n})$ integration error and better-than-Monte-Carlo maximum mean discrepancy in $\\mathcal{O}(n \\log^3 n)$ time and  $\\mathcal{O}( \\sqrt{n} \\log^2 n )$ space. Moreover, Compress++ enjoys the same near-linear runtime given any quadratic-time input and reduces the runtime of super-quadratic algorithms by a square-root factor. In our benchmarks with high-dimensional Monte Carlo samples and Markov chains targeting challenging differential equation posteriors, Compress++ matches or nearly matches the accuracy of its input algorithm in orders of magnitude less time.",
        "conference": "ICLR",
        "中文标题": "近线性时间内的分布压缩",
        "摘要翻译": "在分布压缩中，目标是使用少量代表性点准确总结概率分布ℙ。近最优细化程序通过从马尔可夫链中采样n个点并识别√n个与ℙ有O~(1/√n)差异的点来实现这一目标。不幸的是，这些算法在样本大小n上具有二次或超二次的运行时间。为了解决这一不足，我们引入了Compress++，这是一个简单的元过程，用于加速任何细化算法，同时最多只承受4倍的误差。当与Dwivedi和Mackey（2021）的二次时间核半化和核细化算法结合时，Compress++在O(n log³ n)时间和O(√n log² n)空间内提供√n个点，具有O(√log n/n)的积分误差和优于蒙特卡洛的最大均值差异。此外，Compress++在任何二次时间输入下都享有相同的近线性运行时间，并将超二次算法的运行时间减少平方根因子。在我们针对高维蒙特卡洛样本和针对挑战性微分方程后验的马尔可夫链的基准测试中，Compress++在数量级更少的时间内匹配或几乎匹配其输入算法的准确性。",
        "领域": "概率分布压缩, 马尔可夫链蒙特卡洛, 高维统计",
        "问题": "解决分布压缩算法在样本大小上的高时间复杂度问题",
        "动机": "提高分布压缩算法的效率，减少计算时间和空间需求",
        "方法": "引入Compress++元过程，结合核半化和核细化算法，优化运行时间和空间效率",
        "关键词": [
            "分布压缩",
            "近线性时间",
            "核半化",
            "核细化",
            "Compress++"
        ],
        "涉及的技术概念": {
            "近最优细化程序": "通过采样和识别代表性点来总结概率分布的技术",
            "核半化和核细化": "用于减少样本点数量同时保持分布特性的算法",
            "Compress++": "一种元过程，用于加速任何细化算法，同时控制误差增长"
        },
        "success": true
    },
    {
        "order": 247,
        "title": "Diurnal or Nocturnal? Federated Learning of Multi-branch Networks from Periodically Shifting Distributions",
        "html": "https://iclr.cc//virtual/2022/poster/6742",
        "abstract": "Federated learning has been deployed to train machine learning models from decentralized client data on mobile devices in practice. The clients available for training are observed to have periodically shifting distributions changing with the time of day, which can cause instability in training and degrade the model performance. In this paper, instead of modeling the distribution shift with a block-cyclic pattern as previous works, we model it with a mixture of distributions that gradually shifts between daytime and nighttime modes, and find this intuitive model to better match the observations in practical federated learning systems. Furthermore, we propose to jointly train a clustering model and a multi-branch network to allocate lightweight specialized branches to clients from different modes. A temporal prior is used to significantly boost the training performance.Experiments for image classification on EMNIST and CIFAR datasets, and next word prediction on the Stack Overflow dataset show that the proposed algorithm can counter the effects of the distribution shift and significantly improve the final model performance. ",
        "conference": "ICLR",
        "中文标题": "昼夜之分？从周期性变化分布中学习多分支网络的联邦学习",
        "摘要翻译": "联邦学习已在实践中被用于从移动设备的分散客户端数据中训练机器学习模型。观察到可用于训练的客户端数据分布会随着一天中的时间变化而周期性变化，这可能导致训练不稳定并降低模型性能。在本文中，我们没有像之前的工作那样用块循环模式来建模分布变化，而是用白天和夜间模式之间逐渐变化的混合分布来建模，并发现这种直观的模型能更好地匹配实际联邦学习系统中的观察结果。此外，我们提出联合训练一个聚类模型和一个多分支网络，为来自不同模式的客户端分配轻量级的专用分支。使用时间先验显著提高了训练性能。在EMNIST和CIFAR数据集上的图像分类实验，以及在Stack Overflow数据集上的下一个单词预测实验表明，所提出的算法能够抵消分布变化的影响，并显著提高最终模型的性能。",
        "领域": "联邦学习、图像分类、自然语言处理",
        "问题": "解决联邦学习中因客户端数据分布随时间周期性变化导致的训练不稳定和模型性能下降问题",
        "动机": "实际联邦学习系统中客户端数据分布随时间周期性变化，影响模型训练和性能，需要更准确的建模和优化方法",
        "方法": "提出用白天和夜间模式之间逐渐变化的混合分布建模数据分布变化，联合训练聚类模型和多分支网络，为不同模式客户端分配专用分支，并利用时间先验提升性能",
        "关键词": [
            "联邦学习",
            "多分支网络",
            "分布变化",
            "时间先验",
            "模型性能优化"
        ],
        "涉及的技术概念": {
            "联邦学习": "一种从分散的客户端数据中训练机器学习模型的方法，保护数据隐私",
            "多分支网络": "为不同数据分布模式的客户端分配专用分支的网络结构，提高模型适应性",
            "时间先验": "利用时间信息优化模型训练过程，提升性能"
        },
        "success": true
    },
    {
        "order": 248,
        "title": "DIVA: Dataset Derivative of a Learning Task",
        "html": "https://iclr.cc//virtual/2022/poster/7196",
        "abstract": "We present a method to compute the derivative of a learning task with respect to a dataset. A learning task is a function from a training set to the validation error, which can be represented by a trained deep neural network (DNN). The ``dataset derivative'' is a linear operator, computed around the trained model, that informs how perturbations of the weight of each training sample affect the validation error, usually computed on a separate validation dataset.  Our method, DIVA (Differentiable Validation) hinges on a closed-form differentiable expression of the leave-one-out cross-validation error around a pre-trained DNN. Such expression constitutes the dataset derivative. DIVA could be used for dataset auto-curation, for example removing samples with faulty annotations, augmenting a dataset with additional relevant samples, or rebalancing. More generally, DIVA can be used to optimize the dataset, along with the parameters of the model, as part of the training process without the need for a separate validation dataset, unlike bi-level optimization methods customary in AutoML. To illustrate the flexibility of DIVA, we report experiments on sample auto-curation tasks such as outlier rejection, dataset extension, and automatic aggregation of multi-modal data.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "DIVA：学习任务的数据集导数",
        "摘要翻译": "我们提出了一种计算学习任务相对于数据集导数的方法。学习任务是从训练集到验证误差的函数，可以通过训练好的深度神经网络（DNN）来表示。'数据集导数'是一个线性算子，围绕训练好的模型计算，它告知每个训练样本权重的扰动如何影响验证误差，通常是在单独的验证数据集上计算的。我们的方法DIVA（可微分验证）依赖于预训练DNN周围留一法交叉验证误差的闭式可微分表达式。这样的表达式构成了数据集导数。DIVA可以用于数据集自动管理，例如移除带有错误注释的样本，用额外的相关样本扩充数据集，或重新平衡。更一般地，DIVA可以用于优化数据集，连同模型的参数，作为训练过程的一部分，而不需要像AutoML中习惯的双层优化方法那样需要单独的验证数据集。为了说明DIVA的灵活性，我们报告了关于样本自动管理任务的实验，如异常值拒绝、数据集扩展和多模态数据的自动聚合。",
        "领域": "深度学习优化, 数据集管理, 自动机器学习",
        "问题": "如何计算学习任务相对于数据集的导数，以优化数据集和模型参数",
        "动机": "开发一种方法来自动管理和优化数据集，提高模型训练效率和性能",
        "方法": "提出DIVA方法，通过计算预训练DNN周围留一法交叉验证误差的闭式可微分表达式，作为数据集导数，用于数据集自动管理和优化",
        "关键词": [
            "数据集导数",
            "深度学习优化",
            "自动数据集管理",
            "可微分验证",
            "多模态数据聚合"
        ],
        "涉及的技术概念": {
            "数据集导数": "围绕训练好的模型计算的线性算子，用于评估训练样本权重扰动对验证误差的影响",
            "留一法交叉验证": "一种验证方法，通过排除一个样本来评估模型性能，DIVA利用其闭式可微分表达式作为数据集导数",
            "自动机器学习": "DIVA方法可以优化数据集和模型参数，作为训练过程的一部分，无需单独的验证数据集，区别于传统的双层优化方法"
        }
    },
    {
        "order": 249,
        "title": "Dive Deeper Into Integral Pose Regression",
        "html": "https://iclr.cc//virtual/2022/poster/5955",
        "abstract": "Integral pose regression combines an implicit heatmap with end-to-end training for human body and hand pose estimation. Unlike detection-based heatmap methods, which decode final joint positions from the heatmap with a non-differentiable argmax operation, integral regression methods apply a differentiable expectation operation. This paper offers a deep dive into the inference and back-propagation of integral pose regression to better understand the differences in performance and training compared to detection-based methods. For inference, we give theoretical support why expectation should always be better than the argmax operation, \\ie integral regression should always outperform detection.  Yet in practice, this is observed only in hard cases because the heatmap activation for regression shrinks in easy cases. We then experimentally show that the activation shrinkage is one of the leading causes for integral regression's inferior performance.  For back-propagation, we theoretically and empirically analyze the gradients to explain the slow training speed for integral regression.  Based on these findings, we incorporate the supervision of spatial prior to speed up training and improve performance.",
        "conference": "ICLR",
        "中文标题": "深入探究积分姿态回归",
        "摘要翻译": "积分姿态回归将隐式热图与端到端训练相结合，用于人体和手部姿态估计。与基于检测的热图方法不同，后者通过不可微的argmax操作从热图中解码最终的关节位置，积分回归方法应用了可微的期望操作。本文深入探讨了积分姿态回归的推断和反向传播，以更好地理解与基于检测的方法在性能和训练上的差异。对于推断，我们提供了理论支持，说明为什么期望操作总是优于argmax操作，即积分回归应该总是优于检测。然而在实践中，这仅在困难案例中观察到，因为在简单案例中回归的热图激活会收缩。然后我们通过实验证明，激活收缩是积分回归性能较差的主要原因之一。对于反向传播，我们从理论上和实验上分析了梯度，以解释积分回归训练速度慢的原因。基于这些发现，我们引入了空间先验的监督，以加速训练并提高性能。",
        "领域": "人体姿态估计, 手部姿态估计, 深度学习",
        "问题": "解决积分姿态回归在性能和训练速度上不如基于检测的方法的问题",
        "动机": "深入理解积分姿态回归与基于检测的方法在性能和训练上的差异，并提出改进措施",
        "方法": "通过理论分析和实验验证，探讨积分回归的推断和反向传播机制，并引入空间先验监督以优化训练",
        "关键词": [
            "积分姿态回归",
            "热图激活收缩",
            "空间先验监督",
            "人体姿态估计",
            "手部姿态估计"
        ],
        "涉及的技术概念": {
            "积分姿态回归": "一种结合隐式热图和端到端训练的姿态估计方法，通过可微的期望操作替代传统的argmax操作",
            "热图激活收缩": "在简单案例中，回归的热图激活会收缩，影响积分回归的性能",
            "空间先验监督": "通过引入空间先验的监督，加速训练并提高积分回归的性能"
        },
        "success": true
    },
    {
        "order": 250,
        "title": "Divergence-aware Federated Self-Supervised Learning",
        "html": "https://iclr.cc//virtual/2022/poster/5908",
        "abstract": "Self-supervised learning (SSL) is capable of learning remarkable representations from centrally available data. Recent works further implement federated learning with SSL to learn from rapidly growing decentralized unlabeled images (e.g., from cameras and phones), often resulted from privacy constraints. Extensive attention has been paid to SSL approaches based on Siamese networks. However, such an effort has not yet revealed deep insights into various fundamental building blocks for the federated self-supervised learning (FedSSL) architecture. We aim to fill in this gap via in-depth empirical study and propose a new method to tackle the non-independently and identically distributed (non-IID) data problem of decentralized data. Firstly, we introduce a generalized FedSSL framework that embraces existing SSL methods based on Siamese networks and presents flexibility catering to future methods. In this framework, a server coordinates multiple clients to conduct SSL training and periodically updates local models of clients with the aggregated global model. Using the framework, our study uncovers unique insights of FedSSL: 1) stop-gradient operation, previously reported to be essential, is not always necessary in FedSSL; 2) retaining local knowledge of clients in FedSSL is particularly beneficial for non-IID data. Inspired by the insights, we then propose a new approach for model update, Federated Divergence-aware Exponential Moving Average update (FedEMA). FedEMA updates local models of clients adaptively using EMA of the global model, where the decay rate is dynamically measured by model divergence. Extensive experiments demonstrate that FedEMA outperforms existing methods by 3-4% on linear evaluation. We hope that this work will provide useful insights for future research.",
        "conference": "ICLR",
        "中文标题": "发散感知的联邦自监督学习",
        "摘要翻译": "自监督学习（SSL）能够从集中可用的数据中学习到显著的表示。最近的工作进一步实现了与SSL结合的联邦学习，以从快速增长的去中心化未标记图像（例如，来自相机和手机）中学习，这通常是由于隐私限制而产生的。基于孪生网络的SSL方法受到了广泛关注。然而，这种努力尚未揭示联邦自监督学习（FedSSL）架构中各种基本构建块的深刻见解。我们旨在通过深入的实证研究填补这一空白，并提出一种新方法来处理去中心化数据的非独立同分布（non-IID）问题。首先，我们引入了一个广义的FedSSL框架，该框架包含了基于孪生网络的现有SSL方法，并提供了灵活性以适应未来的方法。在这个框架中，服务器协调多个客户端进行SSL训练，并定期用聚合的全局模型更新客户端的本地模型。利用这个框架，我们的研究揭示了FedSSL的独特见解：1）之前报告认为至关重要的停止梯度操作，在FedSSL中并不总是必要的；2）在FedSSL中保留客户端的本地知识对于非IID数据特别有益。受这些见解的启发，我们随后提出了一种新的模型更新方法，联邦发散感知指数移动平均更新（FedEMA）。FedEMA使用全局模型的EMA自适应地更新客户端的本地模型，其中衰减率通过模型发散动态测量。大量实验表明，FedEMA在线性评估上比现有方法高出3-4%。我们希望这项工作能为未来的研究提供有用的见解。",
        "领域": "联邦学习、自监督学习、非独立同分布数据处理",
        "问题": "解决去中心化数据的非独立同分布问题，并提升联邦自监督学习的效率和效果",
        "动机": "探索联邦自监督学习架构中的基本构建块，提出新方法以处理非IID数据问题",
        "方法": "引入广义FedSSL框架，提出Federated Divergence-aware Exponential Moving Average update (FedEMA)方法，动态调整模型更新",
        "关键词": [
            "联邦学习",
            "自监督学习",
            "非独立同分布数据",
            "模型发散",
            "指数移动平均"
        ],
        "涉及的技术概念": {
            "联邦学习": "一种机器学习方法，允许多个客户端在服务器协调下共同训练模型，而无需共享原始数据",
            "自监督学习": "一种无需人工标注数据的学习方法，通过数据本身生成监督信号进行训练",
            "非独立同分布数据": "指数据在不同客户端之间分布不一致，且数据样本间不独立，这在联邦学习中是一个常见挑战"
        },
        "success": true
    },
    {
        "order": 251,
        "title": "Diverse Client Selection for Federated Learning via Submodular Maximization",
        "html": "https://iclr.cc//virtual/2022/poster/7047",
        "abstract": "In every communication round of federated learning, a random subset of clients communicate  their  model  updates  back  to  the  server  which  then  aggregates them all.  The optimal size of this subset is not known and several studies have shown that typically random selection does not perform very well in terms of convergence, learning efficiency and fairness. We, in this paper, propose to select a small diverse subset of clients, namely those carrying representative gradient information, and we transmit only these updates to the server.  Our aim is for updating via only a subset to approximate updating via aggregating all client information. We achieve this by choosing a subset that maximizes a submodular facility location function defined over gradient space. We introduce “federated averaging with diverse client selection (DivFL)”. We provide a thorough analysis of its convergence in the heterogeneous setting and apply it both to synthetic and to real datasets. Empirical results show several benefits to our approach including improved learning efficiency, faster convergence and also more uniform (i.e., fair) performance across clients. We further show a communication-efficient version of DivFL that can still outperform baselines on the above metrics.",
        "conference": "ICLR",
        "中文标题": "通过子模最大化实现联邦学习的多样化客户端选择",
        "摘要翻译": "在联邦学习的每一轮通信中，随机选择的客户端子集将其模型更新传回服务器，服务器随后聚合所有这些更新。这个子集的最优大小尚不明确，多项研究表明，随机选择通常在收敛性、学习效率和公平性方面表现不佳。本文中，我们提出选择一小部分多样化的客户端，即那些携带代表性梯度信息的客户端，并且我们仅将这些更新传输到服务器。我们的目标是通过仅使用一个子集的更新来近似通过聚合所有客户端信息进行的更新。我们通过选择一个在梯度空间上定义的子模设施位置函数最大化的子集来实现这一点。我们引入了“带有多样化客户端选择的联邦平均（DivFL）”。我们提供了在异构设置下其收敛性的全面分析，并将其应用于合成数据集和真实数据集。实证结果显示，我们的方法带来了多项好处，包括提高学习效率、加快收敛速度以及跨客户端更均匀（即更公平）的性能。我们进一步展示了一个通信效率高的DivFL版本，该版本在上述指标上仍能优于基线方法。",
        "领域": "联邦学习、优化算法、机器学习效率",
        "问题": "解决联邦学习中随机选择客户端子集导致的收敛性、学习效率和公平性不佳的问题。",
        "动机": "提高联邦学习的效率、收敛速度和公平性，通过选择携带代表性梯度信息的客户端子集来近似全客户端聚合的效果。",
        "方法": "提出一种基于子模设施位置函数最大化的多样化客户端选择方法（DivFL），并通过理论和实证分析验证其有效性。",
        "关键词": [
            "联邦学习",
            "客户端选择",
            "子模最大化",
            "梯度信息",
            "收敛性"
        ],
        "涉及的技术概念": {
            "子模最大化": "用于选择能够最大化代表梯度信息的客户端子集的技术，确保选择的子集在梯度空间上具有高代表性。",
            "联邦平均（DivFL）": "一种改进的联邦学习方法，通过多样化客户端选择提高学习效率和公平性。",
            "梯度空间": "在联邦学习中，用于衡量和选择客户端更新代表性的一种空间表示，是实现高效客户端选择的关键。"
        },
        "success": true
    },
    {
        "order": 252,
        "title": "Divisive Feature Normalization Improves Image Recognition Performance in AlexNet",
        "html": "https://iclr.cc//virtual/2022/poster/6633",
        "abstract": "Local divisive normalization provides a phenomenological description of many nonlinear response properties of neurons across visual cortical areas. To gain insight into the utility of this operation, we studied the effects on AlexNet of a local divisive normalization between features, with learned parameters. Developing features were arranged in a line topology, with the influence between features determined by an exponential function of the distance between them. We compared an AlexNet model with no normalization or with canonical normalizations (Batch, Group, Layer) to the same models with divisive normalization added (before the canonical normalization, when those were used). The normalization was performed after the RELU in all five convolutional layers. Divisive normalization always improved performance for models with batch or group or no normalization, gen- erally by 1-2 percentage points, on both the CIFAR-100 and ImageNet databases. Divisive followed by batch normalization showed best performance. To gain in- sight into mechanisms underlying the improved performance, we examined several aspects of network representations. In the early layers both canonical and divisive normalizations reduced manifold capacities and increased average dimension of the individual categorical manifolds. In later layers the capacity was higher and manifold dimension lower for models roughly in order of their performance im- provement. We also use the Gini index, a measure of the inequality of a distribution, as a metric for sparsity of the distribution of activities within a given layer. Divisive normalization layers increase the Gini index (i.e. increase sparsity), whereas the other normalizations decrease the Gini index in their respective layers. Nonetheless, in the final layer, the sparseness of activity increases in the order of no normal- ization, divisive, combined, and canonical. We also investigate how the receptive fields (RFs) in the first convolutional layer (where RFs are most interpretable) change with normalization. Divisive normalization enhances RF Fourier power at low wavelengths, and divisive+canonical enhances power at mid (batch, group) or low (layer) wavelengths, compared to canonical alone or no normalization. In conclusion, divisive normalization enhances image recognition performance, most strongly when combined with canonical normalization, and in doing so it reduces manifold capacity and sparsity in early layers while increasing them in final layers, and increases low- or mid-wavelength power in the first-layer receptive fields.",
        "conference": "ICLR",
        "中文标题": "分裂特征归一化提升AlexNet图像识别性能",
        "摘要翻译": "局部分裂归一化为视觉皮层区域神经元多种非线性响应特性提供了现象学描述。为了深入理解这一操作的效用，我们研究了在AlexNet中特征间局部分裂归一化（具有学习参数）的影响。发展中的特征按线性拓扑排列，特征间的影响由它们之间距离的指数函数决定。我们将没有归一化或使用标准归一化（批、组、层）的AlexNet模型与添加了分裂归一化的相同模型（在使用标准归一化时，分裂归一化在其之前进行）进行了比较。归一化在所有五个卷积层的RELU之后进行。分裂归一化总是能提高使用批归一化、组归一化或无归一化模型的性能，通常在CIFAR-100和ImageNet数据库上提高1-2个百分点。分裂归一化后接批归一化显示出最佳性能。为了深入理解性能提升的机制，我们检查了网络表示的几个方面。在早期层，无论是标准归一化还是分裂归一化都降低了流形容量并增加了单个类别流形的平均维度。在后期层，性能提升大致按顺序的模型流形容量较高且维度较低。我们还使用基尼指数（衡量分布不平等性的指标）作为给定层内活动分布稀疏性的度量。分裂归一化层增加了基尼指数（即增加了稀疏性），而其他归一化在各自层中减少了基尼指数。尽管如此，在最后一层，活动的稀疏性按无归一化、分裂、组合和标准归一化的顺序增加。我们还研究了第一卷积层中感受野（RFs，此处最易解释）如何随归一化而变化。与单独使用标准归一化或无归一化相比，分裂归一化增强了低波长处的RF傅里叶功率，分裂+标准归一化在中（批、组）或低（层）波长处增强了功率。总之，分裂归一化增强了图像识别性能，尤其是与标准归一化结合时最为显著，在此过程中它降低了早期层的流形容量和稀疏性，同时增加了最终层的这些特性，并增加了第一层感受野的低或中波长功率。",
        "领域": "图像识别、深度学习优化、神经网络架构",
        "问题": "如何通过改进归一化方法来提升AlexNet在图像识别任务中的性能",
        "动机": "探索局部分裂归一化对深度学习模型性能的影响，特别是在图像识别任务中的应用效果",
        "方法": "在AlexNet中引入局部分裂归一化，并与标准归一化方法（批、组、层归一化）进行比较，评估其对模型性能的影响",
        "关键词": [
            "分裂归一化",
            "AlexNet优化",
            "图像识别",
            "深度学习",
            "神经网络"
        ],
        "涉及的技术概念": {
            "局部分裂归一化": "一种归一化方法，通过特征间的局部相互作用调整特征响应，以提高模型的识别性能",
            "基尼指数": "用于衡量网络层内活动分布的稀疏性，分裂归一化通过增加基尼指数来提高稀疏性",
            "感受野傅里叶功率": "分析第一卷积层感受野在不同波长下的功率分布，分裂归一化增强了特定波长范围的功率"
        },
        "success": true
    },
    {
        "order": 253,
        "title": "DKM: Differentiable k-Means Clustering Layer for Neural Network Compression",
        "html": "https://iclr.cc//virtual/2022/poster/6260",
        "abstract": "Deep neural network (DNN) model compression for efficient on-device inference is becoming increasingly important to reduce memory requirements and keep user data on-device. To this end, we propose a novel differentiable k-means clustering layer (DKM) and its application to train-time weight clustering-based DNN model compression. DKM casts k-means clustering as an attention problem and enables joint optimization of the DNN parameters and clustering centroids. Unlike prior works that rely on additional regularizers and parameters, DKM-based compression keeps the original loss function and model architecture fixed. We evaluated DKM-based compression on various DNN models for computer vision and natural language processing (NLP) tasks. Our results demonstrate that DKM delivers superior compression and accuracy trade-off on ImageNet1k and GLUE benchmarks. For example, DKM-based compression can offer 74.5% top-1 ImageNet1k accuracy on ResNet50 DNN model with 3.3MB model size (29.4x model compression factor). For MobileNet-v1, which is a challenging DNN to compress, DKM delivers 63.9% top-1 ImageNet1k accuracy with 0.72 MB model size (22.4x model compression factor). This result is 6.8% higher top-1accuracy and 33% relatively smaller model size than the current state-of-the-art DNN compression algorithms. Additionally, DKM enables compression of DistilBERT model by 11.8x with minimal (1.1%) accuracy loss on GLUE NLP benchmarks.",
        "conference": "ICLR",
        "中文标题": "DKM：用于神经网络压缩的可微分k均值聚类层",
        "摘要翻译": "深度神经网络（DNN）模型压缩以实现高效的设备端推理，对于减少内存需求和保持用户数据在设备端变得越来越重要。为此，我们提出了一种新颖的可微分k均值聚类层（DKM）及其在基于训练时权重聚类的DNN模型压缩中的应用。DKM将k均值聚类视为一个注意力问题，并实现了DNN参数和聚类中心的联合优化。与之前依赖额外正则化器和参数的工作不同，基于DKM的压缩保持了原始损失函数和模型架构不变。我们在计算机视觉和自然语言处理（NLP）任务的各种DNN模型上评估了基于DKM的压缩。我们的结果表明，DKM在ImageNet1k和GLUE基准测试上提供了优越的压缩和准确度权衡。例如，基于DKM的压缩可以在ResNet50 DNN模型上提供74.5%的ImageNet1k top-1准确度，模型大小为3.3MB（29.4倍模型压缩比）。对于MobileNet-v1这一难以压缩的DNN，DKM以0.72MB的模型大小（22.4倍模型压缩比）提供了63.9%的ImageNet1k top-1准确度。这一结果比当前最先进的DNN压缩算法高出6.8%的top-1准确度，并且模型大小相对小33%。此外，DKM能够在GLUE NLP基准测试上以最小的（1.1%）准确度损失压缩DistilBERT模型11.8倍。",
        "领域": "神经网络压缩、计算机视觉、自然语言处理",
        "问题": "如何在保持模型性能的同时，有效地压缩深度神经网络模型以适应设备端推理的需求。",
        "动机": "减少深度神经网络模型的内存需求，同时保持用户数据在设备端，以提高设备端推理的效率和隐私保护。",
        "方法": "提出了一种可微分k均值聚类层（DKM），通过将k均值聚类视为注意力问题，实现DNN参数和聚类中心的联合优化，无需改变原始损失函数和模型架构。",
        "关键词": [
            "神经网络压缩",
            "可微分k均值聚类",
            "设备端推理",
            "模型优化",
            "权重聚类"
        ],
        "涉及的技术概念": {
            "可微分k均值聚类层（DKM）": "将k均值聚类转化为可微分操作，允许在训练过程中优化聚类中心和网络参数。",
            "注意力机制": "在DKM中用于模拟k均值聚类的过程，使得聚类过程可以与神经网络训练联合优化。",
            "模型压缩": "通过减少模型的大小和复杂度，以适应设备端资源限制，同时尽可能保持模型性能。"
        },
        "success": true
    },
    {
        "order": 254,
        "title": "Do deep networks transfer invariances across classes?",
        "html": "https://iclr.cc//virtual/2022/poster/6042",
        "abstract": "In order to generalize well, classifiers must learn to be invariant to nuisance transformations that do not alter an input's class. Many problems have 'class-agnostic' nuisance transformations that apply similarly to all classes, such as lighting and background changes for image classification. Neural networks can learn these invariances given sufficient data, but many real-world datasets are heavily class imbalanced and contain only a few examples for most of the classes. We therefore pose the question: how well do neural networks transfer class-agnostic invariances learned from the large classes to the small ones? Through careful experimentation, we observe that invariance to class-agnostic transformations is still heavily dependent on class size, with the networks being much less invariant on smaller classes. This result holds even when using data balancing techniques, and suggests poor invariance transfer across classes. Our results provide one explanation for why classifiers generalize poorly on unbalanced and long-tailed distributions. Based on this analysis, we show how a generative approach for learning the nuisance transformations can help transfer invariances across classes and improve performance on a set of imbalanced image classification benchmarks.",
        "conference": "ICLR",
        "中文标题": "深度网络能否跨类别传递不变性？",
        "摘要翻译": "为了良好地泛化，分类器必须学会对不改变输入类别的干扰变换保持不变。许多问题存在'类别无关'的干扰变换，这些变换同样适用于所有类别，如图像分类中的光照和背景变化。神经网络可以在给定足够数据的情况下学习这些不变性，但许多现实世界的数据集类别极度不平衡，大多数类别只有少量样本。因此，我们提出问题：神经网络如何将从大类学习到的类别无关不变性传递到小类？通过仔细的实验，我们观察到对类别无关变换的不变性仍然高度依赖于类别大小，网络在小类上的不变性要低得多。这一结果即使在使用数据平衡技术时也成立，表明跨类别的不变性传递效果不佳。我们的结果提供了一个解释，说明为什么分类器在不平衡和长尾分布上泛化能力差。基于这一分析，我们展示了如何通过学习干扰变换的生成方法来帮助跨类别传递不变性，并在不平衡图像分类基准集上提高性能。",
        "领域": "图像分类、深度学习、数据不平衡处理",
        "问题": "神经网络如何将从大类学习到的类别无关不变性传递到小类",
        "动机": "解释和改善分类器在不平衡和长尾分布上的泛化能力",
        "方法": "通过实验观察不变性传递效果，并提出使用生成方法学习干扰变换以传递不变性",
        "关键词": [
            "类别无关不变性",
            "数据不平衡",
            "图像分类",
            "泛化能力",
            "生成方法"
        ],
        "涉及的技术概念": {
            "类别无关不变性": "指那些不改变输入类别但可能影响分类器性能的变换，如光照和背景变化",
            "数据不平衡": "数据集中不同类别的样本数量差异显著，影响模型学习效果",
            "生成方法": "通过学习干扰变换的生成模型，帮助模型在不同类别间传递不变性，提高分类性能"
        },
        "success": true
    },
    {
        "order": 255,
        "title": "Does your graph need a confidence boost?  Convergent boosted smoothing on graphs with tabular node features",
        "html": "https://iclr.cc//virtual/2022/poster/7020",
        "abstract": "Many practical modeling tasks require making predictions using tabular data composed of heterogeneous feature types (e.g., text-based, categorical, continuous, etc.).  In this setting boosted decision trees and related ensembling techniques generally dominate real-world applications involving iid training/test sets.  However, when there are relations between samples and the iid assumption is no longer reasonable, it remains unclear how to incorporate these dependencies within existing boosting pipelines.  To this end, we propose a generalized framework for combining boosted trees and more general model ensembling techniques, with graph propagation layers that share  node/sample information across edges connecting related samples.  And unlike previous efforts to integrate graph-based models with boosting, our approach is anchored to a principled meta loss function such that provable convergence can be guaranteed under relatively mild assumptions. Across a variety of benchmarks involving non-iid graph data with tabular node features, our framework achieves comparable or superior performance.",
        "conference": "ICLR",
        "中文标题": "你的图需要信心提升吗？基于表格节点特征的图上收敛增强平滑方法",
        "摘要翻译": "许多实际建模任务需要使用由异构特征类型（例如基于文本的、分类的、连续的等）组成的表格数据进行预测。在这种设置下，增强决策树和相关的集成技术通常在涉及独立同分布训练/测试集的现实世界应用中占据主导地位。然而，当样本之间存在关系且独立同分布假设不再合理时，如何将这些依赖关系纳入现有的增强流程中仍不明确。为此，我们提出了一个通用框架，用于结合增强树和更一般的模型集成技术，通过图传播层在连接相关样本的边之间共享节点/样本信息。与之前尝试将基于图的模型与增强结合的尝试不同，我们的方法锚定于一个有原则的元损失函数，从而在相对温和的假设下可以保证可证明的收敛性。在涉及具有表格节点特征的非独立同分布图数据的各种基准测试中，我们的框架实现了可比或更优的性能。",
        "领域": "图神经网络、集成学习、非独立同分布数据学习",
        "问题": "如何在样本间存在依赖关系的情况下，将图结构与增强决策树等集成学习技术有效结合，以提升预测性能。",
        "动机": "解决在非独立同分布数据上，传统增强决策树方法无法有效利用样本间依赖关系的问题。",
        "方法": "提出一个结合增强树与图传播层的通用框架，通过共享节点信息来整合样本间依赖关系，并基于元损失函数保证收敛性。",
        "关键词": [
            "图神经网络",
            "增强决策树",
            "非独立同分布数据",
            "集成学习",
            "图传播"
        ],
        "涉及的技术概念": {
            "增强决策树": "一种集成学习技术，通过迭代地添加决策树来纠正前序模型的错误，用于提升模型性能。",
            "图传播层": "在图结构中共享和更新节点信息的机制，用于捕捉和利用样本间的依赖关系。",
            "元损失函数": "用于指导模型训练的高层次损失函数，确保模型在特定条件下能够收敛。"
        },
        "success": true
    },
    {
        "order": 256,
        "title": "Domain Adversarial Training: A Game Perspective",
        "html": "https://iclr.cc//virtual/2022/poster/6466",
        "abstract": "The dominant line of work in domain adaptation has focused on learning invariant representations using domain-adversarial training. In this paper, we interpret this approach from a game theoretical perspective. Defining optimal solutions in domain-adversarial training as a local Nash equilibrium, we show that gradient descent in domain-adversarial training can violate the asymptotic convergence guarantees of the optimizer, oftentimes hindering the transfer performance. Our analysis leads us to replace gradient descent with high-order ODE solvers (i.e., Runge–Kutta), for which we derive asymptotic convergence guarantees. This family of optimizers is significantly more stable and allows more aggressive learning rates, leading to high performance gains when used as a drop-in replacement over standard optimizers. Our experiments show that in conjunction with state-of-the-art domain-adversarial methods, we achieve up to 3.5% improvement with less than of half training iterations. Our optimizers are easy to implement, free of additional parameters, and can be plugged into any domain-adversarial framework.",
        "conference": "ICLR",
        "中文标题": "领域对抗训练：一种博弈视角",
        "摘要翻译": "在领域适应领域的主流研究方向集中在利用领域对抗训练学习不变表示。本文中，我们从博弈论的角度解读了这一方法。将领域对抗训练中的最优解定义为局部纳什均衡，我们展示了领域对抗训练中的梯度下降可能违反优化器的渐近收敛保证，常常阻碍迁移性能。我们的分析引导我们用高阶ODE求解器（即龙格-库塔方法）替代梯度下降，为此我们推导了渐近收敛保证。这类优化器显著更稳定，并允许更激进的学习率，当作为标准优化器的即插即用替代时，带来高性能增益。我们的实验表明，结合最先进的领域对抗方法，我们实现了高达3.5%的改进，且训练迭代次数不到一半。我们的优化器易于实现，无额外参数，并可插入任何领域对抗框架中。",
        "领域": "领域适应、对抗学习、优化算法",
        "问题": "领域对抗训练中梯度下降方法可能违反优化器的渐近收敛保证，影响迁移性能。",
        "动机": "从博弈论角度理解领域对抗训练，解决现有优化方法在领域对抗训练中的不足。",
        "方法": "使用高阶ODE求解器（如龙格-库塔方法）替代传统的梯度下降方法，以提高训练的稳定性和效率。",
        "关键词": [
            "领域对抗训练",
            "博弈论",
            "龙格-库塔方法",
            "优化算法",
            "领域适应"
        ],
        "涉及的技术概念": {
            "领域对抗训练": "一种通过对抗过程学习领域不变表示的技术，用于领域适应任务。",
            "局部纳什均衡": "在博弈论中，指在局部区域内没有玩家可以通过单方面改变策略而获得更好结果的策略组合。",
            "高阶ODE求解器": "用于求解常微分方程的高阶数值方法，如龙格-库塔方法，提供更稳定和高效的优化路径。"
        },
        "success": true
    },
    {
        "order": 257,
        "title": "Domino: Discovering Systematic Errors with Cross-Modal Embeddings",
        "html": "https://iclr.cc//virtual/2022/poster/6148",
        "abstract": "Machine learning models that achieve high overall accuracy often make systematic errors on important subsets (or slices) of data. Identifying underperforming slices is particularly challenging when working with high-dimensional inputs (e.g. images, audio), where important slices are often unlabeled. In order to address this issue, recent studies have proposed automated slice discovery methods (SDMs), which leverage learned model representations to mine input data for slices on which a model performs poorly. To be useful to a practitioner, these methods must identify slices that are both underperforming and coherent (i.e. united by a human-understandable concept). However, no quantitative evaluation framework currently exists for rigorously assessing SDMs with respect to these criteria. Additionally, prior qualitative evaluations have shown that SDMs often identify slices that are incoherent. In this work, we address these challenges by first designing a principled evaluation framework that enables a quantitative comparison of SDMs across 1,235 slice discovery settings in three input domains (natural images, medical images, and time-series data).Then, motivated by the recent development of powerful cross-modal representation learning approaches, we present Domino, an SDM that leverages cross-modal embeddings and a novel error-aware mixture model to discover and describe coherent slices. We find that Domino accurately identifies 36% of the 1,235 slices in our framework -- a 12 percentage point improvement over prior methods. Further, Domino is the first SDM that can provide natural language descriptions of identified slices, correctly generating the exact name of the slice in 35% of settings. ",
        "conference": "ICLR",
        "中文标题": "多米诺：利用跨模态嵌入发现系统性错误",
        "摘要翻译": "机器学习模型虽然在整体上达到了高准确率，但在数据的重要子集（或切片）上常常会犯系统性错误。当处理高维输入（如图像、音频）时，识别表现不佳的切片尤其具有挑战性，因为这些重要切片往往未被标记。为了解决这一问题，最近的研究提出了自动切片发现方法（SDMs），这些方法利用学习到的模型表示来挖掘输入数据中模型表现不佳的切片。为了使这些方法对实践者有用，它们必须识别出既表现不佳又连贯（即由人类可理解的概念统一）的切片。然而，目前尚无定量评估框架来严格评估SDMs在这些标准上的表现。此外，先前的定性评估显示，SDMs经常识别出不连贯的切片。在这项工作中，我们首先设计了一个原则性的评估框架，该框架能够在三个输入领域（自然图像、医学图像和时间序列数据）的1,235个切片发现设置中进行SDMs的定量比较。然后，受到最近强大的跨模态表示学习方法发展的启发，我们提出了Domino，这是一种利用跨模态嵌入和一种新颖的错误感知混合模型来发现和描述连贯切片的SDM。我们发现，Domino在我们的框架中准确识别了1,235个切片中的36%——比先前的方法提高了12个百分点。此外，Domino是第一个能够提供识别切片自然语言描述的SDM，在35%的设置中正确生成了切片的精确名称。",
        "领域": "模型错误分析、跨模态学习、自动化诊断",
        "问题": "识别和描述机器学习模型在高维数据中表现不佳的连贯切片",
        "动机": "解决现有自动切片发现方法在识别连贯切片方面的不足，并提供定量评估框架",
        "方法": "设计了一个评估框架进行定量比较，并提出了Domino方法，利用跨模态嵌入和错误感知混合模型来发现和描述连贯切片",
        "关键词": [
            "系统性错误",
            "跨模态嵌入",
            "切片发现",
            "模型评估",
            "自然语言描述"
        ],
        "涉及的技术概念": {
            "跨模态嵌入": "用于连接不同模态（如图像和文本）的数据表示，帮助发现和理解模型错误",
            "错误感知混合模型": "一种新型模型，专门设计来识别和描述模型表现不佳的数据切片",
            "自动切片发现方法（SDMs）": "利用模型表示自动识别数据中模型表现不佳的切片的技术"
        },
        "success": true
    },
    {
        "order": 258,
        "title": "Do Not Escape From the Manifold: Discovering the Local Coordinates on the Latent Space of GANs",
        "html": "https://iclr.cc//virtual/2022/poster/6326",
        "abstract": "The discovery of the disentanglement properties of the latent space in GANs motivated a lot of research to find the semantically meaningful directions on it. In this paper, we suggest that the disentanglement property is closely related to the geometry of the latent space. In this regard, we propose an unsupervised method for finding the semantic-factorizing directions on the intermediate latent space of GANs based on the local geometry. Intuitively, our proposed method, called $\\textit{Local Basis}$, finds the principal variation of the latent space in the neighborhood of the base latent variable. Experimental results show that the local principal variation corresponds to the semantic factorization and traversing along it provides strong robustness to image traversal. Moreover, we suggest an explanation for the limited success in finding the global traversal directions in the latent space, especially $\\mathcal{W}$-space of StyleGAN2. We show that $\\mathcal{W}$-space is warped globally by comparing the local geometry, discovered from Local Basis, through the metric on Grassmannian Manifold. The global warpage implies that the latent space is not well-aligned globally and therefore the global traversal directions are bound to show limited success on it.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "不要逃离流形：在GANs的潜在空间中发现局部坐标",
        "摘要翻译": "GANs潜在空间中解缠性质的发现激发了许多研究来寻找其上的语义有意义的方向。在本文中，我们提出解缠性质与潜在空间的几何结构密切相关。就此而言，我们提出了一种基于局部几何的无监督方法，用于在GANs的中间潜在空间上寻找语义分解方向。直观上，我们提出的方法称为“局部基”，它找到了基础潜在变量邻域内潜在空间的主要变化。实验结果表明，局部主要变化对应于语义分解，并沿着它进行遍历提供了对图像遍历的强大鲁棒性。此外，我们对在潜在空间，尤其是StyleGAN2的W空间中寻找全局遍历方向的有限成功提出了解释。通过Grassmann流形上的度量比较从局部基发现的局部几何，我们展示了W空间在全局上是扭曲的。这种全局扭曲意味着潜在空间在全局上并未良好对齐，因此全局遍历方向在其上必然显示出有限的成功。",
        "领域": "生成对抗网络、图像生成、语义解缠",
        "问题": "如何在GANs的潜在空间中有效地发现语义分解方向",
        "动机": "探索GANs潜在空间的几何结构与其解缠性质之间的关系，以提高图像遍历的鲁棒性和语义分解的有效性",
        "方法": "提出了一种基于局部几何的无监督方法“局部基”，用于发现潜在空间中的语义分解方向，并通过Grassmann流形上的度量分析W空间的全局扭曲",
        "关键词": [
            "生成对抗网络",
            "潜在空间",
            "语义解缠",
            "局部几何",
            "Grassmann流形"
        ],
        "涉及的技术概念": {
            "局部基": "用于发现潜在空间中基础潜在变量邻域内主要变化的方法，对应于语义分解",
            "Grassmann流形": "用于度量和比较潜在空间局部几何的数学结构，揭示了W空间的全局扭曲",
            "语义分解方向": "在GANs潜在空间中，能够分离和控制生成图像特定语义属性的方向"
        }
    },
    {
        "order": 259,
        "title": "Doubly Adaptive Scaled Algorithm for Machine Learning Using Second-Order Information",
        "html": "https://iclr.cc//virtual/2022/poster/6864",
        "abstract": "We present a novel adaptive optimization algorithm for large-scale machine learning problems. Equipped with a low-cost estimate of local curvature and Lipschitz smoothness, our method dynamically adapts the search direction and step-size. The search direction contains gradient information preconditioned by a well-scaled diagonal preconditioning matrix that captures the local curvature information. Our methodology does not require the tedious task of learning rate tuning, as the learning rate is updated automatically without adding an extra hyper-parameter. We provide convergence guarantees on a comprehensive collection of optimization problems, including convex, strongly convex, and nonconvex problems, in both deterministic and stochastic regimes. We also conduct an extensive empirical evaluation on standard machine learning problems, justifying our algorithm's versatility and demonstrating its strong performance compared to other start-of-the-art first-order and second-order methods.",
        "conference": "ICLR",
        "中文标题": "利用二阶信息的机器学习双自适应缩放算法",
        "摘要翻译": "我们提出了一种新颖的自适应优化算法，用于大规模机器学习问题。我们的方法配备了局部曲率和Lipschitz平滑性的低成本估计，动态调整搜索方向和步长。搜索方向包含由良好缩放的对角预处理矩阵预处理的梯度信息，该矩阵捕捉了局部曲率信息。我们的方法不需要繁琐的学习率调整任务，因为学习率会自动更新而不增加额外的超参数。我们提供了在包括凸、强凸和非凸问题在内的全面优化问题集合上的收敛保证，涵盖了确定性和随机性制度。我们还在标准机器学习问题上进行了广泛的实证评估，证明了我们算法的多功能性，并展示了与其他最先进的一阶和二阶方法相比的强劲性能。",
        "领域": "优化算法、机器学习、大规模学习",
        "问题": "大规模机器学习中的优化问题，特别是在动态调整搜索方向和步长方面",
        "动机": "为了解决大规模机器学习中优化算法的效率和适应性，特别是在不需要手动调整学习率的情况下自动适应不同问题",
        "方法": "提出了一种结合二阶信息（局部曲率和Lipschitz平滑性估计）的自适应优化算法，动态调整搜索方向和步长，自动更新学习率",
        "关键词": [
            "自适应优化",
            "二阶信息",
            "机器学习",
            "大规模学习",
            "收敛保证"
        ],
        "涉及的技术概念": {
            "局部曲率": "用于捕捉优化问题的局部几何特性，帮助动态调整搜索方向",
            "Lipschitz平滑性": "用于估计函数的平滑程度，影响步长的动态调整",
            "对角预处理矩阵": "用于预处理梯度信息，提高优化算法的效率和适应性"
        },
        "success": true
    },
    {
        "order": 260,
        "title": "Do Users Benefit From Interpretable Vision? A User Study, Baseline, And Dataset",
        "html": "https://iclr.cc//virtual/2022/poster/5894",
        "abstract": "A variety of methods exist to explain image classification models. However, whether they provide any benefit to users over simply comparing various inputs and the model’s respective predictions remains unclear. We conducted a user study (N=240) to test how such a baseline explanation technique performs against concept-based and counterfactual explanations. To this end, we contribute a synthetic dataset generator capable of biasing individual attributes and quantifying their relevance to the model. In a study, we assess if participants can identify the relevant set of attributes compared to the ground-truth. Our results show that the baseline outperformed concept-based explanations. Counterfactual explanations from an invertible neural network performed similarly as the baseline. Still, they allowed users to identify some attributes more accurately. Our results highlight the importance of measuring how well users can reason about biases of a model, rather than solely relying on technical evaluations or proxy tasks. We open-source our study and dataset so it can serve as a blue-print for future studies.",
        "conference": "ICLR",
        "中文标题": "用户是否从可解释视觉中受益？一项用户研究、基线及数据集",
        "摘要翻译": "存在多种方法来解释图像分类模型。然而，这些方法是否比简单地比较各种输入和模型各自的预测更能为用户提供任何好处，尚不明确。我们进行了一项用户研究（N=240），以测试这种基线解释技术与基于概念和反事实解释的表现。为此，我们贡献了一个能够偏置个体属性并量化它们与模型相关性的合成数据集生成器。在一项研究中，我们评估了参与者是否能够识别出与真实情况相关的属性集。我们的结果显示，基线方法优于基于概念的解释。来自可逆神经网络的反事实解释表现与基线相似。尽管如此，它们使用户能够更准确地识别一些属性。我们的结果强调了衡量用户如何能够推理模型偏差的重要性，而不是仅仅依赖技术评估或代理任务。我们开源了我们的研究和数据集，以便它可以作为未来研究的蓝图。",
        "领域": "可解释人工智能、图像分类、用户研究",
        "问题": "评估不同解释方法（基线、基于概念、反事实）在帮助用户理解图像分类模型方面的有效性。",
        "动机": "探索解释方法是否真正帮助用户理解模型决策，超越简单的输入输出比较。",
        "方法": "通过用户研究比较基线解释、基于概念的解释和反事实解释的效果，并使用合成数据集生成器来偏置和量化属性相关性。",
        "关键词": [
            "可解释性",
            "用户研究",
            "图像分类",
            "反事实解释",
            "合成数据集"
        ],
        "涉及的技术概念": {
            "基线解释技术": "作为比较基准的简单解释方法，通过比较输入和模型预测来提供解释。",
            "基于概念的解释": "通过识别和解释模型决策中使用的关键概念来提供解释的方法。",
            "反事实解释": "通过展示改变输入中的某些特征如何导致不同的模型预测来提供解释的方法。"
        },
        "success": true
    },
    {
        "order": 261,
        "title": "Do We Need Anisotropic Graph Neural Networks?",
        "html": "https://iclr.cc//virtual/2022/poster/6535",
        "abstract": "Common wisdom in the graph neural network (GNN) community dictates that anisotropic models---in which messages sent between nodes are a function of both the source and target node---are required to achieve state-of-the-art performance. Benchmarks to date have demonstrated that these models perform better than comparable isotropic models---where messages are a function of the source node only. In this work we provide empirical evidence challenging this narrative: we propose an isotropic GNN, which we call Efficient Graph Convolution (EGC), that consistently outperforms comparable anisotropic models, including the popular GAT or PNA architectures by using spatially-varying adaptive filters. In addition to raising important questions for the GNN community, our work has significant real-world implications for efficiency. EGC achieves higher model accuracy, with lower memory consumption and latency, along with characteristics suited to accelerator implementation, while being a drop-in replacement for existing architectures. As an isotropic model, it requires memory proportional to the number of vertices in the graph ($\\mathcal{O}(V)$); in contrast, anisotropic models require memory proportional to the number of edges ($\\mathcal{O}(E)$). We demonstrate that EGC outperforms existing approaches across 6 large and diverse benchmark datasets, and conclude by discussing questions that our work raise for the community going forward. Code and pretrained models for our experiments are provided at https://github.com/shyam196/egc.",
        "conference": "ICLR",
        "中文标题": "我们需要各向异性的图神经网络吗？",
        "摘要翻译": "图神经网络（GNN）领域的普遍观点认为，各向异性模型——其中节点之间发送的消息是源节点和目标节点的函数——是实现最先进性能所必需的。迄今为止的基准测试表明，这些模型的性能优于仅依赖于源节点的各向同性模型。在这项工作中，我们提供了挑战这一观点的实证证据：我们提出了一种各向同性的GNN，称为高效图卷积（EGC），它通过使用空间变化的自适应滤波器，持续优于包括流行的GAT或PNA架构在内的各向异性模型。除了为GNN社区提出重要问题外，我们的工作对效率具有重要的现实意义。EGC实现了更高的模型准确性，同时降低了内存消耗和延迟，并具有适合加速器实现的特性，同时可以作为现有架构的直接替代品。作为一个各向同性模型，它需要与图中顶点数量成比例的内存（O(V)）；相比之下，各向异性模型需要与边数量成比例的内存（O(E)）。我们证明，EGC在6个大型且多样化的基准数据集上优于现有方法，并在最后讨论了我们的工作为社区提出的问题。我们的实验代码和预训练模型可在https://github.com/shyam196/egc获取。",
        "领域": "图神经网络、深度学习优化、计算效率",
        "问题": "挑战图神经网络中普遍认为的各向异性模型优于各向同性模型的观念，并提出一种更高效的各向同性模型。",
        "动机": "为了证明各向同性图神经网络在性能和效率上可以超越各向异性模型，从而为图神经网络的设计和实现提供新的视角。",
        "方法": "提出了一种称为高效图卷积（EGC）的各向同性GNN，利用空间变化的自适应滤波器来提升性能。",
        "关键词": [
            "图神经网络",
            "各向同性模型",
            "高效图卷积",
            "计算效率",
            "自适应滤波器"
        ],
        "涉及的技术概念": {
            "各向同性模型": "消息传递仅依赖于源节点的图神经网络模型，与各向异性模型相比，具有更低的内存需求。",
            "高效图卷积（EGC）": "一种提出的各向同性图神经网络模型，通过空间变化的自适应滤波器实现高性能。",
            "空间变化的自适应滤波器": "在EGC中使用的一种技术，用于动态调整节点间消息传递的方式，以提高模型性能。"
        },
        "success": true
    },
    {
        "order": 262,
        "title": "DR3: Value-Based Deep Reinforcement Learning Requires Explicit Regularization",
        "html": "https://iclr.cc//virtual/2022/poster/6927",
        "abstract": "Despite overparameterization, deep networks trained via supervised learning are surprisingly easy to optimize and exhibit excellent generalization. One hypothesis to explain this is that overparameterized deep networks enjoy the benefits of implicit regularization induced by stochastic gradient descent, which favors parsimonious solutions that generalize well on test inputs. It is reasonable to surmise that deep reinforcement learning (RL) methods could also benefit from this effect. In this paper, we discuss how the implicit regularization effect of SGD seen in supervised learning could in fact be harmful in the offline deep RL setting, leading to poor generalization and degenerate feature representations. Our theoretical analysis shows that when existing models of implicit regularization are applied to temporal difference learning, the resulting derived regularizer favors degenerate solutions with excessive aliasing, in stark contrast to the supervised learning case. We back up these findings empirically, showing that feature representations learned by a deep network value function trained via bootstrapping can indeed become degenerate, aliasing the representations for state-action pairs that appear on either side of the Bellman backup. To address this issue, we derive the form of this implicit regularizer and, inspired by this derivation, propose a simple and effective explicit regularizer, called DR3, that counteracts the undesirable effects of this implicit regularizer. When combined with existing offline RL methods, DR3 substantially improves performance and stability, alleviating unlearning in Atari 2600 games, D4RL domains and robotic manipulation from images.",
        "conference": "ICLR",
        "中文标题": "DR3：基于价值的深度强化学习需要显式正则化",
        "摘要翻译": "尽管存在过参数化，通过监督学习训练的深度网络出奇地易于优化，并展现出优异的泛化能力。一种解释这一现象的假设是，过参数化的深度网络受益于随机梯度下降诱导的隐式正则化，这种正则化倾向于那些在测试输入上泛化良好的简约解。有理由推测，深度强化学习（RL）方法也可能从这种效应中受益。在本文中，我们讨论了监督学习中观察到的SGD的隐式正则化效应在离线深度RL设置中实际上可能是有害的，导致泛化能力差和退化的特征表示。我们的理论分析表明，当将现有的隐式正则化模型应用于时间差分学习时，得到的派生正则化器倾向于具有过度混叠的退化解，与监督学习的情况形成鲜明对比。我们通过实验支持这些发现，表明通过自举训练的深度网络价值函数学习的特征表示确实可能退化，混叠出现在Bellman备份两侧的状态-动作对的表示。为了解决这个问题，我们推导了这种隐式正则化器的形式，并受此推导启发，提出了一个简单有效的显式正则化器，称为DR3，以抵消这种隐式正则化器的不良影响。当与现有的离线RL方法结合时，DR3显著提高了性能和稳定性，缓解了在Atari 2600游戏、D4RL领域和基于图像的机器人操作中的遗忘问题。",
        "领域": "深度强化学习",
        "问题": "离线深度强化学习中的隐式正则化导致泛化能力差和特征表示退化",
        "动机": "探讨并解决隐式正则化在离线深度强化学习中的负面影响",
        "方法": "提出显式正则化器DR3，以抵消隐式正则化器的不良影响",
        "关键词": [
            "深度强化学习",
            "隐式正则化",
            "显式正则化",
            "特征表示",
            "离线学习"
        ],
        "涉及的技术概念": {
            "隐式正则化": "由随机梯度下降诱导的正则化效应，倾向于简约解",
            "显式正则化": "人为设计的正则化方法，用于改善模型性能",
            "Bellman备份": "强化学习中用于更新价值函数的操作，可能导致特征表示的混叠"
        },
        "success": true
    },
    {
        "order": 263,
        "title": "DriPP: Driven Point Processes to Model Stimuli Induced Patterns in M/EEG Signals",
        "html": "https://iclr.cc//virtual/2022/poster/6724",
        "abstract": "The quantitative analysis of non-invasive electrophysiology signals from electroencephalography (EEG) and magnetoencephalography (MEG) boils down to the identification of temporal patterns such as evoked responses, transient bursts of neural oscillations but also blinks or heartbeats for data cleaning. Several works have shown that these patterns can be extracted efficiently in an unsupervised way, e.g., using Convolutional Dictionary Learning. This leads to an event-based description of the data. Given these events, a natural question is to estimate how their occurrences are modulated by certain cognitive tasks and experimental manipulations. To address it, we propose a point process approach. While point processes have been used in neuroscience in the past, in particular for single cell recordings (spike trains), techniques such as Convolutional Dictionary Learning make them amenable to human studies based on EEG/MEG signals. We develop a novel statistical point process model – called driven temporal point processes (DriPP) – where the intensity function of the point process model is linked to a set of point processes corresponding to stimulation events. We derive a fast and principled expectation-maximization algorithm to estimate the parameters of this model. Simulations reveal that model parameters can be identified from long enough signals. Results on standard MEG datasets demonstrate that our methodology reveals event-related neural responses – both evoked and induced – and isolates non-task specific temporal patterns.",
        "conference": "ICLR",
        "中文标题": "DriPP：驱动点过程建模M/EEG信号中的刺激诱导模式",
        "摘要翻译": "非侵入性电生理学信号（如脑电图EEG和脑磁图MEG）的定量分析，关键在于识别时间模式，如诱发反应、神经振荡的短暂爆发，以及用于数据清理的眨眼或心跳。多项研究表明，这些模式可以通过无监督方法高效提取，例如使用卷积字典学习。这导致了对数据的事件性描述。给定这些事件，一个自然的问题是估计它们的发生如何被某些认知任务和实验操作所调节。为了解决这个问题，我们提出了一种点过程方法。虽然点过程过去在神经科学中已有应用，特别是用于单细胞记录（尖峰序列），但卷积字典学习等技术使其适用于基于EEG/MEG信号的人类研究。我们开发了一种新的统计点过程模型——称为驱动时间点过程（DriPP）——其中点过程模型的强度函数与对应于刺激事件的一组点过程相关联。我们推导了一种快速且有原则的期望最大化算法来估计该模型的参数。模拟显示，模型参数可以从足够长的信号中识别。标准MEG数据集的结果表明，我们的方法揭示了与事件相关的神经反应——包括诱发和诱导的——并隔离了非任务特定的时间模式。",
        "领域": "神经信号处理、脑电图分析、脑磁图分析",
        "问题": "如何估计EEG/MEG信号中事件的发生如何被认知任务和实验操作所调节",
        "动机": "开发一种能够揭示和量化EEG/MEG信号中由特定认知任务和实验操作调节的时间模式的方法",
        "方法": "提出了一种新的统计点过程模型（DriPP），并通过期望最大化算法估计模型参数",
        "关键词": [
            "驱动点过程",
            "脑电图",
            "脑磁图",
            "卷积字典学习",
            "期望最大化算法"
        ],
        "涉及的技术概念": {
            "驱动时间点过程（DriPP）": "一种新的统计点过程模型，用于建模EEG/MEG信号中由刺激事件调节的时间模式",
            "卷积字典学习": "一种无监督学习方法，用于从EEG/MEG信号中高效提取时间模式",
            "期望最大化算法": "用于估计DriPP模型参数的快速且有原则的算法"
        },
        "success": true
    },
    {
        "order": 264,
        "title": "Dropout Q-Functions for Doubly Efficient Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6233",
        "abstract": "Randomized ensembled double Q-learning (REDQ) (Chen et al., 2021b) has recently achieved state-of-the-art sample efficiency on continuous-action reinforcement learning benchmarks. This superior sample efficiency is made possible by using a large Q-function ensemble. However, REDQ is much less computationally efficient than non-ensemble counterparts such as Soft Actor-Critic (SAC) (Haarnoja et al., 2018a). To make REDQ more computationally efficient, we propose a method of improving computational efficiency called DroQ, which is a variant of REDQ that uses a small ensemble of dropout Q-functions. Our dropout Q-functions are simple Q-functions equipped with dropout connection and layer normalization. Despite its simplicity of implementation, our experimental results indicate that DroQ is doubly (sample and computationally) efficient. It achieved comparable sample efficiency with REDQ, much better computational efficiency than REDQ, and comparable computational efficiency with that of SAC.",
        "conference": "ICLR",
        "中文标题": "用于双重高效强化学习的Dropout Q函数",
        "摘要翻译": "随机集成双Q学习（REDQ）（Chen等人，2021b）最近在连续动作强化学习基准上实现了最先进的样本效率。这种卓越的样本效率是通过使用大型Q函数集成实现的。然而，REDQ的计算效率远低于非集成对应物，如软行动者-评论家（SAC）（Haarnoja等人，2018a）。为了使REDQ在计算上更高效，我们提出了一种提高计算效率的方法，称为DroQ，这是REDQ的一个变体，使用小型dropout Q函数集成。我们的dropout Q函数是配备了dropout连接和层归一化的简单Q函数。尽管实现简单，我们的实验结果表明，DroQ在样本和计算上都是双重高效的。它实现了与REDQ相当的样本效率，比REDQ更好的计算效率，以及与SAC相当的计算效率。",
        "领域": "强化学习、连续动作控制、深度Q网络",
        "问题": "如何在保持高样本效率的同时，提高REDQ算法的计算效率。",
        "动机": "REDQ算法虽然样本效率高，但计算效率低，限制了其在实际应用中的使用。",
        "方法": "提出DroQ方法，通过使用小型dropout Q函数集成来提高计算效率。",
        "关键词": [
            "强化学习",
            "dropout Q函数",
            "计算效率",
            "样本效率",
            "连续动作控制"
        ],
        "涉及的技术概念": {
            "随机集成双Q学习（REDQ）": "一种通过使用大型Q函数集成来提高样本效率的强化学习算法。",
            "dropout Q函数": "配备了dropout连接和层归一化的Q函数，用于提高计算效率。",
            "软行动者-评论家（SAC）": "一种非集成的强化学习算法，以其高计算效率而闻名。"
        },
        "success": true
    },
    {
        "order": 265,
        "title": "Dual Lottery Ticket Hypothesis",
        "html": "https://iclr.cc//virtual/2022/poster/6084",
        "abstract": "Fully exploiting the learning capacity of neural networks requires overparameterized dense networks. On the other side, directly training sparse neural networks typically results in unsatisfactory performance. Lottery Ticket Hypothesis (LTH) provides a novel view to investigate sparse network training and maintain its capacity. Concretely, it claims there exist winning tickets from a randomly initialized network found by iterative magnitude pruning and preserving promising trainability (or we say being in trainable condition). In this work, we regard the winning ticket from LTH as the subnetwork which is in trainable condition and its performance as our benchmark, then go from a complementary direction to articulate the Dual Lottery Ticket Hypothesis (DLTH): Randomly selected subnetworks from a randomly initialized dense network can be transformed into a trainable condition and achieve admirable performance compared with LTH --- random tickets in a given lottery pool can be transformed into winning tickets. Specifically, by using uniform-randomly selected subnetworks to represent the general cases, we propose a simple sparse network training strategy, Random Sparse Network Transformation (RST), to substantiate our DLTH. Concretely, we introduce a regularization term to borrow learning capacity and realize information extrusion from the weights which will be masked. After finishing the transformation for the randomly selected subnetworks, we conduct the regular finetuning to evaluate the model using fair comparisons with LTH and other strong baselines. Extensive experiments on several public datasets and comparisons with competitive approaches validate our DLTH as well as the effectiveness of the proposed model RST. Our work is expected to pave a way for inspiring new research directions of sparse network training in the future. Our code is available at https://github.com/yueb17/DLTH.",
        "conference": "ICLR",
        "中文标题": "双重彩票假设",
        "摘要翻译": "充分利用神经网络的学习能力需要过参数化的密集网络。另一方面，直接训练稀疏神经网络通常会导致性能不尽如人意。彩票假设（LTH）为研究稀疏网络训练并保持其能力提供了新的视角。具体来说，它声称通过迭代幅度剪枝和保留有希望的训练能力（或者说处于可训练状态），可以从随机初始化的网络中找到中奖彩票。在这项工作中，我们将LTH中的中奖彩票视为处于可训练状态的子网络，并将其性能作为我们的基准，然后从一个互补的方向阐述了双重彩票假设（DLTH）：从随机初始化的密集网络中随机选择的子网络可以被转化为可训练状态，并实现与LTH相比令人钦佩的性能——给定彩票池中的随机彩票可以被转化为中奖彩票。具体来说，通过使用均匀随机选择的子网络来代表一般情况，我们提出了一种简单的稀疏网络训练策略，随机稀疏网络转换（RST），以证实我们的DLTH。具体而言，我们引入了一个正则化项来借用学习能力，并从将被掩码的权重中实现信息挤出。在完成对随机选择的子网络的转换后，我们进行常规的微调，以与LTH和其他强基线进行公平比较来评估模型。在几个公共数据集上的大量实验以及与竞争性方法的比较验证了我们的DLTH以及提出的模型RST的有效性。我们的工作预计将为未来激发稀疏网络训练的新研究方向铺平道路。我们的代码可在https://github.com/yueb17/DLTH获取。",
        "领域": "神经网络剪枝",
        "问题": "如何有效地训练稀疏神经网络以保持或提升其性能",
        "动机": "探索稀疏神经网络训练的新方法，以克服直接训练稀疏网络性能不佳的问题",
        "方法": "提出双重彩票假设（DLTH）和随机稀疏网络转换（RST）策略，通过正则化项借用学习能力并实现信息挤出，从而将随机子网络转化为可训练状态",
        "关键词": [
            "双重彩票假设",
            "稀疏神经网络",
            "随机稀疏网络转换"
        ],
        "涉及的技术概念": {
            "彩票假设（LTH）": "一种研究稀疏网络训练的方法，认为通过迭代剪枝可以找到性能优异的子网络",
            "双重彩票假设（DLTH）": "扩展了LTH的概念，认为随机子网络可以通过特定方法转化为高性能网络",
            "随机稀疏网络转换（RST）": "一种训练策略，通过正则化项和信息挤出技术，提升随机子网络的训练性能和效果"
        },
        "success": true
    },
    {
        "order": 266,
        "title": "Dynamics-Aware Comparison of Learned Reward Functions",
        "html": "https://iclr.cc//virtual/2022/poster/7041",
        "abstract": "The ability to learn reward functions plays an important role in enabling the deployment of intelligent agents in the real world. However, $\\textit{comparing}$ reward functions, for example as a means of evaluating reward learning methods, presents a challenge. Reward functions are typically compared by considering the behavior of optimized policies, but this approach conflates deficiencies in the reward function with those of the policy search algorithm used to optimize it. To address this challenge, Gleave et al. (2020) propose the Equivalent-Policy Invariant Comparison (EPIC) distance. EPIC avoids policy optimization, but in doing so requires computing reward values at transitions that may be impossible under the system dynamics. This is problematic for learned reward functions because it entails evaluating them outside of their training distribution, resulting in inaccurate reward values that we show can render EPIC ineffective at comparing rewards. To address this problem, we propose the Dynamics-Aware Reward Distance (DARD), a new reward pseudometric. DARD uses an approximate transition model of the environment to transform reward functions into a form that allows for comparisons that are invariant to reward shaping while only evaluating reward functions on transitions close to their training distribution. Experiments in simulated physical domains demonstrate that DARD enables reliable reward comparisons without policy optimization and is significantly more predictive than baseline methods of downstream policy performance when dealing with learned reward functions.",
        "conference": "ICLR",
        "中文标题": "动态感知的学习奖励函数比较",
        "摘要翻译": "学习奖励函数的能力在实现智能代理在现实世界中的部署方面发挥着重要作用。然而，比较奖励函数，例如作为评估奖励学习手段的一种方法，提出了一个挑战。奖励函数通常通过考虑优化策略的行为来比较，但这种方法将奖励函数的不足与用于优化它的策略搜索算法的不足混为一谈。为了应对这一挑战，Gleave等人（2020）提出了等效策略不变比较（EPIC）距离。EPIC避免了策略优化，但这样做需要计算在系统动态下可能不可能的转换的奖励值。这对于学习的奖励函数来说是有问题的，因为它需要在训练分布之外评估它们，导致不准确的奖励值，我们表明这可以使EPIC在比较奖励时无效。为了解决这个问题，我们提出了动态感知奖励距离（DARD），一种新的奖励伪度量。DARD使用环境的近似转换模型将奖励函数转换为一种形式，允许在仅评估接近其训练分布的转换上的奖励函数时进行对奖励塑形不变的比较。在模拟物理领域的实验表明，DARD能够在不进行策略优化的情况下实现可靠的奖励比较，并且在处理学习的奖励函数时，比基线方法更能预测下游策略性能。",
        "领域": "强化学习、奖励学习、策略优化",
        "问题": "如何在不进行策略优化的情况下，准确比较学习到的奖励函数。",
        "动机": "现有的奖励函数比较方法（如EPIC）在评估学习到的奖励函数时，由于需要在训练分布之外进行评估，导致比较结果不准确。",
        "方法": "提出动态感知奖励距离（DARD），利用环境的近似转换模型，将奖励函数转换为一种形式，使得比较可以在仅评估接近训练分布的转换上的奖励函数时进行，且对奖励塑形不变。",
        "关键词": [
            "奖励学习",
            "动态感知",
            "奖励比较",
            "策略优化",
            "强化学习"
        ],
        "涉及的技术概念": {
            "等效策略不变比较（EPIC）": "一种避免策略优化的奖励函数比较方法，但需要在可能不可能的转换上计算奖励值。",
            "动态感知奖励距离（DARD）": "一种新的奖励伪度量，使用近似转换模型来比较奖励函数，仅在接近训练分布的转换上评估奖励函数。",
            "奖励塑形": "一种修改奖励函数以加速学习过程的技术，DARD的比较方法对此不变。"
        },
        "success": true
    },
    {
        "order": 267,
        "title": "Dynamic Token Normalization improves Vision Transformers",
        "html": "https://iclr.cc//virtual/2022/poster/5898",
        "abstract": "Vision Transformer (ViT) and its variants (e.g., Swin, PVT) have achieved great success in various computer vision tasks, owing to their capability to learn long-range contextual information. Layer Normalization (LN) is an essential ingredient in these models. However, we found that the ordinary LN  makes tokens at different positions similar in magnitude because it normalizes embeddings within each token. It is difficult for Transformers to capture inductive bias such as the positional context in an image with LN. We tackle this problem by proposing a new normalizer, termed Dynamic Token Normalization (DTN), where normalization is performed both within each token (intra-token) and across different tokens (inter-token). DTN has several merits. Firstly, it is built on a unified formulation and thus can represent various existing normalization methods. Secondly, DTN learns to normalize tokens in both intra-token and inter-token manners, enabling Transformers to capture both the global contextual information and the local positional context. Thirdly, by simply replacing LN layers, DTN can be readily plugged into various vision transformers, such as ViT, Swin, and PVT. Extensive experiments show that the transformer equipped with DTN consistently outperforms baseline model with minimal extra parameters and computational overhead. For example, DTN outperforms LN on small ViT by $1.1\\%$ top-1 accuracy on ImageNet.",
        "conference": "ICLR",
        "中文标题": "动态令牌归一化提升视觉变换器性能",
        "摘要翻译": "视觉变换器（ViT）及其变体（如Swin、PVT）因其能够学习长距离上下文信息而在各种计算机视觉任务中取得了巨大成功。层归一化（LN）是这些模型中的一个关键组成部分。然而，我们发现普通的LN会使不同位置的令牌在幅度上变得相似，因为它对每个令牌内的嵌入进行了归一化。这使得变换器难以捕捉如图像中位置上下文等归纳偏差。我们通过提出一种新的归一化器——动态令牌归一化（DTN）来解决这个问题，其中归一化既在每个令牌内部（令牌内）进行，也在不同令牌之间（令牌间）进行。DTN有几个优点。首先，它基于一个统一的公式构建，因此可以表示各种现有的归一化方法。其次，DTN学习以令牌内和令牌间的方式进行归一化，使变换器能够捕捉全局上下文信息和局部位置上下文。第三，通过简单地替换LN层，DTN可以轻松地插入到各种视觉变换器中，如ViT、Swin和PVT。大量实验表明，配备DTN的变换器在额外参数和计算开销最小的情况下，始终优于基线模型。例如，在小型ViT上，DTN在ImageNet上的top-1准确率比LN高出1.1%。",
        "领域": "视觉变换器优化",
        "问题": "普通层归一化（LN）在处理视觉变换器时，难以有效捕捉图像中的位置上下文等归纳偏差。",
        "动机": "改进视觉变换器中的归一化方法，以更好地捕捉图像的全局和局部上下文信息。",
        "方法": "提出动态令牌归一化（DTN），在令牌内和令牌间进行归一化，以增强变换器对图像上下文信息的捕捉能力。",
        "关键词": [
            "动态令牌归一化",
            "视觉变换器",
            "层归一化",
            "上下文信息",
            "图像处理"
        ],
        "涉及的技术概念": {
            "动态令牌归一化（DTN）": "一种新的归一化方法，通过在令牌内和令牌间进行归一化，使变换器能够更好地捕捉图像的全局和局部上下文信息。",
            "层归一化（LN）": "传统的归一化方法，仅对每个令牌内的嵌入进行归一化，难以有效捕捉图像中的位置上下文。",
            "视觉变换器（ViT）": "一种基于变换器架构的模型，用于处理计算机视觉任务，能够学习长距离上下文信息。"
        },
        "success": true
    },
    {
        "order": 268,
        "title": "EE-Net: Exploitation-Exploration Neural Networks in Contextual Bandits",
        "html": "https://iclr.cc//virtual/2022/poster/6185",
        "abstract": "In this paper, we propose a novel neural exploration strategy in contextual bandits, EE-Net, distinct from the standard UCB-based and TS-based approaches. Contextual multi-armed bandits have been studied for decades with various applications. To solve the exploitation-exploration tradeoff in bandits, there are three main techniques: epsilon-greedy, Thompson Sampling (TS), and Upper Confidence Bound (UCB). In recent literature, linear contextual bandits have adopted ridge regression to estimate the reward function and combine it with TS or UCB strategies for exploration. However, this line of works explicitly assumes the reward is based on a linear function of arm vectors, which may not be true in real-world datasets. To overcome this challenge, a series of neural bandit algorithms have been proposed, where a neural network is used to learn the underlying reward function and TS or UCB are adapted for exploration. Instead of calculating a large-deviation based statistical bound for exploration like previous methods,  we propose 'EE-Net', a novel neural-based exploration strategy. In addition to using a neural network (Exploitation network) to learn the reward function, EE-Net uses another neural network (Exploration network) to adaptively learn potential gains compared to the currently estimated reward for exploration. Then, a decision-maker is constructed to combine the outputs from the Exploitation and Exploration networks. We prove that EE-Net can achieve $\\mathcal{O}(\\sqrt{T\\log T})$ regret, which is tighter than existing state-of-the-art neural bandit algorithms. Through extensive experiments on four real-world datasets, we show that EE-Net outperforms existing linear and neural contextual bandit approaches. ",
        "conference": "ICLR",
        "success": true,
        "中文标题": "EE-Net：上下文老虎机中的探索-利用神经网络",
        "摘要翻译": "本文提出了一种新的上下文老虎机中的神经探索策略，EE-Net，它不同于标准的基于UCB和基于TS的方法。上下文多臂老虎机已被研究了几十年，并有各种应用。为了解决老虎机中的利用-探索权衡问题，有三种主要技术：epsilon-greedy、Thompson Sampling（TS）和Upper Confidence Bound（UCB）。在最近的文献中，线性上下文老虎机已经采用岭回归来估计奖励函数，并将其与TS或UCB策略相结合进行探索。然而，这一系列工作明确地假设奖励是基于臂向量的线性函数，这在真实世界的数据集中可能不成立。为了克服这个挑战，已经提出了一系列神经老虎机算法，其中使用神经网络来学习底层奖励函数，并调整TS或UCB用于探索。与先前方法计算基于大偏差的统计界限进行探索不同，我们提出了“EE-Net”，一种新的基于神经的探索策略。除了使用神经网络（利用网络）来学习奖励函数外，EE-Net还使用另一个神经网络（探索网络）来自适应地学习与当前估计的奖励相比的潜在收益，以进行探索。然后，构建决策器以组合来自利用和探索网络的输出。我们证明了EE-Net可以实现$\\\\mathcal{O}(\\\\sqrt{T\\\\log T})$后悔值，这比现有的最先进的神经老虎机算法更紧密。通过在四个真实世界数据集上进行的大量实验，我们表明EE-Net优于现有的线性和神经上下文老虎机方法。",
        "领域": "强化学习、神经网络、上下文老虎机",
        "问题": "如何在上下文老虎机问题中，有效地平衡探索（exploration）和利用（exploitation）之间的权衡，尤其是在奖励函数非线性时。",
        "动机": "现有的线性上下文老虎机算法假设奖励函数是线性的，这在现实世界中可能不成立。而传统的神经老虎机算法在探索时，依赖于计算基于大偏差的统计界限，效率较低。因此，需要一种新的神经探索策略，能够自适应地学习潜在收益，从而更有效地进行探索。",
        "方法": "提出了一种名为EE-Net的新的基于神经的探索策略。该策略使用两个神经网络：一个利用网络（Exploitation network）学习奖励函数，另一个探索网络（Exploration network）自适应地学习与当前估计的奖励相比的潜在收益。然后，使用决策器组合两个网络的输出。",
        "关键词": [
            "上下文老虎机",
            "探索-利用权衡",
            "神经网络",
            "强化学习",
            "EE-Net"
        ],
        "涉及的技术概念": {
            "上下文老虎机": "上下文老虎机是一种强化学习问题，其中智能体根据当前上下文选择一个动作（臂），并接收相应的奖励。目标是最大化累积奖励。",
            "探索-利用权衡": "在强化学习中，探索指的是尝试新的动作以发现潜在的更高奖励，而利用指的是选择当前已知的最佳动作以获得即时奖励。探索-利用权衡需要在两者之间找到平衡。"
        }
    },
    {
        "order": 269,
        "title": "Effective Model Sparsification by Scheduled Grow-and-Prune Methods",
        "html": "https://iclr.cc//virtual/2022/poster/6315",
        "abstract": "Deep neural networks (DNNs) are effective in solving many real-world problems. Larger DNN models usually exhibit better quality (e.g., accuracy) but their excessive computation results in long inference time. Model sparsification can reduce the computation and memory cost while maintaining model quality. Most existing sparsification algorithms unidirectionally remove weights, while others randomly or greedily explore a small subset of weights in each layer for pruning. The limitations of these algorithms reduce the level of achievable sparsity. In addition, many algorithms still require pre-trained dense models and thus suffer from large memory footprint. In this paper, we propose a novel scheduled grow-and-prune (GaP) methodology without having to pre-train a dense model. It addresses the shortcomings of the previous works by repeatedly growing a subset of layers to dense and then pruning them back to sparse after some training. Experiments show that the models pruned using the proposed methods match or beat the quality of the highly optimized dense models at 80% sparsity on a variety of tasks, such as image classification, objective detection, 3D object part segmentation, and translation. They also outperform other state-of-the-art (SOTA) methods for model sparsification. As an example, a 90% non-uniform sparse ResNet-50 model obtained via  GaP achieves 77.9% top-1 accuracy on ImageNet, improving the previous SOTA results by 1.5%. Code available at: https://github.com/boone891214/GaP.",
        "conference": "ICLR",
        "中文标题": "通过预定增长与修剪方法实现有效模型稀疏化",
        "摘要翻译": "深度神经网络（DNNs）在解决许多现实世界的问题上非常有效。更大的DNN模型通常表现出更好的质量（例如，准确率），但它们过度的计算导致了较长的推理时间。模型稀疏化可以在保持模型质量的同时减少计算和内存成本。大多数现有的稀疏化算法单向地移除权重，而其他算法则在每一层随机或贪婪地探索一小部分权重进行修剪。这些算法的局限性降低了可实现的稀疏度水平。此外，许多算法仍然需要预训练的密集模型，因此遭受大内存占用的困扰。在本文中，我们提出了一种新颖的预定增长与修剪（GaP）方法，无需预训练密集模型。它通过反复将一部分层增长为密集然后在一段时间的训练后将它们修剪回稀疏，解决了先前工作的缺点。实验表明，使用所提出的方法修剪的模型在各种任务上，如图像分类、目标检测、3D对象部分分割和翻译，在80%的稀疏度下匹配或超过了高度优化的密集模型的质量。它们也优于其他最先进的（SOTA）模型稀疏化方法。例如，一个通过GaP获得的90%非均匀稀疏ResNet-50模型在ImageNet上达到了77.9%的top-1准确率，比之前的SOTA结果提高了1.5%。代码可在https://github.com/boone891214/GaP获取。",
        "领域": "模型压缩、深度学习优化、神经网络稀疏化",
        "问题": "如何在减少深度神经网络模型的计算和内存成本的同时，保持或提高模型的质量",
        "动机": "解决现有稀疏化算法在实现高稀疏度时的局限性，以及减少对预训练密集模型的依赖",
        "方法": "提出了一种预定增长与修剪（GaP）方法，通过周期性地将部分层增长为密集然后修剪回稀疏，无需预训练密集模型",
        "关键词": [
            "模型稀疏化",
            "增长与修剪方法",
            "深度学习优化",
            "神经网络压缩",
            "高效推理"
        ],
        "涉及的技术概念": {
            "预定增长与修剪（GaP）": "一种无需预训练密集模型的新型稀疏化方法，通过周期性增长和修剪层来实现高效模型压缩",
            "模型稀疏化": "减少神经网络中的权重数量以降低计算和内存成本，同时保持或提高模型性能的技术",
            "非均匀稀疏": "指在不同层或部分网络中应用不同程度的稀疏化，以优化整体模型性能的策略"
        },
        "success": true
    },
    {
        "order": 270,
        "title": "Effect of scale on catastrophic forgetting in neural networks",
        "html": "https://iclr.cc//virtual/2022/poster/6452",
        "abstract": "Catastrophic forgetting presents a challenge in developing deep learning models capable of continual learning, i.e. learning tasks sequentially. Recently, both computer vision and natural-language processing have witnessed great progress through the use of large-scale pretrained models. In this work, we present an empirical study of catastrophic forgetting in this pretraining paradigm.Our experiments indicate that large, pretrained ResNets and Transformers are significantly more resistant to forgetting than randomly-initialized, trained-from-scratch models; this robustness systematically improves with scale of both model and pretraining dataset size.We take initial steps towards characterizing what aspect of model representations allows them to perform continual learning so well, finding that in the pretrained models, distinct class representations grow more orthogonal with scale.  Our results suggest that, when possible, scale and a diverse pretraining dataset can be useful ingredients in mitigating catastrophic forgetting. ",
        "conference": "ICLR",
        "中文标题": "规模对神经网络中灾难性遗忘的影响",
        "摘要翻译": "灾难性遗忘对开发能够持续学习（即顺序学习任务）的深度学习模型提出了挑战。最近，通过使用大规模预训练模型，计算机视觉和自然语言处理领域都取得了巨大进展。在这项工作中，我们对这种预训练范式中的灾难性遗忘进行了实证研究。我们的实验表明，大型预训练的ResNets和Transformers比随机初始化、从头开始训练的模型显著更抗遗忘；这种鲁棒性随着模型规模和预训练数据集大小的增加而系统性提高。我们初步探索了模型表示的哪些方面使它们能够如此出色地进行持续学习，发现在预训练模型中，不同类别的表示随着规模的增加变得更加正交。我们的结果表明，在可能的情况下，规模和多样化的预训练数据集可以作为减轻灾难性遗忘的有用因素。",
        "领域": "持续学习、神经网络鲁棒性、预训练模型",
        "问题": "研究规模如何影响神经网络中的灾难性遗忘问题",
        "动机": "探索大规模预训练模型在减轻灾难性遗忘方面的潜力",
        "方法": "通过实证研究比较大型预训练模型和随机初始化模型在灾难性遗忘方面的表现，并分析模型表示的特性",
        "关键词": [
            "灾难性遗忘",
            "持续学习",
            "预训练模型",
            "模型规模",
            "表示正交性"
        ],
        "涉及的技术概念": {
            "灾难性遗忘": "指神经网络在学习新任务时忘记之前学到的知识，是持续学习中的主要挑战",
            "预训练模型": "在大规模数据集上预先训练的模型，用于提高特定任务的性能和效率",
            "表示正交性": "指不同类别在模型表示空间中的向量彼此正交，有助于减少类别间的干扰，减轻灾难性遗忘"
        },
        "success": true
    },
    {
        "order": 271,
        "title": "Efficient Active Search for Combinatorial Optimization Problems",
        "html": "https://iclr.cc//virtual/2022/poster/6761",
        "abstract": "Recently numerous machine learning based methods for combinatorial optimization problems have been proposed that learn to construct solutions in a sequential decision process via reinforcement learning. While these methods can be easily combined with search strategies like sampling and beam search, it is not straightforward to integrate them into a high-level search procedure offering strong search guidance. Bello et al. (2016) propose active search, which adjusts the weights of a (trained) model with respect to a single instance at test time using reinforcement learning. While active search is simple to implement, it is not competitive with state-of-the-art methods because adjusting all model weights for each test instance is very time and memory intensive. Instead of updating all model weights, we propose and evaluate three efficient active search strategies that only update a subset of parameters during the search. The proposed methods offer a simple way to significantly improve the search performance of a given model and outperform state-of-the-art machine learning based methods on combinatorial problems, even surpassing the well-known heuristic solver LKH3 on the capacitated vehicle routing problem. Finally, we show that (efficient) active search enables learned models to effectively solve instances that are much larger than those seen during training.",
        "conference": "ICLR",
        "中文标题": "组合优化问题的高效主动搜索",
        "摘要翻译": "最近，提出了许多基于机器学习的组合优化问题解决方法，这些方法通过学习在强化学习的序列决策过程中构建解决方案。虽然这些方法可以很容易地与采样和束搜索等搜索策略结合，但将它们整合到一个提供强大搜索指导的高层次搜索过程中并不直接。Bello等人（2016）提出了主动搜索，它使用强化学习在测试时针对单个实例调整（训练过的）模型的权重。虽然主动搜索实现简单，但由于为每个测试实例调整所有模型权重非常耗时和内存密集，因此它与最先进的方法相比并不具有竞争力。我们提出并评估了三种高效的主动搜索策略，这些策略在搜索过程中仅更新参数的一个子集，而不是更新所有模型权重。所提出的方法提供了一种简单的方式来显著提高给定模型的搜索性能，并在组合问题上超越了基于机器学习的最先进方法，甚至在容量车辆路径问题上超过了著名的启发式求解器LKH3。最后，我们展示了（高效）主动搜索使学习模型能够有效解决比训练期间所见实例大得多的问题。",
        "领域": "组合优化、强化学习、启发式搜索",
        "问题": "如何高效地在组合优化问题中应用主动搜索策略，以减少计算资源和时间的消耗。",
        "动机": "现有的主动搜索方法在调整所有模型权重时计算和内存消耗大，限制了其在组合优化问题中的应用效率。",
        "方法": "提出并评估了三种高效的主动搜索策略，这些策略仅更新模型参数的一个子集，以提高搜索效率和性能。",
        "关键词": [
            "组合优化",
            "主动搜索",
            "强化学习",
            "参数子集更新",
            "车辆路径问题"
        ],
        "涉及的技术概念": {
            "主动搜索": "一种在测试时针对单个实例调整模型权重的搜索策略，旨在提高模型在特定实例上的性能。",
            "强化学习": "用于在序列决策过程中学习构建解决方案的机器学习方法，通过奖励信号优化决策策略。",
            "参数子集更新": "在搜索过程中仅更新模型参数的一个子集，以减少计算和内存消耗，提高搜索效率。"
        },
        "success": true
    },
    {
        "order": 272,
        "title": "Efficient and Differentiable Conformal Prediction with General Function Classes",
        "html": "https://iclr.cc//virtual/2022/poster/6067",
        "abstract": "  Quantifying the data uncertainty in learning tasks is often done by learning a prediction interval or prediction set of the label given the input. Two commonly desired properties for learned prediction sets are \\emph{valid coverage} and \\emph{good efficiency} (such as low length or low cardinality). Conformal prediction is a powerful technique for learning prediction sets with valid coverage, yet by default its conformalization step only learns a single parameter, and does not optimize the efficiency over more expressive function classes.  In this paper, we propose a generalization of conformal prediction to multiple learnable parameters, by considering the constrained empirical risk minimization (ERM) problem of finding the most efficient prediction set subject to valid empirical coverage. This meta-algorithm generalizes existing conformal prediction algorithms, and we show that it achieves approximate valid population coverage and near-optimal efficiency within class, whenever the function class in the conformalization step is low-capacity in a certain sense. Next, this ERM problem is challenging to optimize as it involves a non-differentiable coverage constraint. We develop a gradient-based algorithm for it by approximating the original constrained ERM using differentiable surrogate losses and Lagrangians. Experiments show that our algorithm is able to learn valid prediction sets and improve the efficiency significantly over existing approaches in several applications such as prediction intervals with improved length, minimum-volume prediction sets for multi-output regression, and label prediction sets for image classification.",
        "conference": "ICLR",
        "中文标题": "高效且可微的通用函数类共形预测",
        "摘要翻译": "在学习任务中量化数据不确定性通常通过学习给定输入的标签的预测区间或预测集来完成。学习预测集的两个常见期望属性是有效覆盖和良好效率（如低长度或低基数）。共形预测是一种强大的技术，用于学习具有有效覆盖的预测集，但默认情况下，其共形化步骤仅学习单个参数，并不在更具表达性的函数类上优化效率。在本文中，我们提出了一种共形预测的泛化方法，通过考虑约束经验风险最小化（ERM）问题，即在有效经验覆盖的条件下找到最有效的预测集。这种元算法泛化了现有的共形预测算法，并且我们表明，只要共形化步骤中的函数类在某种意义上是低容量的，它就能实现近似有效的总体覆盖和类内接近最优的效率。接下来，这个ERM问题由于涉及不可微的覆盖约束而难以优化。我们通过使用可微替代损失和拉格朗日乘数近似原始约束ERM，开发了一种基于梯度的算法。实验表明，我们的算法能够学习有效的预测集，并在几个应用中显著提高效率，如改进长度的预测区间、多输出回归的最小体积预测集以及图像分类的标签预测集。",
        "领域": "不确定性量化、共形预测、机器学习",
        "问题": "如何在保持有效覆盖的同时，优化预测集的效率",
        "动机": "现有的共形预测方法在优化预测集效率方面存在局限性，尤其是在更具表达性的函数类上。",
        "方法": "提出了一种泛化的共形预测方法，通过约束经验风险最小化（ERM）问题优化预测集效率，并开发了基于梯度的算法来解决非可微覆盖约束问题。",
        "关键词": [
            "共形预测",
            "经验风险最小化",
            "不确定性量化",
            "梯度优化",
            "预测集效率"
        ],
        "涉及的技术概念": {
            "共形预测": "一种用于学习具有有效覆盖的预测集的技术，本文中通过泛化方法优化其效率。",
            "经验风险最小化（ERM）": "本文中用于在有效经验覆盖条件下找到最有效预测集的优化问题。",
            "梯度优化": "本文开发的算法，用于解决ERM问题中的非可微覆盖约束，通过可微替代损失和拉格朗日乘数实现。"
        },
        "success": true
    },
    {
        "order": 273,
        "title": "Efficient Computation of Deep Nonlinear Infinite-Width Neural Networks that Learn Features",
        "html": "https://iclr.cc//virtual/2022/poster/5924",
        "abstract": "While a popular limit of infinite-width neural networks, the Neural Tangent Kernel (NTK) often exhibits performance gaps from finite-width neural networks on standard datasets, due to lack of feature learning. Although the feature learning *maximal update limit*, or *μ-limit* (Yang and Hu, 2020) of wide networks has closed the gap for 1-hidden-layer linear models, no one has been able to demonstrate this for deep nonlinear multi-layer perceptrons (MLP) because of μ-limit’s computational difficulty in this setting.  Here, we solve this problem by proposing a novel feature learning limit, the *π-limit*, that bypasses the computational issues. The π-limit, in short, is the limit of a form of projected gradient descent, and the π-limit of an MLP is roughly another MLP where gradients are appended to weights during training. We prove its almost sure convergence with width using the Tensor Programs technique. We evaluate it on CIFAR10 and Omniglot against NTK as well as finite networks, finding the π-limit outperform finite-width models trained normally (without projection) in both settings, closing the performance gap between finite- and infinite-width neural networks previously left by NTK. Code for this work is available at github.com/santacml/pilim.",
        "conference": "ICLR",
        "中文标题": "高效计算学习特征的深度非线性无限宽度神经网络",
        "摘要翻译": "虽然无限宽度神经网络的一个流行极限——神经切线核（NTK）由于缺乏特征学习，在标准数据集上常常表现出与有限宽度神经网络的性能差距。尽管宽网络的*最大更新极限*或*μ极限*（Yang和Hu，2020）对于1隐藏层线性模型已经缩小了这一差距，但由于μ极限在这种情况下的计算难度，还没有人能够为深度非线性多层感知机（MLP）证明这一点。在这里，我们通过提出一种新颖的特征学习极限——*π极限*，绕过了计算问题，解决了这一问题。简而言之，π极限是一种投影梯度下降的极限，而MLP的π极限大致上是另一个在训练过程中将梯度附加到权重上的MLP。我们使用张量程序技术证明了它在宽度上的几乎必然收敛。我们在CIFAR10和Omniglot上对NTK以及有限网络进行了评估，发现π极限在这两种情况下都优于正常训练（无投影）的有限宽度模型，缩小了之前由NTK留下的有限宽度和无限宽度神经网络之间的性能差距。本工作的代码可在github.com/santacml/pilim获取。",
        "领域": "深度学习理论、神经网络优化、特征学习",
        "问题": "解决无限宽度神经网络在特征学习上的性能差距问题",
        "动机": "缩小有限宽度和无限宽度神经网络在标准数据集上的性能差距",
        "方法": "提出一种新颖的特征学习极限——π极限，通过投影梯度下降的方法实现",
        "关键词": [
            "无限宽度神经网络",
            "特征学习",
            "π极限",
            "投影梯度下降",
            "性能差距"
        ],
        "涉及的技术概念": {
            "神经切线核（NTK）": "用于描述无限宽度神经网络在训练初期行为的理论工具",
            "π极限": "一种新颖的特征学习极限，通过投影梯度下降实现，用于解决无限宽度神经网络的计算和性能问题",
            "张量程序技术": "用于证明π极限在宽度上的几乎必然收敛的技术"
        },
        "success": true
    },
    {
        "order": 274,
        "title": "Efficient Learning of Safe Driving Policy via Human-AI Copilot Optimization",
        "html": "https://iclr.cc//virtual/2022/poster/6470",
        "abstract": "Human intervention is an effective way to inject human knowledge into the training loop of reinforcement learning, which can bring fast learning and ensured training safety. Given the very limited budget of human intervention, it remains challenging to design when and how human expert interacts with the learning agent in the training. In this work, we develop a novel human-in-the-loop learning method called Human-AI Copilot Optimization (HACO).To allow the agent's sufficient exploration in the risky environments while ensuring the training safety, the human expert can take over the control and demonstrate how to avoid probably dangerous situations or trivial behaviors. The proposed HACO then effectively utilizes the data both from the trial-and-error exploration and human's partial demonstration to train a high-performing agent. HACO extracts proxy state-action values from partial human demonstration and optimizes the agent to improve the proxy values meanwhile reduce the human interventions. The experiments show that HACO achieves a substantially high sample efficiency in the safe driving benchmark. HACO can train agents to drive in unseen traffic scenarios with a handful of human intervention budget and achieve high safety and generalizability, outperforming both reinforcement learning and imitation learning baselines with a large margin. Code and demo video are included in the supplementary materials.",
        "conference": "ICLR",
        "中文标题": "通过人机协同优化高效学习安全驾驶策略",
        "摘要翻译": "人类干预是将人类知识注入强化学习训练循环的有效方式，能够带来快速学习并确保训练安全。鉴于人类干预的预算非常有限，设计人类专家何时以及如何与训练中的学习代理互动仍然具有挑战性。在这项工作中，我们开发了一种新颖的人机循环学习方法，称为人机协同优化（HACO）。为了允许代理在风险环境中进行充分探索同时确保训练安全，人类专家可以接管控制权，并展示如何避免可能危险的情况或琐碎行为。提出的HACO方法随后有效地利用了来自试错探索和人类部分演示的数据来训练一个高性能的代理。HACO从部分人类演示中提取代理状态-动作值，并优化代理以提高代理值同时减少人类干预。实验表明，HACO在安全驾驶基准测试中实现了极高的样本效率。HACO能够用少量的人类干预预算训练代理在未见过的交通场景中驾驶，并实现高安全性和泛化能力，大幅优于强化学习和模仿学习的基线。代码和演示视频包含在补充材料中。",
        "领域": "自动驾驶策略学习、强化学习、人机交互",
        "问题": "如何在有限的预算下设计人类专家与学习代理的互动，以实现高效且安全的驾驶策略学习",
        "动机": "通过人类干预将人类知识有效注入强化学习训练循环，以加速学习过程并确保训练安全",
        "方法": "开发了一种名为人机协同优化（HACO）的方法，结合试错探索和人类部分演示数据训练代理，优化代理状态-动作值并减少人类干预",
        "关键词": [
            "人机协同优化",
            "安全驾驶",
            "强化学习",
            "样本效率",
            "泛化能力"
        ],
        "涉及的技术概念": {
            "人机协同优化（HACO）": "一种结合人类干预和强化学习的方法，旨在通过人类专家的部分演示和代理的试错探索来高效学习安全驾驶策略",
            "代理状态-动作值": "从人类演示中提取的值，用于指导代理的学习过程，优化其行为",
            "样本效率": "衡量学习方法在有限样本下学习效果的能力，HACO在实验中展示了高样本效率"
        },
        "success": true
    },
    {
        "order": 275,
        "title": "Efficiently Modeling Long Sequences with Structured State Spaces",
        "html": "https://iclr.cc//virtual/2022/poster/6959",
        "abstract": "A central goal of sequence modeling is designing a single principled model that can address sequence data across a range of modalities and tasks, particularly on long-range dependencies.  Although conventional models including RNNs, CNNs, and Transformers have specialized variants for capturing long dependencies, they still struggle to scale to very long sequences of $10000$ or more steps.  A promising recent approach proposed modeling sequences by simulating the fundamental state space model (SSM) \\( x'(t) = Ax(t) + Bu(t), y(t) = Cx(t) + Du(t) \\), and showed that for appropriate choices of the state matrix \\( A \\), this system could handle long-range dependencies mathematically and empirically.  However, this method has prohibitive computation and memory requirements, rendering it infeasible as a general sequence modeling solution.  We propose the Structured State Space sequence model (S4) based on a new parameterization for the SSM, and show that it can be computed much more efficiently than prior approaches while preserving their theoretical strengths.  Our technique involves conditioning \\( A \\) with a low-rank correction, allowing it to be diagonalized stably and reducing the SSM to the well-studied computation of a Cauchy kernel.  S4 achieves strong empirical results across a diverse range of established benchmarks, including (i) 91\\% accuracy on sequential CIFAR-10 with no data augmentation or auxiliary losses, on par with a larger 2-D ResNet, (ii) substantially closing the gap to Transformers on image and language modeling tasks, while performing generation $60\\times$ faster (iii) SoTA on every task from the Long Range Arena benchmark, including solving the challenging Path-X task of length 16k that all prior work fails on, while being as efficient as all competitors.",
        "conference": "ICLR",
        "中文标题": "高效建模长序列的结构化状态空间",
        "摘要翻译": "序列建模的一个核心目标是设计一个单一的原则性模型，能够处理跨多种模态和任务的序列数据，特别是在长距离依赖上。尽管包括RNNs、CNNs和Transformers在内的传统模型有专门用于捕捉长距离依赖的变体，但它们仍然难以扩展到10000步或更长的序列。最近一个有前景的方法提出通过模拟基本的状态空间模型（SSM）x'(t) = Ax(t) + Bu(t), y(t) = Cx(t) + Du(t)来建模序列，并表明对于适当选择的状态矩阵A，这个系统可以在数学上和经验上处理长距离依赖。然而，这种方法有极高的计算和内存需求，使其无法作为通用的序列建模解决方案。我们提出了基于SSM新参数化的结构化状态空间序列模型（S4），并表明它可以比之前的方法更高效地计算，同时保留其理论优势。我们的技术涉及用低秩修正条件化A，使其能够稳定地对角化，并将SSM简化为广泛研究的Cauchy核计算。S4在多种已建立的基准测试中取得了强劲的经验结果，包括（i）在无数据增强或辅助损失的情况下，在顺序CIFAR-10上达到91%的准确率，与更大的2-D ResNet相当，（ii）在图像和语言建模任务上大幅缩小与Transformers的差距，同时生成速度快60倍，（iii）在Long Range Arena基准测试的每个任务上都达到了SoTA，包括解决了所有先前工作都失败的16k长度的挑战性Path-X任务，同时与所有竞争对手一样高效。",
        "领域": "序列建模",
        "问题": "如何高效地建模和处理非常长的序列数据",
        "动机": "解决现有模型在处理长序列数据时计算和内存需求高的问题",
        "方法": "提出基于新参数化的结构化状态空间序列模型（S4），通过低秩修正条件化状态矩阵A，实现高效计算",
        "关键词": [
            "结构化状态空间",
            "长序列建模",
            "低秩修正",
            "Cauchy核",
            "S4模型"
        ],
        "涉及的技术概念": {
            "结构化状态空间（SSM）": "用于建模序列数据的基本框架，通过状态矩阵A捕捉序列的动态",
            "低秩修正": "用于条件化状态矩阵A的技术，使其能够稳定地对角化，降低计算复杂度",
            "Cauchy核": "简化后的SSM计算形式，基于广泛研究的数学核，提高计算效率"
        },
        "success": true
    },
    {
        "order": 276,
        "title": "Efficient Neural Causal Discovery without Acyclicity Constraints",
        "html": "https://iclr.cc//virtual/2022/poster/6272",
        "abstract": "Learning the structure of a causal graphical model using both observational and interventional data is a fundamental problem in many scientific fields. A promising direction is continuous optimization for score-based methods, which, however, require constrained optimization to enforce acyclicity or lack convergence guarantees. In this paper, we present ENCO, an efficient structure learning method for directed, acyclic causal graphs leveraging observational and interventional data. ENCO formulates the graph search as an optimization of independent edge likelihoods, with the edge orientation being modeled as a separate parameter. Consequently, we provide for ENCO convergence guarantees under mild conditions, without having to constrain the score function with respect to acyclicity. In experiments, we show that ENCO can efficiently recover graphs with hundreds of nodes, an order of magnitude larger than what was previously possible, while handling deterministic variables and discovering latent confounders.",
        "conference": "ICLR",
        "中文标题": "无需无环约束的高效神经因果发现",
        "摘要翻译": "利用观测和干预数据学习因果图模型的结构是许多科学领域中的一个基本问题。一个有前景的方向是基于分数的连续优化方法，然而，这些方法需要约束优化以强制无环性或缺乏收敛保证。在本文中，我们提出了ENCO，一种利用观测和干预数据学习有向无环因果图结构的高效方法。ENCO将图搜索表述为独立边似然的优化，边方向被建模为一个单独的参数。因此，我们在温和条件下为ENCO提供了收敛保证，而无需对分数函数施加无环性约束。在实验中，我们展示了ENCO能够高效地恢复具有数百个节点的图，比之前可能处理的规模大一个数量级，同时处理确定性变量并发现潜在混杂因素。",
        "领域": "因果发现、图模型学习、结构学习",
        "问题": "如何在无需强制无环性约束的情况下，高效地从观测和干预数据中学习因果图模型的结构。",
        "动机": "现有的基于分数的连续优化方法需要约束优化以强制无环性或缺乏收敛保证，限制了其应用范围和效率。",
        "方法": "提出ENCO方法，通过将图搜索表述为独立边似然的优化，并将边方向建模为单独的参数，从而在无需无环性约束的情况下提供收敛保证。",
        "关键词": [
            "因果发现",
            "图模型学习",
            "ENCO",
            "结构学习",
            "优化"
        ],
        "涉及的技术概念": {
            "独立边似然优化": "ENCO方法中将图搜索表述为独立边似然的优化，以提高学习效率和灵活性。",
            "边方向参数化": "将边方向建模为单独的参数，使得模型能够在不强制无环性约束的情况下学习因果图结构。",
            "收敛保证": "在温和条件下为ENCO方法提供收敛保证，确保学习过程的稳定性和可靠性。"
        },
        "success": true
    },
    {
        "order": 277,
        "title": "Efficient Self-supervised Vision Transformers for Representation Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6312",
        "abstract": "This paper investigates two techniques for developing efficient self-supervised vision transformers (EsViT) for visual representation learning. First, we show through a comprehensive empirical study that multi-stage architectures with sparse self-attentions can significantly reduce modeling complexity but with a cost of losing the ability to capture fine-grained correspondences between image regions. Second, we propose a new pre-training task, non-contrastive region-matching, which allows the model to capture fine-grained region dependencies and as a result significantly improves the quality of the learned vision representations. Our results show that combining the two techniques, EsViT achieves 81.3% top-1 on the ImageNet linear probe evaluation, outperforming prior arts with around an order magnitude of higher throughput. When transferring to downstream linear classification tasks, EsViT outperforms its supervised counterpart on 17 out of 18 datasets. The code and pre-trained models are released at: https://github.com/microsoft/esvit",
        "conference": "ICLR",
        "中文标题": "高效自监督视觉变换器用于表示学习",
        "摘要翻译": "本文研究了两种开发高效自监督视觉变换器（EsViT）用于视觉表示学习的技术。首先，我们通过全面的实证研究表明，具有稀疏自注意力的多阶段架构可以显著降低建模复杂度，但代价是失去了捕捉图像区域间细粒度对应关系的能力。其次，我们提出了一种新的预训练任务——非对比区域匹配，这使得模型能够捕捉细粒度的区域依赖性，从而显著提高了学习到的视觉表示的质量。我们的结果表明，结合这两种技术，EsViT在ImageNet线性探针评估中达到了81.3%的top-1准确率，以大约一个数量级的更高吞吐量优于先前的最先进技术。当迁移到下游线性分类任务时，EsViT在18个数据集中的17个上优于其监督对应物。代码和预训练模型发布于：https://github.com/microsoft/esvit",
        "领域": "自监督学习、视觉变换器、图像表示学习",
        "问题": "如何在降低视觉变换器建模复杂度的同时，保持或提高其捕捉图像细粒度区域对应关系的能力。",
        "动机": "探索和开发高效的自监督视觉变换器，以提高视觉表示学习的质量和效率。",
        "方法": "采用多阶段架构与稀疏自注意力降低复杂度，并提出非对比区域匹配预训练任务以增强细粒度区域依赖性的捕捉。",
        "关键词": [
            "自监督学习",
            "视觉变换器",
            "非对比区域匹配",
            "图像表示学习",
            "多阶段架构"
        ],
        "涉及的技术概念": {
            "稀疏自注意力": "用于减少视觉变换器中的计算复杂度，通过限制自注意力机制的应用范围来实现。",
            "非对比区域匹配": "一种新的预训练任务，旨在通过匹配图像中的区域来学习细粒度的视觉表示，而不依赖于对比学习。",
            "多阶段架构": "一种分阶段处理图像的架构设计，用于逐步提取和整合图像特征，以提高模型的效率和性能。"
        },
        "success": true
    },
    {
        "order": 278,
        "title": "Efficient Sharpness-aware Minimization for Improved Training of Neural Networks",
        "html": "https://iclr.cc//virtual/2022/poster/6193",
        "abstract": "Overparametrized Deep Neural Networks (DNNs) often achieve astounding performances, but may potentially result in severe generalization error. Recently, the relation between the sharpness of the loss landscape and the generalization error has been established by Foret et al. (2020), in which the Sharpness Aware Minimizer (SAM) was proposed to mitigate the degradation of the generalization. Unfortunately, SAM’s computational cost is roughly double that of base optimizers, such as Stochastic Gradient Descent (SGD). This paper thus proposes Efficient Sharpness Aware Minimizer (ESAM), which boosts SAM’s efficiency at no cost to its generalization performance. ESAM includes two novel and efficient training strategies—StochasticWeight Perturbation and Sharpness-Sensitive Data Selection. In the former, the sharpness measure is approximated by perturbing a stochastically chosen set of weights in each iteration; in the latter, the SAM loss is optimized using only a judiciously selected subset of data that is sensitive to the sharpness. We provide theoretical explanations as to why these strategies perform well. We also show, via extensive experiments on the CIFAR and ImageNetdatasets, that ESAM enhances the efficiency over SAM from requiring 100% extra computations to 40% vis-`a-vis base optimizers, while test accuracies are preserved or even improved.",
        "conference": "ICLR",
        "中文标题": "高效锐度感知最小化以改进神经网络的训练",
        "摘要翻译": "过参数化的深度神经网络（DNNs）往往能取得惊人的性能，但可能会导致严重的泛化误差。最近，Foret等人（2020）建立了损失景观的锐度与泛化误差之间的关系，并提出了锐度感知最小化器（SAM）来缓解泛化的退化。不幸的是，SAM的计算成本大约是基础优化器（如随机梯度下降（SGD））的两倍。因此，本文提出了高效锐度感知最小化器（ESAM），它在不牺牲其泛化性能的前提下提高了SAM的效率。ESAM包括两种新颖且高效的训练策略——随机权重扰动和锐度敏感数据选择。在前者中，通过每次迭代中扰动随机选择的一组权重来近似锐度度量；在后者中，仅使用对锐度敏感的精心选择的数据子集来优化SAM损失。我们提供了理论解释说明这些策略为何表现良好。我们还通过在CIFAR和ImageNet数据集上的大量实验表明，ESAM将SAM相对于基础优化器的效率从需要100%额外计算提升到40%，同时测试准确率保持不变甚至有所提高。",
        "领域": "深度学习优化、神经网络训练、泛化误差控制",
        "问题": "如何在保持或提高神经网络泛化性能的同时，减少锐度感知最小化器（SAM）的计算成本。",
        "动机": "解决SAM优化器计算成本高的问题，同时不牺牲其提高神经网络泛化性能的能力。",
        "方法": "提出了高效锐度感知最小化器（ESAM），包括随机权重扰动和锐度敏感数据选择两种策略，以减少计算成本并保持或提高泛化性能。",
        "关键词": [
            "锐度感知最小化",
            "神经网络训练",
            "泛化误差",
            "高效优化",
            "随机权重扰动"
        ],
        "涉及的技术概念": {
            "锐度感知最小化（SAM）": "一种优化器，旨在通过最小化损失函数的锐度来改善神经网络的泛化性能。",
            "随机权重扰动": "ESAM中的一种策略，通过随机扰动网络权重来近似损失景观的锐度，减少计算成本。",
            "锐度敏感数据选择": "ESAM中的另一种策略，仅选择对损失景观锐度敏感的数据子集进行优化，以提高训练效率。"
        },
        "success": true
    },
    {
        "order": 279,
        "title": "Efficient Split-Mix Federated Learning for On-Demand and In-Situ Customization",
        "html": "https://iclr.cc//virtual/2022/poster/6081",
        "abstract": "Federated learning (FL) provides a distributed learning framework for multiple participants to collaborate learning without sharing raw data. In many practical FL scenarios, participants have heterogeneous resources due to disparities in hardware and inference dynamics that require quickly loading models of different sizes and levels of robustness. The heterogeneity and dynamics together impose significant challenges to existing FL approaches and thus greatly limit FL's applicability. In this paper, we propose a novel Split-Mix FL strategy for heterogeneous participants that, once training is done, provides in-situ customization of model sizes and robustness. Specifically, we achieve customization by learning a set of base sub-networks of different sizes and robustness levels, which are later aggregated on-demand according to inference requirements. This split-mix strategy achieves customization with high efficiency in communication, storage, and inference. Extensive experiments demonstrate that our method provides better in-situ customization than the existing heterogeneous-architecture FL methods. Codes and pre-trained models are available: https://github.com/illidanlab/SplitMix.",
        "conference": "ICLR",
        "中文标题": "高效的分割混合联邦学习实现按需和现场定制",
        "摘要翻译": "联邦学习（FL）提供了一个分布式学习框架，允许多个参与者在不共享原始数据的情况下协作学习。在许多实际的FL场景中，由于硬件和推理动态的差异，参与者拥有异构资源，这需要快速加载不同大小和鲁棒性级别的模型。这种异构性和动态性共同对现有的FL方法构成了重大挑战，从而极大地限制了FL的适用性。在本文中，我们提出了一种新颖的分割混合FL策略，适用于异构参与者，一旦训练完成，即可提供模型大小和鲁棒性的现场定制。具体来说，我们通过学习一组不同大小和鲁棒性级别的基础子网络来实现定制，这些子网络随后根据推理需求按需聚合。这种分割混合策略在通信、存储和推理方面实现了高效的定制。大量实验证明，我们的方法比现有的异构架构FL方法提供了更好的现场定制。代码和预训练模型可在以下网址获取：https://github.com/illidanlab/SplitMix。",
        "领域": "联邦学习、模型定制、异构计算",
        "问题": "解决联邦学习中由于参与者资源异构性和动态性导致的模型加载和定制难题",
        "动机": "为了扩大联邦学习在资源异构环境下的适用性，提供高效的模型定制方案",
        "方法": "提出分割混合联邦学习策略，通过学习不同大小和鲁棒性的基础子网络，实现按需聚合",
        "关键词": [
            "联邦学习",
            "模型定制",
            "异构计算",
            "分割混合策略",
            "现场定制"
        ],
        "涉及的技术概念": {
            "分割混合策略": "一种通过学习基础子网络并按需聚合来实现模型定制的方法",
            "异构计算": "指参与者因硬件和推理动态差异而拥有不同计算资源的情况",
            "现场定制": "指在训练完成后，根据实际需求快速调整模型大小和鲁棒性的能力"
        },
        "success": true
    },
    {
        "order": 280,
        "title": "Efficient Token Mixing for Transformers via Adaptive Fourier Neural Operators",
        "html": "https://iclr.cc//virtual/2022/poster/6073",
        "abstract": "Vision transformers have delivered tremendous success in representation learning. This is primarily due to effective token mixing through self attention. However, this scales quadratically with the number of pixels, which becomes infeasible for high-resolution inputs. To cope with this challenge, we propose Adaptive Fourier Neural Operator (AFNO) as an efficient token mixer that learns to mix in the Fourier domain. AFNO is based on a principled foundation of operator learning which allows us to frame token mixing as a continuous global convolution without any dependence on the input resolution. This principle was previously used to design FNO, which solves global convolution efficiently in the Fourier domain and has shown promise in learning challenging PDEs. To handle challenges in visual representation learning such as discontinuities in images and high resolution inputs, we propose principled architectural modifications to FNO which results in memory and computational efficiency. This includes imposing a block-diagonal structure on the channel mixing weights, adaptively sharing weights across tokens, and sparsifying the frequency modes via soft-thresholding and shrinkage. The resulting model is highly parallel with a quasi-linear complexity and has linear memory in the sequence size. AFNO outperforms self-attention mechanisms for few-shot segmentation in terms of both efficiency and accuracy. For Cityscapes segmentation with the Segformer-B3 backbone, AFNO can handle a sequence size of 65k and outperforms other efficient self-attention mechanisms.",
        "conference": "ICLR",
        "中文标题": "通过自适应傅里叶神经算子实现Transformer的高效令牌混合",
        "摘要翻译": "视觉Transformer在表示学习方面取得了巨大成功。这主要归功于通过自注意力机制实现的有效的令牌混合。然而，这种方法的计算复杂度与像素数量的平方成正比，对于高分辨率输入变得不可行。为了应对这一挑战，我们提出了自适应傅里叶神经算子（AFNO）作为一种高效的令牌混合器，它学习在傅里叶域中进行混合。AFNO基于算子学习的理论基础，使我们能够将令牌混合视为一个连续的全局卷积，而不依赖于输入分辨率。这一原理之前被用于设计FNO，FNO在傅里叶域中高效地解决了全局卷积问题，并在学习具有挑战性的偏微分方程方面显示出了潜力。为了处理视觉表示学习中的挑战，如图像中的不连续性和高分辨率输入，我们提出了对FNO的原则性架构修改，从而实现了内存和计算效率。这包括在通道混合权重上施加块对角结构，自适应地跨令牌共享权重，以及通过软阈值和收缩稀疏化频率模式。所得到的模型具有高度并行性，具有准线性复杂度，并且在序列大小上具有线性内存。在少样本分割方面，AFNO在效率和准确性上都优于自注意力机制。对于使用Segformer-B3骨干的Cityscapes分割，AFNO可以处理65k的序列大小，并且优于其他高效的自注意力机制。",
        "领域": "视觉Transformer优化、图像分割、高效深度学习模型",
        "问题": "解决视觉Transformer在处理高分辨率输入时计算复杂度高的问题",
        "动机": "提高视觉Transformer在处理高分辨率图像时的效率和准确性",
        "方法": "提出自适应傅里叶神经算子（AFNO），在傅里叶域中实现高效的令牌混合，通过架构修改提高内存和计算效率",
        "关键词": [
            "自适应傅里叶神经算子",
            "令牌混合",
            "高效Transformer",
            "图像分割",
            "傅里叶域学习"
        ],
        "涉及的技术概念": {
            "自适应傅里叶神经算子（AFNO）": "一种高效的令牌混合器，学习在傅里叶域中进行混合，不依赖于输入分辨率",
            "块对角结构": "在通道混合权重上施加的结构，以提高内存和计算效率",
            "软阈值和收缩": "用于稀疏化频率模式的技术，以减少计算复杂度"
        },
        "success": true
    },
    {
        "order": 281,
        "title": "Eigencurve: Optimal Learning Rate Schedule for SGD on Quadratic Objectives with Skewed Hessian Spectrums",
        "html": "https://iclr.cc//virtual/2022/poster/6626",
        "abstract": "Learning rate schedulers have been widely adopted in training deep neural networks. Despite their practical importance, there is a discrepancy between its practice and its theoretical analysis. For instance, it is not known what schedules of SGD achieve best convergence, even for simple problems such as optimizing quadratic objectives. In this paper, we propose Eigencurve, the first family of learning rate schedules that can achieve minimax optimal convergence rates (up to a constant) for SGD on quadratic objectives when the eigenvalue distribution of the underlying Hessian matrix is skewed. The condition is quite common in practice. Experimental results show that Eigencurve can significantly outperform step decay in image classification tasks on CIFAR-10, especially when the number of epochs is small. Moreover, the theory inspires two simple learning rate schedulers for practical applications that can approximate eigencurve. For some problems, the optimal shape of the proposed schedulers resembles that of cosine decay, which sheds light to the success of cosine decay for such situations. For other situations, the proposed schedulers are superior to cosine decay.",
        "conference": "ICLR",
        "中文标题": "Eigencurve：针对具有偏斜Hessian谱的二次目标函数的SGD最优学习率调度",
        "摘要翻译": "学习率调度器在深度神经网络的训练中已被广泛采用。尽管其实践重要性显著，但其实践与理论分析之间存在差异。例如，即使对于优化二次目标函数这样的简单问题，也不清楚哪种SGD调度能达到最佳收敛。在本文中，我们提出了Eigencurve，这是第一个能够在基础Hessian矩阵的特征值分布偏斜时，为二次目标函数的SGD实现极小极大最优收敛率（达到一个常数）的学习率调度家族。这一条件在实践中相当常见。实验结果表明，在CIFAR-10的图像分类任务中，Eigencurve能显著优于步进衰减，尤其是在训练周期较少时。此外，该理论启发了两款简单实用的学习率调度器，可用于近似eigencurve。对于某些问题，所提出调度器的最优形状类似于余弦衰减，这为余弦衰减在此类情况下的成功提供了启示。对于其他情况，所提出的调度器优于余弦衰减。",
        "领域": "深度学习优化、图像分类、学习率调度",
        "问题": "在Hessian矩阵特征值分布偏斜的情况下，如何为SGD设计最优学习率调度以实现最佳收敛。",
        "动机": "解决当前学习率调度实践与理论分析之间的差异，特别是在优化二次目标函数时，缺乏明确的最优SGD调度方案的问题。",
        "方法": "提出Eigencurve，一种新的学习率调度家族，能够在Hessian矩阵特征值分布偏斜时，为二次目标函数的SGD实现极小极大最优收敛率。",
        "关键词": [
            "Eigencurve",
            "学习率调度",
            "SGD优化",
            "Hessian谱",
            "图像分类"
        ],
        "涉及的技术概念": {
            "Eigencurve": "一种学习率调度家族，针对具有偏斜Hessian谱的二次目标函数，能够实现SGD的极小极大最优收敛率。",
            "Hessian矩阵": "在优化问题中，表示目标函数的二阶导数矩阵，其特征值分布影响优化算法的性能。",
            "极小极大最优收敛率": "在最坏情况下达到的最佳可能收敛速率，Eigencurve能够为特定条件下的SGD实现这一速率。"
        },
        "success": true
    },
    {
        "order": 282,
        "title": "EigenGame Unloaded: When playing games is better than optimizing",
        "html": "https://iclr.cc//virtual/2022/poster/7159",
        "abstract": "We build on the recently proposed EigenGame that views eigendecomposition as a competitive game. EigenGame's updates are biased if computed using minibatches of data, which hinders convergence and more sophisticated parallelism in the stochastic setting. In this work, we propose an unbiased stochastic update that is asymptotically equivalent to EigenGame, enjoys greater parallelism allowing computation on datasets of larger sample sizes, and outperforms EigenGame in experiments. We present applications to finding the principal components of massive datasets and performing spectral clustering of graphs. We analyze and discuss our proposed update in the context of EigenGame and the shift in perspective from optimization to games.",
        "conference": "ICLR",
        "中文标题": "卸载特征游戏：玩游戏比优化更优",
        "摘要翻译": "我们基于最近提出的将特征分解视为竞争游戏的EigenGame进行构建。如果使用数据的小批量计算，EigenGame的更新会有偏差，这阻碍了在随机设置中的收敛和更复杂的并行性。在这项工作中，我们提出了一种无偏的随机更新方法，该方法在渐进意义上等同于EigenGame，享有更大的并行性，允许在更大样本量的数据集上进行计算，并且在实验中表现优于EigenGame。我们展示了在寻找大规模数据集的主成分和进行图的谱聚类中的应用。我们在EigenGame的背景下分析并讨论了我们提出的更新方法，以及从优化到游戏的视角转变。",
        "领域": "特征分解、主成分分析、谱聚类",
        "问题": "解决EigenGame在使用小批量数据计算时更新偏差的问题，提高收敛性和并行性",
        "动机": "改进EigenGame的随机更新方法，使其在保持无偏的同时，提高并行处理能力和计算效率",
        "方法": "提出一种无偏的随机更新方法，该方法在渐进意义上等同于EigenGame，并允许在更大规模的数据集上进行高效计算",
        "关键词": [
            "特征分解",
            "主成分分析",
            "谱聚类",
            "随机更新",
            "并行计算"
        ],
        "涉及的技术概念": {
            "EigenGame": "将特征分解视为竞争游戏的方法，用于求解主成分分析问题",
            "无偏随机更新": "提出的新方法，解决了小批量数据计算中的偏差问题，提高了收敛性和并行性",
            "谱聚类": "一种基于图的谱理论的聚类方法，利用特征分解来识别数据中的群组结构"
        },
        "success": true
    },
    {
        "order": 283,
        "title": "Einops: Clear and Reliable Tensor Manipulations with Einstein-like Notation",
        "html": "https://iclr.cc//virtual/2022/poster/6602",
        "abstract": "Tensor computations underlie modern scientific computing and deep learning.A number of tensor frameworks emerged varying in execution model, hardware support, memory management, model definition, etc.However, tensor operations in all frameworks follow the same paradigm.Recent neural network architectures demonstrate demand for higher expressiveness of tensor operations.The current paradigm is not suited to write readable, reliable, or easy-to-modify code for multidimensional tensor manipulations. Moreover, some commonly used operations do not provide sufficient checks and can break a tensor structure.These mistakes are elusive as no tools or tests can detect them.Independently, API discrepancies complicate code transfer between frameworks.We propose einops notation: a uniform and generic way to manipulate tensor structure, that significantly improves code readability and flexibility by focusing on the structure of input and output tensors.We implement einops notation in a Python package that efficiently supports multiple widely used frameworks and provides framework-independent minimalist API for tensor manipulations.",
        "conference": "ICLR",
        "中文标题": "Einops：使用类爱因斯坦符号进行清晰可靠的张量操作",
        "摘要翻译": "张量计算是现代科学计算和深度学习的基础。多个张量框架在执行模型、硬件支持、内存管理、模型定义等方面各不相同。然而，所有框架中的张量操作都遵循相同的范式。最近的神经网络架构展示了对张量操作更高表达力的需求。当前的范式不适合编写可读、可靠或易于修改的多维张量操作代码。此外，一些常用操作没有提供足够的检查，可能会破坏张量结构。这些错误难以捉摸，因为没有工具或测试可以检测到它们。独立地，API差异使得框架间的代码转移变得复杂。我们提出了einops符号：一种统一且通用的方式来操作张量结构，通过专注于输入和输出张量的结构，显著提高了代码的可读性和灵活性。我们在一个Python包中实现了einops符号，该包高效支持多个广泛使用的框架，并提供了框架无关的张量操作最小化API。",
        "领域": "深度学习框架优化、张量计算、神经网络架构设计",
        "问题": "当前张量操作范式在代码可读性、可靠性和灵活性方面的不足，以及框架间API差异导致的代码转移困难。",
        "动机": "提高张量操作的表达力，改善代码的可读性和灵活性，简化框架间的代码转移。",
        "方法": "提出并实现einops符号，一种统一且通用的张量操作方式，专注于输入和输出张量的结构。",
        "关键词": [
            "张量操作",
            "代码可读性",
            "框架无关API",
            "Einops符号",
            "深度学习框架"
        ],
        "涉及的技术概念": {
            "Einops符号": "一种统一且通用的张量操作方式，通过专注于输入和输出张量的结构，提高代码的可读性和灵活性。",
            "框架无关API": "提供了一种最小化的API，使得张量操作可以在不同的深度学习框架之间无缝转移。",
            "张量结构检查": "在张量操作中引入结构检查，避免破坏张量结构的错误操作。"
        },
        "success": true
    },
    {
        "order": 284,
        "title": "Eliminating Sharp Minima from SGD with Truncated Heavy-tailed Noise",
        "html": "https://iclr.cc//virtual/2022/poster/6392",
        "abstract": "The empirical success of deep learning is often attributed to SGD’s mysterious ability to avoid sharp local minima in the loss landscape, as sharp minima are  known to lead to poor generalization. Recently, empirical evidence of heavy-tailed gradient noise was reported in many deep learning tasks; and it was shown in (Simsekli et al., 2019a;b) that SGD can escape sharp local minima under the presence of such heavy-tailed gradient noise, providing a partial solution to the mystery. In this work, we analyze a popular variant of SGD where gradients are truncated above a fixed threshold. We show that it achieves a stronger notion of avoiding sharp minima: it can effectively eliminate sharp local minima entirely from its training trajectory. We characterize the dynamics of truncated SGD driven by heavy-tailed noises. First, we show that the truncation threshold and width of the attraction field dictate the order of the first exit time from the associated local minimum. Moreover, when the objective function satisfies appropriate structural conditions, we prove that as the learning rate decreases, the dynamics of the heavy-tailed truncated SGD closely resemble those of a continuous-time Markov chain that never visits any sharp minima. Real data experiments on deep learning confirm our theoretical prediction that heavy-tailed SGD with gradient clipping finds a flatter local minima and achieves better generalization.",
        "conference": "ICLR",
        "中文标题": "通过截断重尾噪声从SGD中消除尖锐最小值",
        "摘要翻译": "深度学习的经验成功常归因于SGD神秘地避免了损失景观中的尖锐局部最小值，因为已知尖锐最小值会导致泛化能力差。最近，在许多深度学习任务中报告了重尾梯度噪声的经验证据；并且在(Simsekli等人，2019a;b)中显示，在这种重尾梯度噪声存在下，SGD可以逃离尖锐局部最小值，为这一谜题提供了部分解答。在这项工作中，我们分析了一个流行的SGD变体，其中梯度被截断在一个固定阈值之上。我们表明，它实现了一个更强的避免尖锐最小值的概念：它可以有效地从其训练轨迹中完全消除尖锐局部最小值。我们描述了由重尾噪声驱动的截断SGD的动态。首先，我们表明截断阈值和吸引场的宽度决定了从相关局部最小值首次退出时间的顺序。此外，当目标函数满足适当的结构条件时，我们证明随着学习率的降低，重尾截断SGD的动态非常类似于一个从不访问任何尖锐最小值的连续时间马尔可夫链。深度学习的真实数据实验证实了我们的理论预测，即带有梯度裁剪的重尾SGD找到了更平坦的局部最小值并实现了更好的泛化。",
        "领域": "优化算法",
        "问题": "SGD在避免尖锐局部最小值方面的机制不明确",
        "动机": "探索SGD如何通过重尾噪声和梯度截断技术避免尖锐局部最小值，以提高模型的泛化能力",
        "方法": "分析梯度截断的SGD变体，研究其在重尾噪声下的动态行为，并通过理论证明和实验验证其效果",
        "关键词": [
            "梯度截断",
            "重尾噪声",
            "尖锐最小值",
            "泛化能力",
            "SGD"
        ],
        "涉及的技术概念": {
            "梯度截断": "在SGD中设置一个固定阈值，超过该阈值的梯度将被截断，以防止梯度爆炸和帮助逃离尖锐最小值",
            "重尾噪声": "指梯度噪声的分布具有重尾特性，这种噪声有助于SGD逃离尖锐局部最小值",
            "连续时间马尔可夫链": "用于描述重尾截断SGD动态的数学模型，证明其在适当条件下不会访问尖锐最小值"
        },
        "success": true
    },
    {
        "order": 285,
        "title": "Embedded-model flows: Combining the inductive biases of model-free deep learning and explicit probabilistic modeling",
        "html": "https://iclr.cc//virtual/2022/poster/6910",
        "abstract": "Normalizing flows have shown great success as general-purpose density estimators. However, many real world applications require the use of domain-specific knowledge, which normalizing flows cannot readily incorporate. We propose embedded-model flows (EMF), which alternate general-purpose transformations with structured layers that embed domain-specific inductive biases. These layers are automatically constructed by converting user-specified differentiable probabilistic models into equivalent bijective transformations. We also introduce gated structured layers, which allow bypassing the parts of the models that fail to capture the statistics of the data. We demonstrate that EMFs can be used to induce desirable properties such as multimodality and continuity. Furthermore, we show that EMFs enable a high performance form of variational inference where the structure of the prior model is embedded in the variational architecture. In our experiments, we show that this approach outperforms a large number of alternative methods in common structured inference problems.",
        "conference": "ICLR",
        "中文标题": "嵌入式模型流：结合无模型深度学习的归纳偏置与显式概率建模",
        "摘要翻译": "归一化流作为一种通用密度估计器已显示出巨大成功。然而，许多现实世界的应用需要使用领域特定知识，这是归一化流无法轻易融入的。我们提出了嵌入式模型流（EMF），它在通用变换与嵌入领域特定归纳偏置的结构化层之间交替。这些层通过将用户指定的可微分概率模型转换为等效的双射变换自动构建。我们还引入了门控结构化层，允许绕过那些未能捕捉数据统计特性的模型部分。我们证明了EMF可用于诱导诸如多模态和连续性等理想属性。此外，我们展示了EMF能够实现一种高性能的变分推理形式，其中先验模型的结构被嵌入到变分架构中。在我们的实验中，我们表明这种方法在常见的结构化推理问题中优于大量替代方法。",
        "领域": "概率建模与深度学习结合、变分推理、密度估计",
        "问题": "如何在密度估计中有效融入领域特定知识，以提升模型的性能和适应性",
        "动机": "解决归一化流在融入领域特定知识方面的局限性，通过结合深度学习的灵活性和概率建模的结构化优势，提升模型在复杂数据上的表现",
        "方法": "提出嵌入式模型流（EMF），通过交替使用通用变换和结构化层来嵌入领域知识，并引入门控机制以灵活处理数据统计特性",
        "关键词": [
            "嵌入式模型流",
            "归一化流",
            "变分推理",
            "密度估计",
            "领域特定知识"
        ],
        "涉及的技术概念": {
            "嵌入式模型流（EMF）": "一种结合通用变换和结构化层的密度估计方法，旨在融入领域特定知识",
            "门控结构化层": "允许模型绕过不适用于当前数据统计特性的部分，增加模型的灵活性",
            "变分推理": "一种利用EMF嵌入先验模型结构的高性能推理方法，用于解决结构化推理问题"
        },
        "success": true
    },
    {
        "order": 286,
        "title": "Emergent Communication at Scale",
        "html": "https://iclr.cc//virtual/2022/poster/6459",
        "abstract": "Emergent communication aims for a better understanding of human language evolution and building more efficient representations. We posit that reaching these goals will require scaling up, in contrast to a significant amount of literature that focuses on setting up small-scale problems to tease out desired properties of the emergent languages. We focus on three independent aspects to scale up, namely the dataset, task complexity, and population size. We provide a first set of results for large populations solving complex tasks on realistic large-scale datasets, as well as an easy-to-use codebase to enable further experimentation. In more complex tasks and datasets, we find that RL training can become unstable, but responds well to established stabilization techniques.We also identify the need for a different metric than topographic similarity, which does not correlate with the generalization performances when working with natural images. In this context, we probe ease-of-learnability and transfer methods to assess emergent languages. Finally, we observe that larger populations do not induce robust emergent protocols with high generalization performance, leading us to explore different ways to leverage population, through voting and imitation learning. ",
        "conference": "ICLR",
        "中文标题": "规模化的涌现通信",
        "摘要翻译": "涌现通信旨在更好地理解人类语言的演化并构建更高效的表示。我们认为，实现这些目标需要扩大规模，这与大量文献专注于设置小规模问题以引出涌现语言的期望特性形成对比。我们关注于三个独立的方面来进行规模化，即数据集、任务复杂度和群体规模。我们为大规模群体在现实世界的大规模数据集上解决复杂任务提供了第一组结果，以及一个易于使用的代码库以支持进一步的实验。在更复杂的任务和数据集中，我们发现强化学习训练可能变得不稳定，但对已建立的稳定技术反应良好。我们还发现需要一种不同于地形相似性的度量标准，因为在使用自然图像时，地形相似性与泛化性能不相关。在此背景下，我们探讨了易学性和迁移方法来评估涌现语言。最后，我们观察到更大的群体不会诱导出具有高泛化性能的稳健涌现协议，这引导我们探索通过投票和模仿学习来利用群体的不同方式。",
        "领域": "自然语言处理与视觉结合、强化学习、多智能体系统",
        "问题": "如何在扩大数据集、任务复杂度和群体规模的情况下，实现涌现通信的高效表示和稳定性。",
        "动机": "探索在更大规模和更复杂环境下涌现通信的潜力，以更深入地理解人类语言演化和构建更高效的通信表示。",
        "方法": "通过扩大数据集、任务复杂度和群体规模三个独立方面进行规模化研究，并应用强化学习稳定技术和新的评估方法。",
        "关键词": [
            "涌现通信",
            "强化学习",
            "多智能体系统",
            "规模化研究",
            "泛化性能"
        ],
        "涉及的技术概念": {
            "涌现通信": "研究在特定条件下，通信系统如何从简单的交互中自发地演化出复杂的结构和功能。",
            "强化学习稳定技术": "应用于强化学习中以解决训练过程中的不稳定性问题，确保模型能够有效学习。",
            "地形相似性": "一种用于评估涌现语言特性的度量标准，但在处理自然图像时与泛化性能不相关。"
        },
        "success": true
    },
    {
        "order": 287,
        "title": "Enabling Arbitrary Translation Objectives with Adaptive Tree Search",
        "html": "https://iclr.cc//virtual/2022/poster/7206",
        "abstract": "We introduce an adaptive tree search algorithm, which is a deterministic variant of Monte Carlo tree search, that can find high-scoring outputs under translation models that make no assumptions about the form or structure of the search objective. This algorithm enables the exploration of new kinds of models that are unencumbered by constraints imposed to make decoding tractable, such as autoregressivity or conditional independence assumptions. When applied to autoregressive models, our algorithm has different biases than beam search has, which enables a new analysis of the role of decoding bias in autoregressive models. Empirically, we show that our adaptive tree search algorithm finds outputs with substantially better model scores compared to beam search in autoregressive models, and compared to reranking techniques in models whose scores do not decompose additively with respect to the words in the output. We also characterise the correlation of several translation model objectives with respect to BLEU. We find that while some standard models are poorly calibrated and benefit from the beam search bias, other often more robust models (autoregressive models tuned to maximize expected automatic metric scores, the noisy channel model and a newly proposed objective) benefit from increasing amounts of search using our proposed decoder, whereas the beam search bias limits the improvements obtained from such objectives. Thus, we argue that as models improve, the improvements may be masked by over-reliance on beam search or reranking based methods.",
        "conference": "ICLR",
        "中文标题": "实现任意翻译目标的自适应树搜索",
        "摘要翻译": "我们介绍了一种自适应树搜索算法，这是蒙特卡洛树搜索的一种确定性变体，能够在不对搜索目标的形式或结构做出任何假设的翻译模型下找到高分输出。该算法能够探索不受自回归性或条件独立性假设等解码可处理性约束的新型模型。当应用于自回归模型时，我们的算法与束搜索具有不同的偏差，这使得我们能够对自回归模型中解码偏差的作用进行新的分析。实证上，我们展示了我们的自适应树搜索算法在自回归模型中找到了比束搜索模型分数显著更好的输出，并且在分数不随输出中单词加性分解的模型中，与重排序技术相比也表现更佳。我们还描述了几种翻译模型目标与BLEU的相关性。我们发现，虽然一些标准模型校准不佳并受益于束搜索偏差，但其他通常更稳健的模型（如调整以最大化预期自动度量分数的自回归模型、噪声通道模型和新提出的目标）则受益于使用我们提出的解码器进行更多搜索，而束搜索偏差限制了从这些目标中获得的改进。因此，我们认为随着模型的改进，这些改进可能被过度依赖束搜索或基于重排序的方法所掩盖。",
        "领域": "机器翻译、自然语言处理、解码算法",
        "问题": "如何在不对搜索目标的形式或结构做出任何假设的情况下，找到高分输出",
        "动机": "探索不受传统解码约束的新型翻译模型，分析解码偏差在自回归模型中的作用",
        "方法": "提出一种自适应树搜索算法，作为蒙特卡洛树搜索的确定性变体，用于在广泛的翻译模型中找到高分输出",
        "关键词": [
            "自适应树搜索",
            "机器翻译",
            "解码算法",
            "自回归模型",
            "BLEU"
        ],
        "涉及的技术概念": {
            "自适应树搜索算法": "一种确定性变体的蒙特卡洛树搜索，用于在不对搜索目标的形式或结构做出假设的翻译模型下找到高分输出",
            "自回归模型": "一种模型，其当前步骤的输出依赖于之前步骤的输出，常用于序列生成任务",
            "BLEU": "双语评估替补，一种用于评估机器翻译质量的自动度量标准"
        },
        "success": true
    },
    {
        "order": 288,
        "title": "Encoding Weights of Irregular Sparsity for Fixed-to-Fixed Model Compression",
        "html": "https://iclr.cc//virtual/2022/poster/6553",
        "abstract": "Even though fine-grained pruning techniques achieve a high compression ratio, conventional sparsity representations (such as CSR) associated with irregular sparsity degrade parallelism significantly. Practical pruning methods, thus, usually lower pruning rates (by structured pruning) to improve parallelism. In this paper, we study fixed-to-fixed (lossless) encoding architecture/algorithm to support fine-grained pruning methods such that sparse neural networks can be stored in a highly regular structure. We first estimate the maximum compression ratio of encoding-based compression using entropy. Then, as an effort to push the compression ratio to the theoretical maximum (by entropy), we propose a sequential fixed-to-fixed encoding scheme. We demonstrate that our proposed compression scheme achieves almost the maximum compression ratio for the Transformer and ResNet-50 pruned by various fine-grained pruning methods.",
        "conference": "ICLR",
        "中文标题": "编码不规则稀疏权重以实现固定到固定的模型压缩",
        "摘要翻译": "尽管细粒度剪枝技术实现了高压缩比，但与不规则稀疏性相关的传统稀疏表示（如CSR）显著降低了并行性。因此，实用的剪枝方法通常通过结构化剪枝降低剪枝率以提高并行性。在本文中，我们研究了固定到固定（无损）编码架构/算法以支持细粒度剪枝方法，使得稀疏神经网络可以存储在高度规则的结构中。我们首先使用熵估计基于编码的压缩的最大压缩比。然后，为了将压缩比推向理论最大值（通过熵），我们提出了一种顺序固定到固定编码方案。我们证明了我们提出的压缩方案对于通过各种细粒度剪枝方法剪枝的Transformer和ResNet-50几乎达到了最大压缩比。",
        "领域": "模型压缩、神经网络优化、并行计算",
        "问题": "解决不规则稀疏性导致的并行性下降问题，同时保持高压缩比",
        "动机": "提高稀疏神经网络存储和计算的效率，同时保持或提高模型的压缩比",
        "方法": "提出一种顺序固定到固定编码方案，以支持细粒度剪枝方法，实现高规则结构的稀疏神经网络存储",
        "关键词": [
            "模型压缩",
            "细粒度剪枝",
            "固定到固定编码",
            "稀疏神经网络",
            "并行计算"
        ],
        "涉及的技术概念": {
            "细粒度剪枝": "一种剪枝技术，旨在移除神经网络中对模型性能影响较小的权重，以实现模型压缩",
            "固定到固定编码": "一种编码方案，旨在将稀疏神经网络存储在高度规则的结构中，以提高存储和计算的效率",
            "熵估计": "用于估计基于编码的压缩的最大压缩比，为压缩方案的设计提供理论依据"
        },
        "success": true
    },
    {
        "order": 289,
        "title": "End-to-End Learning of Probabilistic Hierarchies on Graphs",
        "html": "https://iclr.cc//virtual/2022/poster/5940",
        "abstract": "We propose a novel probabilistic model over hierarchies on graphs obtained by continuous relaxation of tree-based hierarchies. We draw connections to Markov chain theory, enabling us to perform hierarchical clustering by efficient end-to-end optimization of relaxed versions of quality metrics such as Dasgupta cost or Tree-Sampling Divergence (TSD). We show that our model learns rich, high-quality hierarchies present in 11 real world graphs, including a large  graph with 2.3M nodes. Our model consistently outperforms recent as well as strong traditional baselines such as average linkage. Our model also obtains strong results on link prediction despite not being trained on this task, highlighting the quality of the hierarchies discovered by our model.",
        "conference": "ICLR",
        "中文标题": "图的概率层次结构的端到端学习",
        "摘要翻译": "我们提出了一种新颖的概率模型，用于图的层次结构，该模型通过基于树的层次结构的连续松弛获得。我们建立了与马尔可夫链理论的联系，使我们能够通过高效端到端优化质量指标的松弛版本（如Dasgupta成本或树采样分歧（TSD））来执行层次聚类。我们展示了我们的模型在11个真实世界图中学习到了丰富、高质量的层次结构，包括一个拥有230万个节点的大型图。我们的模型在性能上持续优于最近的以及强大的传统基线方法，如平均链接。尽管没有针对链接预测任务进行训练，我们的模型在该任务上也取得了强劲的结果，这凸显了我们模型发现的层次结构的高质量。",
        "领域": "图神经网络、层次聚类、链接预测",
        "问题": "如何在图上高效学习高质量的层次结构",
        "动机": "探索一种能够自动发现图中层次结构的方法，以提高层次聚类和链接预测的性能",
        "方法": "通过连续松弛树基层次结构，结合马尔可夫链理论，端到端优化质量指标",
        "关键词": [
            "概率模型",
            "层次聚类",
            "端到端学习",
            "图神经网络",
            "链接预测"
        ],
        "涉及的技术概念": {
            "连续松弛": "将离散的树基层次结构转换为连续空间，便于优化",
            "马尔可夫链理论": "用于建立层次结构与概率模型之间的联系，支持高效优化",
            "Dasgupta成本": "一种衡量层次聚类质量的指标，本模型中通过松弛版本进行优化"
        },
        "success": true
    },
    {
        "order": 290,
        "title": "Energy-Based Learning for Cooperative Games, with Applications to Valuation Problems in Machine Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6807",
        "abstract": "Valuation problems, such as feature interpretation, data valuation and model valuation for ensembles, become increasingly more important in many machine learning applications. Such problems are commonly solved by well-known game-theoretic criteria, such as Shapley value or Banzhaf value. In this work, we present a novel energy-based treatment for cooperative games, with a theoretical justification by the maximum entropy framework. Surprisingly, by conducting variational inference of the energy-based model, we recover various game-theoretic valuation criteria through conducting one-step fixed point iteration  for maximizing the mean-field ELBO objective. This observation also verifies the rationality of existing criteria, as they are all attempting to  decouple the  correlations  among  the  players  through the  mean-field approach. By running fixed point iteration for multiple steps, we achieve a trajectory of the valuations, among which we define the valuation with the best conceivable decoupling error as the Variational Index. We prove that under uniform initializations,  these variational valuations all satisfy a set of game-theoretic axioms. We experimentally demonstrate that the proposed Variational Index enjoys lower decoupling error and better valuation performance  on certain synthetic and real-world valuation problems. ",
        "conference": "ICLR",
        "中文标题": "基于能量的合作博弈学习及其在机器学习估值问题中的应用",
        "摘要翻译": "估值问题，如特征解释、数据估值和集成模型估值，在许多机器学习应用中变得越来越重要。这类问题通常通过著名的博弈论标准来解决，如沙普利值或班扎夫值。在这项工作中，我们提出了一种新颖的基于能量的合作博弈处理方法，并通过最大熵框架提供了理论依据。令人惊讶的是，通过对基于能量的模型进行变分推断，我们通过执行一步固定点迭代来最大化平均场ELBO目标，恢复了各种博弈论估值标准。这一观察也验证了现有标准的合理性，因为它们都试图通过平均场方法来解耦玩家之间的相关性。通过运行多步固定点迭代，我们获得了一系列估值轨迹，其中我们定义了解耦误差最小的估值为变分指数。我们证明，在均匀初始化下，这些变分估值都满足一组博弈论公理。我们通过实验证明，所提出的变分指数在某些合成和现实世界的估值问题上享有更低的解耦误差和更好的估值性能。",
        "领域": "机器学习理论、博弈论在机器学习中的应用、模型解释性",
        "问题": "解决机器学习中的估值问题，如特征解释、数据估值和模型估值",
        "动机": "提供一种新的基于能量的合作博弈处理方法，以更有效地解决机器学习中的估值问题",
        "方法": "通过基于能量的模型和变分推断，结合最大熵框架和平均场方法，提出变分指数作为新的估值标准",
        "关键词": [
            "合作博弈",
            "变分推断",
            "最大熵",
            "估值问题",
            "机器学习"
        ],
        "涉及的技术概念": {
            "基于能量的模型": "用于合作博弈的处理，通过能量函数来建模玩家之间的相互作用",
            "变分推断": "用于近似推断基于能量模型的后验分布，通过最大化ELBO目标来优化",
            "平均场方法": "用于解耦玩家之间的相关性，简化模型推断过程"
        },
        "success": true
    },
    {
        "order": 291,
        "title": "Energy-Inspired Molecular Conformation Optimization",
        "html": "https://iclr.cc//virtual/2022/poster/6692",
        "abstract": "This paper studies an important problem in computational chemistry: predicting a molecule's spatial atom arrangements, or a molecular conformation. We propose a neural energy minimization formulation that casts the prediction problem into an unrolled optimization process, where a neural network is parametrized to learn the gradient fields of an implicit conformational energy landscape. Assuming different forms of the underlying potential energy function, we can not only reinterpret and unify many of the existing models but also derive new variants of SE(3)-equivariant neural networks in a principled manner. In our experiments, these new variants show superior performance in molecular conformation optimization comparing to existing SE(3)-equivariant neural networks. Moreover, our energy-inspired formulation is also suitable for molecular conformation generation, where we can generate more diverse and accurate conformers comparing to existing baselines.",
        "conference": "ICLR",
        "中文标题": "能量启发的分子构象优化",
        "摘要翻译": "本文研究了计算化学中的一个重要问题：预测分子的空间原子排列，即分子构象。我们提出了一种神经能量最小化公式，将预测问题转化为一个展开的优化过程，其中神经网络被参数化以学习隐含构象能量景观的梯度场。假设潜在势能函数的不同形式，我们不仅可以重新解释和统一许多现有模型，还可以以原则性的方式推导出新的SE(3)-等变神经网络变体。在我们的实验中，这些新变体在分子构象优化方面显示出优于现有SE(3)-等变神经网络的性能。此外，我们的能量启发公式也适用于分子构象生成，与现有基线相比，我们可以生成更多样化和更准确的构象体。",
        "领域": "分子构象预测",
        "问题": "预测分子的空间原子排列（分子构象）",
        "动机": "解决计算化学中分子构象预测的问题，通过能量最小化方法提高预测的准确性和多样性",
        "方法": "提出神经能量最小化公式，通过参数化神经网络学习隐含构象能量景观的梯度场，并推导新的SE(3)-等变神经网络变体",
        "关键词": [
            "分子构象优化",
            "SE(3)-等变神经网络",
            "神经能量最小化"
        ],
        "涉及的技术概念": {
            "神经能量最小化": "将分子构象预测问题转化为优化过程，通过神经网络学习能量景观的梯度场",
            "SE(3)-等变神经网络": "一种能够处理三维空间中的平移和旋转等变的神经网络，用于分子构象预测",
            "分子构象生成": "利用能量启发公式生成多样化和准确的分子构象体"
        },
        "success": true
    },
    {
        "order": 292,
        "title": "Enhancing Cross-lingual Transfer by Manifold Mixup",
        "html": "https://iclr.cc//virtual/2022/poster/6029",
        "abstract": "Based on large-scale pre-trained multilingual representations, recent cross-lingual transfer methods have achieved impressive transfer performances. However, the performance of target languages still lags far behind the source language. In this paper, our analyses indicate such a performance gap is strongly associated with the cross-lingual representation discrepancy. To achieve better cross-lingual transfer performance, we propose the cross-lingual manifold mixup (X-Mixup) method, which adaptively calibrates the representation discrepancy and gives a compromised representation for target languages. Experiments on the XTREME benchmark show X-Mixup achieves 1.8% performance gains on multiple text understanding tasks, compared with strong baselines, and significantly reduces the cross-lingual representation discrepancy.",
        "conference": "ICLR",
        "中文标题": "通过流形混合增强跨语言迁移",
        "摘要翻译": "基于大规模预训练的多语言表示，近期的跨语言迁移方法已经取得了令人印象深刻的迁移性能。然而，目标语言的性能仍然远远落后于源语言。在本文中，我们的分析表明，这种性能差距与跨语言表示差异密切相关。为了实现更好的跨语言迁移性能，我们提出了跨语言流形混合（X-Mixup）方法，该方法自适应地校准表示差异，并为目标语言提供折衷的表示。在XTREME基准测试上的实验表明，与强大的基线相比，X-Mixup在多个文本理解任务上实现了1.8%的性能提升，并显著减少了跨语言表示差异。",
        "领域": "自然语言处理与视觉结合",
        "问题": "跨语言迁移中目标语言性能落后于源语言的问题",
        "动机": "减少跨语言表示差异，提升跨语言迁移性能",
        "方法": "提出跨语言流形混合（X-Mixup）方法，自适应校准表示差异",
        "关键词": [
            "跨语言迁移",
            "流形混合",
            "文本理解"
        ],
        "涉及的技术概念": {
            "跨语言表示差异": "指不同语言在表示空间中的差异，影响跨语言迁移性能",
            "流形混合": "一种通过混合不同语言的表示来减少表示差异的技术",
            "XTREME基准测试": "用于评估跨语言理解模型性能的标准测试集"
        },
        "success": true
    },
    {
        "order": 293,
        "title": "EntQA: Entity Linking as Question Answering",
        "html": "https://iclr.cc//virtual/2022/poster/6200",
        "abstract": "A conventional approach to entity linking is to first find mentions in a given document and then infer their underlying entities in the knowledge base. A well-known limitation of this approach is that it requires finding mentions without knowing their entities, which is unnatural and difficult. We present a new model that does not suffer from this limitation called $\\textbf{EntQA}$, which stands for $\\mbox{\\textbf{Ent}ity}$ linking as $\\mbox{\\textbf{Q}uestion}$ $\\mbox{\\textbf{A}nswering}$. EntQA first proposes candidate entities with a fast retrieval module, and then scrutinizes the document to find mentions of each candidate with a powerful reader module. Our approach combines progress in entity linking with that in open-domain question answering and capitalizes on pretrained models for dense entity retrieval and reading comprehension. Unlike in previous works, we do not rely on a mention-candidates dictionary or large-scale weak supervision. EntQA achieves strong results on the GERBIL benchmarking platform.",
        "conference": "ICLR",
        "中文标题": "EntQA：将实体链接作为问答处理",
        "摘要翻译": "传统的实体链接方法首先在给定文档中找到提及，然后在知识库中推断它们的基础实体。这种方法的一个众所周知的限制是，它需要在不知道实体的情况下找到提及，这是不自然且困难的。我们提出了一个不受此限制的新模型，称为EntQA，即“将实体链接作为问答处理”。EntQA首先使用快速检索模块提出候选实体，然后使用强大的阅读器模块仔细检查文档以找到每个候选实体的提及。我们的方法将实体链接的进展与开放领域问答的进展结合起来，并利用了预训练模型进行密集实体检索和阅读理解。与之前的工作不同，我们不依赖于提及-候选字典或大规模弱监督。EntQA在GERBIL基准测试平台上取得了强劲的结果。",
        "领域": "实体链接、开放领域问答、知识库构建",
        "问题": "解决传统实体链接方法在不知道实体的情况下需要先找到提及的限制",
        "动机": "提出一种更自然且易于实现的实体链接方法，克服传统方法的限制",
        "方法": "结合快速检索模块和强大的阅读器模块，利用预训练模型进行密集实体检索和阅读理解",
        "关键词": [
            "实体链接",
            "问答系统",
            "知识库",
            "预训练模型",
            "阅读理解"
        ],
        "涉及的技术概念": {
            "快速检索模块": "用于高效提出候选实体，减少搜索空间",
            "阅读器模块": "用于仔细检查文档，准确找到候选实体的提及",
            "预训练模型": "用于提升密集实体检索和阅读理解的性能，减少对大规模监督数据的依赖"
        },
        "success": true
    },
    {
        "order": 294,
        "title": "Entroformer: A Transformer-based Entropy Model for Learned Image Compression",
        "html": "https://iclr.cc//virtual/2022/poster/7022",
        "abstract": "One critical component in lossy deep image compression is the entropy model, which predicts the probability distribution of the quantized latent representation in the encoding and decoding modules. Previous works build entropy models upon convolutional neural networks which are inefficient in capturing global dependencies. In this work, we propose a novel transformer-based entropy model, termed Entroformer, to capture long-range dependencies in probability distribution estimation effectively and efficiently. Different from vision transformers in image classification, the Entroformer is highly optimized for image compression, including a top-k self-attention and a diamond relative position encoding. Meanwhile, we further expand this architecture with a parallel bidirectional context model to speed up the decoding process. The experiments show that the Entroformer achieves state-of-the-art performance on image compression while being time-efficient.",
        "conference": "ICLR",
        "中文标题": "Entroformer：一种基于Transformer的熵模型用于学习型图像压缩",
        "摘要翻译": "在有损深度图像压缩中，一个关键组件是熵模型，它预测编码和解码模块中量化潜在表示的概率分布。以往的工作基于卷积神经网络构建熵模型，这些网络在捕捉全局依赖性方面效率不高。在这项工作中，我们提出了一种新颖的基于Transformer的熵模型，称为Entroformer，以有效且高效地捕捉概率分布估计中的长距离依赖性。与图像分类中的视觉Transformer不同，Entroformer针对图像压缩进行了高度优化，包括一个top-k自注意力机制和一个菱形相对位置编码。同时，我们进一步通过一个并行双向上下文模型扩展了这一架构，以加速解码过程。实验表明，Entroformer在图像压缩上实现了最先进的性能，同时具有时间效率。",
        "领域": "图像压缩、深度学习、熵模型优化",
        "问题": "解决现有基于卷积神经网络的熵模型在捕捉全局依赖性方面的不足",
        "动机": "提高图像压缩中概率分布估计的准确性和效率",
        "方法": "提出基于Transformer的Entroformer模型，引入top-k自注意力机制和菱形相对位置编码，以及并行双向上下文模型",
        "关键词": [
            "图像压缩",
            "熵模型",
            "Transformer",
            "自注意力机制",
            "相对位置编码"
        ],
        "涉及的技术概念": {
            "Transformer": "用于构建熵模型，有效捕捉长距离依赖性",
            "top-k自注意力机制": "优化注意力计算，提高模型效率",
            "菱形相对位置编码": "增强模型对图像局部结构的理解，优化压缩性能"
        },
        "success": true
    },
    {
        "order": 295,
        "title": "Environment Predictive Coding for Visual Navigation",
        "html": "https://iclr.cc//virtual/2022/poster/6109",
        "abstract": "We introduce environment predictive coding, a self-supervised approach to learn environment-level representations for embodied agents. In contrast to prior work on self-supervised learning for individual images, we aim to encode a 3D environment using a series of images observed by an agent moving in it. We learn these representations via a masked-zone prediction task, which segments an agent’s trajectory into zones and then predicts features of randomly masked zones, conditioned on the agent’s camera poses. This explicit spatial conditioning encourages learning representations that capture the geometric and semantic regularities of 3D environments. We learn such representations on a collection of video walkthroughs and demonstrate successful transfer to multiple downstream navigation tasks. Our experiments on the real-world scanned 3D environments of Gibson and Matterport3D show that our method obtains 2 - 6× higher sample-efﬁciency and up to 57% higher performance over standard image-representation learning.",
        "conference": "ICLR",
        "中文标题": "环境预测编码在视觉导航中的应用",
        "摘要翻译": "我们介绍了环境预测编码，这是一种自监督学习方法，用于学习具身代理的环境级表示。与之前针对单个图像的自监督学习工作不同，我们的目标是通过代理在其中移动时观察到的一系列图像来编码3D环境。我们通过一个掩蔽区域预测任务来学习这些表示，该任务将代理的轨迹分割成区域，然后根据代理的相机姿态预测随机掩蔽区域的特征。这种明确的空间条件鼓励学习捕捉3D环境的几何和语义规律性的表示。我们在视频漫游的集合上学习这些表示，并展示了成功转移到多个下游导航任务中。我们在Gibson和Matterport3D的真实世界扫描3D环境上的实验表明，与标准的图像表示学习相比，我们的方法获得了2到6倍的样本效率和高达57%的性能提升。",
        "领域": "视觉导航、3D环境理解、自监督学习",
        "问题": "如何高效地学习3D环境的表示以提升视觉导航的性能",
        "动机": "为了解决在视觉导航中高效学习3D环境表示的问题，以提高导航任务的样本效率和性能",
        "方法": "采用掩蔽区域预测任务，通过分割代理的轨迹并预测掩蔽区域的特征来学习3D环境的表示",
        "关键词": [
            "环境预测编码",
            "视觉导航",
            "3D环境表示",
            "自监督学习",
            "掩蔽区域预测"
        ],
        "涉及的技术概念": {
            "环境预测编码": "一种自监督学习方法，用于学习具身代理的环境级表示",
            "掩蔽区域预测": "将代理的轨迹分割成区域，预测随机掩蔽区域的特征以学习环境表示",
            "3D环境表示": "通过一系列图像编码3D环境的几何和语义信息，用于视觉导航任务"
        },
        "success": true
    },
    {
        "order": 296,
        "title": "Equivariant and Stable Positional Encoding for More Powerful Graph Neural Networks",
        "html": "https://iclr.cc//virtual/2022/poster/6134",
        "abstract": "Graph neural networks (GNN) have shown great advantages in many graph-based learning tasks but often fail to predict accurately for a task-based on sets of nodes such as link/motif prediction and so on.  Many works have recently proposed to address this problem by using random node features or node distance features. However, they suffer from either slow convergence, inaccurate prediction, or high complexity. In this work, we revisit GNNs that allow using positional features of nodes given by positional encoding (PE) techniques such as Laplacian Eigenmap, Deepwalk, etc. GNNs with PE often get criticized because they are not generalizable to unseen graphs (inductive) or stable.  Here, we study these issues in a principled way and propose a provable solution, a class of GNN layers termed PEG with rigorous mathematical analysis. PEG uses separate channels to update the original node features and positional features. PEG imposes permutation equivariance w.r.t. the original node features and rotation equivariance w.r.t. the positional features simultaneously. Extensive link prediction experiments over 8 real-world networks demonstrate the advantages of PEG in generalization and scalability. Code is available at https://github.com/Graph-COM/PEG.",
        "conference": "ICLR",
        "中文标题": "等变且稳定的位置编码为更强大的图神经网络",
        "摘要翻译": "图神经网络（GNN）在许多基于图的学习任务中显示出巨大优势，但在基于节点集的任务（如链接/模体预测等）中往往无法准确预测。最近，许多工作提出通过使用随机节点特征或节点距离特征来解决这个问题。然而，它们要么收敛速度慢，要么预测不准确，要么复杂度高。在这项工作中，我们重新审视了允许使用位置编码（PE）技术（如拉普拉斯特征映射、Deepwalk等）给出的节点位置特征的GNN。带有PE的GNN经常受到批评，因为它们不能推广到未见过的图（归纳性）或不稳定。在这里，我们以原则性的方式研究这些问题，并提出了一种可证明的解决方案，一类称为PEG的GNN层，具有严格的数学分析。PEG使用单独的通道来更新原始节点特征和位置特征。PEG同时对原始节点特征施加排列等变性，对位置特征施加旋转等变性。在8个真实世界网络上进行的广泛链接预测实验证明了PEG在泛化性和可扩展性方面的优势。代码可在https://github.com/Graph-COM/PEG获取。",
        "领域": "图神经网络、链接预测、节点特征学习",
        "问题": "解决图神经网络在基于节点集的任务中预测不准确的问题",
        "动机": "提高图神经网络在链接/模体预测等任务中的准确性和泛化能力",
        "方法": "提出一种新的GNN层PEG，使用单独的通道更新节点和位置特征，同时保证对原始节点特征的排列等变性和对位置特征的旋转等变性",
        "关键词": [
            "图神经网络",
            "位置编码",
            "链接预测",
            "等变性",
            "稳定性"
        ],
        "涉及的技术概念": {
            "位置编码（PE）": "用于为节点提供位置特征的技术，如拉普拉斯特征映射、Deepwalk等",
            "排列等变性": "保证模型对节点排列的不变性，提高模型的泛化能力",
            "旋转等变性": "保证模型对位置特征的旋转不变性，增强模型的稳定性"
        },
        "success": true
    },
    {
        "order": 297,
        "title": "Equivariant Graph Mechanics Networks with Constraints",
        "html": "https://iclr.cc//virtual/2022/poster/6795",
        "abstract": "Learning to reason about relations and dynamics over multiple interacting objects is a challenging topic in machine learning. The challenges mainly stem from that the interacting systems are exponentially-compositional, symmetrical, and commonly geometrically-constrained.Current methods, particularly the ones based on equivariant Graph Neural Networks (GNNs), have targeted on the first two challenges but remain immature for constrained systems. In this paper, we propose Graph Mechanics Network (GMN) which is combinatorially efficient, equivariant and constraint-aware. The core of GMN is that it represents, by generalized coordinates, the forward kinematics information (positions and velocities) of a structural object. In this manner, the geometrical constraints are implicitly and naturally encoded in the forward kinematics. Moreover, to allow equivariant message passing in GMN, we have developed a general form of orthogonality-equivariant functions, given that the dynamics of constrained systems are more complicated than the unconstrained counterparts. Theoretically, the proposed equivariant formulation is proved to be universally expressive under certain conditions. Extensive experiments  support the advantages of GMN compared to the state-of-the-art GNNs in terms of prediction accuracy, constraint satisfaction and data efficiency on the simulated systems consisting of particles, sticks and hinges, as well as two real-world datasets for molecular dynamics prediction and human motion capture.",
        "conference": "ICLR",
        "中文标题": "等变图力学网络与约束",
        "摘要翻译": "学习推理多个相互作用对象之间的关系和动态是机器学习中的一个具有挑战性的主题。这些挑战主要源于相互作用系统具有指数组合性、对称性，并且通常受到几何约束。当前的方法，特别是基于等变图神经网络（GNNs）的方法，已经针对前两个挑战进行了研究，但对于受约束系统仍不成熟。在本文中，我们提出了图力学网络（GMN），它是组合高效的、等变的且约束感知的。GMN的核心在于它通过广义坐标表示结构对象的前向运动学信息（位置和速度）。这样，几何约束被隐式且自然地编码在前向运动学中。此外，为了在GMN中实现等变消息传递，我们开发了一种正交等变函数的通用形式，因为受约束系统的动态比不受约束的系统更为复杂。理论上，所提出的等变公式在一定条件下被证明是普遍表达的。大量实验支持GMN在预测准确性、约束满足度和数据效率方面相比最先进的GNNs在由粒子、棒和铰链组成的模拟系统以及两个用于分子动力学预测和人类运动捕捉的真实世界数据集上的优势。",
        "领域": "图神经网络、分子动力学模拟、运动捕捉",
        "问题": "解决在受几何约束的系统中，如何高效、准确地推理多个相互作用对象之间的关系和动态的问题。",
        "动机": "当前基于等变图神经网络的方法在处理受约束系统时仍不成熟，需要开发能够同时满足组合高效性、等变性和约束感知的新方法。",
        "方法": "提出图力学网络（GMN），通过广义坐标表示结构对象的前向运动学信息，隐式编码几何约束，并开发正交等变函数的通用形式以实现等变消息传递。",
        "关键词": [
            "等变图神经网络",
            "几何约束",
            "分子动力学",
            "运动捕捉",
            "正交等变函数"
        ],
        "涉及的技术概念": {
            "等变图神经网络": "用于处理具有对称性的系统，保证网络输出与输入变换同步。",
            "广义坐标": "用于表示结构对象的前向运动学信息，隐式编码几何约束。",
            "正交等变函数": "在GMN中实现等变消息传递的通用形式，适用于受约束系统的复杂动态。"
        },
        "success": true
    },
    {
        "order": 298,
        "title": "Equivariant Self-Supervised Learning: Encouraging Equivariance in Representations",
        "html": "https://iclr.cc//virtual/2022/poster/6083",
        "abstract": "In state-of-the-art self-supervised learning (SSL) pre-training produces semantically good representations by encouraging them to be invariant under meaningful transformations prescribed from human knowledge. In fact, the property of invariance is a trivial instance of a broader class called equivariance, which can be intuitively understood as the property that representations transform according to the way the inputs transform. Here, we show that rather than using only invariance, pre-training that encourages non-trivial equivariance to some transformations, while maintaining invariance to other transformations, can be used to improve the semantic quality of representations. Specifically, we extend popular SSL methods to a more general framework which we name Equivariant Self-Supervised Learning (E-SSL). In E-SSL, a simple additional pre-training objective encourages equivariance by predicting the transformations applied to the input. We demonstrate E-SSL’s effectiveness empirically on several popular computer vision benchmarks, e.g. improving SimCLR to 72.5% linear probe accuracy on ImageNet. Furthermore, we demonstrate usefulness of E-SSL for applications beyond computer vision; in particular, we show its utility on regression problems in photonics science. Our code, datasets and pre-trained models are available at https://github.com/rdangovs/essl to aid further research in E-SSL.",
        "conference": "ICLR",
        "中文标题": "等变自监督学习：在表示中鼓励等变性",
        "摘要翻译": "在目前最先进的自监督学习（SSL）中，预训练通过鼓励表示在人类知识规定的有意义变换下保持不变性，从而产生语义上良好的表示。实际上，不变性是一种更广泛类别的平凡实例，称为等变性，可以直观地理解为表示根据输入变换的方式而变换的属性。在这里，我们展示了，不仅仅是使用不变性，预训练鼓励对某些变换的非平凡等变性，同时保持对其他变换的不变性，可以用来提高表示的语义质量。具体来说，我们将流行的SSL方法扩展到一个更通用的框架，我们称之为等变自监督学习（E-SSL）。在E-SSL中，一个简单的额外预训练目标通过预测应用于输入的变换来鼓励等变性。我们在几个流行的计算机视觉基准上实证展示了E-SSL的有效性，例如将SimCLR在ImageNet上的线性探针准确率提高到72.5%。此外，我们还展示了E-SSL在计算机视觉之外的应用中的有用性；特别是，我们展示了它在光子科学回归问题上的效用。我们的代码、数据集和预训练模型可在https://github.com/rdangovs/essl上获得，以促进E-SSL的进一步研究。",
        "领域": "自监督学习、计算机视觉、光子科学",
        "问题": "如何通过鼓励表示在变换下的等变性来提高自监督学习中的表示质量",
        "动机": "探索在自监督学习中利用等变性而不仅仅是不变性，以提高表示的语义质量",
        "方法": "扩展流行的自监督学习方法至等变自监督学习（E-SSL）框架，通过预测输入变换来鼓励等变性",
        "关键词": [
            "等变自监督学习",
            "表示学习",
            "计算机视觉",
            "光子科学",
            "预训练"
        ],
        "涉及的技术概念": {
            "等变性": "表示根据输入变换的方式而变换的属性，用于提高表示的语义质量",
            "自监督学习": "一种无需人工标注数据的学习方法，通过数据本身的结构进行学习",
            "预训练": "在特定任务之前，先在大量数据上进行训练以学习通用表示的过程"
        },
        "success": true
    },
    {
        "order": 299,
        "title": "Equivariant Subgraph Aggregation Networks",
        "html": "https://iclr.cc//virtual/2022/poster/6212",
        "abstract": "Message-passing neural networks (MPNNs) are the leading architecture for deep learning on graph-structured data, in large part due to their simplicity and scalability. Unfortunately, it was shown that these architectures are limited in their expressive power. This paper proposes a novel framework called Equivariant Subgraph Aggregation Networks (ESAN) to address this issue. Our main observation is that while two graphs may not be distinguishable by an MPNN, they often contain distinguishable subgraphs. Thus, we propose to represent each graph as a set of subgraphs derived by some predefined policy, and to process it using a suitable equivariant architecture. We develop novel variants of the 1-dimensional Weisfeiler-Leman (1-WL) test for graph isomorphism, and prove lower bounds on the expressiveness of ESAN in terms of these new WL variants. We further prove that our approach increases the expressive power of both MPNNs and more expressive architectures. Moreover, we provide theoretical results that describe how design choices such as the subgraph selection policy and equivariant neural architecture affect our architecture's expressive power. To deal with the increased computational cost, we propose a subgraph sampling scheme, which can be viewed as a stochastic version of our framework. A comprehensive set of experiments on real and synthetic datasets demonstrates that our framework improves the expressive power and overall performance of popular GNN architectures. ",
        "conference": "ICLR",
        "中文标题": "等变子图聚合网络",
        "摘要翻译": "消息传递神经网络（MPNNs）是图结构数据深度学习的主要架构，这在很大程度上归功于其简单性和可扩展性。不幸的是，研究表明这些架构的表达能力有限。本文提出了一种名为等变子图聚合网络（ESAN）的新框架来解决这一问题。我们的主要观察是，虽然两个图可能无法通过MPNN区分，但它们通常包含可区分的子图。因此，我们建议将每个图表示为由某种预定义策略派生的子图集合，并使用合适的等变架构进行处理。我们开发了图同构的一维Weisfeiler-Leman（1-WL）测试的新变体，并根据这些新的WL变体证明了ESAN表达能力的下限。我们进一步证明，我们的方法提高了MPNNs和更具表达力的架构的表达能力。此外，我们提供了理论结果，描述了子图选择策略和等变神经架构等设计选择如何影响我们架构的表达能力。为了应对增加的计算成本，我们提出了一种子图采样方案，可以视为我们框架的随机版本。在真实和合成数据集上的一系列综合实验表明，我们的框架提高了流行GNN架构的表达能力和整体性能。",
        "领域": "图神经网络、图同构测试、子图学习",
        "问题": "提高图神经网络在区分不同图结构时的表达能力",
        "动机": "现有的消息传递神经网络（MPNNs）在图结构数据的处理中表现出有限的表达能力，无法有效区分某些图结构。",
        "方法": "提出等变子图聚合网络（ESAN），通过将图表示为子图集合并使用等变架构处理，以提高表达能力。",
        "关键词": [
            "等变子图聚合网络",
            "图同构测试",
            "子图学习",
            "表达能力",
            "图神经网络"
        ],
        "涉及的技术概念": {
            "等变子图聚合网络（ESAN）": "一种新提出的框架，通过聚合子图信息来提高图神经网络的表达能力。",
            "一维Weisfeiler-Leman（1-WL）测试": "用于图同构测试的方法，本文中开发了新变体以评估和提升模型的表达能力。",
            "子图采样方案": "为了降低计算成本，提出的随机子图选择策略，是ESAN框架的随机版本实现。"
        },
        "success": true
    },
    {
        "order": 300,
        "title": "Equivariant Transformers for Neural Network based Molecular Potentials",
        "html": "https://iclr.cc//virtual/2022/poster/6416",
        "abstract": "The prediction of quantum mechanical properties is historically plagued by a trade-off between accuracy and speed. Machine learning potentials have previously shown great success in this domain, reaching increasingly better accuracy while maintaining computational efficiency comparable with classical force fields. In this work we propose TorchMD-NET, a novel equivariant Transformer (ET) architecture, outperforming state-of-the-art on MD17, ANI-1, and many QM9 targets in both accuracy and computational efficiency. Through an extensive attention weight analysis, we gain valuable insights into the black box predictor and show differences in the learned representation of conformers versus conformations sampled from molecular dynamics or normal modes. Furthermore, we highlight the importance of datasets including off-equilibrium conformations for the evaluation of molecular potentials.",
        "conference": "ICLR",
        "中文标题": "用于神经网络分子势能的等变变换器",
        "摘要翻译": "量子力学性质的预测历史上一直受到准确性与速度之间权衡的困扰。机器学习势能此前在这一领域已显示出巨大成功，达到了越来越好的准确性，同时保持了与经典力场相当的计算效率。在这项工作中，我们提出了TorchMD-NET，一种新颖的等变变换器（ET）架构，在MD17、ANI-1和许多QM9目标上在准确性和计算效率方面均优于现有技术。通过广泛的注意力权重分析，我们获得了对黑盒预测器的宝贵见解，并展示了构象异构体与从分子动力学或正常模式采样的构象在学习表示上的差异。此外，我们强调了包括非平衡构象的数据集对于分子势能评估的重要性。",
        "领域": "分子动力学模拟、量子力学性质预测、机器学习势能",
        "问题": "解决量子力学性质预测中准确性与速度之间的权衡问题",
        "动机": "开发一种既准确又计算效率高的机器学习势能方法，以改进分子动力学模拟和量子力学性质预测",
        "方法": "提出了一种新颖的等变变换器（ET）架构TorchMD-NET，通过注意力权重分析优化模型性能",
        "关键词": [
            "等变变换器",
            "分子动力学",
            "量子力学性质",
            "机器学习势能",
            "TorchMD-NET"
        ],
        "涉及的技术概念": {
            "等变变换器（ET）": "一种新颖的变换器架构，用于处理分子势能预测中的对称性和不变性问题",
            "注意力权重分析": "用于深入理解模型决策过程，揭示不同构象表示之间的差异",
            "非平衡构象数据集": "强调在分子势能评估中包含非平衡构象的重要性，以提高模型的泛化能力和准确性"
        },
        "success": true
    },
    {
        "order": 301,
        "title": "Escaping limit cycles: Global convergence for constrained nonconvex-nonconcave minimax problems",
        "html": "https://iclr.cc//virtual/2022/poster/6528",
        "abstract": "This paper introduces a new extragradient-type algorithm for a class of nonconvex-nonconcave minimax problems. It is well-known that finding a local solution for general minimax problems is computationally intractable. This observation has recently motivated the study of structures sufficient for convergence of first order methods in the more general setting of variational inequalities when the so-called weak Minty variational inequality (MVI) holds. This problem class captures non-trivial structures as we demonstrate with examples, for which a large family of existing algorithms provably converge to limit cycles. Our results require a less restrictive parameter range in the weak MVI compared to what is previously known, thus extending the applicability of our scheme. The proposed algorithm is applicable to constrained and regularized problems, and involves an adaptive stepsize allowing for potentially larger stepsizes. Our scheme also converges globally even in settings where the underlying operator exhibits limit cycles.",
        "conference": "ICLR",
        "中文标题": "逃离极限环：约束非凸非凹极小极大问题的全局收敛",
        "摘要翻译": "本文针对一类非凸非凹极小极大问题，提出了一种新的外梯度类型算法。众所周知，对于一般的极小极大问题，寻找局部解在计算上是不可行的。这一观察最近激发了在更一般的变分不等式设置下，当所谓的弱Minty变分不等式（MVI）成立时，研究一阶方法收敛的充分结构。正如我们通过示例所展示的，这个问题类别捕捉了非平凡的结构，对于这些结构，现有算法的一大类被证明会收敛到极限环。与之前已知的相比，我们的结果在弱MVI中需要较少的限制参数范围，从而扩展了我们方案的适用性。所提出的算法适用于约束和正则化问题，并涉及允许潜在更大步长的自适应步长。即使在底层算子表现出极限环的设置中，我们的方案也能全局收敛。",
        "领域": "优化算法、变分不等式、非凸优化",
        "问题": "解决非凸非凹极小极大问题中的极限环收敛问题",
        "动机": "研究在弱Minty变分不等式条件下，如何设计能够全局收敛的算法，避免陷入极限环",
        "方法": "提出了一种新的外梯度类型算法，采用自适应步长策略，适用于约束和正则化问题",
        "关键词": [
            "非凸非凹极小极大问题",
            "外梯度算法",
            "全局收敛",
            "自适应步长",
            "弱Minty变分不等式"
        ],
        "涉及的技术概念": {
            "外梯度类型算法": "用于解决非凸非凹极小极大问题的一种算法，通过外梯度步骤来更新变量",
            "弱Minty变分不等式": "一种保证算法收敛的条件，本文中放宽了这一条件的参数范围，扩展了算法的适用性",
            "自适应步长": "算法中采用的步长选择策略，允许根据问题特性动态调整步长，以提高收敛效率"
        },
        "success": true
    },
    {
        "order": 302,
        "title": "Evading Adversarial Example Detection Defenses with Orthogonal Projected Gradient Descent",
        "html": "https://iclr.cc//virtual/2022/poster/6295",
        "abstract": "Evading adversarial example detection defenses requires finding adversarial examples that must simultaneously (a) be misclassified by the model and (b) be detected as non-adversarial. We find that existing attacks that attempt to satisfy multiple simultaneous constraints often over-optimize against one constraint at the cost of satisfying another. We introduce Selective Projected Gradient Descent and Orthogonal Projected Gradient Descent, improved attack techniques to generate adversarial examples that avoid this problem by orthogonalizing the gradients when running standard gradient-based attacks. We use our technique to evade four state-of-the-art detection defenses, reducing their accuracy to 0% while maintaining a 0% detection rate.",
        "conference": "ICLR",
        "中文标题": "通过正交投影梯度下降规避对抗样本检测防御",
        "摘要翻译": "规避对抗样本检测防御需要找到同时满足以下两个条件的对抗样本：(a) 被模型误分类；(b) 被检测为非对抗性。我们发现，现有的尝试满足多个同时约束的攻击方法往往过度优化一个约束而牺牲另一个约束的满足。我们引入了选择性投影梯度下降和正交投影梯度下降，这些改进的攻击技术通过在运行基于梯度的标准攻击时正交化梯度，来生成避免这一问题的对抗样本。我们使用我们的技术规避了四种最先进的检测防御，将它们的准确率降至0%，同时保持0%的检测率。",
        "领域": "对抗样本防御、深度学习安全、图像分类",
        "问题": "如何在满足被模型误分类的同时，确保对抗样本不被检测防御机制识别出来。",
        "动机": "现有的对抗样本生成方法在尝试满足多个约束时，往往无法平衡优化，导致无法有效规避检测防御。",
        "方法": "引入选择性投影梯度下降和正交投影梯度下降技术，通过在梯度攻击过程中正交化梯度，生成更有效的对抗样本。",
        "关键词": [
            "对抗样本",
            "梯度下降",
            "检测防御",
            "深度学习安全",
            "正交化梯度"
        ],
        "涉及的技术概念": {
            "对抗样本": "在输入数据上添加微小扰动，导致深度学习模型产生错误输出的样本。",
            "梯度下降": "一种优化算法，用于通过沿着梯度相反方向更新参数来最小化损失函数。",
            "正交化梯度": "在生成对抗样本时，调整梯度方向以避免过度优化某一约束，从而更有效地满足多个约束条件。"
        },
        "success": true
    },
    {
        "order": 303,
        "title": "Evaluating Disentanglement of Structured Representations",
        "html": "https://iclr.cc//virtual/2022/poster/6441",
        "abstract": "We introduce the first metric for evaluating disentanglement at individual hierarchy levels of a structured latent representation. Applied to object-centric generative models, this offers a systematic, unified approach to evaluating (i) object separation between latent slots (ii) disentanglement of object properties inside individual slots (iii) disentanglement of intrinsic and extrinsic object properties. We theoretically show that our framework gives stronger guarantees of selecting a good model than previous disentanglement metrics. Experimentally, we demonstrate that viewing object compositionality as a disentanglement problem addresses several issues with prior visual metrics of object separation. As a core technical component, we present the first representation probing algorithm handling slot permutation invariance.",
        "conference": "ICLR",
        "中文标题": "评估结构化表示的解缠结性",
        "摘要翻译": "我们首次提出了一个用于评估结构化潜在表示在个体层次级别上解缠结性的度量标准。应用于以对象为中心的生成模型时，这提供了一个系统化、统一的方法来评估（i）潜在槽之间的对象分离（ii）单个槽内对象属性的解缠结（iii）对象内在和外在属性的解缠结。我们从理论上证明了我们的框架在选择好模型方面提供了比以往解缠结度量更强的保证。实验上，我们展示了将对象组合性视为解缠结问题，解决了先前视觉对象分离度量的几个问题。作为核心技术组件，我们提出了第一个处理槽排列不变性的表示探测算法。",
        "领域": "生成模型、解缠结表示学习、对象中心表示",
        "问题": "如何系统评估结构化潜在表示在不同层次上的解缠结性",
        "动机": "为了解决现有解缠结度量在评估结构化潜在表示时的不足，特别是在对象分离和属性解缠结方面的评估",
        "方法": "提出了一种新的度量标准，结合理论分析和实验验证，以及一种处理槽排列不变性的表示探测算法",
        "关键词": [
            "解缠结性评估",
            "结构化潜在表示",
            "对象中心生成模型",
            "表示探测算法",
            "槽排列不变性"
        ],
        "涉及的技术概念": {
            "解缠结性评估": "用于量化潜在表示中不同因素被独立编码的程度",
            "结构化潜在表示": "在潜在空间中组织数据以反映其内在结构，如对象和属性",
            "槽排列不变性": "确保表示探测算法对潜在槽的排列顺序不敏感，提高评估的鲁棒性"
        },
        "success": true
    },
    {
        "order": 304,
        "title": "Evaluating Distributional Distortion in Neural Language Modeling",
        "html": "https://iclr.cc//virtual/2022/poster/5993",
        "abstract": "A fundamental characteristic of natural language is the high rate at which speakers produce novel expressions. Because of this novelty, a heavy-tail of rare events accounts for a significant amount of the total probability mass of distributions in language (Baayen, 2001). Standard language modeling metrics such as perplexity quantify the performance of language models (LM) in aggregate.  As a result, we have relatively little understanding of whether neural LMs accurately estimate the probability of sequences in this heavy-tail of rare events. To address this gap, we develop a controlled evaluation scheme which uses generative models trained on natural data as artificial languages from which we can exactly compute sequence probabilities. Training LMs on generations from these artificial languages, we compare the sequence-level probability estimates given by LMs to the true probabilities in the target language. Our experiments reveal that LSTM and Transformer language models (i) systematically underestimate the probability of sequences drawn from the target language, and (ii) do so more severely for less-probable sequences. Investigating where this probability mass went, (iii) we find that LMs tend to overestimate the probability of ill formed (perturbed) sequences. In addition, we find that this underestimation behaviour (iv) is weakened, but not eliminated by greater amounts of training data, and (v) is exacerbated for target distributions with lower entropy.",
        "conference": "ICLR",
        "中文标题": "评估神经语言建模中的分布失真",
        "摘要翻译": "自然语言的一个基本特征是说话者产生新表达的高频率。由于这种新颖性，罕见事件的长尾占据了语言分布总概率质量的显著部分（Baayen，2001）。标准的语言建模指标，如困惑度，量化了语言模型（LM）在整体上的表现。因此，我们对神经语言模型是否能准确估计这一罕见事件长尾中序列的概率了解相对较少。为了填补这一空白，我们开发了一种受控评估方案，该方案使用在自然数据上训练的生成模型作为人工语言，从中我们可以精确计算序列概率。在这些人工语言的生成上训练语言模型，我们将语言模型给出的序列级概率估计与目标语言中的真实概率进行比较。我们的实验揭示了LSTM和Transformer语言模型（i）系统地低估了从目标语言中抽取的序列的概率，（ii）对于概率较低的序列，这种低估更为严重。研究这些概率质量去了哪里，（iii）我们发现语言模型倾向于高估不合法（扰动）序列的概率。此外，我们发现这种低估行为（iv）随着训练数据的增加而减弱，但并未消除，（v）对于熵较低的目标分布，这种行为更为严重。",
        "领域": "自然语言处理与生成模型",
        "问题": "神经语言模型在罕见事件长尾中序列概率估计的准确性",
        "动机": "填补对神经语言模型在罕见事件长尾中序列概率估计准确性理解的空白",
        "方法": "使用生成模型作为人工语言，比较语言模型给出的序列级概率估计与真实概率",
        "关键词": [
            "神经语言模型",
            "概率估计",
            "罕见事件",
            "分布失真",
            "LSTM"
        ],
        "涉及的技术概念": {
            "神经语言模型": "用于估计序列概率的模型，本文中特指LSTM和Transformer模型",
            "罕见事件长尾": "指在自然语言中不常见但占据显著概率质量的事件分布部分",
            "分布失真": "指模型估计的概率分布与真实分布之间的偏差，本文中特指低估罕见事件概率的现象"
        },
        "success": true
    },
    {
        "order": 305,
        "title": "Evaluating Model-Based Planning and Planner Amortization for Continuous Control",
        "html": "https://iclr.cc//virtual/2022/poster/6195",
        "abstract": "There is a widespread intuition that model-based control methods should be able to surpass the data efficiency of model-free approaches. In this paper we attempt to evaluate this intuition on various challenging locomotion tasks. We take a hybrid approach, combining model predictive control (MPC) with a learned model and model-free policy learning; the learned policy serves as a proposal for MPC. We show that MPC with learned proposals and models (trained on the fly or transferred from related tasks) can significantly improve performance and data efficiency with respect to model-free methods. However, we find that well-tuned model-free agents are strong baselines even for high DoF control problems. Finally, we show that it is possible to distil a model-based planner into a policy that amortizes the planning computation without any loss of performance.",
        "conference": "ICLR",
        "中文标题": "评估基于模型的规划与规划者摊销在连续控制中的应用",
        "摘要翻译": "普遍存在一种直觉，即基于模型的控制方法应能超越无模型方法的数据效率。在本文中，我们尝试在各种具有挑战性的运动任务上评估这一直觉。我们采用了一种混合方法，将模型预测控制（MPC）与学习模型和无模型策略学习相结合；学习策略作为MPC的提案。我们展示了带有学习提案和模型（即时训练或从相关任务转移）的MPC可以显著提高性能和数据效率，相对于无模型方法。然而，我们发现即使对于高自由度控制问题，调整良好的无模型代理也是强有力的基线。最后，我们展示了将基于模型的规划器提炼为一种策略，以摊销规划计算而不损失任何性能是可能的。",
        "领域": "强化学习、机器人控制、运动规划",
        "问题": "评估基于模型的控制方法在数据效率上是否优于无模型方法，并探索在连续控制任务中的应用效果。",
        "动机": "探索基于模型的控制方法在提高数据效率和性能方面的潜力，特别是在复杂的运动任务中。",
        "方法": "采用混合方法，结合模型预测控制（MPC）与学习模型和无模型策略学习，利用学习策略作为MPC的提案。",
        "关键词": [
            "模型预测控制",
            "强化学习",
            "运动规划",
            "数据效率",
            "连续控制"
        ],
        "涉及的技术概念": {
            "模型预测控制（MPC）": "用于在有限时间范围内优化控制动作，结合学习模型以提高控制性能。",
            "无模型策略学习": "不依赖于环境模型，直接从经验中学习策略，作为比较的基线方法。",
            "规划摊销": "将基于模型的规划过程提炼为策略，以减少实时计算需求而不牺牲性能。"
        },
        "success": true
    },
    {
        "order": 306,
        "title": "Evaluation Metrics for Graph Generative Models: Problems, Pitfalls, and Practical Solutions",
        "html": "https://iclr.cc//virtual/2022/poster/7082",
        "abstract": "Graph generative models are a highly active branch of machine learning. Given the steady development of new models of ever-increasing complexity, it is necessary to provide a principled way to evaluate and compare them. In this paper, we enumerate the desirable criteria for such a comparison metric and provide an overview of the status quo of graph generative model comparison in use today, which predominantly relies on the maximum mean discrepancy (MMD). We perform a systematic evaluation of MMD in the context of graph generative model comparison, highlighting some of the challenges and pitfalls researchers inadvertently may encounter. After conducting a thorough analysis of the behaviour of MMD on synthetically-generated perturbed graphs as well as on recently-proposed graph generative models, we are able to provide a suitable procedure to mitigate these challenges and pitfalls. We aggregate our findings into a list of practical recommendations for researchers to use when evaluating graph generative models.",
        "conference": "ICLR",
        "中文标题": "图生成模型的评估指标：问题、陷阱与实用解决方案",
        "摘要翻译": "图生成模型是机器学习中一个高度活跃的分支。鉴于新模型不断以日益增加的复杂度被开发出来，有必要提供一种原则性的方法来评估和比较它们。在本文中，我们列举了这种比较指标的理想标准，并概述了当前使用的图生成模型比较的现状，这主要依赖于最大均值差异（MMD）。我们在图生成模型比较的背景下对MMD进行了系统评估，突出了研究人员可能无意中遇到的一些挑战和陷阱。在对合成生成的扰动图以及最近提出的图生成模型上的MMD行为进行了彻底分析后，我们能够提供一个适当的程序来缓解这些挑战和陷阱。我们将我们的发现汇总成一份实用建议清单，供研究人员在评估图生成模型时使用。",
        "领域": "图神经网络、生成模型、机器学习评估",
        "问题": "如何有效评估和比较不同复杂度的图生成模型",
        "动机": "随着图生成模型复杂度的增加，需要一种原则性的方法来评估和比较这些模型，以促进该领域的发展",
        "方法": "通过系统评估最大均值差异（MMD）在图生成模型比较中的应用，分析其挑战和陷阱，并提出缓解策略",
        "关键词": [
            "图生成模型",
            "评估指标",
            "最大均值差异",
            "机器学习",
            "模型比较"
        ],
        "涉及的技术概念": {
            "最大均值差异（MMD）": "用于衡量两个分布之间差异的指标，在图生成模型比较中作为主要评估工具",
            "图生成模型": "能够生成图结构的机器学习模型，用于模拟复杂网络和关系",
            "合成生成的扰动图": "通过人为引入变化生成的图，用于测试和评估图生成模型的鲁棒性和性能"
        },
        "success": true
    },
    {
        "order": 307,
        "title": "Evidential Turing Processes ",
        "html": "https://iclr.cc//virtual/2022/poster/6361",
        "abstract": "A probabilistic classifier with reliable predictive uncertainties i) fits successfully to the target domain data, ii) provides calibrated class probabilities in difficult regions of the target domain (e.g. class overlap), and iii) accurately identifies queries coming out of the target domain and reject them. We introduce an original combination of Evidential Deep Learning, Neural Processes, and Neural Turing Machines capable of providing all three essential properties mentioned above for total uncertainty quantification. We observe our method on three image classification benchmarks to consistently improve the in-domain uncertainty quantification, out-of-domain detection, and robustness against input perturbations with one single model. Our unified solution delivers an implementation-friendly and computationally efficient recipe for safety clearance and provides intellectual economy to an investigation of algorithmic roots of epistemic awareness in deep neural nets.",
        "conference": "ICLR",
        "中文标题": "证据图灵过程",
        "摘要翻译": "一个具有可靠预测不确定性的概率分类器能够：i) 成功适应目标领域数据，ii) 在目标领域的困难区域（如类别重叠）提供校准的类别概率，以及iii) 准确识别来自目标领域之外的查询并拒绝它们。我们引入了一种结合证据深度学习、神经过程和神经图灵机的原创方法，能够为上述三个基本属性提供全面的不确定性量化。我们在三个图像分类基准上观察到，我们的方法通过单一模型持续改进了域内不确定性量化、域外检测以及对输入扰动的鲁棒性。我们的统一解决方案为安全许可提供了一个实现友好且计算效率高的方案，并为探索深度神经网络中认知意识的算法根源提供了智力经济。",
        "领域": "图像分类",
        "问题": "开发一个能够提供可靠预测不确定性、适应目标领域数据、并在困难区域提供校准类别概率的概率分类器。",
        "动机": "为了解决在目标领域的困难区域（如类别重叠）提供校准的类别概率，并准确识别和拒绝来自目标领域之外的查询的问题。",
        "方法": "结合证据深度学习、神经过程和神经图灵机的方法，以实现全面的不确定性量化。",
        "关键词": [
            "概率分类器",
            "不确定性量化",
            "域外检测",
            "证据深度学习",
            "神经图灵机"
        ],
        "涉及的技术概念": {
            "证据深度学习": "用于提升模型对预测不确定性的量化能力。",
            "神经过程": "在模型中引入随机过程，以更好地适应目标领域数据。",
            "神经图灵机": "增强模型的记忆和处理能力，以支持复杂的不确定性量化任务。"
        },
        "success": true
    },
    {
        "order": 308,
        "title": "EViT: Expediting Vision Transformers via Token Reorganizations",
        "html": "https://iclr.cc//virtual/2022/poster/6168",
        "abstract": "Vision Transformers (ViTs) take all the image patches as tokens and construct multi-head self-attention (MHSA) among them. Complete leverage of these image tokens brings redundant computations since not all the tokens are attentive in MHSA. Examples include that tokens containing semantically meaningless or distractive image backgrounds do not positively contribute to the ViT predictions. In this work, we propose to reorganize image tokens during the feed-forward process of ViT models, which is integrated into ViT during training. For each forward inference, we identify the attentive image tokens between MHSA and FFN (i.e., feed-forward network) modules, which is guided by the corresponding class token attention. Then, we reorganize image tokens by preserving attentive image tokens and fusing inattentive ones to expedite subsequent MHSA and FFN computations. To this end, our method EViT improves ViTs from two perspectives. First, under the same amount of input image tokens, our method reduces MHSA and FFN computation for efficient inference. For instance, the inference speed of DeiT-S is increased by 50% while its recognition accuracy is decreased by only 0.3% for ImageNet classification. Second, by maintaining the same computational cost, our method empowers ViTs to take more image tokens as input for recognition accuracy improvement, where the image tokens are from higher resolution images. An example is that we improve the recognition accuracy of DeiT-S by 1% for ImageNet classification at the same computational cost of a vanilla DeiT-S. Meanwhile, our method does not introduce more parameters to ViTs. Experiments on the standard benchmarks show the effectiveness of our method. The code is available at https://github.com/youweiliang/evit",
        "conference": "ICLR",
        "中文标题": "EViT：通过令牌重组加速视觉变换器",
        "摘要翻译": "视觉变换器（ViTs）将所有图像块作为令牌，并在它们之间构建多头自注意力（MHSA）。完全利用这些图像令牌会带来冗余计算，因为并非所有令牌在MHSA中都是注意力集中的。例如，包含语义上无意义或分散注意力的图像背景的令牌对ViT的预测没有积极贡献。在这项工作中，我们提出在ViT模型的前馈过程中重组图像令牌，这一过程在训练时被集成到ViT中。对于每次前向推理，我们在MHSA和FFN（即前馈网络）模块之间识别出注意力集中的图像令牌，这是由相应的类别令牌注意力指导的。然后，我们通过保留注意力集中的图像令牌并融合不集中的令牌来重组图像令牌，以加速后续的MHSA和FFN计算。因此，我们的方法EViT从两个角度改进了ViTs。首先，在相同数量的输入图像令牌下，我们的方法减少了MHSA和FFN的计算以实现高效推理。例如，DeiT-S的推理速度提高了50%，而其识别准确率仅下降了0.3%，用于ImageNet分类。其次，通过保持相同的计算成本，我们的方法使ViTs能够接受更多的图像令牌作为输入以提高识别准确率，这些图像令牌来自更高分辨率的图像。一个例子是，我们在与普通DeiT-S相同的计算成本下，将DeiT-S的ImageNet分类识别准确率提高了1%。同时，我们的方法没有为ViTs引入更多参数。在标准基准上的实验证明了我们方法的有效性。代码可在https://github.com/youweiliang/evit获取。",
        "领域": "视觉变换器优化、图像分类、高效深度学习",
        "问题": "减少视觉变换器中的冗余计算，提高模型推理效率",
        "动机": "视觉变换器在处理图像时存在大量冗余计算，特别是那些不贡献于最终预测的令牌，这降低了模型的推理效率。",
        "方法": "通过在ViT的前馈过程中重组图像令牌，保留注意力集中的令牌并融合不集中的令牌，以减少冗余计算并加速推理。",
        "关键词": [
            "视觉变换器",
            "令牌重组",
            "高效推理",
            "图像分类",
            "多头自注意力"
        ],
        "涉及的技术概念": {
            "多头自注意力（MHSA）": "用于在视觉变换器中建立图像令牌之间的关系，是模型理解图像内容的关键机制。",
            "前馈网络（FFN）": "在视觉变换器中用于进一步处理自注意力模块输出的特征，增强模型的表达能力。",
            "令牌重组": "通过识别和融合不贡献于预测的令牌，减少模型的计算负担，提高推理效率。"
        },
        "success": true
    },
    {
        "order": 309,
        "title": "Evolutionary Diversity Optimization with Clustering-based Selection for Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2022/poster/5983",
        "abstract": "Reinforcement Learning (RL) has achieved significant successes, which aims to obtain a single policy maximizing the expected cumulative rewards for a given task. However, in many real-world scenarios, e.g., navigating in complex environments and controlling robots, one may need to find a set of policies having both high rewards and diverse behaviors, which can bring better exploration and robust few-shot adaptation. Recently, some methods have been developed by using evolutionary techniques, including iterative reproduction and selection of policies. However, due to the inefficient selection mechanisms, these methods cannot fully guarantee both high quality and diversity. In this paper, we propose EDO-CS, a new Evolutionary Diversity Optimization algorithm with Clustering-based Selection. In each iteration, the policies are divided into several clusters based on their behaviors, and a high-quality policy is selected from each cluster for reproduction. EDO-CS also adaptively balances the importance between quality and diversity in the reproduction process. Experiments on various (i.e., deceptive and multi-modal) continuous control tasks, show the superior performance of EDO-CS over previous methods, i.e., EDO-CS can achieve a set of policies with both high quality and diversity efficiently while previous methods cannot.",
        "conference": "ICLR",
        "中文标题": "基于聚类选择的进化多样性优化强化学习",
        "摘要翻译": "强化学习（RL）已取得显著成功，其目标是为给定任务获得一个最大化预期累积奖励的单一策略。然而，在许多现实世界场景中，例如在复杂环境中导航和控制机器人，可能需要找到一组既具有高奖励又具有多样化行为的策略，这可以带来更好的探索和鲁棒的少样本适应。最近，一些方法通过使用进化技术，包括策略的迭代复制和选择，已经发展起来。然而，由于选择机制的低效，这些方法不能完全保证高质量和多样性。在本文中，我们提出了EDO-CS，一种新的基于聚类选择的进化多样性优化算法。在每次迭代中，策略根据其行为被分成几个聚类，并从每个聚类中选择一个高质量的策略进行复制。EDO-CS还在复制过程中自适应地平衡质量和多样性的重要性。在各种（即欺骗性和多模态）连续控制任务上的实验表明，EDO-CS优于以前的方法，即EDO-CS可以高效地实现一组既高质量又多样化的策略，而以前的方法则不能。",
        "领域": "强化学习、进化算法、机器人控制",
        "问题": "如何在强化学习中高效地找到一组既具有高奖励又具有多样化行为的策略",
        "动机": "解决现有方法在选择机制上的低效问题，无法同时保证策略的高质量和多样性",
        "方法": "提出了一种新的基于聚类选择的进化多样性优化算法（EDO-CS），在每次迭代中根据策略行为进行聚类，并从每个聚类中选择高质量策略进行复制，同时自适应地平衡质量和多样性",
        "关键词": [
            "进化多样性优化",
            "聚类选择",
            "强化学习",
            "连续控制任务",
            "多样化策略"
        ],
        "涉及的技术概念": {
            "进化多样性优化": "一种通过进化算法优化策略多样性的技术，旨在找到一组既高质量又多样化的策略",
            "聚类选择": "基于策略行为将策略分组，并从每个组中选择代表性策略进行复制，以提高选择效率",
            "自适应平衡": "在策略复制过程中动态调整质量和多样性的重要性，以优化整体性能"
        },
        "success": true
    },
    {
        "order": 310,
        "title": "EXACT: Scalable Graph Neural Networks Training via Extreme Activation Compression",
        "html": "https://iclr.cc//virtual/2022/poster/6021",
        "abstract": "Training Graph Neural Networks (GNNs) on large graphs is a fundamental challenge due to the high memory usage, which is mainly occupied by activations (e.g., node embeddings). Previous works usually focus on reducing the number of nodes retained in memory.In parallel, unlike what has been developed for other types of neural networks, training with compressed activation maps is less explored for GNNs. This extension is notoriously difficult to implement due to the miss of necessary tools in common graph learning packages. To unleash the potential of this direction, we provide {  an} optimized GPU implementation which supports training GNNs with compressed activations. Based on the implementation, we propose a memory-efficient framework called ``EXACT'', which for the first time demonstrate the potential and evaluate the feasibility of training GNNs with compressed activations. We systematically analyze the trade-off among the memory saving, time overhead, and accuracy drop. In practice, EXACT can reduce the memory footprint of activations by up to $32\\times$ with $0.2$-$0.5\\%$ accuracy drop and $10$-$25\\%$ time overhead across different models and datasets. We implement EXACT as an extension for Pytorch Geometric and Pytorch. In practice, for Pytorch Geometric, EXACT can trim down the hardware requirement of training a three-layer full-batch GraphSAGE on \\textit{ogbn-products} from a 48GB GPU to a 12GB GPU.",
        "conference": "ICLR",
        "中文标题": "EXACT：通过极端激活压缩实现可扩展的图神经网络训练",
        "摘要翻译": "在大图上训练图神经网络（GNNs）是一个基本挑战，主要因为高内存使用，这主要由激活（例如，节点嵌入）占据。以往的工作通常集中在减少内存中保留的节点数量。与此同时，与其他类型的神经网络不同，使用压缩激活映射进行训练在图神经网络中较少探索。由于常见图学习包中缺乏必要工具，这一扩展的实现异常困难。为了释放这一方向的潜力，我们提供了一个优化的GPU实现，支持使用压缩激活训练GNNs。基于这一实现，我们提出了一个名为'EXACT'的内存高效框架，首次展示了使用压缩激活训练GNNs的潜力并评估了其可行性。我们系统地分析了内存节省、时间开销和准确率下降之间的权衡。在实践中，EXACT可以将激活的内存占用减少高达32倍，准确率下降0.2%-0.5%，时间开销增加10%-25%，适用于不同模型和数据集。我们将EXACT实现为Pytorch Geometric和Pytorch的扩展。在实践中，对于Pytorch Geometric，EXACT可以将训练三层全批量GraphSAGE在ogbn-products上的硬件需求从48GB GPU降低到12GB GPU。",
        "领域": "图神经网络、深度学习优化、大规模图处理",
        "问题": "解决在大图上训练图神经网络时的高内存使用问题",
        "动机": "探索通过压缩激活映射来减少图神经网络训练时的内存占用，释放这一方向的潜力",
        "方法": "提出一个名为'EXACT'的内存高效框架，通过优化的GPU实现支持使用压缩激活训练GNNs，并分析内存节省、时间开销和准确率下降之间的权衡",
        "关键词": [
            "图神经网络",
            "激活压缩",
            "内存优化",
            "GPU实现",
            "大规模图处理"
        ],
        "涉及的技术概念": {
            "激活压缩": "通过压缩激活映射减少内存占用，是EXACT框架的核心技术",
            "GPU优化实现": "支持使用压缩激活训练GNNs的优化GPU实现，解决了常见图学习包中缺乏必要工具的问题",
            "内存-时间-准确率权衡": "系统地分析了内存节省、时间开销和准确率下降之间的权衡，是评估EXACT框架可行性的关键"
        },
        "success": true
    },
    {
        "order": 311,
        "title": "Explainable GNN-Based Models over Knowledge Graphs",
        "html": "https://iclr.cc//virtual/2022/poster/5985",
        "abstract": "Graph Neural Networks (GNNs) are often used to learn transformations of graph data. While effective in practice, such approaches make predictions via numeric manipulations so their output cannot be easily explained symbolically. We propose a new family of GNN-based transformations of graph data that can be trained effectively, but where all predictions can be explained symbolically as logical inferences in Datalog—a well-known rule-based formalism. In particular, we show how to encode an input knowledge graph into a graph with numeric feature vectors, process this graph using a GNN, and decode the result into an output knowledge graph. We use a new class of monotonic GNNs (MGNNs) to ensure that this process is equivalent to a round of application of a set of Datalog rules. We also show that, given an arbitrary MGNN, we can automatically extract rules that completely characterise the transformation. We evaluate our approach by applying it to classification tasks in knowledge graph completion.",
        "conference": "ICLR",
        "中文标题": "基于知识图谱的可解释图神经网络模型",
        "摘要翻译": "图神经网络（GNNs）常用于学习图数据的变换。虽然在实践中有效，但这类方法通过数值操作进行预测，因此其输出不易于用符号解释。我们提出了一种新的基于GNN的图数据变换家族，这些变换可以有效地训练，但所有预测都可以用Datalog——一种著名的基于规则的形式化方法——中的逻辑推理符号化解释。具体来说，我们展示了如何将输入知识图谱编码为带有数值特征向量的图，使用GNN处理该图，并将结果解码为输出知识图谱。我们使用一类新的单调GNNs（MGNNs）来确保这一过程等同于一轮Datalog规则的应用。我们还表明，给定任意MGNN，我们可以自动提取完全描述变换的规则。我们通过将我们的方法应用于知识图谱补全中的分类任务来评估其效果。",
        "领域": "知识图谱补全、图神经网络、符号推理",
        "问题": "如何使图神经网络的预测结果能够被符号化解释",
        "动机": "解决图神经网络预测结果难以用符号解释的问题，提高模型的可解释性",
        "方法": "提出一种新的基于GNN的图数据变换家族，使用单调GNNs（MGNNs）确保变换过程等同于Datalog规则的应用，并能自动提取描述变换的规则",
        "关键词": [
            "可解释性",
            "图神经网络",
            "知识图谱",
            "Datalog",
            "单调GNNs"
        ],
        "涉及的技术概念": {
            "图神经网络（GNNs）": "用于学习图数据的变换，但在本研究中其预测结果不易于用符号解释",
            "单调GNNs（MGNNs）": "一类新的GNNs，用于确保图数据变换过程等同于Datalog规则的应用",
            "Datalog": "一种基于规则的形式化方法，用于符号化解释GNNs的预测结果"
        },
        "success": true
    },
    {
        "order": 312,
        "title": "Explaining Point Processes by Learning Interpretable Temporal Logic Rules",
        "html": "https://iclr.cc//virtual/2022/poster/6151",
        "abstract": "We propose a principled method to learn a set of human-readable logic rules to explain temporal point processes. We assume that the generative mechanisms underlying the temporal point processes are governed by a set of first-order temporal logic rules, as a compact representation of domain knowledge. Our method formulates the rule discovery process from noisy event data as a maximum likelihood problem, and designs an efficient and tractable branch-and-price algorithm to progressively search for new rules and expand existing rules. The proposed algorithm alternates between the rule generation stage and the rule evaluation stage, and uncovers the most important collection of logic rules within a fixed time limit for both synthetic and real event data. In a real healthcare application, we also had human experts (i.e., doctors) verify the learned temporal logic rules and provide further improvements. These expert-revised interpretable rules lead to a point process model which outperforms previous state-of-the-arts for symptom prediction, both in their occurrence times and types. ",
        "conference": "ICLR",
        "中文标题": "通过学习可解释的时间逻辑规则来解释点过程",
        "摘要翻译": "我们提出了一种原则性的方法来学习一组人类可读的逻辑规则，以解释时间点过程。我们假设时间点过程背后的生成机制由一组一阶时间逻辑规则控制，作为领域知识的紧凑表示。我们的方法将从噪声事件数据中发现规则的过程表述为一个最大似然问题，并设计了一种高效且易于处理的分支定价算法，以逐步搜索新规则并扩展现有规则。所提出的算法在规则生成阶段和规则评估阶段之间交替进行，并在固定时间限制内为合成和真实事件数据揭示最重要的逻辑规则集合。在一个真实的医疗应用中，我们还让人工专家（即医生）验证了学习到的时间逻辑规则，并提供了进一步的改进。这些经过专家修订的可解释规则导致了一个点过程模型，在症状预测的出现时间和类型上都优于之前的最先进技术。",
        "领域": "时间序列分析, 医疗健康数据分析, 可解释人工智能",
        "问题": "如何从时间点过程中学习可解释的逻辑规则以解释其生成机制",
        "动机": "为了提高时间点过程模型的可解释性，并使其能够被领域专家理解和验证",
        "方法": "采用最大似然问题表述和分支定价算法，交替进行规则生成和评估，以发现重要的逻辑规则",
        "关键词": [
            "时间点过程",
            "可解释性",
            "逻辑规则学习",
            "分支定价算法",
            "医疗健康数据分析"
        ],
        "涉及的技术概念": {
            "时间点过程": "用于建模事件在时间上的随机发生过程，是分析时间序列数据的基础",
            "一阶时间逻辑规则": "作为领域知识的紧凑表示，用于描述时间点过程的生成机制",
            "分支定价算法": "一种高效的优化算法，用于在规则发现过程中逐步搜索和扩展现有规则"
        },
        "success": true
    },
    {
        "order": 313,
        "title": "Explanations of Black-Box Models based on Directional Feature Interactions",
        "html": "https://iclr.cc//virtual/2022/poster/6731",
        "abstract": "As machine learning algorithms are deployed ubiquitously to a variety of domains, it is imperative to make these often black-box models transparent.  Several recent works explain black-box models by capturing the most influential features for prediction per instance; such explanation methods are univariate, as they characterize importance per feature.  We extend univariate explanation to a higher-order; this enhances explainability, as bivariate methods can capture feature interactions in black-box models, represented as a directed graph.  Analyzing this graph enables us to discover groups of features that are equally important (i.e., interchangeable), while the notion of directionality allows us to identify the most influential features.  We apply our bivariate method on Shapley value explanations, and experimentally demonstrate the ability of directional explanations to discover feature interactions. We show the superiority of our method against state-of-the-art on CIFAR10, IMDB, Census, Divorce, Drug, and gene data.  ",
        "conference": "ICLR",
        "中文标题": "基于方向性特征交互的黑盒模型解释",
        "摘要翻译": "随着机器学习算法被广泛部署到各个领域，使这些往往是黑盒的模型变得透明变得至关重要。最近的一些工作通过捕捉每个预测实例中最具影响力的特征来解释黑盒模型；这些解释方法是单变量的，因为它们描述了每个特征的重要性。我们将单变量解释扩展到更高阶；这增强了可解释性，因为双变量方法可以捕捉黑盒模型中的特征交互，表示为有向图。分析这个图使我们能够发现同等重要（即可互换）的特征组，而方向性的概念使我们能够识别最具影响力的特征。我们将我们的双变量方法应用于Shapley值解释，并通过实验证明了方向性解释在发现特征交互方面的能力。我们在CIFAR10、IMDB、Census、Divorce、Drug和基因数据上展示了我们的方法相对于最先进方法的优越性。",
        "领域": "可解释人工智能、特征交互分析、模型透明度",
        "问题": "如何提高黑盒机器学习模型的可解释性，特别是通过捕捉和分析特征之间的交互作用。",
        "动机": "随着机器学习模型在各个领域的广泛应用，理解这些模型的决策过程变得尤为重要，尤其是在模型被视为'黑盒'的情况下。",
        "方法": "通过将单变量特征重要性解释扩展到双变量，捕捉特征间的交互作用，并将其表示为有向图，进而分析特征的重要性和交互性。",
        "关键词": [
            "黑盒模型解释",
            "特征交互",
            "Shapley值",
            "方向性分析",
            "模型透明度"
        ],
        "涉及的技术概念": {
            "Shapley值": "用于量化每个特征对模型预测的贡献，是解释黑盒模型的重要工具。",
            "方向性特征交互": "通过有向图表示特征间的交互作用，帮助识别最具影响力的特征和特征组。",
            "双变量解释方法": "扩展了传统的单变量特征重要性解释，能够捕捉和分析特征间的交互作用，提高模型的可解释性。"
        },
        "success": true
    },
    {
        "order": 314,
        "title": "Exploiting Class Activation Value for Partial-Label Learning",
        "html": "https://iclr.cc//virtual/2022/poster/5942",
        "abstract": "Partial-label learning (PLL) solves the multi-class classification problem, where each training instance is assigned a set of candidate labels that include the true label. Recent advances showed that PLL can be compatible with deep neural networks, which achieved state-of-the-art performance. However, most of the existing deep PLL methods focus on designing proper training objectives under various assumptions on the collected data, which may limit their performance when the collected data cannot satisfy the adopted assumptions. In this paper, we propose to exploit the learned intrinsic representation of the model to identify the true label in the training process, which does not rely on any assumptions on the collected data. We make two key contributions. As the first contribution, we empirically show that the class activation map (CAM), a simple technique for discriminating the learning patterns of each class in images, could surprisingly be utilized to make accurate predictions on selecting the true label from candidate labels. Unfortunately, as CAM is confined to image inputs with convolutional neural networks, we are yet unable to directly leverage CAM to address the PLL problem with general inputs and models. Thus, as the second contribution, we propose the class activation value (CAV), which owns similar properties of CAM, while CAV is versatile in various types of inputs and models. Building upon CAV, we propose a novel method named CAV Learning (CAVL) that selects the true label by the class with the maximum CAV for model training. Extensive experiments on various datasets demonstrate that our proposed CAVL method achieves state-of-the-art performance.",
        "conference": "ICLR",
        "中文标题": "利用类别激活值进行部分标签学习",
        "摘要翻译": "部分标签学习（PLL）解决了多类分类问题，其中每个训练实例被分配一组包含真实标签的候选标签。最近的进展表明，PLL可以与深度神经网络兼容，实现了最先进的性能。然而，大多数现有的深度PLL方法集中在设计合适的训练目标，基于对收集数据的各种假设，这可能在收集的数据不能满足所采用的假设时限制其性能。在本文中，我们提出利用模型学习的内在表示来在训练过程中识别真实标签，这不依赖于对收集数据的任何假设。我们做出了两个关键贡献。作为第一个贡献，我们实证表明，类别激活图（CAM），一种用于区分图像中每个类学习模式的简单技术，可以出人意料地用于从候选标签中选择真实标签的准确预测。不幸的是，由于CAM仅限于使用卷积神经网络的图像输入，我们还无法直接利用CAM来解决具有一般输入和模型的PLL问题。因此，作为第二个贡献，我们提出了类别激活值（CAV），它拥有与CAM相似的属性，而CAV在各种类型的输入和模型中具有通用性。基于CAV，我们提出了一种名为CAV学习（CAVL）的新方法，该方法通过具有最大CAV的类别选择真实标签进行模型训练。在各种数据集上的大量实验表明，我们提出的CAVL方法实现了最先进的性能。",
        "领域": "多类分类",
        "问题": "如何在部分标签学习中准确识别真实标签",
        "动机": "现有的深度PLL方法依赖于对收集数据的假设，限制了其在数据不满足假设时的性能",
        "方法": "提出类别激活值（CAV）和基于CAV的CAVL方法，通过最大CAV选择真实标签进行模型训练",
        "关键词": [
            "部分标签学习",
            "类别激活值",
            "多类分类",
            "深度神经网络",
            "模型训练"
        ],
        "涉及的技术概念": {
            "类别激活图（CAM）": "用于区分图像中每个类学习模式的技术，本文中用于从候选标签中选择真实标签",
            "类别激活值（CAV）": "拥有与CAM相似属性的技术，适用于各种类型的输入和模型",
            "CAV学习（CAVL）": "基于CAV的新方法，通过具有最大CAV的类别选择真实标签进行模型训练"
        },
        "success": true
    },
    {
        "order": 315,
        "title": "Exploring extreme parameter compression for pre-trained language models",
        "html": "https://iclr.cc//virtual/2022/poster/6449",
        "abstract": "Recent work explored the potential of large-scale Transformer-based pre-trained models, especially Pre-trained Language Models (PLMs) in natural language processing. This raises many concerns from various perspectives, e.g.,  financial costs and carbon emissions. Compressing PLMs like BERT with negligible performance loss for faster inference and cheaper deployment has attracted much attention. In this work, we aim to explore larger compression ratios for PLMs, among which tensor decomposition is a potential but under-investigated one. By comparing existing decomposition methods, Tucker decomposition is found to be parameter-efficient for compression.  Two decomposition and reconstruction protocols are further proposed to improve the effectiveness and efficiency of Tucker decomposition in parameter compression.Our compressed BERT with ${1}/{7}$ parameters in Transformer layers performs on-par with,  sometimes slightly better than the original BERT in GLUE benchmark. A tiny version achieves  96.7\\%  performance of  BERT-base with $ {1}/{48} $ encoder parameters (i.e., less than 2M parameters excluding the embedding layer) and  \\textbf{$2.7 \\times$} faster on inference. To show that the proposed method is orthogonal to existing compression methods like knowledge distillation, we also explore the benefit of the proposed method on a distilled BERT. ",
        "conference": "ICLR",
        "中文标题": "探索预训练语言模型的极端参数压缩",
        "摘要翻译": "最近的工作探索了基于Transformer的大规模预训练模型，尤其是预训练语言模型（PLMs）在自然语言处理中的潜力。这从多个角度引发了许多关注，例如财务成本和碳排放。压缩如BERT这样的PLMs，以几乎不损失性能的情况下实现更快的推理和更便宜的部署，已经吸引了大量关注。在这项工作中，我们旨在探索PLMs的更大压缩比例，其中张量分解是一种潜力巨大但研究不足的方法。通过比较现有的分解方法，发现Tucker分解在参数压缩方面效率较高。进一步提出了两种分解和重建协议，以提高Tucker分解在参数压缩中的有效性和效率。我们在Transformer层中压缩BERT的参数至原来的1/7，在GLUE基准测试中表现与原版BERT相当，有时甚至略好。一个微型版本实现了BERT-base性能的96.7%，编码器参数仅为原来的1/48（即不包括嵌入层的参数少于2M），推理速度快2.7倍。为了展示所提出的方法与现有压缩方法（如知识蒸馏）的正交性，我们还探索了所提方法在蒸馏BERT上的益处。",
        "领域": "自然语言处理与视觉结合",
        "问题": "如何在几乎不损失性能的情况下，实现预训练语言模型的极端参数压缩。",
        "动机": "减少预训练语言模型的财务成本和碳排放，同时保持或提升模型性能。",
        "方法": "采用Tucker分解方法进行参数压缩，并提出两种分解和重建协议以提高压缩效率和效果。",
        "关键词": [
            "参数压缩",
            "Tucker分解",
            "预训练语言模型"
        ],
        "涉及的技术概念": {
            "Tucker分解": "一种高效的张量分解方法，用于在压缩预训练语言模型参数时保持模型性能。",
            "参数压缩": "减少模型参数数量的技术，旨在降低模型部署和运行的成本。",
            "知识蒸馏": "一种模型压缩技术，通过训练一个小模型来模仿大模型的行为，此处用于展示所提方法的正交性。"
        },
        "success": true
    },
    {
        "order": 316,
        "title": "Exploring Memorization in Adversarial Training",
        "html": "https://iclr.cc//virtual/2022/poster/6359",
        "abstract": "Deep learning models have a propensity for fitting the entire training set even with random labels, which requires memorization of every training sample. In this paper, we explore the memorization effect in adversarial training (AT) for promoting a deeper understanding of model capacity, convergence, generalization, and especially robust overfitting of the adversarially trained models. We first demonstrate that deep networks have sufficient capacity to memorize adversarial examples of training data with completely random labels, but not all AT algorithms can converge under the extreme circumstance. Our study of AT with random labels motivates further analyses on the convergence and generalization of AT. We find that some AT approaches suffer from a gradient instability issue and the recently suggested complexity measures cannot explain robust generalization by considering models trained on random labels. Furthermore, we identify a significant drawback of memorization in AT that it could result in robust overfitting. We then propose a new mitigation algorithm motivated by detailed memorization analyses. Extensive experiments on various datasets validate the effectiveness of the proposed method. ",
        "conference": "ICLR",
        "中文标题": "探索对抗训练中的记忆效应",
        "摘要翻译": "深度学习模型倾向于拟合整个训练集，即使标签是随机的，这需要记忆每一个训练样本。在本文中，我们探索了对抗训练（AT）中的记忆效应，以促进对模型容量、收敛性、泛化能力，特别是对抗训练模型的鲁棒过拟合的更深理解。我们首先证明了深度网络有足够的能力记忆带有完全随机标签的训练数据的对抗样本，但并非所有的AT算法都能在这种极端情况下收敛。我们对带有随机标签的AT的研究激发了对AT收敛性和泛化能力的进一步分析。我们发现一些AT方法存在梯度不稳定性问题，并且最近提出的复杂性度量无法通过考虑在随机标签上训练的模型来解释鲁棒泛化。此外，我们识别了AT中记忆效应的一个显著缺点，即它可能导致鲁棒过拟合。然后，我们基于详细的记忆分析提出了一种新的缓解算法。在各种数据集上的大量实验验证了所提方法的有效性。",
        "领域": "对抗学习、深度学习理论、模型泛化",
        "问题": "探索对抗训练中的记忆效应及其对模型容量、收敛性、泛化能力和鲁棒过拟合的影响",
        "动机": "理解对抗训练中模型的记忆能力如何影响其性能，特别是鲁棒过拟合问题",
        "方法": "通过实验证明深度网络记忆对抗样本的能力，分析AT算法的收敛性和泛化能力，提出基于记忆分析的新缓解算法",
        "关键词": [
            "对抗训练",
            "记忆效应",
            "鲁棒过拟合",
            "模型泛化",
            "深度学习理论"
        ],
        "涉及的技术概念": {
            "对抗训练（AT）": "一种通过引入对抗样本来提高模型鲁棒性的训练方法",
            "记忆效应": "模型记忆训练数据的能力，特别是在对抗训练中对对抗样本的记忆",
            "鲁棒过拟合": "在对抗训练中，模型在训练数据上表现良好但在未见数据上表现差的现象"
        },
        "success": true
    },
    {
        "order": 317,
        "title": "Exploring the Limits of Large Scale Pre-training",
        "html": "https://iclr.cc//virtual/2022/poster/6231",
        "abstract": "Recent developments in large-scale machine learning suggest that by scaling up data, model size and training time properly, one might  observe that improvements in pre-training would transfer favorably to  most downstream tasks. In this work we systematically study this phenomena and establish that, as we increase the upstream accuracy, performance of downstream tasks \\emph{saturates}. In particular, we investigate more than 4800 experiments on Vision Transformers, MLP-Mixers and ResNets with number of parameters ranging from ten million to ten billion, trained on the largest scale of available image data (JFT, ImageNet21K) and evaluated on more than 20 downstream image recognition tasks. We propose a model for downstream performance  that reflects the saturation phenomena and captures the nonlinear relationship in performance of upstream and downstream tasks. Delving deeper to understand the reasons that give rise to these phenomena, we show that the observed saturation behavior is closely related to the way that representations evolve through the layers of the models. We showcase an even more extreme scenario where performance on upstream and downstream are at odds with each other. That is, in order to have a better downstream performance, we need to hurt upstream accuracy.",
        "conference": "ICLR",
        "中文标题": "探索大规模预训练的极限",
        "摘要翻译": "近期大规模机器学习的发展表明，通过适当扩大数据规模、模型规模和训练时间，可以观察到预训练的改进会良好地迁移到大多数下游任务中。在这项工作中，我们系统地研究了这一现象，并确定随着上游准确率的提高，下游任务的性能会达到饱和。具体来说，我们对超过4800个实验进行了调查，这些实验涉及视觉变换器、MLP-Mixers和ResNets，参数数量从一千万到一百亿不等，训练使用了最大规模的可用图像数据（JFT、ImageNet21K），并在超过20个下游图像识别任务上进行了评估。我们提出了一个反映饱和现象并捕捉上游和下游任务性能之间非线性关系的下游性能模型。为了更深入地理解导致这些现象的原因，我们展示了观察到的饱和行为与表示通过模型各层演变的方式密切相关。我们展示了一个更为极端的情景，其中上游和下游的性能相互矛盾。也就是说，为了获得更好的下游性能，我们需要损害上游的准确率。",
        "领域": "视觉变换器",
        "问题": "研究大规模预训练模型在下游任务中的性能饱和现象",
        "动机": "探索大规模预训练模型性能提升的极限及其对下游任务的影响",
        "方法": "系统性地研究了超过4800个实验，涉及不同规模的视觉变换器、MLP-Mixers和ResNets模型，在最大规模的图像数据上进行训练，并在多个下游任务上评估性能",
        "关键词": [
            "大规模预训练",
            "性能饱和",
            "视觉变换器"
        ],
        "涉及的技术概念": {
            "视觉变换器": "一种基于自注意力机制的模型架构，用于处理图像数据",
            "性能饱和": "指随着上游任务准确率的提高，下游任务性能不再显著提升的现象",
            "非线性关系": "上游和下游任务性能之间不是简单的线性关系，而是存在复杂的相互作用"
        },
        "success": true
    },
    {
        "order": 318,
        "title": "Exposing the Implicit Energy Networks behind Masked Language Models via Metropolis--Hastings",
        "html": "https://iclr.cc//virtual/2022/poster/6637",
        "abstract": "While recent work has shown that scores from models trained by the ubiquitous masked language modeling (MLM) objective effectively discriminate probable from improbable sequences, it is still an open question if these MLMs specify a principled probability distribution over the space of possible sequences. In this paper, we interpret MLMs as energy-based sequence models and propose two energy parametrizations derivable from the trained MLMs. In order to draw samples correctly from these models, we develop a tractable sampling scheme based on the Metropolis--Hastings Monte Carlo algorithm. In our approach, samples are proposed from the same masked conditionals used for training the masked language models, and they are accepted or rejected based on their energy values according to the target distribution. We validate the effectiveness of the proposed parametrizations by exploring the quality of samples drawn from these energy-based models for both open-ended unconditional generation and a conditional generation task of machine translation. We theoretically and empirically justify our sampling algorithm by showing that the masked conditionals on their own do not yield a Markov chain whose stationary distribution is that of our target distribution, and our approach generates higher quality samples than other recently proposed undirected generation approaches (Wang et al., 2019, Ghazvininejad et al., 2019).",
        "conference": "ICLR",
        "中文标题": "通过Metropolis--Hastings揭示掩码语言模型背后的隐性能量网络",
        "摘要翻译": "尽管最近的研究表明，通过普遍使用的掩码语言建模（MLM）目标训练的模型评分能有效区分可能序列与不可能序列，但这些MLM是否在可能的序列空间上指定了一个原则性的概率分布仍是一个开放性问题。在本文中，我们将MLM解释为基于能量的序列模型，并提出了两种可从训练好的MLM中导出的能量参数化方法。为了正确地从这些模型中抽取样本，我们基于Metropolis--Hastings蒙特卡洛算法开发了一种可行的抽样方案。在我们的方法中，样本是从用于训练掩码语言模型的相同掩码条件中提出的，并根据目标分布的能量值接受或拒绝这些样本。我们通过探索从这些基于能量的模型中抽取的样本在开放式无条件生成和机器翻译的条件生成任务中的质量，验证了所提出参数化方法的有效性。我们从理论上和实证上证明了我们的抽样算法的合理性，表明单独的掩码条件不会产生一个其稳态分布为目标分布的马尔可夫链，并且我们的方法比其他最近提出的无向生成方法（Wang等人，2019；Ghazvininejad等人，2019）生成了更高质量的样本。",
        "领域": "自然语言处理与视觉结合, 语言模型, 序列生成",
        "问题": "掩码语言模型是否能在可能的序列空间上指定一个原则性的概率分布",
        "动机": "探索掩码语言模型作为基于能量的序列模型的潜力，并开发有效的抽样方法",
        "方法": "将MLM解释为基于能量的序列模型，提出两种能量参数化方法，并基于Metropolis--Hastings蒙特卡洛算法开发抽样方案",
        "关键词": [
            "掩码语言模型",
            "能量基础模型",
            "Metropolis--Hastings",
            "序列生成",
            "机器翻译"
        ],
        "涉及的技术概念": {
            "掩码语言建模（MLM）": "一种训练语言模型的方法，通过预测被掩码的单词来学习语言表示",
            "基于能量的模型": "一种模型，其中配置的概率由其能量决定，能量越低，概率越高",
            "Metropolis--Hastings算法": "一种马尔可夫链蒙特卡洛方法，用于从复杂的概率分布中抽取样本"
        },
        "success": true
    },
    {
        "order": 319,
        "title": "Expressiveness and Approximation Properties of Graph Neural Networks",
        "html": "https://iclr.cc//virtual/2022/poster/6804",
        "abstract": "Characterizing the separation power of graph neural networks (GNNs) provides an understanding of their limitations for graph learning tasks. Results regarding separation power are, however, usually geared at specific GNNs architectures, and tools for understanding arbitrary GNN architectures are generally lacking. We provide an elegant way to easily obtain bounds on the separation power of GNNs in terms of the Weisfeiler-Leman (WL) tests, which have become the yardstick to measure the separation power of GNNs. The crux is to view GNNs as expressions in a procedural tensor language describing the computations in the layers of the GNNs. Then, by a simple analysis of the obtained expressions, in terms of the number of indexes used and the nesting depth of summations, bounds on the separation power in terms of the WL-tests readily follow. We use tensor language to define Higher-Order Message-Passing Neural Networks (or k-MPNNs), a natural extension of MPNNs. Furthermore, the tensor language point of view allows for the derivation of universality results for classes of GNNs in a natural way. Our approach provides a toolbox with which GNN architecture designers can analyze the separation power of their GNNs, without needing to know the intricacies of the WL-tests. We also provide insights in what is needed to boost the separation power of GNNs.",
        "conference": "ICLR",
        "中文标题": "图神经网络的表达力与近似性质",
        "摘要翻译": "描述图神经网络（GNNs）的分离能力有助于理解其在图学习任务中的局限性。然而，关于分离能力的结果通常针对特定的GNN架构，且普遍缺乏理解任意GNN架构的工具。我们提供了一种优雅的方法，可以轻松地根据Weisfeiler-Leman（WL）测试获得GNN分离能力的界限，WL测试已成为衡量GNN分离能力的标准。关键在于将GNN视为描述GNN层中计算的过程张量语言中的表达式。然后，通过对获得的表达式进行简单分析，根据使用的索引数量和求和嵌套深度，WL测试的分离能力界限随即得出。我们使用张量语言定义了高阶消息传递神经网络（或k-MPNNs），这是MPNNs的自然扩展。此外，张量语言的观点允许以自然方式推导GNN类别的普遍性结果。我们的方法提供了一个工具箱，GNN架构设计师可以用它来分析其GNN的分离能力，而无需了解WL测试的复杂性。我们还提供了关于如何提升GNN分离能力的见解。",
        "领域": "图神经网络、图学习、消息传递神经网络",
        "问题": "理解图神经网络（GNNs）的分离能力及其局限性",
        "动机": "为了提供一种通用的方法来分析和比较不同GNN架构的分离能力，而不需要深入了解Weisfeiler-Leman测试的复杂性",
        "方法": "将GNN视为过程张量语言中的表达式，通过分析这些表达式的结构来推导分离能力的界限",
        "关键词": [
            "图神经网络",
            "分离能力",
            "Weisfeiler-Leman测试",
            "高阶消息传递神经网络",
            "张量语言"
        ],
        "涉及的技术概念": {
            "Weisfeiler-Leman测试": "用于衡量图神经网络分离能力的标准方法",
            "过程张量语言": "描述图神经网络层中计算的语言，用于分析分离能力",
            "高阶消息传递神经网络": "消息传递神经网络的自然扩展，通过张量语言定义"
        },
        "success": true
    },
    {
        "order": 320,
        "title": "Expressivity of Emergent Languages is a Trade-off between Contextual Complexity and Unpredictability",
        "html": "https://iclr.cc//virtual/2022/poster/6566",
        "abstract": "Researchers are using deep learning models to explore the emergence of language in various language games, where agents interact and develop an emergent language to solve tasks. We focus on the factors that determine the expressivity of emergent languages, which reflects the amount of information about input spaces those languages are capable of encoding. We measure the expressivity of emergent languages based on the generalisation performance across different games, and demonstrate that the expressivity of emergent languages is a trade-off between the complexity and unpredictability of the context those languages emerged from. Another contribution of this work is the discovery of message type collapse, i.e. the number of unique messages is lower than that of inputs. We also show that using the contrastive loss proposed by Chen et al. (2020) can alleviate this problem.",
        "conference": "ICLR",
        "中文标题": "涌现语言的表达能力是上下文复杂性与不可预测性之间的权衡",
        "摘要翻译": "研究人员正在使用深度学习模型探索各种语言游戏中语言的涌现现象，其中智能体通过互动发展出一种涌现语言来解决任务。我们关注于决定涌现语言表达能力的因素，这反映了这些语言能够编码输入空间信息量的能力。我们基于不同游戏中的泛化性能来测量涌现语言的表达能力，并证明涌现语言的表达能力是这些语言所涌现的上下文的复杂性与不可预测性之间的权衡。这项工作的另一个贡献是发现了消息类型崩溃，即唯一消息的数量低于输入的数量。我们还展示了使用Chen等人（2020年）提出的对比损失可以缓解这个问题。",
        "领域": "自然语言处理与视觉结合, 深度学习模型训练, 语言游戏模拟",
        "问题": "探索决定涌现语言表达能力的因素及其与上下文复杂性和不可预测性的关系",
        "动机": "理解并量化涌现语言如何编码输入空间信息，以及如何优化这些语言的表达能力",
        "方法": "基于不同语言游戏的泛化性能测量涌现语言的表达能力，并分析其与上下文特性的关系，使用对比损失缓解消息类型崩溃问题",
        "关键词": [
            "涌现语言",
            "表达能力",
            "上下文复杂性",
            "对比损失",
            "语言游戏"
        ],
        "涉及的技术概念": {
            "涌现语言": "在智能体互动过程中自然发展出的通信系统，用于任务解决",
            "表达能力": "衡量语言能够编码和传达信息量的能力",
            "对比损失": "一种用于优化模型训练的目标函数，通过对比正负样本来提高模型的区分能力"
        },
        "success": true
    },
    {
        "order": 321,
        "title": "ExT5: Towards Extreme Multi-Task Scaling for Transfer Learning",
        "html": "https://iclr.cc//virtual/2022/poster/7043",
        "abstract": "Despite the recent success of multi-task learning and transfer learning for natural language processing (NLP), few works have systematically studied the effect of scaling up the number of tasks during pre-training. Towards this goal, this paper introduces ExMix (Extreme Mixture): a massive collection of 107 supervised NLP tasks across diverse domains and task-families. Using ExMix, we study the effect of multi-task pre-training at the largest scale to date, and analyze co-training transfer amongst common families of tasks. Through this analysis, we show that manually curating an ideal set of tasks for multi-task pre-training is not straightforward, and that multi-task scaling can vastly improve models on its own. Finally, we propose ExT5: a model pre-trained using a multi-task objective of self-supervised span denoising and supervised ExMix. Via extensive experiments, we show that ExT5 outperforms strong T5 baselines on SuperGLUE, GEM, Rainbow, Closed-Book QA tasks, and several tasks outside of ExMix. ExT5 also significantly improves sample efficiency while pre-training.",
        "conference": "ICLR",
        "中文标题": "ExT5：面向迁移学习的极端多任务扩展",
        "摘要翻译": "尽管多任务学习和迁移学习在自然语言处理（NLP）领域取得了近期的成功，但很少有工作系统地研究在预训练过程中扩大任务数量的效果。为了实现这一目标，本文介绍了ExMix（极端混合）：一个包含107个跨不同领域和任务家族的监督NLP任务的大规模集合。使用ExMix，我们研究了迄今为止最大规模的多任务预训练效果，并分析了常见任务家族之间的共同训练迁移。通过这一分析，我们表明手动策划一个理想的多任务预训练任务集并不简单，而且多任务扩展本身可以极大地改进模型。最后，我们提出了ExT5：一个使用自监督跨度去噪和监督ExMix的多任务目标预训练的模型。通过大量实验，我们显示ExT5在SuperGLUE、GEM、Rainbow、闭卷问答任务以及ExMix之外的几个任务上优于强大的T5基线。ExT5在预训练过程中还显著提高了样本效率。",
        "领域": "自然语言处理与视觉结合, 迁移学习, 多任务学习",
        "问题": "研究在预训练过程中扩大任务数量对多任务学习和迁移学习效果的影响",
        "动机": "探索多任务预训练在极端规模下的效果，以及如何通过多任务扩展提升模型性能",
        "方法": "引入ExMix任务集合进行多任务预训练，提出ExT5模型结合自监督和监督学习目标",
        "关键词": [
            "多任务学习",
            "迁移学习",
            "自然语言处理",
            "预训练",
            "ExT5"
        ],
        "涉及的技术概念": {
            "ExMix": "一个包含107个监督NLP任务的集合，用于研究多任务预训练的效果",
            "多任务预训练": "在预训练阶段同时学习多个任务，以提高模型的泛化能力和效率",
            "自监督跨度去噪": "一种自监督学习方法，通过预测被噪声掩盖的文本跨度来预训练模型"
        },
        "success": true
    },
    {
        "order": 322,
        "title": "Extending the WILDS Benchmark for Unsupervised Adaptation",
        "html": "https://iclr.cc//virtual/2022/poster/6963",
        "abstract": "Machine learning systems deployed in the wild are often trained on a source distribution but deployed on a different target distribution. Unlabeled data can be a powerful point of leverage for mitigating these distribution shifts, as it is frequently much more available than labeled data and can often be obtained from distributions beyond the source distribution as well. However, existing distribution shift benchmarks with unlabeled data do not reflect the breadth of scenarios that arise in real-world applications. In this work, we present the WILDS 2.0 update, which extends 8 of the 10 datasets in the WILDS benchmark of distribution shifts to include curated unlabeled data that would be realistically obtainable in deployment. These datasets span a wide range of applications (from histology to wildlife conservation), tasks (classification, regression, and detection), and modalities (photos, satellite images, microscope slides, text, molecular graphs). The update maintains consistency with the original WILDS benchmark by using identical labeled training, validation, and test sets, as well as identical evaluation metrics. We systematically benchmark state-of-the-art methods that use unlabeled data, including domain-invariant, self-training, and self-supervised methods, and show that their success on WILDS is limited. To facilitate method development, we provide an open-source package that automates data loading and contains the model architectures and methods used in this paper. Code and leaderboards are available at https://wilds.stanford.edu.",
        "conference": "ICLR",
        "中文标题": "扩展WILDS基准以支持无监督适应",
        "摘要翻译": "在野外部署的机器学习系统通常在源分布上训练，但在不同的目标分布上部署。未标记数据可以成为缓解这些分布偏移的有力杠杆，因为它通常比标记数据更容易获得，并且通常也可以从源分布之外的其他分布中获得。然而，现有的带有未标记数据的分布偏移基准并未反映出实际应用中出现的各种场景。在这项工作中，我们提出了WILDS 2.0更新，该更新扩展了WILDS分布偏移基准中的10个数据集中的8个，以包括在部署中实际可获得的精选未标记数据。这些数据集涵盖了广泛的应用（从组织学到野生动物保护）、任务（分类、回归和检测）和模态（照片、卫星图像、显微镜幻灯片、文本、分子图）。通过使用相同的标记训练、验证和测试集，以及相同的评估指标，该更新保持了与原始WILDS基准的一致性。我们系统地基准测试了使用未标记数据的最先进方法，包括领域不变、自训练和自监督方法，并表明它们在WILDS上的成功是有限的。为了促进方法开发，我们提供了一个开源包，该包自动化了数据加载，并包含了本文中使用的模型架构和方法。代码和排行榜可在https://wilds.stanford.edu上获取。",
        "领域": "无监督学习、领域适应、计算机视觉",
        "问题": "如何利用未标记数据来缓解机器学习模型在源分布和目标分布之间的分布偏移问题",
        "动机": "现有的分布偏移基准未能充分反映实际应用中的多样性，限制了未标记数据在缓解分布偏移方面的潜力",
        "方法": "扩展WILDS基准以包括精选的未标记数据，并系统地评估了包括领域不变、自训练和自监督在内的多种方法",
        "关键词": [
            "无监督学习",
            "领域适应",
            "WILDS基准",
            "分布偏移",
            "机器学习"
        ],
        "涉及的技术概念": {
            "领域不变方法": "旨在减少源分布和目标分布之间差异的技术，以提高模型在目标分布上的性能",
            "自训练方法": "利用模型自身的预测来生成伪标签，然后使用这些伪标签来进一步训练模型的技术",
            "自监督方法": "通过设计辅助任务来从未标记数据中学习有用表示的技术，这些表示可以用于下游任务"
        },
        "success": true
    },
    {
        "order": 323,
        "title": "F8Net: Fixed-Point 8-bit Only Multiplication for Network Quantization",
        "html": "https://iclr.cc//virtual/2022/poster/5943",
        "abstract": "Neural network quantization is a promising compression technique to reduce memory footprint and save energy consumption, potentially leading to real-time inference. However, there is a performance gap between quantized and full-precision models. To reduce it, existing quantization approaches require high-precision INT32 or full-precision multiplication during inference for scaling or dequantization. This introduces a noticeable cost in terms of memory, speed, and required energy. To tackle these issues, we present F8Net, a novel quantization framework consisting in only ﬁxed-point 8-bit multiplication. To derive our method, we ﬁrst discuss the advantages of ﬁxed-point multiplication with different formats of ﬁxed-point numbers and study the statistical behavior of the associated ﬁxed-point numbers. Second, based on the statistical and algorithmic analysis, we apply different ﬁxed-point formats for weights and activations of different layers. We introduce a novel algorithm to automatically determine the right format for each layer during training. Third, we analyze a previous quantization algorithm—parameterized clipping activation (PACT)—and reformulate it using ﬁxed-point arithmetic. Finally, we unify the recently proposed method for quantization ﬁne-tuning and our ﬁxed-point approach to show the potential of our method. We verify F8Net on ImageNet for MobileNet V1/V2 and ResNet18/50. Our approach achieves comparable and better performance, when compared not only to existing quantization techniques with INT32 multiplication or ﬂoating point arithmetic, but also to the full-precision counterparts, achieving state-of-the-art performance.",
        "conference": "ICLR",
        "中文标题": "F8Net：仅使用定点8位乘法的网络量化方法",
        "摘要翻译": "神经网络量化是一种有前景的压缩技术，旨在减少内存占用并节省能源消耗，可能实现实时推理。然而，量化模型与全精度模型之间存在性能差距。为了缩小这一差距，现有的量化方法在推理过程中需要高精度的INT32或全精度乘法进行缩放或去量化，这在内存、速度和所需能源方面引入了显著成本。为了解决这些问题，我们提出了F8Net，一种仅使用定点8位乘法的新型量化框架。为了推导我们的方法，我们首先讨论了不同格式定点数乘法的优势，并研究了相关定点数的统计行为。其次，基于统计和算法分析，我们对不同层的权重和激活应用了不同的定点格式。我们引入了一种新算法，在训练过程中自动为每一层确定正确的格式。第三，我们分析了先前的量化算法——参数化裁剪激活（PACT）——并使用定点算术重新表述了它。最后，我们将最近提出的量化微调方法与我们的定点方法统一起来，展示了我们方法的潜力。我们在ImageNet上对MobileNet V1/V2和ResNet18/50验证了F8Net。与不仅包括使用INT32乘法或浮点算术的现有量化技术，还包括全精度模型相比，我们的方法实现了可比甚至更好的性能，达到了最先进的性能。",
        "领域": "神经网络量化、模型压缩、实时推理",
        "问题": "量化模型与全精度模型之间的性能差距，以及现有量化方法在推理过程中需要高精度乘法的问题",
        "动机": "减少量化模型的内存占用和能源消耗，同时缩小与全精度模型的性能差距",
        "方法": "提出了一种仅使用定点8位乘法的量化框架F8Net，通过分析不同定点格式的优势和统计行为，应用不同定点格式于不同层的权重和激活，并引入算法自动确定每层的最佳格式",
        "关键词": [
            "神经网络量化",
            "定点乘法",
            "模型压缩",
            "实时推理",
            "F8Net"
        ],
        "涉及的技术概念": {
            "定点8位乘法": "在F8Net中用于减少量化过程中的计算复杂度和能源消耗，同时保持模型性能",
            "参数化裁剪激活（PACT）": "一种先前的量化算法，F8Net通过定点算术重新表述了该算法以提高效率",
            "量化微调": "F8Net将量化微调方法与定点方法统一，以优化模型性能"
        },
        "success": true
    },
    {
        "order": 324,
        "title": "FairCal: Fairness Calibration for Face Verification",
        "html": "https://iclr.cc//virtual/2022/poster/6347",
        "abstract": "Despite being widely used, face recognition models suffer from bias: the probability of a false positive (incorrect face match) strongly depends on sensitive attributes such as the ethnicity of the face. As a result, these models can disproportionately and negatively impact minority groups, particularly when used by law enforcement. The majority of bias reduction methods have several drawbacks: they use an end-to-end retraining approach, may not be feasible due to privacy issues, and often reduce accuracy. An alternative approach is post-processing methods that build fairer decision classifiers using the features of pre-trained models, thus avoiding the cost of retraining. However, they still have drawbacks: they reduce accuracy (AGENDA, FTC), or require retuning for different false positive rates (FSN). In this work, we introduce the Fairness Calibration (FairCal) method, a post-training approach that simultaneously: (i) increases model accuracy (improving the state-of-the-art), (ii) produces fairly-calibrated probabilities, (iii) significantly reduces the gap in the false positive rates, (iv) does not require knowledge of the sensitive attribute, and (v) does not require retraining, training an additional model or retuning. We apply it to the task of Face Verification, and obtain state-of-the-art results with all the above advantages.",
        "conference": "ICLR",
        "中文标题": "FairCal: 人脸验证的公平性校准",
        "摘要翻译": "尽管人脸识别模型被广泛使用，但它们存在偏见：错误匹配（错误的人脸匹配）的概率强烈依赖于敏感属性，如人脸的种族。因此，这些模型可能对少数群体产生不成比例的负面影响，尤其是在执法部门使用时。大多数减少偏见的方法有几个缺点：它们使用端到端的重新训练方法，可能由于隐私问题而不可行，并且往往会降低准确性。另一种方法是后处理方法，它们使用预训练模型的特征构建更公平的决策分类器，从而避免重新训练的成本。然而，它们仍有缺点：它们降低了准确性（AGENDA, FTC），或需要为不同的错误匹配率重新调整（FSN）。在这项工作中，我们引入了公平性校准（FairCal）方法，一种训练后方法，同时：（i）提高模型准确性（改进现有技术），（ii）产生公平校准的概率，（iii）显著减少错误匹配率的差距，（iv）不需要知道敏感属性，以及（v）不需要重新训练、训练额外模型或重新调整。我们将其应用于人脸验证任务，并在上述所有优势下获得了最先进的结果。",
        "领域": "人脸识别",
        "问题": "解决人脸识别模型中的偏见问题，特别是在不同种族群体间的错误匹配率差异",
        "动机": "减少人脸识别技术对不同种族群体的不公平影响，特别是在执法等敏感应用中",
        "方法": "提出了一种名为FairCal的训练后公平性校准方法，该方法无需重新训练或知道敏感属性，即可提高准确性并减少错误匹配率的差距",
        "关键词": [
            "公平性校准",
            "人脸验证",
            "偏见减少",
            "训练后方法",
            "错误匹配率"
        ],
        "涉及的技术概念": {
            "公平性校准": "一种训练后处理方法，旨在减少模型预测中的偏见，特别是在不同敏感属性群体间的错误匹配率差异",
            "人脸验证": "确认两张人脸图像是否属于同一个人的过程，是人脸识别技术的一个应用场景",
            "错误匹配率": "在人脸验证中，错误地将两张不同人脸图像识别为同一人的比率，是衡量模型性能的重要指标"
        },
        "success": true
    },
    {
        "order": 325,
        "title": "Fairness Guarantees under Demographic Shift",
        "html": "https://iclr.cc//virtual/2022/poster/6666",
        "abstract": "Recent studies have demonstrated that using machine learning for social applications can lead to injustice in the form of racist, sexist, and otherwise unfair and discriminatory outcomes. To address this challenge, recent machine learning algorithms have been designed to limit the likelihood such unfair behaviors will occur. However, these approaches typically assume the data used for training is representative of what will be encountered once the model is deployed, thus limiting their usefulness. In particular, if certain subgroups of the population become more or less probable after the model is deployed (a phenomenon we call demographic shift), the fair-ness assurances provided by prior algorithms are often invalid. We consider the impact of demographic shift and present a class of algorithms, called Shifty algorithms, that provide high-confidence behavioral guarantees that hold under demographic shift. Shifty is the first technique of its kind and demonstrates an effective strategy for designing algorithms to overcome the challenges demographic shift poses. We evaluate Shifty-ttest, an implementation of Shifty based on Student’s 𝑡-test, and, using a real-world data set of university entrance exams and subsequent student success, show that the models output by our algorithm avoid unfair bias under demo-graphic shift, unlike existing methods. Our experiments demonstrate that our algorithm’s high-confidence fairness guarantees are valid in practice and that our algorithm is an effective tool for training models that are fair when demographic shift occurs.",
        "conference": "ICLR",
        "中文标题": "人口统计变化下的公平性保证",
        "摘要翻译": "最近的研究表明，将机器学习应用于社会领域可能导致不公正的结果，如种族主义、性别歧视以及其他不公平和歧视性后果。为了应对这一挑战，最近的机器学习算法被设计用来限制此类不公平行为发生的可能性。然而，这些方法通常假设用于训练的数据代表了模型部署后将遇到的情况，这限制了它们的实用性。特别是，如果模型部署后某些人口子群的概率增加或减少（我们称这种现象为人口统计变化），先前算法提供的公平性保证往往无效。我们考虑了人口统计变化的影响，并提出了一类名为Shifty的算法，这些算法提供了在人口统计变化下仍然有效的高置信度行为保证。Shifty是此类技术中的首创，展示了设计算法以克服人口统计变化带来的挑战的有效策略。我们评估了Shifty-ttest，这是基于学生t检验的Shifty实现，并使用了一个包含大学入学考试及后续学生成功真实世界数据集，展示了我们的算法输出的模型在人口统计变化下避免了不公平偏见，与现有方法不同。我们的实验证明，我们的算法的高置信度公平性保证在实践中是有效的，并且我们的算法是训练在人口统计变化发生时仍保持公平的模型的有效工具。",
        "领域": "公平机器学习、社会计算、算法偏见缓解",
        "问题": "机器学习算法在人口统计变化下可能产生不公平和歧视性结果的问题",
        "动机": "解决机器学习算法在面对人口统计变化时公平性保证失效的问题",
        "方法": "提出了一类名为Shifty的算法，提供在人口统计变化下有效的高置信度行为保证，并评估了基于学生t检验的Shifty-ttest实现",
        "关键词": [
            "公平机器学习",
            "人口统计变化",
            "算法偏见",
            "高置信度保证",
            "Shifty算法"
        ],
        "涉及的技术概念": {
            "Shifty算法": "一类旨在在人口统计变化下提供高置信度行为保证的算法",
            "人口统计变化": "模型部署后某些人口子群概率增加或减少的现象，影响算法公平性保证的有效性",
            "高置信度行为保证": "算法在特定条件下（如人口统计变化）仍能保持其公平性和有效性的保证"
        },
        "success": true
    },
    {
        "order": 326,
        "title": "Fairness in Representation for Multilingual NLP: Insights from Controlled Experiments on Conditional Language Modeling",
        "html": "https://iclr.cc//virtual/2022/poster/5935",
        "abstract": "We perform systematically and fairly controlled experiments with the 6-layer Transformer to investigate  the hardness in conditional-language-modeling languages which have been traditionally considered morphologically rich (AR and RU) and poor (ZH). We evaluate through statistical comparisons across 30 possible language directions from the 6 languages of the United Nations Parallel Corpus across 5 data sizes on 3 representation levels --- character, byte, and word. Results show that performance is relative to the representation granularity of each of the languages, not to the language as a whole. On the character and byte levels, we are able to eliminate statistically significant performance disparity, hence demonstrating that a language cannot be intrinsically hard. The disparity that mirrors the morphological complexity hierarchy is shown to be a byproduct of word segmentation. Evidence from data statistics, along with the fact that word segmentation is qualitatively indeterminate, renders a decades-long debate on morphological complexity (unless it is being intentionally modeled in a word-based, meaning-driven context) irrelevant in the context of computing. The intent of our work is to help effect more objectivity and adequacy in evaluation as well as fairness and inclusivity in experimental setup in the area of language and computing so to uphold diversity in Machine Learning and Artificial Intelligence research. Multilinguality is real and relevant in computing not due to canonical, structural linguistic concepts such as morphology or 'words' in our minds, but rather standards related to internationalization and localization, such as character encoding --- something which has thus far been sorely overlooked in our discourse and curricula. ",
        "conference": "ICLR",
        "success": true,
        "中文标题": "多语言自然语言处理中的表征公平性：来自条件语言建模控制实验的见解",
        "摘要翻译": "我们系统且公平地进行了6层Transformer的控制实验，以研究传统上被认为形态丰富（阿拉伯语和俄语）和贫乏（中文）的语言在条件语言建模中的难度。我们通过统计比较评估了来自联合国平行语料库6种语言的30种可能语言方向，在5种数据大小和3种表征级别（字符、字节和词）上的表现。结果表明，性能与每种语言的表征粒度相关，而非语言整体。在字符和字节级别，我们能够消除统计上显著的性能差异，从而证明语言本身并非固有困难。反映形态复杂性层次的差异被证明是分词过程的副产品。来自数据统计的证据，加上分词在质量上是不确定的事实，使得关于形态复杂性的长达数十年的辩论（除非在基于词的意义驱动背景下有意建模）在计算背景下变得无关紧要。我们工作的目的是帮助在语言和计算领域实现更客观和充分的评估，以及实验设置的公平性和包容性，从而维护机器学习和人工智能研究的多样性。多语言性在计算中是真实且相关的，不是由于形态或我们头脑中的‘词’等规范的结构语言学概念，而是与国际化和本地化相关的标准，如字符编码——这一直以来在我们的讨论和课程中被严重忽视。",
        "领域": "自然语言处理与多语言模型、机器翻译、计算语言学",
        "问题": "研究多语言自然语言处理中，不同语言在条件语言建模中的性能差异问题，特别是形态丰富与贫乏语言之间的差异。",
        "动机": "旨在揭示语言性能差异的真实原因，促进评估的客观性和实验设置的公平性，支持机器学习和人工智能研究的多样性。",
        "方法": "采用6层Transformer模型，通过控制实验比较不同语言在多种表征级别上的性能，分析数据统计和分词过程对性能差异的影响。",
        "关键词": [
            "多语言自然语言处理",
            "条件语言建模",
            "表征公平性",
            "形态复杂性",
            "字符编码"
        ],
        "涉及的技术概念": {
            "Transformer模型": "用于进行条件语言建模的控制实验，评估不同语言的性能差异。",
            "表征粒度": "指语言表征的不同级别（字符、字节、词），研究显示性能与表征粒度相关。",
            "形态复杂性": "传统上用于描述语言结构的复杂性，研究发现其在计算背景下对性能差异的影响被高估。"
        }
    },
    {
        "order": 327,
        "title": "Fair Normalizing Flows",
        "html": "https://iclr.cc//virtual/2022/poster/7045",
        "abstract": "Fair representation learning is an attractive approach that promises fairness of downstream predictors by encoding sensitive data. Unfortunately, recent work has shown that strong adversarial predictors can still exhibit unfairness by recovering sensitive attributes from these representations. In this work, we present Fair Normalizing Flows (FNF), a new approach offering more rigorous fairness guarantees for learned representations. Specifically, we consider a practical setting where we can estimate the probability density for sensitive groups. The key idea is to model the encoder as a normalizing flow trained to minimize the statistical distance between the latent representations of different groups. The main advantage of FNF is that its exact likelihood computation allows us to obtain guarantees on the maximum unfairness of any potentially adversarial downstream predictor. We experimentally demonstrate the effectiveness of FNF in enforcing various group fairness notions, as well as other attractive properties such as interpretability and transfer learning, on a variety of challenging real-world datasets.",
        "conference": "ICLR",
        "中文标题": "公平归一化流",
        "摘要翻译": "公平表示学习是一种吸引人的方法，它通过编码敏感数据来承诺下游预测器的公平性。不幸的是，最近的工作表明，强大的对抗性预测器仍然可以通过从这些表示中恢复敏感属性来表现出不公平性。在这项工作中，我们提出了公平归一化流（FNF），这是一种为学习表示提供更严格公平保证的新方法。具体来说，我们考虑了一个可以估计敏感群体概率密度的实际设置。关键思想是将编码器建模为一个归一化流，训练以最小化不同群体潜在表示之间的统计距离。FNF的主要优势在于其精确的似然计算使我们能够获得关于任何潜在对抗性下游预测器的最大不公平性的保证。我们通过实验证明了FNF在强制执行各种群体公平概念以及其他吸引人的特性（如可解释性和迁移学习）方面的有效性，这些实验基于一系列具有挑战性的真实世界数据集。",
        "领域": "公平机器学习, 表示学习, 对抗性学习",
        "问题": "如何在表示学习中提供更严格的公平性保证，防止对抗性预测器恢复敏感属性",
        "动机": "解决现有公平表示学习方法在面对对抗性预测器时仍可能表现出不公平性的问题",
        "方法": "使用归一化流模型作为编码器，通过最小化不同群体潜在表示之间的统计距离来训练，利用精确的似然计算提供公平性保证",
        "关键词": [
            "公平表示学习",
            "归一化流",
            "对抗性学习",
            "统计距离",
            "公平性保证"
        ],
        "涉及的技术概念": {
            "归一化流": "用于建模编码器，通过可逆变换将数据从复杂分布转换到简单分布，同时保持精确的似然计算能力",
            "统计距离": "用于衡量不同群体潜在表示之间的差异，训练目标是最小化这一距离以提高公平性",
            "对抗性预测器": "指能够从公平表示中恢复敏感属性的预测模型，FNF旨在提供对这些预测器不公平性的严格保证"
        },
        "success": true
    },
    {
        "order": 328,
        "title": "FALCON: Fast Visual Concept Learning by Integrating Images, Linguistic descriptions, and Conceptual Relations",
        "html": "https://iclr.cc//virtual/2022/poster/6120",
        "abstract": "We present a meta-learning framework for learning new visual concepts quickly, from just one or a few examples, guided by multiple naturally occurring data streams: simultaneously looking at images, reading sentences that describe the objects in the scene, and interpreting supplemental sentences that relate the novel concept with other concepts. The learned concepts support downstream applications, such as answering questions by reasoning about unseen images. Our model, namely FALCON, represents individual visual concepts, such as colors and shapes, as axis-aligned boxes in a high-dimensional space (the ``box embedding space''). Given an input image and its paired sentence, our model first resolves the referential expression in the sentence and associates the novel concept with particular objects in the scene. Next, our model interprets supplemental sentences to relate the novel concept with other known concepts, such as ``X has property Y'' or ``X is a kind of Y''. Finally, it infers an optimal box embedding for the novel concept that jointly 1) maximizes the likelihood of the observed instances in the image, and 2) satisfies the relationships between the novel concepts and the known ones. We demonstrate the effectiveness of our model on both synthetic and real-world datasets.",
        "conference": "ICLR",
        "中文标题": "FALCON：通过整合图像、语言描述和概念关系实现快速视觉概念学习",
        "摘要翻译": "我们提出了一个元学习框架，用于快速学习新的视觉概念，仅需一个或几个示例，通过多种自然发生的数据流引导：同时观察图像、阅读描述场景中物体的句子，以及解释将新概念与其他概念关联的补充句子。学习到的概念支持下游应用，例如通过推理未见过的图像来回答问题。我们的模型，即FALCON，将个体视觉概念（如颜色和形状）表示为高维空间（“盒子嵌入空间”）中的轴对齐盒子。给定输入图像及其配对的句子，我们的模型首先解析句子中的指代表达，并将新概念与场景中的特定对象关联。接着，我们的模型解释补充句子，将新概念与其他已知概念关联，如“X具有属性Y”或“X是Y的一种”。最后，它推断出新概念的最优盒子嵌入，共同1)最大化图像中观察到的实例的似然，和2)满足新概念与已知概念之间的关系。我们在合成和真实世界数据集上证明了我们模型的有效性。",
        "领域": "视觉概念学习、元学习、多模态学习",
        "问题": "如何快速从少量示例中学习新的视觉概念，并利用多模态数据流（图像、语言描述、概念关系）进行指导。",
        "动机": "开发一个能够快速学习新视觉概念的模型，通过整合图像、语言描述和概念关系，以支持如基于未见图像推理回答问题等下游应用。",
        "方法": "提出FALCON模型，将视觉概念表示为高维空间中的轴对齐盒子，通过解析语言描述和概念关系，推断新概念的最优盒子嵌入。",
        "关键词": [
            "视觉概念学习",
            "元学习",
            "多模态学习",
            "盒子嵌入",
            "指代表达解析"
        ],
        "涉及的技术概念": {
            "盒子嵌入空间": "用于表示视觉概念的高维空间，其中每个概念被建模为轴对齐的盒子，便于概念之间的关系推理。",
            "指代表达解析": "模型解析句子中指代特定对象的表达，将新概念与图像中的对象关联。",
            "多模态学习": "整合图像和语言描述等多种数据模态，以更全面地理解和学习新概念。"
        },
        "success": true
    },
    {
        "order": 329,
        "title": "Fast AdvProp",
        "html": "https://iclr.cc//virtual/2022/poster/6172",
        "abstract": "Adversarial Propagation (AdvProp) is an effective way to improve recognition models, leveraging adversarial examples. Nonetheless, AdvProp suffers from the extremely slow training speed, mainly because: a) extra forward and backward passes are required for generating adversarial examples; b) both original samples and their adversarial counterparts are used for training (i.e., 2X data).  In this paper, we introduce Fast AdvProp, which aggressively revamps AdvProp's costly training components, rendering the method nearly as cheap as the vanilla training. Specifically, our modifications in Fast AdvProp are guided by the hypothesis that disentangled learning with adversarial examples is the key for performance improvements, while other training recipes (e.g., paired clean and adversarial training samples, multi-step adversarial attackers) could be largely simplified.   Our empirical results show that, compared to the vanilla training baseline, Fast AdvProp is able to further model performance on a spectrum of visual benchmarks, without incurring extra training cost. Additionally, our ablations find Fast AdvProp scales better if larger models are used, is compatible with existing data augmentation methods (i.e., Mixup and CutMix), and can be easily adapted to other recognition tasks like object detection.  The code is available here: https://github.com/meijieru/fast_advprop.",
        "conference": "ICLR",
        "中文标题": "快速对抗传播",
        "摘要翻译": "对抗传播（AdvProp）是一种利用对抗样本来提升识别模型性能的有效方法。然而，AdvProp的训练速度极慢，主要原因在于：a) 生成对抗样本需要额外的前向和后向传播；b) 训练过程中同时使用原始样本及其对抗样本（即数据量翻倍）。本文介绍了快速对抗传播（Fast AdvProp），该方法大幅改进了AdvProp中成本高昂的训练组件，使得训练成本几乎与普通训练相当。具体而言，Fast AdvProp的改进基于以下假设：利用对抗样本进行解耦学习是性能提升的关键，而其他训练配方（如成对的干净和对抗训练样本、多步对抗攻击者）可以大幅简化。我们的实证结果表明，与普通训练基线相比，Fast AdvProp能够在一系列视觉基准测试中进一步提升模型性能，而无需增加额外的训练成本。此外，我们的消融研究发现，Fast AdvProp在使用更大模型时扩展性更好，与现有的数据增强方法（如Mixup和CutMix）兼容，并且可以轻松适应其他识别任务，如目标检测。代码可在此处获取：https://github.com/meijieru/fast_advprop。",
        "领域": "对抗学习",
        "问题": "解决对抗传播（AdvProp）训练速度慢的问题",
        "动机": "提高对抗传播方法的训练效率，使其在实际应用中更加可行",
        "方法": "通过简化训练配方和优化对抗样本的生成过程，大幅降低训练成本",
        "关键词": [
            "对抗学习",
            "训练效率",
            "视觉识别"
        ],
        "涉及的技术概念": {
            "对抗传播（AdvProp）": "一种利用对抗样本来提升模型性能的技术",
            "解耦学习": "在Fast AdvProp中，通过解耦学习利用对抗样本来提升性能",
            "数据增强": "Fast AdvProp与Mixup和CutMix等数据增强方法兼容，进一步提升模型性能"
        },
        "success": true
    },
    {
        "order": 330,
        "title": "Fast Differentiable Matrix Square Root",
        "html": "https://iclr.cc//virtual/2022/poster/6545",
        "abstract": "Computing the matrix square root or its inverse in a differentiable manner is important in a variety of computer vision tasks. Previous methods either adopt the Singular Value Decomposition (SVD) to explicitly factorize the matrix or use the Newton-Schulz iteration (NS iteration) to derive the approximate solution. However, both methods are not computationally efficient enough in either the forward pass or in the backward pass. In this paper, we propose two more efficient variants to compute the differentiable matrix square root. For the forward propagation, one method is to use Matrix Taylor Polynomial (MTP), and the other method is to use Matrix Pad\\'e Approximants (MPA). The backward gradient is computed by iteratively solving the continuous-time Lyapunov equation using the matrix sign function. Both methods yield considerable speed-up compared with the SVD or the Newton-Schulz iteration. Experimental results on the de-correlated batch normalization and second-order vision transformer demonstrate that our methods can also achieve competitive and even slightly better performances. The code is available at \\href{https://github.com/KingJamesSong/FastDifferentiableMatSqrt}{https://github.com/KingJamesSong/FastDifferentiableMatSqrt}.",
        "conference": "ICLR",
        "中文标题": "快速可微分矩阵平方根",
        "摘要翻译": "以可微分的方式计算矩阵平方根或其逆在多种计算机视觉任务中非常重要。先前的方法要么采用奇异值分解（SVD）显式分解矩阵，要么使用牛顿-舒尔茨迭代（NS迭代）来推导近似解。然而，这两种方法在前向传播或反向传播中计算效率都不够高。在本文中，我们提出了两种更高效的计算可微分矩阵平方根的变体方法。对于前向传播，一种方法是使用矩阵泰勒多项式（MTP），另一种方法是使用矩阵帕德近似（MPA）。反向梯度是通过使用矩阵符号函数迭代求解连续时间李雅普诺夫方程来计算的。与SVD或牛顿-舒尔茨迭代相比，这两种方法都实现了显著的速度提升。在去相关批量归一化和二阶视觉变换器上的实验结果表明，我们的方法还可以达到竞争性甚至略优的性能。代码可在https://github.com/KingJamesSong/FastDifferentiableMatSqrt获取。",
        "领域": "计算机视觉中的矩阵计算优化、深度学习中的二阶优化、视觉变换器",
        "问题": "如何在计算机视觉任务中高效地计算可微分矩阵平方根或其逆",
        "动机": "提高在计算机视觉任务中计算矩阵平方根或其逆的计算效率，特别是在深度学习的反向传播过程中",
        "方法": "提出了两种方法：使用矩阵泰勒多项式（MTP）和矩阵帕德近似（MPA）进行前向传播，以及使用矩阵符号函数迭代求解连续时间李雅普诺夫方程来计算反向梯度",
        "关键词": [
            "可微分矩阵平方根",
            "矩阵泰勒多项式",
            "矩阵帕德近似",
            "李雅普诺夫方程",
            "视觉变换器"
        ],
        "涉及的技术概念": {
            "矩阵泰勒多项式（MTP）": "用于前向传播中高效计算矩阵平方根的近似解",
            "矩阵帕德近似（MPA）": "另一种前向传播方法，通过有理函数近似提高计算效率",
            "连续时间李雅普诺夫方程": "在反向传播中用于计算梯度，通过矩阵符号函数迭代求解"
        },
        "success": true
    },
    {
        "order": 331,
        "title": "Fast Generic Interaction Detection for Model Interpretability and Compression",
        "html": "https://iclr.cc//virtual/2022/poster/6556",
        "abstract": "The ability of discovering feature interactions in a black-box model is vital to explainable deep learning. We propose a principled, global interaction detection method by casting our target as a multi-arm bandits problem and solving it swiftly with the UCB algorithm. This adaptive method is free of ad-hoc assumptions and among the cutting-edge methods with outstanding detection accuracy and stability. Based on the detection outcome, a lightweight and interpretable deep learning model (called ParaACE) is further built using the alternating conditional expectation (ACE) method. Our proposed ParaACE improves the prediction performance by 26 % and reduces the model size by 100+ times as compared to its Teacher model over various datasets. Furthermore, we show the great potential of our method for scientific discovery through interpreting various real datasets in the economics and smart medicine sectors. The code is available at https://github.com/zhangtj1996/ParaACE. ",
        "conference": "ICLR",
        "中文标题": "快速通用交互检测以提升模型可解释性与压缩性",
        "摘要翻译": "在黑盒模型中发现特征交互的能力对于可解释深度学习至关重要。我们提出了一种原则性的全局交互检测方法，通过将我们的目标建模为一个多臂老虎机问题，并利用UCB算法快速求解。这种自适应方法无需临时假设，且在检测准确性和稳定性方面处于尖端方法之列。基于检测结果，进一步使用交替条件期望（ACE）方法构建了一个轻量级且可解释的深度学习模型（称为ParaACE）。与教师模型相比，我们提出的ParaACE在各种数据集上的预测性能提高了26%，模型大小减少了100倍以上。此外，我们通过解释经济和智能医疗领域的各种真实数据集，展示了我们方法在科学发现方面的巨大潜力。代码可在https://github.com/zhangtj1996/ParaACE获取。",
        "领域": "可解释深度学习, 模型压缩, 特征交互检测",
        "问题": "如何在黑盒模型中高效准确地发现特征交互，并基于此构建轻量级且可解释的深度学习模型。",
        "动机": "提升深度学习模型的可解释性和压缩性，使其更易于理解和应用。",
        "方法": "将特征交互检测问题建模为多臂老虎机问题，利用UCB算法快速求解；基于检测结果，使用交替条件期望（ACE）方法构建轻量级且可解释的深度学习模型。",
        "关键词": [
            "特征交互检测",
            "模型可解释性",
            "模型压缩",
            "多臂老虎机",
            "交替条件期望"
        ],
        "涉及的技术概念": {
            "多臂老虎机问题": "用于建模特征交互检测问题，通过UCB算法快速求解。",
            "UCB算法": "用于解决多臂老虎机问题，实现快速且准确的特征交互检测。",
            "交替条件期望（ACE）方法": "用于基于特征交互检测结果构建轻量级且可解释的深度学习模型。"
        },
        "success": true
    },
    {
        "order": 332,
        "title": "Fast Model Editing at Scale",
        "html": "https://iclr.cc//virtual/2022/poster/6846",
        "abstract": "While large pre-trained models have enabled impressive results on a variety of downstream tasks, the largest existing models still make errors, and even accurate predictions may become outdated over time. Because detecting all such failures at training time is impossible, enabling both developers and end users of such models to correct inaccurate outputs while leaving the model otherwise intact is desirable. However, the distributed, black-box nature of the representations learned by large neural networks makes producing such targeted edits difficult. If presented with only a single problematic input and new desired output, fine-tuning approaches tend to overfit; other editing algorithms are either computationally infeasible or simply ineffective when applied to very large models. To enable easy post-hoc editing at scale, we propose Model Editor Networks using Gradient Decomposition (MEND), a collection of small auxiliary editing networks that use a single desired input-output pair to make fast, local edits to a pre-trained model's behavior. MEND learns to transform the gradient obtained by standard fine-tuning, using a low-rank decomposition of the gradient to make the parameterization of this transformation tractable. MEND can be trained on a single GPU in less than a day even for 10 billion+ parameter models; once trained MEND enables rapid application of new edits to the pre-trained model. Our experiments with T5, GPT, BERT, and BART models show that MEND is the only approach to model editing that effectively edits the behavior of models with more than 10 billion parameters. Code available at https://sites.google.com/view/mend-editing.",
        "conference": "ICLR",
        "中文标题": "大规模快速模型编辑",
        "摘要翻译": "尽管大型预训练模型在各种下游任务上取得了令人印象深刻的结果，但现有最大的模型仍然会出错，甚至准确的预测也可能随着时间的推移而过时。由于在训练时检测所有这些失败是不可能的，因此使这些模型的开发者和最终用户能够纠正不准确的输出，同时保持模型的其他部分不变是可取的。然而，大型神经网络学习到的表示的分布式、黑盒特性使得进行这种有针对性的编辑变得困难。如果仅提供一个有问题的输入和新的期望输出，微调方法往往会过拟合；其他编辑算法要么在计算上不可行，要么在应用于非常大的模型时根本无效。为了实现大规模的事后编辑，我们提出了使用梯度分解的模型编辑网络（MEND），这是一组小型辅助编辑网络，使用单个期望的输入-输出对来快速、局部地编辑预训练模型的行为。MEND通过学习转换通过标准微调获得的梯度，使用梯度的低秩分解使这种转换的参数化变得可行。即使对于超过100亿参数的模型，MEND也可以在单个GPU上在不到一天的时间内完成训练；一旦训练完成，MEND可以快速将新的编辑应用到预训练模型上。我们对T5、GPT、BERT和BART模型的实验表明，MEND是唯一能够有效编辑超过100亿参数模型行为的模型编辑方法。代码可在https://sites.google.com/view/mend-editing获取。",
        "领域": "自然语言处理与视觉结合、模型微调、神经网络编辑",
        "问题": "如何在大规模预训练模型中实现快速、有效的局部编辑，以纠正错误或更新预测，而不影响模型的其他部分。",
        "动机": "大型预训练模型在实际应用中可能会出现错误或预测过时，需要一种方法能够在不重新训练整个模型的情况下，快速修正这些错误或更新预测。",
        "方法": "提出了一种名为MEND的模型编辑网络，通过梯度分解技术，利用小型辅助网络对预训练模型进行快速、局部的编辑。",
        "关键词": [
            "模型编辑",
            "梯度分解",
            "预训练模型",
            "神经网络",
            "局部编辑"
        ],
        "涉及的技术概念": {
            "梯度分解": "用于将标准微调获得的梯度转换为可管理的低秩形式，使得大规模模型的编辑变得可行。",
            "模型编辑网络": "小型辅助网络，专门设计用于对预训练模型进行快速、局部的编辑。",
            "低秩分解": "一种数学技术，用于减少梯度的复杂性，使得编辑过程在计算上更加高效。"
        },
        "success": true
    },
    {
        "order": 333,
        "title": "Fast Regression for Structured Inputs",
        "html": "https://iclr.cc//virtual/2022/poster/7050",
        "abstract": "We study the $\\ell_p$ regression problem, which requires finding $\\mathbf{x}\\in\\mathbb R^{d}$ that minimizes $\\|\\mathbf{A}\\mathbf{x}-\\mathbf{b}\\|_p$ for a matrix $\\mathbf{A}\\in\\mathbb R^{n \\times d}$ and response vector $\\mathbf{b}\\in\\mathbb R^{n}$. There has been recent interest in developing subsampling methods for this problem that can outperform standard techniques when $n$ is very large. However, all known subsampling approaches have run time that depends exponentially on $p$, typically, $d^{\\mathcal{O}(p)}$, which can be prohibitively expensive. We improve on this work by showing that for a large class of common \\emph{structured matrices}, such as combinations of low-rank matrices, sparse matrices, and Vandermonde matrices, there are subsampling based methods for $\\ell_p$ regression that depend polynomially on $p$. For example, we give an algorithm for $\\ell_p$ regression on Vandermonde matrices that runs in time $\\mathcal{O}(n\\log^3 n+(dp^2)^{0.5+\\omega}\\cdot\\text{polylog}\\,n)$, where $\\omega$ is the exponent of matrix multiplication. The polynomial dependence on $p$ crucially allows our algorithms to extend naturally to efficient algorithms for $\\ell_\\infty$ regression, via approximation of $\\ell_\\infty$ by $\\ell_{\\mathcal{O}(\\log n)}$. Of practical interest, we also develop a new subsampling algorithm for $\\ell_p$ regression for arbitrary matrices, which is simpler than previous approaches for $p \\ge 4$.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "结构化输入的快速回归",
        "摘要翻译": "我们研究ℓp回归问题，该问题需要找到x∈ℝd，使得对于矩阵A∈ℝn×d和响应向量b∈ℝn，能够最小化||Ax-b||p。最近，人们对为该问题开发子抽样方法产生了兴趣，当n非常大时，这些方法可以胜过标准技术。然而，所有已知的子抽样方法的运行时间都以指数形式依赖于p，通常为d^(O(p))，这可能非常昂贵。我们通过证明对于一大类常见的结构化矩阵，例如低秩矩阵、稀疏矩阵和范德蒙矩阵的组合，存在ℓp回归的基于子抽样的方法，这些方法以多项式形式依赖于p，从而改进了这项工作。例如，我们给出了一个用于范德蒙矩阵上的ℓp回归的算法，该算法的运行时间为O(nlog³n+(dp²) ^(0.5+ω)·polylog\\,n)，其中ω是矩阵乘法的指数。对p的多项式依赖性至关重要，它允许我们的算法通过ℓ_(O(log n))对ℓ_∞的逼近，自然地扩展到ℓ_∞回归的有效算法。在实际应用方面，我们还开发了一种新的任意矩阵的ℓp回归子抽样算法，该算法比以前的p≥4方法更简单。",
        "领域": "数值计算优化、线性回归、矩阵分解",
        "问题": "在高维数据下，传统的ℓp回归计算复杂度高，特别是当p值较大时，其计算成本呈指数级增长。",
        "动机": "旨在提出一种针对特定结构化矩阵（如低秩矩阵、稀疏矩阵和范德蒙矩阵）的快速ℓp回归算法，降低计算复杂度，使其对大规模数据集更具可行性，并推广到ℓ_∞回归。",
        "方法": "开发了基于子抽样的ℓp回归算法，利用结构化矩阵的特性，将时间复杂度对p的依赖性从指数级降低到多项式级。针对范德蒙矩阵设计了特定的算法，并提出了一种通用的、更简单的任意矩阵ℓp回归子抽样算法。",
        "关键词": [
            "ℓp回归",
            "子抽样",
            "结构化矩阵",
            "范德蒙矩阵",
            "快速算法"
        ],
        "涉及的技术概念": {
            "ℓp回归": "一种回归分析方法，旨在最小化预测值与实际值之间差异的ℓp范数。在本文中，ℓp回归被应用于处理高维数据下的回归问题。",
            "子抽样": "一种降低计算复杂度的技术，通过从原始数据集中选择一个子集进行计算，从而减少计算量。论文中，子抽样方法用于加速ℓp回归的计算过程。"
        }
    },
    {
        "order": 334,
        "title": "FastSHAP: Real-Time Shapley Value Estimation",
        "html": "https://iclr.cc//virtual/2022/poster/6282",
        "abstract": "Although Shapley values are theoretically appealing for explaining black-box models, they are costly to calculate and thus impractical in settings that involve large, high-dimensional models. To remedy this issue, we introduce FastSHAP, a new method for estimating Shapley values in a single forward pass using a learned explainer model. To enable efficient training without requiring ground truth Shapley values, we develop an approach to train FastSHAP via stochastic gradient descent using a weighted least-squares objective function. In our experiments with tabular and image datasets, we compare FastSHAP to existing estimation approaches and find that it generates accurate explanations with an orders-of-magnitude speedup.",
        "conference": "ICLR",
        "中文标题": "FastSHAP: 实时Shapley值估计",
        "摘要翻译": "尽管Shapley值在理论上对于解释黑盒模型具有吸引力，但它们的计算成本高昂，因此在涉及大型、高维模型的设置中不切实际。为了解决这个问题，我们引入了FastSHAP，这是一种通过学习的解释器模型在单次前向传递中估计Shapley值的新方法。为了在没有真实Shapley值的情况下实现高效训练，我们开发了一种方法，通过使用加权最小二乘目标函数的随机梯度下降来训练FastSHAP。在我们对表格和图像数据集的实验中，我们将FastSHAP与现有的估计方法进行了比较，发现它以数量级的速度提升生成了准确的解释。",
        "领域": "模型解释性、机器学习、深度学习",
        "问题": "高维模型中Shapley值计算成本高的问题",
        "动机": "提高Shapley值计算的效率，使其在大型、高维模型中变得实用",
        "方法": "通过学习的解释器模型在单次前向传递中估计Shapley值，并使用加权最小二乘目标函数的随机梯度下降进行训练",
        "关键词": [
            "Shapley值",
            "模型解释性",
            "FastSHAP",
            "高效训练",
            "随机梯度下降"
        ],
        "涉及的技术概念": {
            "Shapley值": "用于解释黑盒模型中各个特征对预测结果的贡献度",
            "FastSHAP": "一种新方法，通过学习的解释器模型在单次前向传递中估计Shapley值",
            "随机梯度下降": "用于训练FastSHAP的优化方法，通过最小化加权最小二乘目标函数来提高训练效率"
        },
        "success": true
    },
    {
        "order": 335,
        "title": "Fast topological clustering with Wasserstein distance",
        "html": "https://iclr.cc//virtual/2022/poster/6706",
        "abstract": "The topological patterns exhibited by many real-world networks motivate the development of topology-based methods for assessing the similarity of networks. However, extracting topological structure is difficult, especially for large and dense networks whose node degrees range over multiple orders of magnitude. In this paper, we propose a novel and computationally practical topological clustering method that clusters complex networks with intricate topology using principled theory from persistent homology and optimal transport. Such networks are aggregated into clusters through a centroid-based clustering strategy based on both their topological and geometric structure, preserving correspondence between nodes in different networks. The notions of topological proximity and centroid are characterized using a novel and efficient approach to computation of the Wasserstein distance and barycenter for persistence barcodes associated with connected components and cycles. The proposed method is demonstrated to be effective using both simulated networks and measured functional brain networks.",
        "conference": "ICLR",
        "中文标题": "基于Wasserstein距离的快速拓扑聚类",
        "摘要翻译": "许多现实世界网络展示的拓扑模式激发了基于拓扑的网络相似性评估方法的发展。然而，提取拓扑结构是困难的，特别是对于那些节点度数跨越多个数量级的大型且密集的网络。在本文中，我们提出了一种新颖且计算上可行的拓扑聚类方法，该方法利用持久同调和最优传输的原理理论，对具有复杂拓扑结构的网络进行聚类。这些网络通过基于拓扑和几何结构的基于质心的聚类策略被聚集成簇，保持了不同网络中节点之间的对应关系。拓扑邻近性和质心的概念通过一种新颖且高效的方法来表征，该方法用于计算与连通组件和循环相关的持久性条形码的Wasserstein距离和重心。通过模拟网络和测量的功能性脑网络，证明了所提出方法的有效性。",
        "领域": "复杂网络分析, 拓扑数据分析, 脑网络研究",
        "问题": "如何有效地对具有复杂拓扑结构的大型网络进行聚类分析",
        "动机": "现实世界网络的复杂拓扑结构使得传统的相似性评估方法难以有效应用，需要开发新的拓扑聚类方法来处理这一问题",
        "方法": "结合持久同调和最优传输理论，提出了一种基于Wasserstein距离和质心的拓扑聚类方法，用于分析网络的拓扑和几何结构",
        "关键词": [
            "拓扑聚类",
            "Wasserstein距离",
            "持久同调",
            "最优传输",
            "脑网络分析"
        ],
        "涉及的技术概念": {
            "持久同调": "用于捕捉和量化网络拓扑结构中的持久特征，如连通组件和循环",
            "Wasserstein距离": "用于衡量两个持久性条形码之间的差异，是聚类分析中的关键度量",
            "最优传输": "提供了一种理论框架，用于在保持几何和拓扑结构的同时，有效地计算网络之间的相似性和质心"
        },
        "success": true
    },
    {
        "order": 336,
        "title": "Feature Kernel Distillation",
        "html": "https://iclr.cc//virtual/2022/poster/7194",
        "abstract": "Trained Neural Networks (NNs) can be viewed as data-dependent kernel machines, with predictions determined by the inner product of last-layer representations across inputs, referred to as the feature kernel. We explore the relevance of the feature kernel for Knowledge Distillation (KD), using a mechanistic understanding of an NN’s optimisation process. We extend the theoretical analysis of Allen-Zhu & Li (2020) to show that a trained NN’s feature kernel is highly dependent on its parameter initialisation, which biases different initialisations of the same architecture to learn different data attributes in a multi-view data setting. This enables us to prove that KD using only pairwise feature kernel comparisons can improve NN test accuracy in such settings, with both single & ensemble teacher models, whereas standard training without KD fails to generalise. We further use our theory to motivate practical considerations for improving student generalisation when using distillation with feature kernels, which allows us to propose a novel approach: Feature Kernel Distillation (FKD). Finally, we experimentally corroborate our theory in the image classification setting, showing that FKD is amenable to ensemble distillation, can transfer knowledge across datasets, and outperforms both vanilla KD & other feature kernel based KD baselines across a range of standard architectures & datasets.",
        "conference": "ICLR",
        "中文标题": "特征核蒸馏",
        "摘要翻译": "训练过的神经网络（NNs）可以被视为数据依赖的核机器，其预测由输入间最后一层表示的内积决定，这被称为特征核。我们探讨了特征核在知识蒸馏（KD）中的相关性，利用了对神经网络优化过程的机械理解。我们扩展了Allen-Zhu & Li（2020）的理论分析，表明训练过的神经网络的特征核高度依赖于其参数初始化，这在同一架构的不同初始化在多视图数据设置中学习不同数据属性时产生偏差。这使我们能够证明，仅使用成对特征核比较的KD可以在这种情况下提高神经网络的测试准确率，无论是使用单一还是集成教师模型，而标准训练没有KD则无法泛化。我们进一步利用我们的理论来激励在使用特征核蒸馏时提高学生泛化能力的实际考虑，这使我们提出了一种新方法：特征核蒸馏（FKD）。最后，我们在图像分类设置中实验验证了我们的理论，表明FKD适用于集成蒸馏，可以跨数据集转移知识，并且在一系列标准架构和数据集上优于普通KD和其他基于特征核的KD基线。",
        "领域": "知识蒸馏、神经网络优化、图像分类",
        "问题": "如何通过特征核蒸馏提高神经网络的测试准确率和泛化能力",
        "动机": "探索特征核在知识蒸馏中的作用，以提高神经网络在多视图数据设置中的泛化能力",
        "方法": "提出特征核蒸馏（FKD）方法，通过理论分析和实验验证其在提高测试准确率和泛化能力方面的有效性",
        "关键词": [
            "特征核蒸馏",
            "知识蒸馏",
            "神经网络优化",
            "图像分类",
            "多视图学习"
        ],
        "涉及的技术概念": {
            "特征核": "神经网络最后一层表示的内积，用于决定预测",
            "知识蒸馏": "通过教师模型指导学生模型学习的技术，以提高学生模型的性能",
            "多视图数据设置": "数据可以从多个角度或视图进行解释，不同初始化可能学习到数据的不同属性"
        },
        "success": true
    },
    {
        "order": 337,
        "title": "FedBABU: Toward Enhanced Representation for Federated Image Classification",
        "html": "https://iclr.cc//virtual/2022/poster/6069",
        "abstract": "Federated learning has evolved to improve a single global model under data heterogeneity (as a curse) or to develop multiple personalized models using data heterogeneity (as a blessing). However, little research has considered both directions simultaneously. In this paper, we first investigate the relationship between them by analyzing Federated Averaging at the client level and determine that a better federated global model performance does not constantly improve personalization. To elucidate the cause of this personalization performance degradation problem, we decompose the entire network into the body (extractor), which is related to universality, and the head (classifier), which is related to personalization. We then point out that this problem stems from training the head. Based on this observation, we propose a novel federated learning algorithm, coined FedBABU, which only updates the body of the model during federated training (i.e., the head is randomly initialized and never updated), and the head is fine-tuned for personalization during the evaluation process. Extensive experiments show consistent performance improvements and an efficient personalization of FedBABU. The code is available at https://github.com/jhoon-oh/FedBABU.",
        "conference": "ICLR",
        "中文标题": "FedBABU：面向联邦图像分类的增强表示方法",
        "摘要翻译": "联邦学习已经发展到在数据异质性（作为一种诅咒）下改进单一全局模型，或利用数据异质性（作为一种祝福）开发多个个性化模型。然而，很少有研究同时考虑这两个方向。在本文中，我们首先通过分析客户级别的联邦平均来研究它们之间的关系，并确定更好的联邦全局模型性能并不总是提高个性化。为了阐明这种个性化性能下降问题的原因，我们将整个网络分解为与普遍性相关的身体（提取器）和与个性化相关的头部（分类器）。然后我们指出这个问题源于头部的训练。基于这一观察，我们提出了一种新颖的联邦学习算法，称为FedBABU，该算法在联邦训练期间仅更新模型的身体（即头部随机初始化且从不更新），并在评估过程中对头部进行个性化微调。大量实验显示FedBABU在性能上有一致的提升和高效的个性化。代码可在https://github.com/jhoon-oh/FedBABU获取。",
        "领域": "联邦学习、图像分类、个性化模型",
        "问题": "解决联邦学习中全局模型性能提升与个性化模型需求之间的矛盾",
        "动机": "探索联邦学习中全局模型与个性化模型之间的关系，并提出一种方法以同时优化两者",
        "方法": "提出FedBABU算法，通过仅更新模型的身体部分并在评估阶段微调头部来实现全局模型性能提升和个性化",
        "关键词": [
            "联邦学习",
            "图像分类",
            "个性化模型",
            "FedBABU",
            "模型分解"
        ],
        "涉及的技术概念": {
            "联邦学习": "一种机器学习方法，允许多个客户端在本地数据上训练模型而不共享数据，旨在保护数据隐私",
            "模型分解": "将模型分解为身体（提取器）和头部（分类器）两部分，分别处理普遍性和个性化问题",
            "个性化微调": "在评估过程中对模型的头部进行微调，以适应特定客户端的数据特性，提升个性化性能"
        },
        "success": true
    },
    {
        "order": 338,
        "title": "FedChain: Chained Algorithms for Near-optimal Communication Cost in Federated Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6628",
        "abstract": "Federated learning (FL) aims to minimize the communication complexity of training a model over heterogeneous data distributed across many clients. A common approach is local methods, where clients take multiple optimization steps over local data before communicating with the server (e.g., FedAvg).  Local methods can exploit similarity between clients' data. However, in existing analyses, this comes at the cost of slow convergence in terms of the dependence on the number of communication rounds R.  On the other hand, global methods, where clients simply return a gradient vector in each round (e.g., SGD), converge faster in terms of R but fail to exploit the similarity between clients even when clients are homogeneous.  We propose FedChain, an algorithmic framework that combines the strengths of local methods and global methods to achieve fast convergence in terms of R while  leveraging the similarity between clients.  Using FedChain, we instantiate algorithms that improve upon previously known rates in the general convex and PL settings, and are near-optimal (via an algorithm-independent lower bound that we show) for problems that satisfy strong convexity.  Empirical results support this theoretical gain over existing methods. ",
        "conference": "ICLR",
        "中文标题": "FedChain：联邦学习中近乎最优通信成本的链式算法",
        "摘要翻译": "联邦学习（FL）旨在最小化在分布在许多客户端上的异构数据上训练模型的通信复杂性。一种常见的方法是本地方法，客户端在与服务器通信之前对本地数据采取多个优化步骤（例如，FedAvg）。本地方法可以利用客户端数据之间的相似性。然而，在现有的分析中，这以依赖于通信轮数R的慢收敛为代价。另一方面，全局方法，其中客户端在每一轮简单地返回一个梯度向量（例如，SGD），在R方面收敛更快，但即使客户端是同质的，也无法利用客户端之间的相似性。我们提出了FedChain，一个结合了本地方法和全局方法优点的算法框架，以在R方面实现快速收敛，同时利用客户端之间的相似性。使用FedChain，我们实例化了在一般凸和PL设置中改进先前已知速率的算法，并且对于满足强凸性的问题，是近乎最优的（通过我们展示的一个算法独立的下界）。实证结果支持了这一相对于现有方法的理论增益。",
        "领域": "联邦学习优化、分布式机器学习、通信效率优化",
        "问题": "如何在联邦学习中同时实现快速收敛和低通信成本",
        "动机": "解决现有联邦学习方法在利用客户端数据相似性和通信轮数收敛速度之间的矛盾",
        "方法": "提出FedChain算法框架，结合本地方法和全局方法的优点，实现快速收敛和低通信成本",
        "关键词": [
            "联邦学习",
            "通信效率",
            "链式算法",
            "收敛速度",
            "数据相似性"
        ],
        "涉及的技术概念": {
            "联邦学习": "一种分布式机器学习方法，允许多个客户端在保护数据隐私的同时共同训练模型",
            "链式算法": "FedChain框架中采用的算法，通过链式结构结合本地和全局方法的优点",
            "通信轮数": "联邦学习中客户端与服务器之间交换信息的次数，影响模型的收敛速度和通信成本"
        },
        "success": true
    },
    {
        "order": 339,
        "title": "Federated Learning from Only Unlabeled Data with Class-conditional-sharing Clients",
        "html": "https://iclr.cc//virtual/2022/poster/6108",
        "abstract": "Supervised federated learning (FL) enables multiple clients to share the trained model without sharing their labeled data. However, potential clients might even be reluctant to label their own data, which could limit the applicability of FL in practice. In this paper, we show the possibility of unsupervised FL whose model is still a classifier for predicting class labels, if the class-prior probabilities are shifted while the class-conditional distributions are shared among the unlabeled data owned by the clients. We propose federation of unsupervised learning (FedUL), where the unlabeled data are transformed into surrogate labeled data for each of the clients, a modified model is trained by supervised FL, and the wanted model is recovered from the modified model. FedUL is a very general solution to unsupervised FL: it is compatible with many supervised FL methods, and the recovery of the wanted model can be theoretically guaranteed as if the data have been labeled. Experiments on benchmark and real-world datasets demonstrate the effectiveness of FedUL. Code is available at https://github.com/lunanbit/FedUL.",
        "conference": "ICLR",
        "中文标题": "仅从具有类条件共享客户端的未标记数据进行联邦学习",
        "摘要翻译": "监督式联邦学习（FL）允许多个客户端共享训练好的模型而无需共享其标记数据。然而，潜在的客户端可能甚至不愿意标记自己的数据，这可能会限制FL在实际中的适用性。在本文中，我们展示了无监督FL的可能性，其模型仍然是一个用于预测类标签的分类器，前提是类先验概率发生变化，而类条件分布在客户端拥有的未标记数据之间共享。我们提出了无监督学习的联邦（FedUL），其中未标记的数据被转换为每个客户端的代理标记数据，通过监督FL训练修改后的模型，并从修改后的模型中恢复所需的模型。FedUL是无监督FL的一个非常通用的解决方案：它与许多监督FL方法兼容，并且可以理论上保证所需模型的恢复，就像数据已经被标记一样。在基准和真实世界数据集上的实验证明了FedUL的有效性。代码可在https://github.com/lunanbit/FedUL获取。",
        "领域": "联邦学习、无监督学习、分类器学习",
        "问题": "解决在客户端不愿意标记自己数据的情况下，如何实现有效的联邦学习",
        "动机": "扩展联邦学习的应用范围，使其在无标记数据的情况下也能有效工作",
        "方法": "提出FedUL方法，通过将未标记数据转换为代理标记数据，利用监督FL训练模型，并从修改后的模型中恢复所需模型",
        "关键词": [
            "联邦学习",
            "无监督学习",
            "类条件共享",
            "代理标记数据",
            "模型恢复"
        ],
        "涉及的技术概念": {
            "联邦学习（FL）": "一种机器学习方法，允许多个客户端协作训练模型而不共享原始数据",
            "无监督学习": "在没有标记数据的情况下训练模型的方法",
            "类条件共享": "客户端之间共享类条件分布，使得在无标记数据上也能进行有效的模型训练"
        },
        "success": true
    },
    {
        "order": 340,
        "title": "FedPara: Low-rank Hadamard Product for Communication-Efficient Federated Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6263",
        "abstract": "In this work, we propose a communication-efficient parameterization, $\\texttt{FedPara}$, for federated learning (FL) to overcome the burdens on frequent model uploads and downloads. Our method re-parameterizes weight parameters of layers using low-rank weights followed by the Hadamard product. Compared to the conventional low-rank parameterization, our $\\texttt{FedPara}$ method is not restricted to low-rank constraints, and thereby it has a far larger capacity. This property enables to achieve comparable performance while requiring 3 to 10 times lower communication costs than the model with the original layers, which is not achievable by the traditional low-rank methods. The efficiency of our method can be further improved by combining with other efficient FL optimizers. In addition, we extend our method to a personalized FL application, $\\texttt{pFedPara}$, which separates parameters into global and local ones. We show that $\\texttt{pFedPara}$ outperforms competing personalized FL methods with more than three times fewer parameters.",
        "conference": "ICLR",
        "中文标题": "FedPara：用于通信高效联邦学习的低秩Hadamard乘积",
        "摘要翻译": "在这项工作中，我们提出了一种通信高效的参数化方法，$\texttt{FedPara}$，用于联邦学习（FL），以克服频繁模型上传和下载的负担。我们的方法使用低秩权重后接Hadamard乘积来重新参数化层的权重参数。与传统的低秩参数化相比，我们的$\texttt{FedPara}$方法不受限于低秩约束，因此具有更大的容量。这一特性使得在要求比原始层模型低3到10倍的通信成本的同时，能够达到可比的性能，这是传统低秩方法无法实现的。通过与其他高效的FL优化器结合，可以进一步提高我们方法的效率。此外，我们将我们的方法扩展到个性化FL应用$\texttt{pFedPara}$，它将参数分为全局和局部两部分。我们表明，$\texttt{pFedPara}$在参数数量比竞争个性化FL方法少三倍以上的情况下，表现更优。",
        "领域": "联邦学习、参数优化、个性化学习",
        "问题": "解决联邦学习中频繁模型上传和下载带来的通信负担问题",
        "动机": "减少联邦学习中的通信成本，同时保持或提高模型性能",
        "方法": "使用低秩权重和Hadamard乘积重新参数化模型权重，以增加模型容量并减少通信需求",
        "关键词": [
            "联邦学习",
            "低秩参数化",
            "Hadamard乘积",
            "通信效率",
            "个性化学习"
        ],
        "涉及的技术概念": {
            "低秩权重": "用于减少模型参数的数量，从而降低通信成本",
            "Hadamard乘积": "一种矩阵运算，用于在保持模型性能的同时增加参数化的灵活性",
            "个性化联邦学习": "将模型参数分为全局和局部两部分，以适应不同用户的数据分布"
        },
        "success": true
    },
    {
        "order": 341,
        "title": "Few-Shot Backdoor Attacks on Visual Object Tracking",
        "html": "https://iclr.cc//virtual/2022/poster/6523",
        "abstract": "Visual object tracking (VOT) has been widely adopted in mission-critical applications, such as autonomous driving and intelligent surveillance systems. In current practice, third-party resources such as datasets, backbone networks, and training platforms are frequently used to train high-performance VOT models. Whilst these resources bring certain convenience, they also introduce new security threats into VOT models. In this paper, we reveal such a threat where an adversary can easily implant hidden backdoors into VOT models by tempering with the training process. Specifically, we propose a simple yet effective few-shot backdoor attack (FSBA) that optimizes two losses alternately: 1) a \\emph{feature loss} defined in the hidden feature space, and 2) the standard \\emph{tracking loss}. We show that, once the backdoor is embedded into the target model by our FSBA, it can trick the model to lose track of specific objects even when the \\emph{trigger} only appears in one or a few frames. We examine our attack in both digital and physical-world settings and show that it can significantly degrade the performance of state-of-the-art VOT trackers. We also show that our attack is resistant to potential defenses, highlighting the vulnerability of VOT models to potential backdoor attacks.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "视觉目标跟踪中的少样本后门攻击",
        "摘要翻译": "视觉目标跟踪（VOT）已广泛应用于任务关键型应用中，例如自动驾驶和智能监控系统。在目前的实践中，经常使用第三方资源（如数据集、骨干网络和训练平台）来训练高性能的VOT模型。虽然这些资源带来了一定的便利，但它们也为VOT模型带来了新的安全威胁。在本文中，我们揭示了这样一种威胁，即攻击者可以通过篡改训练过程，轻松地将隐藏的后门植入到VOT模型中。具体来说，我们提出了一种简单而有效的少样本后门攻击（FSBA），该攻击交替优化两个损失：1）在隐藏特征空间中定义的特征损失，以及2）标准跟踪损失。我们表明，一旦通过我们的FSBA将后门嵌入到目标模型中，即使触发器仅出现在一个或几个帧中，它也可以欺骗模型以丢失对特定对象的跟踪。我们在数字和物理世界环境中检查了我们的攻击，结果表明它可以显著降低最先进的VOT跟踪器的性能。我们还表明，我们的攻击可以抵抗潜在的防御，突出了VOT模型对潜在后门攻击的脆弱性。",
        "领域": "视觉目标跟踪、对抗性攻击、模型安全",
        "问题": "如何防止视觉目标跟踪模型遭受后门攻击，确保其在安全敏感场景下的可靠性。",
        "动机": "现有的视觉目标跟踪模型依赖第三方资源，这引入了安全漏洞，攻击者可以利用这些漏洞植入后门，严重影响模型的性能和安全性。",
        "方法": "提出了一种少样本后门攻击（FSBA），通过交替优化隐藏特征空间的特征损失和标准跟踪损失，将后门嵌入到VOT模型中。该方法仅需少量样本即可实现有效的后门植入，并且能够抵抗一些防御措施。",
        "关键词": [
            "视觉目标跟踪",
            "后门攻击",
            "对抗性攻击",
            "模型安全",
            "少样本学习"
        ],
        "涉及的技术概念": {
            "后门攻击": "一种对抗性攻击，通过在模型中植入隐藏的触发器，使得模型在特定条件下产生错误的输出。",
            "特征损失": "在隐藏特征空间中定义的损失函数，用于优化后门触发器的嵌入，使得触发器能够影响模型的内部表示。"
        }
    },
    {
        "order": 342,
        "title": "Few-shot Learning via Dirichlet Tessellation Ensemble",
        "html": "https://iclr.cc//virtual/2022/poster/6124",
        "abstract": "Few-shot learning (FSL) is the process of rapid generalization from abundant base samples to inadequate novel samples. Despite extensive research in recent years, FSL is still not yet able to generate satisfactory solutions for a wide range of real-world applications. To confront this challenge, we study the FSL problem from a geometric point of view in this paper. One observation is that the widely embraced ProtoNet model is essentially a Voronoi Diagram (VD) in the feature space. We retrofit it by making use of a recent advance in computational geometry called Cluster-induced Voronoi Diagram (CIVD). Starting from the simplest nearest neighbor model, CIVD gradually incorporates cluster-to-point and then cluster-to-cluster relationships for space subdivision, which is used to improve the accuracy and robustness at multiple stages of FSL. Specifically, we use CIVD (1) to integrate parametric and nonparametric few-shot classifiers; (2) to combine feature representation and surrogate representation; (3) and to leverage feature-level, transformation-level, and geometry-level heterogeneities for a better ensemble. Our CIVD-based workflow enables us to achieve new state-of-the-art results on mini-ImageNet, CUB, and tiered-ImagenNet datasets, with ${\\sim}2\\%{-}5\\%$ improvements upon the next best. To summarize, CIVD provides a mathematically elegant and geometrically interpretable framework that compensates for extreme data insufficiency, prevents overfitting, and allows for fast geometric ensemble for thousands of individual VD. These together make FSL stronger.",
        "conference": "ICLR",
        "中文标题": "通过狄利克雷镶嵌集成进行少样本学习",
        "摘要翻译": "少样本学习（FSL）是从丰富的基样本快速泛化到不足的新样本的过程。尽管近年来有广泛的研究，FSL仍未能为广泛的实际应用生成令人满意的解决方案。为了应对这一挑战，本文从几何角度研究了FSL问题。一个观察是，广泛采用的ProtoNet模型本质上是特征空间中的Voronoi图（VD）。我们通过利用计算几何中的最新进展——聚类诱导Voronoi图（CIVD）来对其进行改造。从最简单的最近邻模型开始，CIVD逐渐融入聚类到点和聚类到聚类的关系进行空间细分，用于提高FSL多个阶段的准确性和鲁棒性。具体来说，我们使用CIVD（1）整合参数化和非参数化的少样本分类器；（2）结合特征表示和代理表示；（3）利用特征级、变换级和几何级的异质性进行更好的集成。我们基于CIVD的工作流程使我们能够在mini-ImageNet、CUB和tiered-ImagenNet数据集上实现新的最先进结果，比次优结果提高了约2%到5%。总之，CIVD提供了一个数学上优雅且几何上可解释的框架，弥补了极端数据不足，防止了过拟合，并允许对数千个单独的VD进行快速几何集成。这些共同使FSL更加强大。",
        "领域": "少样本学习、图像分类、深度学习",
        "问题": "解决少样本学习在广泛实际应用中表现不佳的问题",
        "动机": "从几何角度改进少样本学习，提高其准确性和鲁棒性",
        "方法": "利用聚类诱导Voronoi图（CIVD）整合和优化少样本学习的多个方面，包括分类器整合、表示结合和异质性利用",
        "关键词": [
            "少样本学习",
            "Voronoi图",
            "聚类诱导",
            "几何集成",
            "深度学习"
        ],
        "涉及的技术概念": {
            "Voronoi图（VD）": "用于特征空间中样本点的空间细分，是ProtoNet模型的基础",
            "聚类诱导Voronoi图（CIVD）": "改进的Voronoi图，通过融入聚类关系优化空间细分，提高少样本学习的准确性和鲁棒性",
            "几何集成": "利用CIVD对数千个单独的Voronoi图进行快速集成，增强少样本学习的性能"
        },
        "success": true
    },
    {
        "order": 343,
        "title": "FILIP: Fine-grained Interactive Language-Image Pre-Training",
        "html": "https://iclr.cc//virtual/2022/poster/6909",
        "abstract": "Unsupervised large-scale vision-language pre-training has shown promising advances on various downstream tasks. Existing methods often model the cross-modal interaction either via the similarity of the global feature of each modality which misses sufficient information, or finer-grained interactions using cross/self-attention upon visual and textual tokens. However, cross/self-attention suffers from inferior efficiency in both training and inference. In this paper, we introduce a large-scale Fine-grained Interactive Language-Image Pre-training (FILIP) to achieve finer-level alignment through a cross-modal late interaction mechanism, which uses a token-wise maximum similarity between visual and textual tokens to guide the contrastive objective. FILIP successfully leverages the finer-grained expressiveness between image patches and textual words by modifying only contrastive loss, while simultaneously gaining the ability to pre-compute image and text representations offline at inference, keeping both large-scale training and inference efficient. Furthermore, we construct a new large-scale image-text pair dataset called FILIP300M for pre-training. Experiments show that FILIP achieves state-of-the-art performance on multiple downstream vision-language tasks including zero-shot image classification and image-text retrieval. The visualization on word-patch alignment further shows that FILIP can learn meaningful fine-grained features with promising localization ability.",
        "conference": "ICLR",
        "中文标题": "FILIP: 细粒度交互式语言-图像预训练",
        "摘要翻译": "无监督的大规模视觉-语言预训练在各种下游任务上显示出了显著的进展。现有方法通常通过每种模态的全局特征的相似性来建模跨模态交互，这遗漏了足够的信息，或者通过视觉和文本标记上的交叉/自注意力来实现更细粒度的交互。然而，交叉/自注意力在训练和推理中都存在效率低下的问题。在本文中，我们引入了一种大规模细粒度交互式语言-图像预训练（FILIP），通过跨模态后期交互机制实现更细粒度的对齐，该机制使用视觉和文本标记之间的标记级最大相似性来指导对比目标。FILIP通过仅修改对比损失，成功地利用了图像块和文本词之间更细粒度的表达能力，同时获得了在推理时离线预计算图像和文本表示的能力，保持了大尺度训练和推理的高效性。此外，我们构建了一个名为FILIP300M的新的大规模图像-文本对数据集用于预训练。实验表明，FILIP在包括零样本图像分类和图像-文本检索在内的多个下游视觉-语言任务上实现了最先进的性能。词-块对齐的可视化进一步表明，FILIP可以学习有意义的细粒度特征，并具有有前景的定位能力。",
        "领域": "视觉-语言预训练",
        "问题": "现有视觉-语言预训练方法在跨模态交互建模上存在信息遗漏或效率低下的问题",
        "动机": "通过更细粒度的跨模态交互机制，提升视觉-语言预训练的性能和效率",
        "方法": "引入跨模态后期交互机制，利用标记级最大相似性指导对比目标，同时保持训练和推理的高效性",
        "关键词": [
            "细粒度交互",
            "视觉-语言预训练",
            "跨模态对齐",
            "对比学习",
            "零样本学习"
        ],
        "涉及的技术概念": {
            "跨模态后期交互机制": "通过视觉和文本标记之间的标记级最大相似性来指导对比目标，实现更细粒度的对齐",
            "对比损失": "用于优化模型训练，通过修改对比损失来提升模型对细粒度特征的表达能力",
            "零样本图像分类": "一种无需特定类别训练样本即可进行分类的任务，展示了模型对未见类别的泛化能力"
        },
        "success": true
    },
    {
        "order": 344,
        "title": "Filling the G_ap_s: Multivariate Time Series Imputation by Graph Neural Networks",
        "html": "https://iclr.cc//virtual/2022/poster/5891",
        "abstract": "Dealing with missing values and incomplete time series is a labor-intensive, tedious, inevitable task when handling data coming from real-world applications. Effective spatio-temporal representations would allow imputation methods to reconstruct missing temporal data by exploiting information coming from sensors at different locations. However, standard methods fall short in capturing the nonlinear time and space dependencies existing within networks of interconnected sensors and do not take full advantage of the available - and often strong - relational information. Notably, most state-of-the-art imputation methods based on deep learning do not explicitly model relational aspects and, in any case, do not exploit processing frameworks able to adequately represent structured spatio-temporal data. Conversely, graph neural networks have recently surged in popularity as both expressive and scalable tools for processing sequential data with relational inductive biases. In this work, we present the first assessment of graph neural networks in the context of multivariate time series imputation. In particular, we introduce a novel graph neural network architecture, named GRIN, which aims at reconstructing missing data in the different channels of a multivariate time series by learning spatio-temporal representations through message passing. Empirical results show that our model outperforms state-of-the-art methods in the imputation task on relevant real-world benchmarks with mean absolute error improvements often higher than 20%.",
        "conference": "ICLR",
        "中文标题": "填补空白：基于图神经网络的多元时间序列插补",
        "摘要翻译": "处理来自现实世界应用的数据时，处理缺失值和不完整的时间序列是一项劳动密集型、繁琐且不可避免的任务。有效的时空表示将使插补方法能够通过利用来自不同位置传感器的信息来重建缺失的时间数据。然而，标准方法在捕捉互连传感器网络中存在的非线性和空间依赖性方面存在不足，并且没有充分利用可用的——通常是强烈的——关系信息。值得注意的是，大多数基于深度学习的最先进插补方法并未明确建模关系方面，并且在任何情况下都没有利用能够充分表示结构化时空数据的处理框架。相反，图神经网络最近因其作为处理具有关系归纳偏见的序列数据的表达性和可扩展性工具而受到欢迎。在这项工作中，我们首次评估了图神经网络在多元时间序列插补中的应用。特别是，我们引入了一种名为GRIN的新型图神经网络架构，旨在通过学习通过消息传递的时空表示来重建多元时间序列不同通道中的缺失数据。实证结果表明，我们的模型在相关现实世界基准测试的插补任务中优于最先进的方法，平均绝对误差改进通常高于20%。",
        "领域": "时间序列分析, 图神经网络, 数据插补",
        "问题": "多元时间序列中缺失数据的有效插补",
        "动机": "现有方法在捕捉传感器网络中的非线性时空依赖性和利用关系信息方面存在不足",
        "方法": "提出了一种新型图神经网络架构GRIN，通过学习时空表示通过消息传递来重建缺失数据",
        "关键词": [
            "多元时间序列",
            "图神经网络",
            "数据插补",
            "时空表示",
            "消息传递"
        ],
        "涉及的技术概念": {
            "图神经网络": "用于处理具有关系归纳偏见的序列数据，能够捕捉传感器网络中的时空依赖性",
            "消息传递": "在图神经网络中用于节点间信息交换，帮助学习时空表示以重建缺失数据",
            "时空表示": "通过学习数据的时间和空间特征，有效重建多元时间序列中的缺失值"
        },
        "success": true
    },
    {
        "order": 345,
        "title": "FILM: Following Instructions in Language with Modular Methods",
        "html": "https://iclr.cc//virtual/2022/poster/6979",
        "abstract": "Recent methods for embodied instruction following are typically trained end-to-end using imitation learning. This often requires the use of expert trajectories and low-level language instructions. Such approaches assume that neural states will integrate multimodal semantics to perform state tracking, building spatial memory, exploration, and long-term planning. In contrast, we propose a modular method with structured representations that (1) builds a semantic map of the scene and (2) performs exploration with a semantic search policy, to achieve the natural language goal. Our modular method achieves SOTA performance (24.46 %) with a substantial (8.17 % absolute) gap from previous work while using less data by eschewing both expert trajectories and low-level instructions. Leveraging low-level language, however, can further increase our performance (26.49 %). Our findings suggest that an explicit spatial memory and a semantic search policy can provide a stronger and more general representation for state-tracking and guidance, even in the absence of expert trajectories or low-level instructions.",
        "conference": "ICLR",
        "中文标题": "FILM：使用模块化方法遵循语言指令",
        "摘要翻译": "最近的实体化指令遵循方法通常使用模仿学习进行端到端训练。这通常需要专家轨迹和低级语言指令的使用。这种方法假设神经状态将整合多模态语义以执行状态跟踪、构建空间记忆、探索和长期规划。相比之下，我们提出了一种具有结构化表示的模块化方法，该方法（1）构建场景的语义地图，（2）通过语义搜索策略进行探索，以实现自然语言目标。我们的模块化方法在使用更少数据的情况下，通过避免使用专家轨迹和低级指令，实现了最先进的性能（24.46%），与之前的工作相比有显著的（8.17%绝对）差距。然而，利用低级语言可以进一步提高我们的性能（26.49%）。我们的研究结果表明，明确的空间记忆和语义搜索策略可以为状态跟踪和指导提供更强和更一般的表示，即使在缺乏专家轨迹或低级指令的情况下。",
        "领域": "自然语言处理与视觉结合、机器人导航、语义理解",
        "问题": "如何在缺乏专家轨迹或低级指令的情况下，有效地遵循自然语言指令进行实体化任务。",
        "动机": "现有的端到端学习方法依赖于专家轨迹和低级指令，限制了方法的通用性和数据效率。",
        "方法": "提出了一种模块化方法，通过构建场景的语义地图和采用语义搜索策略，来实现自然语言指令的遵循。",
        "关键词": [
            "模块化方法",
            "语义地图",
            "语义搜索策略",
            "自然语言指令",
            "实体化任务"
        ],
        "涉及的技术概念": {
            "语义地图": "构建场景的语义表示，用于理解和导航环境。",
            "语义搜索策略": "基于语义信息进行探索和决策的策略，以实现指令目标。",
            "结构化表示": "模块化方法中用于组织和处理信息的框架，提高任务执行的效率和准确性。"
        },
        "success": true
    },
    {
        "order": 346,
        "title": "Filtered-CoPhy: Unsupervised Learning of Counterfactual Physics in Pixel Space",
        "html": "https://iclr.cc//virtual/2022/poster/6541",
        "abstract": "Learning causal relationships in high-dimensional data (images, videos) is a hard task, as they are often defined on low dimensional manifolds and must be extracted from complex signals dominated by appearance, lighting, textures and also spurious correlations in the data. We present a method for learning counterfactual reasoning of physical processes in pixel space, which requires the prediction of the impact of interventions on initial conditions. Going beyond the identification of structural relationships, we deal with the challenging problem of forecasting raw video over long horizons. Our method does not require the knowledge or supervision of any ground truth positions or other object or scene properties. Our model learns and acts on a suitable hybrid latent representation based on a combination of dense features, sets of 2D keypoints and an additional latent vector per keypoint. We show that this better captures the dynamics of physical processes than purely dense or sparse representations. We introduce a new challenging and carefully designed counterfactual benchmark for predictions in pixel space and outperform strong baselines in physics-inspired ML and video prediction.",
        "conference": "ICLR",
        "中文标题": "Filtered-CoPhy：像素空间中反事实物理的无监督学习",
        "摘要翻译": "在高维数据（如图像、视频）中学习因果关系是一项艰巨的任务，因为这些数据通常定义在低维流形上，且必须从由外观、光照、纹理以及数据中的虚假相关性主导的复杂信号中提取。我们提出了一种在像素空间中学习物理过程反事实推理的方法，该方法需要预测初始条件干预的影响。超越结构关系的识别，我们处理了长期原始视频预测这一具有挑战性的问题。我们的方法不需要任何真实位置或其他对象或场景属性的知识或监督。我们的模型基于密集特征、2D关键点集合以及每个关键点的附加潜在向量的组合，学习并作用于合适的混合潜在表示。我们表明，这比纯粹的密集或稀疏表示更好地捕捉了物理过程的动态。我们引入了一个新的、具有挑战性且精心设计的反事实基准，用于像素空间中的预测，并在受物理启发的机器学习和视频预测方面超越了强基线。",
        "领域": "视频预测、物理过程建模、无监督学习",
        "问题": "在高维数据中学习因果关系，特别是在像素空间中进行长期原始视频预测。",
        "动机": "解决从复杂信号中提取因果关系和在无监督条件下预测物理过程动态的挑战。",
        "方法": "采用基于密集特征、2D关键点集合及附加潜在向量的混合潜在表示，进行反事实推理和视频预测。",
        "关键词": [
            "反事实推理",
            "无监督学习",
            "视频预测",
            "物理过程建模",
            "混合潜在表示"
        ],
        "涉及的技术概念": {
            "反事实推理": "在像素空间中预测初始条件干预的影响，用于理解物理过程的因果关系。",
            "混合潜在表示": "结合密集特征、2D关键点集合和附加潜在向量，以更好地捕捉物理过程的动态。",
            "无监督学习": "不需要真实位置或其他对象或场景属性的知识或监督，直接从数据中学习。"
        },
        "success": true
    },
    {
        "order": 347,
        "title": "Finding an Unsupervised Image Segmenter in each of your Deep Generative Models",
        "html": "https://iclr.cc//virtual/2022/poster/6368",
        "abstract": "Recent research has shown that numerous human-interpretable directions exist in the latent space of GANs. In this paper, we develop an automatic procedure for finding directions that lead to foreground-background image separation, and we use these directions to train an image segmentation model without human supervision. Our method is generator-agnostic, producing strong segmentation results with a wide range of different GAN architectures. Furthermore, by leveraging GANs pretrained on large datasets such as ImageNet, we are able to segment images from a range of domains without further training or finetuning. Evaluating our method on image segmentation benchmarks, we compare favorably to prior work while using neither human supervision nor access to the training data. Broadly, our results demonstrate that automatically extracting foreground-background structure from pretrained deep generative models can serve as a remarkably effective substitute for human supervision.",
        "conference": "ICLR",
        "中文标题": "在您的每个深度生成模型中寻找无监督图像分割器",
        "摘要翻译": "最近的研究表明，在GAN的潜在空间中存在许多人类可解释的方向。在本文中，我们开发了一种自动程序，用于找到导致前景-背景图像分离的方向，并利用这些方向在没有人类监督的情况下训练图像分割模型。我们的方法是生成器无关的，能够与多种不同的GAN架构一起产生强大的分割结果。此外，通过利用在大型数据集（如ImageNet）上预训练的GAN，我们能够分割来自多个领域的图像，而无需进一步的训练或微调。在图像分割基准上评估我们的方法时，我们在不使用人类监督也不访问训练数据的情况下，与之前的工作相比表现更优。总的来说，我们的结果表明，从预训练的深度生成模型中自动提取前景-背景结构可以作为一种非常有效的人类监督替代品。",
        "领域": "图像分割、生成对抗网络、无监督学习",
        "问题": "如何在无监督的情况下，利用深度生成模型的潜在空间自动进行图像分割",
        "动机": "探索深度生成模型中潜在空间的可解释方向，以实现无需人类监督的图像分割",
        "方法": "开发一种自动程序，从GAN的潜在空间中寻找导致前景-背景分离的方向，并利用这些方向训练无监督的图像分割模型",
        "关键词": [
            "无监督学习",
            "图像分割",
            "生成对抗网络",
            "潜在空间",
            "前景-背景分离"
        ],
        "涉及的技术概念": {
            "潜在空间": "GAN中编码输入数据的低维空间，本文用于寻找导致图像分割的方向",
            "生成对抗网络": "一种深度学习模型，用于生成逼真的图像，本文中用于无监督图像分割",
            "无监督学习": "一种机器学习方法，不需要标注数据，本文中用于训练图像分割模型"
        },
        "success": true
    },
    {
        "order": 348,
        "title": "Finding Biological Plausibility for Adversarially Robust Features via Metameric Tasks",
        "html": "https://iclr.cc//virtual/2022/poster/6482",
        "abstract": "Recent work suggests that feature constraints in the training datasets of deep neural networks (DNNs) drive robustness to adversarial noise (Ilyas et al., 2019). The representations learned by such adversarially robust networks have also been shown to be more human perceptually-aligned than non-robust networks via image manipulations (Santurkar et al., 2019, Engstrom et al., 2019). Despite appearing closer to human visual perception, it is unclear if the constraints in robust DNN representations match biological constraints found in human vision. Human vision seems to rely on texture-based/summary statistic representations in the periphery, which have been shown to explain phenomena such as crowding (Balas et al., 2009) and performance on visual search tasks (Rosenholtz et al., 2012). To understand how adversarially robust optimizations/representations compare to human vision, we performed a psychophysics experiment using a metamer task similar to Freeman \\& Simoncelli, 2011, Wallis et al., 2016 and Deza et al., 2019 where we evaluated how well human observers could distinguish between images synthesized to match adversarially robust representations compared to non-robust representations and a texture synthesis model of peripheral vision (Texforms a la Long et al., 2018).  We found that the discriminability of robust representation and texture model images decreased to near chance performance as stimuli were presented farther in the periphery.  Moreover, performance on robust and texture-model images showed similar trends within participants, while performance on non-robust representations changed minimally across the visual field.  These results together suggest that (1) adversarially robust representations capture peripheral computation better than non-robust representations and (2) robust representations capture peripheral computation similar to current state-of-the-art texture peripheral vision models. More broadly, our findings support the idea that localized texture summary statistic representations may drive human invariance to adversarial perturbations and that the incorporation of such representations in DNNs could give rise to useful properties like adversarial robustness.",
        "conference": "ICLR",
        "中文标题": "通过同构任务寻找对抗性鲁棒特征的生物学合理性",
        "摘要翻译": "最近的研究表明，深度神经网络（DNNs）训练数据集中的特征约束驱动了对对抗性噪声的鲁棒性（Ilyas等人，2019年）。通过图像操作，这种对抗性鲁棒网络学习的表示也被证明比非鲁棒网络更符合人类感知（Santurkar等人，2019年，Engstrom等人，2019年）。尽管看起来更接近人类视觉感知，但尚不清楚鲁棒DNN表示中的约束是否与人类视觉中的生物约束相匹配。人类视觉似乎依赖于外围的基于纹理/摘要统计的表示，这些表示已被证明可以解释诸如拥挤（Balas等人，2009年）和视觉搜索任务表现（Rosenholtz等人，2012年）等现象。为了理解对抗性鲁棒优化/表示与人类视觉的比较，我们使用类似于Freeman和Simoncelli，2011年，Wallis等人，2016年和Deza等人，2019年的同构任务进行了心理物理学实验，评估了人类观察者区分合成图像的能力，这些图像旨在匹配对抗性鲁棒表示与非鲁棒表示以及外围视觉的纹理合成模型（Texforms，如Long等人，2018年）。我们发现，随着刺激在外围呈现的距离增加，鲁棒表示和纹理模型图像的可区分性降低到接近随机性能。此外，鲁棒和纹理模型图像的表现显示出参与者之间的相似趋势，而非鲁棒表示的表现在整个视野中变化最小。这些结果共同表明：（1）对抗性鲁棒表示比非鲁棒表示更好地捕捉了外围计算；（2）鲁棒表示捕捉外围计算的方式类似于当前最先进的纹理外围视觉模型。更广泛地说，我们的发现支持了这样一种观点，即局部纹理摘要统计表示可能驱动人类对对抗性扰动的不变性，并且将这种表示纳入DNNs可能会产生有用的属性，如对抗性鲁棒性。",
        "领域": "对抗性机器学习、人类视觉感知、计算机视觉",
        "问题": "探索对抗性鲁棒特征与人类视觉生物约束之间的关系",
        "动机": "理解对抗性鲁棒优化/表示是否与人类视觉中的生物约束相匹配",
        "方法": "通过心理物理学实验，使用同构任务评估人类观察者区分对抗性鲁棒表示与非鲁棒表示及纹理合成模型的能力",
        "关键词": [
            "对抗性鲁棒性",
            "人类视觉感知",
            "纹理合成模型",
            "心理物理学实验",
            "同构任务"
        ],
        "涉及的技术概念": {
            "对抗性鲁棒表示": "在对抗性噪声下仍能保持稳定性的特征表示，用于提高模型的鲁棒性",
            "纹理合成模型": "模拟人类外围视觉处理纹理信息的模型，用于解释人类视觉现象如拥挤和视觉搜索任务表现",
            "同构任务": "一种心理物理学实验方法，用于评估人类对不同图像表示的可区分性"
        },
        "success": true
    },
    {
        "order": 349,
        "title": "Fine-grained Differentiable Physics: A Yarn-level Model for Fabrics",
        "html": "https://iclr.cc//virtual/2022/poster/7205",
        "abstract": "Differentiable physics modeling combines physics models with gradient-based learning to provide model explicability and data efficiency. It has been used to learn dynamics, solve inverse problems and facilitate design, and is at its inception of impact. Current successes have concentrated on general physics models such as rigid bodies, deformable sheets, etc, assuming relatively simple structures and forces. Their granularity is intrinsically coarse and therefore incapable of modelling complex physical phenomena. Fine-grained models are still to be developed to incorporate sophisticated material structures and force interactions with gradient-based learning. Following this motivation, we propose a new differentiable fabrics model for composite materials such as cloths, where we dive into the granularity of yarns and model individual yarn physics and yarn-to-yarn interactions. To this end, we propose several differentiable forces, whose counterparts in empirical physics are indifferentiable, to facilitate gradient-based learning. These forces, albeit applied to cloths, are ubiquitous in various physical systems. Through comprehensive evaluation and comparison, we demonstrate our model's $\\textit{explicability}$ in learning meaningful physical parameters, $\\textit{versatility}$ in incorporating complex physical structures and heterogeneous materials, $\\textit{data-efficiency}$ in learning, and $\\textit{high-fidelity}$ in capturing subtle dynamics.",
        "conference": "ICLR",
        "中文标题": "细粒度可微分物理：一种面向织物的纱线级模型",
        "摘要翻译": "可微分物理建模将物理模型与基于梯度的学习相结合，以提供模型的可解释性和数据效率。它已被用于学习动力学、解决逆问题和促进设计，并正处于其影响力的初期。目前的成功主要集中在一般物理模型上，如刚体、可变形薄片等，假设相对简单的结构和力。它们的粒度本质上是粗糙的，因此无法模拟复杂的物理现象。细粒度模型仍有待开发，以将复杂的材料结构和力相互作用与基于梯度的学习相结合。基于这一动机，我们提出了一种新的可微分织物模型，适用于布料等复合材料，其中我们深入到纱线的粒度，模拟单个纱线的物理和纱线间的相互作用。为此，我们提出了几种可微分的力，这些力在经验物理中是不可微分的，以促进基于梯度的学习。这些力虽然应用于布料，但在各种物理系统中普遍存在。通过全面的评估和比较，我们展示了我们的模型在学习有意义的物理参数时的可解释性、在纳入复杂物理结构和异质材料时的多功能性、在学习中的数据效率以及在捕捉微妙动力学时的高保真度。",
        "领域": "计算机视觉与物理模拟结合、材料科学中的机器学习、可微分物理建模",
        "问题": "如何开发细粒度可微分物理模型以模拟复杂材料结构和力相互作用",
        "动机": "现有可微分物理模型的粒度粗糙，无法准确模拟复杂物理现象，需要开发细粒度模型以提高模拟的准确性和应用范围",
        "方法": "提出一种新的可微分织物模型，深入到纱线级别模拟单个纱线的物理和纱线间的相互作用，并开发了几种可微分的力以促进基于梯度的学习",
        "关键词": [
            "可微分物理",
            "纱线级模型",
            "织物模拟",
            "梯度学习",
            "物理参数学习"
        ],
        "涉及的技术概念": {
            "可微分物理建模": "将物理模型与基于梯度的学习相结合，提供模型的可解释性和数据效率",
            "纱线级模型": "深入到纱线的粒度，模拟单个纱线的物理和纱线间的相互作用，以提高模拟的准确性",
            "可微分力": "在经验物理中不可微分的力被设计为可微分，以促进基于梯度的学习，扩展模型的应用范围"
        },
        "success": true
    },
    {
        "order": 350,
        "title": "Finetuned Language Models are Zero-Shot Learners",
        "html": "https://iclr.cc//virtual/2022/poster/6254",
        "abstract": "This paper explores a simple method for improving the zero-shot learning abilities of language models. We show that instruction tuning—finetuning language models on a collection of datasets described via instructions—substantially improves zero-shot performance on unseen tasks. We take a 137B parameter pretrained language model and instruction tune it on over 60 NLP datasets verbalized via natural language instruction templates. We evaluate this instruction-tuned model, which we call FLAN, on unseen task types. FLAN substantially improves the performance of its unmodified counterpart and surpasses zero-shot 175B GPT-3 on 20 of 25 datasets that we evaluate. FLAN even outperforms few-shot GPT-3 by a large margin on ANLI, RTE, BoolQ, AI2-ARC, OpenbookQA, and StoryCloze. Ablation studies reveal that number of finetuning datasets, model scale, and natural language instructions are key to the success of instruction tuning.",
        "conference": "ICLR",
        "中文标题": "微调语言模型作为零样本学习者",
        "摘要翻译": "本文探讨了一种简单的方法来提升语言模型的零样本学习能力。我们展示了指令调优——即在通过指令描述的数据集集合上对语言模型进行微调——显著提高了在未见任务上的零样本表现。我们采用了一个1370亿参数的预训练语言模型，并在超过60个通过自然语言指令模板表述的NLP数据集上进行了指令调优。我们评估了这个经过指令调优的模型，我们称之为FLAN，在未见任务类型上的表现。FLAN显著提高了其未经修改的对应模型的性能，并在我们评估的25个数据集中的20个上超过了零样本1750亿参数的GPT-3。FLAN在ANLI、RTE、BoolQ、AI2-ARC、OpenbookQA和StoryCloze等数据集上甚至大幅优于少量样本的GPT-3。消融研究表明，微调数据集的数量、模型规模和自然语言指令是指令调优成功的关键。",
        "领域": "自然语言处理与视觉结合",
        "问题": "如何提升语言模型在未见任务上的零样本学习能力",
        "动机": "探索通过指令调优方法提升语言模型在零样本学习任务上的表现",
        "方法": "在多个通过自然语言指令表述的NLP数据集上对预训练语言模型进行指令调优",
        "关键词": [
            "指令调优",
            "零样本学习",
            "语言模型",
            "NLP数据集",
            "自然语言处理"
        ],
        "涉及的技术概念": {
            "指令调优": "在通过指令描述的数据集集合上对语言模型进行微调，以提高其在未见任务上的零样本表现",
            "零样本学习": "模型在没有直接训练样本的情况下执行任务的能力",
            "自然语言指令": "用于描述任务和目标的人类可读的指令，指导模型如何执行特定任务"
        },
        "success": true
    },
    {
        "order": 351,
        "title": "Fine-Tuning can Distort Pretrained Features and Underperform Out-of-Distribution",
        "html": "https://iclr.cc//virtual/2022/poster/5945",
        "abstract": "When transferring a pretrained model to a downstream task, two popular methods are full fine-tuning (updating all the model parameters) and linear probing (updating only the last linear layer---the 'head'). It is well known that fine-tuning leads to better accuracy in-distribution (ID). However, in this paper, we find that fine-tuning can achieve worse accuracy than linear probing out-of-distribution (OOD) when the pretrained features are good and the distribution shift is large. On 10 distribution shift datasets (BREEDS-Living17, BREEDS-Entity30, DomainNet, CIFAR $\\to$ STL, CIFAR-10.1, FMoW, ImageNetV2, ImageNet-R, ImageNet-A, ImageNet-Sketch), fine-tuning obtains on average 2% higher accuracy ID but 7% lower accuracy OOD than linear probing. We show theoretically that this tradeoff between ID and OOD accuracy arises even in a simple setting: fine-tuning overparameterized two-layer linear networks. We prove that the OOD error of fine-tuning is high when we initialize with a fixed or random head---this is because while fine-tuning learns the head, the lower layers of the neural network change simultaneously and distort the pretrained features. Our analysis suggests that the easy two-step strategy of linear probing then full fine-tuning (LP-FT), sometimes used as a fine-tuning heuristic, combines the benefits of both fine-tuning and linear probing. Empirically, LP-FT outperforms both fine-tuning and linear probing on the above datasets (1% better ID, 10% better OOD than full fine-tuning).",
        "conference": "ICLR",
        "中文标题": "微调可能扭曲预训练特征并在分布外表现不佳",
        "摘要翻译": "在将预训练模型迁移到下游任务时，两种流行的方法是全面微调（更新所有模型参数）和线性探测（仅更新最后的线性层——'头部'）。众所周知，微调在分布内（ID）能带来更高的准确率。然而，在本文中，我们发现当预训练特征良好且分布变化较大时，微调在分布外（OOD）的准确率可能低于线性探测。在10个分布变化数据集（BREEDS-Living17、BREEDS-Entity30、DomainNet、CIFAR→STL、CIFAR-10.1、FMoW、ImageNetV2、ImageNet-R、ImageNet-A、ImageNet-Sketch）上，微调在分布内的平均准确率比线性探测高2%，但在分布外低7%。我们从理论上证明，即使在简单的设置中——过参数化的两层线性网络的微调——这种ID和OOD准确率之间的权衡也会出现。我们证明，当我们用固定或随机的头部初始化时，微调的OOD误差较高——这是因为在微调学习头部的同时，神经网络的较低层同时变化并扭曲了预训练的特征。我们的分析表明，线性探测然后全面微调（LP-FT）的简单两步策略，有时作为微调启发式使用，结合了微调和线性探测的好处。实证上，LP-FT在上述数据集上优于微调和线性探测（比全面微调在ID上好1%，在OOD上好10%）。",
        "领域": "迁移学习, 深度学习优化, 模型微调",
        "问题": "研究微调预训练模型在下游任务中可能导致的预训练特征扭曲和分布外表现不佳的问题",
        "动机": "探索在预训练特征良好且分布变化较大时，微调为何在分布外表现不如线性探测，并提出解决方案",
        "方法": "通过理论分析和实证研究，比较全面微调和线性探测在分布内外的表现，提出线性探测后全面微调（LP-FT）的两步策略",
        "关键词": [
            "微调",
            "线性探测",
            "分布外泛化",
            "迁移学习",
            "模型优化"
        ],
        "涉及的技术概念": {
            "全面微调": "更新预训练模型的所有参数以适应下游任务，可能导致预训练特征的扭曲",
            "线性探测": "仅更新预训练模型最后的线性层（头部），保持其他层不变，以减少对预训练特征的干扰",
            "LP-FT策略": "先进行线性探测然后进行全面微调的两步策略，旨在结合线性探测和全面微调的优势，提高模型在分布内外的表现"
        },
        "success": true
    },
    {
        "order": 352,
        "title": "Finite-Time Convergence and Sample Complexity of Multi-Agent Actor-Critic Reinforcement Learning with Average Reward",
        "html": "https://iclr.cc//virtual/2022/poster/6851",
        "abstract": "In this paper, we establish the first finite-time convergence result of the actor-critic algorithm for fully decentralized multi-agent reinforcement learning (MARL) problems with average reward. In this problem, a set of $N$ agents work cooperatively to maximize the global average reward through interacting with their neighbors over a communication network.We consider a practical MARL setting, where the rewards and actions of each agent are only known to itself, and the knowledge of joint actions of the agents is not assumed. Toward this end, we propose a mini-batch Markovian sampled fully decentralized actor-critic algorithm and analyze its finite-time convergence and sample complexity.We show that the sample complexity of this algorithm is $\\mathcal{O}(N^{2}/\\epsilon^{2}\\log(N/\\epsilon))$.Interestingly, this sample complexity bound matches that of the state-of-the-art single-agent actor-critic algorithms for reinforcement learning. ",
        "conference": "ICLR",
        "success": true,
        "中文标题": "基于平均奖励的多智能体Actor-Critic强化学习的有限时间收敛性和样本复杂度",
        "摘要翻译": "本文针对具有平均奖励的完全去中心化多智能体强化学习（MARL）问题，建立了actor-critic算法的第一个有限时间收敛结果。在这个问题中，一组 $N$ 个智能体通过在通信网络上与其邻居交互，协同工作以最大化全局平均奖励。我们考虑了一个实际的MARL设置，其中每个智能体的奖励和动作仅为自身所知，并且不假定智能体联合动作的知识。为此，我们提出了一种小批量马尔可夫采样完全去中心化actor-critic算法，并分析了它的有限时间收敛性和样本复杂度。我们证明了该算法的样本复杂度为$\\mathcal{O}(N^{2}/\\epsilon^{2}\\log(N/\\epsilon))$。有趣的是，这个样本复杂度界限与强化学习中最先进的单智能体actor-critic算法的样本复杂度界限相匹配。",
        "领域": "多智能体强化学习, Actor-Critic方法, 强化学习理论分析",
        "问题": "解决多智能体强化学习中actor-critic算法的有限时间收敛性和样本复杂度问题，尤其是在去中心化和平均奖励设置下。",
        "动机": "研究去中心化多智能体强化学习的actor-critic算法在实际应用中的可行性，并通过理论分析提供算法性能的保证，提高算法的效率和可靠性。",
        "方法": "提出一种小批量马尔可夫采样完全去中心化actor-critic算法，通过数学推导和证明，分析其有限时间收敛性和样本复杂度。",
        "关键词": [
            "多智能体强化学习",
            "Actor-Critic",
            "有限时间收敛",
            "样本复杂度",
            "去中心化"
        ],
        "涉及的技术概念": {
            "Actor-Critic算法": "一种结合了策略梯度方法（Actor）和价值函数方法（Critic）的强化学习算法，用于学习最优策略。",
            "平均奖励": "在强化学习中，智能体长期获得的平均奖励，用于评估策略的性能。"
        }
    },
    {
        "order": 353,
        "title": "Fixed Neural Network Steganography: Train the images, not the network",
        "html": "https://iclr.cc//virtual/2022/poster/6161",
        "abstract": "Recent attempts at image steganography make use of advances in deep learning to train an encoder-decoder network pair to hide and retrieve secret messages in images. These methods are able to hide large amounts of data, but they also incur high decoding error rates (around 20%). In this paper, we propose a novel algorithm for steganography that takes advantage of the fact that neural networks are sensitive to tiny perturbations. Our method, Fixed Neural Network Steganography (FNNS), yields significantly lower error rates when compared to prior state-of-the-art methods and achieves 0% error reliably for hiding up to 3 bits per pixel (bpp) of secret information in images. FNNS also successfully evades existing statistical steganalysis systems and can be modified to evade neural steganalysis systems as well. Recovering every bit correctly, up to 3 bpp, enables novel applications that requires encryption. We introduce one specific use case for facilitating anonymized and safe image sharing.  Our code is available at https://github.com/varshakishore/FNNS.",
        "conference": "ICLR",
        "中文标题": "固定神经网络隐写术：训练图像而非网络",
        "摘要翻译": "最近的图像隐写术尝试利用深度学习的进展，训练一个编码器-解码器网络对来隐藏和检索图像中的秘密信息。这些方法能够隐藏大量数据，但也会导致较高的解码错误率（约20%）。在本文中，我们提出了一种新颖的隐写术算法，该算法利用了神经网络对微小扰动敏感的事实。我们的方法，固定神经网络隐写术（FNNS），与之前的最先进方法相比，显著降低了错误率，并且在隐藏每像素最多3比特（bpp）的秘密信息时，可靠地实现了0%的错误率。FNNS还成功避开了现有的统计隐写分析系统，并且可以修改以避开神经隐写分析系统。正确恢复每一位，最多3 bpp，使得需要加密的新应用成为可能。我们介绍了一个具体的用例，以促进匿名和安全的图像共享。我们的代码可在https://github.com/varshakishore/FNNS获取。",
        "领域": "图像隐写术、深度学习安全应用、隐写分析对抗",
        "问题": "降低图像隐写术中的解码错误率并提高隐藏信息的容量",
        "动机": "利用神经网络对微小扰动的敏感性，开发一种能够高效隐藏和准确恢复秘密信息，同时避开隐写分析检测的方法",
        "方法": "提出固定神经网络隐写术（FNNS），通过训练图像而非网络来隐藏信息，显著降低解码错误率并提高信息隐藏容量",
        "关键词": [
            "图像隐写术",
            "固定神经网络",
            "隐写分析对抗",
            "信息隐藏",
            "深度学习安全"
        ],
        "涉及的技术概念": {
            "固定神经网络隐写术（FNNS）": "一种新颖的隐写术算法，通过训练图像而非网络来隐藏信息，显著降低解码错误率",
            "隐写分析对抗": "FNNS能够避开现有的统计和神经隐写分析系统的检测",
            "信息隐藏容量": "FNNS能够在隐藏每像素最多3比特的秘密信息时，实现0%的错误率"
        },
        "success": true
    },
    {
        "order": 354,
        "title": "FlexConv: Continuous Kernel Convolutions With Differentiable Kernel Sizes",
        "html": "https://iclr.cc//virtual/2022/poster/6763",
        "abstract": "When designing Convolutional Neural Networks (CNNs), one must select the size of the convolutional kernels before training. Recent works show CNNs benefit from different kernel sizes at different layers, but exploring all possible combinations is unfeasible in practice. A more efficient approach is to learn the kernel size during training. However, existing works that learn the kernel size have a limited bandwidth. These approaches scale kernels by dilation, and thus the detail they can describe is limited. In this work, we propose FlexConv, a novel convolutional operation with which high bandwidth convolutional kernels of learnable kernel size can be learned at a fixed parameter cost. FlexNets model long-term dependencies without the use of pooling, achieve state-of-the-art performance on several sequential datasets, outperform recent works with learned kernel sizes, and are competitive with much deeper ResNets on image benchmark datasets. Additionally, FlexNets can be deployed at higher resolutions than those seen during training. To avoid aliasing, we propose a novel kernel parameterization with which the frequency of the kernels can be analytically controlled. Our novel kernel parameterization shows higher descriptive power and faster convergence speed than existing parameterizations. This leads to important improvements in classification accuracy.",
        "conference": "ICLR",
        "中文标题": "FlexConv：具有可微分核大小的连续核卷积",
        "摘要翻译": "在设计卷积神经网络（CNNs）时，必须在训练前选择卷积核的大小。最近的研究表明，CNNs在不同层使用不同大小的核会受益，但在实践中探索所有可能的组合是不可行的。一种更高效的方法是在训练过程中学习核的大小。然而，现有学习核大小的方法带宽有限。这些方法通过扩张来缩放核，因此它们能描述的细节有限。在这项工作中，我们提出了FlexConv，一种新颖的卷积操作，可以在固定参数成本下学习具有可学习核大小的高带宽卷积核。FlexNets无需使用池化即可建模长期依赖关系，在多个序列数据集上实现了最先进的性能，优于最近的学习核大小的工作，并且在图像基准数据集上与更深的ResNets竞争激烈。此外，FlexNets可以在比训练时更高的分辨率下部署。为了避免混叠，我们提出了一种新颖的核参数化方法，可以解析控制核的频率。我们新颖的核参数化显示出比现有参数化更高的描述能力和更快的收敛速度。这导致了分类准确性的重要提升。",
        "领域": "卷积神经网络优化、序列数据处理、图像分类",
        "问题": "如何在固定参数成本下学习高带宽卷积核的大小，以提高卷积神经网络的性能和灵活性",
        "动机": "探索在训练过程中学习卷积核大小的高效方法，以克服现有方法带宽有限和细节描述不足的问题",
        "方法": "提出FlexConv操作和FlexNets，通过新颖的核参数化方法学习高带宽卷积核的大小，无需池化即可建模长期依赖关系",
        "关键词": [
            "FlexConv",
            "可微分核大小",
            "高带宽卷积核",
            "核参数化",
            "FlexNets"
        ],
        "涉及的技术概念": {
            "FlexConv": "一种新颖的卷积操作，允许在固定参数成本下学习高带宽卷积核的大小",
            "核参数化": "一种新颖的方法，用于解析控制卷积核的频率，避免混叠，提高描述能力和收敛速度",
            "FlexNets": "基于FlexConv构建的网络，无需池化即可建模长期依赖关系，在多个任务上实现高性能"
        },
        "success": true
    },
    {
        "order": 355,
        "title": "Focus on the Common Good: Group Distributional Robustness Follows",
        "html": "https://iclr.cc//virtual/2022/poster/6216",
        "abstract": "We consider the problem of training a classification model with group annotated training data. Recent work has established that, if there is distribution shift across different groups, models trained using the standard empirical risk minimization (ERM) objective suffer from poor performance on minority groups and that group distributionally robust optimization (Group-DRO) objective is a better alternative. The starting point of this paper is the observation that though Group-DRO performs better than ERM on minority groups for some benchmark datasets, there are several other datasets where it performs much worse than ERM. Inspired by ideas from the closely related problem of domain generalization, this paper proposes a new and simple algorithm that explicitly encourages learning of features that are shared across various groups. The key insight behind our proposed algorithm is that while Group-DRO focuses on groups with worst regularized loss, focusing instead, on groups that enable better performance even on other groups, could lead to learning of shared/common features, thereby enhancing minority performance beyond what is achieved by Group-DRO. Empirically, we show that our proposed algorithm matches or achieves better performance compared to strong contemporary baselines including ERM and Group-DRO on standard benchmarks on both minority groups and across all groups.  Theoretically, we show that the proposed algorithm is a descent method and finds first order stationary points of smooth nonconvex functions.",
        "conference": "ICLR",
        "中文标题": "关注共同利益：群体分布鲁棒性随之而来",
        "摘要翻译": "我们考虑使用带有群体标注的训练数据来训练分类模型的问题。最近的研究表明，如果不同群体之间存在分布偏移，使用标准经验风险最小化（ERM）目标训练的模型在少数群体上表现不佳，而群体分布鲁棒优化（Group-DRO）目标是一个更好的选择。本文的出发点是观察到，尽管在某些基准数据集上Group-DRO在少数群体上的表现优于ERM，但在其他几个数据集上，它的表现却比ERM差得多。受到与领域泛化密切相关问题的启发，本文提出了一种新的简单算法，明确鼓励学习跨群体的共享特征。我们提出的算法的关键见解是，虽然Group-DRO关注的是具有最差正则化损失的群体，但转而关注那些能够在其他群体上实现更好性能的群体，可能会导致学习共享/共同特征，从而在Group-DRO的基础上进一步提高少数群体的性能。实证上，我们展示了我们提出的算法在标准基准测试中，无论是在少数群体还是所有群体上，都达到或超过了包括ERM和Group-DRO在内的强大当代基线的性能。理论上，我们证明了所提出的算法是一种下降方法，并且能够找到平滑非凸函数的一阶稳定点。",
        "领域": "群体分布鲁棒性、领域泛化、少数群体性能优化",
        "问题": "解决在存在群体间分布偏移的情况下，分类模型在少数群体上表现不佳的问题",
        "动机": "提高分类模型在少数群体上的性能，通过学习跨群体的共享特征",
        "方法": "提出一种新算法，鼓励学习跨群体的共享特征，以提升模型在少数群体上的性能",
        "关键词": [
            "群体分布鲁棒性",
            "领域泛化",
            "共享特征学习",
            "少数群体性能",
            "经验风险最小化"
        ],
        "涉及的技术概念": {
            "群体分布鲁棒优化（Group-DRO）": "一种优化目标，旨在提高模型在不同群体上的鲁棒性，特别是在存在分布偏移的情况下",
            "经验风险最小化（ERM）": "标准训练目标，旨在最小化训练数据上的平均损失",
            "共享特征学习": "算法中鼓励学习跨群体的共同特征，以提高模型在少数群体上的性能"
        },
        "success": true
    },
    {
        "order": 356,
        "title": "Fooling Explanations in Text Classifiers",
        "html": "https://iclr.cc//virtual/2022/poster/5998",
        "abstract": "State-of-the-art text classification models are becoming increasingly reliant on deep neural networks (DNNs). Due to their black-box nature, faithful and robust explanation methods need to accompany classifiers for deployment in real-life scenarios. However, it has been shown that explanation methods in vision applications are susceptible to local, imperceptible perturbations that can significantly alter the explanations without changing the predicted classes. We show here that the existence of such perturbations extends to text classifiers as well. Specifically, we introduce TextExplanationFooler (TEF), a novel explanation attack algorithm that alters text input samples imperceptibly so that the outcome of widely-used explanation methods changes considerably while leaving classifier predictions unchanged. We evaluate the attribution robustness estimation performance of TEF on five text classification datasets, utilizing three DNN architectures and a transformer architecture for each dataset. By significantly decreasing the correlation between unchanged and perturbed input attributions, we show that all models and explanation methods are susceptible to TEF perturbations. Moreover, we evaluate how the perturbations transfer to other model architectures and attribution methods, finding better than random performance in scenarios where the exact attacked model and explanation method are unknown. Finally, we introduce a semi-universal attack that is able to compute fast, computationally light perturbations with no knowledge of the attacked classifier nor explanation method. Overall, our work shows that explanations in text classifiers are fragile and users need to carefully address their robustness before relying on them in critical applications.",
        "conference": "ICLR",
        "中文标题": "愚弄文本分类器中的解释",
        "摘要翻译": "最先进的文本分类模型越来越依赖于深度神经网络（DNNs）。由于其黑盒特性，在实际应用场景中部署时，需要忠实且鲁棒的解释方法伴随分类器。然而，已经证明，在视觉应用中的解释方法容易受到局部、不易察觉的扰动的影响，这些扰动可以显著改变解释而不改变预测类别。我们在此展示，这种扰动的存在也延伸到了文本分类器。具体来说，我们引入了TextExplanationFooler（TEF），一种新颖的解释攻击算法，它不易察觉地改变文本输入样本，使得广泛使用的解释方法的结果发生显著变化，同时保持分类器预测不变。我们在五个文本分类数据集上评估了TEF的归因鲁棒性估计性能，每个数据集利用了三种DNN架构和一种变压器架构。通过显著降低未改变和扰动输入归因之间的相关性，我们展示了所有模型和解释方法都容易受到TEF扰动的影响。此外，我们评估了这些扰动如何转移到其他模型架构和归因方法上，发现在攻击模型和解释方法未知的情况下，性能优于随机。最后，我们引入了一种半通用攻击，它能够在不知道被攻击分类器也不了解解释方法的情况下，计算快速、计算量小的扰动。总的来说，我们的工作表明，文本分类器中的解释是脆弱的，用户在关键应用中依赖它们之前需要仔细考虑其鲁棒性。",
        "领域": "自然语言处理与视觉结合、文本分类、深度学习安全",
        "问题": "文本分类器中的解释方法容易受到不易察觉的扰动影响，导致解释结果被显著改变而预测结果不变的问题。",
        "动机": "研究动机是揭示和解决文本分类器中解释方法的脆弱性，确保在实际应用中解释的可靠性和鲁棒性。",
        "方法": "引入TextExplanationFooler（TEF）算法，通过不易察觉地扰动文本输入，改变解释方法的结果而不影响分类器预测，评估其在多种模型和解释方法上的效果。",
        "关键词": [
            "文本分类",
            "解释攻击",
            "深度学习安全",
            "归因鲁棒性",
            "TEF算法"
        ],
        "涉及的技术概念": {
            "TextExplanationFooler（TEF）": "一种新颖的解释攻击算法，用于不易察觉地改变文本输入样本，使得解释方法的结果发生显著变化而分类器预测不变。",
            "归因鲁棒性": "评估解释方法在面对输入扰动时的稳定性和可靠性。",
            "半通用攻击": "一种不需要了解被攻击分类器或解释方法的具体细节，就能生成有效扰动的攻击方法。"
        },
        "success": true
    },
    {
        "order": 357,
        "title": "Fortuitous Forgetting in Connectionist Networks",
        "html": "https://iclr.cc//virtual/2022/poster/6512",
        "abstract": "Forgetting is often seen as an unwanted characteristic in both human and machine learning. However, we propose that forgetting can in fact be favorable to learning. We introduce forget-and-relearn as a powerful paradigm for shaping the learning trajectories of artificial neural networks. In this process, the forgetting step selectively removes undesirable information from the model, and the relearning step reinforces features that are consistently useful under different conditions. The forget-and-relearn framework unifies many existing iterative training algorithms in the image classification and language emergence literature, and allows us to understand the success of these algorithms in terms of the disproportionate forgetting of undesirable information. We leverage this understanding to improve upon existing algorithms by designing more targeted forgetting operations. Insights from our analysis provide a coherent view on the dynamics of iterative training in neural networks and offer a clear path towards performance improvements.",
        "conference": "ICLR",
        "中文标题": "连接网络中的偶然遗忘",
        "摘要翻译": "遗忘在人类和机器学习中常被视为一种不受欢迎的特性。然而，我们提出遗忘实际上可能有利于学习。我们引入了‘遗忘与重新学习’作为一种强大的范式，用于塑造人工神经网络的学习轨迹。在这一过程中，遗忘步骤有选择地从模型中移除不理想的信息，而重新学习步骤则强化在不同条件下持续有用的特征。‘遗忘与重新学习’框架统一了图像分类和语言涌现文献中的许多现有迭代训练算法，并使我们能够从不成比例地遗忘不理想信息的角度理解这些算法的成功。我们利用这一理解，通过设计更有针对性的遗忘操作来改进现有算法。我们的分析提供的见解为神经网络中迭代训练的动力学提供了一个连贯的视角，并为性能改进提供了一条清晰的路径。",
        "领域": "神经网络优化、图像分类、语言模型训练",
        "问题": "如何利用遗忘机制优化神经网络的学习过程",
        "动机": "探索遗忘在神经网络学习中的积极作用，以改进现有训练算法",
        "方法": "提出‘遗忘与重新学习’框架，通过选择性遗忘和有针对性的重新学习优化模型",
        "关键词": [
            "遗忘机制",
            "神经网络优化",
            "迭代训练",
            "图像分类",
            "语言模型"
        ],
        "涉及的技术概念": {
            "遗忘与重新学习": "一种通过选择性遗忘不理想信息和强化有用特征来优化神经网络学习过程的框架",
            "迭代训练算法": "在训练过程中多次重复学习步骤以逐步改进模型性能的方法",
            "选择性遗忘": "有针对性地从模型中移除特定信息以优化学习轨迹的技术"
        },
        "success": true
    },
    {
        "order": 358,
        "title": "FP-DETR: Detection Transformer Advanced by Fully Pre-training",
        "html": "https://iclr.cc//virtual/2022/poster/6043",
        "abstract": "Large-scale pre-training has proven to be effective for visual representation learning on downstream tasks, especially for improving robustness and generalization. However, the recently developed detection transformers only employ pre-training on its backbone while leaving the key component, i.e., a 12-layer transformer, being trained from scratch, which prevents the model from above benefits. This separated training paradigm is mainly caused by the discrepancy between the upstream and downstream tasks. To mitigate the issue, we propose FP-DETR, a new method that Fully Pre-Trains an encoder-only transformer and smoothly fine-tunes it for object detection via a task adapter. Inspired by the success of textual prompts in NLP, we treat query positional embeddings as visual prompts to help the model attend to the target area (prompting) and recognize the object. To this end, we propose the task adapter which leverages self-attention to model the contextual relation between object query embedding. Experiments on the challenging COCO dataset demonstrate that our FP-DETR achieves competitive performance. Moreover, it enjoys better robustness to common corruptions and generalization to small-size datasets than state-of-the-art detection transformers. Code will be made publicly available at https://github.com/encounter1997/FP-DETR.",
        "conference": "ICLR",
        "中文标题": "FP-DETR：通过完全预训练提升的检测变换器",
        "摘要翻译": "大规模预训练已被证明对下游任务的视觉表示学习有效，尤其是在提高鲁棒性和泛化能力方面。然而，最近开发的检测变换器仅在其骨干网络上进行预训练，而关键组件，即一个12层的变换器，是从头开始训练的，这阻碍了模型从上述优势中受益。这种分离的训练范式主要是由上游和下游任务之间的差异引起的。为了缓解这一问题，我们提出了FP-DETR，一种新方法，它完全预训练一个仅编码器的变换器，并通过任务适配器平滑地对其进行微调以进行目标检测。受到NLP中文本提示成功的启发，我们将查询位置嵌入视为视觉提示，以帮助模型关注目标区域（提示）并识别对象。为此，我们提出了任务适配器，它利用自注意力来建模对象查询嵌入之间的上下文关系。在具有挑战性的COCO数据集上的实验表明，我们的FP-DETR实现了竞争性的性能。此外，与最先进的检测变换器相比，它对常见损坏具有更好的鲁棒性，并且对小规模数据集具有更好的泛化能力。代码将在https://github.com/encounter1997/FP-DETR公开提供。",
        "领域": "目标检测",
        "问题": "检测变换器在预训练过程中仅对骨干网络进行预训练，而关键组件变换器层从头开始训练，导致模型无法充分利用大规模预训练的优势。",
        "动机": "解决检测变换器中预训练和微调之间的不一致问题，以提高模型的鲁棒性和泛化能力。",
        "方法": "提出FP-DETR方法，完全预训练一个仅编码器的变换器，并通过任务适配器平滑地进行微调，利用查询位置嵌入作为视觉提示来提升目标检测性能。",
        "关键词": [
            "FP-DETR",
            "完全预训练",
            "检测变换器",
            "任务适配器",
            "视觉提示"
        ],
        "涉及的技术概念": {
            "完全预训练": "对整个变换器模型进行预训练，而不仅仅是骨干网络，以提高模型的鲁棒性和泛化能力。",
            "任务适配器": "一种技术，用于在预训练模型和目标检测任务之间建立桥梁，通过微调来适应特定任务。",
            "视觉提示": "类似于NLP中的文本提示，用于引导模型关注图像中的特定区域，以提升目标检测的准确性。"
        },
        "success": true
    },
    {
        "order": 359,
        "title": "Frame Averaging for Invariant and Equivariant Network Design",
        "html": "https://iclr.cc//virtual/2022/poster/6189",
        "abstract": "Many machine learning tasks involve learning functions that are known to be invariant or equivariant to certain symmetries of the input data. However, it is often challenging to design neural network architectures that respect these symmetries while being expressive and computationally efficient. For example, Euclidean motion invariant/equivariant graph or point cloud neural networks. We introduce Frame Averaging (FA), a highly general purpose and systematic framework for adapting known (backbone) architectures to become invariant or equivariant to new symmetry types. Our framework builds on the well known group averaging operator that guarantees invariance or equivariance but is intractable. In contrast, we observe that for many important classes of symmetries, this operator can be replaced with an averaging operator over a small subset of the group elements, called a frame. We show that averaging over a frame guarantees exact invariance or equivariance while often being much simpler to compute than averaging over the entire group. Furthermore, we prove that FA-based models have maximal expressive power in a broad setting and in general preserve the expressive power of their backbone architectures. Using frame averaging, we propose a new class of universal Graph Neural Networks (GNNs), universal Euclidean motion invariant point cloud networks, and Euclidean motion invariant Message Passing (MP) GNNs. We demonstrate the practical effectiveness of FA on several applications including point cloud normal estimation, beyond $2$-WL graph separation, and $n$-body dynamics prediction, achieving state-of-the-art results in all of these benchmarks.",
        "conference": "ICLR",
        "中文标题": "帧平均用于不变和等变网络设计",
        "摘要翻译": "许多机器学习任务涉及学习已知对输入数据的某些对称性不变或等变的函数。然而，设计既尊重这些对称性又具有表达力且计算效率高的神经网络架构往往具有挑战性。例如，欧几里得运动不变/等变的图或点云神经网络。我们引入了帧平均（FA），这是一个高度通用和系统化的框架，用于使已知（骨干）架构适应新的对称类型，成为不变或等变的。我们的框架建立在众所周知的群平均算子之上，该算子保证了不变性或等变性，但计算上不可行。相比之下，我们观察到，对于许多重要的对称性类别，这个算子可以被替换为对群元素的一个小子集（称为帧）的平均算子。我们展示了在帧上平均保证了精确的不变性或等变性，同时通常比在整个群上平均要简单得多。此外，我们证明了基于FA的模型在广泛设置下具有最大的表达力，并且通常保留了其骨干架构的表达力。使用帧平均，我们提出了一类新的通用图神经网络（GNNs）、通用欧几里得运动不变点云网络和欧几里得运动不变消息传递（MP）GNNs。我们在几个应用上展示了FA的实际效果，包括点云法线估计、超越2-WL图分离和n体动力学预测，在所有这些基准测试中都达到了最先进的结果。",
        "领域": "图神经网络、点云处理、对称性学习",
        "问题": "设计既尊重输入数据对称性又具有表达力且计算效率高的神经网络架构",
        "动机": "解决在保持对称性不变或等变的同时，提高神经网络架构的表达力和计算效率的挑战",
        "方法": "引入帧平均（FA）框架，通过平均群元素的一个小子集（帧）来保证精确的不变性或等变性，同时保持计算效率",
        "关键词": [
            "帧平均",
            "对称性学习",
            "图神经网络",
            "点云处理",
            "欧几里得运动不变性"
        ],
        "涉及的技术概念": {
            "帧平均（FA）": "一种通过平均群元素的一个小子集（帧）来保证神经网络对特定对称性不变或等变的框架",
            "群平均算子": "传统上用于保证神经网络不变性或等变性的算子，但计算上不可行",
            "通用图神经网络（GNNs）": "一类新的图神经网络，能够处理广泛的对称性，同时保持高度的表达力"
        },
        "success": true
    },
    {
        "order": 360,
        "title": "Frequency-aware SGD for Efficient Embedding Learning with Provable Benefits",
        "html": "https://iclr.cc//virtual/2022/poster/6670",
        "abstract": "Embedding learning has found widespread applications in recommendation systems and natural language modeling, among other domains. To learn quality embeddings efficiently, adaptive learning rate algorithms have demonstrated superior empirical performance over SGD, largely accredited to their token-dependent learning rate. However, the underlying mechanism for the efficiency of token-dependent learning rate remains underexplored. We show that incorporating frequency information of tokens in the embedding learning problems leads to provably efficient algorithms, and demonstrate that common adaptive algorithms implicitly exploit the frequency information to a large extent. Specifically, we propose (Counter-based) Frequency-aware Stochastic Gradient Descent, which applies a frequency-dependent learning rate for each token, and exhibits provable speed-up compared to SGD when the token distribution is imbalanced. Empirically, we show the proposed algorithms are able to improve or match the performance of adaptive algorithms on benchmark recommendation tasks and a large-scale industrial recommendation system,  closing the performance gap between SGD and adaptive algorithms. Our results are the first to show token-dependent learning rate provably improves convergence for non-convex embedding learning problems.",
        "conference": "ICLR",
        "中文标题": "频率感知SGD用于高效嵌入学习及其可证明的优势",
        "摘要翻译": "嵌入学习在推荐系统和自然语言建模等领域有着广泛的应用。为了高效学习高质量的嵌入，自适应学习率算法在实证表现上优于SGD，这主要归功于它们的令牌依赖学习率。然而，令牌依赖学习率效率的底层机制仍未得到充分探索。我们展示了在嵌入学习问题中融入令牌的频率信息可以产生可证明的高效算法，并且证明了常见的自适应算法在很大程度上隐式地利用了频率信息。具体来说，我们提出了（基于计数器的）频率感知随机梯度下降，它为每个令牌应用了一个依赖于频率的学习率，并且在令牌分布不平衡时，与SGD相比，展现了可证明的加速效果。实证上，我们展示了所提出的算法能够在基准推荐任务和一个大规模工业推荐系统上改进或匹配自适应算法的性能，缩小了SGD与自适应算法之间的性能差距。我们的结果首次展示了令牌依赖学习率可证明地改善了非凸嵌入学习问题的收敛性。",
        "领域": "推荐系统、自然语言处理、嵌入学习",
        "问题": "探索令牌依赖学习率在嵌入学习中的效率机制，并提出一种能够利用令牌频率信息以提高学习效率的算法。",
        "动机": "当前自适应学习率算法在嵌入学习中表现出色，但其效率的底层机制不明确，且SGD与自适应算法之间存在性能差距。",
        "方法": "提出频率感知随机梯度下降（Frequency-aware SGD），通过为每个令牌应用频率依赖的学习率，以在令牌分布不平衡时加速收敛。",
        "关键词": [
            "嵌入学习",
            "频率感知",
            "随机梯度下降",
            "推荐系统",
            "自然语言处理"
        ],
        "涉及的技术概念": {
            "令牌依赖学习率": "根据令牌的频率调整学习率，以提高嵌入学习的效率和性能。",
            "频率感知随机梯度下降": "一种改进的SGD算法，通过考虑令牌的频率信息来调整学习率，旨在加速收敛。",
            "非凸嵌入学习问题": "指在嵌入学习中遇到的优化问题，其目标函数通常是非凸的，使得传统的优化方法难以保证全局最优解。"
        },
        "success": true
    },
    {
        "order": 361,
        "title": "From Intervention to Domain Transportation: A Novel Perspective to Optimize Recommendation",
        "html": "https://iclr.cc//virtual/2022/poster/6653",
        "abstract": "The interventional nature of recommendation has attracted increasing attention in recent years. It particularly motivates researchers to formulate learning and evaluating recommendation as causal inference and data missing-not-at-random problems. However, few take seriously the consequence of violating the critical assumption of overlapping, which we prove can significantly threaten the validity and interpretation of the outcome. We find a critical piece missing in the current understanding of information retrieval (IR) systems: as interventions, recommendation not only affects the already observed data, but it also interferes with the target domain (distribution) of interest. We then rephrase optimizing recommendation as finding an intervention that best transports the patterns it learns from the observed domain to its intervention domain. Towards this end, we use domain transportation to characterize the learning-intervention mechanism of recommendation. We design a principled transportation-constraint risk minimization objective and convert it to a two-player minimax game.We prove the consistency, generalization, and excessive risk bounds for the proposed objective, and elaborate how they compare to the current results. Finally, we carry out extensive real-data and semi-synthetic experiments to demonstrate the advantage of our approach, and launch online testing with a real-world IR system.",
        "conference": "ICLR",
        "中文标题": "从干预到领域迁移：优化推荐的新视角",
        "摘要翻译": "近年来，推荐的干预性质引起了越来越多的关注。这特别激励研究人员将推荐的学习和评估表述为因果推断和数据非随机缺失问题。然而，很少有人认真对待违反重叠关键假设的后果，我们证明这会显著威胁结果的有效性和解释。我们发现当前对信息检索（IR）系统的理解中缺少一个关键部分：作为干预，推荐不仅影响已经观察到的数据，而且还干扰感兴趣的目标领域（分布）。然后，我们将优化推荐重新表述为寻找一个干预，该干预最好地将其从观察到的领域学习到的模式迁移到其干预领域。为此，我们使用领域迁移来表征推荐的学习-干预机制。我们设计了一个有原则的迁移约束风险最小化目标，并将其转换为一个双玩家极小极大游戏。我们证明了所提出目标的一致性、泛化和过度风险界限，并详细阐述了它们与当前结果的比较。最后，我们进行了大量的真实数据和半合成实验，以证明我们方法的优势，并与真实世界的信息检索系统启动了在线测试。",
        "领域": "推荐系统、因果推断、信息检索",
        "问题": "解决推荐系统中因干预导致的领域分布变化问题",
        "动机": "当前推荐系统研究忽视了干预对目标领域分布的影响，导致结果解释和有效性受限",
        "方法": "提出将推荐优化问题重新定义为领域迁移问题，设计迁移约束风险最小化目标，并通过双玩家极小极大游戏实现",
        "关键词": [
            "推荐系统",
            "领域迁移",
            "因果推断",
            "信息检索",
            "风险最小化"
        ],
        "涉及的技术概念": {
            "领域迁移": "用于描述推荐系统如何将学习到的模式从观察到的领域迁移到干预领域",
            "双玩家极小极大游戏": "用于实现迁移约束风险最小化目标的优化框架",
            "风险界限": "用于评估所提出目标在一致性、泛化和过度风险方面的理论保证"
        },
        "success": true
    },
    {
        "order": 362,
        "title": "From Stars to Subgraphs: Uplifting Any GNN with Local Structure Awareness",
        "html": "https://iclr.cc//virtual/2022/poster/6178",
        "abstract": "Message Passing Neural Networks (MPNNs) are a common type of Graph Neural Network (GNN), in which each node’s representation is computed recursively by aggregating representations (“messages”) from its immediate neighbors akin to a star-shaped pattern. MPNNs are appealing for being efficient and scalable, however their expressiveness is upper-bounded by the 1st-order Weisfeiler-Lehman isomorphism test (1-WL). In response, prior works propose highly expressive models at the cost of scalability and sometimes generalization performance. Our work stands between these two regimes: we introduce a general framework to uplift any MPNN to be more expressive, with limited scalability overhead and greatly improved practical performance. We achieve this by extending local aggregation in MPNNs from star patterns to general subgraph patterns (e.g., k-egonets): in our framework, each node representation is computed as the encoding of a surrounding induced subgraph rather than encoding of immediate neighbors only (i.e. a star). We choose the subgraph encoder to be a GNN (mainly MPNNs, considering scalability) to design a general framework that serves as a wrapper to uplift any GNN. We call our proposed method GNN-AK (GNN As Kernel), as the framework resembles a convolutional neural network by replacing the kernel withGNNs. Theoretically, we show that our framework is strictly more powerful than 1&2-WL, and is not less powerful than 3-WL. We also design subgraph sampling strategies which greatly reduce memory footprint and improve speed while maintaining performance. Our method sets new state-of-the-art performance by large margins for several well-known graph ML tasks; specifically, 0.08 MAE on ZINC,74.79% and 86.887% accuracy on CIFAR10 and PATTERN respectively.",
        "conference": "ICLR",
        "中文标题": "从星形到子图：通过局部结构感知提升任意图神经网络",
        "摘要翻译": "消息传递神经网络（MPNNs）是图神经网络（GNN）的一种常见类型，其中每个节点的表示通过递归聚合其直接邻居的表示（“消息”）来计算，类似于星形模式。MPNNs因其高效和可扩展性而受到青睐，但其表达能力受限于一阶Weisfeiler-Lehman同构测试（1-WL）。为此，先前的工作提出了具有高表达能力的模型，但牺牲了可扩展性和有时泛化性能。我们的工作介于这两种情况之间：我们引入了一个通用框架，以有限的可扩展性开销和显著提高的实际性能，提升任何MPNN的表达能力。我们通过将MPNN中的局部聚合从星形模式扩展到一般子图模式（例如，k-egonets）来实现这一点：在我们的框架中，每个节点的表示被计算为周围诱导子图的编码，而不仅仅是直接邻居的编码（即星形）。我们选择子图编码器为GNN（主要是考虑到可扩展性的MPNNs），以设计一个通用框架，作为提升任何GNN的包装器。我们称我们提出的方法为GNN-AK（GNN As Kernel），因为该框架类似于卷积神经网络，通过用GNN替换内核。理论上，我们展示了我们的框架严格比1&2-WL更强大，并且不比3-WL弱。我们还设计了子图采样策略，大大减少了内存占用并提高了速度，同时保持了性能。我们的方法在几个著名的图机器学习任务中大幅刷新了最先进的性能；具体来说，在ZINC上为0.08 MAE，在CIFAR10和PATTERN上分别为74.79%和86.887%的准确率。",
        "领域": "图神经网络、图表示学习、图结构分析",
        "问题": "提升图神经网络（GNN）的表达能力而不显著牺牲其可扩展性和泛化性能",
        "动机": "现有的高表达能力图神经网络模型往往牺牲了可扩展性和泛化性能，需要在表达能力和实用性之间找到平衡",
        "方法": "通过扩展局部聚合从星形模式到一般子图模式，引入一个通用框架GNN-AK，以提升任何GNN的表达能力，同时设计子图采样策略优化性能",
        "关键词": [
            "图神经网络",
            "消息传递神经网络",
            "子图编码",
            "Weisfeiler-Lehman测试",
            "GNN-AK"
        ],
        "涉及的技术概念": {
            "消息传递神经网络（MPNNs）": "一种图神经网络，通过递归聚合邻居节点的信息来计算节点表示",
            "Weisfeiler-Lehman同构测试（WL）": "用于评估图神经网络表达能力的测试，本文提出的框架在表达能力上超越了1&2-WL，不弱于3-WL",
            "GNN-AK（GNN As Kernel）": "提出的通用框架，通过将GNN作为内核替换，提升任何GNN的表达能力，同时保持可扩展性"
        },
        "success": true
    },
    {
        "order": 363,
        "title": "GATSBI: Generative Adversarial Training for Simulation-Based Inference",
        "html": "https://iclr.cc//virtual/2022/poster/6518",
        "abstract": "Simulation-based inference (SBI) refers to statistical inference on stochastic models for which we can generate samples, but not compute likelihoods.Like SBI algorithms, generative adversarial networks (GANs) do not require explicit likelihoods. We study the relationship between SBI and GANs, and introduce GATSBI, an adversarial approach to SBI. GATSBI reformulates the variational objective in an adversarial setting to learn implicit posterior distributions. Inference with GATSBI is amortised across observations, works in high-dimensional posterior spaces and supports implicit priors. We evaluate GATSBI on two common SBI benchmark problems and on two high-dimensional simulators. On a model for wave propagation on the surface of a shallow water body, we show that GATSBI can return well-calibrated posterior estimates even in high dimensions. On a model of camera optics, it infers a high-dimensional posterior given an implicit prior, and performs better than astate-of-the-art SBI approach. We also show how GATSBI can be extended to perform sequential posterior estimation to focus on individual observations.Overall, GATSBI opens up opportunities for leveraging advances in GANs to perform Bayesian inference on high-dimensional simulation-based models.",
        "conference": "ICLR",
        "中文标题": "GATSBI：基于模拟推理的生成对抗训练",
        "摘要翻译": "基于模拟的推理（SBI）指的是对我们可以生成样本但不能计算似然的随机模型进行统计推断。与SBI算法一样，生成对抗网络（GANs）也不需要显式的似然。我们研究了SBI与GANs之间的关系，并介绍了GATSBI，一种SBI的对抗方法。GATSBI在对抗环境中重新制定了变分目标，以学习隐式后验分布。使用GATSBI进行的推理在观察中摊销，适用于高维后验空间，并支持隐式先验。我们在两个常见的SBI基准问题和两个高维模拟器上评估了GATSBI。在一个浅水体表面波传播模型上，我们展示了GATSBI即使在高维情况下也能返回良好校准的后验估计。在一个相机光学模型上，它在给定隐式先验的情况下推断出一个高维后验，并且表现优于最先进的SBI方法。我们还展示了如何扩展GATSBI以执行顺序后验估计，以专注于个别观察。总体而言，GATSBI为利用GANs的进展在高维基于模拟的模型上执行贝叶斯推理开辟了机会。",
        "领域": "生成对抗网络, 贝叶斯推理, 高维模拟",
        "问题": "解决在高维模拟模型中执行贝叶斯推理时无法计算似然的问题",
        "动机": "探索生成对抗网络（GANs）与基于模拟的推理（SBI）之间的关系，开发一种新的对抗方法GATSBI，以在高维模拟模型中执行有效的贝叶斯推理",
        "方法": "在对抗环境中重新制定变分目标，学习隐式后验分布，支持高维后验空间和隐式先验",
        "关键词": [
            "生成对抗网络",
            "贝叶斯推理",
            "高维模拟",
            "隐式后验",
            "变分目标"
        ],
        "涉及的技术概念": {
            "生成对抗网络（GANs）": "用于学习隐式后验分布，不需要显式的似然计算",
            "变分目标": "在对抗环境中重新制定，以优化后验分布的学习",
            "隐式后验": "GATSBI学习的目标，适用于高维空间和复杂模型"
        },
        "success": true
    },
    {
        "order": 364,
        "title": "Gaussian Mixture Convolution Networks",
        "html": "https://iclr.cc//virtual/2022/poster/5970",
        "abstract": "This paper proposes a novel method for deep learning based on the analytical convolution of multidimensional Gaussian mixtures.In contrast to tensors, these do not suffer from the curse of dimensionality and allow for a compact representation, as data is only stored where details exist.Convolution kernels and data are Gaussian mixtures with unconstrained weights, positions, and covariance matrices.Similar to discrete convolutional networks, each convolution step produces several feature channels, represented by independent Gaussian mixtures.Since traditional transfer functions like ReLUs do not produce Gaussian mixtures, we propose using a fitting of these functions instead.This fitting step also acts as a pooling layer if the number of Gaussian components is reduced appropriately.We demonstrate that networks based on this architecture reach competitive accuracy on Gaussian mixtures fitted to the MNIST and ModelNet data sets.",
        "conference": "ICLR",
        "中文标题": "高斯混合卷积网络",
        "摘要翻译": "本文提出了一种基于多维高斯混合解析卷积的深度学习方法。与张量相比，这种方法不受维度诅咒的影响，并允许紧凑表示，因为数据仅存储在存在细节的地方。卷积核和数据是具有无约束权重、位置和协方差矩阵的高斯混合。类似于离散卷积网络，每个卷积步骤产生几个特征通道，由独立的高斯混合表示。由于传统的传递函数如ReLUs不产生高斯混合，我们建议使用这些函数的拟合来代替。如果适当减少高斯组件的数量，这个拟合步骤也可以作为池化层。我们证明，基于这种架构的网络在拟合到MNIST和ModelNet数据集的高斯混合上达到了竞争性的准确度。",
        "领域": "深度学习架构设计、图像识别、三维形状识别",
        "问题": "如何在深度学习中有效处理高维数据并保持模型的紧凑性和准确性",
        "动机": "解决传统深度学习方法在处理高维数据时面临的维度诅咒问题，以及如何更有效地表示和存储数据",
        "方法": "提出了一种基于多维高斯混合解析卷积的深度学习方法，使用高斯混合表示卷积核和数据，通过拟合传递函数替代传统方法，并在适当情况下减少高斯组件数量作为池化层",
        "关键词": [
            "高斯混合模型",
            "卷积网络",
            "深度学习架构",
            "MNIST数据集",
            "ModelNet数据集"
        ],
        "涉及的技术概念": {
            "高斯混合模型": "用于表示卷积核和数据，允许无约束的权重、位置和协方差矩阵，以紧凑形式存储数据",
            "解析卷积": "对多维高斯混合进行卷积操作，避免了维度诅咒，提高了处理高维数据的效率",
            "传递函数拟合": "替代传统的ReLU等传递函数，以保持高斯混合的特性，并在适当情况下实现池化功能"
        },
        "success": true
    },
    {
        "order": 365,
        "title": "GDA-AM: ON THE EFFECTIVENESS OF SOLVING MIN-IMAX OPTIMIZATION VIA ANDERSON MIXING",
        "html": "https://iclr.cc//virtual/2022/poster/6099",
        "abstract": "Many modern machine learning algorithms such as generative adversarial networks (GANs) and adversarial training can be formulated as minimax optimization.Gradient descent ascent (GDA) is the most commonly used algorithm due to its simplicity.  However, GDA can converge to non-optimal minimax points.  We propose a new minimax optimization framework,GDA-AM, that views the GDA dynamics as a fixed-point iteration and solves it using Anderson Mixing to converge to the local minimax. It addresses the diverging issue of simultaneous GDA and accelerates the convergence of alternating GDA. We show theoretically that the algorithm can achieve global convergence for bilinear problems under mildconditions. We also empirically show that GDA-AM solves a variety of minimax problems and improves GAN training on several datasets",
        "conference": "ICLR",
        "中文标题": "GDA-AM：关于通过安德森混合解决极小极大优化问题的有效性",
        "摘要翻译": "许多现代机器学习算法，如生成对抗网络（GANs）和对抗训练，可以被表述为极小极大优化问题。梯度下降上升（GDA）由于其简单性成为最常用的算法。然而，GDA可能会收敛到非最优的极小极大点。我们提出了一个新的极小极大优化框架GDA-AM，它将GDA动态视为固定点迭代，并使用安德森混合来解决它，以收敛到局部极小极大。它解决了同步GDA的发散问题，并加速了交替GDA的收敛。我们从理论上证明了该算法在温和条件下可以实现双线性问题的全局收敛。我们还通过实验表明，GDA-AM解决了多种极小极大问题，并在多个数据集上改进了GAN的训练。",
        "领域": "生成对抗网络、对抗训练、优化算法",
        "问题": "解决GDA算法在极小极大优化中可能收敛到非最优点的问题",
        "动机": "提高极小极大优化问题的求解效率和准确性，特别是在生成对抗网络和对抗训练中的应用",
        "方法": "提出GDA-AM框架，将GDA动态视为固定点迭代，并应用安德森混合技术以改善收敛性",
        "关键词": [
            "极小极大优化",
            "安德森混合",
            "生成对抗网络",
            "梯度下降上升",
            "对抗训练"
        ],
        "涉及的技术概念": {
            "梯度下降上升（GDA）": "一种常用的优化算法，用于解决极小极大问题，但在某些情况下可能收敛到非最优点",
            "安德森混合": "一种加速固定点迭代收敛的技术，用于改进GDA算法的性能",
            "局部极小极大": "优化问题的一个解概念，表示在局部范围内达到的极小极大点"
        },
        "success": true
    },
    {
        "order": 366,
        "title": "GeneDisco: A Benchmark for Experimental Design in Drug Discovery",
        "html": "https://iclr.cc//virtual/2022/poster/6889",
        "abstract": "In vitro cellular experimentation with genetic interventions, using for example CRISPR technologies, is an essential step in early-stage drug discovery and target validation that serves to assess initial hypotheses about causal associations between biological mechanisms and disease pathologies. With billions of potential hypotheses to test, the experimental design space for in vitro genetic experiments is extremely vast, and the available experimental capacity - even at the largest research institutions in the world - pales in relation to the size of this biological hypothesis space. Machine learning methods, such as active and reinforcement learning, could aid in optimally exploring the vast biological space by integrating prior knowledge from various information sources as well as extrapolating to yet unexplored areas of the experimental design space based on available data. However, there exist no standardised benchmarks and data sets for this challenging task and little research has been conducted in this area to date. Here, we introduce GeneDisco, a benchmark suite for evaluating active learning algorithms for experimental design in drug discovery. GeneDisco contains a curated set of multiple publicly available experimental data sets as well as open-source implementations of state-of-the-art active learning policies for experimental design and exploration.",
        "conference": "ICLR",
        "中文标题": "GeneDisco: 药物发现中实验设计的基准",
        "摘要翻译": "利用基因干预（例如CRISPR技术）进行的体外细胞实验是早期药物发现和靶点验证的关键步骤，旨在评估关于生物机制与疾病病理之间因果关联的初始假设。面对数十亿个待测试的潜在假设，体外基因实验的设计空间极为广阔，而即便是世界上最大研究机构的可用实验能力，与这一生物假设空间的规模相比也显得微不足道。机器学习方法，如主动学习和强化学习，可以通过整合来自各种信息源的先验知识，以及基于现有数据推断实验设计空间中尚未探索的区域，来帮助最优地探索这一广阔的生物学空间。然而，目前尚无针对这一挑战性任务的标准基准和数据集，且该领域的研究也相对匮乏。在此，我们介绍了GeneDisco，一个用于评估药物发现中实验设计的主动学习算法的基准套件。GeneDisco包含了一系列精选的公开可用实验数据集，以及用于实验设计和探索的最先进主动学习策略的开源实现。",
        "领域": "药物发现、基因编辑技术、机器学习应用",
        "问题": "如何高效探索广阔的体外基因实验设计空间以验证生物机制与疾病病理之间的因果关联",
        "动机": "解决在药物发现早期阶段，面对庞大的生物假设空间，实验能力有限的问题",
        "方法": "引入GeneDisco基准套件，整合公开实验数据集和先进主动学习策略，评估和优化实验设计",
        "关键词": [
            "药物发现",
            "基因编辑",
            "主动学习",
            "实验设计",
            "机器学习"
        ],
        "涉及的技术概念": {
            "主动学习": "用于优化实验设计过程，通过选择最有信息量的样本来减少实验次数",
            "CRISPR技术": "用于进行基因干预，验证生物机制与疾病之间的因果关联",
            "强化学习": "在探索实验设计空间时，用于基于现有数据推断未探索区域的方法"
        },
        "success": true
    },
    {
        "order": 367,
        "title": "Generalisation in Lifelong Reinforcement Learning through Logical Composition ",
        "html": "https://iclr.cc//virtual/2022/poster/6562",
        "abstract": "We leverage logical composition in reinforcement learning to create a framework that enables an agent to autonomously determine whether a new task can be immediately solved using its existing abilities, or whether a task-specific skill should be learned. In the latter case, the proposed algorithm also enables the agent to learn the new task faster by generating an estimate of the optimal policy. Importantly, we provide two main theoretical results: we bound the performance of the transferred policy on a new task, and we give bounds on the necessary and sufficient number of tasks that need to be learned throughout an agent's lifetime to generalise over a distribution. We verify our approach in a series of experiments, where we perform transfer learning both after learning a set of base tasks, and after learning an arbitrary set of tasks. We also demonstrate that, as a side effect of our transfer learning approach, an agent can produce an interpretable Boolean expression of its understanding of the current task. Finally, we demonstrate our approach in the full lifelong setting where an agent receives tasks from an unknown distribution. Starting from scratch, an agent is able to quickly generalise over the task distribution after learning only a few tasks, which are sub-logarithmic in the size of the task space.",
        "conference": "ICLR",
        "中文标题": "终身强化学习中的逻辑组合泛化",
        "摘要翻译": "我们利用强化学习中的逻辑组合创建了一个框架，使智能体能够自主判断新任务是否可以利用其现有能力立即解决，或者是否需要学习特定任务的技能。在后一种情况下，所提出的算法还通过生成最优策略的估计，使智能体能够更快地学习新任务。重要的是，我们提供了两个主要的理论结果：我们界定了转移策略在新任务上的性能，并给出了智能体在其生命周期中需要学习的任务数量的必要和充分界限，以在分布上进行泛化。我们在一系列实验中验证了我们的方法，其中我们在学习了一组基础任务后以及在学习了一组任意任务后进行了迁移学习。我们还证明，作为我们迁移学习方法的一个副作用，智能体可以产生一个可解释的布尔表达式，表达其对当前任务的理解。最后，我们在完整的终身学习设置中展示了我们的方法，其中智能体从未知分布接收任务。从零开始，智能体在学习仅少数任务后能够快速泛化任务分布，这些任务在任务空间的大小上是次对数的。",
        "领域": "强化学习、迁移学习、终身学习",
        "问题": "如何在终身强化学习中通过逻辑组合实现任务的快速泛化和高效学习",
        "动机": "解决智能体在面对新任务时如何有效利用已有知识和技能，以及如何快速学习新技能的问题",
        "方法": "提出了一种基于逻辑组合的强化学习框架，使智能体能够自主判断新任务的解决方式，并通过生成最优策略的估计加速学习过程",
        "关键词": [
            "逻辑组合",
            "终身强化学习",
            "迁移学习",
            "泛化能力",
            "策略估计"
        ],
        "涉及的技术概念": {
            "逻辑组合": "用于使智能体能够自主判断新任务是否可以利用现有能力解决或需要学习新技能的技术",
            "最优策略估计": "算法通过生成最优策略的估计，加速智能体对新任务的学习过程",
            "任务分布泛化": "研究智能体如何在学习有限数量的任务后，能够快速泛化到整个任务分布"
        },
        "success": true
    },
    {
        "order": 368,
        "title": "Generalization of Neural Combinatorial Solvers Through the Lens of Adversarial Robustness",
        "html": "https://iclr.cc//virtual/2022/poster/7081",
        "abstract": "End-to-end (geometric) deep learning has seen first successes in approximating the solution of combinatorial optimization problems. However, generating data in the realm of NP-hard/-complete tasks brings practical and theoretical challenges, resulting in evaluation protocols that are too optimistic. Specifically, most datasets only capture a simpler subproblem and likely suffer from spurious features. We investigate these effects by studying adversarial robustness -a local generalization property- to reveal hard, model-specific instances and spurious features. For this purpose, we derive perturbation models for SAT and TSP. Unlike in other applications, where perturbation models are designed around subjective notions of imperceptibility, our perturbation models are efficient and sound, allowing us to determine the true label of perturbed samples without a solver. Surprisingly, with such perturbations, a sufficiently expressive neural solver does not suffer from the limitations of the accuracy-robustness trade-off common in supervised learning. Although such robust solvers exist, we show empirically that the assessed neural solvers do not generalize well w.r.t. small perturbations of the problem instance.",
        "conference": "ICLR",
        "中文标题": "通过对抗鲁棒性视角看神经组合求解器的泛化能力",
        "摘要翻译": "端到端（几何）深度学习在近似组合优化问题解方面已取得初步成功。然而，在NP难/完全任务领域生成数据带来了实践和理论上的挑战，导致评估协议过于乐观。具体而言，大多数数据集仅捕获了一个更简单的子问题，并可能受到虚假特征的影响。我们通过研究对抗鲁棒性——一种局部泛化属性——来揭示困难的、模型特定的实例和虚假特征，以调查这些效应。为此，我们为SAT和TSP推导了扰动模型。与其他应用不同，其他应用中的扰动模型围绕主观的不可感知性概念设计，我们的扰动模型高效且合理，使我们能够无需求解器即可确定扰动样本的真实标签。令人惊讶的是，对于这样的扰动，一个足够表达力的神经求解器不会受到监督学习中常见的准确性-鲁棒性权衡的限制。尽管存在这样的鲁棒求解器，我们通过实证表明，评估的神经求解器在问题实例的小扰动方面泛化能力不佳。",
        "领域": "组合优化求解、对抗鲁棒性、深度学习",
        "问题": "研究神经组合求解器在对抗扰动下的泛化能力，揭示现有数据集和评估协议中的局限性。",
        "动机": "探索神经组合求解器在实际应用中的鲁棒性和泛化能力，特别是在面对NP难/完全任务时的表现。",
        "方法": "通过为SAT和TSP问题设计高效且合理的扰动模型，研究神经求解器在对抗扰动下的表现。",
        "关键词": [
            "神经组合求解器",
            "对抗鲁棒性",
            "组合优化",
            "深度学习",
            "泛化能力"
        ],
        "涉及的技术概念": {
            "对抗鲁棒性": "研究神经求解器在面对精心设计的扰动时的表现，以评估其泛化能力和鲁棒性。",
            "扰动模型": "为SAT和TSP问题设计的特定扰动方法，用于生成对抗样本，测试求解器的鲁棒性。",
            "神经求解器": "利用深度学习技术近似解决组合优化问题的模型，本研究关注其在对抗扰动下的表现。"
        },
        "success": true
    },
    {
        "order": 369,
        "title": "Generalization Through the Lens of Leave-One-Out Error",
        "html": "https://iclr.cc//virtual/2022/poster/6753",
        "abstract": "Despite the tremendous empirical success of deep learning models to solve various learning tasks, our theoretical understanding of their generalization ability is very limited. Classical generalization bounds based on tools such as the VC dimension or Rademacher complexity, are so far unsuitable for deep models and it is doubtful that these techniques can yield tight bounds even in the most idealistic settings~\\citep{nagarajan2019uniform}. In this work, we instead revisit the concept of leave-one-out (LOO) error to measure the generalization ability of deep models in the so-called kernel regime. While popular in statistics, the LOO error has been largely overlooked in the context of deep learning. By building upon the recently established connection between neural networks and kernel learning, we leverage the closed-form expression for the leave-one-out error, giving us access to an efficient proxy for the test error. We show both theoretically and empirically that the leave-one-out error is capable of capturing various phenomena in generalization theory, such as double descent, random labels or transfer learning.Our work therefore demonstrates that the leave-one-out error provides a tractable way to estimate the generalization ability of deep neural networks in the kernel regime, opening the door to potential, new research directions in the field of generalization.",
        "conference": "ICLR",
        "中文标题": "通过留一法误差的视角看泛化",
        "摘要翻译": "尽管深度学习模型在解决各种学习任务方面取得了巨大的经验成功，但我们对它们泛化能力的理论理解非常有限。基于VC维度或Rademacher复杂性等工具的经典泛化界限，迄今为止不适合深度模型，并且即使在最理想的情况下，这些技术能否产生紧密的界限也值得怀疑。在这项工作中，我们重新审视了留一法（LOO）误差的概念，以测量深度模型在所谓核机制下的泛化能力。虽然在统计学中很流行，但留一法误差在深度学习的背景下很大程度上被忽视了。通过建立在神经网络和核学习之间最近建立的联系上，我们利用了留一法误差的闭式表达式，使我们能够访问测试误差的有效代理。我们从理论上和经验上展示了留一法误差能够捕捉泛化理论中的各种现象，如双下降、随机标签或迁移学习。因此，我们的工作表明，留一法误差提供了一种可处理的方法来估计深度神经网络在核机制下的泛化能力，为泛化领域潜在的新研究方向打开了大门。",
        "领域": "深度学习理论、核方法、泛化能力分析",
        "问题": "深度学习模型的泛化能力理论理解有限，缺乏有效的泛化界限测量方法。",
        "动机": "探索深度学习模型泛化能力的理论基础，提供一种新的方法来估计和解释深度神经网络的泛化性能。",
        "方法": "利用留一法误差作为泛化能力的测量工具，基于神经网络与核学习之间的联系，通过闭式表达式高效估计测试误差。",
        "关键词": [
            "留一法误差",
            "泛化能力",
            "核机制",
            "深度学习理论",
            "测试误差估计"
        ],
        "涉及的技术概念": {
            "留一法误差": "用于测量模型泛化能力的统计方法，通过排除一个样本训练模型并计算该样本的预测误差。",
            "核机制": "指深度学习模型在特定条件下可以被视为核机器的状态，使得核学习理论可以应用于分析深度模型。",
            "双下降现象": "指模型复杂度增加时，泛化误差先下降后上升再下降的现象，留一法误差能够捕捉这一现象。"
        },
        "success": true
    },
    {
        "order": 370,
        "title": "Generalized Decision Transformer for Offline Hindsight Information Matching",
        "html": "https://iclr.cc//virtual/2022/poster/6141",
        "abstract": "How to extract as much learning signal from each trajectory data has been a key problem in reinforcement learning (RL), where sample inefficiency has posed serious challenges for practical applications. Recent works have shown that using expressive policy function approximators and conditioning on future trajectory information -- such as future states in hindsight experience replay (HER) or returns-to-go in Decision Transformer (DT) -- enables efficient learning of multi-task policies, where at times online RL is fully replaced by offline behavioral cloning (BC), e.g. sequence modeling. We demonstrate that all these approaches are doing hindsight information matching (HIM) -- training policies that can output the rest of trajectory that matches some statistics of future state information. We present Generalized Decision Transformer (GDT) for solving any HIM problem, and show how different choices for the feature function and the anti-causal aggregator not only recover DT as a special case, but also lead to novel Categorical DT (CDT) and Bi-directional DT (BDT) for matching different statistics of the future. For evaluating CDT and BDT, we define offline multi-task state-marginal matching (SMM) and imitation learning (IL) as two generic HIM problems, propose a Wasserstein distance loss as a metric for both, and empirically study them on MuJoCo continuous control benchmarks. Categorical DT, which simply replaces anti-causal summation with anti-causal binning in DT, enables arguably the first effective offline multi-task SMM algorithm that generalizes well to unseen (and even synthetic) multi-modal reward or state-feature distributions. Bi-directional DT, which uses an anti-causal second transformer as the aggregator, can learn to model any statistics of the future and outperforms DT variants in offline multi-task IL, i.e. one-shot IL. Our generalized formulations from HIM and GDT greatly expand the role of powerful sequence modeling architectures in modern RL.",
        "conference": "ICLR",
        "中文标题": "广义决策变换器用于离线后见信息匹配",
        "摘要翻译": "如何从每条轨迹数据中提取尽可能多的学习信号一直是强化学习（RL）中的一个关键问题，其中样本效率低下给实际应用带来了严重挑战。最近的研究表明，使用表达性强的策略函数逼近器并结合未来轨迹信息——如后见经验回放（HER）中的未来状态或决策变换器（DT）中的回报到目标——能够高效学习多任务策略，有时甚至完全用离线行为克隆（BC）替代在线RL，例如序列建模。我们证明所有这些方法都在进行后见信息匹配（HIM）——训练能够输出与未来状态信息某些统计量匹配的剩余轨迹的策略。我们提出了广义决策变换器（GDT）来解决任何HIM问题，并展示了特征函数和反因果聚合器的不同选择不仅将DT作为一个特例恢复，而且还导致了新颖的分类DT（CDT）和双向DT（BDT）以匹配未来的不同统计量。为了评估CDT和BDT，我们将离线多任务状态边际匹配（SMM）和模仿学习（IL）定义为两个通用的HIM问题，提出了Wasserstein距离损失作为两者的度量标准，并在MuJoCo连续控制基准上进行了实证研究。分类DT简单地将DT中的反因果求和替换为反因果分箱，可以说是第一个有效的离线多任务SMM算法，能够很好地泛化到未见（甚至合成的）多模态奖励或状态特征分布。双向DT使用反因果第二个变换器作为聚合器，可以学习建模未来的任何统计量，并在离线多任务IL（即一次性IL）中优于DT变体。我们从HIM和GDT的广义表述极大地扩展了强大序列建模架构在现代RL中的作用。",
        "领域": "强化学习、多任务学习、模仿学习",
        "问题": "如何从每条轨迹数据中提取尽可能多的学习信号，以解决强化学习中的样本效率低下问题。",
        "动机": "研究旨在通过后见信息匹配（HIM）方法，提高强化学习在多任务策略学习中的效率和效果。",
        "方法": "提出了广义决策变换器（GDT）来解决HIM问题，包括分类DT（CDT）和双向DT（BDT）两种新方法，用于匹配未来的不同统计量，并在MuJoCo连续控制基准上进行实证研究。",
        "关键词": [
            "广义决策变换器",
            "后见信息匹配",
            "多任务学习",
            "模仿学习",
            "Wasserstein距离"
        ],
        "涉及的技术概念": {
            "后见信息匹配（HIM）": "训练策略以输出与未来状态信息某些统计量匹配的剩余轨迹。",
            "广义决策变换器（GDT）": "用于解决任何HIM问题的框架，能够恢复决策变换器（DT）并衍生出新的方法如分类DT（CDT）和双向DT（BDT）。",
            "Wasserstein距离": "用于度量离线多任务状态边际匹配（SMM）和模仿学习（IL）的性能。"
        },
        "success": true
    },
    {
        "order": 371,
        "title": "Generalized Demographic Parity for Group Fairness",
        "html": "https://iclr.cc//virtual/2022/poster/6839",
        "abstract": "This work aims to generalize demographic parity to continuous sensitive attributes while preserving tractable computation. Current fairness metrics for continuous sensitive attributes largely rely on intractable statistical independence between variables, such as Hirschfeld-Gebelein-Renyi (HGR) and mutual information. Statistical fairness metrics estimation relying on either tractable bounds or neural network approximation, however, are not sufficiently trustful to rank algorithms prediction bias due to lack of estimation accuracy guarantee. To make fairness metrics trustable, we propose \\textit{\\underline{G}eneralized \\underline{D}emographic \\underline{P}arity} (GDP), a group fairness metric for continuous and discrete attributes. We show the understanding of GDP from the probability perspective and theoretically reveal the connection between GDP regularizer and adversarial debiasing. To estimate GDP, we adopt hard and soft group strategies via the one-hot or the soft group indicator, representing the membership of each sample in different groups of the sensitive attribute. We provably and numerically show that the soft group strategy achieves a faster estimation error convergence rate. Experiments show the better bias mitigation performance of GDP regularizer, compared with adversarial debiasing, for regression and classification tasks in tabular and graph benchmarks.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "广义人口均等性用于群体公平性",
        "摘要翻译": "本工作旨在将人口均等性推广至连续敏感属性，同时保持可处理的计算。当前针对连续敏感属性的公平性度量主要依赖于变量间难以处理的统计独立性，如Hirschfeld-Gebelein-Renyi（HGR）和互信息。然而，依赖于可处理边界或神经网络近似的统计公平性度量估计，由于缺乏估计准确性保证，不足以信任以排名算法预测偏差。为了使公平性度量可信，我们提出了广义人口均等性（GDP），一种适用于连续和离散属性的群体公平性度量。我们从概率角度展示了GDP的理解，并从理论上揭示了GDP正则化器与对抗性去偏之间的联系。为了估计GDP，我们通过独热或软组指示器采用硬和软组策略，表示每个样本在敏感属性不同组中的成员资格。我们证明并数值上展示了软组策略实现了更快的估计误差收敛率。实验显示，与对抗性去偏相比，GDP正则化器在表格和图基准的回归和分类任务中具有更好的偏差缓解性能。",
        "领域": "公平性学习, 机器学习公平性, 统计学习",
        "问题": "如何在连续敏感属性上定义和计算公平性度量，同时保证计算的可处理性和估计的准确性。",
        "动机": "当前针对连续敏感属性的公平性度量依赖于难以处理的统计独立性，缺乏估计准确性保证，需要一种更可信的公平性度量方法。",
        "方法": "提出广义人口均等性（GDP）作为群体公平性度量，采用硬和软组策略进行估计，理论上和实验上验证其有效性。",
        "关键词": [
            "广义人口均等性",
            "群体公平性",
            "连续敏感属性",
            "对抗性去偏",
            "统计独立性"
        ],
        "涉及的技术概念": {
            "广义人口均等性（GDP）": "一种适用于连续和离散敏感属性的群体公平性度量，旨在提供可信的公平性评估。",
            "对抗性去偏": "一种通过对抗训练减少模型偏差的技术，GDP正则化器与其有理论上的联系。",
            "软组策略": "通过软组指示器表示样本在敏感属性不同组中的成员资格，以实现更快的估计误差收敛率。"
        }
    },
    {
        "order": 372,
        "title": "Generalized Kernel Thinning",
        "html": "https://iclr.cc//virtual/2022/poster/6234",
        "abstract": "The kernel thinning (KT) algorithm of Dwivedi and Mackey (2021) compresses a probability distribution more effectively than independent sampling by targeting a reproducing kernel Hilbert space (RKHS) and leveraging a less smooth square-root kernel. Here we provide four improvements.  First, we show that KT applied directly to the target RKHS yields tighter, dimension-free guarantees for any kernel, any distribution, and any fixed function in the RKHS. Second, we show that, for analytic kernels like Gaussian, inverse multiquadric, and sinc, target KT admits maximum mean discrepancy (MMD) guarantees comparable to or better than those of square-root KT without making explicit use of a square-root kernel.  Third, we prove that KT with a fractional power kernel yields better-than-Monte-Carlo MMD guarantees for non-smooth kernels, like Laplace and Matern, that do not have square-roots. Fourth, we establish that KT applied to a sum of the target and power kernels (a procedure we call KT+) simultaneously inherits the improved MMD guarantees of power KT and the tighter individual function guarantees of target KT.  In our experiments with target KT and KT+, we witness significant improvements in integration error even in 100 dimensions and when compressing challenging differential equation posteriors.",
        "conference": "ICLR",
        "中文标题": "广义核细化",
        "摘要翻译": "Dwivedi和Mackey（2021年）提出的核细化（KT）算法通过针对再生核希尔伯特空间（RKHS）并利用一个不那么平滑的平方根核，比独立采样更有效地压缩概率分布。在此，我们提供了四项改进。首先，我们展示直接应用于目标RKHS的KT为任何核、任何分布以及RKHS中的任何固定函数提供了更紧、无维度的保证。其次，我们证明，对于高斯、逆多二次和sinc等解析核，目标KT在不明确使用平方根核的情况下，获得了与平方根KT相当或更好的最大均值差异（MMD）保证。第三，我们证明，对于没有平方根的非平滑核，如拉普拉斯和Matern，使用分数幂核的KT提供了优于蒙特卡洛的MMD保证。第四，我们确定，应用于目标和幂核之和的KT（我们称之为KT+）同时继承了幂KT改进的MMD保证和目标KT更紧的个别函数保证。在我们的目标KT和KT+实验中，即使在100维度和压缩具有挑战性的微分方程后验时，我们也见证了积分误差的显著改善。",
        "领域": "概率分布压缩",
        "问题": "如何更有效地压缩概率分布",
        "动机": "改进核细化算法，以提供更紧的保证和更好的性能",
        "方法": "直接应用于目标RKHS的KT、使用解析核的目标KT、使用分数幂核的KT、以及KT+方法",
        "关键词": [
            "核细化",
            "再生核希尔伯特空间",
            "最大均值差异",
            "概率分布压缩",
            "积分误差"
        ],
        "涉及的技术概念": {
            "核细化（KT）": "一种通过针对RKHS并利用特定核来压缩概率分布的算法",
            "再生核希尔伯特空间（RKHS）": "一种函数空间，核细化算法在此空间中操作以压缩概率分布",
            "最大均值差异（MMD）": "用于衡量两个概率分布之间差异的度量，核细化算法旨在优化这一度量"
        },
        "success": true
    },
    {
        "order": 373,
        "title": "Generalized Natural Gradient Flows in Hidden Convex-Concave Games and GANs",
        "html": "https://iclr.cc//virtual/2022/poster/7040",
        "abstract": "Game-theoretic formulations in machine learning have recently risen in prominence, whereby entire modeling paradigms are best captured as zero-sum games. Despite their popularity, however, their dynamics are still poorly understood. This lack of theory is often substantiated with painful empirical observations of volatile training dynamics and even divergence. Such results highlight the need to develop an appropriate theory with convergence guarantees that are powerful enough to inform practice. This paper studies the generalized Gradient Descent-Ascent (GDA) flow in a large class of non-convex non-concave Zero-Sum games dubbed Hidden Convex-Concave games, a class of games that includes GANs. We focus on two specific geometries: a novel geometry induced by the hidden convex-concave structure that we call the hidden mapping geometry and the Fisher information geometry. For the hidden mapping geometry, we prove global convergence under mild assumptions. In the case of Fisher information geometry, we provide a complete picture of the dynamics in an interesting special setting of team competition via invariant function analysis.",
        "conference": "ICLR",
        "中文标题": "广义自然梯度流在隐藏凸凹博弈与生成对抗网络中的应用",
        "摘要翻译": "机器学习中的博弈论表述最近日益突出，整个建模范式最好被描述为零和博弈。尽管它们很受欢迎，但其动态仍然知之甚少。这种理论的缺乏常常通过训练动态波动甚至发散的痛苦经验观察得到证实。这些结果强调了需要发展一种具有足够强大以指导实践的收敛保证的适当理论。本文研究了一类被称为隐藏凸凹博弈的非凸非凹零和博弈中的广义梯度下降-上升（GDA）流，这类博弈包括生成对抗网络（GANs）。我们专注于两种特定的几何：一种由隐藏凸凹结构诱导的新几何，我们称之为隐藏映射几何，以及Fisher信息几何。对于隐藏映射几何，我们在温和的假设下证明了全局收敛性。在Fisher信息几何的情况下，我们通过不变函数分析提供了一个有趣的特殊团队竞争设置中动态的完整图景。",
        "领域": "生成对抗网络、博弈论机器学习、优化理论",
        "问题": "理解并保证非凸非凹零和博弈中的训练动态收敛性",
        "动机": "由于缺乏对博弈论机器学习模型动态的理论理解，导致训练过程中出现波动和发散现象，需要发展具有收敛保证的理论来指导实践。",
        "方法": "研究广义梯度下降-上升（GDA）流在隐藏凸凹博弈中的应用，专注于隐藏映射几何和Fisher信息几何，通过不变函数分析提供动态的完整图景。",
        "关键词": [
            "广义梯度下降-上升",
            "隐藏凸凹博弈",
            "生成对抗网络",
            "Fisher信息几何",
            "不变函数分析"
        ],
        "涉及的技术概念": {
            "广义梯度下降-上升（GDA）流": "用于研究非凸非凹零和博弈中的动态收敛性，特别是在隐藏凸凹博弈中。",
            "隐藏凸凹博弈": "一类特殊的非凸非凹零和博弈，包括生成对抗网络（GANs），其结构允许全局收敛性的证明。",
            "Fisher信息几何": "一种几何结构，用于分析博弈动态，特别是在团队竞争的特殊设置中。"
        },
        "success": true
    },
    {
        "order": 374,
        "title": "Generalized rectifier wavelet covariance models for texture synthesis",
        "html": "https://iclr.cc//virtual/2022/poster/6762",
        "abstract": "State-of-the-art maximum entropy models for texture synthesis are built from statistics relying on image representations defined by convolutional neural networks (CNN). Such representations capture rich structures in texture images, outperforming wavelet-based representations in this regard. However, conversely to neural networks, wavelets offer meaningful representations, as they are known to detect structures at multiple scales (e.g. edges) in images. In this work, we propose a family of statistics built upon non-linear wavelet based representations, that can be viewed as a particular instance of a one-layer CNN, using a generalized rectifier non-linearity. These statistics significantly improve the visual quality of previous classical wavelet-based models, and allow one to produce syntheses of similar quality to state-of-the-art models, on both gray-scale and color textures.",
        "conference": "ICLR",
        "中文标题": "广义整流器小波协方差模型用于纹理合成",
        "摘要翻译": "目前最先进的纹理合成最大熵模型是基于卷积神经网络（CNN）定义的图像表示的统计量构建的。这样的表示能够捕捉纹理图像中的丰富结构，在这方面优于基于小波的表示。然而，与神经网络相反，小波提供了有意义的表示，因为它们已知能够检测图像中多尺度的结构（例如边缘）。在这项工作中，我们提出了一族基于非线性小波表示的统计量，可以视为使用广义整流器非线性的单层CNN的一个特定实例。这些统计量显著提高了之前基于经典小波模型的视觉质量，并且允许在灰度和彩色纹理上产生与最先进模型相似质量的合成。",
        "领域": "纹理合成",
        "问题": "如何利用小波表示提升纹理合成的视觉质量",
        "动机": "探索小波表示在纹理合成中的应用，以结合小波的多尺度结构检测能力和神经网络的丰富表示能力",
        "方法": "提出基于非线性小波表示的统计量家族，视为使用广义整流器非线性的单层CNN实例",
        "关键词": [
            "纹理合成",
            "小波表示",
            "广义整流器",
            "最大熵模型",
            "卷积神经网络"
        ],
        "涉及的技术概念": {
            "小波表示": "用于检测图像中多尺度结构（如边缘）的技术，提供有意义的图像表示",
            "广义整流器非线性的单层CNN": "一种特定的神经网络结构，用于构建非线性小波表示的统计量",
            "最大熵模型": "用于纹理合成的统计模型，基于图像表示的统计量构建"
        },
        "success": true
    },
    {
        "order": 375,
        "title": "Generalizing Few-Shot NAS with Gradient Matching",
        "html": "https://iclr.cc//virtual/2022/poster/6058",
        "abstract": "Efficient performance estimation of architectures drawn from large search spaces is essential to Neural Architecture Search. One-Shot methods tackle this challenge by training one supernet to approximate the performance of every architecture in the search space via weight-sharing, thereby drastically reducing the search cost. However, due to coupled optimization between child architectures caused by weight-sharing, One-Shot supernet's performance estimation could be inaccurate, leading to degraded search outcomes. To address this issue, Few-Shot NAS reduces the level of weight-sharing by splitting the One-Shot supernet into multiple separated sub-supernets via edge-wise (layer-wise) exhaustive partitioning. Since each partition of the supernet is not equally important, it necessitates the design of a more effective splitting criterion. In this work, we propose a gradient matching score (GM) that leverages gradient information at the shared weight for making informed splitting decisions. Intuitively, gradients from different child models can be used to identify whether they agree on how to update the shared modules, and subsequently to decide if they should share weight. Compared with exhaustive partitioning, the proposed criterion significantly reduces the branching factor per edge. This allows us to split more edges (layers) for a given budget, resulting in substantially improved performance as NAS search spaces usually include dozens of edges (layers). Extensive empirical evaluations of the proposed method on a wide range of search spaces (NASBench-201, DARTS, MobileNet Space), datasets (cifar10, cifar100, ImageNet) and search algorithms (DARTS, SNAS, RSPS, ProxylessNAS, OFA) demonstrate that it significantly outperforms its Few-Shot counterparts while surpassing previous comparable methods in terms of the accuracy of derived architectures. Our code is available at https://github.com/skhu101/GM-NAS.",
        "conference": "ICLR",
        "中文标题": "通过梯度匹配推广少样本神经架构搜索",
        "摘要翻译": "从大型搜索空间中抽取架构的高效性能估计对于神经架构搜索（NAS）至关重要。单样本方法通过训练一个超级网络来近似搜索空间中每个架构的性能，通过权重共享大幅降低搜索成本。然而，由于权重共享导致的子架构间耦合优化，单样本超级网络的性能估计可能不准确，从而导致搜索结果下降。为解决这一问题，少样本NAS通过边缘（层）级详尽分割将单样本超级网络分割为多个分离的子超级网络，减少了权重共享的程度。由于超级网络的每个分割部分并非同等重要，因此需要设计一个更有效的分割标准。在这项工作中，我们提出了一个梯度匹配分数（GM），该分数利用共享权重的梯度信息来做出明智的分割决策。直观上，来自不同子模型的梯度可用于识别它们是否同意如何更新共享模块，进而决定它们是否应该共享权重。与详尽分割相比，提出的标准显著减少了每边的分支因子。这使我们能够在给定预算下分割更多的边（层），从而显著提高性能，因为NAS搜索空间通常包含数十个边（层）。在广泛的搜索空间（NASBench-201、DARTS、MobileNet空间）、数据集（cifar10、cifar100、ImageNet）和搜索算法（DARTS、SNAS、RSPS、ProxylessNAS、OFA）上对所提方法进行的广泛实证评估表明，它显著优于其少样本对应方法，同时在派生架构的准确性方面超过了以前的可比方法。我们的代码可在https://github.com/skhu101/GM-NAS获取。",
        "领域": "神经架构搜索",
        "问题": "解决单样本超级网络由于权重共享导致的性能估计不准确问题",
        "动机": "提高神经架构搜索中性能估计的准确性，以优化搜索结果",
        "方法": "提出梯度匹配分数（GM）作为分割标准，减少权重共享的程度，提高性能估计的准确性",
        "关键词": [
            "神经架构搜索",
            "梯度匹配",
            "权重共享"
        ],
        "涉及的技术概念": {
            "梯度匹配分数（GM）": "利用共享权重的梯度信息来做出明智的分割决策，减少权重共享的程度",
            "权重共享": "在神经架构搜索中，通过共享权重来近似不同架构的性能，以降低搜索成本",
            "超级网络": "一个包含多个子架构的网络，通过训练来估计搜索空间中每个架构的性能"
        },
        "success": true
    },
    {
        "order": 376,
        "title": "Generating Videos with Dynamics-aware Implicit Generative Adversarial Networks",
        "html": "https://iclr.cc//virtual/2022/poster/5954",
        "abstract": "In the deep learning era, long video generation of high-quality still remains challenging due to the spatio-temporal complexity and continuity of videos. Existing prior works have attempted to model video distribution by representing videos as 3D grids of RGB values, which impedes the scale of generated videos and neglects continuous dynamics. In this paper, we found that the recent emerging paradigm of implicit neural representations (INRs) that encodes a continuous signal into a parameterized neural network effectively mitigates the issue. By utilizing INRs of video, we propose dynamics-aware implicit generative adversarial network (DIGAN), a novel generative adversarial network for video generation. Specifically, we introduce (a) an INR-based video generator that improves the motion dynamics by manipulating the space and time coordinates differently and (b) a motion discriminator that efficiently identifies the unnatural motions without observing the entire long frame sequences. We demonstrate the superiority of DIGAN under various datasets, along with multiple intriguing properties, e.g., long video synthesis, video extrapolation, and non-autoregressive video generation. For example, DIGAN improves the previous state-of-the-art FVD score on UCF-101 by 30.7% and can be trained on 128 frame videos of 128x128 resolution, 80 frames longer than the 48 frames of the previous state-of-the-art method.",
        "conference": "ICLR",
        "中文标题": "利用动态感知隐式生成对抗网络生成视频",
        "摘要翻译": "在深度学习时代，由于视频的时空复杂性和连续性，高质量的长视频生成仍然具有挑战性。现有的先前工作尝试通过将视频表示为RGB值的3D网格来建模视频分布，这限制了生成视频的规模并忽视了连续动态。在本文中，我们发现最近兴起的隐式神经表示（INRs）范式，即将连续信号编码到参数化神经网络中，有效缓解了这一问题。通过利用视频的INRs，我们提出了动态感知隐式生成对抗网络（DIGAN），一种用于视频生成的新型生成对抗网络。具体来说，我们引入了（a）一个基于INR的视频生成器，通过不同地操纵空间和时间坐标来改善运动动态；（b）一个运动判别器，无需观察整个长帧序列即可有效识别不自然的运动。我们在多个数据集下展示了DIGAN的优越性，以及多种引人入胜的特性，例如长视频合成、视频外推和非自回归视频生成。例如，DIGAN在UCF-101上将先前最先进的FVD分数提高了30.7%，并且可以在128x128分辨率的128帧视频上进行训练，比先前最先进方法的48帧多80帧。",
        "领域": "视频生成、生成对抗网络、隐式神经表示",
        "问题": "解决高质量长视频生成中的时空复杂性和连续性问题",
        "动机": "现有方法通过3D网格表示视频限制了生成视频的规模并忽视了连续动态，需要一种新方法来有效建模视频分布",
        "方法": "提出动态感知隐式生成对抗网络（DIGAN），利用隐式神经表示（INRs）编码视频，通过改进的视频生成器和运动判别器优化视频生成",
        "关键词": [
            "视频生成",
            "隐式神经表示",
            "生成对抗网络",
            "动态感知",
            "长视频合成"
        ],
        "涉及的技术概念": {
            "隐式神经表示（INRs）": "将连续信号编码到参数化神经网络中，用于有效建模视频的连续动态",
            "动态感知隐式生成对抗网络（DIGAN）": "一种新型生成对抗网络，通过改进的视频生成器和运动判别器优化视频生成",
            "运动判别器": "无需观察整个长帧序列即可识别不自然运动，提高生成视频的质量"
        },
        "success": true
    },
    {
        "order": 377,
        "title": "Generative Modeling with Optimal Transport Maps",
        "html": "https://iclr.cc//virtual/2022/poster/6183",
        "abstract": "With the discovery of Wasserstein GANs, Optimal Transport (OT) has become a powerful tool for large-scale generative modeling tasks. In these tasks, OT cost is typically used as the loss for training GANs. In contrast to this approach, we show that the OT map itself can be used as a generative model, providing comparable performance. Previous analogous approaches consider OT maps as generative models only in the latent spaces due to their poor performance in the original high-dimensional ambient space. In contrast, we apply OT maps directly in the ambient space, e.g., a space of high-dimensional images. First, we derive a min-max optimization algorithm to efficiently compute OT maps for the quadratic cost (Wasserstein-2 distance). Next, we extend the approach to the case when the input and output distributions are located in the spaces of different dimensions and derive error bounds for the computed OT map. We evaluate the algorithm on image generation and unpaired image restoration tasks. In particular, we consider denoising, colorization, and inpainting, where the optimality of the restoration map is a desired attribute, since the output (restored) image is expected to be close to the input (degraded) one.",
        "conference": "ICLR",
        "中文标题": "使用最优传输映射的生成建模",
        "摘要翻译": "随着Wasserstein GANs的发现，最优传输（OT）已成为大规模生成建模任务的强大工具。在这些任务中，OT成本通常被用作训练GANs的损失。与这种方法相反，我们展示了OT映射本身可以用作生成模型，提供可比较的性能。以前的类似方法仅将OT映射视为潜在空间中的生成模型，因为它们在原始高维环境空间中表现不佳。相比之下，我们直接在环境空间中应用OT映射，例如高维图像的空间。首先，我们推导出一个最小-最大优化算法，以高效计算二次成本（Wasserstein-2距离）的OT映射。接下来，我们将方法扩展到输入和输出分布位于不同维度空间的情况，并为计算的OT映射导出误差界限。我们在图像生成和无配对图像恢复任务上评估了该算法。特别是，我们考虑了去噪、着色和修复，其中恢复映射的最优性是一个期望的属性，因为输出（恢复的）图像预期接近输入（退化的）图像。",
        "领域": "生成对抗网络、图像恢复、最优传输",
        "问题": "如何直接在高维环境空间中使用最优传输映射作为生成模型，以解决图像生成和恢复任务。",
        "动机": "探索最优传输映射作为生成模型的潜力，特别是在高维环境空间中的应用，以提供与现有方法可比较的性能。",
        "方法": "推导最小-最大优化算法计算Wasserstein-2距离的最优传输映射，并将其扩展到不同维度空间的情况，同时为计算的映射导出误差界限。",
        "关键词": [
            "最优传输",
            "生成模型",
            "图像恢复",
            "Wasserstein距离",
            "高维空间"
        ],
        "涉及的技术概念": {
            "最优传输（OT）": "用于衡量两个概率分布之间距离的数学工具，在本文中作为生成模型的核心。",
            "Wasserstein距离": "最优传输成本的一种具体形式，用于量化分布之间的距离，本文中特指Wasserstein-2距离。",
            "最小-最大优化算法": "用于高效计算最优传输映射的算法，通过最小化生成模型和判别模型之间的对抗损失来实现。"
        },
        "success": true
    },
    {
        "order": 378,
        "title": "Generative Models as a Data Source for Multiview Representation Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6339",
        "abstract": "Generative models are now capable of producing highly realistic images that look nearly indistinguishable from the data on which they are trained. This raises the question: if we have good enough generative models, do we still need datasets? We investigate this question in the setting of learning general-purpose visual representations from a black-box generative model rather than directly from data. Given an off-the-shelf image generator without any access to its training data, we train representations from the samples output by this generator. We compare several representation learning methods that can be applied to this setting, using the latent space of the generator to generate multiple 'views' of the same semantic content. We show that for contrastive methods, this multiview data can naturally be used to identify positive pairs (nearby in latent space) and negative pairs (far apart in latent space). We find that the resulting representations rival or even outperform those learned directly from real data, but that good performance requires care in the sampling strategy applied and the training method. Generative models can be viewed as a compressed and organized copy of a dataset, and we envision a future where more and more 'model zoos' proliferate while datasets become increasingly unwieldy, missing, or private. This paper suggests several techniques for dealing with visual representation learning in such a future. Code is available on our project page https://ali-design.github.io/GenRep/.",
        "conference": "ICLR",
        "中文标题": "生成模型作为多视图表示学习的数据源",
        "摘要翻译": "生成模型现在能够产生高度逼真的图像，这些图像几乎与它们训练所用的数据难以区分。这引发了一个问题：如果我们有足够好的生成模型，是否还需要数据集？我们在从黑盒生成模型而非直接从数据中学习通用视觉表示的背景下探讨这个问题。给定一个现成的图像生成器，且无法访问其训练数据，我们从该生成器输出的样本中训练表示。我们比较了几种可以应用于此场景的表示学习方法，利用生成器的潜在空间生成相同语义内容的多个‘视图’。我们表明，对于对比方法，这种多视图数据可以自然地用于识别正对（潜在空间中相近的）和负对（潜在空间中远离的）。我们发现，由此产生的表示可以与直接从真实数据中学习的表示相媲美，甚至更优，但良好的性能需要在应用的采样策略和训练方法上小心谨慎。生成模型可以被视为数据集的压缩和有组织的副本，我们预见未来越来越多的‘模型动物园’会激增，而数据集变得越来越难以处理、缺失或私有。本文提出了几种技术，以应对这种未来中的视觉表示学习。代码可在我们的项目页面https://ali-design.github.io/GenRep/上获取。",
        "领域": "生成对抗网络、表示学习、多视图学习",
        "问题": "探讨是否可以通过生成模型而非真实数据集来学习有效的视觉表示",
        "动机": "随着生成模型能力的提升，研究是否可以利用生成模型作为数据源来学习视觉表示，以应对数据集难以获取或处理的问题",
        "方法": "利用生成模型的潜在空间生成多视图数据，应用对比学习方法训练视觉表示",
        "关键词": [
            "生成模型",
            "多视图学习",
            "表示学习",
            "对比学习",
            "潜在空间"
        ],
        "涉及的技术概念": {
            "生成模型": "用于生成逼真图像的模型，作为学习视觉表示的数据源",
            "多视图学习": "通过生成相同语义内容的多个视图来学习表示，提高模型的泛化能力",
            "对比学习": "通过识别潜在空间中的正对和负对来训练模型，以学习有效的视觉表示"
        },
        "success": true
    },
    {
        "order": 379,
        "title": "Generative Planning for Temporally Coordinated Exploration in Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6673",
        "abstract": "Standard model-free reinforcement learning algorithms optimize a policy that generates the action to be taken in the current time step in order to maximize expected future return. While flexible, it faces difficulties arising from the inefficient exploration due to its single step nature. In this work, we present Generative Planning method (GPM), which can generate actions not only for the current step, but also for a number of future steps (thus termed as generative planning). This brings several benefits to GPM. Firstly,  since GPM is trained by maximizing value, the plans generated from it can be regarded as intentional action sequences for reaching high value regions. GPM can therefore leverage its generated multi-step plans for temporally coordinated exploration towards high value regions, which is potentially more effective than a sequence of actions generated by perturbing each action at single step level, whose consistent movement decays exponentially with the number of exploration steps. Secondly, starting from a crude initial plan generator, GPM can refine it to be adaptive to the task, which, in return, benefits future explorations. This is potentially more effective than commonly used action-repeat strategy, which is non-adaptive in its form of plans. Additionally, since the multi-step plan can be interpreted as the intent of the agent from now to a span of time period into the future, it offers a more informative and intuitive signal for interpretation. Experiments are conducted on several benchmark environments and the results demonstrated its effectiveness compared with several baseline methods.",
        "conference": "ICLR",
        "中文标题": "强化学习中时间协调探索的生成规划",
        "摘要翻译": "标准的无模型强化学习算法优化一个策略，该策略生成当前时间步要采取的动作，以最大化预期的未来回报。虽然灵活，但由于其单步性质，它面临着由于探索效率低下而产生的困难。在这项工作中，我们提出了生成规划方法（GPM），它不仅可以生成当前步骤的动作，还可以生成未来多个步骤的动作（因此称为生成规划）。这为GPM带来了几个好处。首先，由于GPM通过最大化价值来训练，从中生成的计划可以被视为达到高价值区域的故意动作序列。因此，GPM可以利用其生成的多步计划进行时间协调的探索，朝向高价值区域，这可能比通过在单步级别扰动每个动作生成的动作序列更有效，后者的连续移动随着探索步骤的数量呈指数级衰减。其次，从一个粗糙的初始计划生成器开始，GPM可以将其精炼以适应任务，这反过来又有利于未来的探索。这可能比常用的动作重复策略更有效，后者在其计划形式上是非自适应的。此外，由于多步计划可以被解释为从现在到未来一段时间内代理的意图，它提供了一个更有信息和更直观的解释信号。在几个基准环境上进行了实验，结果证明了与几种基线方法相比，其有效性。",
        "领域": "强化学习探索策略、多步动作规划、自适应策略优化",
        "问题": "解决单步强化学习算法在探索效率上的不足",
        "动机": "提高强化学习中的探索效率，通过多步规划实现更有效的探索",
        "方法": "提出生成规划方法（GPM），通过生成多步动作序列进行时间协调的探索",
        "关键词": [
            "生成规划",
            "时间协调探索",
            "多步动作序列",
            "自适应策略",
            "强化学习"
        ],
        "涉及的技术概念": {
            "生成规划方法（GPM）": "一种能够生成当前及未来多步动作的方法，用于提高探索效率",
            "时间协调探索": "通过生成的多步动作序列实现探索过程中的时间协调，朝向高价值区域",
            "自适应策略优化": "GPM能够从粗糙的初始计划生成器开始，逐步优化以适应特定任务，提高探索效率"
        },
        "success": true
    },
    {
        "order": 380,
        "title": "Generative Principal Component Analysis",
        "html": "https://iclr.cc//virtual/2022/poster/5902",
        "abstract": "In this paper, we study the problem of principal component analysis with generative modeling assumptions, adopting a general model for the observed matrix that encompasses notable special cases, including spiked matrix recovery and phase retrieval. The key assumption is that the first principal eigenvector lies near the range of an $L$-Lipschitz continuous generative model with bounded $k$-dimensional inputs. We propose a quadratic estimator, and show that it enjoys a statistical rate of order $\\sqrt{\\frac{k\\log L}{m}}$, where $m$ is the number of samples. Moreover, we provide a variant of the classic power method, which projects the calculated data onto the range of the generative model during each iteration. We show that under suitable conditions, this method converges exponentially fast to a point achieving the above-mentioned statistical rate. This rate is conjectured in~\\citep{aubin2019spiked,cocola2020nonasymptotic} to be the best possible even when we only restrict to the special case of spiked matrix models. We perform experiments on various image datasets for spiked matrix and phase retrieval models, and illustrate performance gains of our method to the classic power method and the truncated power method devised for sparse principal component analysis.",
        "conference": "ICLR",
        "中文标题": "生成式主成分分析",
        "摘要翻译": "本文研究了在生成模型假设下的主成分分析问题，采用了一个涵盖包括尖峰矩阵恢复和相位检索在内的显著特例的观测矩阵通用模型。关键假设是第一主特征向量位于一个有界k维输入的L-Lipschitz连续生成模型的范围内附近。我们提出了一个二次估计器，并证明其统计速率为√(klogL/m)，其中m是样本数量。此外，我们提供了一种经典幂方法的变体，该方法在每次迭代时将计算的数据投影到生成模型的范围内。我们表明，在适当的条件下，该方法以指数速度收敛到达到上述统计速率的点。这一速率在文献中被推测为即使在仅限制于尖峰矩阵模型的特例时也是可能的最佳速率。我们在各种图像数据集上对尖峰矩阵和相位检索模型进行了实验，并展示了我们的方法相对于经典幂方法和为稀疏主成分分析设计的截断幂方法的性能提升。",
        "领域": "主成分分析、生成模型、矩阵恢复",
        "问题": "在生成模型假设下进行主成分分析，特别是在尖峰矩阵恢复和相位检索等特例中的应用。",
        "动机": "探索在生成模型假设下进行主成分分析的可能性，以提高在特定应用如尖峰矩阵恢复和相位检索中的性能。",
        "方法": "提出了一种二次估计器和一种改进的幂方法，后者在每次迭代时将数据投影到生成模型的范围内，以加速收敛并提高统计速率。",
        "关键词": [
            "生成式主成分分析",
            "尖峰矩阵恢复",
            "相位检索",
            "幂方法",
            "统计速率"
        ],
        "涉及的技术概念": {
            "生成模型": "用于假设第一主特征向量位于其范围内的模型，关键于理解数据的生成过程。",
            "L-Lipschitz连续": "描述生成模型平滑性的条件，影响估计器的统计性能。",
            "幂方法": "一种迭代算法，用于估计主特征向量，本文中通过投影到生成模型范围内进行改进。"
        },
        "success": true
    },
    {
        "order": 381,
        "title": "Generative Pseudo-Inverse Memory",
        "html": "https://iclr.cc//virtual/2022/poster/6447",
        "abstract": "We propose Generative Pseudo-Inverse Memory (GPM), a class of deep generative memory models that are fast to write in and read out. Memory operations are recast as seeking robust solutions of linear systems, which naturally lead to the use of matrix pseudo-inverses. The pseudo-inverses are iteratively approximated, with practical computation complexity of almost $O(1)$. We prove theoretically and verify empirically that our model can retrieve exactly what have been written to the memory under mild conditions. A key capability of GPM is iterative reading, during which the attractor dynamics towards fixed points are enabled, allowing the model to iteratively improve sample quality in denoising and generating. More impressively, GPM can store a large amount of data while maintaining key abilities of accurate retrieving of stored patterns, denoising of corrupted data and generating novel samples. Empirically we demonstrate the efficiency and versatility of GPM on a comprehensive suite of experiments involving binarized MNIST, binarized Omniglot, FashionMNIST, CIFAR10 & CIFAR100 and CelebA.",
        "conference": "ICLR",
        "中文标题": "生成伪逆记忆",
        "摘要翻译": "我们提出了生成伪逆记忆（GPM），一类快速写入和读取的深度生成记忆模型。记忆操作被重新定义为寻求线性系统的鲁棒解，这自然导致了矩阵伪逆的使用。伪逆被迭代近似，实际计算复杂度几乎为O(1)。我们从理论上证明并通过实验验证，在温和条件下，我们的模型可以准确检索写入记忆的内容。GPM的一个关键能力是迭代读取，在此过程中，朝向固定点的吸引子动力学被启用，允许模型在去噪和生成中迭代提高样本质量。更令人印象深刻的是，GPM可以存储大量数据，同时保持准确检索存储模式、去噪损坏数据和生成新样本的关键能力。我们通过涉及二值化MNIST、二值化Omniglot、FashionMNIST、CIFAR10 & CIFAR100和CelebA的综合实验套件，实证展示了GPM的效率和多功能性。",
        "领域": "深度学习、生成模型、记忆网络",
        "问题": "如何高效实现深度生成记忆模型的快速写入和读取，同时保持准确检索、去噪和生成能力",
        "动机": "为了解决现有记忆模型在写入和读取效率、存储容量以及准确检索、去噪和生成能力方面的限制",
        "方法": "通过将记忆操作重新定义为寻求线性系统的鲁棒解，利用矩阵伪逆的迭代近似，实现快速写入和读取，同时通过迭代读取和吸引子动力学提高样本质量",
        "关键词": [
            "生成伪逆记忆",
            "深度生成模型",
            "记忆网络",
            "矩阵伪逆",
            "迭代读取"
        ],
        "涉及的技术概念": {
            "矩阵伪逆": "用于实现记忆操作的线性系统鲁棒解，支持快速写入和读取",
            "吸引子动力学": "在迭代读取过程中启用，帮助模型在去噪和生成中迭代提高样本质量",
            "迭代近似": "用于近似矩阵伪逆，保持实际计算复杂度几乎为O(1)"
        },
        "success": true
    },
    {
        "order": 382,
        "title": "GeoDiff: A Geometric Diffusion Model for Molecular Conformation Generation",
        "html": "https://iclr.cc//virtual/2022/poster/7028",
        "abstract": "Predicting molecular conformations from molecular graphs is a fundamental problem in cheminformatics and drug discovery. Recently, significant progress has been achieved with machine learning approaches, especially with deep generative models. Inspired by the diffusion process in classical non-equilibrium thermodynamics where heated particles will diffuse from original states to a noise distribution, in this paper, we propose a novel generative model named GeoDiff for molecular conformation prediction. GeoDiff treats each atom as a particle and learns to directly reverse the diffusion process (i.e., transforming from a noise distribution to stable conformations) as a Markov chain. Modeling such a generation process is however very challenging as the likelihood of conformations should be roto-translational invariant. We theoretically show that Markov chains evolving with equivariant Markov kernels can induce an invariant distribution by design, and further propose building blocks for the Markov kernels to preserve the desirable equivariance property. The whole framework can be efficiently trained in an end-to-end fashion by optimizing a weighted variational lower bound to the (conditional) likelihood. Experiments on multiple benchmarks show that GeoDiff is superior or comparable to existing state-of-the-art approaches, especially on large molecules. ",
        "conference": "ICLR",
        "中文标题": "GeoDiff：一种用于分子构象生成的几何扩散模型",
        "摘要翻译": "从分子图预测分子构象是化学信息学和药物发现中的一个基本问题。近年来，机器学习方法，特别是深度生成模型，在这一领域取得了显著进展。受经典非平衡热力学中扩散过程的启发，即加热的粒子会从原始状态扩散到噪声分布，本文提出了一种名为GeoDiff的新型生成模型，用于分子构象预测。GeoDiff将每个原子视为一个粒子，并学习直接逆转扩散过程（即从噪声分布转变为稳定构象）作为马尔可夫链。然而，建模这样的生成过程非常具有挑战性，因为构象的似然应该是旋转平移不变的。我们从理论上证明了具有等变马尔可夫核演化的马尔可夫链可以通过设计诱导出一个不变的分布，并进一步提出了构建马尔可夫核的模块以保持所需的等变性。整个框架可以通过优化（条件）似然的加权变分下界，以端到端的方式高效训练。在多个基准测试上的实验表明，GeoDiff优于或可与现有的最先进方法相媲美，尤其是在大分子上。",
        "领域": "分子构象预测、药物发现、化学信息学",
        "问题": "如何从分子图高效准确地预测分子构象",
        "动机": "受非平衡热力学中扩散过程的启发，开发一种能够直接逆转扩散过程以生成稳定分子构象的模型",
        "方法": "提出GeoDiff模型，将分子构象生成视为逆转扩散过程，利用等变马尔可夫核保持构象的旋转平移不变性，并通过优化加权变分下界进行端到端训练",
        "关键词": [
            "分子构象生成",
            "扩散模型",
            "等变马尔可夫核",
            "药物发现",
            "化学信息学"
        ],
        "涉及的技术概念": {
            "几何扩散模型": "用于分子构象生成的模型，通过模拟扩散过程逆转来预测稳定构象",
            "等变马尔可夫核": "确保生成的分子构象在旋转和平移变换下保持不变的马尔可夫核",
            "加权变分下界": "用于优化模型训练的目标函数，确保模型能够高效学习生成过程"
        },
        "success": true
    },
    {
        "order": 383,
        "title": "Geometric and Physical Quantities improve E(3) Equivariant Message Passing",
        "html": "https://iclr.cc//virtual/2022/poster/6225",
        "abstract": "Including covariant information, such as position, force, velocity or spin is important in many tasks in computational physics and chemistry. We introduce Steerable E($3$) Equivariant Graph Neural Networks (SEGNNs) that generalise equivariant graph networks, such that node and edge attributes are not restricted to invariant scalars, but can contain covariant information, such as vectors or tensors. Our model, composed of steerable MLPs, is able to incorporate geometric and physical information in both the message and update functions.Through the definition of steerable node attributes, the MLPs provide a new class of activation functions for general use with steerable feature fields. We discuss ours and related work through the lens of equivariant non-linear convolutions, which further allows us to pin-point the successful components of SEGNNs: non-linear message aggregation improves upon classic linear (steerable) point convolutions; steerable messages improve upon recent equivariant graph networks that send invariant messages. We demonstrate the effectiveness of our method on several tasks in computational physics and chemistry and provide extensive ablation studies.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "几何与物理量提升E(3)等变消息传递",
        "摘要翻译": "在许多计算物理和化学的任务中，包含协变信息（如位置、力、速度或自旋）是非常重要的。我们介绍了可转向E(3)等变图神经网络（SEGNNs），它推广了等变图网络，使得节点和边的属性不仅限于不变的标量，还可以包含协变信息，如向量或张量。我们的模型由可转向的多层感知器（MLPs）组成，能够在消息和更新函数中融入几何和物理信息。通过定义可转向的节点属性，MLPs为一般使用的可转向特征场提供了一类新的激活函数。我们通过等变非线性卷积的视角讨论了我们和相关工作，这进一步使我们能够确定SEGNNs的成功组件：非线性消息聚合改进了经典的线性（可转向）点卷积；可转向消息改进了最近发送不变消息的等变图网络。我们在计算物理和化学的几个任务上展示了我们方法的有效性，并提供了广泛的消融研究。",
        "领域": "计算物理, 计算化学, 图神经网络",
        "问题": "如何在图神经网络中有效利用几何和物理信息，以提升模型在计算物理和化学任务中的表现。",
        "动机": "现有的等变图网络在处理协变信息（如向量或张量）方面存在限制，需要一种能够更灵活处理这类信息的方法。",
        "方法": "提出了一种可转向E(3)等变图神经网络（SEGNNs），通过可转向的多层感知器（MLPs）在消息和更新函数中融入几何和物理信息，并引入新的激活函数类别。",
        "关键词": [
            "可转向图神经网络",
            "E(3)等变性",
            "计算物理",
            "计算化学",
            "非线性消息聚合"
        ],
        "涉及的技术概念": {
            "可转向E(3)等变图神经网络（SEGNNs）": "一种推广的等变图网络，能够处理协变信息，如向量或张量，而不仅限于不变的标量。",
            "可转向多层感知器（MLPs）": "用于在消息和更新函数中融入几何和物理信息的模型组件，提供新的激活函数类别。",
            "非线性消息聚合": "改进经典线性点卷积的技术，通过非线性方式聚合消息，提升模型性能。"
        }
    },
    {
        "order": 384,
        "title": "Geometric Transformers for Protein Interface Contact Prediction",
        "html": "https://iclr.cc//virtual/2022/poster/6202",
        "abstract": "Computational methods for predicting the interface contacts between proteins come highly sought after for drug discovery as they can significantly advance the accuracy of alternative approaches, such as protein-protein docking, protein function analysis tools, and other computational methods for protein bioinformatics. In this work, we present the Geometric Transformer, a novel geometry-evolving graph transformer for rotation and translation-invariant protein interface contact prediction, packaged within DeepInteract, an end-to-end prediction pipeline. DeepInteract predicts partner-specific protein interface contacts (i.e., inter-protein residue-residue contacts) given the 3D tertiary structures of two proteins as input. In rigorous benchmarks, DeepInteract, on challenging protein complex targets from the 13th and 14th CASP-CAPRI experiments as well as Docking Benchmark 5, achieves 14% and 1.1% top L/5 precision (L: length of a protein unit in a complex), respectively. In doing so, DeepInteract, with the Geometric Transformer as its graph-based backbone, outperforms existing methods for interface contact prediction in addition to other graph-based neural network backbones compatible with DeepInteract, thereby validating the effectiveness of the Geometric Transformer for learning rich relational-geometric features for downstream tasks on 3D protein structures.",
        "conference": "ICLR",
        "中文标题": "用于蛋白质界面接触预测的几何变换器",
        "摘要翻译": "预测蛋白质间界面接触的计算方法在药物发现中备受追捧，因为它们可以显著提高替代方法的准确性，如蛋白质-蛋白质对接、蛋白质功能分析工具以及其他蛋白质生物信息学的计算方法。在这项工作中，我们提出了几何变换器，一种新颖的几何演化图变换器，用于旋转和平移不变的蛋白质界面接触预测，集成在DeepInteract中，一个端到端的预测流程。DeepInteract在给定两个蛋白质的三维三级结构作为输入的情况下，预测特定伙伴的蛋白质界面接触（即蛋白质间残基-残基接触）。在严格的基准测试中，DeepInteract在来自第13和第14届CASP-CAPRI实验以及Docking Benchmark 5的挑战性蛋白质复合物目标上，分别达到了14%和1.1%的top L/5精度（L：复合物中蛋白质单元的长度）。通过这样做，DeepInteract以几何变换器作为其基于图的骨干，不仅优于现有的界面接触预测方法，还优于与DeepInteract兼容的其他基于图的神经网络骨干，从而验证了几何变换器在学习用于三维蛋白质结构下游任务的丰富关系几何特征方面的有效性。",
        "领域": "蛋白质结构预测、生物信息学、深度学习",
        "问题": "预测蛋白质间的界面接触，以提高药物发现中蛋白质-蛋白质对接等方法的准确性。",
        "动机": "开发一种能够准确预测蛋白质界面接触的计算方法，以支持药物发现和蛋白质功能分析。",
        "方法": "提出了一种名为几何变换器的新颖几何演化图变换器，集成在DeepInteract端到端预测流程中，用于旋转和平移不变的蛋白质界面接触预测。",
        "关键词": [
            "几何变换器",
            "蛋白质界面接触预测",
            "DeepInteract",
            "生物信息学",
            "三维蛋白质结构"
        ],
        "涉及的技术概念": {
            "几何变换器": "一种新颖的几何演化图变换器，用于学习蛋白质结构中的丰富关系几何特征。",
            "DeepInteract": "一个端到端的预测流程，用于预测特定伙伴的蛋白质界面接触。",
            "蛋白质界面接触预测": "预测两个蛋白质间残基-残基的接触，对于理解蛋白质相互作用和药物设计至关重要。"
        },
        "success": true
    },
    {
        "order": 385,
        "title": "Geometry-Consistent Neural Shape Representation with Implicit Displacement Fields",
        "html": "https://iclr.cc//virtual/2022/poster/6338",
        "abstract": "We present implicit displacement fields, a novel representation for detailed 3D geometry. Inspired by a classic surface deformation technique, displacement mapping, our method represents a complex surface as a smooth base surface plus a displacement along the base's normal directions, resulting in a frequency-based shape decomposition, where the high-frequency signal is constrained geometrically by the low-frequency signal. Importantly, this disentanglement is unsupervised thanks to a tailored architectural design that has an innate frequency hierarchy by construction. We explore implicit displacement field surface reconstruction and detail transferand demonstrate superior representational power, training stability, and generalizability.",
        "conference": "ICLR",
        "中文标题": "几何一致的神经形状表示与隐式位移场",
        "摘要翻译": "我们提出了隐式位移场，这是一种用于详细3D几何形状的新颖表示方法。受经典表面变形技术——位移映射的启发，我们的方法将一个复杂表面表示为一个平滑的基础表面加上沿基础表面法线方向的位移，从而实现了基于频率的形状分解，其中高频信号在几何上受到低频信号的约束。重要的是，由于采用了具有固有频率层次结构的定制架构设计，这种解缠是无监督的。我们探索了隐式位移场的表面重建和细节转移，并展示了卓越的表示能力、训练稳定性和泛化能力。",
        "领域": "三维重建, 几何处理, 深度学习在计算机图形学中的应用",
        "问题": "如何有效地表示和重建具有复杂细节的3D几何形状",
        "动机": "为了解决传统方法在表示复杂3D几何形状时遇到的细节丢失和训练不稳定的问题",
        "方法": "提出了一种基于隐式位移场的方法，通过将复杂表面分解为平滑基础表面和沿法线方向的位移，实现频率基的形状分解和无监督的解缠",
        "关键词": [
            "隐式位移场",
            "三维重建",
            "几何处理",
            "无监督学习",
            "细节转移"
        ],
        "涉及的技术概念": {
            "隐式位移场": "用于表示复杂3D几何形状的新方法，通过平滑基础表面和沿法线方向的位移实现",
            "频率基的形状分解": "将形状分解为不同频率的信号，高频细节由低频基础形状约束",
            "无监督解缠": "通过定制架构设计实现形状特征的自动分离，无需监督信号"
        },
        "success": true
    },
    {
        "order": 386,
        "title": "GiraffeDet: A Heavy-Neck Paradigm for Object Detection",
        "html": "https://iclr.cc//virtual/2022/poster/6863",
        "abstract": "In conventional object detection frameworks, a backbone body inherited from image recognition models extracts deep latent features and then a neck module fuses these latent features to capture information at different scales. As the resolution in object detection is much larger than in image recognition, the computational cost of the backbone often dominates the total inference cost. This heavy-backbone design paradigm is mostly due to the historical legacy when transferring image recognition models to object detection rather than an end-to-end optimized design for object detection. In this work, we show that such  paradigm indeed leads to sub-optimal object detection models. To this end, we propose a novel heavy-neck paradigm, GiraffeDet, a giraffe-like network for efficient object detection. The GiraffeDet uses an extremely lightweight backbone and a very deep and large neck module which encourages dense information exchange among different spatial scales as well as different levels of latent semantics simultaneously. This design paradigm allows detectors to process the high-level semantic information and low-level spatial information at the same priority even in the early stage of the network, making it more effective in detection tasks.  Numerical evaluations on multiple popular object detection benchmarks show that GiraffeDet consistently outperforms previous SOTA models across a wide spectrum of resource constraints. The source code is available athttps://github.com/jyqi/GiraffeDet.",
        "conference": "ICLR",
        "中文标题": "GiraffeDet：一种用于目标检测的重颈范式",
        "摘要翻译": "在传统的目标检测框架中，一个继承自图像识别模型的主干网络提取深层潜在特征，然后一个颈部模块融合这些潜在特征以捕捉不同尺度的信息。由于目标检测中的分辨率远大于图像识别中的分辨率，主干网络的计算成本往往占据了总推理成本的大部分。这种重主干的设计范式主要是由于历史遗留问题，当将图像识别模型迁移到目标检测时，而不是为目标检测进行端到端优化的设计。在这项工作中，我们展示了这种范式确实导致了次优的目标检测模型。为此，我们提出了一种新颖的重颈范式，GiraffeDet，一种类似长颈鹿的网络，用于高效的目标检测。GiraffeDet使用了一个极其轻量级的主干网络和一个非常深且大的颈部模块，该模块鼓励在不同空间尺度以及不同层次的潜在语义之间进行密集的信息交换。这种设计范式使得检测器能够在网络的早期阶段同时处理高级语义信息和低级空间信息，使其在检测任务中更加有效。在多个流行的目标检测基准上的数值评估表明，GiraffeDet在广泛的资源约束范围内始终优于之前的SOTA模型。源代码可在https://github.com/jyqi/GiraffeDet获取。",
        "领域": "目标检测",
        "问题": "传统目标检测框架中重主干设计导致的次优性能和计算成本问题",
        "动机": "为了解决传统目标检测框架中由于重主干设计导致的次优性能和计算成本问题，提出一种新的重颈设计范式",
        "方法": "提出GiraffeDet，一种使用轻量级主干和深大颈部模块的网络，以促进不同尺度和语义层次间的信息交换",
        "关键词": [
            "GiraffeDet",
            "重颈范式",
            "目标检测",
            "轻量级主干",
            "信息交换"
        ],
        "涉及的技术概念": {
            "重颈范式": "一种新颖的网络设计范式，通过使用深且大的颈部模块来优化目标检测性能",
            "轻量级主干": "在GiraffeDet中使用的极其轻量级的主干网络，以减少计算成本",
            "信息交换": "GiraffeDet颈部模块鼓励在不同空间尺度和语义层次间进行密集的信息交换，以提高检测效率"
        },
        "success": true
    },
    {
        "order": 387,
        "title": "Givens Coordinate Descent Methods for Rotation Matrix Learning in Trainable Embedding Indexes",
        "html": "https://iclr.cc//virtual/2022/poster/5974",
        "abstract": "Product quantization (PQ) coupled with a space rotation, is widely used in modern approximate nearest neighbor (ANN) search systems to significantly compress the disk storage for embeddings and speed up the inner product computation. Existing rotation learning methods, however, minimize quantization distortion for fixed embeddings, which are not applicable to an end-to-end training scenario where embeddings are updated constantly. In this paper, based on geometric intuitions from Lie group theory,  in particular the special orthogonal groupSO(n),  we propose a family of block Givens coordinate descent algorithms to learn rotation matrix that are provably convergent on any convex objectives. Compared to the state-of-the-art SVD method, the Givens algorithms are much more parallelizable, reducing runtime by orders of magnitude on modern GPUs, and converge more stably  according  to  experimental  studies.   They  further  improve  upon  vanilla product quantization significantly in an end-to-end training scenario.",
        "conference": "ICLR",
        "中文标题": "可训练嵌入索引中旋转矩阵学习的吉文斯坐标下降方法",
        "摘要翻译": "产品量化（PQ）结合空间旋转，被广泛应用于现代近似最近邻（ANN）搜索系统中，以显著压缩嵌入的磁盘存储并加速内积计算。然而，现有的旋转学习方法最小化固定嵌入的量化失真，这不适用于嵌入不断更新的端到端训练场景。在本文中，基于李群理论，特别是特殊正交群SO(n)的几何直觉，我们提出了一系列块吉文斯坐标下降算法来学习旋转矩阵，这些算法在任何凸目标上都是可证明收敛的。与最先进的SVD方法相比，吉文斯算法更具并行性，在现代GPU上运行时减少了数量级，并且根据实验研究更稳定地收敛。在端到端训练场景中，它们进一步显著优于普通产品量化。",
        "领域": "近似最近邻搜索、嵌入学习、量化技术",
        "问题": "解决在端到端训练场景中，如何有效地学习旋转矩阵以优化嵌入量化的问题。",
        "动机": "现有的旋转学习方法不适用于嵌入不断更新的端到端训练场景，需要一种新的方法来有效学习旋转矩阵。",
        "方法": "基于李群理论，提出了一系列块吉文斯坐标下降算法来学习旋转矩阵，这些算法在任何凸目标上都是可证明收敛的。",
        "关键词": [
            "吉文斯坐标下降",
            "旋转矩阵学习",
            "产品量化",
            "近似最近邻搜索",
            "端到端训练"
        ],
        "涉及的技术概念": {
            "吉文斯坐标下降": "一种用于优化旋转矩阵学习的算法，通过坐标下降方法在特殊正交群上进行操作。",
            "产品量化": "一种用于压缩嵌入和加速内积计算的技术，广泛应用于近似最近邻搜索系统。",
            "特殊正交群SO(n)": "李群理论中的一个概念，用于描述所有n维旋转矩阵的集合，是旋转矩阵学习的基础。"
        },
        "success": true
    },
    {
        "order": 388,
        "title": "GLASS: GNN with Labeling Tricks for Subgraph Representation Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6916",
        "abstract": "Despite the remarkable achievements of Graph Neural Networks (GNNs) on graph representation learning, few works have tried to use them to predict properties of subgraphs in the whole graph. The existing state-of-the-art method SubGNN introduces an overly complicated subgraph-level GNN model which synthesizes three artificial channels each of which has two carefully designed subgraph-level message passing modules, yet only slightly outperforms a plain GNN which performs node-level message passing and then pools node embeddings within the subgraph. By analyzing SubGNN and plain GNNs, we find that the key for subgraph representation learning might be to distinguish nodes inside and outside the subgraph. With this insight, we propose an expressive and scalable labeling trick, namely max-zero-one, to enhance plain GNNs for subgraph tasks. The resulting model is called GLASS (GNN with LAbeling trickS for Subgraph). We theoretically characterize GLASS's expressive power. Compared with SubGNN, GLASS is more expressive, more scalable, and easier to implement. Experiments on eight benchmark datasets show that GLASS outperforms the strongest baseline by $14.8\\%$ on average. And ablation analysis shows that our max-zero-one labeling trick can boost the performance of a plain GNN by up to $105\\%$ in maximum, which illustrates the effectiveness of labeling trick on subgraph tasks. Furthermore, training a GLASS model only takes $37\\%$ time needed for a SubGNN on average. ",
        "conference": "ICLR",
        "中文标题": "GLASS：用于子图表示学习的带标签技巧的图神经网络",
        "摘要翻译": "尽管图神经网络（GNNs）在图表示学习方面取得了显著成就，但很少有工作尝试使用它们来预测整个图中子图的属性。现有的最先进方法SubGNN引入了一个过于复杂的子图级GNN模型，该模型合成了三个人工通道，每个通道都有两个精心设计的子图级消息传递模块，但仅略微优于执行节点级消息传递然后汇集子图内节点嵌入的普通GNN。通过分析SubGNN和普通GNNs，我们发现子图表示学习的关键可能是区分子图内外的节点。基于这一见解，我们提出了一种表达性强且可扩展的标签技巧，即max-zero-one，以增强普通GNNs用于子图任务。由此产生的模型被称为GLASS（用于子图的带标签技巧的GNN）。我们从理论上描述了GLASS的表达能力。与SubGNN相比，GLASS更具表达性、更可扩展且更易于实现。在八个基准数据集上的实验表明，GLASS平均比最强基线高出14.8%。消融分析显示，我们的max-zero-one标签技巧最多可以将普通GNN的性能提升105%，这说明了标签技巧在子图任务上的有效性。此外，训练一个GLASS模型平均仅需SubGNN所需时间的37%。",
        "领域": "图神经网络、子图表示学习、图表示学习",
        "问题": "如何有效地预测整个图中子图的属性",
        "动机": "现有方法SubGNN过于复杂且性能提升有限，需要一种更高效、更简单的方法来提升子图表示学习的性能",
        "方法": "提出了一种名为max-zero-one的标签技巧，用于增强普通GNNs在子图任务中的表现，从而构建了GLASS模型",
        "关键词": [
            "图神经网络",
            "子图表示学习",
            "标签技巧",
            "max-zero-one",
            "GLASS"
        ],
        "涉及的技术概念": {
            "图神经网络（GNNs）": "用于图表示学习的深度学习模型，能够处理图结构数据",
            "子图表示学习": "专注于学习图中子结构的表示，以便于预测子图的属性",
            "max-zero-one标签技巧": "一种用于增强GNNs在子图任务中表现的标签技巧，通过区分子图内外的节点来提升模型性能"
        },
        "success": true
    },
    {
        "order": 389,
        "title": "Global Convergence of Multi-Agent Policy Gradient in Markov Potential Games",
        "html": "https://iclr.cc//virtual/2022/poster/7008",
        "abstract": "Potential games are arguably one of the most important and widely studied classes of normal form games. They define the archetypal setting of multi-agent coordination in which all agents utilities are perfectly aligned via a common potential function. Can this intuitive framework be transplanted in the setting of Markov games? What are the similarities and differences between multi-agent coordination with and without state dependence? To answer these questions, we study a natural class of Markov Potential Games (MPGs) that generalize prior attempts at capturing complex stateful multi-agent coordination. Counter-intuitively, insights from normal-form potential games do not carry over as MPGs involve settings where state-games can be zero-sum games. In the opposite direction, Markov games where every state-game is a potential game are not necessarily MPGs. Nevertheless, MPGs showcase standard desirable properties such as the existence of deterministic Nash policies. In our main technical result, we prove convergence of independent policy gradient and its stochastic counterpart to Nash policies (polynomially fast in the approximation error) by adapting recent gradient dominance property arguments developed for single-agent Markov decision processes to multi-agent learning settings. ",
        "conference": "ICLR",
        "中文标题": "马尔可夫势博弈中多智能体策略梯度的全局收敛性",
        "摘要翻译": "势博弈可以说是最重要且被广泛研究的一类正规形式博弈。它们定义了多智能体协调的典型场景，其中所有智能体的效用通过一个共同的势函数完美对齐。这个直观的框架能否移植到马尔可夫博弈的设置中？有状态依赖和无状态依赖的多智能体协调之间有哪些相似之处和差异？为了回答这些问题，我们研究了一类自然的马尔可夫势博弈（MPGs），它概括了先前尝试捕捉复杂有状态多智能体协调的努力。与直觉相反，来自正规形式势博弈的洞察并不适用于MPGs，因为MPGs涉及的状态博弈可以是零和博弈。相反，每个状态博弈都是势博弈的马尔可夫博弈不一定是MPGs。尽管如此，MPGs展示了标准的理想属性，如确定性纳什策略的存在。在我们的主要技术结果中，我们通过将最近为单智能体马尔可夫决策过程开发的梯度优势属性论证适应于多智能体学习设置，证明了独立策略梯度及其随机对应物对纳什策略的收敛性（在近似误差中以多项式速度）。",
        "领域": "多智能体学习、博弈论、强化学习",
        "问题": "研究马尔可夫势博弈（MPGs）中多智能体策略梯度的全局收敛性问题，以及有状态依赖和无状态依赖的多智能体协调之间的差异。",
        "动机": "探索势博弈框架在马尔可夫博弈中的适用性，理解多智能体协调在有状态和无状态依赖下的异同，以及验证MPGs中确定性纳什策略的存在性和策略梯度的收敛性。",
        "方法": "通过将单智能体马尔可夫决策过程中的梯度优势属性论证扩展到多智能体学习设置，研究独立策略梯度及其随机对应物在MPGs中的收敛性。",
        "关键词": [
            "马尔可夫势博弈",
            "多智能体学习",
            "策略梯度",
            "纳什策略",
            "梯度优势属性"
        ],
        "涉及的技术概念": {
            "马尔可夫势博弈（MPGs）": "一类自然的马尔可夫博弈，概括了复杂有状态多智能体协调的场景，其中状态博弈可以是零和博弈。",
            "策略梯度": "一种在多智能体学习中用于优化策略的方法，通过梯度上升来调整策略参数。",
            "梯度优势属性": "一种用于证明策略梯度方法收敛性的技术，通过展示策略空间的梯度优势来保证收敛到纳什策略。"
        },
        "success": true
    },
    {
        "order": 390,
        "title": "GNN is a Counter? Revisiting GNN for Question Answering",
        "html": "https://iclr.cc//virtual/2022/poster/6194",
        "abstract": "Question Answering (QA) has been a long-standing research topic in AI and NLP fields, and a wealth of studies has been conducted to attempt to equip QA systems with human-level reasoning capability. To approximate the complicated human reasoning process, state-of-the-art QA systems commonly use pre-trained language models (LMs) to access knowledge encoded in LMs together with elaborately designed modules based on Graph Neural Networks (GNNs) to perform reasoning over knowledge graphs (KGs). However, many problems remain open regarding the reasoning functionality of these GNN-based modules. Can these GNN-based modules really perform a complex reasoning process? Are they under- or over-complicated for QA? To open the black box of GNN and investigate these problems, we dissect state-of-the-art GNN modules for QA and analyze their reasoning capability. We discover that even a very simple graph neural counter can outperform all the existing GNN modules on CommonsenseQA and OpenBookQA, two popular QA benchmark datasets which heavily rely on knowledge-aware reasoning. Our work reveals that existing knowledge-aware GNN modules may only carry out some simple reasoning such as counting. It remains a challenging open problem to build comprehensive reasoning modules for knowledge-powered QA.",
        "conference": "ICLR",
        "中文标题": "GNN是计数器吗？重新审视GNN在问答系统中的应用",
        "摘要翻译": "问答（QA）一直是人工智能和自然语言处理领域的一个长期研究课题，大量研究试图赋予QA系统人类水平的推理能力。为了近似复杂的人类推理过程，最先进的QA系统通常使用预训练语言模型（LMs）来访问编码在LMs中的知识，并结合基于图神经网络（GNNs）精心设计的模块在知识图谱（KGs）上进行推理。然而，关于这些基于GNN的模块的推理功能，许多问题仍然悬而未决。这些基于GNN的模块真的能执行复杂的推理过程吗？它们对于QA来说是过于简单还是过于复杂？为了打开GNN的黑匣子并研究这些问题，我们剖析了最先进的用于QA的GNN模块，并分析了它们的推理能力。我们发现，即使是一个非常简单的图神经计数器，也可以在CommonsenseQA和OpenBookQA这两个严重依赖知识感知推理的流行QA基准数据集上，超越所有现有的GNN模块。我们的工作揭示了现有的知识感知GNN模块可能只执行一些简单的推理，如计数。构建用于知识驱动的QA的全面推理模块仍然是一个具有挑战性的开放性问题。",
        "领域": "自然语言处理与视觉结合、知识图谱推理、问答系统",
        "问题": "探讨基于图神经网络（GNN）的模块在问答系统中的实际推理能力及其复杂性是否适合QA任务。",
        "动机": "揭示现有知识感知GNN模块在问答系统中的推理能力，特别是它们是否能够执行复杂的推理过程，或者是否过于简单或复杂。",
        "方法": "通过剖析最先进的用于QA的GNN模块，并分析它们的推理能力，包括比较一个简单的图神经计数器与现有GNN模块在基准数据集上的表现。",
        "关键词": [
            "图神经网络",
            "问答系统",
            "知识图谱推理",
            "推理能力",
            "知识感知"
        ],
        "涉及的技术概念": {
            "图神经网络（GNNs）": "用于在知识图谱上进行推理的技术，旨在模拟复杂的推理过程。",
            "知识图谱（KGs）": "结构化知识表示，用于支持问答系统中的知识感知推理。",
            "预训练语言模型（LMs）": "用于访问和编码知识的模型，支持问答系统中的语言理解和推理。"
        },
        "success": true
    },
    {
        "order": 391,
        "title": "GNN-LM: Language Modeling based on Global Contexts via GNN",
        "html": "https://iclr.cc//virtual/2022/poster/6501",
        "abstract": "Inspired by the notion that ``{\\it to copy is easier than to memorize}``, in this work, we introduce GNN-LM, which extends vanilla neural language model (LM) by allowing to reference similar contexts in the entire training corpus. We build a directed heterogeneous graph between an input context and its semantically related neighbors selected from the training corpus, where nodes are tokens in the input context and retrieved neighbor contexts, and edges represent connections between nodes. Graph neural networks (GNNs) are constructed upon the graph to aggregate information from similar contexts to decode the token. This learning paradigm provides direct access to the reference contexts and helps improve a model's generalization ability. We conduct comprehensive experiments to validate the effectiveness of the GNN-LM: GNN-LM achieves a new state-of-the-art perplexity of 14.8 on WikiText-103 (a 3.9 point improvement over its counterpart of the vanilla  LM model), and shows substantial improvement on One Billion Word and Enwiki8 datasets against strong baselines. In-depth ablation studies are performed to understand the mechanics of GNN-LM. The code can be found at \\url{https://github.com/ShannonAI/GNN-LM}. ",
        "conference": "ICLR",
        "中文标题": "GNN-LM：基于全局上下文的图神经网络语言模型",
        "摘要翻译": "受到“复制比记忆更容易”这一理念的启发，在本工作中，我们介绍了GNN-LM，它通过允许引用整个训练语料库中的相似上下文来扩展普通的神经语言模型（LM）。我们在输入上下文和从训练语料库中选出的语义相关邻居之间构建了一个有向异构图，其中节点是输入上下文和检索到的邻居上下文中的令牌，边代表节点之间的连接。图神经网络（GNNs）被构建在图上，以从相似上下文中聚合信息来解码令牌。这种学习范式提供了对参考上下文的直接访问，并有助于提高模型的泛化能力。我们进行了全面的实验来验证GNN-LM的有效性：GNN-LM在WikiText-103上实现了14.8的最新困惑度（比普通LM模型对应物提高了3.9点），并在One Billion Word和Enwiki8数据集上显示出对强基线的显著改进。进行了深入的消融研究以理解GNN-LM的机制。代码可以在https://github.com/ShannonAI/GNN-LM找到。",
        "领域": "自然语言处理与视觉结合",
        "问题": "如何通过引用训练语料库中的相似上下文来提升神经语言模型的性能",
        "动机": "受到“复制比记忆更容易”理念的启发，探索通过直接访问相似上下文来提高语言模型的泛化能力",
        "方法": "构建有向异构图连接输入上下文和语义相关的邻居上下文，利用图神经网络聚合信息来解码令牌",
        "关键词": [
            "图神经网络",
            "语言模型",
            "全局上下文"
        ],
        "涉及的技术概念": {
            "有向异构图": "用于表示输入上下文和其语义相关邻居之间关系的图结构，节点代表令牌，边代表连接",
            "图神经网络（GNNs）": "用于在构建的图上聚合来自相似上下文的信息，以帮助解码令牌",
            "困惑度": "用于评估语言模型性能的指标，GNN-LM在WikiText-103上实现了14.8的最新困惑度"
        },
        "success": true
    },
    {
        "order": 392,
        "title": "Goal-Directed Planning via Hindsight Experience Replay",
        "html": "https://iclr.cc//virtual/2022/poster/6831",
        "abstract": "We consider the problem of goal-directed planning under a deterministic transition model. Monte Carlo Tree Search has shown remarkable performance in solving deterministic control problems. It has been extended from complex continuous domains through function approximators to bias the search of the planning tree in AlphaZero. Nonetheless, these algorithms still struggle with control problems with sparse rewards, such as goal-directed domains, where a positive reward is awarded only when reaching a goal state. In this work, we recast AlphaZero with Hindsight Experience Replay to tackle complex goal-directed planning tasks. We perform a thorough empirical evaluation in several simulated domains, including a novel application to a quantum compiling domain.",
        "conference": "ICLR",
        "中文标题": "通过后见之明经验回放实现目标导向规划",
        "摘要翻译": "我们考虑在确定性转移模型下的目标导向规划问题。蒙特卡洛树搜索在解决确定性控制问题方面表现出了显著的性能。它已通过函数逼近器从复杂的连续领域扩展到AlphaZero中，以偏置规划树的搜索。尽管如此，这些算法仍然难以应对奖励稀疏的控制问题，如目标导向领域，其中只有在达到目标状态时才会获得正奖励。在这项工作中，我们通过后见之明经验回放重新构建AlphaZero，以解决复杂的目标导向规划任务。我们在几个模拟领域进行了彻底的实证评估，包括在量子编译领域的新应用。",
        "领域": "强化学习、自动规划、量子计算",
        "问题": "解决在确定性转移模型下，目标导向规划任务中奖励稀疏的问题",
        "动机": "针对目标导向领域中的稀疏奖励问题，提高规划算法的效率和性能",
        "方法": "结合后见之明经验回放技术重新构建AlphaZero算法，应用于复杂的目标导向规划任务",
        "关键词": [
            "目标导向规划",
            "后见之明经验回放",
            "AlphaZero",
            "蒙特卡洛树搜索",
            "量子编译"
        ],
        "涉及的技术概念": {
            "后见之明经验回放": "一种强化学习技术，通过重新标记过去的经验来学习稀疏奖励环境下的策略",
            "AlphaZero": "结合深度学习和蒙特卡洛树搜索的算法，用于解决复杂的规划和控制问题",
            "蒙特卡洛树搜索": "一种用于决策过程的搜索算法，特别适用于具有巨大状态空间的规划问题"
        },
        "success": true
    },
    {
        "order": 393,
        "title": "GPT-Critic: Offline Reinforcement Learning for End-to-End Task-Oriented Dialogue Systems",
        "html": "https://iclr.cc//virtual/2022/poster/6823",
        "abstract": "Training a task-oriented dialogue agent can be naturally formulated as offline reinforcement learning (RL) problem, where the agent aims to learn a conversational strategy to achieve user goals, only from a dialogue corpus. It is very challenging in terms of RL since the natural language action space is astronomical, while feasible (syntactically and semantically correct) actions are very sparse. Thus, standard RL methods easily fail and generate responses diverging from human language, even when fine-tuning a powerful pre-trained language model. In this paper, we introduce GPT-Critic, an offline RL method for task-oriented dialogue. GPT-Critic is built upon GPT-2, fine-tuning the language model through behavior cloning of the critic-guided self-generated sentences. GPT-Critic is essentially free from the issue of diverging from human language since it learns from the sentences sampled from the pre-trained language model. In the experiments, we demonstrate that our algorithm outperforms the state-of-the-art in the task-oriented dialogue benchmarks including MultiWOZ 2.0 and ConvLab.",
        "conference": "ICLR",
        "中文标题": "GPT-Critic：面向端到端任务导向对话系统的离线强化学习",
        "摘要翻译": "训练一个任务导向的对话代理可以自然地表述为一个离线强化学习（RL）问题，其中代理旨在仅从对话语料库中学习一种对话策略以实现用户目标。这在RL方面非常具有挑战性，因为自然语言动作空间极其庞大，而可行（语法和语义上正确）的动作非常稀少。因此，标准的RL方法容易失败并生成偏离人类语言的响应，即使是在微调一个强大的预训练语言模型时。在本文中，我们介绍了GPT-Critic，一种用于任务导向对话的离线RL方法。GPT-Critic基于GPT-2构建，通过行为克隆批评者引导的自生成句子来微调语言模型。GPT-Critic基本上不会偏离人类语言的问题，因为它学习的是从预训练语言模型中采样的句子。在实验中，我们证明了我们的算法在包括MultiWOZ 2.0和ConvLab在内的任务导向对话基准测试中优于最先进的技术。",
        "领域": "任务导向对话系统、离线强化学习、自然语言处理",
        "问题": "如何在庞大的自然语言动作空间中有效地学习对话策略，以生成语法和语义正确的响应。",
        "动机": "解决标准强化学习方法在任务导向对话系统中因自然语言动作空间庞大而可行动作稀少导致的失败和生成偏离人类语言响应的问题。",
        "方法": "基于GPT-2构建GPT-Critic，通过行为克隆批评者引导的自生成句子来微调语言模型，从而避免偏离人类语言的问题。",
        "关键词": [
            "任务导向对话系统",
            "离线强化学习",
            "GPT-2",
            "行为克隆",
            "批评者引导"
        ],
        "涉及的技术概念": {
            "离线强化学习": "在本文中用于从对话语料库中学习对话策略，而不需要在线交互。",
            "行为克隆": "用于微调语言模型，通过模仿批评者引导的自生成句子来学习。",
            "GPT-2": "作为基础模型，用于生成自然语言响应，并通过批评者引导的微调来优化对话策略。"
        },
        "success": true
    },
    {
        "order": 394,
        "title": "Gradient Importance Learning for Incomplete Observations",
        "html": "https://iclr.cc//virtual/2022/poster/6859",
        "abstract": "Though recent works have developed methods that can generate estimates (or imputations) of the missing entries in a dataset to facilitate downstream analysis, most depend on assumptions that may not align with real-world applications and could suffer from poor performance in subsequent tasks such as classification. This is particularly true if the data have large missingness rates or a small sample size. More importantly, the imputation error could be propagated into the prediction step that follows, which may constrain the capabilities of the prediction model. In this work, we introduce the gradient importance learning (GIL) method to train multilayer perceptrons (MLPs) and long short-term memories (LSTMs) to directly perform inference from inputs containing missing values without imputation. Specifically, we employ reinforcement learning (RL) to adjust the gradients used to train these models via back-propagation. This allows the model to exploit the underlying information behind missingness patterns. We test the approach on real-world time-series (i.e., MIMIC-III), tabular data obtained from an eye clinic, and a standard dataset (i.e., MNIST), where our imputation-free predictions outperform the traditional two-step imputation-based predictions using state-of-the-art imputation methods.",
        "conference": "ICLR",
        "中文标题": "梯度重要性学习用于不完整观测",
        "摘要翻译": "尽管最近的研究已经开发出可以生成数据集中缺失条目估计（或填补）的方法以促进下游分析，但大多数方法依赖于可能与现实世界应用不符的假设，并且在后续任务（如分类）中可能表现不佳。如果数据的缺失率很高或样本量很小，这一点尤其明显。更重要的是，填补误差可能会传播到随后的预测步骤中，这可能限制预测模型的能力。在这项工作中，我们引入了梯度重要性学习（GIL）方法来训练多层感知器（MLPs）和长短期记忆网络（LSTMs），直接从包含缺失值的输入进行推理，而无需填补。具体来说，我们采用强化学习（RL）来调整通过反向传播训练这些模型的梯度。这使得模型能够利用缺失模式背后的潜在信息。我们在真实世界的时间序列数据（即MIMIC-III）、从眼科诊所获得的表格数据以及标准数据集（即MNIST）上测试了这种方法，其中我们的无需填补的预测在使用最先进填补方法的传统两步填补预测中表现更优。",
        "领域": "缺失数据处理, 时间序列分析, 深度学习应用",
        "问题": "解决在数据缺失率高或样本量小的情况下，传统填补方法可能导致的预测性能下降问题。",
        "动机": "减少或避免因数据填补引入的误差对后续预测任务的影响，提高模型在缺失数据情况下的直接推理能力。",
        "方法": "采用梯度重要性学习（GIL）方法，结合强化学习调整训练梯度，使模型能够直接从包含缺失值的输入进行有效推理。",
        "关键词": [
            "梯度重要性学习",
            "缺失数据处理",
            "强化学习",
            "多层感知器",
            "长短期记忆网络"
        ],
        "涉及的技术概念": {
            "梯度重要性学习（GIL）": "用于调整模型训练过程中的梯度，以利用缺失数据背后的信息，避免传统填补步骤。",
            "强化学习（RL）": "用于动态调整训练梯度，优化模型在缺失数据情况下的性能。",
            "多层感知器（MLPs）和长短期记忆网络（LSTMs）": "作为基础模型，直接从包含缺失值的输入进行预测，无需预先填补。"
        },
        "success": true
    },
    {
        "order": 395,
        "title": "Gradient Information Matters in Policy Optimization by Back-propagating through Model",
        "html": "https://iclr.cc//virtual/2022/poster/5997",
        "abstract": "Model-based reinforcement learning provides an efficient mechanism to find the optimal policy by interacting with the learned environment. In addition to treating the learned environment like a black-box simulator, a more effective way to use the model is to exploit its differentiability. Such methods require the gradient information of the learned environment model when calculating the policy gradient. However, since the error of gradient is not considered in the model learning phase, there is no guarantee for the model's accuracy. To address this problem, we first analyze the convergence rate for the policy optimization methods when the policy gradient is calculated using the learned environment model. The theoretical results show that the model gradient error matters in the policy optimization phrase. Then we propose a two-model-based learning method to control the prediction error and the gradient error. We separate the different roles of these two models at the model learning phase and coordinate them at the policy optimization phase. After proposing the method, we introduce the directional derivative projection policy optimization (DDPPO) algorithm as a practical implementation to find the optimal policy. Finally, we empirically demonstrate the proposed algorithm has better sample efficiency when achieving a comparable or better performance on benchmark continuous control tasks.",
        "conference": "ICLR",
        "中文标题": "梯度信息在通过模型反向传播的策略优化中至关重要",
        "摘要翻译": "基于模型的强化学习通过与被学习的环境互动，提供了一种寻找最优策略的有效机制。除了将学习到的环境视为黑盒模拟器外，更有效地利用模型的方法是开发其可微分性。这类方法在计算策略梯度时需要学习环境模型的梯度信息。然而，由于在模型学习阶段未考虑梯度误差，无法保证模型的准确性。为了解决这个问题，我们首先分析了当使用学习到的环境模型计算策略梯度时，策略优化方法的收敛速度。理论结果表明，模型梯度误差在策略优化阶段至关重要。然后，我们提出了一种基于双模型的学习方法，以控制预测误差和梯度误差。我们在模型学习阶段分离这两个模型的不同角色，并在策略优化阶段协调它们。提出方法后，我们引入了方向导数投影策略优化（DDPPO）算法作为寻找最优策略的实际实现。最后，我们通过实验证明，在基准连续控制任务上达到相当或更好性能时，所提出的算法具有更好的样本效率。",
        "领域": "强化学习、连续控制、策略优化",
        "问题": "在基于模型的强化学习中，如何有效利用环境模型的可微分性来提高策略优化的效率和准确性",
        "动机": "由于在模型学习阶段未考虑梯度误差，导致在策略优化阶段无法保证模型的准确性，影响了策略优化的效率和效果",
        "方法": "提出了一种基于双模型的学习方法，分离模型学习阶段的两个模型角色并在策略优化阶段协调它们，以及引入了方向导数投影策略优化（DDPPO）算法",
        "关键词": [
            "强化学习",
            "策略优化",
            "梯度误差",
            "双模型学习",
            "DDPPO算法"
        ],
        "涉及的技术概念": {
            "梯度误差": "在策略优化阶段，模型梯度误差对策略优化的效率和准确性有重要影响",
            "双模型学习": "通过分离两个模型在模型学习阶段的不同角色，并在策略优化阶段协调它们，以控制预测误差和梯度误差",
            "方向导数投影策略优化（DDPPO）算法": "作为寻找最优策略的实际实现，该算法在基准连续控制任务上表现出更好的样本效率"
        },
        "success": true
    },
    {
        "order": 396,
        "title": "Gradient Matching for Domain Generalization",
        "html": "https://iclr.cc//virtual/2022/poster/6373",
        "abstract": "Machine learning systems typically assume that the distributions of training and test sets match closely. However, a critical requirement of such systems in the real world is their ability to generalize to unseen domains. Here, we propose an _inter-domain gradient matching_ objective that targets domain generalization by maximizing the inner product between gradients from different domains. Since direct optimization of the gradient inner product can be computationally prohibitive --- it requires computation of second-order derivatives –-- we derive a simpler first-order algorithm named Fish that approximates its optimization. We perform experiments on the Wilds benchmark, which captures distribution shift in the real world, as well as the DomainBed benchmark that focuses more on synthetic-to-real transfer. Our method produces competitive results on both benchmarks, demonstrating its effectiveness across a wide range of domain generalization tasks.",
        "conference": "ICLR",
        "中文标题": "领域泛化的梯度匹配方法",
        "摘要翻译": "机器学习系统通常假设训练集和测试集的分布紧密匹配。然而，在现实世界中，这类系统的一个关键要求是它们能够泛化到未见过的领域。在此，我们提出了一种_跨领域梯度匹配_目标，通过最大化来自不同领域的梯度之间的内积来实现领域泛化。由于直接优化梯度内积可能在计算上非常昂贵——它需要计算二阶导数——我们推导出了一个更简单的一阶算法，名为Fish，以近似其优化。我们在Wilds基准测试上进行了实验，该基准测试捕捉了现实世界中的分布变化，以及在DomainBed基准测试上，后者更侧重于从合成到真实的转移。我们的方法在这两个基准测试上都产生了有竞争力的结果，证明了其在广泛的领域泛化任务中的有效性。",
        "领域": "领域泛化、迁移学习、深度学习",
        "问题": "解决机器学习模型在未见过的领域上泛化能力不足的问题",
        "动机": "提高机器学习模型在现实世界中面对分布变化时的泛化能力",
        "方法": "提出了一种跨领域梯度匹配目标，并开发了一个名为Fish的一阶算法来近似优化该目标",
        "关键词": [
            "领域泛化",
            "梯度匹配",
            "Fish算法",
            "Wilds基准",
            "DomainBed基准"
        ],
        "涉及的技术概念": {
            "跨领域梯度匹配": "通过最大化不同领域梯度之间的内积来实现领域泛化的技术",
            "Fish算法": "一种简化的一阶优化算法，用于近似优化梯度内积，避免计算二阶导数的高成本",
            "Wilds基准": "一个旨在捕捉现实世界中分布变化的基准测试，用于评估领域泛化方法的有效性"
        },
        "success": true
    },
    {
        "order": 397,
        "title": "Gradient Step Denoiser for convergent Plug-and-Play",
        "html": "https://iclr.cc//virtual/2022/poster/6192",
        "abstract": "Plug-and-Play methods constitute a class of iterative algorithms for imaging problems where regularization is performed by an off-the-shelf denoiser. Although Plug-and-Play methods can lead to tremendous visual performance for various image problems, the few existing convergence guarantees are based on unrealistic (or suboptimal) hypotheses on the denoiser, or limited to strongly convex data terms. In this work, we propose a new type of Plug-and-Play methods, based on half-quadratic splitting, for which the denoiser is realized as a gradient descent step on a functional parameterized by a deep neural network. Exploiting convergence results for proximal gradient descent algorithms in the non-convex setting, we show that the proposed Plug-and-Play algorithm is a convergent iterative scheme that targets stationary points of an explicit global functional. Besides, experiments show that it is possible to learn such a deep denoiser while not compromising the performance in comparison to other state-of-the-art deep denoisers used in Plug-and-Play schemes. We apply our proximal gradient algorithm to various ill-posed inverse problems, e.g. deblurring, super-resolution and inpainting. For all these applications, numerical results empirically confirm the convergence results. Experiments also show that this new algorithm reaches state-of-the-art performance, both quantitatively and qualitatively.",
        "conference": "ICLR",
        "中文标题": "梯度步降噪器用于收敛的即插即用方法",
        "摘要翻译": "即插即用方法构成了一类用于成像问题的迭代算法，其中正则化是通过现成的降噪器执行的。尽管即插即用方法可以为各种图像问题带来巨大的视觉性能，但现有的少数收敛保证是基于对降噪器的不现实（或次优）假设，或仅限于强凸数据项。在这项工作中，我们提出了一种新型的即插即用方法，基于半二次分裂，其中降噪器被实现为对由深度神经网络参数化的功能进行梯度下降步骤。利用非凸设置中近端梯度下降算法的收敛结果，我们表明所提出的即插即用算法是一种收敛的迭代方案，针对显式全局功能的静止点。此外，实验表明，可以学习这样的深度降噪器，同时不损害与其他用于即插即用方案的最先进深度降噪器相比的性能。我们将我们的近端梯度算法应用于各种不适定反问题，例如去模糊、超分辨率和修复。对于所有这些应用，数值结果经验上证实了收敛结果。实验还表明，这种新算法在数量和质量上都达到了最先进的性能。",
        "领域": "图像去噪、图像恢复、深度学习在图像处理中的应用",
        "问题": "解决即插即用方法中降噪器的收敛性问题，以及在不牺牲性能的情况下学习深度降噪器。",
        "动机": "现有的即插即用方法在降噪器的收敛性保证上存在不足，或仅限于特定条件，本研究旨在提出一种新型即插即用方法，确保收敛性同时保持高性能。",
        "方法": "基于半二次分裂的新型即插即用方法，将降噪器实现为深度神经网络参数化功能的梯度下降步骤，利用非凸设置中的近端梯度下降算法确保收敛。",
        "关键词": [
            "即插即用方法",
            "梯度步降噪器",
            "半二次分裂",
            "深度神经网络",
            "图像恢复"
        ],
        "涉及的技术概念": {
            "半二次分裂": "用于将复杂问题分解为更简单子问题的优化技术，在本研究中用于实现即插即用方法的降噪步骤。",
            "近端梯度下降算法": "一种优化算法，用于在非凸设置中找到函数的静止点，本研究利用其确保即插即用方法的收敛性。",
            "深度神经网络参数化功能": "通过深度神经网络来参数化降噪器的功能，使得降噪器能够学习复杂的图像特征，同时保持算法的收敛性。"
        },
        "success": true
    },
    {
        "order": 398,
        "title": "GradMax: Growing Neural Networks using Gradient Information",
        "html": "https://iclr.cc//virtual/2022/poster/7131",
        "abstract": "The architecture and the parameters of neural networks are often optimized independently, which requires costly retraining of the parameters whenever the architecture is modified. In this work we instead focus on growing the architecture without requiring costly retraining. We present a method that adds new neurons during training without impacting what is already learned, while improving the training dynamics. We do this by maximizing the gradients of the new neurons and find an approximation to the optimal initialization by means of the singular value decomposition (SVD). We call this technique Gradient Maximizing Growth (GradMax) and demonstrate its effectiveness in variety of vision tasks and architectures.",
        "conference": "ICLR",
        "中文标题": "GradMax：利用梯度信息增长神经网络",
        "摘要翻译": "神经网络的架构和参数通常被独立优化，这要求在架构修改时对参数进行昂贵的重新训练。在本工作中，我们转而专注于在不需昂贵重新训练的情况下增长架构。我们提出了一种方法，在训练过程中添加新的神经元，而不影响已学习的内容，同时改善训练动态。我们通过最大化新神经元的梯度来实现这一点，并通过奇异值分解（SVD）找到最优初始化的近似。我们将这种技术称为梯度最大化增长（GradMax），并在多种视觉任务和架构中证明了其有效性。",
        "领域": "神经网络架构优化、计算机视觉、深度学习",
        "问题": "如何在修改神经网络架构时避免昂贵的参数重新训练",
        "动机": "减少因架构修改导致的参数重新训练成本，提高训练效率",
        "方法": "通过最大化新神经元的梯度并利用奇异值分解（SVD）近似最优初始化，实现架构增长而不影响已学习内容",
        "关键词": [
            "神经网络增长",
            "梯度最大化",
            "奇异值分解",
            "架构优化",
            "训练动态改善"
        ],
        "涉及的技术概念": {
            "梯度最大化": "通过最大化新神经元的梯度来优化其初始化，促进有效学习",
            "奇异值分解（SVD）": "用于近似计算新神经元的最优初始化，支持架构的有效增长",
            "训练动态改善": "通过优化新神经元的初始化，改善整体网络的训练过程和性能"
        },
        "success": true
    },
    {
        "order": 399,
        "title": "GradSign: Model Performance Inference with Theoretical Insights",
        "html": "https://iclr.cc//virtual/2022/poster/6993",
        "abstract": "A key challenge in neural architecture search (NAS) is quickly inferring the predictive performance of a broad spectrum of networks to discover statistically accurate and computationally efficient ones.  We refer to this task as model performance inference (MPI). The current practice for efficient MPI is gradient-based methods that leverage the gradients of a network at initialization to infer its performance. However, existing gradient-based methods rely only on heuristic metrics and lack the necessary theoretical foundations to consolidate their designs.  We propose GradSign, an accurate, simple, and flexible metric for model performance inference with theoretical insights. The key idea behind GradSign is a quantity Ψ to analyze the sample-wise optimization landscape of different networks. Theoretically, we show that  Ψ is an upper bound for both the training and true population losses of a neural network under reasonable assumptions. However, it is computationally prohibitive to directly calculate Ψ for modern neural networks. Toaddress this challenge, we design GradSign, an accurate and simple approximation of Ψ using the gradients of a network evaluated at a random initialization state. Evaluation on seven NAS benchmarks across three training datasets shows that GradSign generalizes well to real-world networks and consistently outperforms state-of-the-art gradient-based methods for MPI evaluated by Spearman’s ρ and Kendall’s Tau.  Additionally, we integrate GradSign into four existing NAS algorithms and show that the GradSign-assisted NAS algorithms outperform their vanilla counterparts by improving the accuracies of best-discovered networks by up to 0.3%, 1.1%, and 1.0% on three real-world tasks.",
        "conference": "ICLR",
        "中文标题": "GradSign：基于理论洞察的模型性能推断",
        "摘要翻译": "在神经架构搜索（NAS）中，一个关键挑战是快速推断广泛网络谱的预测性能，以发现统计上准确且计算效率高的网络。我们将此任务称为模型性能推断（MPI）。当前高效MPI的实践是基于梯度的方法，这些方法利用网络在初始化时的梯度来推断其性能。然而，现有的基于梯度的方法仅依赖于启发式指标，缺乏巩固其设计所需的理论基础。我们提出了GradSign，一个准确、简单且灵活的模型性能推断指标，带有理论洞察。GradSign背后的关键思想是一个量Ψ，用于分析不同网络的样本优化景观。理论上，我们表明在合理的假设下，Ψ是神经网络训练和真实总体损失的上界。然而，直接计算现代神经网络的Ψ在计算上是不可行的。为了解决这一挑战，我们设计了GradSign，一个使用网络在随机初始化状态下评估的梯度对Ψ进行准确且简单的近似。在三个训练数据集上的七个NAS基准测试评估表明，GradSign能够很好地泛化到现实世界的网络，并且在Spearman的ρ和Kendall的Tau评估下，始终优于最先进的基于梯度的MPI方法。此外，我们将GradSign集成到四个现有的NAS算法中，并显示GradSign辅助的NAS算法通过将最佳发现网络的准确度提高多达0.3%、1.1%和1.0%，在三个现实世界任务上优于其原始版本。",
        "领域": "神经架构搜索、深度学习优化、模型性能评估",
        "问题": "如何快速且准确地推断神经网络的预测性能，以发现高效且准确的网络架构",
        "动机": "现有的基于梯度的模型性能推断方法缺乏理论基础，且仅依赖于启发式指标，限制了其在神经架构搜索中的应用效果",
        "方法": "提出GradSign指标，通过分析网络的样本优化景观量Ψ，设计了一个基于网络初始化梯度的简单且准确的近似方法",
        "关键词": [
            "神经架构搜索",
            "模型性能推断",
            "梯度分析",
            "优化景观",
            "GradSign"
        ],
        "涉及的技术概念": {
            "模型性能推断（MPI）": "指在神经架构搜索中快速推断网络预测性能的任务，旨在发现高效且准确的网络架构",
            "梯度分析": "利用网络在初始化时的梯度信息来推断其性能，是GradSign方法的核心",
            "优化景观量Ψ": "用于分析不同网络的样本优化景观，理论上作为训练和真实总体损失的上界，是GradSign的理论基础"
        },
        "success": true
    },
    {
        "order": 400,
        "title": "GRAND++: Graph Neural Diffusion with A Source Term",
        "html": "https://iclr.cc//virtual/2022/poster/7172",
        "abstract": "We propose GRAph Neural Diffusion with a source term (GRAND++) for graph deep learning with a limited number of labeled nodes, i.e., low-labeling rate. GRAND++ is a class of continuous-depth graph deep learning architectures whose theoretical underpinning is the diffusion process on graphs with a source term. The source term guarantees two interesting theoretical properties of GRAND++: (i) the representation of graph nodes, under the dynamics of GRAND++, will not converge to a constant vector over all nodes even as the time goes to infinity, which mitigates the over-smoothing issue of graph neural networks and enables graph learning in very deep architectures. (ii) GRAND++ can provide accurate classification even when the model is trained with a very limited number of labeled training data. We experimentally verify the above two advantages on various graph deep learning benchmark tasks, showing a significant improvement over many existing graph neural networks.",
        "conference": "ICLR",
        "中文标题": "GRAND++：带有源项的图神经扩散",
        "摘要翻译": "我们提出了带有源项的图神经扩散（GRAND++），用于在标记节点数量有限（即低标记率）的情况下进行图深度学习。GRAND++是一类连续深度的图深度学习架构，其理论基础是带有源项的图上的扩散过程。源项保证了GRAND++的两个有趣的理论特性：（i）在GRAND++的动态下，图节点的表示即使时间趋于无穷大也不会收敛到所有节点上的常向量，这缓解了图神经网络的过度平滑问题，并使得在非常深的架构中进行图学习成为可能。（ii）即使模型使用非常有限的标记训练数据进行训练，GRAND++也能提供准确的分类。我们在各种图深度学习基准任务上实验验证了上述两个优势，显示出对许多现有图神经网络的显著改进。",
        "领域": "图神经网络、深度学习、半监督学习",
        "问题": "解决在标记节点数量有限的情况下进行图深度学习的问题",
        "动机": "缓解图神经网络的过度平滑问题，并实现在非常有限的标记数据下进行准确的分类",
        "方法": "提出带有源项的图神经扩散（GRAND++），利用扩散过程的理论基础，保证节点表示不收敛到常向量，从而缓解过度平滑问题",
        "关键词": [
            "图神经网络",
            "扩散过程",
            "半监督学习",
            "深度学习",
            "节点分类"
        ],
        "涉及的技术概念": {
            "源项": "在扩散过程中引入的项，保证节点表示不收敛到常向量，缓解过度平滑问题",
            "连续深度架构": "允许构建非常深的图神经网络架构，而不受过度平滑问题的限制",
            "低标记率": "指在训练过程中可用的标记数据非常有限，GRAND++能够在这种情况下仍保持高分类准确率"
        },
        "success": true
    },
    {
        "order": 401,
        "title": "Granger causal inference on DAGs identifies genomic loci regulating transcription",
        "html": "https://iclr.cc//virtual/2022/poster/6680",
        "abstract": "When a dynamical system can be modeled as a sequence of observations, Granger causality is a powerful approach for detecting predictive interactions between its variables. However, traditional Granger causal inference has limited utility in domains where the dynamics need to be represented as directed acyclic graphs (DAGs) rather than as a linear sequence, such as with cell differentiation trajectories. Here, we present GrID-Net, a framework based on graph neural networks with lagged message passing for Granger causal inference on DAG-structured systems. Our motivating application is the analysis of single-cell multimodal data to identify genomic loci that mediate the regulation of specific genes. To our knowledge, GrID-Net is the first single-cell analysis tool that accounts for the temporal lag between a genomic locus becoming accessible and its downstream effect on a target gene's expression. We applied GrID-Net on multimodal single-cell assays that profile chromatin accessibility (ATAC-seq) and gene expression (RNA-seq) in the same cell and show that it dramatically outperforms existing methods for inferring regulatory locus-gene links, achieving up to 71% greater agreement with independent population genetics-based estimates. By extending Granger causality to DAG-structured dynamical systems, our work unlocks new domains for causal analyses and, more specifically, opens a path towards elucidating gene regulatory interactions relevant to cellular differentiation and complex human diseases at unprecedented scale and resolution.",
        "conference": "ICLR",
        "中文标题": "基于有向无环图的格兰杰因果推断识别调控转录的基因组位点",
        "摘要翻译": "当一个动态系统可以被建模为一系列观测时，格兰杰因果性是检测其变量间预测性相互作用的有力方法。然而，在动态需要表示为有向无环图（DAGs）而非线性序列的领域，如细胞分化轨迹，传统的格兰杰因果推断的实用性有限。在此，我们提出了GrID-Net，一个基于图神经网络的框架，采用滞后消息传递进行DAG结构系统的格兰杰因果推断。我们的动机应用是分析单细胞多模态数据，以识别介导特定基因调控的基因组位点。据我们所知，GrID-Net是第一个考虑基因组位点变得可访问与其对目标基因表达的下游效应之间时间滞后的单细胞分析工具。我们将GrID-Net应用于在相同细胞中分析染色质可及性（ATAC-seq）和基因表达（RNA-seq）的多模态单细胞测定，结果显示其在推断调控位点-基因链接方面显著优于现有方法，与基于群体遗传学的独立估计的一致性提高了71%。通过将格兰杰因果性扩展到DAG结构的动态系统，我们的工作为因果分析开辟了新领域，更具体地说，为以前所未有的规模和分辨率阐明与细胞分化和复杂人类疾病相关的基因调控相互作用开辟了道路。",
        "领域": "基因组学数据分析、单细胞测序技术、基因调控网络",
        "问题": "在DAG结构动态系统中识别基因组位点与基因表达之间的调控关系",
        "动机": "开发一种能够处理DAG结构动态系统并考虑时间滞后效应的格兰杰因果推断方法，以更准确地识别基因调控关系",
        "方法": "基于图神经网络构建GrID-Net框架，采用滞后消息传递技术进行格兰杰因果推断",
        "关键词": [
            "格兰杰因果推断",
            "有向无环图",
            "单细胞多模态数据",
            "基因调控网络",
            "图神经网络"
        ],
        "涉及的技术概念": {
            "格兰杰因果推断": "用于检测变量间预测性相互作用的方法，本文扩展其应用于DAG结构系统",
            "有向无环图（DAGs）": "用于表示动态系统的结构，特别是在细胞分化轨迹等非线性序列领域",
            "图神经网络": "本文采用的核心技术，用于处理DAG结构数据并进行因果推断"
        },
        "success": true
    },
    {
        "order": 402,
        "title": "Graph-Augmented Normalizing Flows for Anomaly Detection of Multiple Time Series",
        "html": "https://iclr.cc//virtual/2022/poster/6770",
        "abstract": "Anomaly detection is a widely studied task for a broad variety of data types; among them, multiple time series appear frequently in applications, including for example, power grids and traffic networks. Detecting anomalies for multiple time series, however, is a challenging subject, owing to the intricate interdependencies among the constituent series. We hypothesize that anomalies occur in low density regions of a distribution and explore the use of normalizing flows for unsupervised anomaly detection, because of their superior quality in density estimation. Moreover, we propose a novel flow model by imposing a Bayesian network among constituent series. A Bayesian network is a directed acyclic graph (DAG) that models causal relationships; it factorizes the joint probability of the series into the product of easy-to-evaluate conditional probabilities. We call such a graph-augmented normalizing flow approach GANF and propose joint estimation of the DAG with flow parameters. We conduct extensive experiments on real-world datasets and demonstrate the effectiveness of GANF for density estimation, anomaly detection, and identification of time series distribution drift.",
        "conference": "ICLR",
        "中文标题": "图增强归一化流用于多时间序列异常检测",
        "摘要翻译": "异常检测是针对多种数据类型广泛研究的任务；其中，多时间序列在应用中频繁出现，例如电网和交通网络。然而，由于构成序列之间复杂的相互依赖关系，检测多时间序列的异常是一个具有挑战性的课题。我们假设异常发生在分布的低密度区域，并探索使用归一化流进行无监督异常检测，因为它们在密度估计方面具有优越的质量。此外，我们通过在各构成序列之间施加贝叶斯网络，提出了一种新颖的流模型。贝叶斯网络是一种有向无环图（DAG），用于建模因果关系；它将序列的联合概率分解为易于评估的条件概率的乘积。我们称这种图增强归一化流方法为GANF，并提出了DAG与流参数的联合估计。我们在真实世界的数据集上进行了广泛的实验，并证明了GANF在密度估计、异常检测和时间序列分布漂移识别方面的有效性。",
        "领域": "时间序列分析, 异常检测, 概率图模型",
        "问题": "解决多时间序列中由于复杂相互依赖关系导致的异常检测难题",
        "动机": "探索利用归一化流在密度估计上的优势，结合贝叶斯网络建模时间序列间的因果关系，以提高多时间序列异常检测的准确性和效率",
        "方法": "提出了一种图增强归一化流（GANF）方法，通过在各构成序列之间施加贝叶斯网络，将联合概率分解为条件概率的乘积，并进行DAG与流参数的联合估计",
        "关键词": [
            "归一化流",
            "贝叶斯网络",
            "异常检测",
            "时间序列分析",
            "密度估计"
        ],
        "涉及的技术概念": {
            "归一化流": "用于无监督异常检测，因其在密度估计方面的优越性能",
            "贝叶斯网络": "建模时间序列间的因果关系，将联合概率分解为条件概率的乘积",
            "有向无环图（DAG）": "用于表示贝叶斯网络中的因果关系，支持联合概率的分解和条件概率的评估"
        },
        "success": true
    },
    {
        "order": 403,
        "title": "Graph Auto-Encoder via Neighborhood Wasserstein Reconstruction",
        "html": "https://iclr.cc//virtual/2022/poster/6434",
        "abstract": "Graph neural networks (GNNs) have drawn significant research attention recently, mostly under the setting of semi-supervised learning. When task-agnostic representations are preferred or supervision is simply unavailable, the auto-encoder framework comes in handy with a natural graph reconstruction objective for unsupervised GNN training. However, existing graph auto-encoders are designed to reconstruct the direct links, so GNNs trained in this way are only optimized towards proximity-oriented graph mining tasks, and will fall short when the topological structures matter. In this work, we revisit the graph encoding process of GNNs which essentially learns to encode the neighborhood information of each node into an embedding vector, and propose a novel graph decoder to reconstruct the entire neighborhood information regarding both proximity and structure via Neighborhood Wasserstein Reconstruction (NWR). Specifically, from the GNN embedding of each node, NWR jointly predicts its node degree and neighbor feature distribution, where the distribution prediction adopts an optimal-transport loss based on the Wasserstein distance. Extensive experiments on both synthetic and real-world network datasets show that the unsupervised node representations learned with NWR have much more advantageous in structure-oriented graph mining tasks, while also achieving competitive performance in proximity-oriented ones.",
        "conference": "ICLR",
        "中文标题": "图自动编码器通过邻域Wasserstein重建",
        "摘要翻译": "图神经网络（GNNs）近年来吸引了大量的研究关注，主要是在半监督学习的设置下。当需要任务无关的表示或监督信息不可用时，自动编码器框架通过自然的图重建目标为无监督GNN训练提供了便利。然而，现有的图自动编码器设计用于重建直接链接，因此以这种方式训练的GNN仅针对面向邻近性的图挖掘任务进行了优化，当拓扑结构重要时将表现不佳。在这项工作中，我们重新审视了GNN的图编码过程，该过程本质上是学习将每个节点的邻域信息编码为一个嵌入向量，并提出了一种新颖的图解码器，通过邻域Wasserstein重建（NWR）重建关于邻近性和结构的整个邻域信息。具体来说，从每个节点的GNN嵌入中，NWR联合预测其节点度和邻居特征分布，其中分布预测采用了基于Wasserstein距离的最优传输损失。在合成和真实世界网络数据集上的大量实验表明，使用NWR学习的无监督节点表示在面向结构的图挖掘任务中具有更大的优势，同时在面向邻近性的任务中也实现了竞争性能。",
        "领域": "图神经网络、无监督学习、图挖掘",
        "问题": "现有的图自动编码器仅能重建直接链接，无法有效处理拓扑结构重要的图挖掘任务。",
        "动机": "为了提升图自动编码器在无监督学习中对图结构信息的捕捉能力，特别是在拓扑结构重要的任务中。",
        "方法": "提出了一种新颖的图解码器，通过邻域Wasserstein重建（NWR）方法，联合预测节点度和邻居特征分布，利用基于Wasserstein距离的最优传输损失来优化模型。",
        "关键词": [
            "图自动编码器",
            "Wasserstein距离",
            "无监督学习",
            "图神经网络",
            "图挖掘"
        ],
        "涉及的技术概念": {
            "邻域Wasserstein重建（NWR）": "一种新颖的图解码方法，通过预测节点度和邻居特征分布来重建邻域信息，利用Wasserstein距离作为损失函数。",
            "最优传输损失": "基于Wasserstein距离的损失函数，用于优化邻居特征分布的预测，确保模型能够有效捕捉图的结构信息。",
            "图自动编码器": "一种无监督学习框架，通过编码和解码过程学习图的表示，特别适用于任务无关的图表示学习。"
        },
        "success": true
    },
    {
        "order": 404,
        "title": "Graph-based Nearest Neighbor Search in Hyperbolic Spaces",
        "html": "https://iclr.cc//virtual/2022/poster/6589",
        "abstract": "The nearest neighbor search (NNS) problem is widely studied in Euclidean space, and graph-based algorithms are known to outperform other approaches for this task. However, hyperbolic geometry often allows for better data representation in various domains, including graphs, words, and images. In this paper, we show that graph-based approaches are also well suited for hyperbolic geometry. From a theoretical perspective, we rigorously analyze the time and space complexity of graph-based NNS, assuming that an $n$-element dataset is uniformly distributed within a $d$-dimensional ball of radius $R$ in the hyperbolic space of curvature $-1$. Under some conditions on $R$ and $d$, we derive the time and space complexity of graph-based NNS and compare the obtained results with known guarantees for the Euclidean case. Interestingly, in the dense setting ($d \\ll \\log n$) and under some assumptions on the radius $R$, graph-based NNS has lower time complexity in the hyperbolic space. This agrees with our experiments: we consider datasets embedded in hyperbolic and Euclidean spaces and show that graph-based NNS can be more efficient in the hyperbolic space. We also demonstrate that graph-based methods outperform other existing baselines for hyperbolic NNS. Overall, our theoretical and empirical analysis suggests that graph-based NNS can be considered a default approach for similarity search in hyperbolic spaces.",
        "conference": "ICLR",
        "中文标题": "双曲空间中基于图的最近邻搜索",
        "摘要翻译": "最近邻搜索（NNS）问题在欧几里得空间中被广泛研究，基于图的算法在这一任务中表现优于其他方法。然而，双曲几何在图、词和图像等多种领域中往往能提供更好的数据表示。本文中，我们展示了基于图的方法同样适用于双曲几何。从理论角度出发，我们严格分析了基于图的NNS的时间和空间复杂度，假设一个包含n个元素的数据集均匀分布在曲率为-1的双曲空间中半径为R的d维球内。在R和d的某些条件下，我们推导出基于图的NNS的时间和空间复杂度，并将所得结果与欧几里得情况下的已知保证进行比较。有趣的是，在密集设置（d远小于log n）及对半径R的某些假设下，基于图的NNS在双曲空间中具有更低的时间复杂度。这与我们的实验相符：我们考虑了嵌入双曲和欧几里得空间的数据集，并展示了基于图的NNS在双曲空间中可能更高效。我们还证明了基于图的方法在双曲NNS中优于其他现有基线。总体而言，我们的理论和实证分析表明，基于图的NNS可以被视为双曲空间中相似性搜索的默认方法。",
        "领域": "图嵌入、双曲几何、相似性搜索",
        "问题": "解决在双曲空间中高效进行最近邻搜索的问题",
        "动机": "探索基于图的算法在双曲几何中的适用性和效率，以提供比欧几里得空间更优的数据表示和搜索性能",
        "方法": "通过理论分析和实验验证，研究基于图的最近邻搜索在双曲空间中的时间和空间复杂度，并与欧几里得空间中的性能进行比较",
        "关键词": [
            "双曲几何",
            "最近邻搜索",
            "图算法",
            "相似性搜索",
            "复杂度分析"
        ],
        "涉及的技术概念": {
            "双曲几何": "用于提供比欧几里得空间更优的数据表示，特别是在图、词和图像等领域",
            "基于图的最近邻搜索": "在双曲空间中应用图算法进行高效相似性搜索的方法",
            "时间和空间复杂度分析": "评估基于图的NNS在双曲空间中的性能，并与欧几里得空间中的情况进行比较"
        },
        "success": true
    },
    {
        "order": 405,
        "title": "Graph Condensation for Graph Neural Networks",
        "html": "https://iclr.cc//virtual/2022/poster/6573",
        "abstract": "Given the prevalence of large-scale graphs in real-world applications, the storage and time for training neural models have raised increasing concerns. To alleviate the concerns, we propose and study the problem of graph condensation for graph neural networks (GNNs).  Specifically, we aim to condense the large, original graph into a small, synthetic and highly-informative graph, such that GNNs trained on the small graph and large graph have comparable performance. We approach the condensation problem by imitating the GNN training trajectory  on the original graph through the optimization of a gradient matching loss and design a strategy to condense node futures and structural information simultaneously. Extensive experiments have demonstrated the effectiveness of the proposed framework in condensing different graph datasets into informative smaller graphs. In particular, we are able to approximate the original test accuracy by 95.3\\% on Reddit, 99.8\\% on Flickr and 99.0\\% on Citeseer,  while reducing their graph size by more than 99.9\\%, and the condensed graphs can be used to train various GNN architectures. ",
        "conference": "ICLR",
        "中文标题": "图神经网络的图压缩",
        "摘要翻译": "鉴于大规模图在现实世界应用中的普遍性，训练神经模型的存储和时间问题日益引起关注。为了缓解这些问题，我们提出并研究了图神经网络（GNNs）的图压缩问题。具体来说，我们的目标是将大型原始图压缩成一个小的、合成的且信息量大的图，使得在小图上和大图上训练的GNNs具有可比的性能。我们通过优化梯度匹配损失来模仿原始图上的GNN训练轨迹，并设计了一种同时压缩节点特征和结构信息的策略。大量实验证明了所提出框架在将不同图数据集压缩成信息量大的小图方面的有效性。特别是，我们能够在Reddit上达到原始测试准确率的95.3%，在Flickr上达到99.8%，在Citeseer上达到99.0%，同时将图的大小减少了99.9%以上，并且压缩后的图可用于训练各种GNN架构。",
        "领域": "图神经网络优化、图数据压缩、深度学习效率提升",
        "问题": "如何减少大规模图数据训练图神经网络时的存储和时间消耗",
        "动机": "解决大规模图数据训练图神经网络时的高存储和时间成本问题",
        "方法": "通过优化梯度匹配损失模仿原始图上的GNN训练轨迹，同时压缩节点特征和结构信息",
        "关键词": [
            "图压缩",
            "梯度匹配",
            "节点特征压缩",
            "结构信息压缩",
            "GNN训练效率"
        ],
        "涉及的技术概念": {
            "图压缩": "将大型原始图压缩成小的、合成的且信息量大的图，以减少存储和时间消耗",
            "梯度匹配损失": "用于模仿原始图上的GNN训练轨迹，优化压缩过程",
            "节点特征和结构信息压缩": "同时压缩图中的节点特征和结构信息，保持图的信息量和训练效果"
        },
        "success": true
    },
    {
        "order": 406,
        "title": "Graph-Enhanced Exploration for Goal-oriented Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2022/poster/5917",
        "abstract": "Goal-oriented Reinforcement Learning (GoRL) is a promising approach for scaling up RL techniques on sparse reward environments requiring long horizon planning. Recent works attempt to build suitable abstraction graph of the environment and enhance GoRL with classical graphical methods such as shortest path searching; however, these approaches mainly focus on either graph construction or agent exploitation, but leave the exploration lack of study. This paper proposes Graph-enhanced GoRL (G2RL), a new GoRL framework for effective exploration and efficient training based on the state-transition graph. We first introduce the optimal goals for exploration on the graph and then use them as supervised signals to train the goal generator in G2RL in a hindsight manner. Furthermore, we define relevant trajectories of a state based on its graph neighborhood and show that giving high priority to these trajectories would lead to an efficient policy learning. In addition to the theoretical results regarding optimal goal generation, our empirical results on standard discrete and continuous control benchmarks show that leveraging the state-transition graph is beneficial for GoRL to learn an effective and informative exploration strategy and outperform the state-of-the-art methods.",
        "conference": "ICLR",
        "中文标题": "面向目标强化学习的图增强探索",
        "摘要翻译": "面向目标的强化学习（GoRL）是一种在需要长期规划的稀疏奖励环境中扩展强化学习技术的有前途的方法。最近的工作尝试构建环境的合适抽象图，并通过经典的图形方法（如最短路径搜索）增强GoRL；然而，这些方法主要集中于图构建或智能体利用，而忽视了探索的研究。本文提出了图增强的GoRL（G2RL），一个新的GoRL框架，基于状态转移图进行有效探索和高效训练。我们首先介绍了图上探索的最优目标，然后以后见之明的方式使用它们作为监督信号来训练G2RL中的目标生成器。此外，我们基于状态的图邻域定义了相关轨迹，并表明给予这些轨迹高优先级将导致高效的策略学习。除了关于最优目标生成的理论结果外，我们在标准离散和连续控制基准上的实证结果表明，利用状态转移图有助于GoRL学习一种有效且信息丰富的探索策略，并超越最先进的方法。",
        "领域": "强化学习、图神经网络、自动控制",
        "问题": "如何在稀疏奖励环境中进行有效的长期规划探索",
        "动机": "解决现有面向目标强化学习方法在图构建和智能体利用方面的不足，特别是在探索策略上的研究空白",
        "方法": "提出基于状态转移图的图增强GoRL框架（G2RL），引入最优目标作为探索指导，并利用图邻域定义相关轨迹以优化策略学习",
        "关键词": [
            "面向目标强化学习",
            "图增强探索",
            "状态转移图",
            "最优目标生成",
            "策略学习"
        ],
        "涉及的技术概念": {
            "状态转移图": "用于表示环境中状态之间转移关系的图结构，是G2RL框架中探索和训练的基础",
            "最优目标生成": "在状态转移图上确定最优探索目标，作为训练目标生成器的监督信号",
            "相关轨迹优先级": "基于状态的图邻域定义的轨迹，通过提高这些轨迹的优先级来加速和优化策略学习过程"
        },
        "success": true
    },
    {
        "order": 407,
        "title": "GraphENS: Neighbor-Aware Ego Network Synthesis for Class-Imbalanced Node Classification",
        "html": "https://iclr.cc//virtual/2022/poster/5932",
        "abstract": "In many real-world node classification scenarios, nodes are highly class-imbalanced, where graph neural networks (GNNs) can be readily biased to major class instances. Albeit existing class imbalance approaches in other domains can alleviate this issue to some extent, they do not consider the impact of message passing between nodes. In this paper, we hypothesize that overfitting to the neighbor sets of minor class due to message passing is a major challenge for class-imbalanced node classification. To tackle this issue, we propose GraphENS, a novel augmentation method that synthesizes the whole ego network for minor class (minor node and its one-hop neighbors) by combining two different ego networks based on their similarity. Additionally, we introduce a saliency-based node mixing method to exploit the abundant class-generic attributes of other nodes while blocking the injection of class-specific features. Our approach consistently outperforms the baselines over multiple node classification benchmark datasets and architectures.",
        "conference": "ICLR",
        "中文标题": "GraphENS：面向类别不平衡节点分类的邻居感知自我网络合成",
        "摘要翻译": "在许多现实世界的节点分类场景中，节点存在高度的类别不平衡问题，图神经网络（GNNs）容易偏向于主要类别的实例。尽管其他领域现有的类别不平衡方法可以在一定程度上缓解这一问题，但它们没有考虑节点间消息传递的影响。在本文中，我们假设由于消息传递导致的对于次要类别邻居集合的过拟合是类别不平衡节点分类的一个主要挑战。为了解决这个问题，我们提出了GraphENS，一种新颖的增强方法，它通过基于相似性结合两个不同的自我网络来合成次要类别（次要节点及其一跳邻居）的整个自我网络。此外，我们引入了一种基于显著性的节点混合方法，以利用其他节点丰富的类别通用属性，同时阻止类别特定特征的注入。我们的方法在多个节点分类基准数据集和架构上始终优于基线方法。",
        "领域": "图神经网络、类别不平衡学习、节点分类",
        "问题": "解决图神经网络在类别不平衡节点分类中对主要类别实例的偏见问题",
        "动机": "研究图神经网络在类别不平衡节点分类中由于消息传递导致的对于次要类别邻居集合的过拟合问题",
        "方法": "提出GraphENS方法，通过合成次要类别的自我网络和基于显著性的节点混合方法，增强次要类别的表示",
        "关键词": [
            "图神经网络",
            "类别不平衡",
            "节点分类",
            "自我网络合成",
            "显著性混合"
        ],
        "涉及的技术概念": {
            "自我网络合成": "通过结合两个不同的自我网络来合成次要类别的整个自我网络，以增强次要类别的表示",
            "基于显著性的节点混合": "利用其他节点丰富的类别通用属性，同时阻止类别特定特征的注入，以优化次要类别的表示",
            "消息传递": "图神经网络中节点间信息交换的机制，本文中探讨其对类别不平衡节点分类的影响"
        },
        "success": true
    },
    {
        "order": 408,
        "title": "Graph-Guided Network for Irregularly Sampled Multivariate Time Series",
        "html": "https://iclr.cc//virtual/2022/poster/6409",
        "abstract": "In many domains, including healthcare, biology, and climate science, time series are irregularly sampled with varying time intervals between successive readouts and different subsets of variables (sensors) observed at different time points. Here, we introduce RAINDROP, a graph neural network that embeds irregularly sampled and multivariate time series while also learning the dynamics of sensors purely from observational data. RAINDROP represents every sample as a separate sensor graph and models time-varying dependencies between sensors with a novel message passing operator. It estimates the latent sensor graph structure and leverages the structure together with nearby observations to predict misaligned readouts. This model can be interpreted as a graph neural network that sends messages over graphs that are optimized for capturing time-varying dependencies among sensors. We use RAINDROP to classify time series and interpret temporal dynamics on three healthcare and human activity datasets. RAINDROP outperforms state-of-the-art methods by up to 11.4% (absolute F1-score points), including techniques that deal with irregular sampling using fixed discretization and set functions. RAINDROP shows superiority in diverse setups, including challenging leave-sensor-out settings. ",
        "conference": "ICLR",
        "中文标题": "图引导网络用于不规则采样多元时间序列",
        "摘要翻译": "在许多领域，包括医疗保健、生物学和气候科学中，时间序列是不规则采样的，连续读数之间的时间间隔不等，且在不同时间点观察到的变量（传感器）子集也不同。本文介绍了RAINDROP，一种图神经网络，它能够嵌入不规则采样和多元时间序列，同时仅从观测数据中学习传感器的动态。RAINDROP将每个样本表示为单独的传感器图，并通过一种新颖的消息传递操作符模拟传感器之间的时变依赖关系。它估计潜在的传感器图结构，并利用该结构与附近的观测值来预测未对齐的读数。该模型可以解释为一种在图神经网络上发送消息的模型，这些图被优化以捕捉传感器之间的时变依赖关系。我们使用RAINDROP对三个医疗保健和人类活动数据集中的时间序列进行分类并解释时间动态。RAINDROP在包括使用固定离散化和集合函数处理不规则采样的技术在内的多种设置中，比最先进的方法表现优越，最高可提升11.4%（绝对F1分数点）。RAINDROP在多样化的设置中显示出优越性，包括具有挑战性的留出传感器设置。",
        "领域": "时间序列分析、图神经网络、医疗健康数据分析",
        "问题": "处理不规则采样和多元时间序列的嵌入与传感器动态学习问题",
        "动机": "解决不规则采样时间序列在医疗保健等领域的应用挑战，提高时间序列分类和动态解释的准确性",
        "方法": "提出RAINDROP图神经网络，通过构建传感器图和消息传递操作符模拟时变依赖关系，预测未对齐读数",
        "关键词": [
            "图神经网络",
            "不规则采样时间序列",
            "传感器动态学习",
            "医疗健康数据分析",
            "消息传递操作符"
        ],
        "涉及的技术概念": {
            "图神经网络": "用于嵌入不规则采样和多元时间序列，学习传感器动态",
            "消息传递操作符": "模拟传感器之间的时变依赖关系，优化图结构以捕捉动态变化",
            "传感器图结构": "表示样本和传感器间的关系，用于预测未对齐读数和理解时间动态"
        },
        "success": true
    },
    {
        "order": 409,
        "title": "Graph-less Neural Networks: Teaching Old MLPs New Tricks Via Distillation",
        "html": "https://iclr.cc//virtual/2022/poster/6711",
        "abstract": "Graph Neural Networks (GNNs) are popular for graph machine learning and have shown great results on wide node classification tasks. Yet, they are less popular for practical deployments in the industry owing to their scalability challenges incurred by data dependency. Namely, GNN inference depends on neighbor nodes multiple hops away from the target, and fetching them burdens latency-constrained applications. Existing inference acceleration methods like pruning and quantization can speed up GNNs by reducing Multiplication-and-ACcumulation (MAC) operations, but the improvements are limited given the data dependency is not resolved. Conversely, multi-layer perceptrons (MLPs) have no graph dependency and infer much faster than GNNs, even though they are less accurate than GNNs for node classification in general. Motivated by these complementary strengths and weaknesses, we bring GNNs and MLPs together via knowledge distillation (KD). Our work shows that the performance of MLPs can be improved by large margins with GNN KD. We call the distilled MLPs Graph-less Neural Networks (GLNNs) as they have no inference graph dependency. We show that GLNNs with competitive accuracy infer faster than GNNs by 146X-273X and faster than other acceleration methods by 14X-27X. Under a production setting involving both transductive and inductive predictions across 7 datasets, GLNN accuracies improve over stand-alone MLPs by 12.36% on average and match GNNs on 6/7 datasets. Comprehensive analysis shows when and why GLNNs can achieve competitive accuracies to GNNs and suggests GLNN as a handy choice for latency-constrained applications. ",
        "conference": "ICLR",
        "中文标题": "无图神经网络：通过蒸馏让老式多层感知器学会新技巧",
        "摘要翻译": "图神经网络（GNNs）在图机器学习中非常流行，并在广泛的节点分类任务上显示出优异的结果。然而，由于数据依赖性带来的可扩展性挑战，它们在工业中的实际部署并不那么受欢迎。也就是说，GNN的推理依赖于距离目标多跳远的邻居节点，获取这些节点会给延迟受限的应用带来负担。现有的推理加速方法，如剪枝和量化，可以通过减少乘积累加（MAC）操作来加速GNNs，但由于数据依赖性未解决，改进有限。相反，多层感知器（MLPs）没有图依赖性，推理速度比GNNs快得多，尽管在节点分类上通常不如GNNs准确。受到这些互补优势和劣势的启发，我们通过知识蒸馏（KD）将GNNs和MLPs结合起来。我们的工作表明，通过GNN KD，MLPs的性能可以大幅提高。我们将蒸馏后的MLPs称为无图神经网络（GLNNs），因为它们没有推理图依赖性。我们展示，具有竞争力的准确性的GLNNs比GNNs推理快146X-273X，比其他加速方法快14X-27X。在一个涉及7个数据集的转导和归纳预测的生产设置下，GLNNs的准确性比独立MLPs平均提高了12.36%，并在6/7的数据集上与GNNs匹配。全面的分析显示了GLNNs何时以及为何能够达到与GNNs竞争的准确性，并建议将GLNN作为延迟受限应用的便捷选择。",
        "领域": "图神经网络、知识蒸馏、节点分类",
        "问题": "解决图神经网络（GNNs）在实际部署中因数据依赖性导致的可扩展性挑战和推理延迟问题。",
        "动机": "结合图神经网络（GNNs）和多层感知器（MLPs）的互补优势，通过知识蒸馏（KD）提高MLPs的性能，同时保持其推理速度的优势。",
        "方法": "通过知识蒸馏（KD）将GNNs的知识转移到MLPs中，创建无图依赖性的无图神经网络（GLNNs），以提高推理速度和准确性。",
        "关键词": [
            "无图神经网络",
            "知识蒸馏",
            "节点分类",
            "推理加速",
            "多层感知器"
        ],
        "涉及的技术概念": {
            "知识蒸馏（KD）": "用于将GNNs的知识转移到MLPs中，以提高后者的性能而不增加图依赖性。",
            "无图神经网络（GLNNs）": "通过知识蒸馏从GNNs中学习得到的MLPs，具有无图依赖性的特点，适用于延迟受限的应用。",
            "乘积累加（MAC）操作": "在神经网络推理中常见的计算操作，减少这些操作可以加速推理过程。"
        },
        "success": true
    },
    {
        "order": 410,
        "title": "Graph Neural Network Guided Local Search for the Traveling Salesperson Problem",
        "html": "https://iclr.cc//virtual/2022/poster/6596",
        "abstract": "Solutions to the Traveling Salesperson Problem (TSP) have practical applications to processes in transportation, logistics, and automation, yet must be computed with minimal delay to satisfy the real-time nature of the underlying tasks. However, solving large TSP instances quickly without sacrificing solution quality remains challenging for current approximate algorithms. To close this gap, we present a hybrid data-driven approach for solving the TSP based on Graph Neural Networks (GNNs) and Guided Local Search (GLS). Our model predicts the regret of including each edge of the problem graph in the solution; GLS uses these predictions in conjunction with the original problem graph to find solutions. Our experiments demonstrate that this approach converges to optimal solutions at a faster rate than three recent learning based approaches for the TSP. Notably, we reduce the mean optimality gap on the 100-node problem set from 1.534% to 0.705%, a 2x improvement. When generalizing from 20-node instances to the 100-node problem set, we reduce the optimality gap from 18.845% to 2.622%, a 7x improvement.",
        "conference": "ICLR",
        "中文标题": "图神经网络引导的旅行商问题局部搜索",
        "摘要翻译": "旅行商问题（TSP）的解决方案在交通、物流和自动化过程中具有实际应用，但为了满足底层任务的实时性，必须最小化延迟进行计算。然而，对于当前的近似算法来说，快速解决大型TSP实例而不牺牲解的质量仍然是一个挑战。为了缩小这一差距，我们提出了一种基于图神经网络（GNNs）和引导局部搜索（GLS）的混合数据驱动方法来解决TSP。我们的模型预测了在解中包含问题图的每条边的后悔值；GLS利用这些预测与原始问题图一起寻找解。我们的实验表明，与最近三种基于学习的TSP方法相比，这种方法以更快的速度收敛到最优解。值得注意的是，我们将100节点问题集的平均最优性差距从1.534%降低到0.705%，提高了2倍。当从20节点实例推广到100节点问题集时，我们将最优性差距从18.845%降低到2.622%，提高了7倍。",
        "领域": "组合优化、图神经网络、路径规划",
        "问题": "如何在保证解质量的前提下，快速解决大型旅行商问题实例。",
        "动机": "解决当前近似算法在快速解决大型TSP实例时无法同时保证解质量的挑战。",
        "方法": "结合图神经网络和引导局部搜索的混合数据驱动方法，预测边的后悔值并用于寻找解。",
        "关键词": [
            "旅行商问题",
            "图神经网络",
            "引导局部搜索",
            "组合优化",
            "路径规划"
        ],
        "涉及的技术概念": {
            "图神经网络": "用于预测问题图中每条边在解中的后悔值，为引导局部搜索提供指导。",
            "引导局部搜索": "利用图神经网络的预测结果和原始问题图，高效寻找高质量的解。",
            "后悔值": "衡量在解中包含某条边的潜在损失，是图神经网络预测的核心目标。"
        },
        "success": true
    },
    {
        "order": 411,
        "title": "Graph Neural Networks with Learnable Structural and Positional Representations",
        "html": "https://iclr.cc//virtual/2022/poster/6463",
        "abstract": "Graph neural networks (GNNs) have become the standard learning architectures for graphs. GNNs have been applied to numerous domains ranging from quantum chemistry, recommender systems to knowledge graphs and natural language processing. A major issue with arbitrary graphs is the absence of canonical positional information of nodes, which decreases the representation power of GNNs to distinguish e.g. isomorphic nodes and other graph symmetries. An approach to tackle this issue is to introduce Positional Encoding (PE) of nodes, and inject it into the input layer, like in Transformers. Possible graph PE are Laplacian eigenvectors. In this work, we propose to decouple structural and positional representations to make easy for the network to learn these two essential properties. We introduce a novel generic architecture which we call \\texttt{LSPE} (Learnable Structural and Positional Encodings). We investigate several sparse and fully-connected (Transformer-like) GNNs, and observe a performance increase for molecular datasets, from $1.79\\%$ up to $64.14\\%$ when considering learnable PE for both GNN classes.",
        "conference": "ICLR",
        "中文标题": "具有可学习结构和位置表示的图神经网络",
        "摘要翻译": "图神经网络（GNNs）已成为图的标准学习架构。GNNs已被应用于从量子化学、推荐系统到知识图谱和自然语言处理等众多领域。任意图的一个主要问题是缺乏节点的规范位置信息，这降低了GNNs区分例如同构节点和其他图对称性的表示能力。解决这个问题的一种方法是引入节点的位置编码（PE），并将其注入输入层，就像在Transformers中那样。可能的图PE是拉普拉斯特征向量。在这项工作中，我们提出将结构和位置表示解耦，以便网络更容易学习这两个基本属性。我们引入了一种新颖的通用架构，我们称之为\texttt{LSPE}（可学习的结构和位置编码）。我们研究了几种稀疏和全连接（类似Transformer的）GNNs，并观察到在考虑可学习PE时，分子数据集的性能提高了从1.79%到64.14%。",
        "领域": "图神经网络、分子图分析、知识图谱",
        "问题": "解决图神经网络中节点缺乏规范位置信息导致的表示能力不足问题",
        "动机": "提升图神经网络在区分同构节点和其他图对称性方面的表示能力",
        "方法": "提出一种将结构和位置表示解耦的新架构LSPE，并研究其在稀疏和全连接GNNs中的应用",
        "关键词": [
            "图神经网络",
            "位置编码",
            "分子数据集",
            "结构和位置表示解耦",
            "LSPE"
        ],
        "涉及的技术概念": {
            "位置编码（PE）": "用于为图中的节点提供位置信息，增强GNNs的表示能力",
            "结构和位置表示解耦": "使网络能够更容易地学习图的结构和位置属性",
            "LSPE架构": "一种新颖的通用架构，旨在通过可学习的结构和位置编码提升GNNs的性能"
        },
        "success": true
    },
    {
        "order": 412,
        "title": "Graphon based Clustering and Testing of Networks: Algorithms and Theory",
        "html": "https://iclr.cc//virtual/2022/poster/6208",
        "abstract": "Network-valued data are encountered in a wide range of applications, and pose challenges in learning due to their complex structure and absence of vertex correspondence. Typical examples of such problems include classification or grouping of protein structures and social networks. Various methods, ranging from graph kernels to graph neural networks, have been proposed that achieve some success in graph classification problems. However, most methods have limited theoretical justification, and their applicability beyond classification remains unexplored. In this work, we propose methods for clustering multiple graphs, without vertex correspondence, that are inspired by the recent literature on estimating graphons---symmetric functions corresponding to infinite vertex limit of graphs. We propose a novel graph distance based on sorting-and-smoothing graphon estimators. Using the proposed graph distance, we present two clustering algorithms and show that they achieve state-of-the-art results. We prove the statistical consistency of both algorithms under Lipschitz assumptions on the graph degrees. We further study the applicability of the proposed distance for graph two-sample testing problems.",
        "conference": "ICLR",
        "中文标题": "基于图元的网络聚类与测试：算法与理论",
        "摘要翻译": "网络值数据在广泛的应用中遇到，由于其复杂的结构和顶点对应的缺失，在学习中提出了挑战。这类问题的典型例子包括蛋白质结构和社会网络的分类或分组。从图核到图神经网络的各种方法已经被提出，在图分类问题中取得了一定的成功。然而，大多数方法的理论依据有限，且它们在分类之外的适用性仍未探索。在这项工作中，我们提出了用于聚类多个图的方法，无需顶点对应，这些方法受到最近关于估计图元——图的无限顶点极限对应的对称函数——的文献的启发。我们提出了一种基于排序和平滑图元估计器的新图距离。使用提出的图距离，我们展示了两种聚类算法，并显示它们达到了最先进的结果。我们在图度的Lipschitz假设下证明了这两种算法的统计一致性。我们进一步研究了提出的距离在图两样本测试问题中的适用性。",
        "领域": "图神经网络、网络数据分析、图分类",
        "问题": "解决在网络值数据中由于复杂结构和顶点对应缺失导致的聚类和测试问题",
        "动机": "探索无需顶点对应的图聚类方法，并验证其在图两样本测试中的适用性",
        "方法": "提出基于排序和平滑图元估计器的新图距离，并开发两种聚类算法",
        "关键词": [
            "图元估计",
            "图距离",
            "聚类算法",
            "图两样本测试",
            "统计一致性"
        ],
        "涉及的技术概念": {
            "图元": "对称函数，对应于图的无限顶点极限，用于估计和理解图的结构",
            "图距离": "基于排序和平滑图元估计器的新距离度量，用于比较不同图之间的相似性",
            "Lipschitz假设": "在图度的连续性假设下，保证聚类算法统计一致性的条件"
        },
        "success": true
    },
    {
        "order": 413,
        "title": "Graph-Relational Domain Adaptation",
        "html": "https://iclr.cc//virtual/2022/poster/7145",
        "abstract": "Existing domain adaptation methods tend to treat every domain equally and align them all perfectly. Such uniform alignment ignores topological structures among different domains; therefore it may be beneficial for nearby domains, but not necessarily for distant domains. In this work, we relax such uniform alignment by using a domain graph to encode domain adjacency, e.g., a graph of states in the US with each state as a domain and each edge indicating adjacency, thereby allowing domains to align flexibly based on the graph structure. We generalize the existing adversarial learning framework with a novel graph discriminator using encoding-conditioned graph embeddings. Theoretical analysis shows that at equilibrium, our method recovers classic domain adaptation when the graph is a clique, and achieves non-trivial alignment for other types of graphs. Empirical results show that our approach successfully generalizes uniform alignment, naturally incorporates domain information represented by graphs, and improves upon existing domain adaptation methods on both synthetic and real-world datasets.",
        "conference": "ICLR",
        "中文标题": "图关系域适应",
        "摘要翻译": "现有的域适应方法倾向于平等对待每个域并完美地对齐它们。这种统一的对齐忽略了不同域之间的拓扑结构；因此，它可能对附近的域有益，但不一定对遥远的域有益。在这项工作中，我们通过使用域图来编码域邻接性来放松这种统一的对齐，例如，美国各州的图，每个州作为一个域，每条边表示邻接，从而允许域基于图结构灵活地对齐。我们通过使用编码条件图嵌入的新颖图鉴别器来概括现有的对抗学习框架。理论分析表明，在平衡状态下，当图是一个团时，我们的方法恢复了经典的域适应，并对其他类型的图实现了非平凡的对齐。实证结果表明，我们的方法成功地概括了统一对齐，自然地包含了由图表表示的域信息，并在合成和真实世界数据集上改进了现有的域适应方法。",
        "领域": "域适应、图神经网络、对抗学习",
        "问题": "现有域适应方法在处理不同域之间的拓扑结构时表现不佳，特别是对于距离较远的域。",
        "动机": "通过引入域图来编码域之间的邻接关系，以实现更灵活的域对齐，从而提高域适应方法的性能。",
        "方法": "提出了一种新颖的图鉴别器，利用编码条件图嵌入来扩展现有的对抗学习框架，允许基于图结构的灵活域对齐。",
        "关键词": [
            "图关系域适应",
            "对抗学习",
            "图神经网络",
            "域图",
            "编码条件图嵌入"
        ],
        "涉及的技术概念": {
            "域图": "用于编码不同域之间的邻接关系，允许基于图结构的灵活域对齐。",
            "图鉴别器": "一种新颖的鉴别器，利用编码条件图嵌入来扩展对抗学习框架，用于实现基于图结构的域对齐。",
            "编码条件图嵌入": "在图鉴别器中使用的技术，用于生成基于图结构的域嵌入，从而实现灵活的域对齐。"
        },
        "success": true
    },
    {
        "order": 414,
        "title": "GreaseLM: Graph REASoning Enhanced Language Models",
        "html": "https://iclr.cc//virtual/2022/poster/5938",
        "abstract": "Answering complex questions about textual narratives requires reasoning over both stated context and the world knowledge that underlies it. However, pretrained language models (LM), the foundation of most modern QA systems, do not robustly represent latent relationships between concepts, which is necessary for reasoning. While knowledge graphs (KG) are often used to augment LMs with structured representations of world knowledge, it remains an open question how to effectively fuse and reason over the KG representations and the language context, which provides situational constraints and nuances. In this work, we propose GreaseLM, a new model that fuses encoded representations from pretrained LMs and graph neural networks over multiple layers of modality interaction operations. Information from both modalities propagates to the other, allowing language context representations to be grounded by structured world knowledge, and allowing linguistic nuances (e.g., negation, hedging) in the context to inform the graph representations of knowledge. Our results on three benchmarks in the commonsense reasoning (i.e., CommonsenseQA, OpenbookQA) and medical question answering (i.e., MedQA-USMLE) domains demonstrate that GreaseLM can more reliably answer questions that require reasoning over both situational constraints and structured knowledge, even outperforming models 8x larger.",
        "conference": "ICLR",
        "中文标题": "GreaseLM：图推理增强的语言模型",
        "摘要翻译": "回答关于文本叙述的复杂问题需要对所述上下文及其背后的世界知识进行推理。然而，作为大多数现代问答系统基础的预训练语言模型（LM）并不能稳健地表示概念之间的潜在关系，这是推理所必需的。虽然知识图谱（KG）常被用来通过世界知识的结构化表示来增强语言模型，但如何有效地融合并推理知识图谱表示和提供情境约束及细微差别的语言上下文，仍是一个未解决的问题。在这项工作中，我们提出了GreaseLM，一个新模型，它通过多层模态交互操作融合了来自预训练语言模型和图神经网络的编码表示。来自两种模态的信息相互传播，使得语言上下文表示能够基于结构化的世界知识，同时允许上下文中的语言细微差别（如否定、模糊表达）通知知识的图表示。我们在常识推理（即CommonsenseQA、OpenbookQA）和医学问答（即MedQA-USMLE）领域的三个基准测试中的结果表明，GreaseLM能够更可靠地回答需要同时推理情境约束和结构化知识的问题，甚至表现优于规模大8倍的模型。",
        "领域": "常识推理、医学问答、知识图谱与语言模型融合",
        "问题": "如何有效地融合并推理知识图谱表示和语言上下文，以回答需要复杂推理的问题",
        "动机": "预训练语言模型在表示概念间潜在关系方面存在不足，而知识图谱可以提供结构化知识，但如何有效结合两者以提升问答系统的推理能力是一个挑战",
        "方法": "提出GreaseLM模型，通过多层模态交互操作融合预训练语言模型和图神经网络的编码表示，实现语言上下文和结构化知识的双向信息传播",
        "关键词": [
            "图推理",
            "语言模型",
            "知识图谱",
            "模态交互",
            "问答系统"
        ],
        "涉及的技术概念": {
            "图神经网络": "用于处理知识图谱中的结构化信息，增强模型对概念间关系的理解和推理能力",
            "模态交互操作": "实现语言模型和图神经网络之间的信息交换和融合，使得两种模态的信息能够相互补充和增强",
            "结构化世界知识": "通过知识图谱提供的结构化表示，为语言模型提供外部知识支持，增强模型的推理能力"
        },
        "success": true
    },
    {
        "order": 415,
        "title": "Group-based Interleaved Pipeline Parallelism for Large-scale DNN Training",
        "html": "https://iclr.cc//virtual/2022/poster/5959",
        "abstract": "The recent trend of using large-scale deep neural networks (DNN) to boost performance has propelled the development of the parallel pipelining technique for efficient DNN training, which has resulted in the development of several prominent pipelines such as GPipe, PipeDream, and PipeDream-2BW. However, the current leading pipeline PipeDream-2BW still suffers from two major drawbacks, i.e., the excessive memory redundancy and the delayed weight updates across all stages. In this work, we propose a novel pipeline named WPipe, which achieves better memory efficiency and fresher weight updates. WPipe uses a novel pipelining scheme that divides model partitions into two groups. It moves the forward pass of the next period of weight updates to the front of the backward pass of the current period of weight updates in the first group, retains the order in the second group, and updates each group alternatively. This scheme can eliminate half of the delayed gradients and memory redundancy compared to PipeDream-2BW. The experiments, which train large BERT language models, show that compared to PipeDream-2BW, WPipe achieves $1.4\\times$ acceleration and reduces the memory footprint by 36%, without nearly sacrificing any final model accuracy.",
        "conference": "ICLR",
        "中文标题": "基于分组的交错流水线并行技术用于大规模深度神经网络训练",
        "摘要翻译": "近期，利用大规模深度神经网络（DNN）提升性能的趋势推动了用于高效DNN训练的并行流水线技术的发展，从而催生了几种著名的流水线技术，如GPipe、PipeDream和PipeDream-2BW。然而，当前领先的流水线技术PipeDream-2BW仍存在两大缺点，即过度的内存冗余和所有阶段权重更新的延迟。在本工作中，我们提出了一种名为WPipe的新型流水线，它实现了更高的内存效率和更及时的权重更新。WPipe采用了一种新颖的流水线方案，将模型分区分为两组。它将下一周期权重更新的前向传递移动到当前周期权重更新的反向传递之前在第一组中执行，在第二组中保持顺序，并交替更新每组。与PipeDream-2BW相比，该方案可以消除一半的延迟梯度和内存冗余。训练大型BERT语言模型的实验表明，与PipeDream-2BW相比，WPipe实现了1.4倍的加速，并将内存占用减少了36%，几乎不牺牲任何最终模型的准确性。",
        "领域": "深度学习并行计算、大规模神经网络训练、自然语言处理",
        "问题": "解决大规模深度神经网络训练中的内存冗余和权重更新延迟问题",
        "动机": "提升大规模DNN训练的内存效率和权重更新速度，减少训练时间和资源消耗",
        "方法": "提出WPipe流水线技术，通过分组和交错执行前向与反向传递，优化内存使用和权重更新效率",
        "关键词": [
            "流水线并行",
            "内存优化",
            "权重更新",
            "大规模训练",
            "BERT模型"
        ],
        "涉及的技术概念": {
            "流水线并行": "一种将模型训练过程分割成多个阶段，并在不同设备上并行执行这些阶段的技术，以提高训练效率",
            "权重更新延迟": "在分布式训练中，由于通信和同步开销导致的模型权重更新不及时的问题，影响训练速度和模型性能",
            "内存冗余": "在并行训练过程中，由于数据复制或缓存导致的额外内存消耗，限制了模型规模和训练效率"
        },
        "success": true
    },
    {
        "order": 416,
        "title": "Group equivariant neural posterior estimation",
        "html": "https://iclr.cc//virtual/2022/poster/6752",
        "abstract": "Simulation-based inference with conditional neural density estimators is a powerful approach to solving inverse problems in science. However, these methods typically treat the underlying forward model as a black box, with no way to exploit geometric properties such as equivariances. Equivariances are common in scientific models, however integrating them directly into expressive inference networks (such as normalizing flows) is not straightforward. We here describe an alternative method to incorporate equivariances under joint transformations of parameters and data. Our method---called group equivariant neural posterior estimation (GNPE)---is based on self-consistently standardizing the 'pose' of the data while estimating the posterior over parameters. It is architecture-independent, and applies both to exact and approximate equivariances. As a real-world application, we use GNPE for amortized inference of astrophysical binary black hole systems from gravitational-wave observations. We show that GNPE achieves state-of-the-art accuracy while reducing inference times by three orders of magnitude.",
        "conference": "ICLR",
        "中文标题": "群等变神经后验估计",
        "摘要翻译": "基于条件神经密度估计器的模拟推理是解决科学中逆问题的强大方法。然而，这些方法通常将底层前向模型视为黑箱，无法利用诸如等变性之类的几何特性。等变性在科学模型中很常见，但直接将它们整合到表达性推理网络（如标准化流）中并不简单。我们在此描述了一种在参数和数据的联合变换下纳入等变性的替代方法。我们的方法——称为群等变神经后验估计（GNPE）——基于在估计参数后验时自洽地标准化数据的'姿态'。它是架构无关的，适用于精确和近似的等变性。作为一个实际应用，我们使用GNPE从引力波观测中对天体物理双黑洞系统进行摊销推理。我们展示了GNPE在将推理时间减少三个数量级的同时，实现了最先进的准确性。",
        "领域": "逆问题求解、天体物理信号处理、深度学习模型优化",
        "问题": "如何在模拟推理中有效利用模型的几何等变性质以提高推理效率和准确性",
        "动机": "科学模型中的等变性普遍存在，但现有方法难以直接将这些性质整合到复杂的推理网络中，限制了推理的效率和准确性",
        "方法": "提出了一种称为群等变神经后验估计（GNPE）的方法，通过在参数和数据的联合变换下自洽地标准化数据的'姿态'来纳入等变性，适用于各种网络架构和等变类型",
        "关键词": [
            "群等变性",
            "神经后验估计",
            "逆问题求解",
            "标准化流",
            "引力波分析"
        ],
        "涉及的技术概念": {
            "群等变性": "在参数和数据的联合变换下保持模型行为一致的性质，GNPE利用这一性质提高推理的效率和准确性",
            "神经后验估计": "使用神经网络估计参数的后验分布，GNPE是对这一方法的扩展，特别考虑了等变性",
            "标准化流": "一种表达性强的概率分布变换方法，GNPE方法不依赖于特定架构，但可以与标准化流等技术结合使用"
        },
        "success": true
    },
    {
        "order": 417,
        "title": "Half-Inverse Gradients for Physical Deep Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6768",
        "abstract": "Recent works in deep learning have shown that integrating differentiable physics simulators into the training process can greatly improve the quality of results. Although this combination represents a more complex optimization task than usual neural network training, the same gradient-based optimizers are used to minimize the loss function. However, the integrated physics solvers have a profound effect on the gradient flow as manipulating scales in magnitude and direction is an inherent property of many physical processes. Consequently, the gradient flow is often highly unbalanced and creates an environment in which existing gradient-based optimizers perform poorly. In this work, we analyze the characteristics of both physical and neural network optimizations separately to derive a new method based on a half-inversion of the Jacobian. Our approach combines principles of both classical network and physics optimizers to solve the combined optimization task. Compared to state-of-the-art neural network optimizers, our method converges more quickly and to better solutions, which we demonstrate on three complex learning problems involving nonlinear oscillators, the Schroedinger equation and the Poisson problem.",
        "conference": "ICLR",
        "中文标题": "物理深度学习的半逆梯度方法",
        "摘要翻译": "近期的深度学习研究表明，将可微分物理模拟器整合到训练过程中可以显著提高结果的质量。尽管这种组合比通常的神经网络训练代表了更复杂的优化任务，但同样的基于梯度的优化器被用来最小化损失函数。然而，集成的物理求解器对梯度流有深远的影响，因为操纵大小和方向的比例是许多物理过程的固有属性。因此，梯度流往往高度不平衡，并创造了一个现有基于梯度的优化器表现不佳的环境。在这项工作中，我们分别分析了物理和神经网络优化的特点，以推导出一种基于雅可比矩阵半逆的新方法。我们的方法结合了经典网络和物理优化器的原理来解决组合优化任务。与最先进的神经网络优化器相比，我们的方法收敛更快，达到更好的解决方案，我们在涉及非线性振荡器、薛定谔方程和泊松问题的三个复杂学习问题上证明了这一点。",
        "领域": "物理信息神经网络、微分方程求解、优化算法",
        "问题": "解决在物理深度学习中梯度流不平衡导致优化器性能不佳的问题",
        "动机": "通过分析物理和神经网络优化的特点，开发一种新的优化方法，以提高在物理深度学习任务中的收敛速度和解的质量",
        "方法": "提出了一种基于雅可比矩阵半逆的新方法，结合了经典网络和物理优化器的原理",
        "关键词": [
            "物理深度学习",
            "梯度优化",
            "雅可比矩阵半逆",
            "非线性振荡器",
            "薛定谔方程"
        ],
        "涉及的技术概念": {
            "可微分物理模拟器": "用于整合物理过程到深度学习训练中，允许通过物理模型进行梯度传播",
            "梯度流": "描述了在优化过程中梯度的变化和传播，物理过程的集成可能导致梯度流不平衡",
            "雅可比矩阵半逆": "提出的新方法中的关键技术，用于调整梯度流，提高优化效率和解的质量"
        },
        "success": true
    },
    {
        "order": 418,
        "title": "Handling Distribution Shifts on Graphs: An Invariance Perspective",
        "html": "https://iclr.cc//virtual/2022/poster/7180",
        "abstract": "There is increasing evidence suggesting neural networks' sensitivity to distribution shifts, so that research on out-of-distribution (OOD) generalization comes into the spotlight. Nonetheless, current endeavors mostly focus on Euclidean data, and its formulation for graph-structured data is not clear and remains under-explored, given two-fold fundamental challenges: 1) the inter-connection among nodes in one graph, which induces non-IID generation of data points even under the same environment, and 2) the structural information in the input graph, which is also informative for prediction. In this paper, we formulate the OOD problem on graphs and develop a new invariant learning approach, Explore-to-Extrapolate Risk Minimization (EERM), that facilitates graph neural networks to leverage invariance principles for prediction. EERM resorts to multiple context explorers (specified as graph structure editers in our case) that are adversarially trained to maximize the variance of risks from multiple virtual environments. Such a design enables the model to extrapolate from a single observed environment which is the common case for node-level prediction. We prove the validity of our method by theoretically showing its guarantee of a valid OOD solution and further demonstrate its power on various real-world datasets for handling distribution shifts from artificial spurious features, cross-domain transfers and dynamic graph evolution.",
        "conference": "ICLR",
        "中文标题": "处理图上的分布偏移：一种不变性视角",
        "摘要翻译": "越来越多的证据表明神经网络对分布偏移的敏感性，因此关于分布外（OOD）泛化的研究成为焦点。然而，当前的努力主要集中在欧几里得数据上，对于图结构数据的表述尚不明确且探索不足，这源于两个基本挑战：1）图中节点间的相互连接，导致即使在相同环境下数据点的生成也是非独立同分布的；2）输入图中的结构信息，对预测同样具有信息量。在本文中，我们形式化了图上的OOD问题，并开发了一种新的不变性学习方法——探索到外推风险最小化（EERM），该方法促进图神经网络利用不变性原则进行预测。EERM依赖于多个上下文探索器（在我们的案例中指定为图结构编辑器），这些探索器通过对抗训练以最大化来自多个虚拟环境的风险方差。这样的设计使得模型能够从单一观察到的环境中外推，这是节点级预测的常见情况。我们通过理论上展示其有效OOD解决方案的保证来证明我们方法的有效性，并进一步展示了其在处理来自人工虚假特征、跨域转移和动态图演化的分布偏移方面的多种实际数据集上的能力。",
        "领域": "图神经网络、分布外泛化、不变性学习",
        "问题": "解决图结构数据在分布偏移下的泛化问题",
        "动机": "当前关于分布外泛化的研究主要集中于欧几里得数据，对图结构数据的探索不足，存在非独立同分布数据生成和结构信息利用的挑战",
        "方法": "开发了一种新的不变性学习方法EERM，通过对抗训练多个上下文探索器以最大化风险方差，促进图神经网络利用不变性原则进行预测",
        "关键词": [
            "图神经网络",
            "分布外泛化",
            "不变性学习",
            "对抗训练",
            "风险最小化"
        ],
        "涉及的技术概念": {
            "探索到外推风险最小化（EERM）": "一种新的不变性学习方法，通过对抗训练多个上下文探索器以最大化风险方差，促进图神经网络利用不变性原则进行预测",
            "图结构编辑器": "在EERM方法中用作上下文探索器，通过编辑图结构来创建多个虚拟环境",
            "对抗训练": "用于训练上下文探索器以最大化风险方差的技术，帮助模型从单一观察到的环境中外推"
        },
        "success": true
    },
    {
        "order": 419,
        "title": "Heteroscedastic Temporal Variational Autoencoder For Irregularly Sampled Time Series",
        "html": "https://iclr.cc//virtual/2022/poster/6271",
        "abstract": "Irregularly sampled time series commonly occur in several domains where they present a significant challenge to standard deep learning models. In this paper, we propose a new deep learning framework for probabilistic interpolation of irregularly sampled time series that we call the Heteroscedastic Temporal Variational Autoencoder (HeTVAE). HeTVAE includes a novel input layer to encode information about input observation sparsity, a temporal VAE architecture to propagate uncertainty due to input sparsity, and a heteroscedastic output layer to enable variable uncertainty in the output interpolations.  Our results show that the proposed architecture is better able to reflect variable uncertainty through time due to sparse and irregular sampling than a range of baseline and traditional models, as well as recently proposed deep latent variable models that use homoscedastic output layers.",
        "conference": "ICLR",
        "中文标题": "异方差时间变分自编码器用于不规则采样时间序列",
        "摘要翻译": "不规则采样的时间序列在多个领域中普遍存在，这对标准的深度学习模型构成了重大挑战。本文提出了一种新的深度学习框架，用于不规则采样时间序列的概率插值，我们称之为异方差时间变分自编码器（HeTVAE）。HeTVAE包括一个新颖的输入层，用于编码输入观测稀疏性的信息；一个时间VAE架构，用于传播由于输入稀疏性引起的不确定性；以及一个异方差输出层，以实现输出插值中的可变不确定性。我们的结果表明，与一系列基线和传统模型以及最近提出的使用同方差输出层的深度潜在变量模型相比，所提出的架构能够更好地反映由于稀疏和不规则采样导致的时间上的可变不确定性。",
        "领域": "时间序列分析、深度学习、概率建模",
        "问题": "解决不规则采样时间序列的概率插值问题",
        "动机": "针对不规则采样时间序列在标准深度学习模型中处理不足的问题，提出一种能够更好地反映由于稀疏和不规则采样导致的时间上可变不确定性的模型",
        "方法": "提出了一种名为异方差时间变分自编码器（HeTVAE）的新框架，包括编码输入观测稀疏性的输入层、传播不确定性的时间VAE架构和实现输出可变不确定性的异方差输出层",
        "关键词": [
            "不规则采样时间序列",
            "概率插值",
            "异方差时间变分自编码器",
            "不确定性传播",
            "深度学习"
        ],
        "涉及的技术概念": {
            "异方差时间变分自编码器（HeTVAE）": "一种新的深度学习框架，用于不规则采样时间序列的概率插值，能够处理输入稀疏性和输出不确定性",
            "时间VAE架构": "用于传播由于输入稀疏性引起的不确定性的变分自编码器架构",
            "异方差输出层": "使模型能够根据输入的不同部分产生不同水平的不确定性输出"
        },
        "success": true
    },
    {
        "order": 420,
        "title": "Hidden Convexity of Wasserstein GANs: Interpretable Generative Models with Closed-Form Solutions",
        "html": "https://iclr.cc//virtual/2022/poster/6284",
        "abstract": "Generative Adversarial Networks (GANs) are commonly used for modeling complex distributions of data. Both the generators and discriminators of GANs are often modeled by neural networks, posing a non-transparent optimization problem which is non-convex and non-concave over the generator and discriminator, respectively. Such networks are often heuristically optimized with gradient descent-ascent (GDA), but it is unclear whether the optimization problem contains any saddle points, or whether heuristic methods can find them in practice. In this work, we analyze the training of Wasserstein GANs with two-layer neural network discriminators through the lens of convex duality, and for a variety of generators expose the conditions under which Wasserstein GANs can be solved exactly with convex optimization approaches, or can be represented as convex-concave games. Using this convex duality interpretation, we further demonstrate the impact of different activation functions of the discriminator. Our observations are verified with numerical results demonstrating the power of the convex interpretation, with an application in progressive training of convex architectures corresponding to linear generators and quadratic-activation discriminators for CelebA image generation. The code for our experiments is available at https://github.com/ardasahiner/ProCoGAN.",
        "conference": "ICLR",
        "中文标题": "Wasserstein GANs的隐藏凸性：具有闭式解的可解释生成模型",
        "摘要翻译": "生成对抗网络（GANs）通常用于建模数据的复杂分布。GANs的生成器和判别器通常由神经网络建模，这提出了一个不透明的优化问题，该问题在生成器和判别器上分别是非凸和非凹的。这样的网络通常通过梯度下降-上升（GDA）启发式优化，但尚不清楚优化问题是否包含任何鞍点，或者启发式方法在实践中是否能找到它们。在这项工作中，我们通过凸对偶的视角分析了使用两层神经网络判别器的Wasserstein GANs的训练，并为多种生成器揭示了在哪些条件下Wasserstein GANs可以通过凸优化方法精确求解，或者可以表示为凸-凹游戏。利用这种凸对偶解释，我们进一步展示了判别器不同激活函数的影响。我们的观察结果通过数值结果验证了凸解释的力量，并应用于对应于线性生成器和二次激活判别器的凸架构的渐进训练，用于CelebA图像生成。我们实验的代码可在https://github.com/ardasahiner/ProCoGAN获取。",
        "领域": "生成对抗网络、凸优化、图像生成",
        "问题": "解决GANs训练过程中的非凸优化问题，提供闭式解和可解释性",
        "动机": "探索Wasserstein GANs在特定条件下的凸优化可能性，以提高训练效率和模型可解释性",
        "方法": "通过凸对偶理论分析Wasserstein GANs的训练，揭示使用凸优化方法精确求解的条件，并研究不同激活函数的影响",
        "关键词": [
            "Wasserstein GANs",
            "凸优化",
            "生成对抗网络",
            "凸对偶",
            "图像生成"
        ],
        "涉及的技术概念": {
            "Wasserstein GANs": "一种生成对抗网络，使用Wasserstein距离作为损失函数，以提高训练的稳定性",
            "凸对偶": "用于分析优化问题的数学工具，帮助揭示问题的凸性质",
            "梯度下降-上升（GDA）": "一种启发式优化方法，用于训练生成对抗网络"
        },
        "success": true
    },
    {
        "order": 421,
        "title": "Hidden Parameter Recurrent State Space Models For Changing Dynamics Scenarios",
        "html": "https://iclr.cc//virtual/2022/poster/6915",
        "abstract": "Recurrent State-space models (RSSMs) are highly expressive models for learning patterns in time series data and for system identification. However, these models are often based on the assumption that the dynamics are fixed and unchanging, which is rarely the case in real-world scenarios. Many control applications often exhibit tasks with similar, but not identical dynamics, that can be modelled as having a common latent structure. We introduce the Hidden Parameter Recurrent State Space Models (HiP-RSSMs), a framework that parametrizes a family of related state-space models with a low-dimensional set of latent factors. We present a simple and effective way of performing learning and inference over this Gaussian graphical model that avoids approximations like variational inference. We show that HiP-RSSMs outperforms RSSMs and competing multi-task models on several challenging robotic benchmarks both on real systems and simulations.",
        "conference": "ICLR",
        "中文标题": "用于变化动态场景的隐藏参数递归状态空间模型",
        "摘要翻译": "递归状态空间模型（RSSMs）是学习时间序列数据模式和系统识别的高度表达性模型。然而，这些模型通常基于动态固定不变的假设，这在实际场景中很少成立。许多控制应用经常表现出具有相似但不完全相同动态的任务，这些任务可以被建模为具有共同的潜在结构。我们引入了隐藏参数递归状态空间模型（HiP-RSSMs），这是一个通过一组低维潜在因素参数化相关状态空间模型家族的框架。我们提出了一种简单有效的方法，在这个高斯图形模型上进行学习和推理，避免了变分推断等近似方法。我们展示了HiP-RSSMs在几个具有挑战性的机器人基准测试中，无论是在真实系统还是模拟中，都优于RSSMs和竞争的多任务模型。",
        "领域": "时间序列分析, 系统识别, 机器人控制",
        "问题": "解决递归状态空间模型在动态变化场景中的适应性问题",
        "动机": "现实世界中的控制应用往往涉及动态变化的任务，需要模型能够适应这些变化",
        "方法": "引入隐藏参数递归状态空间模型（HiP-RSSMs），通过低维潜在因素参数化相关状态空间模型家族，并提出一种简单有效的学习和推理方法",
        "关键词": [
            "递归状态空间模型",
            "隐藏参数",
            "动态变化",
            "系统识别",
            "机器人控制"
        ],
        "涉及的技术概念": {
            "递归状态空间模型（RSSMs）": "用于学习时间序列数据模式和系统识别的高度表达性模型",
            "隐藏参数递归状态空间模型（HiP-RSSMs）": "通过低维潜在因素参数化相关状态空间模型家族的框架，以适应动态变化场景",
            "高斯图形模型": "HiP-RSSMs中用于学习和推理的模型，避免了变分推断等近似方法"
        },
        "success": true
    },
    {
        "order": 422,
        "title": "Hierarchical Few-Shot Imitation with Skill Transition Models",
        "html": "https://iclr.cc//virtual/2022/poster/6735",
        "abstract": "A desirable property of autonomous agents is the ability to both solve long-horizon problems and generalize to unseen tasks. Recent advances in data-driven skill learning have shown that extracting behavioral priors from offline data can enable agents to solve challenging long-horizon tasks with reinforcement learning. However, generalization to tasks unseen during behavioral prior training remains an outstanding challenge. To this end, we present Few-shot Imitation with Skill Transition Models (FIST), an algorithm that extracts skills from offline data and utilizes them to generalize to unseen tasks given a few downstream demonstrations. FIST learns an inverse skill dynamics model, a distance function, and utilizes a semi-parametric approach for imitation. We show that FIST is capable of generalizing to new tasks and substantially outperforms prior baselines in navigation experiments requiring traversing unseen parts of a large maze and 7-DoF robotic arm experiments requiring manipulating previously unseen objects in a kitchen.",
        "conference": "ICLR",
        "中文标题": "分层少样本模仿与技能转换模型",
        "摘要翻译": "自主代理的一个理想特性是能够解决长期视野问题并泛化到未见过的任务。数据驱动技能学习的最新进展表明，从离线数据中提取行为先验可以使代理通过强化学习解决具有挑战性的长期视野任务。然而，泛化到行为先验训练期间未见过的任务仍然是一个突出的挑战。为此，我们提出了少样本模仿与技能转换模型（FIST），这是一种从离线数据中提取技能并利用它们通过少量下游演示泛化到未见任务的算法。FIST学习了一个逆技能动态模型、一个距离函数，并利用半参数方法进行模仿。我们证明，FIST能够泛化到新任务，并在需要穿越大型迷宫未见部分的导航实验和需要在厨房中操作先前未见物体的7自由度机械臂实验中显著优于先前的基线。",
        "领域": "强化学习、机器人操作、自主导航",
        "问题": "如何使自主代理能够泛化到在行为先验训练期间未见过的任务",
        "动机": "解决自主代理在长期视野任务中泛化能力的不足",
        "方法": "从离线数据中提取技能，学习逆技能动态模型和距离函数，采用半参数方法进行模仿",
        "关键词": [
            "少样本模仿",
            "技能转换模型",
            "强化学习",
            "机器人操作",
            "自主导航"
        ],
        "涉及的技术概念": {
            "逆技能动态模型": "用于从观察到的行为中推断出技能序列的模型",
            "距离函数": "用于衡量技能之间相似性的函数，帮助模型泛化到新任务",
            "半参数方法": "结合参数化和非参数化方法的优点，用于模仿学习"
        },
        "success": true
    },
    {
        "order": 423,
        "title": "Hierarchical Variational Memory for Few-shot Learning Across Domains",
        "html": "https://iclr.cc//virtual/2022/poster/6912",
        "abstract": "Neural memory enables fast adaptation to new tasks with just a few training samples. Existing memory models store features only from the single last layer, which does not generalize well in presence of a domain shift between training and test distributions. Rather than relying on a flat memory, we propose a hierarchical alternative that stores features at different semantic levels. We introduce a hierarchical prototype model, where each level of the prototype fetches corresponding information from the hierarchical memory. The model is endowed with the ability to flexibly rely on features at different semantic levels if the domain shift circumstances so demand. We meta-learn the model by a newly derived hierarchical variational inference framework, where hierarchical memory and prototypes are jointly optimized. To explore and exploit the importance of different semantic levels, we further propose to learn the weights associated with the prototype at each level in a data-driven way, which enables the model to adaptively choose the most generalizable features. We conduct thorough ablation studies to demonstrate the effectiveness of each component in our model. The new state-of-the-art performance on cross-domain and competitive performance on traditional few-shot classification further substantiates the benefit of hierarchical variational memory.",
        "conference": "ICLR",
        "中文标题": "跨领域少样本学习的层次变分记忆",
        "摘要翻译": "神经记忆能够快速适应仅需少量训练样本的新任务。现有的记忆模型仅存储来自单一最后一层的特征，这在训练和测试分布之间存在领域偏移时泛化能力不佳。我们提出了一种层次化的替代方案，而非依赖扁平记忆，该方案在不同语义层次上存储特征。我们引入了一个层次原型模型，其中每个层次的原型从层次记忆中获取相应信息。该模型具备根据领域偏移情况灵活依赖不同语义层次特征的能力。我们通过新推导的层次变分推理框架对模型进行元学习，其中层次记忆和原型被联合优化。为了探索和利用不同语义层次的重要性，我们进一步提出以数据驱动的方式学习与每个层次原型相关的权重，这使得模型能够自适应地选择最具泛化能力的特征。我们进行了彻底的消融研究，以证明模型中每个组件的有效性。在跨领域少样本分类上的新最先进性能以及在传统少样本分类上的竞争性能进一步证实了层次变分记忆的优势。",
        "领域": "少样本学习, 跨领域适应, 元学习",
        "问题": "解决在训练和测试分布之间存在领域偏移时，现有记忆模型泛化能力不佳的问题。",
        "动机": "为了提高模型在跨领域少样本学习任务中的适应能力和泛化性能。",
        "方法": "提出了一种层次变分记忆模型，通过在不同语义层次上存储特征，并利用层次变分推理框架进行元学习，以自适应地选择最具泛化能力的特征。",
        "关键词": [
            "层次变分记忆",
            "少样本学习",
            "跨领域适应",
            "元学习",
            "层次原型模型"
        ],
        "涉及的技术概念": {
            "层次变分记忆": "在不同语义层次上存储特征，以提高模型在跨领域少样本学习任务中的泛化能力。",
            "层次原型模型": "通过从层次记忆中获取相应信息，使模型能够灵活依赖不同语义层次的特征。",
            "层次变分推理框架": "用于元学习层次记忆和原型，联合优化模型以适应跨领域少样本学习任务。"
        },
        "success": true
    },
    {
        "order": 424,
        "title": "High Probability Bounds for a Class of Nonconvex Algorithms with AdaGrad Stepsize",
        "html": "https://iclr.cc//virtual/2022/poster/7173",
        "abstract": "In this paper, we propose a new, simplified high probability analysis of AdaGrad for smooth, non-convex problems. More specifically, we focus on a particular accelerated gradient (AGD) template (Lan, 2020), through which we recover the original AdaGrad and its variant with averaging, and prove a convergence rate of $\\mathcal O (1/ \\sqrt{T})$ with high probability without the knowledge of smoothness and variance. We use a particular version of Freedman's concentration bound for martingale difference sequences (Kakade & Tewari, 2008) which enables us to achieve the best-known dependence of $\\log (1 / \\delta )$ on the probability margin $\\delta$. We present our analysis in a modular way and obtain a complementary $\\mathcal O (1 / T)$ convergence rate in the deterministic setting. To the best of our knowledge, this is the first high probability result for AdaGrad with a truly adaptive scheme, i.e., completely oblivious to the knowledge of smoothness and uniform variance bound, which simultaneously has best-known dependence of $\\log( 1/ \\delta)$. We further prove noise adaptation property of AdaGrad under additional noise assumptions.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "一类具有AdaGrad步长的非凸算法的高概率界限",
        "摘要翻译": "在本文中，我们针对平滑的非凸问题，提出了一种新的、简化的AdaGrad高概率分析方法。更具体地说，我们专注于一个特定的加速梯度（AGD）模板（Lan, 2020），通过该模板，我们恢复了原始的AdaGrad及其带有平均的变体，并在不知道平滑性和方差的情况下，证明了具有高概率的收敛速度为$\\mathcal O (1/ \\sqrt{T})$。我们使用了Freedman鞅差序列的特殊版本浓度界限（Kakade & Tewari, 2008），这使我们能够实现$\\log (1 / \\delta )$对概率边际$\\delta$的最佳已知依赖性。我们以模块化的方式呈现我们的分析，并在确定性设置中获得互补的$\\mathcal O (1 / T)$收敛速度。据我们所知，这是AdaGrad的第一个高概率结果，它采用了一种真正自适应的方案，即完全忽略了平滑性和一致方差界的知识，同时具有$\\log( 1/ \\delta)$的最佳已知依赖性。我们还在额外的噪声假设下证明了AdaGrad的噪声自适应特性。",
        "领域": "优化算法、自适应学习率、非凸优化",
        "问题": "研究AdaGrad算法在非凸优化问题中的收敛速度和概率界限。",
        "动机": "现有的AdaGrad分析通常需要对平滑性或方差有先验知识，而这项研究旨在提供一种无需这些知识的自适应方案，并获得更好的概率依赖性。",
        "方法": "通过分析特定的加速梯度（AGD）模板，并利用Freedman鞅差序列的浓度界限，证明AdaGrad在高概率下的收敛速度。",
        "关键词": [
            "AdaGrad",
            "非凸优化",
            "高概率界限",
            "自适应学习率",
            "加速梯度"
        ],
        "涉及的技术概念": {
            "AdaGrad": "一种自适应学习率的优化算法，可以根据历史梯度信息调整每个参数的学习率，有助于在非凸优化问题中更快地收敛。",
            "加速梯度 (AGD)": "一种改进的梯度下降算法，通过引入动量项来加速收敛，特别适用于凸优化和非凸优化问题。"
        }
    },
    {
        "order": 425,
        "title": "High Probability Generalization Bounds with Fast Rates for Minimax Problems",
        "html": "https://iclr.cc//virtual/2022/poster/7058",
        "abstract": "Minimax problems are receiving an increasing amount of attention in a wide range of applications in machine learning (ML), for instance, reinforcement learning, robust optimization, adversarial learning, and distributed computing, to mention but a few. Current studies focus on the fundamental understanding of general minimax problems with an emphasis on convergence behavior. As a comparison, there is far less work to study the generalization performance. Additionally, existing generalization bounds are almost all derived in expectation, and the high probability bounds are all presented in the slow order $\\mathcal{O}(1/\\sqrt{n})$, where $n$ is the sample size. In this paper, we provide improved generalization analyses and obtain sharper high probability generalization bounds for most existing generalization measures of minimax problems. We then use the improved learning bounds to establish high probability generalization bounds with fast rates for classical empirical saddle point (ESP) solution and several popular gradient-based optimization algorithms, including gradient descent ascent (GDA), stochastic gradient descent ascent (SGDA), proximal point method (PPM), extra-gradient (EG), and optimistic gradient descent ascent (OGDA). In summary, we provide a systematical analysis of sharper generalization bounds of minimax problems.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "极小极大问题的高概率泛化界限与快速收敛速度",
        "摘要翻译": "极小极大问题在机器学习（ML）的广泛应用中受到越来越多的关注，例如，强化学习、鲁棒优化、对抗学习和分布式计算等等。目前的研究主要集中在对一般极小极大问题的基本理解上，重点是收敛行为。相比之下，研究泛化性能的工作要少得多。此外，现有的泛化界限几乎都是在期望下推导出来的，而高概率界限都以较慢的速率呈现，即O(1/√n)，其中n是样本大小。在本文中，我们提供了改进的泛化分析，并获得了针对大多数现有极小极大问题泛化度量的更清晰的高概率泛化界限。然后，我们利用改进的学习界限，为经典经验鞍点（ESP）解和几种流行的基于梯度的优化算法（包括梯度下降上升（GDA）、随机梯度下降上升（SGDA）、近端点法（PPM）、额外梯度（EG）和乐观梯度下降上升（OGDA））建立具有快速收敛速度的高概率泛化界限。总而言之，我们对极小极大问题的更清晰的泛化界限进行了系统分析。",
        "领域": "对抗学习, 鲁棒优化, 强化学习",
        "问题": "现有极小极大问题的泛化界限研究较少，且高概率界限收敛速度慢。",
        "动机": "提高极小极大问题泛化性能的理论分析，并获得更快的泛化界限收敛速度。",
        "方法": "通过改进的泛化分析，获得更清晰的高概率泛化界限，并将其应用于经典经验鞍点解和多种梯度优化算法。",
        "关键词": [
            "极小极大问题",
            "泛化界限",
            "高概率界限",
            "梯度下降上升",
            "收敛速度"
        ],
        "涉及的技术概念": {
            "泛化界限": "衡量模型在未见过的数据上的表现能力，越小的界限意味着更好的泛化性能。",
            "高概率界限": "以较高的概率保证泛化误差在一个可接受的范围内。"
        }
    },
    {
        "order": 426,
        "title": "Hindsight Foresight Relabeling for Meta-Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6247",
        "abstract": "Meta-reinforcement learning (meta-RL) algorithms allow for agents to learn new behaviors from small amounts of experience, mitigating the sample inefficiency problem in RL. However, while meta-RL agents can adapt quickly to new tasks at test time after experiencing only a few trajectories, the meta-training process is still sample-inefficient. Prior works have found that in the multi-task RL setting, relabeling past transitions and thus sharing experience among tasks can improve sample efficiency and asymptotic performance. We apply this idea to the meta-RL setting and devise a new relabeling method called Hindsight Foresight Relabeling (HFR). We construct a relabeling distribution using the combination of 'hindsight', which is used to relabel trajectories using reward functions from the training task distribution, and 'foresight', which takes the relabeled trajectories and computes the utility of each trajectory for each task. HFR is easy to implement and readily compatible with existing meta-RL algorithms. We find that HFR improves performance when compared to other relabeling methods on a variety of meta-RL tasks.",
        "conference": "ICLR",
        "中文标题": "元强化学习中的后见之明前瞻性重标记",
        "摘要翻译": "元强化学习（meta-RL）算法使智能体能够从少量经验中学习新行为，缓解了强化学习中的样本效率问题。然而，尽管元强化学习智能体在测试时仅经历少量轨迹后就能快速适应新任务，元训练过程仍然样本效率低下。先前的研究发现，在多任务强化学习设置中，通过重标记过去的转移从而在任务间共享经验，可以提高样本效率和渐近性能。我们将这一想法应用于元强化学习设置，并设计了一种新的重标记方法，称为后见之明前瞻性重标记（HFR）。我们构建了一个重标记分布，结合了‘后见之明’和‘前瞻性’：前者用于使用训练任务分布中的奖励函数重标记轨迹，后者则利用重标记后的轨迹计算每个轨迹对每个任务的效用。HFR易于实现，且与现有的元强化学习算法兼容。我们发现，在各种元强化学习任务中，与其他重标记方法相比，HFR提高了性能。",
        "领域": "元强化学习、多任务学习、样本效率优化",
        "问题": "解决元强化学习在元训练过程中的样本效率低下问题",
        "动机": "通过共享任务间的经验来提高元强化学习的样本效率和性能",
        "方法": "提出了一种结合后见之明和前瞻性的重标记方法（HFR），用于在元强化学习中共享任务经验",
        "关键词": [
            "元强化学习",
            "样本效率",
            "重标记",
            "后见之明",
            "前瞻性"
        ],
        "涉及的技术概念": {
            "后见之明": "用于重标记轨迹，利用训练任务分布中的奖励函数来评估过去的经验",
            "前瞻性": "评估重标记后的轨迹对每个任务的效用，帮助智能体更好地适应新任务",
            "元强化学习": "一种使智能体能够从少量经验中快速适应新任务的强化学习方法"
        },
        "success": true
    },
    {
        "order": 427,
        "title": "Hindsight is 20/20: Leveraging Past Traversals to Aid 3D Perception",
        "html": "https://iclr.cc//virtual/2022/poster/6048",
        "abstract": "Self-driving cars must detect vehicles, pedestrians, and other trafﬁc participants accurately to operate safely. Small, far-away, or highly occluded objects are particularly challenging because there is limited information in the LiDAR point clouds for detecting them. To address this challenge, we leverage valuable information from the past: in particular, data collected in past traversals of the same scene. We posit that these past data, which are typically discarded, provide rich contextual information for disambiguating the above-mentioned challenging cases. To this end, we propose a novel end-to-end trainable Hindsight framework to extract this contextual information from past traversals and store it in an easy-to-query data structure, which can then be leveraged to aid future 3D object detection of the same scene. We show that this framework is compatible with most modern 3D detection architectures and can substantially improve their average precision on multiple autonomous driving datasets, most notably by more than 300% on the challenging cases. Our code is available at https://github.com/YurongYou/Hindsight.",
        "conference": "ICLR",
        "中文标题": "后见之明：利用历史遍历数据辅助3D感知",
        "摘要翻译": "自动驾驶汽车必须准确检测车辆、行人和其他交通参与者以确保安全运行。小而远、或被高度遮挡的物体尤其具有挑战性，因为激光雷达点云中用于检测它们的信息有限。为了应对这一挑战，我们利用过去收集的宝贵信息：特别是同一场景过去遍历中收集的数据。我们认为这些通常被丢弃的过去数据为消除上述挑战性情况的歧义提供了丰富的上下文信息。为此，我们提出了一种新颖的端到端可训练的Hindsight框架，用于从过去的遍历中提取这些上下文信息，并将其存储在一个易于查询的数据结构中，然后可以利用这些信息来辅助同一场景的未来3D物体检测。我们展示了这个框架与大多数现代3D检测架构兼容，并且可以显著提高它们在多个自动驾驶数据集上的平均精度，尤其是在挑战性案例上提高了300%以上。我们的代码可在https://github.com/YurongYou/Hindsight获取。",
        "领域": "自动驾驶3D物体检测",
        "问题": "解决在激光雷达点云中检测小而远、或被高度遮挡物体的挑战",
        "动机": "利用过去遍历同一场景收集的数据，提供丰富的上下文信息，以改善3D物体检测的准确性",
        "方法": "提出一个端到端可训练的Hindsight框架，从历史数据中提取并存储上下文信息，用于辅助未来的3D物体检测",
        "关键词": [
            "自动驾驶",
            "3D物体检测",
            "激光雷达",
            "上下文信息",
            "历史数据"
        ],
        "涉及的技术概念": {
            "Hindsight框架": "一个端到端可训练的框架，用于从过去的遍历中提取和存储上下文信息",
            "激光雷达点云": "用于3D物体检测的主要数据来源，提供了场景的三维信息",
            "上下文信息": "从历史数据中提取的信息，用于辅助当前场景中的物体检测，特别是在处理挑战性案例时"
        },
        "success": true
    },
    {
        "order": 428,
        "title": "Hindsight: Posterior-guided training of retrievers for improved open-ended generation",
        "html": "https://iclr.cc//virtual/2022/poster/6736",
        "abstract": "Many text generation systems benefit from retrieving passages from a textual knowledge corpus (e.g., Wikipedia) and using them to generate the output. For open-ended generation tasks, like generating informative utterances in conversations, many varied passages $z$ are relevant to the context $x$ but few are relevant to the observed next utterance $y$ (label). For such tasks, existing methods (that jointly train the retriever and generator) underperform: during training the top-k context-relevant retrieved passages might not contain the label-relevant passage and the generator may hence not learn a preference to ground its generated output in them. We propose using an additional guide-retriever that also conditions on the observed label $y$ and “in hindsight” retrieves label-relevant passages during training. We maximize the evidence lower bound (ELBo) to jointly train the guide-retriever $Q(z|x,y)$ with the standard retriever $P_\\eta(z|x)$ and the generator $P_\\theta(y|x,z)$ and find that ELBo has better inductive biases than prior work. For informative conversations from the Wizard of Wikipedia dataset, with our posterior-guided training, the retriever finds passages with higher relevance in the top-10 (23% relative improvement), the generator’s responses are more grounded in the retrieved passage (19% relative improvement) and the end-to-end system produces better overall output (6.4% relative improvement). ",
        "conference": "ICLR",
        "success": true,
        "中文标题": "事后诸葛亮：后验引导的检索器训练，以改进开放式生成",
        "摘要翻译": "许多文本生成系统受益于从文本知识语料库（例如，维基百科）中检索段落，并使用它们来生成输出。对于开放式生成任务，例如在对话中生成信息丰富的语句，许多不同的段落 $z$ 与上下文 $x$ 相关，但很少有与观察到的下一个语句 $y$（标签）相关。对于此类任务，现有方法（联合训练检索器和生成器）表现不佳：在训练期间，前 k 个与上下文相关的检索段落可能不包含与标签相关的段落，因此生成器可能无法学习到基于它们生成输出的偏好。我们建议使用一个额外的引导检索器，该检索器也以观察到的标签 $y$ 为条件，并在训练期间“事后”检索与标签相关的段落。我们最大化证据下界 (ELBo) 以联合训练引导检索器 $Q(z|x,y)$ 与标准检索器 $P_η(z|x)$ 和生成器 $P_θ(y|x,z)$，并发现 ELBo 比之前的工作具有更好的归纳偏好。对于来自维基百科向导数据集的信息性对话，通过我们的后验引导训练，检索器在前 10 个中找到具有更高相关性的段落（相对改进 23%），生成器的响应更基于检索到的段落（相对改进 19%），并且端到端系统产生更好的整体输出（相对改进 6.4%）。",
        "领域": "开放域对话生成, 信息检索, 文本生成",
        "问题": "在开放式生成任务中，如何提升检索器检索到的段落与生成内容的相关性，从而提高生成质量？",
        "动机": "现有方法在联合训练检索器和生成器时，检索到的与上下文相关的段落可能不包含与标签相关的段落，导致生成器难以学习基于检索内容生成输出。",
        "方法": "提出一种后验引导的检索器训练方法，使用一个额外的引导检索器，该检索器以观察到的标签为条件，并在训练期间检索与标签相关的段落。 通过最大化证据下界 (ELBo) 来联合训练引导检索器、标准检索器和生成器。",
        "关键词": [
            "开放式生成",
            "信息检索",
            "后验引导",
            "证据下界",
            "对话生成"
        ],
        "涉及的技术概念": {
            "信息检索": "从大量文本数据中找到与给定查询相关的段落，在本文中用于检索与对话上下文相关的知识。",
            "证据下界(ELBo)": "一种用于近似推断的变分推断方法，本文中用于联合训练检索器和生成器，优化模型参数。"
        }
    },
    {
        "order": 429,
        "title": "Hot-Refresh Model Upgrades with Regression-Free Compatible Training in Image Retrieval",
        "html": "https://iclr.cc//virtual/2022/poster/5920",
        "abstract": "The task of hot-refresh model upgrades of image retrieval systems plays an essential role in the industry but has never been investigated in academia before. Conventional cold-refresh model upgrades can only deploy new models after the gallery is overall backfilled, taking weeks or even months for massive data. In contrast, hot-refresh model upgrades deploy the new model immediately and then gradually improve the retrieval accuracy by backfilling the gallery on-the-fly. Compatible training has made it possible, however, the problem of model regression with negative flips poses a great challenge to the stable improvement of user experience. We argue that it is mainly due to the fact that new-to-old positive query-gallery pairs may show less similarity than new-to-new negative pairs. To solve the problem, we introduce a Regression-Alleviating Compatible Training (RACT) method to properly constrain the feature compatibility while reducing negative flips. The core is to encourage the new-to-old positive pairs to be more similar than both the new-to-old negative pairs and the new-to-new negative pairs. An efficient uncertainty-based backfilling strategy is further introduced to fasten accuracy improvements. Extensive experiments on large-scale retrieval benchmarks (e.g., Google Landmark) demonstrate that our RACT effectively alleviates the model regression for one more step towards seamless model upgrades.",
        "conference": "ICLR",
        "中文标题": "图像检索中基于回归自由兼容训练的热刷新模型升级",
        "摘要翻译": "图像检索系统的热刷新模型升级任务在工业界扮演着重要角色，但此前在学术界尚未被研究。传统的冷刷新模型升级只能在图库完全回填后部署新模型，对于海量数据需要数周甚至数月时间。相比之下，热刷新模型升级立即部署新模型，然后通过即时回填图库逐步提高检索准确率。兼容训练使之成为可能，然而，模型回归与负面翻转的问题对用户体验的稳定提升构成了巨大挑战。我们认为，这主要是由于新旧正查询-图库对可能显示出比新旧负对更低的相似度。为解决这一问题，我们引入了一种回归缓解兼容训练（RACT）方法，以适当约束特征兼容性同时减少负面翻转。其核心是鼓励新旧正对比新旧负对和新新负对更相似。进一步引入了一种高效的基于不确定性的回填策略以加速准确率提升。在大规模检索基准（如Google Landmark）上的大量实验表明，我们的RACT有效缓解了模型回归，向无缝模型升级又迈进了一步。",
        "领域": "图像检索、模型升级、兼容学习",
        "问题": "解决图像检索系统在热刷新模型升级过程中出现的模型回归和负面翻转问题，以稳定提升用户体验。",
        "动机": "传统的冷刷新模型升级需要长时间回填图库，而热刷新模型升级虽能即时部署新模型，但面临模型回归和负面翻转的挑战，影响用户体验的稳定提升。",
        "方法": "提出回归缓解兼容训练（RACT）方法，通过约束特征兼容性和减少负面翻转，以及引入基于不确定性的回填策略，加速准确率提升。",
        "关键词": [
            "热刷新模型升级",
            "回归缓解兼容训练",
            "图像检索",
            "负面翻转",
            "基于不确定性的回填"
        ],
        "涉及的技术概念": {
            "回归缓解兼容训练（RACT）": "一种旨在减少模型回归和负面翻转的兼容训练方法，通过优化新旧正负对的相似度关系来提升模型性能。",
            "负面翻转": "指在模型升级过程中，新模型对某些查询的检索结果比旧模型更差的现象，影响用户体验。",
            "基于不确定性的回填策略": "一种高效的策略，用于在热刷新模型升级过程中快速提升检索准确率，通过优先处理不确定性高的样本优化回填过程。"
        },
        "success": true
    },
    {
        "order": 430,
        "title": "How Attentive are Graph Attention Networks? ",
        "html": "https://iclr.cc//virtual/2022/poster/6366",
        "abstract": "Graph Attention Networks (GATs) are one of the most popular GNN architectures and are considered as the state-of-the-art architecture for representation learning with graphs. In GAT, every node attends to its neighbors given its own representation as the query.However, in this paper we show that GAT computes a very limited kind of attention: the ranking of the attention scores is unconditioned on the query node. We formally define this restricted kind of attention as static attention and distinguish it from a strictly more expressive dynamic attention.Because GATs use a static attention mechanism, there are simple graph problems that GAT cannot express: in a controlled problem, we show that static attention hinders GAT from even fitting the training data. To remove this limitation, we introduce a simple fix by modifying the order of operations and propose GATv2: a dynamic graph attention variant that is strictly more expressive than GAT. We perform an extensive evaluation and show that GATv2 outperforms GAT across 12 OGB and other benchmarks while we match their parametric costs. Our code is available at https://github.com/tech-srl/how_attentive_are_gats . GATv2 is available as part of the PyTorch Geometric library, the Deep Graph Library, and the TensorFlow GNN library.",
        "conference": "ICLR",
        "中文标题": "图注意力网络有多专注？",
        "摘要翻译": "图注意力网络（GATs）是最流行的图神经网络架构之一，被认为是图表示学习的最先进架构。在GAT中，每个节点根据其自身的表示作为查询来关注其邻居。然而，在本文中，我们展示了GAT计算了一种非常有限的注意力：注意力得分的排名与查询节点无关。我们正式将这种受限的注意力定义为静态注意力，并将其与表达能力更强的动态注意力区分开来。由于GATs使用静态注意力机制，存在一些简单的图问题GAT无法表达：在一个控制问题中，我们展示了静态注意力甚至阻碍了GAT拟合训练数据。为了消除这一限制，我们通过修改操作顺序引入了一个简单的修复方法，并提出了GATv2：一种动态图注意力变体，其表达能力严格强于GAT。我们进行了广泛的评估，并展示了GATv2在12个OGB和其他基准测试中优于GAT，同时我们匹配了它们的参数成本。我们的代码可在https://github.com/tech-srl/how_attentive_are_gats获取。GATv2作为PyTorch Geometric库、Deep Graph库和TensorFlow GNN库的一部分提供。",
        "领域": "图神经网络、注意力机制、图表示学习",
        "问题": "GATs的静态注意力机制限制了其在某些图问题上的表达能力。",
        "动机": "提高图注意力网络的表达能力，使其能够处理更广泛的图问题。",
        "方法": "通过修改操作顺序，引入动态注意力机制，提出GATv2。",
        "关键词": [
            "图注意力网络",
            "动态注意力",
            "图表示学习"
        ],
        "涉及的技术概念": {
            "静态注意力": "GAT中使用的注意力机制，注意力得分的排名与查询节点无关。",
            "动态注意力": "GATv2中引入的注意力机制，其表达能力严格强于静态注意力。",
            "图表示学习": "通过图神经网络学习图中节点的表示，用于下游任务。"
        },
        "success": true
    },
    {
        "order": 431,
        "title": "How Did the Model Change? Efficiently Assessing Machine Learning API Shifts ",
        "html": "https://iclr.cc//virtual/2022/poster/6133",
        "abstract": "ML prediction APIs from providers like Amazon and Google have made it simple to use ML in applications. A challenge for users is that such APIs continuously change over time as the providers update models, and changes can happen silently without users knowing. It is thus important to monitor when and how much the MLAPIs’ performance shifts. To provide detailed change assessment, we model MLAPI shifts as confusion matrix differences, and propose a principled algorithmic framework, MASA, to provably assess these shifts efficiently given a sample budget constraint.MASAemploys an upper-confidence bound based approach to adaptively determine on which data point to query the ML API to estimate shifts. Empirically, we observe significant ML API shifts from 2020 to 2021 among 12 out of 36 applications using commercial APIs from Google, Microsoft, Amazon, and other providers. These real-world shifts include both improvements and reductions in accuracy. Extensive experiments show that MASA can estimate such API shifts more accurately than standard approaches given the same budget",
        "conference": "ICLR",
        "中文标题": "模型如何变化？高效评估机器学习API的变动",
        "摘要翻译": "来自亚马逊和谷歌等提供商的ML预测API使得在应用中使用ML变得简单。用户面临的一个挑战是，这些API会随着提供商更新模型而不断变化，且这些变化可能在用户不知情的情况下悄然发生。因此，监控MLAPI性能何时及多大程度上发生变化变得尤为重要。为了提供详细的变动评估，我们将MLAPI的变动建模为混淆矩阵的差异，并提出了一种原则性的算法框架MASA，以在给定样本预算约束的情况下，可证明地高效评估这些变动。MASA采用基于上置信界的方法，自适应地决定查询ML API的数据点以估计变动。实证上，我们观察到从2020年到2021年，使用来自谷歌、微软、亚马逊等提供商的商业API的36个应用中有12个出现了显著的ML API变动。这些现实世界中的变动包括准确率的提升和下降。大量实验表明，在相同预算下，MASA比标准方法能更准确地估计此类API变动。",
        "领域": "机器学习模型监控、API性能评估、商业ML服务",
        "问题": "监控和评估商业机器学习API随时间变化对性能的影响",
        "动机": "由于商业ML API的更新可能导致性能变化，用户需要有效方法来监控这些变化，以确保应用的稳定性和性能",
        "方法": "提出MASA算法框架，通过建模API变动为混淆矩阵差异，并采用基于上置信界的方法自适应地选择查询点，以高效评估API性能变动",
        "关键词": [
            "机器学习API",
            "性能监控",
            "混淆矩阵",
            "MASA算法",
            "商业ML服务"
        ],
        "涉及的技术概念": {
            "混淆矩阵差异": "用于量化ML API性能变动的指标，通过比较不同时间点的混淆矩阵来评估变化",
            "上置信界": "MASA算法中用于自适应选择查询点的技术，旨在高效利用有限的样本预算",
            "MASA算法": "一种原则性的算法框架，旨在在给定样本预算约束下，高效准确地评估ML API的性能变动"
        },
        "success": true
    },
    {
        "order": 432,
        "title": "How Does SimSiam Avoid Collapse Without Negative Samples? A Unified Understanding with Self-supervised Contrastive Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6629",
        "abstract": "To avoid collapse in self-supervised learning (SSL), a contrastive loss is widely used but often requires a large number of negative samples. Without negative samples yet achieving competitive performance, a recent work~\\citep{chen2021exploring} has attracted significant attention for providing a minimalist simple Siamese (SimSiam) method to avoid collapse. However, the reason for how it avoids collapse without negative samples remains not fully clear and our investigation starts by revisiting the explanatory claims in the original SimSiam. After refuting their claims, we introduce vector decomposition for analyzing the collapse based on the gradient analysis of the $l_2$-normalized representation vector. This yields a unified perspective on how negative samples and SimSiam alleviate collapse. Such a unified perspective comes timely for understanding the recent progress in SSL. ",
        "conference": "ICLR",
        "中文标题": "SimSiam如何在没有负样本的情况下避免崩溃？与自监督对比学习的统一理解",
        "摘要翻译": "为了避免自监督学习（SSL）中的崩溃，对比损失被广泛使用，但通常需要大量负样本。最近的一项工作在没有使用负样本的情况下实现了竞争性性能，因其提供了一个极简的简单孪生（SimSiam）方法来避免崩溃而引起了广泛关注。然而，它如何在没有负样本的情况下避免崩溃的原因尚不完全清楚，我们的调查从重新审视原始SimSiam中的解释性主张开始。在反驳了他们的主张后，我们引入了基于$l_2$归一化表示向量梯度分析的向量分解来分析崩溃。这为我们提供了一个关于负样本和SimSiam如何缓解崩溃的统一视角。这样的统一视角对于理解SSL的最新进展非常及时。",
        "领域": "自监督学习、对比学习、深度学习优化",
        "问题": "探索在没有负样本的情况下，SimSiam方法如何避免自监督学习中的模型崩溃问题。",
        "动机": "理解并解释SimSiam方法在没有使用负样本的情况下避免模型崩溃的机制，为自监督学习领域提供新的理论支持。",
        "方法": "通过向量分解和$l_2$归一化表示向量的梯度分析，提出一个统一视角来解释负样本和SimSiam方法如何缓解模型崩溃。",
        "关键词": [
            "自监督学习",
            "对比学习",
            "模型崩溃",
            "SimSiam",
            "梯度分析"
        ],
        "涉及的技术概念": {
            "自监督学习": "一种无需人工标注数据的学习范式，通过数据自身生成监督信号进行模型训练。",
            "对比学习": "通过比较样本间的相似性和差异性来学习有效表示的方法，常用于自监督学习。",
            "$l_2$归一化": "将向量除以其欧几里得范数，使其长度为1的过程，用于梯度分析和避免模型崩溃。"
        },
        "success": true
    },
    {
        "order": 433,
        "title": "How Do Vision Transformers Work?",
        "html": "https://iclr.cc//virtual/2022/poster/6017",
        "abstract": "The success of multi-head self-attentions (MSAs) for computer vision is now indisputable. However, little is known about how MSAs work. We present fundamental explanations to help better understand the nature of MSAs. In particular, we demonstrate the following properties of MSAs and Vision Transformers (ViTs): (1) MSAs improve not only accuracy but also generalization by flattening the loss landscapes. Such improvement is primarily attributable to their data specificity, not long-range dependency. On the other hand, ViTs suffer from non-convex losses. Large datasets and loss landscape smoothing methods alleviate this problem; (2) MSAs and Convs exhibit opposite behaviors. For example, MSAs are low-pass filters, but Convs are high-pass filters. Therefore, MSAs and Convs are complementary; (3) Multi-stage neural networks behave like a series connection of small individual models. In addition, MSAs at the end of a stage play a key role in prediction. Based on these insights, we propose AlterNet, a model in which Conv blocks at the end of a stage are replaced with MSA blocks. AlterNet outperforms CNNs not only in large data regimes but also in small data regimes. The code is available at https://github.com/xxxnell/how-do-vits-work.",
        "conference": "ICLR",
        "中文标题": "视觉变换器如何工作？",
        "摘要翻译": "多头自注意力机制（MSAs）在计算机视觉领域的成功现已毋庸置疑。然而，关于MSAs如何工作，人们知之甚少。我们提出了基本解释，以帮助更好地理解MSAs的本质。特别是，我们展示了MSAs和视觉变换器（ViTs）的以下属性：（1）MSAs不仅提高了准确性，还通过平坦化损失景观提高了泛化能力。这种改进主要归因于它们的数据特异性，而非长距离依赖性。另一方面，ViTs遭受非凸损失的问题。大型数据集和损失景观平滑方法缓解了这一问题；（2）MSAs和卷积（Convs）表现出相反的行为。例如，MSAs是低通滤波器，而Convs是高通滤波器。因此，MSAs和Convs是互补的；（3）多阶段神经网络的行为类似于一系列小型独立模型的串联。此外，阶段末端的MSAs在预测中扮演关键角色。基于这些见解，我们提出了AlterNet，一个在阶段末端用MSA块替换Conv块的模型。AlterNet不仅在大量数据情况下优于CNNs，在小数据情况下也是如此。代码可在https://github.com/xxxnell/how-do-vits-work获取。",
        "领域": "视觉变换器、多头自注意力机制、卷积神经网络",
        "问题": "理解多头自注意力机制（MSAs）和视觉变换器（ViTs）的工作原理及其在计算机视觉中的应用效果。",
        "动机": "探索MSAs和ViTs在计算机视觉中的工作机制，以优化模型设计和提高性能。",
        "方法": "通过分析MSAs和ViTs的属性，提出AlterNet模型，将阶段末端的卷积块替换为MSA块，以验证MSAs的有效性。",
        "关键词": [
            "视觉变换器",
            "多头自注意力机制",
            "卷积神经网络",
            "损失景观",
            "AlterNet"
        ],
        "涉及的技术概念": {
            "多头自注意力机制（MSAs）": "用于提高模型准确性和泛化能力的关键技术，通过平坦化损失景观实现。",
            "视觉变换器（ViTs）": "利用MSAs的变换器架构，用于计算机视觉任务，但面临非凸损失的问题。",
            "损失景观": "描述模型损失函数在不同参数下的表现，MSAs通过平坦化损失景观提高泛化能力。"
        },
        "success": true
    },
    {
        "order": 434,
        "title": "How Low Can We Go: Trading Memory for Error in Low-Precision Training",
        "html": "https://iclr.cc//virtual/2022/poster/6320",
        "abstract": "Low-precision arithmetic trains deep learning models using less energy, less memory and less time. However, we pay a price for the savings: lower precision may yield larger round-off error and hence larger prediction error. As applications proliferate, users must choose which precision to use to train a new model, and chip manufacturers must decide which precisions to manufacture. We view these precision choices as a hyperparameter tuning problem, and borrow ideas from meta-learning to learn the tradeoff between memory and error. In this paper, we introduce Pareto Estimation to Pick the Perfect Precision (PEPPP). We use matrix factorization to find non-dominated configurations (the Pareto frontier) with a limited number of network evaluations. For any given memory budget, the precision that minimizes error is a point on this frontier. Practitioners can use the frontier to trade memory for error and choose the best precision for their goals.",
        "conference": "ICLR",
        "中文标题": "我们能走多低：在低精度训练中以内存换取误差",
        "摘要翻译": "低精度算术使用更少的能量、内存和时间来训练深度学习模型。然而，我们为这种节省付出了代价：较低的精度可能会产生较大的舍入误差，从而导致较大的预测误差。随着应用的增多，用户必须选择使用哪种精度来训练新模型，芯片制造商也必须决定生产哪种精度。我们将这些精度选择视为超参数调整问题，并借鉴元学习的思想来学习内存和误差之间的权衡。在本文中，我们介绍了Pareto估计以选择完美精度（PEPPP）。我们使用矩阵分解来找到非支配配置（Pareto前沿），且仅需有限的网络评估次数。对于任何给定的内存预算，最小化误差的精度就是前沿上的一个点。从业者可以利用前沿来权衡内存和误差，并根据自己的目标选择最佳精度。",
        "领域": "深度学习优化, 低精度计算, 超参数调优",
        "问题": "如何在低精度训练中找到内存使用和预测误差之间的最佳平衡点",
        "动机": "随着深度学习应用的扩展，需要在减少计算资源消耗的同时，最小化因低精度计算带来的预测误差",
        "方法": "引入Pareto Estimation to Pick the Perfect Precision (PEPPP)方法，利用矩阵分解技术识别Pareto前沿，以有限的网络评估次数找到最优精度配置",
        "关键词": [
            "低精度训练",
            "Pareto前沿",
            "内存-误差权衡",
            "矩阵分解",
            "超参数调优"
        ],
        "涉及的技术概念": {
            "低精度算术": "用于减少深度学习模型训练过程中的能量、内存和时间消耗，但可能增加预测误差",
            "Pareto前沿": "通过矩阵分解技术识别，表示在给定内存预算下，能够最小化预测误差的最优精度配置集合",
            "超参数调优": "将精度选择视为超参数调整问题，借鉴元学习思想优化内存和误差之间的权衡"
        },
        "success": true
    },
    {
        "order": 435,
        "title": "How many degrees of freedom do we need to train deep networks: a loss landscape perspective",
        "html": "https://iclr.cc//virtual/2022/poster/6283",
        "abstract": "A variety of recent works, spanning pruning, lottery tickets, and training within random subspaces, have shown that deep neural networks can be trained using far fewer degrees of freedom than the total number of parameters. We analyze this phenomenon for random subspaces by first examining the success probability of hitting a training loss sublevel set when training within a random subspace of a given training dimensionality.  We find a sharp phase transition in the success probability from $0$ to $1$ as the training dimension surpasses a threshold. This threshold training dimension increases as the desired final loss decreases, but decreases as the initial loss decreases. We then theoretically explain the origin of this phase transition, and its dependence on initialization and final desired loss, in terms of properties of the high dimensional geometry of the loss landscape.  In particular, we show via Gordon's escape theorem, that the training dimension plus the Gaussian width of the desired loss sub-level set, projected onto a unit sphere surrounding the initialization, must exceed the total number of parameters for the success probability to be large.  In several architectures and datasets, we measure the threshold training dimension as a function of initialization and demonstrate that it is a small fraction of the total parameters, implying by our theory that successful training with so few dimensions is possible precisely because the Gaussian width of low loss sub-level sets is very large. Moreover, we compare this threshold training dimension to more sophisticated ways of reducing training degrees of freedom, including lottery tickets as well as a new, analogous method: lottery subspaces. ",
        "conference": "ICLR",
        "中文标题": "我们需要多少自由度来训练深度网络：从损失景观的视角",
        "摘要翻译": "近期的一系列工作，包括剪枝、彩票假设以及在随机子空间中的训练，已经表明深度神经网络可以使用远少于参数总数的自由度进行训练。我们通过首先检查在给定训练维度的随机子空间内训练时达到训练损失子水平集的成功概率，来分析这一现象。我们发现，当训练维度超过一个阈值时，成功概率会从0急剧转变为1。这个阈值训练维度随着期望的最终损失的减少而增加，但随着初始损失的减少而减少。然后，我们从理论上解释了这一相变的起源，以及它对初始化和最终期望损失的依赖性，这涉及到损失景观高维几何特性的属性。特别是，我们通过戈登的逃逸定理表明，训练维度加上期望损失子水平集的高斯宽度，投影到围绕初始化的单位球面上，必须超过参数总数，才能使成功概率较大。在几种架构和数据集中，我们测量了作为初始化函数的阈值训练维度，并证明它只占总参数的一小部分，这意味着根据我们的理论，使用如此少的维度成功训练正是因为低损失子水平集的高斯宽度非常大。此外，我们将这个阈值训练维度与更复杂的减少训练自由度的方法进行了比较，包括彩票假设以及一种新的类似方法：彩票子空间。",
        "领域": "深度学习理论、神经网络优化、损失景观分析",
        "问题": "深度神经网络训练所需的最小自由度数量及其与损失景观的关系",
        "动机": "探索深度神经网络在远少于总参数数量的自由度下成功训练的可能性及其理论基础",
        "方法": "通过分析随机子空间训练的成功概率及其与损失景观高维几何特性的关系，结合戈登的逃逸定理进行理论解释",
        "关键词": [
            "自由度",
            "损失景观",
            "高斯宽度",
            "彩票假设",
            "随机子空间"
        ],
        "涉及的技术概念": {
            "损失景观": "描述神经网络训练过程中损失函数随参数变化的几何形状，用于分析训练动态和优化难度",
            "高斯宽度": "衡量高维空间中集合复杂度的指标，用于分析损失子水平集的几何特性",
            "戈登的逃逸定理": "用于分析高维几何中随机子空间与固定集合相交概率的数学工具，支持理论分析"
        },
        "success": true
    },
    {
        "order": 436,
        "title": "How Much Can CLIP Benefit Vision-and-Language Tasks?",
        "html": "https://iclr.cc//virtual/2022/poster/6845",
        "abstract": "Most existing Vision-and-Language (V&L) models rely on pre-trained visual encoders, using a relatively small set of manually-annotated data (as compared to web-crawled data), to perceive the visual world. However, it has been observed that large-scale pretraining usually can result in better generalization performance, e.g., CLIP (Contrastive Language-Image Pre-training), trained on a massive amount of image-caption pairs, has shown a strong zero-shot capability on various vision tasks. To further study the advantage brought by CLIP, we propose to use CLIP as the visual encoder in various V&L models in two typical scenarios: 1) plugging CLIP into task-specific fine-tuning; 2) combining CLIP with V&L pre-training and transferring to downstream tasks. We show that CLIP significantly outperforms widely-used visual encoders trained with in-domain annotated data, such as BottomUp-TopDown. We achieve competitive or better results on diverse V&L tasks, while establishing new state-of-the-art results on Visual Question Answering, Visual Entailment, and V&L Navigation tasks.",
        "conference": "ICLR",
        "中文标题": "CLIP能在多大程度上惠及视觉与语言任务？",
        "摘要翻译": "大多数现有的视觉与语言（V&L）模型依赖于预训练的视觉编码器，使用相对较小规模的手工标注数据集（与网络爬取的数据相比）来感知视觉世界。然而，已经观察到，大规模预训练通常能够带来更好的泛化性能，例如，CLIP（对比性语言-图像预训练）在大量图像-标题对上训练后，在各种视觉任务上展现出了强大的零样本能力。为了进一步研究CLIP带来的优势，我们提出在两种典型场景中使用CLIP作为各种V&L模型的视觉编码器：1）将CLIP插入到特定任务的微调中；2）将CLIP与V&L预训练结合并迁移到下游任务。我们展示出，CLIP显著优于使用领域内标注数据训练的广泛使用的视觉编码器，如BottomUp-TopDown。我们在多种V&L任务上取得了竞争性或更好的结果，同时在视觉问答、视觉蕴含和V&L导航任务上建立了新的最先进成果。",
        "领域": "视觉问答、视觉蕴含、视觉与语言导航",
        "问题": "探索CLIP作为视觉编码器在视觉与语言任务中的优势和应用效果。",
        "动机": "研究大规模预训练模型CLIP在视觉与语言任务中的潜力，以提升模型性能和泛化能力。",
        "方法": "在两种场景中使用CLIP作为视觉编码器：任务特定微调和与V&L预训练结合迁移到下游任务。",
        "关键词": [
            "CLIP",
            "视觉与语言模型",
            "视觉编码器",
            "大规模预训练",
            "零样本学习"
        ],
        "涉及的技术概念": {
            "CLIP": "对比性语言-图像预训练模型，用于提升模型对视觉内容的理解和泛化能力。",
            "视觉编码器": "用于从视觉输入中提取特征的模型组件，CLIP在此作为更高效的替代方案。",
            "零样本能力": "模型在没有特定任务训练数据的情况下，能够理解和执行任务的能力。"
        },
        "success": true
    },
    {
        "order": 437,
        "title": "How to deal with missing data in supervised deep learning?",
        "html": "https://iclr.cc//virtual/2022/poster/5973",
        "abstract": "The issue of missing data in supervised learning has been largely overlooked, especially in the deep learning community. We investigate strategies to adapt neural architectures for handling missing values. Here, we focus on regression and classification problems where the features are assumed to be missing at random. Of particular interest are schemes that allow reusing as-is a neural discriminative architecture. To address supervised deep learning with missing values, we propose to marginalize over missing values in a joint model of covariates and outcomes. Thereby, we leverage both the flexibility of deep generative models to describe the distribution of the covariates and the power of purely discriminative models to make predictions. More precisely, a deep latent variable model can be learned jointly with the discriminative model, using importance-weighted variational inference, essentially using importance sampling to mimick averaging over multiple imputations. In low-capacity regimes, or when the discriminative model has a strong inductive bias, we find that our hybrid generative/discriminative approach generally outperforms single imputations methods.",
        "conference": "ICLR",
        "中文标题": "如何在监督式深度学习中处理缺失数据？",
        "摘要翻译": "监督学习中的缺失数据问题在很大程度上被忽视了，尤其是在深度学习领域。我们研究了调整神经架构以处理缺失值的策略。在此，我们关注于特征被假定为随机缺失的回归和分类问题。特别令人感兴趣的是那些允许直接重用神经判别架构的方案。为了解决带有缺失值的监督深度学习问题，我们提出在协变量和结果的联合模型中对缺失值进行边缘化处理。由此，我们既利用了深度生成模型描述协变量分布的灵活性，又发挥了纯判别模型进行预测的强大能力。更准确地说，可以使用重要性加权变分推断联合学习深度潜在变量模型和判别模型，本质上使用重要性采样来模拟对多重插补的平均。在低容量状态下，或者当判别模型具有强归纳偏置时，我们发现我们的混合生成/判别方法通常优于单一插补方法。",
        "领域": "缺失数据处理、监督学习、深度学习",
        "问题": "解决监督深度学习中缺失数据的问题",
        "动机": "深度学习领域中对缺失数据问题的研究不足，需要有效的方法来处理缺失值以提高模型的预测能力",
        "方法": "提出了一种混合生成/判别方法，通过在协变量和结果的联合模型中对缺失值进行边缘化处理，结合深度生成模型和判别模型的优势",
        "关键词": [
            "缺失数据",
            "监督学习",
            "深度学习",
            "边缘化处理",
            "混合模型"
        ],
        "涉及的技术概念": {
            "边缘化处理": "在联合模型中对缺失值进行边缘化处理，以利用生成模型描述数据分布",
            "重要性加权变分推断": "用于联合学习深度潜在变量模型和判别模型的技术，通过重要性采样模拟多重插补",
            "混合生成/判别方法": "结合生成模型和判别模型的优势，提高在缺失数据情况下的预测性能"
        },
        "success": true
    },
    {
        "order": 438,
        "title": "How to Inject Backdoors with Better Consistency: Logit Anchoring on Clean Data",
        "html": "https://iclr.cc//virtual/2022/poster/6256",
        "abstract": "Since training a large-scale backdoored model from scratch requires a large training dataset, several recent attacks have considered to inject backdoors into a trained clean model without altering model behaviors on the clean data. Previous work finds that backdoors can be injected into a trained clean model with Adversarial Weight Perturbation (AWP), which means the variation of parameters are small in backdoor learning. In this work, we observe an interesting phenomenon that the variations of parameters are always AWPs when tuning the trained clean model to inject backdoors. We further provide theoretical analysis to explain this phenomenon. We are the first to formulate the behavior of maintaining accuracy on clean data as the consistency of backdoored models, which includes both global consistency and instance-wise consistency. We extensively analyze the effects of AWPs on the consistency of backdoored models. In order to achieve better consistency, we propose a novel anchoring loss to anchor or freeze the model behaviors on the clean data, with a theoretical guarantee. ",
        "conference": "ICLR",
        "中文标题": "如何以更高一致性注入后门：基于干净数据的Logit锚定",
        "摘要翻译": "由于从头开始训练一个大规模的后门模型需要大量的训练数据，最近的几次攻击考虑在不改变模型在干净数据上行为的情况下，将后门注入到已训练的干净模型中。先前的工作发现，可以通过对抗性权重扰动（AWP）将后门注入到已训练的干净模型中，这意味着在后门学习中参数的变化很小。在这项工作中，我们观察到一个有趣的现象，即在调整已训练的干净模型以注入后门时，参数的变化总是AWP。我们进一步提供了理论分析来解释这一现象。我们是第一个将保持干净数据上准确性的行为表述为后门模型的一致性，包括全局一致性和实例级一致性。我们广泛分析了AWP对后门模型一致性的影响。为了实现更好的一致性，我们提出了一种新颖的锚定损失来锚定或冻结模型在干净数据上的行为，并提供了理论保证。",
        "领域": "深度学习安全、对抗性攻击、模型后门",
        "问题": "如何在保持模型在干净数据上性能的同时，有效地注入后门。",
        "动机": "研究如何在不需要大量训练数据的情况下，通过调整已训练模型来注入后门，同时保持模型在干净数据上的行为不变。",
        "方法": "提出了一种基于对抗性权重扰动（AWP）的后门注入方法，并通过理论分析和实验验证了其有效性；进一步提出了一种锚定损失来优化模型在干净数据上的行为一致性。",
        "关键词": [
            "后门攻击",
            "对抗性权重扰动",
            "模型一致性",
            "锚定损失",
            "深度学习安全"
        ],
        "涉及的技术概念": {
            "对抗性权重扰动（AWP）": "一种在后门学习中保持参数变化小的技术，用于在不显著改变模型在干净数据上行为的情况下注入后门。",
            "模型一致性": "指后门模型在干净数据上的行为与原始模型保持一致的能力，包括全局一致性和实例级一致性。",
            "锚定损失": "一种新颖的损失函数，用于在训练过程中锚定或冻结模型在干净数据上的行为，以提高后门模型的一致性。"
        },
        "success": true
    },
    {
        "order": 439,
        "title": "How to Robustify Black-Box ML Models? A Zeroth-Order Optimization Perspective",
        "html": "https://iclr.cc//virtual/2022/poster/6612",
        "abstract": "The lack of adversarial robustness has been recognized as an important issue for state-of-the-art machine learning (ML) models, e.g., deep neural networks (DNNs). Thereby, robustifying ML models against adversarial attacks is now a major focus of research. However, nearly all existing defense methods, particularly for robust training, made the white-box assumption that the defender has the access to the details of an ML model (or its surrogate alternatives if available), e.g., its architectures and parameters. Beyond existing works, in this paper we aim to address the problem of black-box defense: How to robustify a black-box model using just input queries and output feedback? Such a problem arises in practical scenarios, where the owner of the predictive model is reluctant to share model information in order to preserve privacy. To this end, we propose a general notion of defensive operation that can be applied to black-box models, and design it through the lens of denoised smoothing (DS), a ﬁrst-order (FO) certiﬁed defense technique. To allow the design of merely using model queries, we further integrate DS with the zeroth-order (gradient-free) optimization. However, a direct implementation of zeroth-order (ZO) optimization suffers a high variance of gradient estimates, and thus leads to ineffective defense. To tackle this problem, we next propose to prepend an autoencoder (AE) to a given (black-box) model so that DS can be trained using variance-reduced ZO optimization. We term the eventual defense as ZO-AE-DS. In practice, we empirically show that ZO-AE-DS can achieve improved accuracy, certiﬁed robustness, and query complexity over existing baselines. And the effectiveness of our approach is justiﬁed under both image classiﬁcation and image reconstruction tasks.",
        "conference": "ICLR",
        "中文标题": "如何强化黑盒机器学习模型的鲁棒性？零阶优化视角",
        "摘要翻译": "对抗性鲁棒性的缺乏已被认为是当前最先进的机器学习（ML）模型，如深度神经网络（DNNs）的一个重要问题。因此，强化ML模型以抵御对抗性攻击现在成为研究的主要焦点。然而，几乎所有现有的防御方法，特别是鲁棒训练，都基于白盒假设，即防御者可以访问ML模型（或其替代品，如果可用）的详细信息，例如其架构和参数。在现有工作之外，本文旨在解决黑盒防御问题：如何仅使用输入查询和输出反馈来强化黑盒模型？这种问题在实际场景中出现，其中预测模型的所有者不愿分享模型信息以保护隐私。为此，我们提出了一种可以应用于黑盒模型的防御操作的一般概念，并通过去噪平滑（DS）这一一阶（FO）认证防御技术的视角来设计它。为了仅使用模型查询进行设计，我们进一步将DS与零阶（无梯度）优化相结合。然而，零阶（ZO）优化的直接实现遭受梯度估计的高方差，从而导致防御效果不佳。为了解决这个问题，我们接下来提出在给定（黑盒）模型前添加一个自动编码器（AE），以便可以使用方差减少的ZO优化来训练DS。我们最终将这种防御称为ZO-AE-DS。在实践中，我们经验性地表明，ZO-AE-DS在准确性、认证鲁棒性和查询复杂性方面优于现有基线。我们的方法的有效性在图像分类和图像重建任务下得到了验证。",
        "领域": "对抗性防御、图像分类、图像重建",
        "问题": "如何在不访问模型内部信息的情况下，提高黑盒机器学习模型对抗对抗性攻击的鲁棒性。",
        "动机": "在实际应用中，模型所有者可能不愿分享模型细节以保护隐私，因此需要开发不依赖模型内部信息的防御方法。",
        "方法": "提出了一种结合去噪平滑（DS）和零阶优化（ZO）的方法，并通过在模型前添加自动编码器（AE）来减少ZO优化的方差，最终形成ZO-AE-DS防御策略。",
        "关键词": [
            "黑盒防御",
            "零阶优化",
            "去噪平滑",
            "自动编码器",
            "对抗性鲁棒性"
        ],
        "涉及的技术概念": {
            "去噪平滑（DS）": "一种一阶认证防御技术，用于提高模型对抗对抗性攻击的鲁棒性。",
            "零阶优化（ZO）": "一种无梯度的优化方法，适用于无法直接访问模型梯度的情况。",
            "自动编码器（AE）": "用于减少零阶优化过程中的梯度估计方差，提高防御效果。"
        },
        "success": true
    },
    {
        "order": 440,
        "title": "How to Train Your MAML to Excel in Few-Shot Classification",
        "html": "https://iclr.cc//virtual/2022/poster/6294",
        "abstract": "Model-agnostic meta-learning (MAML) is arguably one of the most popular meta-learning algorithms nowadays.Nevertheless, its performance on few-shot classification is far behind many recent algorithms dedicated to the problem. In this paper, we point out several key facets of how to train MAML to excel in few-shot classification. First, we find that MAML needs a large number of gradient steps in its inner loop update, which contradicts its common usage in few-shot classification. Second, we find that MAML is sensitive to the class label assignments during meta-testing. Concretely, MAML meta-trains the initialization of an $N$-way classifier. These $N$ ways, during meta-testing, then have '$N!$' different permutations to be paired with a few-shot task of $N$ novel classes. We find that these permutations lead to a huge variance of accuracy, making MAML unstable in few-shot classification. Third, we investigate several approaches to make MAML permutation-invariant, among which meta-training a single vector to initialize all the $N$ weight vectors in the classification head performs the best. On benchmark datasets like MiniImageNet and TieredImageNet, our approach, which we name UNICORN-MAML, performs on a par with or even outperforms many recent few-shot classification algorithms, without sacrificing MAML's simplicity.",
        "conference": "ICLR",
        "中文标题": "如何训练您的MAML在少样本分类中表现出色",
        "摘要翻译": "模型无关的元学习（MAML）可以说是当今最流行的元学习算法之一。然而，其在少样本分类上的表现远远落后于许多专门针对该问题的近期算法。在本文中，我们指出了如何训练MAML以在少样本分类中表现出色的几个关键方面。首先，我们发现MAML在其内部循环更新中需要大量的梯度步骤，这与其在少样本分类中的常见用法相矛盾。其次，我们发现MAML对元测试期间的类别标签分配敏感。具体来说，MAML元训练一个$N$路分类器的初始化。在元测试期间，这些$N$路然后有'$N!$'种不同的排列方式与$N$个新类别的少样本任务配对。我们发现这些排列导致准确率的巨大差异，使得MAML在少样本分类中不稳定。第三，我们研究了几种使MAML排列不变的方法，其中元训练一个单一向量以初始化分类头中的所有$N$个权重向量的方法表现最佳。在MiniImageNet和TieredImageNet等基准数据集上，我们的方法（我们称之为UNICORN-MAML）与许多最近的少样本分类算法表现相当甚至更优，而不牺牲MAML的简单性。",
        "领域": "元学习、少样本学习、图像分类",
        "问题": "提高MAML在少样本分类任务中的性能和稳定性",
        "动机": "MAML在少样本分类中的表现不佳，需要改进其训练方法和稳定性",
        "方法": "通过增加内部循环的梯度步骤、解决类别标签分配的敏感性问题，以及使MAML排列不变，来提高其在少样本分类中的表现",
        "关键词": [
            "MAML",
            "少样本分类",
            "元学习",
            "排列不变性",
            "UNICORN-MAML"
        ],
        "涉及的技术概念": {
            "模型无关的元学习（MAML）": "一种流行的元学习算法，旨在通过少量样本快速适应新任务",
            "少样本分类": "一种机器学习任务，旨在使用非常有限的样本进行有效的分类",
            "排列不变性": "在本文中指MAML对类别标签排列的不敏感性，通过特定方法实现以提高模型稳定性"
        },
        "success": true
    },
    {
        "order": 441,
        "title": "How unlabeled data improve generalization in self-training? A one-hidden-layer theoretical analysis",
        "html": "https://iclr.cc//virtual/2022/poster/6549",
        "abstract": "Self-training, a semi-supervised learning algorithm, leverages a large amount of unlabeled data to improve learning when the labeled data are limited. Despite empirical successes, its theoretical characterization remains elusive. To the best of our knowledge, this work establishes the first theoretical analysis for the known iterative self-training paradigm and formally proves the benefits of unlabeled data in both training convergence and generalization ability. To make our theoretical analysis feasible, we focus on the case of one-hidden-layer neural networks. However, theoretical understanding of iterative self-training is non-trivial even for a shallow neural network. One of the key challenges is that existing neural network landscape analysis built upon supervised learning no longer holds in the (semi-supervised) self-training paradigm. We address this challenge and prove that iterative self-training converges linearly with both convergence rate and generalization accuracy improved in the order of $1/\\sqrt{M}$, where $M$ is the number of unlabeled samples. Extensive experiments from shallow neural networks to deep neural networks are also provided to justify the correctness of our established theoretical insights on self-training.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "无标签数据如何在自训练中提高泛化能力？单隐层理论分析",
        "摘要翻译": "自训练是一种半监督学习算法，它利用大量的无标签数据来改进在有标签数据有限情况下的学习效果。尽管在实践中取得了成功，但其理论特性仍然难以捉摸。据我们所知，这项工作首次建立了对已知迭代自训练范式的理论分析，并正式证明了无标签数据在训练收敛性和泛化能力方面的优势。为了使我们的理论分析可行，我们专注于单隐层神经网络的情况。然而，即使对于一个浅层神经网络来说，迭代自训练的理论理解也是非常重要的。其中一个关键挑战是，现有的基于监督学习的神经网络景观分析在（半监督）自训练范式中不再适用。我们解决了这个挑战，并证明迭代自训练线性收敛，收敛速度和泛化精度都以$1/\\\\sqrt{M}$的量级提高，其中$M$是无标签样本的数量。我们还提供了从浅层神经网络到深度神经网络的大量实验，以证明我们对自训练的既定理论见解的正确性。",
        "领域": "半监督学习, 神经网络理论分析, 模型泛化",
        "问题": "如何在理论上证明自训练算法利用无标签数据提高模型泛化能力和训练收敛性的有效性，尤其是在神经网络模型中？",
        "动机": "尽管自训练算法在实践中被广泛应用，并取得了经验上的成功，但其背后的理论基础和无标签数据带来的好处尚未得到充分的理论解释和证明。",
        "方法": "通过对单隐层神经网络的迭代自训练过程进行理论分析，建立了收敛性和泛化能力的数学模型。并通过实验验证理论分析的正确性。",
        "关键词": [
            "自训练",
            "半监督学习",
            "泛化能力",
            "理论分析",
            "神经网络"
        ],
        "涉及的技术概念": {
            "自训练": "一种半监督学习方法，使用模型对无标签数据进行预测，并将置信度高的预测结果作为伪标签加入训练集，以提高模型性能。",
            "泛化能力": "模型在未见过的数据上的表现能力，衡量模型从训练数据中学到的知识推广到新数据的程度。"
        }
    },
    {
        "order": 442,
        "title": "How Well Does Self-Supervised Pre-Training Perform with Streaming Data?",
        "html": "https://iclr.cc//virtual/2022/poster/5967",
        "abstract": "Prior works on self-supervised pre-training focus on the joint training scenario, where massive unlabeled data are assumed to be given as input all at once, and only then is a learner trained. Unfortunately, such a problem setting is often impractical if not infeasible since many real-world tasks rely on sequential learning, e.g., data are decentralized or collected in a streaming fashion. In this paper, we conduct the first thorough and dedicated investigation on self-supervised pre-training with streaming data, aiming to shed light on the model behavior under this overlooked setup. Specifically, we pre-train over 500 models on four categories of pre-training streaming data from ImageNet and DomainNet and evaluate them on three types of downstream tasks and 12 different downstream datasets. Our studies show that, somehow beyond our expectation, with simple data replay or parameter regularization, sequential self-supervised pre-training turns out to be an efficient alternative for joint pre-training, as the performances of the former are mostly on par with those of the latter. Moreover, catastrophic forgetting, a common issue in sequential supervised learning, is much alleviated in sequential self-supervised learning (SSL), which is well justified through our comprehensive empirical analysis on representations and the sharpness of minima in the loss landscape. Our findings, therefore, suggest that, in practice, for SSL, the cumbersome joint training can be replaced mainly by sequential learning, which in turn enables a much broader spectrum of potential application scenarios. ",
        "conference": "ICLR",
        "中文标题": "自监督预训练在流式数据上的表现如何？",
        "摘要翻译": "以往关于自监督预训练的研究主要集中在联合训练场景，即假设大量未标记数据一次性全部输入，然后才训练学习器。然而，这样的问题设置往往不切实际，因为许多现实世界的任务依赖于顺序学习，例如数据是分散的或以流式方式收集的。在本文中，我们首次对使用流式数据进行自监督预训练进行了全面而专注的调查，旨在揭示在这种被忽视的设置下模型的行为。具体来说，我们在来自ImageNet和DomainNet的四类预训练流式数据上预训练了超过500个模型，并在三种类型的下游任务和12个不同的下游数据集上进行了评估。我们的研究表明，出乎意料的是，通过简单的数据回放或参数正则化，顺序自监督预训练成为了联合预训练的有效替代方案，因为前者的性能大多与后者相当。此外，在顺序监督学习中常见的灾难性遗忘问题，在顺序自监督学习（SSL）中得到了很大缓解，这一点通过对表示和损失景观中极小值的锐度的全面实证分析得到了很好的证明。因此，我们的发现表明，在实践中，对于SSL，繁琐的联合训练可以主要由顺序学习替代，这反过来又为潜在的应用场景提供了更广泛的可能。",
        "领域": "自监督学习、流式学习、深度学习预训练",
        "问题": "自监督预训练在流式数据上的有效性和可行性问题",
        "动机": "探索在现实世界中更常见的流式数据场景下自监督预训练的表现，以替代传统的联合训练方法",
        "方法": "通过在ImageNet和DomainNet上的四类流式数据预训练超过500个模型，并在多种下游任务和数据集上评估，比较顺序自监督预训练与联合预训练的性能差异",
        "关键词": [
            "自监督学习",
            "流式数据",
            "顺序学习",
            "预训练",
            "灾难性遗忘"
        ],
        "涉及的技术概念": {
            "自监督预训练": "在没有人工标注的情况下，利用数据本身的结构进行预训练，为下游任务提供更好的初始模型",
            "流式数据": "数据以连续流的形式到达，需要模型能够实时或近实时地处理和学习",
            "灾难性遗忘": "在学习新任务时，模型忘记之前学到的知识，这在顺序学习中是一个常见问题"
        },
        "success": true
    },
    {
        "order": 443,
        "title": "HTLM: Hyper-Text Pre-Training and Prompting of Language Models",
        "html": "https://iclr.cc//virtual/2022/poster/6281",
        "abstract": "<div><p>We introduce HTLM, a hyper-text language model trained on a large-scale web crawl. Modeling hyper-text has a number of advantages: (1) it is easily gathered at scale, (2) it provides rich document-level and end-task-adjacent supervision (e.g. 'class' and 'id' attributes often encode document category information), and (3) it allows for new structured prompting that follows the established semantics of HTML (e.g. to do zero-shot summarization by infilling '</p>' tags for a webpage that contains the input text).  We show that pretraining with a BART-style denoising loss directly on simplified HTML provides highly effective transfer for a wide range of end tasks and supervision levels. HTLM matches or exceeds the performance of comparably sized text-only LMs for zero-shot prompting and fine-tuning for classification benchmarks, while also setting new state-of-the-art performance levels for zero-shot summarization. We also find that hyper-text prompts provide more value to HTLM, in terms of data efficiency, than plain text prompts do for existing LMs, and that HTLM is highly effective at auto-prompting itself, by simply generating the most likely hyper-text formatting for any available training data. We will release all code and models to support future HTLM research. </div>",
        "conference": "ICLR",
        "中文标题": "HTLM：超文本语言模型的预训练与提示",
        "摘要翻译": "我们介绍了HTLM，一种基于大规模网络爬取数据训练的超文本语言模型。建模超文本具有多项优势：（1）易于大规模收集，（2）提供丰富的文档级和接近最终任务的监督（例如，'class'和'id'属性通常编码文档类别信息），以及（3）允许遵循HTML既定语义的新结构化提示（例如，通过为包含输入文本的网页填充'</p>'标签来进行零样本摘要）。我们表明，直接在简化的HTML上使用BART风格的去噪损失进行预训练，为广泛的最终任务和监督级别提供了高效的迁移。HTLM在零样本提示和分类基准的微调方面，匹配或超过了同等规模的纯文本语言模型的性能，同时在零样本摘要方面设定了新的最先进性能水平。我们还发现，就数据效率而言，超文本提示为HTLM提供的价值，比纯文本提示为现有语言模型提供的更多，并且HTLM通过简单地为任何可用训练数据生成最可能的超文本格式，在自动提示自身方面非常有效。我们将发布所有代码和模型以支持未来的HTLM研究。",
        "领域": "自然语言处理与视觉结合",
        "问题": "如何有效利用超文本信息提升语言模型的预训练和提示效率",
        "动机": "探索超文本在语言模型预训练和提示中的应用，以提高模型性能和效率",
        "方法": "使用BART风格的去噪损失在简化的HTML上进行预训练，并利用超文本的结构化提示进行零样本学习和自动提示",
        "关键词": [
            "超文本语言模型",
            "预训练",
            "零样本学习",
            "结构化提示",
            "自动提示"
        ],
        "涉及的技术概念": {
            "超文本语言模型": "一种利用HTML等超文本信息进行预训练的语言模型，旨在提升模型理解和生成结构化文本的能力",
            "BART风格去噪损失": "一种预训练目标，通过重构被噪声干扰的输入文本来学习语言表示",
            "结构化提示": "利用HTML等结构化信息的提示方法，以提高模型在特定任务上的零样本学习能力"
        },
        "success": true
    },
    {
        "order": 444,
        "title": "Huber Additive Models for Non-stationary Time Series Analysis",
        "html": "https://iclr.cc//virtual/2022/poster/6601",
        "abstract": "Sparse additive models have shown promising ﬂexibility and interpretability in processing time series data. However, existing methods usually assume the time series data to be stationary and the innovation is sampled from a Gaussian distribution. Both assumptions are too stringent for heavy-tailed and non-stationary time series data that frequently arise in practice, such as ﬁnance and medical ﬁelds. To address these problems, we propose an adaptive sparse Huber additive model for robust forecasting in both non-Gaussian data and (non)stationary data. In theory, the generalization bounds of our estimator are established for both stationary and nonstationary time series data, which are independent of the widely used mixing conditions in learning theory of dependent observations. Moreover, the error bound for non-stationary time series contains a discrepancy measure for the shifts of the data distributions over time. Such a discrepancy measure can be estimated empirically and used as a penalty in our method. Experimental results on both synthetic and real-world benchmark datasets validate the effectiveness of the proposed method. The code is available at https://github.com/xianruizhong/SpHAM.",
        "conference": "ICLR",
        "中文标题": "Huber加性模型在非平稳时间序列分析中的应用",
        "摘要翻译": "稀疏加性模型在处理时间序列数据时展现了良好的灵活性和可解释性。然而，现有方法通常假设时间序列数据是平稳的，且创新项服从高斯分布。这两个假设对于实践中经常出现的重尾和非平稳时间序列数据（如金融和医疗领域）来说过于严格。为了解决这些问题，我们提出了一种自适应稀疏Huber加性模型，用于在非高斯数据和（非）平稳数据中进行稳健预测。理论上，我们为平稳和非平稳时间序列数据建立了估计器的泛化边界，这些边界独立于依赖观测学习理论中广泛使用的混合条件。此外，非平稳时间序列的误差边界包含了一个用于衡量数据分布随时间变化的差异度量。这种差异度量可以经验性地估计，并在我们的方法中用作惩罚项。在合成和真实世界基准数据集上的实验结果验证了所提方法的有效性。代码可在https://github.com/xianruizhong/SpHAM获取。",
        "领域": "时间序列分析、金融数据分析、医疗数据分析",
        "问题": "解决在重尾和非平稳时间序列数据中现有稀疏加性模型假设过于严格的问题",
        "动机": "为了在非高斯和非平稳时间序列数据中实现更稳健的预测",
        "方法": "提出自适应稀疏Huber加性模型，建立估计器的泛化边界，并使用差异度量作为惩罚项",
        "关键词": [
            "稀疏加性模型",
            "Huber损失",
            "非平稳时间序列"
        ],
        "涉及的技术概念": {
            "稀疏加性模型": "用于处理时间序列数据，提供灵活性和可解释性",
            "Huber损失": "用于在非高斯数据中实现稳健预测",
            "泛化边界": "为平稳和非平稳时间序列数据建立的理论保证"
        },
        "success": true
    },
    {
        "order": 445,
        "title": "HyAR: Addressing Discrete-Continuous Action Reinforcement Learning via Hybrid Action Representation",
        "html": "https://iclr.cc//virtual/2022/poster/6794",
        "abstract": "Discrete-continuous hybrid action space is a natural setting in many practical problems, such as robot control and game AI. However, most previous Reinforcement Learning (RL) works only demonstrate the success in controlling with either discrete or continuous action space, while seldom take into account the hybrid action space. One naive way to address hybrid action RL is to convert the hybrid action space into a unified homogeneous action space by discretization or continualization, so that conventional RL algorithms can be applied. However, this ignores the underlying structure of hybrid action space and also induces the scalability issue and additional approximation difficulties, thus leading to degenerated results. In this paper, we propose Hybrid Action Representation (HyAR) to learn a compact and decodable latent representation space for the original hybrid action space. HyAR constructs the latent space and embeds the dependence between discrete action and continuous parameter via an embedding table and conditional Variantional Auto-Encoder (VAE). To further improve the effectiveness, the action representation is trained to be semantically smooth through unsupervised environmental dynamics prediction. Finally, the agent then learns its policy with conventional DRL algorithms in the learned representation space and interacts with the environment by decoding the hybrid action embeddings to the original action space. We evaluate HyAR in a variety of environments with discrete-continuous action space. The results demonstrate the superiority of HyAR when compared with previous baselines, especially for high-dimensional action spaces.",
        "conference": "ICLR",
        "中文标题": "HyAR：通过混合动作表示解决离散-连续动作强化学习问题",
        "摘要翻译": "离散-连续混合动作空间在许多实际问题中是一种自然设置，如机器人控制和游戏AI。然而，大多数先前的强化学习（RL）工作仅展示了在离散或连续动作空间中控制的成功，而很少考虑到混合动作空间。解决混合动作RL的一种简单方法是通过离散化或连续化将混合动作空间转换为统一的同质动作空间，从而可以应用传统的RL算法。然而，这忽略了混合动作空间的基本结构，并引发了可扩展性问题和额外的近似困难，从而导致结果退化。在本文中，我们提出了混合动作表示（HyAR）来为原始混合动作空间学习一个紧凑且可解码的潜在表示空间。HyAR通过嵌入表和条件变分自编码器（VAE）构建潜在空间并嵌入离散动作和连续参数之间的依赖关系。为了进一步提高有效性，动作表示通过无监督环境动态预测被训练为语义平滑的。最后，代理在学习的表示空间中使用传统的DRL算法学习其策略，并通过将混合动作嵌入解码回原始动作空间与环境交互。我们在具有离散-连续动作空间的各种环境中评估HyAR。结果表明，与之前的基线相比，HyAR具有优越性，特别是对于高维动作空间。",
        "领域": "强化学习、机器人控制、游戏AI",
        "问题": "解决在离散-连续混合动作空间中进行有效强化学习的问题",
        "动机": "现有的强化学习方法大多仅适用于纯离散或纯连续动作空间，忽视了混合动作空间的自然设置和结构，导致在实际应用中效果不佳",
        "方法": "提出混合动作表示（HyAR），通过嵌入表和条件变分自编码器构建潜在表示空间，结合无监督环境动态预测训练语义平滑的动作表示，最后在潜在空间中使用传统DRL算法学习策略",
        "关键词": [
            "混合动作表示",
            "强化学习",
            "变分自编码器",
            "机器人控制",
            "游戏AI"
        ],
        "涉及的技术概念": {
            "混合动作表示（HyAR）": "为原始混合动作空间学习一个紧凑且可解码的潜在表示空间，以解决离散和连续动作空间的混合问题",
            "条件变分自编码器（VAE）": "用于构建潜在空间并嵌入离散动作和连续参数之间的依赖关系",
            "无监督环境动态预测": "用于训练动作表示，使其语义平滑，提高强化学习的效果"
        },
        "success": true
    },
    {
        "order": 446,
        "title": "Hybrid Local SGD for Federated Learning with Heterogeneous Communications",
        "html": "https://iclr.cc//virtual/2022/poster/6077",
        "abstract": "Communication is a key bottleneck in federated learning where a large number of edge devices collaboratively learn a model under the orchestration of a central server without sharing their own training data. While local SGD has been proposed to reduce the number of FL rounds and become the algorithm of choice for FL, its total communication cost is still prohibitive when each device needs to communicate with the remote server repeatedly for many times over bandwidth-limited networks. In light of both device-to-device (D2D) and device-to-server (D2S) cooperation opportunities in modern communication networks, this paper proposes a new federated optimization algorithm dubbed hybrid local SGD (HL-SGD) in FL settings where devices are grouped into a set of disjoint clusters with high D2D communication bandwidth. HL-SGD subsumes previous proposed algorithms such as local SGD and gossip SGD and enables us to strike the best balance between model accuracy and runtime. We analyze the convergence of HL-SGD in the presence of heterogeneous data for general nonconvex settings. We also perform extensive experiments and show that the use of hybrid model aggregation via D2D and D2S communications in HL-SGD can largely speed up the training time of federated learning. ",
        "conference": "ICLR",
        "中文标题": "混合本地随机梯度下降在异构通信联邦学习中的应用",
        "摘要翻译": "通信是联邦学习中的一个关键瓶颈，其中大量边缘设备在中央服务器的协调下协作学习一个模型，而不共享自己的训练数据。虽然本地随机梯度下降（SGD）被提出来减少联邦学习的轮数，并成为联邦学习的首选算法，但当每个设备需要在带宽有限的网络上多次与远程服务器通信时，其总通信成本仍然令人望而却步。鉴于现代通信网络中设备到设备（D2D）和设备到服务器（D2S）的合作机会，本文提出了一种新的联邦优化算法，称为混合本地SGD（HL-SGD），在联邦学习设置中，设备被分组到一组具有高D2D通信带宽的不相交集群中。HL-SGD包含了先前提出的算法，如本地SGD和八卦SGD，并使我们能够在模型准确性和运行时间之间取得最佳平衡。我们分析了在一般非凸设置下，HL-SGD在异构数据存在下的收敛性。我们还进行了大量实验，并表明在HL-SGD中通过D2D和D2S通信使用混合模型聚合可以大大加快联邦学习的训练时间。",
        "领域": "联邦学习",
        "问题": "减少联邦学习中的通信成本和加速训练时间",
        "动机": "利用现代通信网络中的D2D和D2S合作机会，优化联邦学习的通信效率和训练速度",
        "方法": "提出混合本地SGD（HL-SGD）算法，结合D2D和D2S通信，优化模型聚合过程",
        "关键词": [
            "联邦学习",
            "本地SGD",
            "D2D通信",
            "D2S通信",
            "模型聚合"
        ],
        "涉及的技术概念": {
            "本地SGD": "用于减少联邦学习中的通信轮数，通过在本地进行多次梯度下降更新",
            "D2D通信": "设备间直接通信，用于在集群内部快速交换模型更新",
            "D2S通信": "设备与服务器间的通信，用于全局模型聚合和更新"
        },
        "success": true
    },
    {
        "order": 447,
        "title": "Hybrid Memoised Wake-Sleep: Approximate Inference at the Discrete-Continuous Interface",
        "html": "https://iclr.cc//virtual/2022/poster/6869",
        "abstract": "Modeling complex phenomena typically involves the use of both discrete and continuous variables. Such a setting applies across a wide range of problems, from identifying trends in time-series data to performing effective compositional scene understanding in images. Here, we propose Hybrid Memoised Wake-Sleep (HMWS), an algorithm for effective inference in such hybrid discrete-continuous models. Prior approaches to learning suffer as they need to perform repeated expensive inner-loop discrete inference. We build on a recent approach, Memoised Wake-Sleep (MWS), which alleviates part of the problem by memoising discrete variables, and extend it to allow for a principled and effective way to handle continuous variables by learning a separate recognition model used for importance-sampling based approximate inference and marginalization. We evaluate HMWS in the GP-kernel learning and 3D scene understanding domains, and show that it outperforms current state-of-the-art inference methods.",
        "conference": "ICLR",
        "中文标题": "混合记忆唤醒-睡眠算法：离散-连续界面的近似推理",
        "摘要翻译": "建模复杂现象通常涉及使用离散和连续变量。这种设置适用于从识别时间序列数据中的趋势到在图像中进行有效的组合场景理解等广泛问题。在此，我们提出了混合记忆唤醒-睡眠算法（HMWS），一种在此类混合离散-连续模型中进行有效推理的算法。先前学习方法的问题在于它们需要执行重复昂贵的内部循环离散推理。我们基于最近的一种方法——记忆唤醒-睡眠算法（MWS），通过记忆离散变量来部分缓解问题，并将其扩展以允许通过学习一个单独用于基于重要性采样的近似推理和边缘化的识别模型，来处理连续变量。我们在GP核学习和3D场景理解领域评估了HMWS，并显示其优于当前最先进的推理方法。",
        "领域": "概率图模型, 机器学习, 计算机视觉",
        "问题": "在混合离散-连续变量模型中实现有效推理",
        "动机": "解决现有方法在混合离散-连续变量模型中推理效率低下的问题",
        "方法": "扩展记忆唤醒-睡眠算法，引入单独识别模型处理连续变量，实现基于重要性采样的近似推理和边缘化",
        "关键词": [
            "混合模型",
            "近似推理",
            "记忆唤醒-睡眠算法",
            "重要性采样",
            "3D场景理解"
        ],
        "涉及的技术概念": {
            "记忆唤醒-睡眠算法": "一种通过记忆离散变量来优化推理过程的技术",
            "重要性采样": "用于近似推理和边缘化的技术，通过从提议分布中采样来估计目标分布",
            "混合离散-连续模型": "结合离散和连续变量的模型，用于建模复杂现象"
        },
        "success": true
    },
    {
        "order": 448,
        "title": "Hybrid Random Features",
        "html": "https://iclr.cc//virtual/2022/poster/6410",
        "abstract": "We propose a new class of random feature methods for linearizing softmax and Gaussian kernels called hybrid random features (HRFs) that automatically adapt the quality of kernel estimation to provide most accurate approximation in the defined regions of interest. Special instantiations of HRFs lead to well-known methods such as trigonometric (Rahimi & Recht, 2007) or (recently introduced in the context of linear-attention Transformers) positive random features (Choromanski et al., 2021). By generalizing Bochner’s Theorem for softmax/Gaussian kernels and leveraging random features for compositional kernels, the HRF-mechanism provides strong theoretical guarantees - unbiased approximation and strictly smaller worst-case relative errors than its counterparts.  We conduct exhaustive empirical evaluation of HRF ranging from pointwise kernel estimation experiments, through tests on data admitting clustering structure to benchmarking implicit-attention Transformers (also for downstream Robotics applications), demonstrating its quality in a wide spectrum of machine learning problems.",
        "conference": "ICLR",
        "中文标题": "混合随机特征",
        "摘要翻译": "我们提出了一类新的随机特征方法，用于线性化softmax和高斯核，称为混合随机特征（HRFs），该方法自动调整核估计的质量，以在定义的感兴趣区域提供最准确的近似。HRFs的特殊实例化导致了众所周知的方法，如三角随机特征（Rahimi & Recht, 2007）或在线性注意力Transformer背景下最近引入的正随机特征（Choromanski et al., 2021）。通过推广softmax/高斯核的Bochner定理，并利用组合核的随机特征，HRF机制提供了强有力的理论保证——无偏近似和比其对应方法严格更小的最坏情况相对误差。我们对HRF进行了全面的实证评估，从点态核估计实验，到对具有聚类结构的数据的测试，再到基准测试隐式注意力Transformer（也包括下游机器人应用），证明了其在广泛的机器学习问题中的质量。",
        "领域": "核方法",
        "问题": "如何在线性化softmax和高斯核的同时，自动调整核估计的质量以在感兴趣区域提供最准确的近似",
        "动机": "开发一种能够自动适应核估计质量，提供更准确近似的新随机特征方法",
        "方法": "通过推广Bochner定理和利用组合核的随机特征，提出混合随机特征（HRFs）方法",
        "关键词": [
            "混合随机特征",
            "核方法",
            "线性化",
            "softmax核",
            "高斯核"
        ],
        "涉及的技术概念": {
            "混合随机特征（HRFs）": "一种新的随机特征方法，用于线性化softmax和高斯核，自动调整核估计的质量",
            "Bochner定理": "用于推广softmax/高斯核的理论基础",
            "组合核的随机特征": "利用随机特征技术处理组合核，以提供无偏近似和更小的最坏情况相对误差"
        },
        "success": true
    },
    {
        "order": 449,
        "title": "HyperDQN: A Randomized Exploration Method for Deep Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6658",
        "abstract": "Randomized least-square value iteration (RLSVI) is a provably efficient exploration method. However, it is limited to the case where (1) a good feature is known in advance and (2) this feature is fixed during the training. If otherwise, RLSVI suffers an unbearable computational burden to obtain the posterior samples. In this work, we present a practical algorithm named HyperDQN to address the above issues under deep RL. In addition to a non-linear neural network (i.e., base model) that predicts Q-values, our method employs a probabilistic hypermodel (i.e., meta model), which outputs the parameter of the base model. When both models are jointly optimized under a specifically designed objective, three purposes can be achieved. First, the hypermodel can generate approximate posterior samples regarding the parameter of the Q-value function. As a result, diverse Q-value functions are sampled to select exploratory action sequences. This retains the punchline of RLSVI for efficient exploration. Second, a good feature is learned to approximate Q-value functions. This addresses limitation (1). Third, the posterior samples of the Q-value function can be obtained in a more efficient way than the existing methods, and the changing feature does not affect the efficiency. This deals with limitation (2). On the Atari suite, HyperDQN with 20M frames outperforms DQN with 200M frames in terms of the maximum human-normalized score. For SuperMarioBros, HyperDQN outperforms several exploration bonus and randomized exploration methods on 5 out of 9 games.",
        "conference": "ICLR",
        "中文标题": "HyperDQN：一种深度强化学习的随机探索方法",
        "摘要翻译": "随机最小二乘价值迭代（RLSVI）是一种理论上高效的探索方法。然而，它仅限于以下情况：（1）事先已知一个好的特征，（2）这个特征在训练过程中是固定的。如果不是这样，RLSVI将承受无法忍受的计算负担以获得后验样本。在这项工作中，我们提出了一个名为HyperDQN的实用算法，以解决深度强化学习下的上述问题。除了预测Q值的非线性神经网络（即基础模型）外，我们的方法还采用了一个概率超模型（即元模型），它输出基础模型的参数。当这两个模型在特定设计的目标下联合优化时，可以实现三个目的。首先，超模型可以生成关于Q值函数参数的近似后验样本。因此，可以采样出多样化的Q值函数来选择探索性动作序列。这保留了RLSVI高效探索的核心思想。其次，学习到一个好的特征来近似Q值函数。这解决了限制（1）。第三，可以比现有方法更高效地获得Q值函数的后验样本，并且变化的特征不会影响效率。这解决了限制（2）。在Atari套件上，使用2000万帧的HyperDQN在使用2亿帧的DQN方面在最大人类标准化得分上表现更优。对于SuperMarioBros，HyperDQN在9个游戏中的5个上优于几种探索奖励和随机探索方法。",
        "领域": "深度强化学习、探索策略、Q学习",
        "问题": "解决在深度强化学习中，当缺乏预先已知的固定好特征时，随机最小二乘价值迭代（RLSVI）方法面临的高计算负担和效率低下的问题。",
        "动机": "为了在深度强化学习中实现高效探索，尤其是在没有预先已知的固定好特征的情况下，开发一种能够自动学习特征并高效生成后验样本的方法。",
        "方法": "提出HyperDQN算法，结合基础模型（预测Q值的神经网络）和元模型（生成基础模型参数的超模型），通过联合优化这两个模型来实现高效探索和特征学习。",
        "关键词": [
            "HyperDQN",
            "随机探索",
            "深度强化学习",
            "Q学习",
            "后验采样"
        ],
        "涉及的技术概念": {
            "随机最小二乘价值迭代（RLSVI）": "一种理论上高效的探索方法，但在缺乏预先已知的固定好特征时效率低下。",
            "概率超模型（元模型）": "用于生成基础模型参数的模型，能够高效生成后验样本以支持探索。",
            "联合优化": "同时优化基础模型和元模型，以实现高效探索和特征学习。"
        },
        "success": true
    },
    {
        "order": 450,
        "title": "Hyperparameter Tuning with Renyi Differential Privacy",
        "html": "https://iclr.cc//virtual/2022/poster/6746",
        "abstract": "For many differentially private algorithms, such as the prominent noisy stochastic gradient descent (DP-SGD), the analysis needed to bound the privacy leakage of a single training run is well understood. However, few studies have reasoned about the privacy leakage resulting from the multiple training runs needed to fine tune the value of the training algorithm’s hyperparameters. In this work, we first illustrate how simply setting hyperparameters based on non-private training runs can leak private information. Motivated by this observation, we then provide privacy guarantees for hyperparameter search procedures within the framework of Renyi Differential Privacy. Our results improve and extend the work of Liu and Talwar (STOC 2019). Our analysis supports our previous observation that tuning hyperparameters does indeed leak private information, but we prove that, under certain assumptions, this leakage is modest, as long as each candidate training run needed to select hyperparameters is itself differentially private.",
        "conference": "ICLR",
        "中文标题": "使用Renyi差分隐私进行超参数调优",
        "摘要翻译": "对于许多差分隐私算法，如著名的噪声随机梯度下降（DP-SGD），分析单次训练运行的隐私泄露边界已被充分理解。然而，很少有研究探讨了为微调训练算法的超参数值所需的多次训练运行所导致的隐私泄露。在这项工作中，我们首先说明了仅基于非私有训练运行设置超参数如何泄露私有信息。受这一观察的启发，我们随后在Renyi差分隐私的框架内为超参数搜索过程提供了隐私保证。我们的结果改进并扩展了Liu和Talwar（STOC 2019）的工作。我们的分析支持了我们之前的观察，即调优超参数确实会泄露私有信息，但我们证明，在某些假设下，只要选择超参数所需的每个候选训练运行本身是差分隐私的，这种泄露是适度的。",
        "领域": "差分隐私、机器学习安全、超参数优化",
        "问题": "探讨在超参数调优过程中如何保护数据隐私，防止私有信息泄露。",
        "动机": "发现基于非私有训练运行设置超参数会泄露私有信息，促使研究在差分隐私框架下进行超参数搜索的隐私保证。",
        "方法": "在Renyi差分隐私框架内分析超参数搜索过程的隐私泄露，并证明在特定条件下，即使调优超参数，隐私泄露也是可控的。",
        "关键词": [
            "差分隐私",
            "超参数调优",
            "Renyi差分隐私",
            "隐私泄露",
            "DP-SGD"
        ],
        "涉及的技术概念": {
            "Renyi差分隐私": "提供了一种量化隐私泄露的框架，用于分析超参数搜索过程中的隐私保证。",
            "噪声随机梯度下降（DP-SGD）": "一种差分隐私算法，通过在梯度下降过程中添加噪声来保护数据隐私。",
            "超参数调优": "指在机器学习模型训练过程中调整超参数以优化模型性能的过程，本研究关注其在差分隐私下的隐私保护问题。"
        },
        "success": true
    },
    {
        "order": 451,
        "title": "iFlood: A Stable and Effective Regularizer",
        "html": "https://iclr.cc//virtual/2022/poster/6432",
        "abstract": "Various regularization methods have been designed to prevent overfitting of machine learning models. Among them, a surprisingly simple yet effective one, called Flooding, is proposed recently, which directly constrains the training loss on average to stay at a given level. However, our further studies uncover that the design of the loss function of Flooding can lead to a discrepancy between its objective and implementation, and cause the instability issue. To resolve these issues, in this paper, we propose a new regularizer, called individual Flood (denoted as iFlood). With instance-level constraints on training loss, iFlood encourages the trained models to better fit the under-fitted instances while suppressing the confidence on over-fitted ones. We theoretically show that the design of iFlood can be intrinsically connected with removing the noise or bias in training data, which makes it suitable for a variety of applications to improve the generalization performances of learned models. We also theoretically link iFlood to some other regularizers by comparing the inductive biases they introduce. Our experimental results on both image classification and language understanding tasks confirm that models learned with iFlood can stably converge to solutions with better generalization ability, and behave consistently at instance-level.",
        "conference": "ICLR",
        "中文标题": "iFlood：一种稳定有效的正则化方法",
        "摘要翻译": "为了防止机器学习模型的过拟合，已经设计了各种正则化方法。其中，最近提出了一种出奇简单却有效的方法，称为Flooding，它直接约束训练损失平均保持在给定水平。然而，我们的进一步研究发现，Flooding的损失函数设计可能导致其目标与实现之间存在差异，并引发不稳定性问题。为了解决这些问题，本文提出了一种新的正则化方法，称为个体Flood（简称iFlood）。通过对训练损失施加实例级约束，iFlood鼓励训练模型更好地适应欠拟合实例，同时抑制对过拟合实例的置信度。我们从理论上证明，iFlood的设计本质上可以与去除训练数据中的噪声或偏差相联系，这使得它适用于多种应用，以提高学习模型的泛化性能。我们还通过比较它们引入的归纳偏差，理论上将iFlood与其他一些正则化方法联系起来。我们在图像分类和语言理解任务上的实验结果证实，使用iFlood学习的模型能够稳定地收敛到具有更好泛化能力的解决方案，并在实例级别表现一致。",
        "领域": "深度学习正则化、图像分类、自然语言处理",
        "问题": "解决Flooding正则化方法在实现与目标之间的差异及不稳定性问题",
        "动机": "提高机器学习模型的泛化能力，通过改进正则化方法来更有效地处理训练数据中的噪声或偏差",
        "方法": "提出个体Flood（iFlood）正则化方法，通过实例级约束训练损失，优化模型对欠拟合和过拟合实例的处理",
        "关键词": [
            "正则化方法",
            "泛化能力",
            "实例级约束",
            "图像分类",
            "语言理解"
        ],
        "涉及的技术概念": {
            "Flooding": "一种简单有效的正则化方法，通过直接约束训练损失平均保持在给定水平来防止过拟合",
            "iFlood": "改进的正则化方法，通过实例级约束训练损失，优化模型对欠拟合和过拟合实例的处理",
            "归纳偏差": "不同正则化方法引入的偏好或假设，影响模型学习的方式和泛化能力"
        },
        "success": true
    },
    {
        "order": 452,
        "title": "IFR-Explore: Learning Inter-object Functional Relationships in 3D Indoor Scenes",
        "html": "https://iclr.cc//virtual/2022/poster/6870",
        "abstract": "Building embodied intelligent agents that can interact with 3D indoor environments has received increasing research attention in recent years. While most works focus on single-object or agent-object visual functionality and affordances, our work proposes to study a novel, underexplored, kind of visual relations that is also important to perceive and model -- inter-object functional relationships (e.g., a switch on the wall turns on or off the light, a remote control operates the TV). Humans often spend no effort or only a little to infer these relationships, even when entering a new room, by using our strong prior knowledge (e.g., we know that buttons control electrical devices) or using only a few exploratory interactions in cases of uncertainty (e.g., multiple switches and lights in the same room). In this paper, we take the first step in building AI system learning inter-object functional relationships in 3D indoor environments with key technical contributions of modeling prior knowledge by training over large-scale scenes and designing interactive policies for effectively exploring the training scenes and quickly adapting to novel test scenes. We create a new dataset based on the AI2Thor and PartNet datasets and perform extensive experiments that prove the effectiveness of our proposed method.",
        "conference": "ICLR",
        "中文标题": "IFR-探索：学习3D室内场景中的物体间功能关系",
        "摘要翻译": "近年来，构建能够与3D室内环境交互的具身智能代理受到了越来越多的研究关注。虽然大多数工作集中在单一物体或代理-物体的视觉功能和可供性上，但我们的工作提出研究一种新颖且未被充分探索的视觉关系——物体间功能关系（例如，墙上的开关控制灯的开关，遥控器操作电视）。人类通常无需努力或仅需少量努力就能推断出这些关系，即使是在进入一个新房间时，通过利用我们强大的先验知识（例如，我们知道按钮控制电子设备）或在不确定的情况下仅使用少量探索性互动（例如，同一房间内的多个开关和灯）。在本文中，我们迈出了构建学习3D室内环境中物体间功能关系的AI系统的第一步，关键技术贡献包括通过在大规模场景上训练来建模先验知识，以及设计交互策略以有效探索训练场景并快速适应新的测试场景。我们基于AI2Thor和PartNet数据集创建了一个新数据集，并进行了广泛的实验，证明了我们提出的方法的有效性。",
        "领域": "3D场景理解、具身智能、物体间交互",
        "问题": "如何让AI系统理解和学习3D室内场景中物体间的功能关系",
        "动机": "现有的研究多集中于单一物体或代理-物体的交互，忽视了物体间功能关系的重要性，而这对构建能够与复杂环境交互的智能代理至关重要。",
        "方法": "通过在大规模3D场景上训练建模先验知识，并设计交互策略以有效探索训练场景和快速适应新场景。",
        "关键词": [
            "3D场景理解",
            "物体间功能关系",
            "具身智能",
            "交互策略",
            "先验知识建模"
        ],
        "涉及的技术概念": {
            "物体间功能关系": "描述3D室内场景中物体之间如何通过功能相互关联，如开关与灯的控制关系。",
            "先验知识建模": "通过在大规模场景上训练，使AI系统能够理解和预测物体间的功能关系。",
            "交互策略": "设计的方法和策略，使AI系统能够有效探索环境并快速适应新场景中的物体间功能关系。"
        },
        "success": true
    },
    {
        "order": 453,
        "title": "Igeood: An Information Geometry Approach to Out-of-Distribution Detection",
        "html": "https://iclr.cc//virtual/2022/poster/5915",
        "abstract": "Reliable out-of-distribution (OOD) detection is fundamental to implementing safer modern machine learning (ML)  systems. In this paper, we introduce Igeood, an effective method for detecting OOD samples. Igeood applies to any pre-trained neural network, works under various degrees of access to the ML model, does not require OOD samples or assumptions on the OOD data but can also benefit (if available) from OOD samples. By building on the geodesic (Fisher-Rao) distance between the underlying data distributions, our discriminator can combine confidence scores from the logits outputs and the learned features of a deep neural network. Empirically, we show that Igeood outperforms competing state-of-the-art methods on a variety of network architectures and datasets.",
        "conference": "ICLR",
        "中文标题": "Igeood：一种基于信息几何的分布外检测方法",
        "摘要翻译": "可靠的分布外（OOD）检测是实现更安全的现代机器学习（ML）系统的基础。在本文中，我们介绍了Igeood，一种有效的OOD样本检测方法。Igeood适用于任何预训练的神经网络，可以在不同程度访问ML模型的情况下工作，不需要OOD样本或对OOD数据的假设，但如果可用，也可以从OOD样本中受益。通过建立在基础数据分布之间的测地线（Fisher-Rao）距离上，我们的判别器可以结合来自logits输出和深度神经网络学习特征的置信度分数。实证上，我们展示了Igeood在各种网络架构和数据集上优于竞争的最先进方法。",
        "领域": "异常检测、深度学习安全、神经网络可靠性",
        "问题": "如何在不需要OOD样本或对OOD数据做出假设的情况下，有效地检测出分布外的样本。",
        "动机": "提高机器学习系统的安全性，通过开发一种不依赖于OOD样本或特定假设的分布外检测方法。",
        "方法": "利用信息几何中的Fisher-Rao距离，结合深度神经网络的logits输出和学习特征，开发了一种新的分布外检测方法Igeood。",
        "关键词": [
            "分布外检测",
            "信息几何",
            "Fisher-Rao距离",
            "神经网络",
            "机器学习安全"
        ],
        "涉及的技术概念": {
            "信息几何": "用于衡量数据分布之间的差异，为分布外检测提供理论基础。",
            "Fisher-Rao距离": "一种在信息几何中衡量概率分布之间差异的测地线距离，用于构建判别器。",
            "logits输出": "深度神经网络最后一层的输出，用于生成置信度分数，帮助识别分布外样本。"
        },
        "success": true
    },
    {
        "order": 454,
        "title": "IGLU: Efficient GCN Training via Lazy Updates",
        "html": "https://iclr.cc//virtual/2022/poster/6235",
        "abstract": "Training multi-layer Graph Convolution Networks (GCN) using standard SGD techniques scales poorly as each descent step ends up updating node embeddings for a large portion of the graph. Recent attempts to remedy this sub-sample the graph that reduces compute but introduce additional variance and may offer suboptimal performance. This paper develops the IGLU method that caches intermediate computations at various GCN layers thus enabling lazy updates that significantly reduce the compute cost of descent. IGLU introduces bounded bias into the gradients but nevertheless converges to a first-order saddle point under standard assumptions such as objective smoothness. Benchmark experiments show that IGLU offers up to 1.2% better accuracy despite requiring up to 88% less compute.",
        "conference": "ICLR",
        "中文标题": "IGLU：通过惰性更新实现高效的图卷积网络训练",
        "摘要翻译": "使用标准的随机梯度下降（SGD）技术训练多层图卷积网络（GCN）时，由于每个下降步骤都需要更新图中大部分节点的嵌入，因此效率低下。最近尝试通过子采样图来减少计算量，但这引入了额外的方差，并可能导致性能不佳。本文开发了IGLU方法，该方法在各个GCN层缓存中间计算结果，从而实现惰性更新，显著降低了下降步骤的计算成本。IGLU在梯度中引入了有界偏差，但在目标平滑性等标准假设下仍能收敛到一阶鞍点。基准测试表明，IGLU在减少高达88%计算量的同时，准确率提高了1.2%。",
        "领域": "图神经网络优化、图卷积网络、深度学习效率提升",
        "问题": "解决图卷积网络训练过程中计算成本高和效率低下的问题",
        "动机": "提高图卷积网络训练的效率，减少计算资源消耗，同时保持或提高模型性能",
        "方法": "通过在各GCN层缓存中间计算结果，实现惰性更新，减少下降步骤的计算成本",
        "关键词": [
            "图卷积网络",
            "惰性更新",
            "训练效率",
            "计算优化",
            "深度学习"
        ],
        "涉及的技术概念": {
            "惰性更新": "通过缓存中间计算结果减少计算量，提高训练效率",
            "图卷积网络": "用于处理图结构数据的深度学习模型",
            "随机梯度下降": "优化算法，用于训练深度学习模型"
        },
        "success": true
    },
    {
        "order": 455,
        "title": "Illiterate DALL-E Learns to Compose",
        "html": "https://iclr.cc//virtual/2022/poster/6051",
        "abstract": "Although DALL-E has shown an impressive ability of composition-based systematic generalization in image generation, it requires the dataset of text-image pairs and the compositionality is provided by the text. In contrast, object-centric representation models like the Slot Attention model learn composable representations without the text prompt. However, unlike DALL-E, its ability to systematically generalize for zero-shot generation is significantly limited. In this paper, we propose a simple but novel slot-based autoencoding architecture, called SLATE, for combining the best of both worlds: learning object-centric representations that allow systematic generalization in zero-shot image generation without text. As such, this model can also be seen as an illiterate DALL-E model. Unlike the pixel-mixture decoders of existing object-centric representation models, we propose to use the Image GPT decoder conditioned on the slots for capturing complex interactions among the slots and pixels. In experiments, we show that this simple and easy-to-implement architecture not requiring a text prompt achieves significant improvement in in-distribution and out-of-distribution (zero-shot) image generation and qualitatively comparable or better slot-attention structure than the models based on mixture decoders.",
        "conference": "ICLR",
        "中文标题": "不识字的DALL-E学会构图",
        "摘要翻译": "尽管DALL-E在基于组合的系统性泛化图像生成方面展示了令人印象深刻的能力，但它需要文本-图像对的数据集，并且组合性由文本提供。相比之下，像Slot Attention模型这样的以对象为中心的表示模型无需文本提示即可学习可组合的表示。然而，与DALL-E不同，它在零样本生成方面的系统性泛化能力显著受限。在本文中，我们提出了一种简单但新颖的基于槽的自编码架构，称为SLATE，以结合两者的优点：学习允许在无需文本的情况下进行零样本图像生成的系统性泛化的以对象为中心的表示。因此，该模型也可以被视为不识字的DALL-E模型。与现有以对象为中心的表示模型的像素混合解码器不同，我们提出使用基于槽的Image GPT解码器来捕捉槽和像素之间的复杂交互。在实验中，我们展示了这种简单且易于实现的架构，无需文本提示，就在分布内和分布外（零样本）图像生成方面实现了显著改进，并且在槽注意力结构上定性比较或优于基于混合解码器的模型。",
        "领域": "图像生成、零样本学习、对象中心表示学习",
        "问题": "如何在无需文本提示的情况下，实现零样本图像生成的系统性泛化",
        "动机": "结合DALL-E的组合性生成能力和对象中心表示模型的无需文本提示的优点，提升零样本图像生成的系统性泛化能力",
        "方法": "提出了一种基于槽的自编码架构SLATE，使用Image GPT解码器捕捉槽和像素间的复杂交互",
        "关键词": [
            "SLATE",
            "零样本图像生成",
            "对象中心表示",
            "系统性泛化",
            "自编码架构"
        ],
        "涉及的技术概念": {
            "Slot Attention模型": "一种以对象为中心的表示学习方法，无需文本提示即可学习可组合的表示",
            "零样本生成": "在未见过的类别或条件下生成图像的能力",
            "Image GPT解码器": "一种基于槽的解码器，用于捕捉槽和像素之间的复杂交互，提升图像生成的质量"
        },
        "success": true
    },
    {
        "order": 456,
        "title": "iLQR-VAE : control-based learning of input-driven dynamics with applications to neural data",
        "html": "https://iclr.cc//virtual/2022/poster/6079",
        "abstract": "Understanding how neural dynamics give rise to behaviour is one of the most fundamental questions in systems neuroscience. To achieve this, a common approach is to record neural populations in behaving animals, and model these data as emanating from a latent dynamical system whose state trajectories can then be related back to behavioural observations via some form of decoding. As recordings are typically performed in localized circuits that form only a part of the wider implicated network, it is important to simultaneously learn the local dynamics and infer any unobserved external input that might drive them. Here, we introduce iLQR-VAE, a novel control-based approach to variational inference in nonlinear dynamical systems, capable of learning both latent dynamics, initial conditions, and ongoing external inputs. As in recent deep learning approaches, our method is based on an input-driven sequential variational autoencoder (VAE). The main novelty lies in the use of the powerful iterative linear quadratic regulator algorithm (iLQR) in the recognition model. Optimization of the standard evidence lower-bound requires differentiating through iLQR solutions, which is made possible by recent advances in differentiable control. Importantly, having the recognition model be implicitly defined by the generative model greatly reduces the number of free parameters and allows for flexible, high-quality inference. This makes it possible for instance to evaluate the model on a single long trial after training on smaller chunks. We demonstrate the effectiveness of iLQR-VAE on a range of synthetic systems, with autonomous as well as input-driven dynamics. We further apply it to neural and behavioural recordings in non-human primates performing two different reaching tasks, and show that iLQR-VAE yields high-quality kinematic reconstructions from the neural data. ",
        "conference": "ICLR",
        "中文标题": "iLQR-VAE：基于控制的输入驱动动力学学习及其在神经数据中的应用",
        "摘要翻译": "理解神经动力学如何产生行为是系统神经科学中最基本的问题之一。为实现这一目标，常见的方法是在行为动物中记录神经群体，并将这些数据建模为来自一个潜在的动态系统，其状态轨迹随后可以通过某种形式的解码与行为观察相关联。由于记录通常在局部电路中进行，这些电路仅构成更广泛网络的一部分，因此同时学习局部动态并推断可能驱动它们的任何未观察到的外部输入非常重要。在这里，我们介绍了iLQR-VAE，一种在非线性动态系统中进行变分推理的基于控制的新方法，能够学习潜在动态、初始条件和持续的外部输入。与最近的深度学习方法一样，我们的方法基于输入驱动的序列变分自编码器（VAE）。主要新颖之处在于在识别模型中使用强大的迭代线性二次调节器算法（iLQR）。优化标准的证据下界需要通过iLQR解决方案进行微分，这得益于可微分控制的最新进展成为可能。重要的是，使识别模型由生成模型隐式定义大大减少了自由参数的数量，并允许灵活、高质量的推理。这使得例如在训练较小的块后，可以在单个长试验上评估模型成为可能。我们在一系列合成系统上展示了iLQR-VAE的有效性，包括自主和输入驱动的动态。我们进一步将其应用于非人类灵长类动物执行两种不同到达任务的神经和行为记录，并显示iLQR-VAE从神经数据中产生高质量的动力学重建。",
        "领域": "神经动力学建模、变分自编码器、控制理论在神经科学中的应用",
        "问题": "如何在局部神经回路中同时学习动态模型和推断未观察到的外部输入",
        "动机": "为了更深入地理解神经动力学如何导致行为，需要一种能够同时学习局部动态和推断外部输入的方法",
        "方法": "提出iLQR-VAE方法，结合变分自编码器和迭代线性二次调节器算法，用于学习非线性动态系统中的潜在动态、初始条件和外部输入",
        "关键词": [
            "iLQR-VAE",
            "神经动力学",
            "变分自编码器",
            "迭代线性二次调节器",
            "行为重建"
        ],
        "涉及的技术概念": {
            "变分自编码器（VAE）": "用于建模神经数据的潜在动态系统，能够学习数据的潜在表示",
            "迭代线性二次调节器算法（iLQR）": "在识别模型中使用，用于优化控制问题，使得模型能够处理非线性动态系统",
            "可微分控制": "使得通过iLQR解决方案进行微分成为可能，从而优化证据下界"
        },
        "success": true
    },
    {
        "order": 457,
        "title": "Image BERT Pre-training with Online Tokenizer",
        "html": "https://iclr.cc//virtual/2022/poster/6156",
        "abstract": "The success of language Transformers is primarily attributed to the pretext task of masked language modeling (MLM), where texts are first tokenized into semantically meaningful pieces.In this work, we study masked image modeling (MIM) and indicate the necessity and challenges of using a semantically meaningful visual tokenizer.We present a self-supervised framework iBOT that can perform masked prediction with an online tokenizer. Specifically, we perform self-distillation on masked patch tokens and take the teacher network as the online tokenizer, along with self-distillation on the class token to acquire visual semantics.The online tokenizer is jointly learnable with the MIM objective and dispenses with a multi-stage training pipeline where the tokenizer needs to be pre-trained beforehand.We show the prominence of iBOT by achieving an 82.3% linear probing accuracy and an 87.8% fine-tuning accuracy evaluated on ImageNet-1K.Beyond the state-of-the-art image classification results, we underline emerging local semantic patterns, which helps the models to obtain strong robustness against common corruptions and achieve leading results on dense downstream tasks, e.g., object detection, instance segmentation, and semantic segmentation.",
        "conference": "ICLR",
        "中文标题": "使用在线分词器进行图像BERT预训练",
        "摘要翻译": "语言Transformer的成功主要归功于掩码语言建模（MLM）这一前置任务，其中文本首先被分词为语义上有意义的片段。在这项工作中，我们研究了掩码图像建模（MIM），并指出了使用语义上有意义的视觉分词器的必要性和挑战。我们提出了一个自监督框架iBOT，该框架可以使用在线分词器执行掩码预测。具体来说，我们在掩码补丁令牌上执行自蒸馏，并将教师网络作为在线分词器，同时在类别令牌上执行自蒸馏以获取视觉语义。在线分词器可以与MIM目标联合学习，并且无需预先训练分词器的多阶段训练流程。我们通过在ImageNet-1K上达到82.3%的线性探测准确率和87.8%的微调准确率来展示iBOT的卓越性能。除了最先进的图像分类结果外，我们还强调了新兴的局部语义模式，这有助于模型获得对常见损坏的强大鲁棒性，并在密集的下游任务（如目标检测、实例分割和语义分割）中取得领先结果。",
        "领域": "自监督学习、图像分类、语义分割",
        "问题": "如何在视觉任务中有效地应用掩码图像建模（MIM）并开发一个语义上有意义的视觉分词器。",
        "动机": "探索掩码图像建模（MIM）在视觉任务中的应用潜力，解决现有方法中视觉分词器需要预先训练的限制。",
        "方法": "提出自监督框架iBOT，通过自蒸馏技术在掩码补丁令牌和类别令牌上学习，实现与MIM目标联合学习的在线分词器。",
        "关键词": [
            "自监督学习",
            "掩码图像建模",
            "在线分词器",
            "图像分类",
            "语义分割"
        ],
        "涉及的技术概念": {
            "掩码图像建模（MIM）": "一种自监督学习技术，通过预测图像中被掩码的部分来学习图像表示。",
            "自蒸馏": "一种学习策略，通过教师网络指导学生网络的训练，以提高模型的性能。",
            "在线分词器": "一种无需预先训练即可与主任务联合学习的视觉分词器，用于将图像分割为语义上有意义的片段。"
        },
        "success": true
    },
    {
        "order": 458,
        "title": "Imbedding Deep Neural Networks",
        "html": "https://iclr.cc//virtual/2022/poster/6530",
        "abstract": "Continuous-depth neural networks, such as Neural ODEs, have refashioned the understanding of residual neural networks in terms of non-linear vector-valued optimal control problems. The common solution is to use the adjoint sensitivity method to replicate a forward-backward pass optimisation problem. We propose a new approach which explicates the network's `depth' as a fundamental variable, thus reducing the problem to a system of forward-facing initial value problems. This new method is based on the principal of `Invariant Imbedding' for which we prove a general solution, applicable to all non-linear, vector-valued optimal control problems with both running and terminal loss.Our new architectures provide a tangible tool for inspecting the theoretical--and to a great extent unexplained--properties of network depth. They also constitute a resource of discrete implementations of Neural ODEs comparable to classes of imbedded residual neural networks. Through a series of experiments, we show the competitive performance of the proposed architectures for supervised learning and time series prediction. ",
        "conference": "ICLR",
        "中文标题": "嵌入深度神经网络",
        "摘要翻译": "连续深度神经网络，如神经ODE，已经以非线性向量值最优控制问题的形式重塑了对残差神经网络的理解。常见的解决方案是使用伴随敏感性方法来复制一个前向-后向传递优化问题。我们提出了一种新方法，该方法将网络的‘深度’作为一个基本变量明确化，从而将问题简化为一个前向初值问题的系统。这一新方法基于‘不变嵌入’原理，我们为此证明了一个适用于所有具有运行和终端损失的非线性向量值最优控制问题的通用解。我们的新架构为检查网络深度的理论性质——在很大程度上尚未解释——提供了一个切实可行的工具。它们也构成了神经ODE的离散实现资源，可与嵌入残差神经网络的类别相媲美。通过一系列实验，我们展示了所提出架构在监督学习和时间序列预测方面的竞争性能。",
        "领域": "深度学习理论、神经网络架构设计、时间序列预测",
        "问题": "如何更有效地理解和优化深度神经网络中的‘深度’概念及其在非线性向量值最优控制问题中的应用。",
        "动机": "探索和解释深度神经网络中‘深度’的理论性质，以及如何通过新方法优化网络性能。",
        "方法": "提出了一种基于‘不变嵌入’原理的新方法，将网络深度作为基本变量，简化问题为前向初值问题的系统，适用于非线性向量值最优控制问题。",
        "关键词": [
            "连续深度神经网络",
            "不变嵌入",
            "最优控制问题",
            "监督学习",
            "时间序列预测"
        ],
        "涉及的技术概念": {
            "神经ODE": "用于描述连续深度神经网络的动态系统，将残差网络理解为最优控制问题。",
            "不变嵌入": "新方法的核心原理，用于将网络深度作为变量处理，简化优化问题。",
            "伴随敏感性方法": "传统优化方法，用于解决前向-后向传递优化问题，新方法旨在提供更高效的替代方案。"
        },
        "success": true
    },
    {
        "order": 459,
        "title": "Imitation Learning by Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6902",
        "abstract": "Imitation learning algorithms learn a policy from demonstrations of expert behavior. We show that, for deterministic experts, imitation learning can be done by reduction to reinforcement learning with a stationary reward. Our theoretical analysis both certifies the recovery of expert reward and bounds the total variation distance between the expert and the imitation learner, showing a link to adversarial imitation learning. We conduct experiments which confirm that our reduction works well in practice for continuous control tasks.",
        "conference": "ICLR",
        "中文标题": "通过强化学习实现模仿学习",
        "摘要翻译": "模仿学习算法通过专家行为的示范学习策略。我们证明，对于确定性专家，模仿学习可以通过转化为具有固定奖励的强化学习来完成。我们的理论分析既验证了专家奖励的恢复，也界定了专家与模仿学习者之间的总变差距离，显示了与对抗性模仿学习的联系。我们进行的实验证实，我们的转化方法在连续控制任务中实际效果良好。",
        "领域": "模仿学习、强化学习、连续控制",
        "问题": "如何有效地从专家示范中学习策略，并将其转化为强化学习问题",
        "动机": "探索模仿学习与强化学习之间的联系，提供一种新的学习策略方法",
        "方法": "将模仿学习问题转化为具有固定奖励的强化学习问题，并通过理论分析和实验验证其有效性",
        "关键词": [
            "模仿学习",
            "强化学习",
            "连续控制",
            "专家示范",
            "总变差距离"
        ],
        "涉及的技术概念": {
            "模仿学习": "通过专家行为的示范学习策略的技术",
            "强化学习": "通过奖励机制学习最优策略的方法",
            "总变差距离": "用于衡量专家与模仿学习者之间策略差异的度量标准"
        },
        "success": true
    },
    {
        "order": 460,
        "title": "Imitation Learning from Observations under Transition Model Disparity",
        "html": "https://iclr.cc//virtual/2022/poster/6137",
        "abstract": "Learning to perform tasks by leveraging a dataset of expert observations, also known as imitation learning from observations (ILO), is an important paradigm for learning skills without access to the expert reward function or the expert actions. We consider ILO in the setting where the expert and the learner agents operate in different environments, with the source of the discrepancy being the transition dynamics model. Recent methods for scalable ILO utilize adversarial learning to match the state-transition distributions of the expert and the learner, an approach that becomes challenging when the dynamics are dissimilar. In this work, we propose an algorithm that trains an intermediary policy in the learner environment and uses it as a surrogate expert for the learner. The intermediary policy is learned such that the state transitions generated by it are close to the state transitions in the expert dataset. To derive a practical and scalable algorithm, we employ concepts from prior work on estimating the support of a probability distribution. Experiments using MuJoCo locomotion tasks highlight that our method compares favorably to the baselines for ILO with transition dynamics mismatch.",
        "conference": "ICLR",
        "中文标题": "在转移模型差异下的观察模仿学习",
        "摘要翻译": "通过利用专家观察数据集学习执行任务，也称为观察模仿学习（ILO），是在无法访问专家奖励函数或专家动作的情况下学习技能的重要范式。我们考虑专家和学习者代理在不同环境中操作的ILO设置，差异的来源是转移动态模型。最近的可扩展ILO方法利用对抗学习来匹配专家和学习者的状态转移分布，当动态不相似时，这种方法变得具有挑战性。在这项工作中，我们提出了一种算法，该算法在学习者环境中训练一个中间策略，并将其用作学习者的替代专家。学习中间策略的目的是使其生成的状态转移接近专家数据集中的状态转移。为了推导出一个实用且可扩展的算法，我们采用了先前关于估计概率分布支持的工作中的概念。使用MuJoCo运动任务的实验表明，我们的方法在转移动态不匹配的ILO中优于基线。",
        "领域": "模仿学习、强化学习、机器人运动控制",
        "问题": "解决在专家和学习者代理转移动态模型不同的情况下，如何有效进行观察模仿学习的问题。",
        "动机": "研究动机是为了在专家和学习者代理操作环境不同的情况下，克服转移动态模型差异带来的挑战，实现有效的技能学习。",
        "方法": "提出了一种算法，通过在学习者环境中训练一个中间策略作为替代专家，并确保其生成的状态转移接近专家数据集中的状态转移，从而解决转移动态不匹配的问题。",
        "关键词": [
            "观察模仿学习",
            "转移动态模型",
            "对抗学习",
            "中间策略",
            "MuJoCo运动任务"
        ],
        "涉及的技术概念": {
            "观察模仿学习（ILO）": "一种通过专家观察数据集学习技能的方法，无需访问专家奖励函数或动作。",
            "对抗学习": "用于匹配专家和学习者状态转移分布的技术，但在动态不相似时面临挑战。",
            "中间策略": "在学习者环境中训练的替代专家策略，用于生成接近专家数据集状态转移的状态转移。"
        },
        "success": true
    },
    {
        "order": 461,
        "title": "Implicit Bias of Adversarial Training for Deep Neural Networks",
        "html": "https://iclr.cc//virtual/2022/poster/7019",
        "abstract": "We provide theoretical understandings of the implicit bias imposed by adversarial training for homogeneous deep neural networks without any explicit regularization. In particular, for deep linear networks adversarially trained by gradient descent on a linearly separable dataset, we prove that the direction of the product of weight matrices converges to the direction of the max-margin solution of the original dataset. Furthermore, we generalize this result to the case of adversarial training for non-linear homogeneous deep neural networks without the linear separability of the dataset. We show that, when the neural network is adversarially trained with  $\\ell_2$ or $\\ell_{\\infty}$ FGSM, FGM and PGD perturbations, the direction of the limit point of normalized parameters of the network along the trajectory of the gradient flow converges to a KKT point of a constrained optimization problem that aims to maximize the margin for adversarial examples. Our results theoretically justify the longstanding conjecture that adversarial training modifies the decision boundary by utilizing adversarial examples to improve robustness, and potentially provides insights for designing new robust training strategies.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "深度神经网络对抗训练的隐式偏差",
        "摘要翻译": "我们对同构深度神经网络在没有任何显式正则化的情况下，通过对抗训练施加的隐式偏差进行了理论上的理解。 特别是，对于通过梯度下降在可线性分离的数据集上进行对抗训练的深度线性网络，我们证明了权重矩阵乘积的方向收敛于原始数据集的最大间隔解的方向。 此外，我们将此结果推广到非线性同构深度神经网络的对抗训练，而无需数据集的线性可分性。 我们表明，当神经网络使用  l2 或 l∞ FGSM，FGM 和 PGD 扰动进行对抗训练时，网络归一化参数沿梯度流轨迹的极限点的方向收敛到约束优化问题的 KKT 点，该约束优化问题旨在最大化对抗样本的间隔。 我们的结果从理论上证明了长期存在的猜想，即对抗训练通过利用对抗样本来改进鲁棒性来修改决策边界，并可能为设计新的鲁棒训练策略提供见解。",
        "领域": "对抗学习, 鲁棒性, 深度学习理论",
        "问题": "理解和解释对抗训练在深度神经网络中产生的隐式偏差，并揭示其如何影响模型的鲁棒性和泛化能力。",
        "动机": "对抗训练已被广泛用于提高深度神经网络的鲁棒性，但其内在机制和对模型的影响尚未完全理解。这项研究旨在从理论上解释对抗训练如何通过隐式偏差来影响模型的决策边界和泛化性能。",
        "方法": "通过理论分析和梯度下降的收敛性证明，研究了对抗训练对深度线性网络和非线性同构深度神经网络的影响。利用KKT条件分析了对抗训练的优化目标，并将其与最大化对抗样本间隔的约束优化问题联系起来。",
        "关键词": [
            "对抗训练",
            "隐式偏差",
            "鲁棒性",
            "最大间隔",
            "深度神经网络"
        ],
        "涉及的技术概念": {
            "对抗训练": "一种通过生成对抗样本并将其用于训练来提高模型鲁棒性的技术。论文研究了对抗训练对模型隐式偏差的影响。",
            "梯度下降": "一种优化算法，用于最小化损失函数并更新模型参数。论文分析了梯度下降在对抗训练中的收敛性。"
        }
    },
    {
        "order": 462,
        "title": "Implicit Bias of MSE Gradient Optimization in Underparameterized Neural Networks",
        "html": "https://iclr.cc//virtual/2022/poster/7090",
        "abstract": "We study the dynamics of a neural network in function space when optimizing the mean squared error via gradient flow.  We show that in the underparameterized regime the network learns eigenfunctions of an integral operator $T_K$ determined by the Neural Tangent Kernel at rates corresponding to their eigenvalues.  For example, for uniformly distributed data on the sphere $S^{d - 1}$ and rotation invariant weight distributions, the eigenfunctions of $T_K$ are the spherical harmonics.  Our results can be understood as describing a spectral bias in the underparameterized regime. The proofs use the concept of ``Damped Deviations'' where deviations of the NTK matter less for eigendirections with large eigenvalues.  Aside from the underparameterized regime, the damped deviations point-of-view allows us to extend certain results in the literature in the overparameterized setting. ",
        "conference": "ICLR",
        "中文标题": "欠参数化神经网络中MSE梯度优化的隐式偏差",
        "摘要翻译": "我们研究了在通过梯度流优化均方误差时，神经网络在函数空间中的动态。我们表明，在欠参数化状态下，网络学习由神经切线核确定的积分算子$T_K$的特征函数，其速率与它们的特征值相对应。例如，对于球面$S^{d - 1}$上均匀分布的数据和旋转不变的权重分布，$T_K$的特征函数是球谐函数。我们的结果可以被理解为描述了欠参数化状态下的谱偏差。证明使用了'阻尼偏差'的概念，其中对于具有大特征值的特征方向，神经切线核的偏差影响较小。除了欠参数化状态外，阻尼偏差的观点还允许我们在文献中扩展某些过参数化设置的结果。",
        "领域": "深度学习理论、神经网络优化、机器学习理论",
        "问题": "理解在欠参数化神经网络中，通过均方误差梯度优化学习过程中的隐式偏差及其动态特性。",
        "动机": "探索欠参数化状态下神经网络优化的动态特性，特别是如何学习特定积分算子的特征函数，以及这种学习过程中的谱偏差现象。",
        "方法": "通过梯度流优化均方误差，分析神经网络在欠参数化状态下的学习动态，使用神经切线核和阻尼偏差的概念来描述和证明学习过程中的谱偏差。",
        "关键词": [
            "欠参数化神经网络",
            "梯度流优化",
            "神经切线核",
            "谱偏差",
            "阻尼偏差"
        ],
        "涉及的技术概念": {
            "神经切线核": "用于描述神经网络在训练过程中动态变化的核函数，本文中用于确定积分算子$T_K$的特征函数。",
            "阻尼偏差": "一种概念，指在优化过程中，对于具有较大特征值的特征方向，神经切线核的偏差影响较小。",
            "谱偏差": "描述了在欠参数化状态下，神经网络优先学习某些特征函数的现象，这些特征函数对应于较大的特征值。"
        },
        "success": true
    },
    {
        "order": 463,
        "title": "Implicit Bias of Projected Subgradient Method Gives Provable Robust Recovery of Subspaces of Unknown Codimension",
        "html": "https://iclr.cc//virtual/2022/poster/7038",
        "abstract": "Robust subspace recovery (RSR) is the problem of learning a subspace from sample data points corrupted by outliers. Dual Principal Component Pursuit (DPCP) is a robust subspace recovery method that aims to find a basis for the orthogonal complement of the subspace by minimizing the sum of the distances of the points to the subspaces subject to orthogonality constraints on the basis. Prior work has shown that DPCP can provably recover the correct subspace in the presence of outliers as long as the true dimension of the subspace is known. In this paper, we show that if the orthogonality constraints --adopted in previous DPCP formulations-- are relaxed and random initialization is used instead of spectral one, DPCP can provably recover a subspace of \\emph{unknown dimension}. Specifically, we propose a very simple algorithm based on running multiple instances of a projected sub-gradient descent method (PSGM), with each problem instance seeking to find one vector in the null space of the subspace. We theoretically prove that under mild conditions this approach succeeds with high probability. In particular, we show that 1) all of the problem instances will converge to a vector in the nullspace of the subspace and 2) the ensemble of problem instance solutions will be sufficiently diverse to fully span the nullspace of the subspace thus also revealing its true unknown codimension. We provide empirical results that corroborate our theoretical results and showcase the remarkable implicit rank regularization behavior of the PSGM algorithm that allows us to perform RSR without knowing the subspace dimension",
        "conference": "ICLR",
        "中文标题": "投影次梯度法的隐式偏差为未知余维数子空间的可证明鲁棒恢复提供了保证",
        "摘要翻译": "鲁棒子空间恢复（RSR）是从被异常值污染的样本数据点中学习子空间的问题。双主成分追踪（DPCP）是一种鲁棒子空间恢复方法，旨在通过最小化点到子空间的距离之和，在基的正交性约束下，找到子空间的正交补的一个基。先前的工作表明，只要子空间的真实维度已知，DPCP就可以在存在异常值的情况下可证明地恢复正确的子空间。在本文中，我们表明，如果放松先前DPCP公式中采用的正交性约束，并使用随机初始化而不是谱初始化，DPCP可以可证明地恢复一个未知维度的子空间。具体来说，我们提出了一种非常简单的算法，基于运行多个投影次梯度下降法（PSGM）的实例，每个问题实例寻求找到子空间零空间中的一个向量。我们从理论上证明，在温和的条件下，这种方法以高概率成功。特别是，我们展示了1）所有问题实例都将收敛到子空间零空间中的一个向量，以及2）问题实例解的集合将足够多样化，以完全跨越子空间的零空间，从而也揭示了其真实的未知余维数。我们提供的实证结果证实了我们的理论结果，并展示了PSGM算法的显著隐式秩正则化行为，使我们能够在不知道子空间维度的情况下执行RSR。",
        "领域": "鲁棒子空间恢复",
        "问题": "在子空间维度未知的情况下，从含有异常值的数据中鲁棒地恢复子空间",
        "动机": "研究在子空间维度未知的情况下，如何通过放松正交性约束和使用随机初始化，提高鲁棒子空间恢复的可行性和效率",
        "方法": "提出基于投影次梯度下降法（PSGM）的多实例算法，每个实例寻找子空间零空间中的一个向量，理论上证明该方法在温和条件下以高概率成功",
        "关键词": [
            "鲁棒子空间恢复",
            "双主成分追踪",
            "投影次梯度下降法",
            "隐式秩正则化",
            "未知维度子空间"
        ],
        "涉及的技术概念": {
            "鲁棒子空间恢复（RSR）": "从含有异常值的数据中学习子空间的技术",
            "双主成分追踪（DPCP）": "一种通过最小化点到子空间的距离之和来恢复子空间正交补的基的方法",
            "投影次梯度下降法（PSGM）": "用于优化问题，特别是在约束条件下寻找子空间零空间中的向量"
        },
        "success": true
    },
    {
        "order": 464,
        "title": "Improved deterministic l2 robustness on CIFAR-10 and CIFAR-100",
        "html": "https://iclr.cc//virtual/2022/poster/6980",
        "abstract": "Training convolutional neural networks (CNNs) with a strict Lipschitz constraint under the $l_{2}$ norm is useful for provable adversarial robustness, interpretable gradients and stable training. While $1$-Lipschitz CNNs can be designed by enforcing a $1$-Lipschitz constraint on each layer, training such networks requires each layer to have an orthogonal Jacobian matrix (for all inputs) to prevent the gradients from vanishing during backpropagation. A layer with this property is said to be Gradient Norm Preserving (GNP). In this work, we introduce a procedure to certify the robustness of $1$-Lipschitz CNNs by relaxing the orthogonalization of the last linear layer of the network that significantly advances the state of the art for both standard and provable robust accuracies on CIFAR-100 (gains of $4.80\\%$ and $4.71\\%$, respectively). We further boost their robustness by introducing (i) a novel Gradient Norm preserving activation function called the Householder activation function (that includes every $\\mathrm{GroupSort}$ activation) and (ii) a certificate regularization. On CIFAR-10, we achieve significant improvements over prior works in provable robust accuracy ($5.81\\%$) with only a minor drop in standard accuracy ($-0.29\\%$). Code for reproducing all experiments in the paper is available at \\url{https://github.com/singlasahil14/SOC}. ",
        "conference": "ICLR",
        "success": true,
        "中文标题": "在CIFAR-10和CIFAR-100上改进的确定性l2鲁棒性",
        "摘要翻译": "在$l_{2}$范数下，使用严格的Lipschitz约束训练卷积神经网络（CNN）对于可证明的对抗鲁棒性、可解释的梯度和稳定的训练非常有用。虽然可以通过对每一层强制执行1-Lipschitz约束来设计1-Lipschitz CNN，但训练这种网络需要每一层都有一个正交雅可比矩阵（对于所有输入），以防止梯度在反向传播期间消失。具有此属性的层被称为梯度范数保持（GNP）。在这项工作中，我们介绍了一种通过放宽网络最后一层线性层的正交化来验证1-Lipschitz CNN鲁棒性的程序，该程序显着提高了CIFAR-100上的标准和可证明鲁棒性精度（分别提高了4.80％和4.71％）。我们通过引入（i）一种名为Householder激活函数的新型梯度范数保持激活函数（包括每个GroupSort激活）和（ii）证书正则化来进一步提高它们的鲁棒性。在CIFAR-10上，我们在可证明的鲁棒性精度方面实现了显着改进（5.81％），而标准精度仅略有下降（-0.29％）。用于重现本文中所有实验的代码可在 [https://github.com/singlasahil14/SOC](https://github.com/singlasahil14/SOC) 上找到。",
        "领域": "对抗鲁棒性, 卷积神经网络, 图像分类",
        "问题": "如何在保证标准准确率的同时，提高卷积神经网络的对抗鲁棒性，尤其是在CIFAR-10和CIFAR-100数据集上的可证明鲁棒性。",
        "动机": "现有的1-Lipschitz CNN训练方法依赖于每一层的正交雅可比矩阵，这限制了模型的表达能力和性能。通过放宽最后一层线性层的正交化约束，并引入新的梯度范数保持激活函数和证书正则化，可以显著提高模型的鲁棒性和准确性。",
        "方法": "该论文提出了一种放宽最后一层线性层正交化约束的方法，并引入了Householder激活函数和证书正则化来提高1-Lipschitz CNN的鲁棒性。通过这种方法，在CIFAR-10和CIFAR-100数据集上实现了更高的标准精度和可证明的鲁棒性精度。",
        "关键词": [
            "对抗鲁棒性",
            "1-Lipschitz CNN",
            "梯度范数保持",
            "Householder激活函数",
            "证书正则化"
        ],
        "涉及的技术概念": {
            "对抗鲁棒性": "指模型抵抗对抗样本攻击的能力，即在输入数据中添加微小扰动后，模型仍能正确预测。",
            "梯度范数保持": "指网络层保持梯度范数不变的性质，有助于防止梯度消失或爆炸，从而稳定训练。"
        }
    },
    {
        "order": 465,
        "title": "Improving Federated Learning Face Recognition via Privacy-Agnostic Clusters",
        "html": "https://iclr.cc//virtual/2022/poster/6471",
        "abstract": "The growing public concerns on data privacy in face recognition can be partly relieved by the federated learning (FL) paradigm. However, conventional FL methods usually perform poorly  due to the particularity of the task, \\textit{i.e.},  broadcasting class centers among clients is essential for recognition performances but leads to privacy leakage. To resolve the privacy-utility paradox, this work proposes PrivacyFace, a framework largely improves the federated learning face recognition via communicating auxiliary and privacy-agnostic information among clients. PrivacyFace mainly consists of two components: First, a practical Differentially Private Local Clustering (DPLC) mechanism is proposed to distill sanitized clusters from local class centers. Second, a consensus-aware recognition loss subsequently encourages global consensuses among clients, which ergo leads to more discriminative features. The proposed schemes are mathematically proved to be differential private, introduce a lightweight overhead as well as yield prominent performance boosts (\\textit{e.g.}, +9.63\\% and +10.26\\% for TAR@FAR=1e-4 on IJB-B and IJB-C respectively). Extensive experiments and ablation studies on a large-scale dataset have demonstrated the efficacy and practicability of our method.  ",
        "conference": "ICLR",
        "中文标题": "通过隐私无关聚类改进联邦学习人脸识别",
        "摘要翻译": "公众对人脸识别中数据隐私的日益关注可以通过联邦学习（FL）范式部分缓解。然而，由于任务的特殊性，传统的FL方法通常表现不佳，即在客户端之间广播类中心对于识别性能至关重要，但会导致隐私泄露。为了解决隐私与效用之间的矛盾，本研究提出了PrivacyFace，一个通过在客户端之间交流辅助和隐私无关信息来大幅改进联邦学习人脸识别的框架。PrivacyFace主要由两个部分组成：首先，提出了一种实用的差分隐私本地聚类（DPLC）机制，从本地类中心中提取经过消毒的聚类。其次，一个共识感知的识别损失随后鼓励客户端之间的全局共识，从而产生更具区分性的特征。所提出的方案在数学上被证明是差分隐私的，引入了轻量级的开销，并带来了显著的性能提升（例如，在IJB-B和IJB-C上，TAR@FAR=1e-4分别提高了9.63%和10.26%）。在大规模数据集上的广泛实验和消融研究证明了我们方法的有效性和实用性。",
        "领域": "人脸识别、联邦学习、隐私保护",
        "问题": "解决联邦学习在人脸识别任务中隐私泄露与识别性能之间的矛盾",
        "动机": "传统联邦学习方法在人脸识别任务中因需广播类中心而导致隐私泄露，影响识别性能",
        "方法": "提出PrivacyFace框架，包括差分隐私本地聚类机制和共识感知的识别损失，以在保护隐私的同时提升识别性能",
        "关键词": [
            "联邦学习",
            "人脸识别",
            "隐私保护",
            "差分隐私",
            "聚类"
        ],
        "涉及的技术概念": {
            "差分隐私本地聚类（DPLC）": "从本地类中心中提取经过消毒的聚类，保护用户隐私",
            "共识感知的识别损失": "鼓励客户端之间的全局共识，提升特征的区分性",
            "联邦学习（FL）": "一种分布式机器学习方法，允许多个客户端在保护数据隐私的前提下共同训练模型"
        },
        "success": true
    },
    {
        "order": 466,
        "title": "Improving Mutual Information Estimation with Annealed and Energy-Based Bounds",
        "html": "https://iclr.cc//virtual/2022/poster/6176",
        "abstract": "Mutual information (MI) is a fundamental quantity in information theory and machine learning. However, direct estimation of mutual information is intractable, even if the true joint probability density for the variables of interest is known, as it involves estimating a potentially high-dimensional log partition function. In this work, we view mutual information estimation from the perspective of importance sampling. Since naive importance sampling with the marginal distribution as a proposal requires exponential sample complexity in the true mutual information, we propose several improved proposals which assume additional density information is available. In settings where the full joint distribution is available, we propose Multi-Sample Annealed Importance Sampling (AIS) bounds on mutual information, which we demonstrate can tightly estimate large values of MI in our experiments. In settings where only a single marginal distribution is known, our MINE-AIS method improves upon existing variational methods by directly optimizing a tighter lower bound on MI, using energy-based training to estimate gradients and Multi-Sample AIS for evaluation. Our methods are particularly suitable for evaluating MI in deep generative models, since explicit forms for the marginal or joint densities are often available. We evaluate our bounds on estimating the MI of VAEs and GANs trained on the MNIST and CIFAR datasets, and showcase significant gains over existing bounds in these challenging settings with high ground truth MI.",
        "conference": "ICLR",
        "中文标题": "通过退火和基于能量的界限改进互信息估计",
        "摘要翻译": "互信息（MI）是信息论和机器学习中的一个基本量。然而，直接估计互信息是难以处理的，即使已知感兴趣变量的真实联合概率密度，因为它涉及到估计一个可能高维的对数配分函数。在这项工作中，我们从重要性采样的角度看待互信息估计。由于使用边际分布作为提议的朴素重要性采样在真实互信息中需要指数样本复杂度，我们提出了几种改进的提议，这些提议假设额外的密度信息是可用的。在可以获得完整联合分布的情况下，我们提出了互信息的多样本退火重要性采样（AIS）界限，我们在实验中证明这可以紧密估计大的MI值。在仅知道单一边际分布的情况下，我们的MINE-AIS方法通过直接优化MI的更紧下界，使用基于能量的训练来估计梯度和多样本AIS进行评估，改进了现有的变分方法。我们的方法特别适用于评估深度生成模型中的MI，因为边际或联合密度的显式形式通常是可用的。我们在MNIST和CIFAR数据集上训练的VAEs和GANs的MI估计上评估了我们的界限，并在这些具有高真实MI的挑战性设置中展示了相对于现有界限的显著增益。",
        "领域": "信息论与机器学习、深度生成模型、变分方法",
        "问题": "直接估计互信息的高维对数配分函数难以处理的问题",
        "动机": "改进互信息估计的准确性和效率，特别是在高维和复杂模型中的应用",
        "方法": "提出多样本退火重要性采样（AIS）界限和MINE-AIS方法，利用基于能量的训练和多样本AIS进行优化和评估",
        "关键词": [
            "互信息估计",
            "退火重要性采样",
            "深度生成模型",
            "变分方法",
            "能量基于训练"
        ],
        "涉及的技术概念": {
            "多样本退火重要性采样（AIS）": "用于估计互信息的界限，特别是在高维情况下，通过退火过程提高估计的准确性",
            "MINE-AIS方法": "一种改进的变分方法，直接优化互信息的更紧下界，适用于单一边际分布已知的情况",
            "基于能量的训练": "用于估计梯度，优化互信息估计过程，提高模型的训练效率和估计准确性"
        },
        "success": true
    },
    {
        "order": 467,
        "title": "Improving Non-Autoregressive Translation Models Without Distillation",
        "html": "https://iclr.cc//virtual/2022/poster/7197",
        "abstract": "Transformer-based autoregressive (AR) machine translation models have achieved significant performance improvements, nearing human-level accuracy on some languages. The AR framework translates one token at a time which can be time consuming, especially for long sequences. To accelerate inference, recent work has been exploring non-autoregressive (NAR) approaches that translate blocks of tokens in parallel. Despite significant progress, leading NAR models still lag behind their AR counterparts, and only become competitive when trained with distillation. In this paper we investigate possible reasons behind this performance gap, namely, the indistinguishability of tokens, and mismatch between training and inference. We then propose the Conditional Masked Language Model with Correction (CMLMC) that addresses these problems. Empirically, we show that CMLMC achieves state-of-the-art NAR performance when trained on raw data without distillation and approaches AR performance on multiple datasets. Full code for this work will be released at the time of publication.",
        "conference": "ICLR",
        "中文标题": "无需蒸馏改进非自回归翻译模型",
        "摘要翻译": "基于Transformer的自回归（AR）机器翻译模型已实现显著的性能提升，在某些语言上接近人类水平的准确度。AR框架一次翻译一个标记，这可能耗时较长，尤其是对于长序列。为了加速推理，最近的研究开始探索能够并行翻译标记块的非自回归（NAR）方法。尽管取得了显著进展，领先的NAR模型仍落后于其AR对应模型，并且只有在使用蒸馏训练时才具有竞争力。在本文中，我们调查了这种性能差距背后的可能原因，即标记的不可区分性以及训练与推理之间的不匹配。然后，我们提出了条件掩码语言模型与校正（CMLMC）来解决这些问题。实证表明，CMLMC在未经蒸馏的原始数据上训练时实现了最先进的NAR性能，并在多个数据集上接近AR性能。本工作的完整代码将在发表时发布。",
        "领域": "机器翻译、自然语言处理、深度学习",
        "问题": "非自回归翻译模型在未经蒸馏训练时性能落后于自回归模型",
        "动机": "探索非自回归翻译模型性能差距的原因，并提出改进方法以减少与自回归模型的差距",
        "方法": "提出条件掩码语言模型与校正（CMLMC）方法，解决标记不可区分性和训练与推理不匹配的问题",
        "关键词": [
            "非自回归翻译",
            "条件掩码语言模型",
            "机器翻译",
            "性能改进",
            "无需蒸馏"
        ],
        "涉及的技术概念": {
            "非自回归（NAR）翻译": "并行翻译标记块以加速推理的机器翻译方法",
            "条件掩码语言模型与校正（CMLMC）": "提出的新方法，旨在解决NAR模型中的标记不可区分性和训练推理不匹配问题",
            "蒸馏训练": "一种训练方法，通过让模型学习另一个模型的输出来提高性能，但本文提出的方法无需此过程"
        },
        "success": true
    },
    {
        "order": 468,
        "title": "Improving the Accuracy of Learning Example Weights for Imbalance Classification",
        "html": "https://iclr.cc//virtual/2022/poster/6446",
        "abstract": "To solve the imbalance classification, methods of weighting examples have been proposed. Recent work has studied to assign adaptive weights to training examples through learning mechanisms, that is, the weights, similar to classification models, are regarded as parameters that need to be learned. However, the algorithms in recent work use local information to approximately optimize the weights, which may lead to inaccurate learning of the weights. In this work, we first propose a novel mechanism of learning with a constraint, which can accurately train the weights and model. Then, we propose a combined method of our learning mechanism and the work by Hu et al., which can promote each other to perform better. Our proposed method can be applied to any type of deep network model. Experiments show that compared with the state-of-the-art algorithms, our method has significant improvement in varieties of settings, including text and image classification over different imbalance ratios, binary and multi-class classification.",
        "conference": "ICLR",
        "中文标题": "提高不平衡分类中学习样本权重的准确性",
        "摘要翻译": "为了解决不平衡分类问题，已经提出了加权样本的方法。最近的工作研究了通过学习机制为训练样本分配自适应权重，即权重与分类模型类似，被视为需要学习的参数。然而，最近工作中的算法使用局部信息来近似优化权重，这可能导致权重学习不准确。在这项工作中，我们首先提出了一种带有约束的新学习机制，可以准确训练权重和模型。然后，我们提出了一种将我们的学习机制与Hu等人的工作相结合的方法，这种方法可以相互促进，表现更好。我们提出的方法可以应用于任何类型的深度网络模型。实验表明，与最先进的算法相比，我们的方法在各种设置下都有显著改进，包括不同不平衡比例的文本和图像分类，二分类和多分类。",
        "领域": "不平衡学习、深度学习优化、分类算法",
        "问题": "解决不平衡分类中样本权重学习不准确的问题",
        "动机": "现有方法使用局部信息近似优化权重，导致权重学习不准确，影响分类性能",
        "方法": "提出一种带有约束的新学习机制，准确训练权重和模型，并与现有方法结合以相互促进",
        "关键词": [
            "不平衡分类",
            "样本权重学习",
            "深度学习优化",
            "约束学习机制",
            "分类算法改进"
        ],
        "涉及的技术概念": {
            "样本权重学习": "通过学习机制为训练样本分配自适应权重，视为需要学习的参数",
            "约束学习机制": "提出的一种新机制，用于准确训练权重和模型，避免局部信息导致的权重学习不准确",
            "深度网络模型": "提出的方法可以应用于任何类型的深度网络模型，提高分类性能"
        },
        "success": true
    },
    {
        "order": 469,
        "title": "In a Nutshell, the Human Asked for This: Latent Goals for Following Temporal Specifications",
        "html": "https://iclr.cc//virtual/2022/poster/7075",
        "abstract": "We address the problem of building agents whose goal is to learn to execute out-of distribution (OOD) multi-task instructions expressed in temporal logic (TL) by using deep reinforcement learning (DRL). Recent works provided evidence that the agent's neural architecture is a key feature when DRL agents are learning to solve OOD tasks in TL. Yet, the studies on this topic are still in their infancy. In this work, we propose a new deep learning configuration with inductive biases that lead agents to generate latent representations of their current goal, yielding a stronger generalization performance. We use these latent-goal networks within a neuro-symbolic framework that executes multi-task formally-defined instructions and contrast the performance of the proposed neural networks against employing different state-of-the-art (SOTA) architectures when generalizing to unseen instructions in OOD environments. ",
        "conference": "ICLR",
        "中文标题": "简而言之，人类提出了这个要求：遵循时间规范的潜在目标",
        "摘要翻译": "我们解决了构建代理的问题，这些代理的目标是学习执行通过深度强化学习（DRL）表达的时间逻辑（TL）中的分布外（OOD）多任务指令。最近的工作提供了证据，表明当DRL代理学习解决TL中的OOD任务时，代理的神经架构是一个关键特征。然而，关于这一主题的研究仍处于起步阶段。在这项工作中，我们提出了一种新的深度学习配置，具有归纳偏差，引导代理生成其当前目标的潜在表示，从而产生更强的泛化性能。我们在一个神经符号框架内使用这些潜在目标网络，该框架执行多任务正式定义的指令，并将提出的神经网络与在OOD环境中泛化到未见指令时采用的不同最先进（SOTA）架构的性能进行对比。",
        "领域": "深度强化学习、时间逻辑、多任务学习",
        "问题": "构建能够学习执行分布外多任务指令的代理，这些指令通过时间逻辑表达。",
        "动机": "研究如何通过改进代理的神经架构，提高其在时间逻辑中解决分布外任务的泛化能力。",
        "方法": "提出了一种新的深度学习配置，利用归纳偏差生成潜在目标表示，并在神经符号框架中对比不同架构的性能。",
        "关键词": [
            "深度强化学习",
            "时间逻辑",
            "多任务学习",
            "神经符号框架",
            "泛化性能"
        ],
        "涉及的技术概念": {
            "深度强化学习（DRL）": "用于训练代理学习执行多任务指令的核心方法。",
            "时间逻辑（TL）": "用于表达多任务指令的形式化语言。",
            "神经符号框架": "结合神经网络和符号逻辑的框架，用于执行和理解正式定义的指令。"
        },
        "success": true
    },
    {
        "order": 470,
        "title": "Increasing the Cost of Model Extraction with Calibrated Proof of Work",
        "html": "https://iclr.cc//virtual/2022/poster/6513",
        "abstract": "In model extraction attacks, adversaries can steal a machine learning model exposed via a public API by repeatedly querying it and adjusting their own model based on obtained predictions. To prevent model stealing, existing defenses focus on detecting malicious queries, truncating, or distorting outputs, thus necessarily introducing a tradeoff between robustness and model utility for legitimate users. Instead, we propose to impede model extraction by requiring users to complete a proof-of-work before they can read the model's predictions. This deters attackers by greatly increasing (even up to 100x) the computational effort needed to leverage query access for model extraction. Since we calibrate the effort required to complete the proof-of-work to each query, this only introduces a slight overhead for regular users (up to 2x). To achieve this, our calibration applies tools from differential privacy to measure the information revealed by a query. Our method requires no modification of the victim model and can be applied by machine learning practitioners to guard their publicly exposed models against being easily stolen.",
        "conference": "ICLR",
        "中文标题": "通过校准工作量证明提高模型提取的成本",
        "摘要翻译": "在模型提取攻击中，攻击者可以通过重复查询公开API并基于获得的预测调整自己的模型来窃取机器学习模型。为了防止模型被窃取，现有的防御措施主要集中在检测恶意查询、截断或扭曲输出，这必然在鲁棒性和合法用户的模型效用之间引入权衡。相反，我们提出通过要求用户在读取模型的预测之前完成工作量证明来阻碍模型提取。这通过大大增加（甚至高达100倍）利用查询访问进行模型提取所需的计算努力来阻止攻击者。由于我们校准了完成工作量证明所需的努力以适应每个查询，这仅为常规用户引入了轻微的开销（最多2倍）。为了实现这一点，我们的校准应用了差分隐私工具来衡量查询揭示的信息。我们的方法不需要修改受害模型，机器学习从业者可以应用它来保护他们公开暴露的模型不被轻易窃取。",
        "领域": "模型安全、差分隐私、机器学习防御",
        "问题": "如何有效防止通过公开API进行的模型提取攻击，同时最小化对合法用户的影响。",
        "动机": "现有的模型提取防御措施在鲁棒性和模型效用之间存在权衡，需要一种既能有效阻止攻击者又不显著影响合法用户的方法。",
        "方法": "提出了一种基于校准工作量证明的方法，通过增加攻击者进行模型提取所需的计算努力来阻止攻击，同时通过差分隐私工具校准工作量证明，最小化对合法用户的影响。",
        "关键词": [
            "模型提取防御",
            "工作量证明",
            "差分隐私",
            "模型安全",
            "机器学习"
        ],
        "涉及的技术概念": {
            "模型提取攻击": "攻击者通过查询公开API并基于响应调整自己的模型来窃取机器学习模型的行为。",
            "工作量证明": "一种要求用户完成一定计算任务以证明其合法性的机制，用于增加攻击者的成本。",
            "差分隐私": "一种隐私保护技术，用于衡量和限制查询操作中信息泄露的程度，确保用户数据的安全。"
        },
        "success": true
    },
    {
        "order": 471,
        "title": "Incremental False Negative Detection for Contrastive Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6346",
        "abstract": "Self-supervised learning has recently shown great potential in vision tasks through contrastive learning, which aims to discriminate each image, or instance, in the dataset. However, such instance-level learning ignores the semantic relationship among instances and sometimes undesirably repels the anchor from the semantically similar samples, termed as 'false negatives'. In this work, we show that the unfavorable effect from false negatives is more significant for the large-scale datasets with more semantic concepts. To address the issue, we propose a novel self-supervised contrastive learning framework that incrementally detects and explicitly removes the false negative samples. Specifically, following the training process, our method dynamically detects increasing high-quality false negatives considering that the encoder gradually improves and the embedding space becomes more semantically structural. Next, we discuss two strategies to explicitly remove the detected false negatives during contrastive learning. Extensive experiments show that our framework outperforms other self-supervised contrastive learning methods on multiple benchmarks in a limited resource setup.",
        "conference": "ICLR",
        "中文标题": "对比学习中增量式假阴性检测",
        "摘要翻译": "自监督学习最近通过对比学习在视觉任务中显示出巨大潜力，其目的是区分数据集中的每个图像或实例。然而，这种实例级别的学习忽略了实例之间的语义关系，有时不理想地将锚点从语义相似的样本中排斥出去，这被称为‘假阴性’。在这项工作中，我们展示了假阴性的不利影响对于具有更多语义概念的大规模数据集更为显著。为了解决这个问题，我们提出了一种新颖的自监督对比学习框架，该框架增量地检测并显式地移除假阴性样本。具体来说，随着训练过程的进行，考虑到编码器逐渐改进且嵌入空间变得更加语义结构化，我们的方法动态检测出越来越多高质量的假阴性。接下来，我们讨论了在对比学习期间显式移除检测到的假阴性的两种策略。大量实验表明，在资源有限的情况下，我们的框架在多个基准测试中优于其他自监督对比学习方法。",
        "领域": "自监督学习、对比学习、视觉表示学习",
        "问题": "解决对比学习中假阴性样本对模型性能的不利影响",
        "动机": "假阴性样本在对比学习中排斥语义相似样本，影响模型性能，尤其是在大规模数据集上",
        "方法": "提出一种增量检测并显式移除假阴性样本的自监督对比学习框架",
        "关键词": [
            "假阴性检测",
            "对比学习",
            "自监督学习",
            "语义相似性",
            "嵌入空间"
        ],
        "涉及的技术概念": {
            "假阴性": "在对比学习中被错误地排斥的语义相似样本，影响模型学习正确的语义关系",
            "对比学习": "一种自监督学习方法，通过区分不同实例来学习有效的特征表示",
            "嵌入空间": "模型将输入数据映射到的空间，理想情况下应反映数据的语义结构"
        },
        "success": true
    },
    {
        "order": 472,
        "title": "Independent SE(3)-Equivariant Models for End-to-End Rigid Protein Docking",
        "html": "https://iclr.cc//virtual/2022/poster/7055",
        "abstract": "Protein complex formation is a central problem in biology, being involved in most of the cell's processes, and essential for applications, e.g. drug design or protein engineering. We tackle rigid body protein-protein docking, i.e., computationally predicting the 3D structure of a protein-protein complex from the individual unbound structures, assuming no conformational change within the proteins happens during binding. We design a novel pairwise-independent SE(3)-equivariant graph matching network to predict the rotation and translation to place one of the proteins at the right docked position relative to the second protein. We mathematically guarantee a basic principle: the predicted complex is always identical regardless of the initial locations and orientations of the two structures. Our model, named EquiDock, approximates the binding pockets and predicts the docking poses using keypoint matching and alignment, achieved through optimal transport and a differentiable Kabsch algorithm. Empirically, we achieve significant running time improvements and often outperform existing  docking software despite not relying on heavy candidate sampling, structure refinement, or templates.",
        "conference": "ICLR",
        "中文标题": "独立SE(3)-等变模型用于端到端刚性蛋白质对接",
        "摘要翻译": "蛋白质复合物的形成是生物学中的一个核心问题，涉及细胞的大部分过程，并且对于药物设计或蛋白质工程等应用至关重要。我们解决了刚性蛋白质-蛋白质对接问题，即从单个未结合结构计算预测蛋白质-蛋白质复合物的3D结构，假设在结合过程中蛋白质内部没有构象变化。我们设计了一种新颖的成对独立SE(3)-等变图匹配网络，以预测将一个蛋白质相对于第二个蛋白质放置在正确对接位置所需的旋转和平移。我们在数学上保证了一个基本原则：无论两个结构的初始位置和方向如何，预测的复合物总是相同的。我们的模型名为EquiDock，通过关键点匹配和对齐来近似结合口袋并预测对接姿态，这是通过最优传输和可微分的Kabsch算法实现的。经验上，尽管不依赖于大量的候选采样、结构细化或模板，我们实现了显著的运行时间改进，并且经常优于现有的对接软件。",
        "领域": "蛋白质结构预测, 生物信息学, 计算生物学",
        "问题": "计算预测蛋白质-蛋白质复合物的3D结构，假设在结合过程中蛋白质内部没有构象变化。",
        "动机": "解决刚性蛋白质-蛋白质对接问题，为药物设计或蛋白质工程等应用提供支持。",
        "方法": "设计了一种成对独立SE(3)-等变图匹配网络，通过关键点匹配和对齐来预测对接姿态，使用最优传输和可微分的Kabsch算法。",
        "关键词": [
            "蛋白质对接",
            "SE(3)-等变",
            "图匹配网络",
            "最优传输",
            "Kabsch算法"
        ],
        "涉及的技术概念": {
            "SE(3)-等变": "确保模型预测结果不受蛋白质初始位置和方向的影响，保持空间变换的一致性。",
            "最优传输": "用于在蛋白质对接过程中优化关键点匹配，提高对接姿态预测的准确性。",
            "Kabsch算法": "一种可微分的算法，用于计算最佳旋转和平移，以实现蛋白质结构的精确对齐。"
        },
        "success": true
    },
    {
        "order": 473,
        "title": "Inductive Relation Prediction Using Analogy Subgraph Embeddings",
        "html": "https://iclr.cc//virtual/2022/poster/5914",
        "abstract": "Prevailing methods for relation prediction in heterogeneous graphs aim at learning latent representations (i.e., embeddings) of observed nodes and relations, and thus are limited to the transductive setting where the relation types must be known during training.  Here,  we propose ANalogy  SubGraphEmbeddingLearning (GraphANGEL), a novel relation prediction framework that predicts relations5between each node pair based on the subgraphs containing the pair, as well as other  (analogy)  subgraphs with the same graph patterns.   Each graph pattern explicitly represents a specific logical rule, which contributes to an inductive bias that facilitates generalization to unseen relations and leads to more explainable predictive models. Moreover, our method also removes the limited neighborhood constraint of graph neural networks. Our model consistently outperforms existing models on heterogeneous graph based recommendation as well as knowledge graph completion.  We also empirically demonstrate our model’s capability in generalizing to new relations while producing explainable heat maps of attention scores across the discovered logic.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "基于类比子图嵌入的归纳关系预测",
        "摘要翻译": "当前在异质图中进行关系预测的主流方法旨在学习观察到的节点和关系的潜在表示（即嵌入），因此仅限于在训练期间必须知道关系类型的转导设置。在此，我们提出了ANalogy SubGraphEmbeddingLearning（GraphANGEL），一种新颖的关系预测框架，该框架基于包含节点对的子图以及其他具有相同图模式的（类比）子图来预测每对节点之间的关系。每个图模式明确表示一个特定的逻辑规则，这有助于形成一种归纳偏置，促进对未见关系的泛化，并导致更可解释的预测模型。此外，我们的方法还消除了图神经网络的有限邻域约束。我们的模型在基于异质图的推荐以及知识图补全上一致优于现有模型。我们还通过实验证明了我们的模型在泛化到新关系的同时，能够生成跨发现逻辑的注意力分数的可解释热图的能力。",
        "领域": "知识图谱补全, 异质图分析, 图神经网络",
        "问题": "解决在异质图中预测未见关系类型的问题，以及提高预测模型的可解释性。",
        "动机": "现有的关系预测方法局限于转导设置，无法泛化到未见的关系类型，且缺乏解释性。",
        "方法": "提出GraphANGEL框架，通过类比子图嵌入学习，利用子图和相同图模式的类比子图进行关系预测，引入逻辑规则作为归纳偏置。",
        "关键词": [
            "异质图",
            "关系预测",
            "子图嵌入",
            "归纳学习",
            "可解释性"
        ],
        "涉及的技术概念": {
            "类比子图嵌入": "用于捕捉节点对之间的关系模式，基于子图和类比子图进行预测。",
            "逻辑规则": "作为归纳偏置，帮助模型泛化到未见关系，并提高预测的可解释性。",
            "注意力机制": "生成可解释的热图，展示模型在预测过程中关注的逻辑部分。"
        }
    },
    {
        "order": 474,
        "title": "InfinityGAN: Towards Infinite-Pixel Image Synthesis",
        "html": "https://iclr.cc//virtual/2022/poster/6857",
        "abstract": "We present InfinityGAN, a method to generate arbitrary-sized images. The problem is associated with several key challenges. First, scaling existing models to an arbitrarily large image size is resource-constrained, both in terms of computation and availability of large-field-of-view training data. InfinityGAN trains and infers patch-by-patch seamlessly with low computational resources. Second, large images should be locally and globally consistent, avoid repetitive patterns, and look realistic. To address these, InfinityGAN takes global appearance, local structure and texture into account. With this formulation, we can generate images with spatial size and level of detail not attainable before. Experimental evaluation supports that InfinityGAN generates images with superior global structure compared to baselines and features parallelizable inference. Finally, we show several applications unlocked by our approach, such as fusing styles spatially, multi-modal outpainting and image inbetweening at arbitrary input and output sizes.",
        "conference": "ICLR",
        "中文标题": "InfinityGAN：迈向无限像素图像合成",
        "摘要翻译": "我们提出了InfinityGAN，一种生成任意大小图像的方法。这一问题涉及几个关键挑战。首先，将现有模型扩展到任意大图像尺寸受到资源限制，包括计算和大视场训练数据的可用性。InfinityGAN以低计算资源无缝地进行逐块训练和推断。其次，大图像应在局部和全局上保持一致，避免重复模式，并看起来真实。为了解决这些问题，InfinityGAN考虑了全局外观、局部结构和纹理。通过这种形式，我们可以生成以前无法达到的空间大小和细节水平的图像。实验评估支持InfinityGAN生成的图像在全局结构上优于基线，并具有可并行化的推断特性。最后，我们展示了我们的方法解锁的几个应用，如空间风格融合、多模态外推和任意输入输出大小的图像中间生成。",
        "领域": "图像生成、生成对抗网络、图像合成",
        "问题": "生成任意大小的高质量图像，同时解决计算资源限制和图像一致性问题",
        "动机": "解决现有模型在生成大尺寸图像时的资源限制和图像一致性问题",
        "方法": "采用逐块训练和推断的方法，结合全局外观、局部结构和纹理考虑，以低计算资源生成高质量大尺寸图像",
        "关键词": [
            "无限像素图像合成",
            "生成对抗网络",
            "图像一致性",
            "并行化推断",
            "多模态外推"
        ],
        "涉及的技术概念": {
            "逐块训练和推断": "通过分块处理大图像，降低计算资源需求，实现无缝训练和推断",
            "全局与局部一致性": "确保生成的大图像在整体和细节上均保持高质量和一致性",
            "并行化推断": "支持并行处理，提高图像生成效率"
        },
        "success": true
    },
    {
        "order": 475,
        "title": "Information Bottleneck: Exact Analysis of (Quantized) Neural Networks",
        "html": "https://iclr.cc//virtual/2022/poster/6830",
        "abstract": "The information bottleneck (IB) principle has been suggested as a way to analyze deep neural networks. The learning dynamics are studied by inspecting the mutual information (MI) between the hidden layers and the input and output. Notably, separate fitting and compression phases  during training have been reported. This led to some controversy including claims that the observations are not reproducible and strongly dependent on the type of activation function used as well as on the way the MI is estimated. Our study confirms that  different ways of binning  when computing the MI lead to qualitatively different results, either supporting or refusing IB conjectures.To resolve the controversy, we study the IB principle in settings where MI is non-trivial and can be computed exactly. We monitor the dynamics of quantized neural networks, that is, we discretize the whole deep learning system so that no approximation is required when computing the MI. This allows us to quantify the information flow without measurement errors. In this setting, we observed a fitting phase for all layers and a compression phase for the output layer in all experiments; the compression in the hidden layers was dependent on the type of activation function. Our study shows that the initial IB results were not artifacts of binning when computing the MI. However, the critical claim that the compression phase may not be observed for some networks also holds true.",
        "conference": "ICLR",
        "中文标题": "信息瓶颈：量化神经网络的精确分析",
        "摘要翻译": "信息瓶颈（IB）原理被提出作为分析深度神经网络的一种方法。通过检查隐藏层与输入和输出之间的互信息（MI）来研究学习动态。值得注意的是，训练期间单独的拟合和压缩阶段已被报告。这引发了一些争议，包括声称观察结果不可复现且强烈依赖于所使用的激活函数类型以及MI的估计方式。我们的研究证实，在计算MI时不同的分箱方式会导致性质上不同的结果，要么支持要么拒绝IB猜想。为了解决争议，我们在MI非平凡且可以精确计算的设置中研究IB原理。我们监控量化神经网络的动态，即离散化整个深度学习系统，以便在计算MI时不需要近似。这使我们能够量化信息流而无需测量误差。在这种设置下，我们在所有实验中观察到所有层的拟合阶段和输出层的压缩阶段；隐藏层的压缩依赖于激活函数的类型。我们的研究表明，最初的IB结果并非计算MI时分箱的伪影。然而，对于某些网络可能观察不到压缩阶段的这一关键主张也成立。",
        "领域": "深度学习理论、神经网络分析、信息论应用",
        "问题": "解决信息瓶颈原理在分析深度神经网络时的争议和不可复现性问题",
        "动机": "为了澄清信息瓶颈原理在神经网络分析中的应用，并解决由于互信息估计方法不同导致的争议",
        "方法": "通过量化神经网络，精确计算互信息，避免近似误差，从而研究信息瓶颈原理在不同网络设置下的表现",
        "关键词": [
            "信息瓶颈",
            "互信息",
            "量化神经网络",
            "深度学习动态",
            "激活函数"
        ],
        "涉及的技术概念": {
            "信息瓶颈": "用于分析神经网络中信息流动的原理，旨在理解和优化网络的信息处理能力",
            "互信息": "衡量两个变量之间相互依赖性的指标，用于研究神经网络隐藏层与输入输出之间的关系",
            "量化神经网络": "通过离散化网络参数和激活值，使得互信息可以精确计算，避免近似误差的技术"
        },
        "success": true
    },
    {
        "order": 476,
        "title": "Information Gain Propagation: a New Way to Graph Active Learning with Soft Labels",
        "html": "https://iclr.cc//virtual/2022/poster/6074",
        "abstract": "Graph Neural Networks (GNNs) have achieved great success in various tasks, but their performance highly relies on a large number of labeled nodes, which typically requires considerable human effort. GNN-based Active Learning (AL) methods are proposed to improve the labeling efficiency by selecting the most valuable nodes to label. Existing methods assume an oracle can correctly categorize all the selected nodes and thus just focus on the node selection. However, such an exact labeling task is costly, especially when the categorization is out of the domain of individual expert (oracle). The paper goes further, presenting a soft-label approach to AL on GNNs. Our key innovations are: i) relaxed queries where a domain expert (oracle) only judges the correctness of the predicted labels (a binary question) rather than identifying the exact class (a multi-class question), and ii) new criteria of maximizing information gain propagation for active learner with relaxed queries and soft labels. Empirical studies on public datasets demonstrate that our method significantly outperforms the state-of-the-art GNN-based AL methods in terms of both accuracy and labeling cost. ",
        "conference": "ICLR",
        "中文标题": "信息增益传播：一种基于软标签的图主动学习新方法",
        "摘要翻译": "图神经网络（GNNs）在各种任务中取得了巨大成功，但其性能高度依赖于大量标记节点，这通常需要相当大的人力投入。基于GNN的主动学习（AL）方法通过选择最有价值的节点进行标记来提高标记效率。现有方法假设一个预言机可以正确分类所有选定的节点，因此只关注节点选择。然而，这种精确的标记任务成本高昂，特别是当分类超出个别专家（预言机）的领域时。本文进一步提出了一种基于GNNs的软标签主动学习方法。我们的关键创新是：i）宽松查询，其中领域专家（预言机）仅判断预测标签的正确性（一个二元问题）而不是识别确切的类别（一个多类问题），以及ii）新的标准，即最大化具有宽松查询和软标签的主动学习者的信息增益传播。在公共数据集上的实证研究表明，我们的方法在准确性和标记成本方面显著优于最先进的基于GNN的AL方法。",
        "领域": "图神经网络、主动学习、软标签学习",
        "问题": "如何减少图神经网络训练中对大量精确标记节点的依赖，同时保持或提高模型的性能。",
        "动机": "现有的基于图神经网络的主动学习方法依赖于精确标记节点，这在实践中成本高昂且不切实际，尤其是在分类任务超出专家领域时。",
        "方法": "提出了一种基于软标签的主动学习方法，通过宽松查询（仅判断预测标签的正确性而非具体类别）和最大化信息增益传播的新标准，来优化节点选择和标记过程。",
        "关键词": [
            "图神经网络",
            "主动学习",
            "软标签",
            "信息增益传播",
            "标记效率"
        ],
        "涉及的技术概念": {
            "图神经网络（GNNs）": "用于处理图结构数据的深度学习模型，本文中作为基础模型进行节点分类任务。",
            "主动学习（AL）": "一种机器学习策略，通过选择最有价值的样本进行标记来减少标记成本，本文中应用于图数据。",
            "信息增益传播": "本文提出的新标准，用于评估和选择能够最大化信息增益的节点进行标记，以提高模型性能。"
        },
        "success": true
    },
    {
        "order": 477,
        "title": "Information Prioritization through Empowerment in Visual Model-based RL",
        "html": "https://iclr.cc//virtual/2022/poster/6014",
        "abstract": "Model-based reinforcement learning (RL) algorithms designed for handling complex visual observations typically learn some sort of latent state representation, either explicitly or implicitly. Standard methods of this sort do not distinguish between functionally relevant aspects of the state and irrelevant distractors, instead aiming to represent all available information equally. We propose a modified objective for model-based RL that, in combination with mutual information maximization, allows us to learn representations and dynamics for visual model-based RL without reconstruction in a way that explicitly prioritizes functionally relevant factors. The key principle behind our design is to integrate a term inspired by variational empowerment into a state-space learning model based on mutual information. This term prioritizes information that is correlated with action, thus ensuring that functionally relevant factors are captured first. Furthermore, the same empowerment term also promotes faster exploration during the RL process, especially for sparse-reward tasks where the reward signal is insufficient to drive exploration in the early stages of learning. We evaluate the approach on a suite of vision-based robot control tasks with natural video backgrounds, and show that the proposed prioritized information objective outperforms state-of-the-art model based RL approaches by an average of 20\\% in terms of episodic returns at 1M environment interactions with 30\\% higher sample efficiency at 100k interactions.",
        "conference": "ICLR",
        "中文标题": "通过赋能在视觉模型强化学习中实现信息优先级排序",
        "摘要翻译": "为处理复杂视觉观察而设计的基于模型的强化学习（RL）算法通常会学习某种潜在状态表示，无论是显式还是隐式。这类标准方法不区分状态中功能相关的方面和不相关的干扰因素，而是旨在平等地表示所有可用信息。我们提出了一种修改后的基于模型RL的目标，结合互信息最大化，使我们能够以明确优先考虑功能相关因素的方式，无需重建即可学习视觉模型RL的表示和动态。我们设计背后的关键原则是将受变分赋能力启发的术语整合到基于互信息的状态空间学习模型中。该术语优先考虑与行动相关的信息，从而确保首先捕获功能相关因素。此外，同样的赋能力术语还促进了RL过程中更快的探索，特别是对于奖励稀疏的任务，在学习的早期阶段，奖励信号不足以驱动探索。我们在一套具有自然视频背景的基于视觉的机器人控制任务上评估了该方法，并表明所提出的优先级信息目标在1M环境交互时的情节回报方面平均优于最先进的基于模型RL方法20%，在100k交互时样本效率高出30%。",
        "领域": "强化学习",
        "问题": "如何在视觉模型强化学习中区分并优先处理功能相关的信息",
        "动机": "解决标准方法无法区分功能相关和不相关信息的问题，提高模型在复杂视觉任务中的表现和探索效率",
        "方法": "结合互信息最大化和受变分赋能力启发的术语，学习优先考虑功能相关因素的表示和动态",
        "关键词": [
            "强化学习",
            "信息优先级",
            "变分赋能",
            "互信息最大化",
            "视觉模型"
        ],
        "涉及的技术概念": {
            "互信息最大化": "用于学习状态表示和动态，确保捕获与行动相关的信息",
            "变分赋能": "整合到模型中，优先考虑与行动相关的信息，促进探索",
            "视觉模型强化学习": "专注于处理复杂视觉观察的强化学习方法，通过改进的信息优先级排序提高性能"
        },
        "success": true
    },
    {
        "order": 478,
        "title": "Information-theoretic Online Memory Selection for Continual Learning",
        "html": "https://iclr.cc//virtual/2022/poster/5961",
        "abstract": "A challenging problem in task-free continual learning is the online selection of a representative replay memory from data streams. In this work, we investigate the online memory selection problem from an information-theoretic perspective. To gather the most information, we propose the \\textit{surprise} and the \\textit{learnability} criteria to pick informative points and to avoid outliers. We present a Bayesian model to compute the criteria efficiently by exploiting rank-one matrix structures. We demonstrate that these criteria encourage selecting informative points in a greedy algorithm for online memory selection. Furthermore, by identifying the importance of \\textit{the timing to update the memory}, we introduce a stochastic information-theoretic reservoir sampler (InfoRS), which conducts sampling among selective points with high information. Compared to reservoir sampling, InfoRS demonstrates improved robustness against data imbalance. Finally, empirical performances over continual learning benchmarks manifest its efficiency and efficacy.",
        "conference": "ICLR",
        "中文标题": "持续学习中基于信息论的在线记忆选择",
        "摘要翻译": "在无任务持续学习中，一个具有挑战性的问题是从数据流中在线选择具有代表性的回放记忆。在这项工作中，我们从信息论的角度研究了在线记忆选择问题。为了收集最多的信息，我们提出了\textit{惊喜度}和\textit{可学习性}标准来选取信息量大的点并避免异常值。我们提出了一个贝叶斯模型，通过利用秩一矩阵结构高效地计算这些标准。我们证明了这些标准在在线记忆选择的贪心算法中鼓励选择信息量大的点。此外，通过识别\textit{更新记忆的时机}的重要性，我们引入了一种随机信息论水库采样器（InfoRS），它在高信息量的选择点中进行采样。与水库采样相比，InfoRS展示了对数据不平衡的更强鲁棒性。最后，在持续学习基准测试中的实证表现证明了其效率和有效性。",
        "领域": "持续学习",
        "问题": "如何从数据流中在线选择具有代表性的回放记忆",
        "动机": "解决无任务持续学习中的在线记忆选择问题，以提高学习效率和效果",
        "方法": "提出基于信息论的惊喜度和可学习性标准，结合贝叶斯模型和贪心算法，以及引入随机信息论水库采样器（InfoRS）进行高效记忆选择",
        "关键词": [
            "持续学习",
            "信息论",
            "在线记忆选择",
            "贝叶斯模型",
            "水库采样"
        ],
        "涉及的技术概念": {
            "惊喜度": "用于评估数据点的信息量，帮助选择最具信息量的点",
            "可学习性": "用于避免选择异常值，确保记忆中的点有助于模型学习",
            "随机信息论水库采样器（InfoRS）": "一种在高信息量点中进行采样的方法，提高了对数据不平衡的鲁棒性"
        },
        "success": true
    },
    {
        "order": 479,
        "title": "Interacting Contour Stochastic Gradient Langevin Dynamics",
        "html": "https://iclr.cc//virtual/2022/poster/7052",
        "abstract": "We propose an interacting contour stochastic gradient Langevin dynamics (ICSGLD) sampler, an embarrassingly parallel multiple-chain contour stochastic gradient Langevin dynamics (CSGLD) sampler with efficient interactions. We show that ICSGLD can be theoretically more efficient than a single-chain CSGLD with an equivalent computational budget. We also present a novel random-field function, which facilitates the estimation of self-adapting parameters in big data and obtains free mode explorations. Empirically, we compare the proposed algorithm with popular benchmark methods for posterior sampling. The numerical results show a great potential of ICSGLD for large-scale uncertainty estimation tasks.",
        "conference": "ICLR",
        "中文标题": "交互式轮廓随机梯度朗之万动力学",
        "摘要翻译": "我们提出了一种交互式轮廓随机梯度朗之万动力学（ICSGLD）采样器，这是一种具有高效交互的、令人尴尬的并行多链轮廓随机梯度朗之万动力学（CSGLD）采样器。我们证明，在相同的计算预算下，ICSGLD在理论上比单链CSGLD更高效。我们还提出了一种新颖的随机场函数，该函数有助于在大数据中估计自适应参数，并获得自由模式探索。实证上，我们将所提出的算法与后验采样的流行基准方法进行了比较。数值结果显示，ICSGLD在大规模不确定性估计任务中具有巨大潜力。",
        "领域": "贝叶斯深度学习、不确定性估计、并行计算",
        "问题": "如何在大规模数据中高效进行后验采样和不确定性估计",
        "动机": "提高在大规模数据环境下进行后验采样的效率和准确性，特别是在不确定性估计任务中",
        "方法": "提出了一种交互式轮廓随机梯度朗之万动力学（ICSGLD）采样器，通过多链并行和高效交互提高采样效率，并引入随机场函数优化参数估计",
        "关键词": [
            "交互式采样",
            "并行计算",
            "不确定性估计",
            "随机梯度朗之万动力学",
            "大数据"
        ],
        "涉及的技术概念": {
            "交互式轮廓随机梯度朗之万动力学（ICSGLD）": "一种多链并行采样方法，通过链间交互提高采样效率和准确性",
            "随机场函数": "用于在大数据中自适应估计参数，促进自由模式探索的新颖函数",
            "后验采样": "在贝叶斯统计中，用于从后验分布中抽取样本以进行不确定性估计的技术"
        },
        "success": true
    },
    {
        "order": 480,
        "title": "Interpretable Unsupervised Diversity Denoising and Artefact Removal",
        "html": "https://iclr.cc//virtual/2022/poster/5977",
        "abstract": "Image denoising and artefact removal are complex inverse problems admitting multiple valid solutions. Unsupervised diversity restoration, that is, obtaining a diverse set of possible restorations given a corrupted image, is important for ambiguity removal in many applications such as microscopy where paired data for supervised training are often unobtainable. In real world applications, imaging noise and artefacts are typically hard to model, leading to unsatisfactory performance of existing unsupervised approaches. This work presents an interpretable approach for unsupervised and diverse image restoration. To this end, we introduce a capable architecture called Hierarchical DivNoising (HDN) based on hierarchical Variational Autoencoder. We show that HDN learns an interpretable multi-scale representation of artefacts  and we leverage this interpretability to remove imaging artefacts commonly occurring in microscopy data. Our method achieves state-of-the-art results on twelve benchmark image denoising datasets while providing access to a whole distribution of sensibly restored solutions.Additionally, we demonstrate on three real microscopy datasets that HDN removes artefacts without supervision, being the first method capable of doing so while generating multiple plausible restorations all consistent with the given corrupted image.",
        "conference": "ICLR",
        "中文标题": "可解释的无监督多样性去噪与伪影去除",
        "摘要翻译": "图像去噪和伪影去除是复杂的逆问题，允许多种有效解决方案。无监督多样性恢复，即在给定损坏图像的情况下获得一组可能的恢复多样性，对于许多应用中的歧义消除非常重要，例如在显微镜学中，监督训练的配对数据往往难以获得。在现实世界的应用中，成像噪声和伪影通常难以建模，导致现有无监督方法的性能不尽如人意。这项工作提出了一种可解释的无监督多样性图像恢复方法。为此，我们引入了一种称为分层多样性去噪（HDN）的强大架构，基于分层变分自编码器。我们展示了HDN学习了一个可解释的多尺度伪影表示，并利用这种可解释性去除显微镜数据中常见的成像伪影。我们的方法在十二个基准图像去噪数据集上实现了最先进的结果，同时提供了对整个合理恢复解决方案分布的访问。此外，我们在三个真实的显微镜数据集上证明，HDN无需监督即可去除伪影，是首个能够在生成多个与给定损坏图像一致的可能恢复的同时做到这一点的方法。",
        "领域": "图像去噪、显微镜图像处理、无监督学习",
        "问题": "解决在无监督条件下，对图像进行多样性去噪和伪影去除的复杂逆问题。",
        "动机": "在显微镜等应用中，由于难以获得监督训练的配对数据，需要开发一种能够在不依赖监督数据的情况下，进行多样性图像恢复和伪影去除的方法。",
        "方法": "提出了一种基于分层变分自编码器的分层多样性去噪（HDN）架构，通过学习可解释的多尺度伪影表示来去除伪影，并在无监督条件下实现多样性图像恢复。",
        "关键词": [
            "无监督学习",
            "图像去噪",
            "伪影去除",
            "多样性恢复",
            "分层变分自编码器"
        ],
        "涉及的技术概念": {
            "分层变分自编码器": "用于构建HDN架构的核心技术，通过学习数据的层次化表示来实现图像恢复。",
            "多样性恢复": "指在图像恢复过程中生成多个合理且多样的解决方案，以解决逆问题中的歧义。",
            "多尺度伪影表示": "HDN学习到的伪影表示，能够在不同尺度上识别和去除图像中的伪影，提高恢复质量。"
        },
        "success": true
    },
    {
        "order": 481,
        "title": "IntSGD: Adaptive Floatless Compression of Stochastic Gradients",
        "html": "https://iclr.cc//virtual/2022/poster/6683",
        "abstract": "We propose a family of adaptive integer compression operators for distributed Stochastic Gradient Descent (SGD) that do not communicate a single float. This is achieved by multiplying floating-point vectors with a number known to every device and then rounding to integers. In contrast to the prior work on integer compression for SwitchML by (Sapio et al., 2021), our IntSGD method is provably convergent and computationally cheaper as it estimates the scaling of vectors adaptively. Our theory shows that the iteration complexity of IntSGD matches that of SGD up to constant factors for both convex and non-convex, smooth and non-smooth functions, with and without overparameterization. Moreover, our algorithm can also be tailored for the popular all-reduce primitive and shows promising empirical performance.",
        "conference": "ICLR",
        "中文标题": "IntSGD：随机梯度的自适应无浮点数压缩",
        "摘要翻译": "我们提出了一系列用于分布式随机梯度下降（SGD）的自适应整数压缩算子，这些算子不传输任何浮点数。这是通过将浮点向量与每个设备都知道的数字相乘，然后四舍五入为整数来实现的。与（Sapio等人，2021）关于SwitchML的整数压缩的先前工作相比，我们的IntSGD方法被证明是收敛的，并且在计算上更便宜，因为它自适应地估计向量的缩放比例。我们的理论表明，对于凸和非凸、光滑和非光滑的函数，无论是否过参数化，IntSGD的迭代复杂度与SGD的迭代复杂度在常数因子内匹配。此外，我们的算法也可以为流行的all-reduce原语量身定制，并显示出有希望的实证性能。",
        "领域": "分布式机器学习优化、梯度压缩技术、深度学习训练加速",
        "问题": "如何在分布式随机梯度下降（SGD）中有效压缩梯度数据，减少通信开销而不影响模型收敛性。",
        "动机": "减少分布式SGD训练中的通信成本，同时保证算法的收敛性和计算效率。",
        "方法": "提出了一种自适应整数压缩算子IntSGD，通过将浮点梯度向量转换为整数来避免浮点数通信，并自适应地估计向量缩放比例以保证收敛。",
        "关键词": [
            "梯度压缩",
            "分布式SGD",
            "整数转换",
            "自适应缩放",
            "all-reduce"
        ],
        "涉及的技术概念": {
            "自适应整数压缩算子": "用于将浮点梯度向量转换为整数，减少通信数据量，同时自适应调整缩放比例以保证算法收敛。",
            "分布式随机梯度下降（SGD）": "一种在分布式环境中优化机器学习模型的算法，通过并行计算梯度来加速训练过程。",
            "all-reduce原语": "一种在分布式计算中常用的通信模式，用于在所有计算节点间聚合数据，IntSGD算法可以针对此模式进行优化。"
        },
        "success": true
    },
    {
        "order": 482,
        "title": "Invariant Causal Representation Learning for Out-of-Distribution Generalization",
        "html": "https://iclr.cc//virtual/2022/poster/6685",
        "abstract": "Due to spurious correlations, machine learning systems often fail to generalize to environments whose distributions differ from the ones used at training time. Prior work addressing this, either explicitly or implicitly, attempted to find a data representation that has an invariant relationship with the target. This is done by leveraging a diverse set of training environments to reduce the effect of spurious features and build an invariant predictor. However, these methods have generalization guarantees only when both data representation and classifiers come from a linear model class. We propose invariant Causal Representation Learning (iCaRL), an approach that enables out-of-distribution (OOD) generalization in the nonlinear setting (i.e., nonlinear representations and nonlinear classifiers). It builds upon a practical and general assumption: the prior over the data representation (i.e., a set of latent variables encoding the data) given the target and the environment belongs to general exponential family distributions, i.e., a more flexible conditionally non-factorized prior that can actually capture complicated dependences between the latent variables. Based on this, we show that it is possible to identify the data representation up to simple transformations. We also show that all direct causes of the target can be fully discovered, which further enables us to obtain generalization guarantees in the nonlinear setting. Experiments on both synthetic and real-world datasets demonstrate that our approach outperforms a variety of baseline methods. ",
        "conference": "ICLR",
        "中文标题": "不变因果表示学习用于分布外泛化",
        "摘要翻译": "由于虚假相关性，机器学习系统常常无法泛化到与训练时分布不同的环境。先前的工作，无论是显式还是隐式地，都试图找到与目标具有不变关系的数据表示。这是通过利用多样化的训练环境集来减少虚假特征的影响并构建一个不变的预测器来实现的。然而，这些方法只有在数据表示和分类器都来自线性模型类时才有泛化保证。我们提出了不变因果表示学习（iCaRL），一种在非线性设置（即非线性表示和非线性分类器）中实现分布外（OOD）泛化的方法。它基于一个实用且一般的假设：给定目标和环境的数据表示的先验（即编码数据的一组潜在变量）属于一般指数族分布，即一个更灵活的条件非分解先验，可以实际捕捉潜在变量之间的复杂依赖关系。基于这一点，我们表明可以识别数据表示直至简单变换。我们还表明，可以完全发现目标的所有直接原因，这进一步使我们能够在非线性设置中获得泛化保证。在合成和真实世界数据集上的实验表明，我们的方法优于各种基线方法。",
        "领域": "因果表示学习",
        "问题": "解决机器学习系统在分布变化环境下泛化能力不足的问题",
        "动机": "通过构建不变的数据表示和预测器，提高模型在分布外环境中的泛化能力",
        "方法": "提出不变因果表示学习（iCaRL），利用一般指数族分布作为数据表示的先验，识别数据表示直至简单变换，并发现目标的所有直接原因",
        "关键词": [
            "不变因果表示学习",
            "分布外泛化",
            "非线性分类器",
            "指数族分布",
            "潜在变量"
        ],
        "涉及的技术概念": {
            "不变因果表示学习": "一种在非线性设置中实现分布外泛化的方法，通过构建与目标具有不变关系的数据表示",
            "指数族分布": "作为数据表示的先验，能够捕捉潜在变量之间的复杂依赖关系",
            "潜在变量": "编码数据的变量集，通过iCaRL方法可以识别直至简单变换"
        },
        "success": true
    },
    {
        "order": 483,
        "title": "Inverse Online Learning: Understanding Non-Stationary and Reactionary Policies",
        "html": "https://iclr.cc//virtual/2022/poster/7211",
        "abstract": "Human decision making is well known to be imperfect and the ability to analyse such processes individually is crucial when attempting to aid or improve a decision-maker's ability to perform a task, e.g. to alert them to potential biases or oversights on their part. To do so, it is necessary to develop interpretable representations of how agents make decisions and how this process changes over time as the agent learns online in reaction to the accrued experience. To then understand the decision-making processes underlying a set of observed trajectories, we cast the policy inference problem as the inverse to this online learning problem. By interpreting actions within a potential outcomes framework, we introduce a meaningful mapping based on agents choosing an action they believe to have the greatest treatment effect. We introduce a practical algorithm for retrospectively estimating such perceived effects, alongside the process through which agents update them, using a novel architecture built upon an expressive family of deep state-space models. Through application to the analysis of UNOS organ donation acceptance decisions, we demonstrate that our approach can bring valuable insights into the factors that govern decision processes and how they change over time. ",
        "conference": "ICLR",
        "中文标题": "逆向在线学习：理解非稳态与反应性策略",
        "摘要翻译": "众所周知，人类的决策过程并不完美，在尝试帮助或提高决策者执行任务的能力时，例如提醒他们注意潜在的偏见或疏忽，分析这些决策过程的能力至关重要。为此，有必要开发可解释的表示方法，以展示代理如何做出决策以及这一过程如何随着代理在线学习以应对累积经验而随时间变化。为了理解一组观察到的轨迹背后的决策过程，我们将策略推断问题转化为这一在线学习问题的逆向问题。通过在潜在结果框架内解释行动，我们引入了一个有意义的映射，基于代理选择他们认为具有最大处理效果的行动。我们引入了一种实用算法，用于回顾性估计这种感知效果以及代理更新它们的过程，使用了一种建立在表达性深度状态空间模型家族上的新颖架构。通过应用于分析UNOS器官捐赠接受决策，我们证明了我们的方法可以为支配决策过程的因素及其随时间变化的方式提供有价值的见解。",
        "领域": "在线学习、决策分析、深度状态空间模型",
        "问题": "如何理解和分析人类决策过程中的非稳态和反应性策略，以改善决策者的表现。",
        "动机": "人类决策存在偏见和疏忽，通过分析决策过程，可以帮助决策者识别并改进这些不足。",
        "方法": "将策略推断问题转化为在线学习问题的逆向问题，利用潜在结果框架和深度状态空间模型，开发了一种回顾性估计感知效果及其更新过程的算法。",
        "关键词": [
            "逆向在线学习",
            "决策分析",
            "深度状态空间模型",
            "非稳态策略",
            "反应性策略"
        ],
        "涉及的技术概念": {
            "逆向在线学习": "将策略推断问题转化为在线学习问题的逆向问题，以理解决策过程。",
            "潜在结果框架": "用于解释代理选择行动的理论框架，基于代理认为的行动处理效果。",
            "深度状态空间模型": "一种表达性强的模型家族，用于构建算法以估计和更新代理的感知效果。"
        },
        "success": true
    },
    {
        "order": 484,
        "title": "Is Fairness Only Metric Deep? Evaluating and Addressing Subgroup Gaps in Deep Metric Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6112",
        "abstract": "Deep metric learning (DML) enables learning with less supervision through its emphasis on the similarity structure of representations. There has been much work on improving  generalization of DML in settings like zero-shot retrieval, but little is known about its implications for fairness. In this paper, we are the first to evaluate state-of-the-art DML methods trained on imbalanced data, and to show the negative impact these representations have on minority subgroup performance when used for downstream tasks. In this work, we first define fairness in DML through an analysis of three properties of the representation space -- inter-class alignment, intra-class alignment, and uniformity -- and propose \\textit{\\textbf{finDML}}, the \\textit{\\textbf{f}}airness \\textit{\\textbf{i}}n \\textit{\\textbf{n}}on-balanced \\textit{\\textbf{DML}} benchmark to characterize representation fairness. Utilizing \\textit{finDML}, we find bias in DML representations to propagate to common downstream classification tasks. Surprisingly, this bias is propagated even when training data in the downstream task is re-balanced. To address this problem, we present Partial Attribute De-correlation (\\textit{\\textbf{\\pad}}) to disentangle feature representations from sensitive attributes and reduce performance gaps between subgroups in both embedding space and downstream metrics.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "公平性仅仅是深度度量的问题吗？评估和解决深度度量学习中的子群体差距",
        "摘要翻译": "深度度量学习 (DML) 通过强调表征的相似性结构，能够以较少的监督进行学习。在诸如零样本检索等设置中，已经有很多关于提高 DML 泛化能力的工作，但对其公平性的影响知之甚少。在本文中，我们首次评估了在不平衡数据上训练的最先进的 DML 方法，并展示了当用于下游任务时，这些表征对少数子群体性能的负面影响。在这项工作中，我们首先通过分析表征空间的三个属性——类间对齐、类内对齐和均匀性——来定义 DML 中的公平性，并提出了 finDML，即非平衡 DML 中的公平性基准，以表征表征的公平性。利用 finDML，我们发现 DML 表征中的偏差会传播到常见的下游分类任务中。令人惊讶的是，即使下游任务中的训练数据被重新平衡，这种偏差仍然会传播。为了解决这个问题，我们提出了部分属性去相关 (PAD) 来解耦特征表征与敏感属性，并减少嵌入空间和下游指标中子群体之间的性能差距。",
        "领域": "度量学习, 公平性, 表征学习",
        "问题": "现有的深度度量学习方法在不平衡数据集上训练时，会对少数子群体的性能产生负面影响，导致公平性问题。",
        "动机": "希望评估并解决深度度量学习中存在的公平性问题，特别是在不平衡数据集上训练时对少数子群体性能的影响。",
        "方法": "通过定义表征空间的公平性属性（类间对齐、类内对齐和均匀性），提出 finDML 基准来评估 DML 的公平性，并使用部分属性去相关 (PAD) 来解耦特征表征与敏感属性，从而减少子群体之间的性能差距。",
        "关键词": [
            "深度度量学习",
            "公平性",
            "不平衡数据",
            "子群体性能",
            "部分属性去相关"
        ],
        "涉及的技术概念": {
            "度量学习": "通过学习一个度量空间，使得相似的样本在该空间中距离较近，不相似的样本距离较远。本文侧重于评估和改进现有度量学习方法在公平性方面的表现。",
            "公平性": "在机器学习中，公平性指的是算法对不同群体或个体产生一致或无偏见结果的能力。本文将公平性定义为表征空间的类间对齐、类内对齐和均匀性。"
        }
    },
    {
        "order": 485,
        "title": "Is High Variance Unavoidable in RL? A Case Study in Continuous Control",
        "html": "https://iclr.cc//virtual/2022/poster/6507",
        "abstract": "Reinforcement learning (RL) experiments have notoriously high variance, and minor details can have disproportionately large effects on measured outcomes. This is problematic for creating reproducible research and also serves as an obstacle when applying RL to sensitive real-world applications. In this paper, we investigate causes for this perceived instability. To allow for an in-depth analysis, we focus on a specifically popular setup with high variance -- continuous control from pixels with an actor-critic agent. In this setting, we demonstrate that poor outlier runs which completely fail to learn are an important source of variance, but that weight initialization and initial exploration are not at fault. We show that one cause for these outliers is unstable network parametrization which leads to saturating nonlinearities. We investigate several fixes to this issue and find that simply normalizing penultimate features is surprisingly effective. For sparse tasks, we also find that partially disabling clipped double Q-learning decreases variance. By combining fixes we significantly decrease variances, lowering the average standard deviation across 21 tasks by a factor >3 for a state-of-the-art agent. This demonstrates that the perceived variance is not necessarily inherent to RL. Instead, it may be addressed via simple modifications and we argue that developing low-variance agents is an important goal for the RL community.",
        "conference": "ICLR",
        "中文标题": "强化学习中的高方差是否不可避免？连续控制案例研究",
        "摘要翻译": "强化学习（RL）实验以高方差著称，细微的细节可能对测量结果产生不成比例的巨大影响。这对于创建可重复的研究是有问题的，并且在将RL应用于敏感的现实世界应用时也构成了障碍。在本文中，我们调查了这种感知不稳定的原因。为了进行深入分析，我们专注于一个特别受欢迎但高方差的设置——使用演员-评论家代理从像素进行连续控制。在此设置中，我们证明了完全未能学习的异常运行是方差的重要来源，但权重初始化和初始探索并非罪魁祸首。我们表明，这些异常值的一个原因是不稳定的网络参数化，导致非线性饱和。我们调查了几种解决此问题的方法，并发现简单地归一化倒数第二特征出奇地有效。对于稀疏任务，我们还发现部分禁用裁剪双Q学习可以减少方差。通过结合修复措施，我们显著降低了方差，对于最先进的代理，在21个任务中平均标准差降低了>3倍。这表明感知到的方差不一定是RL固有的。相反，它可以通过简单的修改来解决，我们认为开发低方差代理是RL社区的一个重要目标。",
        "领域": "强化学习、连续控制、演员-评论家方法",
        "问题": "强化学习实验中的高方差问题及其对研究可重复性和实际应用的影响",
        "动机": "调查强化学习实验中高方差的根源，以促进可重复研究和实际应用",
        "方法": "专注于连续控制设置，分析异常运行的原因，提出并测试几种减少方差的方法",
        "关键词": [
            "强化学习",
            "连续控制",
            "方差减少",
            "演员-评论家",
            "网络参数化"
        ],
        "涉及的技术概念": {
            "演员-评论家代理": "一种结合了价值函数和策略梯度方法的强化学习框架，用于从像素进行连续控制",
            "裁剪双Q学习": "一种减少Q学习高估偏差的技术，本文发现部分禁用它有助于减少稀疏任务的方差",
            "倒数第二特征归一化": "一种简单的技术，通过归一化网络倒数第二层的特征来减少异常运行，从而降低方差"
        },
        "success": true
    },
    {
        "order": 486,
        "title": "Is Homophily a Necessity for Graph Neural Networks?",
        "html": "https://iclr.cc//virtual/2022/poster/6329",
        "abstract": "Graph neural networks (GNNs) have shown great prowess in learning representations suitable for numerous graph-based machine learning tasks. When applied to semi-supervised node classification,  GNNs are widely believed to work well due to the homophily assumption (``like attracts like''), and fail to generalize to heterophilous graphs where dissimilar nodes connect. Recent works design new architectures to overcome such heterophily-related limitations, citing poor baseline performance and new architecture improvements on a few heterophilous graph benchmark datasets as evidence for this notion. In our experiments, we empirically find that standard graph convolutional networks (GCNs) can actually achieve better performance than such carefully designed methods on some commonly used heterophilous graphs. This motivates us to reconsider whether homophily is truly necessary for good GNN performance.  We find that this claim is not quite true, and in fact, GCNs can achieve strong performance on heterophilous graphs under certain conditions. Our work carefully characterizes these conditions and provides supporting theoretical understanding and empirical observations.  Finally, we examine existing heterophilous graphs benchmarks and reconcile how the GCN (under)performs on them based on this understanding.",
        "conference": "ICLR",
        "中文标题": "同质性是否是图神经网络的必要条件？",
        "摘要翻译": "图神经网络（GNNs）在学习适用于众多基于图的机器学习任务的表示方面显示出了巨大的能力。当应用于半监督节点分类时，广泛认为GNNs由于同质性假设（“物以类聚”）而表现良好，但在不相似节点连接的异质性图上无法泛化。最近的工作设计了新的架构来克服这种与异质性相关的限制，引用了一些异质性图基准数据集上的基线性能不佳和新架构改进作为这一观点的证据。在我们的实验中，我们经验性地发现，标准的图卷积网络（GCNs）实际上可以在一些常用的异质性图上比这些精心设计的方法获得更好的性能。这促使我们重新考虑同质性是否真的是GNN性能良好的必要条件。我们发现这一说法并不完全正确，事实上，GCNs在特定条件下可以在异质性图上实现强大的性能。我们的工作仔细描述了这些条件，并提供了支持的理论理解和经验观察。最后，我们检查了现有的异质性图基准，并根据这一理解调和了GCN在这些基准上的（欠）表现。",
        "领域": "图神经网络、半监督学习、节点分类",
        "问题": "探讨同质性是否是图神经网络性能良好的必要条件，以及GNNs在异质性图上的表现。",
        "动机": "重新评估同质性对GNNs性能的影响，挑战广泛认为的同质性假设，探索GNNs在异质性图上的潜力。",
        "方法": "通过实验验证标准图卷积网络（GCNs）在异质性图上的性能，分析影响性能的条件，并提供理论支持和经验观察。",
        "关键词": [
            "图神经网络",
            "同质性",
            "异质性图",
            "节点分类",
            "图卷积网络"
        ],
        "涉及的技术概念": {
            "图神经网络（GNNs）": "用于处理图结构数据的深度学习模型，能够学习节点和图的表示。",
            "同质性假设": "认为相似节点更可能相连的假设，传统上被认为是GNNs表现良好的关键。",
            "图卷积网络（GCNs）": "一种特定的GNN架构，通过卷积操作聚合邻居信息来更新节点表示。"
        },
        "success": true
    },
    {
        "order": 487,
        "title": "Is Importance Weighting Incompatible with Interpolating Classifiers?",
        "html": "https://iclr.cc//virtual/2022/poster/7198",
        "abstract": "Importance weighting is a classic technique to handle distribution shifts. However, prior work has presented strong empirical and theoretical evidence demonstrating that importance weights can have little to no effect on overparameterized neural networks. \\emph{Is importance weighting truly incompatible with the training of overparameterized neural networks?} Our paper answers this in the negative. We show that importance weighting fails not because of the overparameterization, but instead, as a result of using exponentially-tailed losses like the logistic or cross-entropy loss. As a remedy, we show that polynomially-tailed losses restore the effects of importance reweighting in correcting distribution shift in overparameterized models. We characterize the behavior of gradient descent on importance weighted polynomially-tailed losses with overparameterized linear models, and theoretically demonstrate the advantage of using polynomially-tailed losses in a label shift setting. Surprisingly, our theory shows that using weights that are obtained by exponentiating the classical unbiased importance weights can improve performance. Finally, we demonstrate the practical value of our analysis with neural network experiments on a subpopulation shift and a label shift dataset. When reweighted, our loss function can outperform reweighted cross-entropy by as much as 9\\% in test accuracy. Our loss function also gives test accuracies comparable to, or even exceeding, well-tuned state-of-the-art methods for correcting distribution shifts.",
        "conference": "ICLR",
        "中文标题": "重要性加权与插值分类器是否不兼容？",
        "摘要翻译": "重要性加权是一种处理分布偏移的经典技术。然而，先前的工作提供了强有力的经验和理论证据，表明重要性加权对过参数化神经网络的影响可能微乎其微，甚至没有影响。重要性加权真的与过参数化神经网络的训练不兼容吗？我们的论文对此给出了否定的答案。我们表明，重要性加权失败的原因不在于过参数化，而是由于使用了如逻辑损失或交叉熵损失这样的指数尾部损失。作为补救措施，我们展示了多项式尾部损失可以恢复重要性重新加权在纠正过参数化模型中分布偏移的效果。我们通过过参数化线性模型，描述了梯度下降在重要性加权多项式尾部损失上的行为，并从理论上证明了在标签偏移设置中使用多项式尾部损失的优势。令人惊讶的是，我们的理论表明，使用通过指数化经典无偏重要性权重获得的权重可以提高性能。最后，我们通过在子群体偏移和标签偏移数据集上的神经网络实验，展示了我们分析的实际价值。当重新加权时，我们的损失函数在测试准确率上可以比重新加权的交叉熵高出多达9%。我们的损失函数还提供了与经过良好调整的最先进方法相媲美，甚至超过的测试准确率，用于纠正分布偏移。",
        "领域": "深度学习优化、分布偏移纠正、神经网络训练",
        "问题": "探讨重要性加权在过参数化神经网络训练中的有效性及其与损失函数类型的关系",
        "动机": "解决重要性加权在过参数化神经网络中看似无效的问题，揭示其失败的真实原因，并提出改进方法",
        "方法": "通过理论分析和实验验证，比较指数尾部损失和多项式尾部损失在重要性加权中的作用，提出使用多项式尾部损失以提高性能",
        "关键词": [
            "重要性加权",
            "过参数化神经网络",
            "多项式尾部损失",
            "分布偏移",
            "梯度下降"
        ],
        "涉及的技术概念": {
            "重要性加权": "一种调整训练样本权重以纠正分布偏移的技术",
            "多项式尾部损失": "一种损失函数类型，相比指数尾部损失，能更有效地与重要性加权结合使用",
            "过参数化神经网络": "参数数量远大于训练样本数量的神经网络，能够拟合训练数据到零误差"
        },
        "success": true
    },
    {
        "order": 488,
        "title": "Iterated Reasoning with Mutual Information in Cooperative and Byzantine Decentralized Teaming",
        "html": "https://iclr.cc//virtual/2022/poster/6808",
        "abstract": "Information sharing is key in building team cognition and enables coordination and cooperation. High-performing human teams also benefit from acting strategically with hierarchical levels of iterated communication and rationalizability, meaning a human agent can reason about the actions of their teammates in their decision-making. Yet, the majority of prior work in Multi-Agent Reinforcement Learning (MARL) does not support iterated rationalizability and only encourage inter-agent communication, resulting in a suboptimal equilibrium cooperation strategy. In this work, we show that reformulating an agent's policy to be conditional on the policies of its neighboring teammates inherently maximizes Mutual Information (MI) lower-bound when optimizing under Policy Gradient (PG). Building on the idea of decision-making under bounded rationality and cognitive hierarchy theory, we show that our modified PG approach not only maximizes local agent rewards but also implicitly reasons about MI between agents without the need for any explicit ad-hoc regularization terms. Our approach, InfoPG, outperforms baselines in learning emergent collaborative behaviors and sets the state-of-the-art in decentralized cooperative MARL tasks. Our experiments validate the utility of InfoPG by achieving higher sample efficiency and significantly larger cumulative reward in several complex cooperative multi-agent domains.",
        "conference": "ICLR",
        "中文标题": "在合作与拜占庭分散团队中基于互信息的迭代推理",
        "摘要翻译": "信息共享是构建团队认知的关键，它使得协调与合作成为可能。高效的人类团队还受益于具有层次化迭代沟通和合理性的战略行动，这意味着人类代理可以在其决策中推理队友的行为。然而，先前在多智能体强化学习（MARL）中的大多数工作并不支持迭代合理性，仅鼓励智能体间的沟通，导致了一种次优的均衡合作策略。在这项工作中，我们展示了将智能体的策略重新制定为条件于其邻近队友的策略，在策略梯度（PG）优化下本质上最大化互信息（MI）下界。基于有限理性下的决策制定和认知层次理论的思想，我们展示了我们改进的PG方法不仅最大化局部智能体奖励，而且无需任何显式的临时正则化项即可隐式推理智能体间的MI。我们的方法InfoPG在学习涌现协作行为方面优于基线，并在分散合作MARL任务中设定了最新技术。我们的实验通过在一些复杂的合作多智能体领域实现更高的样本效率和显著更大的累积奖励，验证了InfoPG的实用性。",
        "领域": "多智能体强化学习",
        "问题": "如何在多智能体系统中通过迭代推理和互信息最大化来优化合作策略",
        "动机": "解决现有MARL方法在支持迭代合理性和促进智能体间沟通方面的不足，以提高团队合作效率",
        "方法": "通过将智能体的策略条件于邻近队友的策略，在策略梯度优化下最大化互信息下界，无需显式正则化项",
        "关键词": [
            "多智能体强化学习",
            "互信息",
            "策略梯度",
            "迭代推理",
            "合作策略"
        ],
        "涉及的技术概念": {
            "互信息": "用于衡量智能体间策略的相互依赖程度，优化合作策略",
            "策略梯度": "一种优化智能体策略的方法，通过梯度上升来最大化预期奖励",
            "认知层次理论": "用于理解和模拟智能体在有限理性下的决策过程，支持迭代推理"
        },
        "success": true
    },
    {
        "order": 489,
        "title": "Iterative Refinement Graph Neural Network for Antibody Sequence-Structure Co-design",
        "html": "https://iclr.cc//virtual/2022/poster/6664",
        "abstract": "Antibodies are versatile proteins that bind to pathogens like viruses and stimulate the adaptive immune system. The specificity of antibody binding is determined by complementarity-determining regions (CDRs) at the tips of these Y-shaped proteins. In this paper, we propose a generative model to automatically design the CDRs of antibodies with enhanced binding specificity or neutralization capabilities. Previous generative approaches formulate protein design as a structure-conditioned sequence generation task, assuming the desired 3D structure is given a priori. In contrast, we propose to co-design the sequence and 3D structure of CDRs as graphs. Our model unravels a sequence autoregressively while iteratively refining its predicted global structure. The inferred structure in turn guides subsequent residue choices. For efficiency, we model the conditional dependence between residues inside and outside of a CDR in a coarse-grained manner. Our method achieves superior log-likelihood on the test set and outperforms previous baselines in designing antibodies capable of neutralizing the SARS-CoV-2 virus.",
        "conference": "ICLR",
        "中文标题": "迭代优化图神经网络用于抗体序列-结构协同设计",
        "摘要翻译": "抗体是一种多功能蛋白质，能够与病毒等病原体结合并刺激适应性免疫系统。抗体结合的特异性由这些Y形蛋白质末端的互补决定区（CDRs）决定。在本文中，我们提出了一种生成模型，用于自动设计具有增强结合特异性或中和能力的抗体CDRs。以往的生成方法将蛋白质设计表述为结构条件下的序列生成任务，假设所需的3D结构是先验给定的。相比之下，我们提出将CDRs的序列和3D结构作为图进行协同设计。我们的模型自回归地展开序列，同时迭代优化其预测的全局结构。推断出的结构反过来指导后续残基的选择。为了提高效率，我们以粗粒度的方式建模CDR内外残基之间的条件依赖关系。我们的方法在测试集上实现了优越的对数似然，并在设计能够中和SARS-CoV-2病毒的抗体方面优于之前的基线。",
        "领域": "蛋白质设计、图神经网络、生物信息学",
        "问题": "如何自动设计具有增强结合特异性或中和能力的抗体互补决定区（CDRs）",
        "动机": "克服以往方法中假设3D结构先验给定的限制，实现抗体序列和结构的协同设计",
        "方法": "提出一种生成模型，将CDRs的序列和3D结构作为图进行协同设计，通过迭代优化结构指导序列生成",
        "关键词": [
            "抗体设计",
            "图神经网络",
            "序列-结构协同设计",
            "SARS-CoV-2",
            "互补决定区"
        ],
        "涉及的技术概念": {
            "图神经网络": "用于建模抗体序列和3D结构之间的关系，实现协同设计",
            "自回归模型": "用于逐步生成抗体序列，每次生成一个残基",
            "粗粒度建模": "用于高效处理CDR内外残基之间的条件依赖关系，提高计算效率"
        },
        "success": true
    },
    {
        "order": 490,
        "title": "It Takes Four to Tango: Multiagent Self Play for Automatic Curriculum Generation",
        "html": "https://iclr.cc//virtual/2022/poster/6991",
        "abstract": "We are interested in training general-purpose reinforcement learning agents that can solve a wide variety of goals. Training such agents efficiently requires automatic generation of a goal curriculum. This is challenging as it requires (a) exploring goals of increasing difficulty, while ensuring that the agent (b) is exposed to a diverse set of goals in a sample efficient manner and (c) does not catastrophically forget previously solved goals. We propose Curriculum Self Play (CuSP), an automated goal generation framework that seeks to satisfy these desiderata by virtue of a multi-player game with 4 agents. We extend the asymmetric curricula learning in PAIRED (Dennis et al., 2020) to a symmetrized game that carefully balances cooperation and competition between two off-policy student learners and two regret-maximizing teachers. CuSP additionally introduces entropic goal coverage and accounts for the non-stationary nature of the students, allowing us to automatically induce a curriculum that balances progressive exploration with anti-catastrophic exploitation. We demonstrate that our method succeeds at generating an effective curricula of goals for a range of control tasks, outperforming other methods at zero-shot test-time generalization to novel out-of-distribution goals.",
        "conference": "ICLR",
        "中文标题": "四人探戈：多智能体自我对弈实现自动课程生成",
        "摘要翻译": "我们致力于训练能够解决多种目标的通用强化学习智能体。高效训练此类智能体需要自动生成目标课程。这一任务具有挑战性，因为它需要（a）探索难度递增的目标，同时确保智能体（b）以样本高效的方式接触到多样化的目标集合，并且（c）不会灾难性地遗忘之前已解决的目标。我们提出了课程自我对弈（Curriculum Self Play, CuSP），这是一个通过四智能体游戏满足这些需求的自目标生成框架。我们将PAIRED（Dennis等人，2020年）中的非对称课程学习扩展为一个对称游戏，该游戏在两个离策略学生学习者和两个遗憾最大化教师之间精心平衡了合作与竞争。CuSP还引入了熵目标覆盖，并考虑了学生的非稳态特性，使我们能够自动生成一个平衡渐进探索与抗灾难性利用的课程。我们证明了我们的方法在为一系列控制任务生成有效目标课程方面取得成功，在零样本测试时对新分布外目标的泛化能力上优于其他方法。",
        "领域": "强化学习",
        "问题": "如何自动生成一个既能够探索难度递增目标，又能保证目标多样性和避免灾难性遗忘的课程",
        "动机": "训练能够解决多种目标的通用强化学习智能体，需要高效自动生成目标课程",
        "方法": "提出了课程自我对弈（CuSP）框架，通过四智能体游戏平衡合作与竞争，引入熵目标覆盖并考虑学生的非稳态特性",
        "关键词": [
            "强化学习",
            "课程学习",
            "多智能体系统",
            "自动课程生成",
            "零样本泛化"
        ],
        "涉及的技术概念": {
            "课程自我对弈（CuSP）": "一个通过四智能体游戏自动生成目标课程的框架，平衡了合作与竞争",
            "熵目标覆盖": "用于确保智能体接触到多样化的目标集合，提高样本效率",
            "非稳态特性": "考虑了学习过程中智能体行为的变化，以优化课程生成过程"
        },
        "success": true
    },
    {
        "order": 491,
        "title": "It Takes Two to Tango: Mixup for Deep Metric Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6337",
        "abstract": "Metric learning involves learning a discriminative representation such that embeddings of similar classes are encouraged to be close, while embeddings of dissimilar classes are pushed far apart. State-of-the-art methods focus mostly on sophisticated loss functions or mining strategies. On the one hand, metric learning losses consider two or more examples at a time. On the other hand, modern data augmentation methods for classification consider two or more examples at a time. The combination of the two ideas is under-studied.In this work, we aim to bridge this gap and improve representations using mixup, which is a powerful data augmentation approach interpolating two or more examples and corresponding target labels at a time. This task is challenging because, unlike classification, the loss functions used in metric learning are not additive over examples, so the idea of interpolating target labels is not straightforward. To the best of our knowledge, we are the first to investigate mixing both examples and target labels for deep metric learning. We develop a generalized formulation that encompasses existing metric learning loss functions and modify it to accommodate for mixup, introducing Metric Mix, or Metrix. We also introduce a new metric---utilization---to demonstrate that by mixing examples during training, we are exploring areas of the embedding space beyond the training classes, thereby improving representations. To validate the effect of improved representations, we show that mixing inputs, intermediate representations or embeddings along with target labels significantly outperforms state-of-the-art metric learning methods on four benchmark deep metric learning datasets.",
        "conference": "ICLR",
        "中文标题": "探戈需要两人共舞：深度度量学习中的Mixup应用",
        "摘要翻译": "度量学习涉及学习一种判别性表示，使得相似类别的嵌入被鼓励靠近，而不相似类别的嵌入被推远。最先进的方法主要集中在复杂的损失函数或挖掘策略上。一方面，度量学习损失一次考虑两个或更多示例。另一方面，现代分类数据增强方法一次考虑两个或更多示例。这两种想法的结合研究不足。在这项工作中，我们旨在弥合这一差距，并使用mixup改进表示，mixup是一种强大的数据增强方法，一次插值两个或更多示例及相应的目标标签。这项任务具有挑战性，因为与分类不同，度量学习中使用的损失函数在示例上不是加性的，因此插值目标标签的想法并不直接。据我们所知，我们是第一个研究在深度度量学习中混合示例和目标标签的。我们开发了一个广义公式，涵盖了现有的度量学习损失函数，并修改它以适应mixup，引入了Metric Mix或Metrix。我们还引入了一个新的度量——利用率——来证明通过在训练期间混合示例，我们正在探索嵌入空间中超出训练类别的区域，从而改进表示。为了验证改进表示的效果，我们展示了混合输入、中间表示或嵌入以及目标标签，在四个基准深度度量学习数据集上显著优于最先进的度量学习方法。",
        "领域": "深度度量学习",
        "问题": "如何通过数据增强方法改进深度度量学习中的表示学习",
        "动机": "探索mixup数据增强方法在深度度量学习中的应用，以改进表示学习的效果",
        "方法": "开发了一个广义公式来适应mixup，引入了Metric Mix（Metrix），并通过混合输入、中间表示或嵌入以及目标标签来改进表示",
        "关键词": [
            "深度度量学习",
            "mixup",
            "数据增强",
            "表示学习",
            "Metrix"
        ],
        "涉及的技术概念": {
            "mixup": "一种数据增强方法，通过插值两个或更多示例及相应的目标标签来生成新的训练数据",
            "深度度量学习": "学习一种判别性表示，使得相似类别的嵌入靠近，不相似类别的嵌入远离",
            "Metrix": "本文提出的方法，通过修改现有度量学习损失函数以适应mixup，以改进表示学习"
        },
        "success": true
    },
    {
        "order": 492,
        "title": "Joint Shapley values: a measure of joint feature importance",
        "html": "https://iclr.cc//virtual/2022/poster/6484",
        "abstract": "The Shapley value is one of the most widely used measures of feature importance partly as it measures a feature's average effect on a model's prediction.  We introduce joint Shapley values, which directly extend Shapley's axioms and intuitions: joint Shapley values measure a set of features' average effect on a model's prediction.  We prove the uniqueness of joint Shapley values, for any order of explanation.  Results for games show that joint Shapley values present different insights from existing interaction indices, which assess the effect of a feature within a set of features.  The joint Shapley values seem to provide sensible results in ML attribution problems.  With binary features, we present a presence-adjusted global value that is more consistent with local intuitions than the usual approach.",
        "conference": "ICLR",
        "中文标题": "联合Shapley值：一种联合特征重要性的度量方法",
        "摘要翻译": "Shapley值是最广泛使用的特征重要性度量之一，部分原因是它衡量了一个特征对模型预测的平均影响。我们引入了联合Shapley值，它直接扩展了Shapley的公理和直觉：联合Shapley值衡量了一组特征对模型预测的平均影响。我们证明了联合Shapley值的唯一性，适用于任何解释顺序。对于博弈的结果表明，联合Shapley值提供了与现有交互指数不同的见解，后者评估了特征在特征集合中的影响。联合Shapley值似乎在机器学习归因问题中提供了合理的结果。对于二元特征，我们提出了一种存在调整的全局值，它比通常的方法更符合局部直觉。",
        "领域": "特征重要性分析",
        "问题": "如何衡量一组特征对模型预测的联合影响",
        "动机": "扩展Shapley值的应用，以更全面地理解特征集合对模型预测的贡献",
        "方法": "引入并理论验证了联合Shapley值的概念，提出了一种针对二元特征的存在调整全局值方法",
        "关键词": [
            "Shapley值",
            "特征重要性",
            "机器学习归因",
            "联合特征影响",
            "存在调整全局值"
        ],
        "涉及的技术概念": {
            "Shapley值": "用于衡量单个特征对模型预测的平均影响，基于博弈论中的贡献分配概念",
            "联合Shapley值": "扩展了Shapley值的概念，用于衡量一组特征对模型预测的联合平均影响",
            "存在调整全局值": "针对二元特征提出的一种改进方法，旨在使全局特征重要性评估更符合局部直觉"
        },
        "success": true
    },
    {
        "order": 493,
        "title": "KL Guided Domain Adaptation",
        "html": "https://iclr.cc//virtual/2022/poster/6322",
        "abstract": "Domain adaptation is an important problem and often needed for real-world applications. In this problem, instead of i.i.d. training and testing datapoints, we assume that the source (training) data and the target (testing) data have different distributions. With that setting, the empirical risk minimization training procedure often does not perform well, since it does not account for the change in the distribution. A common approach in the domain adaptation literature is to learn a representation of the input that has the same (marginal) distribution over the source and the target domain. However, these approaches often require additional networks and/or optimizing an adversarial (minimax) objective, which can be very expensive or unstable in practice. To improve upon these marginal alignment techniques, in this paper, we first derive a generalization bound for the target loss based on the training loss and the reverse Kullback-Leibler (KL) divergence between the source and the target representation distributions. Based on this bound, we derive an algorithm that minimizes the KL term to obtain a better generalization to the target domain. We show that with a probabilistic representation network, the KL term can be estimated efficiently via minibatch samples without any additional network or a minimax objective. This leads to a theoretically sound alignment method which is also very efficient and stable in practice. Experimental results also suggest that our method outperforms other representation-alignment approaches.",
        "conference": "ICLR",
        "中文标题": "KL引导的领域自适应",
        "摘要翻译": "领域自适应是一个重要的问题，对于现实世界的应用来说往往是必需的。在这个问题中，我们假设源（训练）数据和目标（测试）数据具有不同的分布，而不是独立同分布的训练和测试数据点。在这种设置下，经验风险最小化训练程序通常表现不佳，因为它没有考虑到分布的变化。领域自适应文献中的一个常见方法是学习一个输入表示，该表示在源域和目标域上具有相同的（边际）分布。然而，这些方法通常需要额外的网络和/或优化一个对抗性（极小极大）目标，这在实践中可能非常昂贵或不稳定。为了改进这些边际对齐技术，本文首先基于训练损失和源与目标表示分布之间的反向Kullback-Leibler（KL）散度推导了目标损失的泛化界限。基于这个界限，我们推导了一种算法，该算法最小化KL项以获得对目标域更好的泛化。我们表明，通过概率表示网络，KL项可以通过小批量样本高效估计，而无需任何额外的网络或极小极大目标。这导致了一种理论上可靠的对齐方法，该方法在实践中也非常高效和稳定。实验结果还表明，我们的方法优于其他表示对齐方法。",
        "领域": "领域自适应、深度学习、概率建模",
        "问题": "解决源域和目标域数据分布不同导致的模型泛化能力差的问题",
        "动机": "改进现有的领域自适应方法，使其更加高效和稳定",
        "方法": "基于KL散度推导泛化界限，并开发一种最小化KL项以优化目标域泛化的算法",
        "关键词": [
            "领域自适应",
            "KL散度",
            "概率表示网络",
            "泛化界限",
            "表示对齐"
        ],
        "涉及的技术概念": {
            "反向Kullback-Leibler（KL）散度": "用于衡量源域和目标域表示分布之间的差异，作为优化目标的一部分",
            "概率表示网络": "用于高效估计KL项，无需额外网络或极小极大目标",
            "泛化界限": "基于训练损失和KL散度推导，指导算法设计以优化目标域性能"
        },
        "success": true
    },
    {
        "order": 494,
        "title": "Knowledge Infused Decoding",
        "html": "https://iclr.cc//virtual/2022/poster/6163",
        "abstract": "Pre-trained language models (LMs) have been shown to memorize a substantial amount of knowledge from the pre-training corpora; however, they are still limited in recalling factually correct knowledge given a certain context. Hence. they tend to suffer from counterfactual or hallucinatory generation when used in knowledge-intensive natural language generation (NLG) tasks. Recent remedies to this problem focus on modifying either the pre-training or task fine-tuning objectives to incorporate knowledge, which normally require additional costly training or architecture modification of LMs for practical applications.We present Knowledge Infused Decoding (KID)---a novel decoding algorithm for generative LMs, which dynamically infuses external knowledge into each step of the LM decoding. Specifically, we maintain a local knowledge memory based on the current context, interacting with a dynamically created external knowledge trie, and continuously update the local memory as a knowledge-aware constraint to guide decoding via reinforcement learning. On six diverse knowledge-intensive NLG tasks, task-agnostic LMs (e.g., GPT-2 and BART) armed with KID outperform many task-optimized state-of-the-art models, and show particularly strong performance in few-shot scenarios over seven related knowledge-infusion techniques. Human evaluation confirms KID's ability to generate more relevant and factual language for the input context when compared with multiple baselines. Finally, KID also alleviates exposure bias and provides stable generation quality when generating longer sequences.",
        "conference": "ICLR",
        "中文标题": "知识注入解码",
        "摘要翻译": "预训练语言模型（LMs）已被证明能够从预训练语料库中记忆大量知识；然而，它们在给定特定上下文时回忆事实正确知识的能力仍然有限。因此，在知识密集型自然语言生成（NLG）任务中使用时，它们往往会产生反事实或幻觉性的生成。最近针对这一问题的补救措施主要集中在修改预训练或任务微调目标以融入知识，这通常需要额外的昂贵训练或对LMs的架构进行修改以适应实际应用。我们提出了知识注入解码（KID）——一种新颖的生成LMs解码算法，它动态地将外部知识注入到LM解码的每一步。具体来说，我们基于当前上下文维护一个局部知识记忆，与动态创建的外部知识树交互，并通过强化学习不断更新局部记忆作为知识感知约束来指导解码。在六个多样化的知识密集型NLG任务上，配备KID的任务无关LMs（例如，GPT-2和BART）优于许多任务优化的最先进模型，并在少量样本情况下显示出比七种相关知识注入技术更强的性能。人类评估证实，与多个基线相比，KID能够为输入上下文生成更相关和事实性的语言。最后，KID还减轻了暴露偏差，并在生成长序列时提供了稳定的生成质量。",
        "领域": "自然语言处理与视觉结合, 知识图谱, 文本生成",
        "问题": "预训练语言模型在知识密集型自然语言生成任务中生成反事实或幻觉性内容的问题",
        "动机": "提高预训练语言模型在知识密集型任务中生成内容的准确性和事实性",
        "方法": "提出知识注入解码（KID）算法，动态地将外部知识注入到语言模型解码的每一步，通过强化学习更新局部知识记忆以指导解码",
        "关键词": [
            "知识注入解码",
            "自然语言生成",
            "强化学习",
            "知识图谱",
            "预训练语言模型"
        ],
        "涉及的技术概念": {
            "知识注入解码（KID）": "一种动态将外部知识注入到语言模型解码每一步的算法，以提高生成内容的准确性和事实性",
            "局部知识记忆": "基于当前上下文维护的知识存储，用于与外部知识树交互并指导解码",
            "强化学习": "用于不断更新局部知识记忆，作为知识感知约束来优化解码过程的技术"
        },
        "success": true
    },
    {
        "order": 495,
        "title": "Knowledge Removal in Sampling-based Bayesian Inference",
        "html": "https://iclr.cc//virtual/2022/poster/6020",
        "abstract": "The right to be forgotten has been legislated in many countries, but its enforcement in the AI industry would cause unbearable costs. When single data deletion requests come, companies may need to delete the whole models learned with massive resources. Existing works propose methods to remove knowledge learned from data for explicitly parameterized models, which however are not appliable to the sampling-based Bayesian inference, {\\it i.e.}, Markov chain Monte Carlo (MCMC), as MCMC can only infer implicit distributions. In this paper, we propose the first machine unlearning algorithm for MCMC. We first convert the MCMC unlearning problem into an explicit optimization problem. Based on this problem conversion, an {\\it MCMC influence function} is designed to provably characterize the learned knowledge from data, which then delivers the MCMC unlearning algorithm. Theoretical analysis shows that MCMC unlearning would not compromise the generalizability of the MCMC models. Experiments on Gaussian mixture models and Bayesian neural networks confirm the effectiveness of the proposed algorithm. The code is available at \\url{https://github.com/fshp971/mcmc-unlearning}.",
        "conference": "ICLR",
        "中文标题": "基于采样的贝叶斯推断中的知识移除",
        "摘要翻译": "被遗忘的权利已在许多国家立法，但在AI行业中的执行将导致难以承受的成本。当单个数据删除请求到来时，公司可能需要删除用大量资源学习的整个模型。现有工作提出了从显式参数化模型中移除从数据中学到的知识的方法，然而这些方法不适用于基于采样的贝叶斯推断，即马尔可夫链蒙特卡洛（MCMC），因为MCMC只能推断隐式分布。在本文中，我们提出了第一个用于MCMC的机器遗忘算法。我们首先将MCMC遗忘问题转化为一个显式优化问题。基于这个问题转换，设计了一个MCMC影响函数来可证明地描述从数据中学到的知识，然后提供了MCMC遗忘算法。理论分析表明，MCMC遗忘不会损害MCMC模型的泛化能力。在高斯混合模型和贝叶斯神经网络上的实验证实了所提出算法的有效性。代码可在https://github.com/fshp971/mcmc-unlearning获取。",
        "领域": "贝叶斯机器学习、机器遗忘、马尔可夫链蒙特卡洛",
        "问题": "如何在基于采样的贝叶斯推断（MCMC）中有效移除特定数据的学习知识，而无需重新训练整个模型。",
        "动机": "解决AI行业中执行‘被遗忘权’时面临的高成本问题，特别是在处理单个数据删除请求时避免删除整个模型的需求。",
        "方法": "将MCMC遗忘问题转化为显式优化问题，设计MCMC影响函数来描述数据学习知识，进而开发MCMC遗忘算法。",
        "关键词": [
            "机器遗忘",
            "贝叶斯推断",
            "马尔可夫链蒙特卡洛",
            "知识移除",
            "优化问题"
        ],
        "涉及的技术概念": {
            "MCMC影响函数": "用于描述从数据中学到的知识，是实现MCMC遗忘算法的关键技术。",
            "机器遗忘算法": "专门为MCMC设计的算法，用于移除特定数据的学习知识而不影响模型的其他部分。",
            "贝叶斯推断": "基于采样的统计方法，用于估计隐式分布，本文中特指MCMC方法。"
        },
        "success": true
    },
    {
        "order": 496,
        "title": "Know Thyself: Transferable Visual Control Policies Through Robot-Awareness",
        "html": "https://iclr.cc//virtual/2022/poster/6041",
        "abstract": "Training visual control policies from scratch on a new robot typically requires generating large amounts of robot-specific data. How might we leverage data previously collected on another robot to reduce or even completely remove this need for robot-specific data? We propose a 'robot-aware control' paradigm that achieves this by exploiting readily available knowledge about the robot. We then instantiate this in a robot-aware model-based RL policy by training modular dynamics models that couple a transferable, robot-aware world dynamics module with a robot-specific, potentially analytical, robot dynamics module. This also enables us to set up visual planning costs that separately consider the robot agent and the world. Our experiments on tabletop manipulation tasks with simulated and real robots demonstrate that these plug-in improvements dramatically boost the transferability of visual model-based RL policies, even permitting zero-shot transfer of visual manipulation skills onto new robots. Project website: https://edwardshu.com/rac",
        "conference": "ICLR",
        "中文标题": "认识自我：通过机器人感知实现可迁移的视觉控制策略",
        "摘要翻译": "在新机器人上从头开始训练视觉控制策略通常需要生成大量机器人特定的数据。我们如何利用之前在其他机器人上收集的数据来减少甚至完全消除对机器人特定数据的需求？我们提出了一种‘机器人感知控制’范式，通过利用易于获取的机器人知识来实现这一点。然后，我们在一个机器人感知的基于模型的强化学习策略中实例化这一点，通过训练模块化动态模型，这些模型将一个可迁移的、机器人感知的世界动态模块与一个机器人特定的、可能是解析的机器人动态模块耦合起来。这也使我们能够设置视觉规划成本，分别考虑机器人代理和世界。我们在模拟和真实机器人上的桌面操作任务实验表明，这些插件改进极大地提升了基于模型的视觉强化学习策略的可迁移性，甚至允许将视觉操作技能零次迁移到新机器人上。项目网站：https://edwardshu.com/rac",
        "领域": "机器人视觉控制、模型基于强化学习、视觉操作技能迁移",
        "问题": "如何减少或消除在新机器人上训练视觉控制策略时对大量机器人特定数据的需求",
        "动机": "利用已有机器人数据，减少新机器人训练所需数据，提高视觉控制策略的可迁移性",
        "方法": "提出机器人感知控制范式，训练模块化动态模型，耦合可迁移的世界动态模块和机器人特定的动态模块，设置分离考虑机器人代理和世界的视觉规划成本",
        "关键词": [
            "机器人感知控制",
            "模型基于强化学习",
            "视觉操作技能迁移",
            "模块化动态模型",
            "零次迁移"
        ],
        "涉及的技术概念": {
            "机器人感知控制": "通过利用机器人知识，实现视觉控制策略的高效迁移",
            "模块化动态模型": "耦合可迁移的世界动态模块和机器人特定的动态模块，提高策略的适应性和可迁移性",
            "零次迁移": "允许视觉操作技能无需额外训练即可直接应用于新机器人"
        },
        "success": true
    },
    {
        "order": 497,
        "title": "Know Your Action Set: Learning Action Relations for Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6594",
        "abstract": "Intelligent agents can solve tasks in various ways depending on their available set of actions. However, conventional reinforcement learning (RL) assumes a fixed action set. This work asserts that tasks with varying action sets require reasoning of the relations between the available actions. For instance, taking a nail-action in a repair task is meaningful only if a hammer-action is also available. To learn and utilize such action relations, we propose a novel policy architecture consisting of a graph attention network over the available actions. We show that our model makes informed action decisions by correctly attending to other related actions in both value-based and policy-based RL. Consequently, it outperforms non-relational architectures on applications where the action space often varies, such as recommender systems and physical reasoning with tools and skills. Results and code at https://sites.google.com/view/varyingaction .",
        "conference": "ICLR",
        "中文标题": "了解你的动作集：学习动作关系以促进强化学习",
        "摘要翻译": "智能代理可以根据其可用的动作集以多种方式解决任务。然而，传统的强化学习（RL）假设动作集是固定的。这项工作断言，动作集变化的任务需要对可用动作之间的关系进行推理。例如，在维修任务中采取钉子动作只有在锤子动作也可用时才有意义。为了学习和利用这些动作关系，我们提出了一种新颖的策略架构，该架构由对可用动作的图注意力网络组成。我们展示了我们的模型通过在基于价值和基于策略的RL中正确关注其他相关动作，做出了明智的动作决策。因此，它在动作空间经常变化的应用中优于非关系架构，如推荐系统和利用工具和技能进行物理推理。结果和代码可在https://sites.google.com/view/varyingaction查看。",
        "领域": "强化学习、推荐系统、物理推理",
        "问题": "解决在动作集变化的任务中，如何利用动作间的关系进行有效决策的问题",
        "动机": "传统的强化学习假设动作集固定，无法适应动作集变化的任务，需要开发能够理解和利用动作间关系的新方法",
        "方法": "提出了一种基于图注意力网络的策略架构，用于学习和利用动作间的关系，以在动作集变化的任务中做出更好的决策",
        "关键词": [
            "强化学习",
            "动作关系",
            "图注意力网络",
            "推荐系统",
            "物理推理"
        ],
        "涉及的技术概念": {
            "图注意力网络": "用于在可用动作上建立关系模型，帮助模型理解动作间的关系",
            "强化学习": "论文的研究框架，用于训练智能代理在特定任务中做出决策",
            "动作关系": "论文核心概念，指不同动作之间的相互依赖和作用关系，对任务解决至关重要"
        },
        "success": true
    },
    {
        "order": 498,
        "title": "L0-Sparse Canonical Correlation Analysis",
        "html": "https://iclr.cc//virtual/2022/poster/6814",
        "abstract": "Canonical Correlation Analysis (CCA) models are powerful for studying the associations between two sets of variables. The canonically correlated representations, termed \\textit{canonical variates} are widely used in unsupervised learning to analyze unlabeled multi-modal registered datasets. Despite their success, CCA models may break (or overfit) if the number of variables in either of the modalities exceeds the number of samples. Moreover, often a significant fraction of the variables measures modality-specific information, and thus removing them is beneficial for identifying the \\textit{canonically correlated variates}. Here, we propose $\\ell_0$-CCA, a method for learning correlated representations based on sparse subsets of variables from two observed modalities.Sparsity is obtained by multiplying the input variables by stochastic gates, whose parameters are learned together with the CCA weights via an $\\ell_0$-regularized correlation loss. We further propose $\\ell_0$-Deep CCA for solving the problem of non-linear sparse CCA by modeling the correlated representations using deep nets. We demonstrate the efficacy of the method using several synthetic and real examples. Most notably, by gating nuisance input variables, our approach improves the extracted representations compared to other linear, non-linear and sparse CCA-based models.",
        "conference": "ICLR",
        "中文标题": "L0稀疏典型相关分析",
        "摘要翻译": "典型相关分析（CCA）模型在研究两组变量之间的关联方面非常强大。被称为典型变量的典型相关表示在无监督学习中广泛用于分析未标记的多模态注册数据集。尽管它们取得了成功，但如果任一模态中的变量数量超过样本数量，CCA模型可能会崩溃（或过拟合）。此外，通常有相当一部分变量测量的是模态特定信息，因此去除它们有助于识别典型相关变量。在这里，我们提出了ℓ0-CCA，一种基于两个观察模态的变量稀疏子集学习相关表示的方法。稀疏性是通过将输入变量乘以随机门获得的，其参数与CCA权重一起通过ℓ0正则化相关损失学习。我们进一步提出了ℓ0-深度CCA，通过使用深度网络建模相关表示来解决非线性稀疏CCA的问题。我们使用几个合成和真实例子证明了该方法的有效性。最值得注意的是，通过门控干扰输入变量，我们的方法与其他基于线性、非线性和稀疏CCA的模型相比，提高了提取的表示。",
        "领域": "多模态学习, 稀疏表示学习, 无监督学习",
        "问题": "解决在变量数量超过样本数量时CCA模型的崩溃或过拟合问题，以及去除模态特定信息变量以提高典型相关变量的识别。",
        "动机": "提高在多模态数据中识别典型相关变量的能力，尤其是在高维数据中避免过拟合。",
        "方法": "提出ℓ0-CCA方法，通过随机门实现变量稀疏性，并结合ℓ0正则化相关损失学习；进一步提出ℓ0-深度CCA，使用深度网络解决非线性稀疏CCA问题。",
        "关键词": [
            "稀疏典型相关分析",
            "多模态学习",
            "ℓ0正则化",
            "深度网络",
            "随机门"
        ],
        "涉及的技术概念": {
            "ℓ0正则化": "用于在损失函数中引入稀疏性，促使模型选择少量重要变量。",
            "随机门": "通过乘以输入变量实现稀疏性，参数与CCA权重共同学习。",
            "深度网络": "用于建模非线性相关表示，解决非线性稀疏CCA问题。"
        },
        "success": true
    },
    {
        "order": 499,
        "title": "Label-Efficient Semantic Segmentation with Diffusion Models",
        "html": "https://iclr.cc//virtual/2022/poster/6569",
        "abstract": "Denoising diffusion probabilistic models have recently received much research attention since they outperform alternative approaches, such as GANs, and currently provide state-of-the-art generative performance. The superior performance of diffusion models has made them an appealing tool in several applications, including inpainting, super-resolution, and semantic editing. In this paper, we demonstrate that diffusion models can also serve as an instrument for semantic segmentation, especially in the setup when labeled data is scarce. In particular, for several pretrained diffusion models, we investigate the intermediate activations from the networks that perform the Markov step of the reverse diffusion process. We show that these activations effectively capture the semantic information from an input image and appear to be excellent pixel-level representations for the segmentation problem. Based on these observations, we describe a simple segmentation method, which can work even if only a few training images are provided. Our approach significantly outperforms the existing alternatives on several datasets for the same amount of human supervision. ",
        "conference": "ICLR",
        "中文标题": "基于扩散模型的高效标签语义分割",
        "摘要翻译": "去噪扩散概率模型最近受到了广泛的研究关注，因为它们超越了其他方法，如生成对抗网络（GANs），并且目前提供了最先进的生成性能。扩散模型的卓越性能使其成为多种应用中的有力工具，包括修复、超分辨率和语义编辑。在本文中，我们证明了扩散模型也可以作为语义分割的工具，特别是在标记数据稀缺的情况下。具体来说，对于几种预训练的扩散模型，我们研究了执行反向扩散过程马尔可夫步骤的网络中的中间激活。我们表明，这些激活有效地捕捉了输入图像的语义信息，并且似乎是分割问题的优秀像素级表示。基于这些观察，我们描述了一种简单的分割方法，即使在仅提供少量训练图像的情况下也能工作。我们的方法在相同数量的人工监督下，在多个数据集上显著优于现有的替代方法。",
        "领域": "语义分割、图像生成、计算机视觉",
        "问题": "在标记数据稀缺的情况下实现高效的语义分割",
        "动机": "探索扩散模型在语义分割中的应用，特别是在标记数据有限的情况下，以提高分割的效率和准确性",
        "方法": "利用预训练扩散模型的中间激活作为像素级表示，开发了一种简单有效的分割方法，适用于少量训练图像的情况",
        "关键词": [
            "扩散模型",
            "语义分割",
            "标签效率",
            "像素级表示",
            "少量样本学习"
        ],
        "涉及的技术概念": {
            "扩散模型": "一种生成模型，通过逐步添加和去除噪声来生成数据，本文中用于捕捉图像的语义信息",
            "中间激活": "扩散模型在反向扩散过程中网络层的输出，本文中用作分割问题的像素级表示",
            "马尔可夫步骤": "扩散模型中反向扩散过程的一个步骤，本文中用于研究网络激活如何捕捉语义信息"
        },
        "success": true
    },
    {
        "order": 500,
        "title": "Label Encoding for Regression Networks",
        "html": "https://iclr.cc//virtual/2022/poster/6164",
        "abstract": "Deep neural networks are used for a wide range of regression problems. However, there exists a significant gap in accuracy between specialized approaches and generic direct regression in which a network is trained by minimizing the squared or absolute error of output labels. Prior work has shown that solving a regression problem with a set of binary classifiers can improve accuracy by utilizing well-studied binary classification algorithms. We introduce binary-encoded labels (BEL), which generalizes the application of binary classification to regression by providing a framework for considering arbitrary multi-bit values when encoding target values. We identify desirable properties of suitable encoding and decoding functions used for the conversion between real-valued and binary-encoded labels based on theoretical and empirical study. These properties highlight a tradeoff between classification error probability and error-correction capabilities of label encodings. BEL can be combined with off-the-shelf task-specific feature extractors and trained end-to-end. We propose a series of sample encoding, decoding, and training loss functions for BEL and demonstrate they result in lower error than direct regression and specialized approaches while being suitable for a diverse set of regression problems, network architectures, and evaluation metrics. BEL achieves state-of-the-art accuracies for several regression benchmarks. Code is available at https://github.com/ubc-aamodt-group/BEL_regression.",
        "conference": "ICLR",
        "中文标题": "回归网络的标签编码",
        "摘要翻译": "深度神经网络被广泛应用于各种回归问题。然而，在专门化方法和通用直接回归（即通过最小化输出标签的平方或绝对误差来训练网络）之间，存在显著的准确度差距。先前的研究表明，通过使用一组二元分类器来解决回归问题，可以利用经过充分研究的二元分类算法来提高准确度。我们引入了二进制编码标签（BEL），它通过提供一个框架来考虑编码目标值时的任意多比特值，从而将二元分类的应用推广到回归问题。基于理论和实证研究，我们确定了用于实值标签和二进制编码标签之间转换的合适编码和解码函数的理想属性。这些属性突出了标签编码在分类错误概率和纠错能力之间的权衡。BEL可以与现成的任务特定特征提取器结合使用，并进行端到端训练。我们为BEL提出了一系列样本编码、解码和训练损失函数，并证明它们比直接回归和专门化方法产生更低的误差，同时适用于多样化的回归问题、网络架构和评估指标。BEL在多个回归基准测试中达到了最先进的准确度。代码可在https://github.com/ubc-aamodt-group/BEL_regression获取。",
        "领域": "回归分析、深度学习、机器学习",
        "问题": "提高回归问题的准确度，减少专门化方法和通用直接回归之间的准确度差距",
        "动机": "利用二元分类算法的优势来提高回归问题的准确度",
        "方法": "引入二进制编码标签（BEL）框架，结合样本编码、解码和训练损失函数，与任务特定特征提取器结合使用，进行端到端训练",
        "关键词": [
            "二进制编码标签",
            "回归问题",
            "深度学习",
            "误差纠正",
            "端到端训练"
        ],
        "涉及的技术概念": {
            "二进制编码标签（BEL）": "一种将回归问题转化为二元分类问题的方法，通过编码目标值为二进制形式来提高准确度",
            "误差纠正能力": "在标签编码过程中，通过优化编码和解码函数来减少分类错误，提高模型的准确度",
            "端到端训练": "BEL框架可以与特征提取器结合，直接从输入到输出进行训练，无需中间步骤"
        },
        "success": true
    },
    {
        "order": 501,
        "title": "Label Leakage and Protection in Two-party Split Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6388",
        "abstract": "Two-party split learning is a popular technique for learning a model across feature-partitioned data. In this work, we explore whether it is possible for one party to steal the private label information from the other party during split training, and whether there are methods that can protect against such attacks. Specifically, we first formulate a realistic threat model and propose a privacy loss metric to quantify label leakage in split learning. We then show that there exist two simple yet effective methods within the threat model that can allow one party to accurately recover private ground-truth labels owned by the other party. To combat these attacks, we propose several random perturbation techniques, including $\\texttt{Marvell}$, an approach that strategically finds the structure of the noise perturbation by minimizing the amount of label leakage (measured through our quantification metric) of a worst-case adversary. We empirically demonstrate the effectiveness of our protection techniques against the identified attacks, and show that $\\texttt{Marvell}$ in particular has improved privacy-utility tradeoffs relative to baseline approaches.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "两方分割学习中的标签泄露与保护",
        "摘要翻译": "两方分割学习是一种在特征分区数据上学习模型的流行技术。在这项工作中，我们探讨了在分割训练过程中，一方是否可能从另一方窃取私有标签信息，以及是否存在可以防止此类攻击的方法。具体来说，我们首先制定了一个现实的威胁模型，并提出了一个隐私损失度量来量化分割学习中的标签泄露。然后，我们展示了在威胁模型内存在两种简单而有效的方法，可以让一方准确恢复另一方拥有的私有真实标签。为了对抗这些攻击，我们提出了几种随机扰动技术，包括$\texttt{Marvell}$，这是一种通过最小化最坏情况对手的标签泄露量（通过我们的量化度量来衡量）来战略性地找到噪声扰动结构的方法。我们通过实验证明了我们的保护技术对已识别攻击的有效性，并显示$\texttt{Marvell}$相对于基线方法具有更好的隐私-效用权衡。",
        "领域": "隐私保护机器学习, 分布式机器学习, 对抗性机器学习",
        "问题": "在两方分割学习中，如何防止一方窃取另一方的私有标签信息。",
        "动机": "探索分割学习中的隐私泄露风险，并提出有效的保护措施以防止标签信息被窃取。",
        "方法": "提出了一种隐私损失度量来量化标签泄露，并开发了随机扰动技术，包括$\texttt{Marvell}$方法，以最小化标签泄露。",
        "关键词": [
            "分割学习",
            "标签泄露",
            "隐私保护",
            "对抗性攻击",
            "随机扰动"
        ],
        "涉及的技术概念": {
            "分割学习": "一种在特征分区数据上学习模型的技术，允许多方协作训练而不直接共享数据。",
            "隐私损失度量": "用于量化在分割学习过程中标签信息泄露的程度。",
            "随机扰动技术": "通过添加噪声来干扰潜在的攻击者，保护私有标签信息不被窃取的技术。"
        }
    },
    {
        "order": 502,
        "title": "Language-biased image classification: evaluation based on semantic representations",
        "html": "https://iclr.cc//virtual/2022/poster/5990",
        "abstract": "Humans show language-biased image recognition for a word-embedded image, known as picture-word interference. Such interference depends on hierarchical semantic categories and reflects that human language processing highly interacts with visual processing. Similar to humans, recent artificial models jointly trained on texts and images, e.g., OpenAI CLIP, show language-biased image classification. Exploring whether the bias leads to interference similar to those observed in humans can contribute to understanding how much the model acquires hierarchical semantic representations from joint learning of language and vision. The present study introduces methodological tools from the cognitive science literature to assess the biases of artificial models. Specifically, we introduce a benchmark task to test whether words superimposed on images can distort the image classification across different category levels and, if it can, whether the perturbation is due to the shared semantic representation between language and vision. Our dataset is a set of word-embedded images and consists of a mixture of natural image datasets and hierarchical word labels with superordinate/basic category levels. Using this benchmark test, we evaluate the CLIP model. We show that presenting words distorts the image classification by the model across different category levels, but the effect does not depend on the semantic relationship between images and embedded words. This suggests that the semantic word representation in the CLIP visual processing is not shared with the image representation, although the word representation strongly dominates for word-embedded images.",
        "conference": "ICLR",
        "中文标题": "语言偏见的图像分类：基于语义表示的评价",
        "摘要翻译": "人类对嵌入单词的图像表现出语言偏见的识别，这种现象被称为图片-单词干扰。这种干扰依赖于分层的语义类别，并反映了人类语言处理与视觉处理高度互动。类似于人类，最近在文本和图像上联合训练的人工模型，如OpenAI CLIP，显示出语言偏见的图像分类。探索这种偏见是否会导致类似于人类观察到的干扰，有助于理解模型从语言和视觉的联合学习中获得多少分层语义表示。本研究引入了认知科学文献中的方法论工具来评估人工模型的偏见。具体来说，我们引入了一个基准任务来测试叠加在图像上的单词是否可以跨不同类别级别扭曲图像分类，如果可以，这种扰动是否是由于语言和视觉之间共享的语义表示。我们的数据集是一组嵌入单词的图像，由自然图像数据集和具有上级/基本类别级别的分层单词标签混合组成。使用这个基准测试，我们评估了CLIP模型。我们展示了呈现单词会跨不同类别级别扭曲模型的图像分类，但这种效果不依赖于图像和嵌入单词之间的语义关系。这表明在CLIP视觉处理中的语义单词表示与图像表示不共享，尽管单词表示对于嵌入单词的图像强烈主导。",
        "领域": "自然语言处理与视觉结合",
        "问题": "评估人工模型在图像分类中是否存在语言偏见及其对分层语义表示的影响",
        "动机": "探索人工模型是否像人类一样在图像分类中表现出语言偏见，以及这种偏见是否反映了语言和视觉处理之间的互动",
        "方法": "引入认知科学的方法论工具，创建一个包含嵌入单词的图像和分层单词标签的数据集，用于评估CLIP模型的图像分类偏见",
        "关键词": [
            "语言偏见",
            "图像分类",
            "语义表示",
            "CLIP模型",
            "认知科学"
        ],
        "涉及的技术概念": {
            "图片-单词干扰": "描述人类或模型在处理嵌入单词的图像时，单词对图像识别的干扰现象",
            "分层语义类别": "指语义信息按照从一般到具体的层次结构组织，影响语言和视觉处理的互动",
            "CLIP模型": "OpenAI开发的一个联合训练于文本和图像的模型，用于评估语言偏见对图像分类的影响"
        },
        "success": true
    },
    {
        "order": 503,
        "title": "Language-driven Semantic Segmentation",
        "html": "https://iclr.cc//virtual/2022/poster/6809",
        "abstract": "We present LSeg, a novel model for language-driven semantic image segmentation. LSeg uses a text encoder to compute embeddings of descriptive input labels (e.g., ``grass'' or ``building'') together with a transformer-based image encoder that computes dense per-pixel embeddings of the input image. The image encoder is trained with a contrastive objective to align pixel embeddings to the text embedding of the corresponding semantic class. The text embeddings provide a flexible label representation in which semantically similar labels map to similar regions in the embedding space (e.g., ``cat'' and ``furry''). This allows LSeg to generalize to previously unseen categories at test time, without retraining or even requiring a single additional training sample. We demonstrate that our approach achieves highly competitive zero-shot performance compared to existing zero- and few-shot semantic segmentation methods, and even matches the accuracy of traditional segmentation algorithms when a fixed label set is provided. Code and demo are available at https://github.com/isl-org/lang-seg.",
        "conference": "ICLR",
        "中文标题": "语言驱动的语义分割",
        "摘要翻译": "我们提出了LSeg，一种用于语言驱动语义图像分割的新模型。LSeg使用文本编码器计算描述性输入标签（例如“草”或“建筑”）的嵌入，同时使用基于变换器的图像编码器计算输入图像的密集每像素嵌入。图像编码器通过对比目标训练，以将像素嵌入与相应语义类别的文本嵌入对齐。文本嵌入提供了一种灵活的标签表示，其中语义相似的标签映射到嵌入空间中的相似区域（例如“猫”和“毛茸茸”）。这使得LSeg能够在测试时泛化到以前未见过的类别，而无需重新训练甚至不需要任何额外的训练样本。我们证明，与现有的零样本和少样本语义分割方法相比，我们的方法实现了极具竞争力的零样本性能，并且在提供固定标签集时甚至与传统分割算法的准确性相匹配。代码和演示可在https://github.com/isl-org/lang-seg获取。",
        "领域": "语义分割、零样本学习、自然语言处理与视觉结合",
        "问题": "解决在语义分割任务中如何利用语言描述来泛化到未见过的类别的问题",
        "动机": "探索如何通过语言驱动的模型实现语义分割的零样本学习，提高模型对新类别的泛化能力",
        "方法": "采用文本编码器和基于变换器的图像编码器，通过对比学习对齐像素嵌入与文本嵌入，实现语言驱动的语义分割",
        "关键词": [
            "语言驱动",
            "语义分割",
            "零样本学习",
            "变换器",
            "对比学习"
        ],
        "涉及的技术概念": {
            "文本编码器": "用于计算描述性输入标签的嵌入，为模型提供语言信息",
            "变换器图像编码器": "计算输入图像的密集每像素嵌入，捕捉图像的深层特征",
            "对比学习": "训练图像编码器以对齐像素嵌入与相应语义类别的文本嵌入，增强模型的泛化能力"
        },
        "success": true
    },
    {
        "order": 504,
        "title": "Language model compression with weighted low-rank factorization",
        "html": "https://iclr.cc//virtual/2022/poster/6157",
        "abstract": "Factorizing a large matrix into small matrices is a popular strategy for model compression. Singular value decomposition (SVD) plays a vital role in this compression strategy, approximating a learned matrix with fewer parameters. However, SVD minimizes the squared error toward reconstructing the original matrix without gauging the importance of the parameters, potentially giving a larger reconstruction error for those who affect the task accuracy more. In other words, the optimization objective of SVD is not aligned with the trained model's task accuracy. We analyze this previously unexplored problem, make observations, and address it by introducing Fisher information to weigh the importance of parameters affecting the model prediction. This idea leads to our method: Fisher-Weighted SVD (FWSVD). Although the factorized matrices from our approach do not result in smaller reconstruction errors, we find that our resulting task accuracy is much closer to the original model's performance. We perform analysis with the transformer-based language models, showing our weighted SVD largely alleviates the mismatched optimization objectives and can maintain model performance with a higher compression rate. Our method can directly compress a task-specific model while achieving better performance than other compact model strategies requiring expensive model pre-training. Moreover, the evaluation of compressing an already compact model shows our method can further reduce 9% to 30% parameters with an insignificant impact on task accuracy.",
        "conference": "ICLR",
        "中文标题": "语言模型压缩与加权低秩分解",
        "摘要翻译": "将大矩阵分解为小矩阵是模型压缩的一种流行策略。奇异值分解（SVD）在这种压缩策略中扮演着至关重要的角色，它用更少的参数近似学习到的矩阵。然而，SVD最小化重建原始矩阵的平方误差，而没有衡量参数的重要性，可能对那些影响任务准确度更大的参数产生更大的重建误差。换句话说，SVD的优化目标与训练模型的任务准确度不一致。我们分析了这个之前未被探索的问题，进行了观察，并通过引入Fisher信息来衡量影响模型预测的参数的重要性来解决它。这个想法引出了我们的方法：Fisher加权SVD（FWSVD）。尽管我们方法分解的矩阵不会导致更小的重建误差，但我们发现我们得到的任务准确度更接近原始模型的性能。我们基于transformer的语言模型进行了分析，显示我们的加权SVD在很大程度上缓解了不匹配的优化目标，并且可以在更高的压缩率下保持模型性能。我们的方法可以直接压缩特定任务的模型，同时实现比其他需要昂贵模型预训练的紧凑模型策略更好的性能。此外，对已经紧凑的模型进行压缩的评估显示，我们的方法可以进一步减少9%到30%的参数，对任务准确度的影响不显著。",
        "领域": "模型压缩、自然语言处理、深度学习优化",
        "问题": "解决SVD在模型压缩中优化目标与任务准确度不一致的问题",
        "动机": "提高模型压缩后的任务准确度，使其更接近原始模型的性能",
        "方法": "引入Fisher信息来加权参数重要性，提出Fisher加权SVD（FWSVD）方法",
        "关键词": [
            "模型压缩",
            "加权低秩分解",
            "Fisher信息",
            "SVD",
            "任务准确度"
        ],
        "涉及的技术概念": {
            "奇异值分解（SVD）": "用于模型压缩，通过分解矩阵减少参数数量",
            "Fisher信息": "用于衡量参数对模型预测的重要性，优化压缩过程",
            "transformer": "作为分析的语言模型架构，验证FWSVD方法的有效性"
        },
        "success": true
    },
    {
        "order": 505,
        "title": "Language modeling via stochastic processes",
        "html": "https://iclr.cc//virtual/2022/poster/5950",
        "abstract": "Modern language models can generate high-quality short texts. However, they often meander or are incoherent when generating longer texts. These issues arise from the next-token-only language modeling objective. To address these issues, we introduce Time Control (TC), a language model that implicitly plans via a latent stochastic process. TC does this by learning a representation which maps the dynamics of how text changes in a document to the dynamics of a stochastic process of interest. Using this representation, the language model can generate text by first implicitly generating a document plan via a stochastic process, and then generating text that is consistent with this latent plan. Compared to domain-specific methods and fine-tuning GPT2 across a variety of text domains, TC improves performance on text infilling and discourse coherence. On long text generation settings, TC preserves the text structure both in terms of ordering (up to +40% better) and text length consistency (up to +17% better).  Human evaluators also prefer TC's output 28.6% more than the baselines.",
        "conference": "ICLR",
        "中文标题": "通过随机过程进行语言建模",
        "摘要翻译": "现代语言模型能够生成高质量的短文本。然而，在生成长文本时，它们常常会偏离主题或缺乏连贯性。这些问题源于仅基于下一个词的语言建模目标。为了解决这些问题，我们引入了时间控制（TC），这是一种通过潜在随机过程隐式规划的语言模型。TC通过学习一种表示来实现这一点，该表示将文本在文档中变化的动态映射到感兴趣的随机过程的动态。利用这种表示，语言模型可以首先通过随机过程隐式生成文档计划，然后生成与这一潜在计划一致的文本。与领域特定方法以及在各种文本领域微调GPT2相比，TC在文本填充和话语连贯性方面提高了性能。在长文本生成设置中，TC在文本结构的顺序（最高提高40%）和文本长度一致性（最高提高17%）方面都保持了更好的表现。人类评估者也更倾向于TC的输出，比基线模型高出28.6%。",
        "领域": "自然语言处理与视觉结合、文本生成、语言模型优化",
        "问题": "解决现代语言模型在生成长文本时偏离主题或缺乏连贯性的问题",
        "动机": "通过引入随机过程来隐式规划文本生成，以提高长文本的连贯性和结构一致性",
        "方法": "开发时间控制（TC）语言模型，通过学习文本变化动态与随机过程动态的映射表示，实现隐式文档规划和连贯文本生成",
        "关键词": [
            "时间控制",
            "随机过程",
            "文本生成",
            "语言模型",
            "连贯性"
        ],
        "涉及的技术概念": {
            "时间控制（TC）": "一种通过潜在随机过程隐式规划的语言模型，用于提高文本生成的连贯性和结构一致性",
            "潜在随机过程": "用于隐式生成文档计划的技术，通过映射文本变化动态到随机过程动态来实现",
            "文本填充": "评估语言模型性能的一个方面，TC在这方面相比基线模型有显著提升"
        },
        "success": true
    },
    {
        "order": 506,
        "title": "Large Language Models Can Be Strong Differentially Private Learners",
        "html": "https://iclr.cc//virtual/2022/poster/6894",
        "abstract": "Differentially Private (DP) learning has seen limited success for building large deep learning models of text, and straightforward attempts at applying Differentially Private Stochastic Gradient Descent (DP-SGD) to NLP tasks have resulted in large performance drops and high computational overhead.We show that this performance drop can be mitigated with (1) the use of large pretrained language models; (2) non-standard hyperparameters that suit DP optimization; and (3) fine-tuning objectives which are aligned with the pretraining procedure.With the above, we obtain NLP models that outperform state-of-the-art DP-trained models under the same privacy budget and strong non-private baselines---by directly fine-tuning pretrained models with DP optimization on moderately-sized corpora. To address the computational challenge of running DP-SGD with large Transformers, we propose a memory saving technique that allows clipping in DP-SGD to run without instantiating per-example gradients for any linear layer in the model. The technique enables privately training Transformers with almost the same memory cost as non-private training at a modest run-time overhead. Contrary to conventional wisdom that DP optimization fails at learning high-dimensional models (due to noise that scales with dimension) empirical results reveal that private learning with pretrained language models tends to not suffer from dimension-dependent performance degradation.Code to reproduce results can be found at https://github.com/lxuechen/private-transformers.",
        "conference": "ICLR",
        "中文标题": "大型语言模型可以成为强大的差分隐私学习者",
        "摘要翻译": "差分隐私（DP）学习在构建大型深度学习文本模型方面取得的成功有限，直接尝试将差分隐私随机梯度下降（DP-SGD）应用于NLP任务导致了性能大幅下降和高计算开销。我们表明，通过（1）使用大型预训练语言模型；（2）适合DP优化的非标准超参数；以及（3）与预训练过程一致的微调目标，可以减轻这种性能下降。通过上述方法，我们在相同的隐私预算下获得了优于最先进的DP训练模型和强大的非隐私基线的NLP模型——通过在中等规模的语料库上直接使用DP优化微调预训练模型。为了解决使用大型Transformers运行DP-SGD的计算挑战，我们提出了一种内存节省技术，该技术允许在DP-SGD中进行裁剪，而无需为模型中的任何线性层实例化每个示例的梯度。该技术使得以与非隐私训练几乎相同的内存成本私下训练Transformers成为可能，仅需适度的运行时开销。与DP优化因学习高维模型（由于噪声随维度缩放）而失败的常规智慧相反，实证结果显示，使用预训练语言模型进行隐私学习往往不会遭受依赖于维度的性能下降。重现结果的代码可以在https://github.com/lxuechen/private-transformers找到。",
        "领域": "自然语言处理与隐私保护结合",
        "问题": "如何在保持差分隐私的同时，有效训练大型语言模型并减少性能下降",
        "动机": "解决差分隐私学习在大型深度学习文本模型构建中的性能下降和高计算开销问题",
        "方法": "使用大型预训练语言模型、适合DP优化的非标准超参数、与预训练过程一致的微调目标，并提出内存节省技术以减少计算开销",
        "关键词": [
            "差分隐私学习",
            "大型语言模型",
            "DP-SGD优化",
            "内存节省技术",
            "预训练模型微调"
        ],
        "涉及的技术概念": {
            "差分隐私随机梯度下降（DP-SGD）": "用于在保证数据隐私的前提下优化模型训练的技术",
            "预训练语言模型": "在大量数据上预先训练的模型，用于提升特定任务的性能",
            "内存节省技术": "减少在差分隐私训练过程中内存使用的技术，使得大型模型训练成为可能"
        },
        "success": true
    },
    {
        "order": 507,
        "title": "Large Learning Rate Tames Homogeneity: Convergence and Balancing Effect",
        "html": "https://iclr.cc//virtual/2022/poster/6679",
        "abstract": "Recent empirical advances show that training deep models with large learning rate often improves generalization performance. However, theoretical justifications on the benefits of large learning rate are highly limited, due to challenges in analysis. In this paper, we consider using Gradient Descent (GD) with a large learning rate on a homogeneous matrix factorization problem, i.e., $\\min_{X, Y} \\|A - XY^\\top\\|_{\\sf F}^2$. We prove a convergence theory for constant large learning rates well beyond $2/L$, where $L$ is the largest eigenvalue of Hessian at the initialization. Moreover, we rigorously establish an implicit bias of GD induced by such a large learning rate, termed `balancing', meaning that magnitudes of $X$ and $Y$ at the limit of GD iterations will be close even if their initialization is significantly unbalanced. Numerical experiments are provided to support our theory.",
        "conference": "ICLR",
        "中文标题": "大学习率驯服同质性：收敛与平衡效应",
        "摘要翻译": "近期的实证研究表明，使用大学习率训练深度模型往往能提高泛化性能。然而，由于分析上的挑战，关于大学习率好处的理论解释非常有限。在本文中，我们考虑在一个同质矩阵分解问题上使用梯度下降（GD）和大学习率，即最小化$A - XY^\top$的Frobenius范数平方。我们证明了对于远超过$2/L$的恒定大学习率的收敛理论，其中$L$是初始化时Hessian矩阵的最大特征值。此外，我们严格建立了由这种大学习率引起的GD的隐式偏差，称为‘平衡’，意味着在GD迭代的极限下，$X$和$Y$的幅度将接近，即使它们的初始化显著不平衡。数值实验支持了我们的理论。",
        "领域": "深度学习优化、矩阵分解、梯度下降算法",
        "问题": "大学习率在深度模型训练中提高泛化性能的理论解释不足",
        "动机": "探索和理论证明大学习率在训练深度模型时的优势及其背后的机制",
        "方法": "在矩阵分解问题上应用梯度下降算法，结合大学习率，分析其收敛性和平衡效应",
        "关键词": [
            "大学习率",
            "梯度下降",
            "矩阵分解",
            "收敛理论",
            "平衡效应"
        ],
        "涉及的技术概念": {
            "梯度下降（GD）": "用于优化矩阵分解问题的迭代算法，本文中特别关注于使用大学习率的情况",
            "Hessian矩阵的最大特征值（L）": "在收敛理论中用于界定学习率的上限，本文中学习率远超过传统的2/L界限",
            "平衡效应": "指在使用大学习率时，GD迭代会使得解的参数趋于平衡，即使初始参数不平衡"
        },
        "success": true
    },
    {
        "order": 508,
        "title": "Large-Scale Representation Learning on Graphs via Bootstrapping",
        "html": "https://iclr.cc//virtual/2022/poster/6390",
        "abstract": "Self-supervised learning provides a promising path towards eliminating the need for costly label information in representation learning on graphs.  However, to achieve state-of-the-art performance, methods often need large numbers of negative examples and rely on complex augmentations.  This can be prohibitively expensive, especially for large graphs. To address these challenges, we introduce Bootstrapped Graph Latents (BGRL) - a graph representation learning method that learns by predicting alternative augmentations of the input. BGRL uses only simple augmentations and alleviates the need for contrasting with negative examples, and thus is scalable by design. BGRL outperforms or matches prior methods on several established benchmarks, while achieving a 2-10x reduction in memory costs. Furthermore, we show that BGRL can be scaled up to extremely large graphs with hundreds of millions of nodes in the semi-supervised regime, achieving state-of-the-art performance and improving over supervised baselines where representations are shaped only through label information.  In particular, our solution centered on BGRL constituted one of the winning entries to the Open Graph Benchmark -Large Scale Challenge at KDD Cup 2021, on a graph orders of magnitudes larger than all previously available benchmarks, thus demonstrating the scalability and effectiveness of our approach.",
        "conference": "ICLR",
        "中文标题": "通过自举实现图上的大规模表示学习",
        "摘要翻译": "自监督学习为消除图表示学习中对昂贵标签信息的需求提供了一条有希望的途径。然而，为了达到最先进的性能，方法通常需要大量的负例样本并依赖于复杂的增强技术。这对于大型图来说可能是极其昂贵的。为了解决这些挑战，我们引入了自举图潜在表示（BGRL）——一种通过预测输入的替代增强来学习的图表示学习方法。BGRL仅使用简单的增强技术，并且不需要与负例样本进行对比，因此在设计上具有可扩展性。BGRL在几个已建立的基准测试中优于或匹配先前的方法，同时实现了内存成本2-10倍的降低。此外，我们展示了BGRL可以在半监督机制下扩展到具有数亿个节点的极大图，达到最先进的性能，并在仅通过标签信息塑造表示的情况下改进了监督基线。特别是，我们以BGRL为中心的解决方案构成了KDD Cup 2021开放图基准大规模挑战赛的获胜作品之一，该图的规模比之前所有可用的基准测试大几个数量级，从而证明了我们方法的可扩展性和有效性。",
        "领域": "图表示学习",
        "问题": "如何在减少计算和内存成本的同时，实现高效的图表示学习",
        "动机": "减少图表示学习中对大量负例样本和复杂增强技术的依赖，以降低计算和内存成本",
        "方法": "引入自举图潜在表示（BGRL），通过预测输入的替代增强来学习，仅使用简单的增强技术，不需要与负例样本进行对比",
        "关键词": [
            "自监督学习",
            "图表示学习",
            "自举",
            "大规模图",
            "半监督学习"
        ],
        "涉及的技术概念": {
            "自监督学习": "一种不需要大量标注数据的学习方法，通过数据自身的结构来学习表示",
            "图表示学习": "旨在将图中的节点或整个图转换为低维向量表示的技术，以便于后续的机器学习任务",
            "自举": "在本研究中指通过预测输入的替代增强来学习图表示的方法，减少了对负例样本的需求"
        },
        "success": true
    },
    {
        "order": 509,
        "title": "Latent Image Animator: Learning to Animate Images via Latent Space Navigation",
        "html": "https://iclr.cc//virtual/2022/poster/6122",
        "abstract": "Due to the remarkable progress of deep generative models, animating images has become increasingly efficient, whereas associated results have become increasingly realistic. Current animation-approaches commonly exploit structure representation extracted from driving videos. Such structure representation is instrumental in transferring motion from driving videos to still images. However, such approaches fail in case the source image and driving video encompass large appearance variation. Moreover, the extraction of structure information requires additional modules that endow the animation-model with increased complexity. Deviating from such models, we here introduce the Latent Image Animator (LIA), a self-supervised autoencoder that evades need for structure representation. LIA is streamlined to animate images by linear navigation in the latent space. Specifically, motion in generated video is constructed by linear displacement of codes in the latent space. Towards this, we learn a set of orthogonal motion directions simultaneously, and use their linear combination, in order to represent any displacement in the latent space. Extensive quantitative and qualitative analysis suggests that our model systematically and significantly outperforms state-of-art methods on VoxCeleb, Taichi and TED-talk datasets w.r.t. generated quality.",
        "conference": "ICLR",
        "中文标题": "潜在图像动画师：通过潜在空间导航学习动画图像",
        "摘要翻译": "由于深度生成模型的显著进步，动画制作变得越来越高效，同时相关结果也变得越来越逼真。当前的动画方法通常利用从驱动视频中提取的结构表示。这种结构表示在将运动从驱动视频转移到静止图像中起到了关键作用。然而，当源图像和驱动视频包含较大的外观变化时，这种方法就会失败。此外，结构信息的提取需要额外的模块，这增加了动画模型的复杂性。与这些模型不同，我们在这里介绍了潜在图像动画师（LIA），这是一种自监督的自动编码器，它避免了对结构表示的需求。LIA通过在潜在空间中的线性导航来简化图像的动画制作。具体来说，生成视频中的运动是通过潜在空间中代码的线性位移构建的。为此，我们同时学习一组正交的运动方向，并使用它们的线性组合来表示潜在空间中的任何位移。广泛的定量和定性分析表明，我们的模型在VoxCeleb、Taichi和TED-talk数据集上生成的视频质量方面，系统且显著地优于最先进的方法。",
        "领域": "图像生成、视频动画、自监督学习",
        "问题": "解决在源图像和驱动视频外观差异较大时，现有动画方法失效的问题，以及减少动画模型复杂性的问题。",
        "动机": "为了开发一种不需要复杂结构表示、能够处理大外观变化图像的动画方法。",
        "方法": "引入潜在图像动画师（LIA），一种自监督的自动编码器，通过在潜在空间中进行线性导航来动画化图像。",
        "关键词": [
            "潜在空间导航",
            "自监督学习",
            "图像动画",
            "线性位移",
            "正交运动方向"
        ],
        "涉及的技术概念": {
            "潜在空间导航": "通过在潜在空间中的线性位移来构建视频中的运动。",
            "自监督自动编码器": "用于学习图像表示而不需要显式结构信息的模型。",
            "正交运动方向": "学习一组方向，其线性组合可以表示潜在空间中的任何位移。"
        },
        "success": true
    },
    {
        "order": 510,
        "title": "Latent Variable Sequential Set Transformers for Joint Multi-Agent Motion Prediction",
        "html": "https://iclr.cc//virtual/2022/poster/6106",
        "abstract": "Robust multi-agent trajectory prediction is essential for the safe control of robotic systems. A major challenge is to efficiently learn a representation that approximates the true joint distribution of contextual, social, and temporal information to enable planning. We propose Latent Variable Sequential Set Transformers which are encoder-decoder architectures that generate scene-consistent multi-agent trajectories. We refer to these architectures as “AutoBots”. The encoder is a stack of interleaved temporal and social multi-head self-attention (MHSA) modules which alternately perform equivariant processing across the temporal and social dimensions. The decoder employs learnable seed parameters in combination with temporal and social MHSA modules allowing it to perform inference over theentire future scene in a single forward pass efficiently. AutoBots can produce either the trajectory of one ego-agent or a distribution over the future trajectories for all agents in the scene. For the single-agent prediction case, our model achieves top results on the global nuScenes vehicle motion prediction leaderboard, and produces strong results on the Argoverse vehicle prediction challenge. In the multi-agent setting, we evaluate on the synthetic partition of TrajNet++ dataset to showcase the model’s socially-consistent predictions. We also demonstrate our model on general sequences of sets and provide illustrative experiments modelling the sequential structure of the multiple strokes that make up symbols in the Omniglot data. A distinguishing feature of AutoBots is that all models are trainable on asingle desktop GPU (1080 Ti) in under 48h.",
        "conference": "ICLR",
        "中文标题": "潜在变量序列集合变换器用于联合多智能体运动预测",
        "摘要翻译": "鲁棒的多智能体轨迹预测对于机器人系统的安全控制至关重要。一个主要挑战是高效学习一个能够近似真实联合分布的表示，该分布包含上下文、社交和时间信息，以支持规划。我们提出了潜在变量序列集合变换器，这是一种编码器-解码器架构，能够生成场景一致的多智能体轨迹。我们将这些架构称为“AutoBots”。编码器由交替进行时间和社交多头自注意力（MHSA）模块的堆叠组成，这些模块在时间和社交维度上交替进行等变处理。解码器采用可学习的种子参数结合时间和社交MHSA模块，使其能够高效地在单次前向传递中对整个未来场景进行推理。AutoBots可以生成单个自我智能体的轨迹或场景中所有智能体未来轨迹的分布。在单智能体预测情况下，我们的模型在全局nuScenes车辆运动预测排行榜上取得了顶尖成绩，并在Argoverse车辆预测挑战中产生了强劲的结果。在多智能体设置中，我们在TrajNet++数据集的合成分区上评估，展示了模型的社会一致性预测。我们还在通用集合序列上展示了我们的模型，并提供了关于Omniglot数据中构成符号的多个笔画的顺序结构的说明性实验。AutoBots的一个显著特点是所有模型都可以在单个桌面GPU（1080 Ti）上在48小时内完成训练。",
        "领域": "多智能体轨迹预测",
        "问题": "高效学习一个能够近似真实联合分布的表示，该分布包含上下文、社交和时间信息，以支持规划",
        "动机": "为了机器人系统的安全控制，需要鲁棒的多智能体轨迹预测",
        "方法": "提出潜在变量序列集合变换器，采用编码器-解码器架构，通过时间和社交多头自注意力模块交替处理，生成场景一致的多智能体轨迹",
        "关键词": [
            "多智能体轨迹预测",
            "潜在变量序列集合变换器",
            "多头自注意力"
        ],
        "涉及的技术概念": {
            "潜在变量序列集合变换器": "用于生成场景一致的多智能体轨迹的编码器-解码器架构",
            "多头自注意力（MHSA）模块": "在时间和社交维度上交替进行等变处理，以学习上下文、社交和时间信息的表示",
            "AutoBots": "提出的模型名称，能够在单次前向传递中对整个未来场景进行高效推理"
        },
        "success": true
    },
    {
        "order": 511,
        "title": "Learnability Lock: Authorized Learnability Control Through Adversarial Invertible Transformations",
        "html": "https://iclr.cc//virtual/2022/poster/6516",
        "abstract": "Owing much to the revolution of information technology, recent progress of deep learning benefits incredibly from the vastly enhanced access to data available in various digital formats. Yet those publicly accessible information also raises a fundamental issue concerning Intellectual Property, that is, how to precisely control legal or illegal exploitation of a dataset for training commercial models. To tackle this issue, this paper introduces and investigates a new concept called ''learnability lock'' for securing the process of data authorization. In particular, we propose adversarial invertible transformation, that can be viewed as a mapping from image to image, to encrypt data samples so that they become ''unlearnable'' by machine learning models with negligible loss of visual features. Meanwhile, authorized clients can use a specific key to unlock the learnability of the protected dataset and train models normally. The proposed learnability lock leverages class-wise perturbation that applies a universal transformation function on data samples of the same label. This ensures that the learnability can be easily restored with a simple inverse transformation while remaining difficult to be detected or reverse-engineered. We empirically demonstrate the success and practicability of our method on visual classification tasks.  ",
        "conference": "ICLR",
        "中文标题": "可学习性锁：通过对抗性可逆变换实现授权的可学习性控制",
        "摘要翻译": "由于信息技术的革命，深度学习的最新进展极大地受益于以各种数字格式广泛增强的数据访问。然而，这些公开可访问的信息也引发了一个关于知识产权的基本问题，即如何精确控制数据集用于训练商业模型的合法或非法利用。为了解决这个问题，本文介绍并研究了一个名为'可学习性锁'的新概念，用于保护数据授权过程。特别是，我们提出了对抗性可逆变换，可以视为从图像到图像的映射，以加密数据样本，使它们对机器学习模型变得'不可学习'，同时视觉特征的损失可以忽略不计。同时，授权客户可以使用特定的密钥解锁受保护数据集的可学习性，并正常训练模型。提出的可学习性锁利用了类级扰动，对同一标签的数据样本应用通用的变换函数。这确保了可学习性可以通过简单的逆变换轻松恢复，同时难以被检测或逆向工程。我们在视觉分类任务上实证证明了我们方法的成功和实用性。",
        "领域": "深度学习安全、图像加密、对抗性机器学习",
        "问题": "如何精确控制数据集用于训练商业模型的合法或非法利用",
        "动机": "保护数据知识产权，防止未经授权的数据利用",
        "方法": "提出对抗性可逆变换加密数据样本，使其对机器学习模型不可学习，同时授权用户可通过密钥解锁",
        "关键词": [
            "可学习性锁",
            "对抗性可逆变换",
            "数据授权",
            "类级扰动",
            "视觉分类"
        ],
        "涉及的技术概念": {
            "对抗性可逆变换": "用于加密数据样本，使其对机器学习模型不可学习的技术",
            "类级扰动": "对同一标签的数据样本应用通用的变换函数，确保可学习性可通过逆变换恢复",
            "可学习性锁": "一种新概念，用于保护数据授权过程，确保只有授权用户才能解锁数据的可学习性"
        },
        "success": true
    },
    {
        "order": 512,
        "title": "Learnability of convolutional neural networks for infinite dimensional input via mixed and anisotropic smoothness",
        "html": "https://iclr.cc//virtual/2022/poster/6811",
        "abstract": "Among a wide range of success of deep learning, convolutional neural networks have been extensively utilized in several tasks such as speech recognition, image processing, and natural language processing, which require inputs with large dimensions.Several studies have investigated function estimation capability of deep learning, but most of them have assumed that the dimensionality of the input is much smaller than the sample size. However, for typical data in applications such as those handled by the convolutional neural networks described above, the dimensionality of inputs is relatively high or even infinite. In this paper, we investigate the approximation and estimation errors of the (dilated) convolutional neural networks when the input is infinite dimensional. Although the approximation and estimation errors of neural networks are affected by the curse of dimensionality in the existing analyses for typical function spaces such as the \\Holder and Besov spaces, we show that, by considering anisotropic smoothness, they can alleviate exponential dependency on the dimensionality but they only depend on the smoothness of the target functions. Our theoretical analysis supports the great practical success of convolutional networks.  Furthermore, we show that the dilated convolution is advantageous when the smoothness of the target function has a sparse structure.",
        "conference": "ICLR",
        "中文标题": "通过混合和各向异性平滑度研究卷积神经网络对无限维输入的可学习性",
        "摘要翻译": "在深度学习的广泛应用中，卷积神经网络已被广泛用于语音识别、图像处理和自然语言处理等需要大维度输入的任务中。多项研究探讨了深度学习的功能估计能力，但大多数研究假设输入的维度远小于样本大小。然而，对于上述卷积神经网络处理的典型应用数据，输入的维度相对较高甚至是无限的。本文研究了当输入为无限维时，（扩张）卷积神经网络的近似和估计误差。尽管在现有的分析中，对于典型的函数空间如Holder和Besov空间，神经网络的近似和估计误差受到维度诅咒的影响，但我们表明，通过考虑各向异性平滑度，可以减轻对维度的指数依赖，而仅依赖于目标函数的平滑度。我们的理论分析支持了卷积网络在实际中的巨大成功。此外，我们还表明，当目标函数的平滑度具有稀疏结构时，扩张卷积具有优势。",
        "领域": "深度学习理论、卷积神经网络、函数逼近理论",
        "问题": "研究卷积神经网络在处理无限维输入时的近似和估计误差问题",
        "动机": "探讨在高维或无限维输入情况下，卷积神经网络的性能及其理论基础",
        "方法": "通过考虑各向异性平滑度，分析卷积神经网络的近似和估计误差，减轻维度诅咒的影响",
        "关键词": [
            "卷积神经网络",
            "无限维输入",
            "各向异性平滑度",
            "维度诅咒",
            "扩张卷积"
        ],
        "涉及的技术概念": {
            "各向异性平滑度": "用于描述目标函数在不同方向上的平滑程度，帮助减轻维度诅咒的影响",
            "维度诅咒": "指在高维空间中，数据稀疏性增加，导致学习任务变得更加困难的现象",
            "扩张卷积": "一种卷积操作，通过引入间隔来扩大感受野，有助于捕捉稀疏结构的目标函数平滑度"
        },
        "success": true
    },
    {
        "order": 513,
        "title": "Learned Simulators for Turbulence",
        "html": "https://iclr.cc//virtual/2022/poster/6985",
        "abstract": "Turbulence simulation with classical numerical solvers requires  high-resolution grids to accurately resolve dynamics. Here we train learned simulators at low spatial and temporal resolutions to capture turbulent dynamics generated at high resolution. We show that our proposed model can simulate turbulent dynamics more accurately than classical numerical solvers at the comparably low resolutions across various scientifically relevant metrics. Our model is trained end-to-end from data and is capable of learning a range of challenging chaotic and turbulent dynamics at low resolution, including trajectories generated by the state-of-the-art Athena++ engine. We show that our simpler, general-purpose architecture outperforms various more specialized, turbulence-specific architectures from the learned turbulence simulation literature. In general, we see that learned simulators yield unstable trajectories; however, we show that tuning training noise and temporal downsampling solves this problem. We also find that while generalization beyond the training distribution is a challenge for learned models, training noise, added loss constraints, and dataset augmentation can help. Broadly, we conclude that our learned simulator outperforms traditional solvers run on coarser grids, and emphasize that simple design choices can offer stability and robust generalization.",
        "conference": "ICLR",
        "中文标题": "湍流的学习模拟器",
        "摘要翻译": "使用经典数值求解器进行湍流模拟需要高分辨率网格以准确解析动态。在此，我们训练了在低空间和时间分辨率下的学习模拟器，以捕捉高分辨率生成的湍流动态。我们表明，我们提出的模型在各种科学相关指标上，能够在相对较低的分辨率下比经典数值求解器更准确地模拟湍流动态。我们的模型是从数据端到端训练的，能够学习一系列具有挑战性的混沌和湍流动态，包括由最先进的Athena++引擎生成的轨迹。我们展示了我们更简单、通用的架构优于学习湍流模拟文献中各种更专门化、针对湍流的架构。一般来说，我们看到学习模拟器产生不稳定的轨迹；然而，我们表明调整训练噪声和时间下采样可以解决这个问题。我们还发现，虽然对于学习模型来说，超出训练分布的泛化是一个挑战，但训练噪声、增加的损失约束和数据集增强可以帮助。总的来说，我们得出结论，我们的学习模拟器优于在较粗网格上运行的传统求解器，并强调简单的设计选择可以提供稳定性和强大的泛化能力。",
        "领域": "流体动力学模拟、深度学习应用、科学计算",
        "问题": "如何在低分辨率下准确模拟高分辨率湍流动态",
        "动机": "减少湍流模拟对高分辨率网格的依赖，提高计算效率",
        "方法": "训练端到端的学习模拟器，通过调整训练噪声和时间下采样来提高稳定性和泛化能力",
        "关键词": [
            "湍流模拟",
            "学习模拟器",
            "低分辨率",
            "Athena++",
            "泛化能力"
        ],
        "涉及的技术概念": {
            "学习模拟器": "通过深度学习技术训练的模型，用于在低分辨率下模拟高分辨率湍流动态",
            "训练噪声": "在训练过程中引入的噪声，用于提高模型的稳定性和泛化能力",
            "时间下采样": "减少时间分辨率的技术，用于帮助模型学习更稳定的动态"
        },
        "success": true
    },
    {
        "order": 514,
        "title": "Learning 3D Representations of Molecular Chirality with Invariance to Bond Rotations",
        "html": "https://iclr.cc//virtual/2022/poster/6759",
        "abstract": "Molecular chirality, a form of stereochemistry most often describing relative spatial arrangements of bonded neighbors around tetrahedral carbon centers, influences the set of 3D conformers accessible to the molecule without changing its 2D graph connectivity. Chirality can strongly alter (bio)chemical interactions, particularly protein-drug binding. Most 2D graph neural networks (GNNs) designed for molecular property prediction at best use atomic labels to naïvely treat chirality, while E(3)-invariant 3D GNNs are invariant to chirality altogether. To enable representation learning on molecules with defined stereochemistry, we design an SE(3)-invariant model that processes torsion angles of a 3D molecular conformer. We explicitly model conformational flexibility by integrating a novel type of invariance to rotations about internal molecular bonds into the architecture, mitigating the need for multi-conformer data augmentation. We test our model on four benchmarks: contrastive learning to distinguish conformers of different stereoisomers in a learned latent space, classification of chiral centers as R/S, prediction of how enantiomers rotate circularly polarized light, and ranking enantiomers by their docking scores in an enantiosensitive protein pocket. We compare our model, Chiral InterRoto-Invariant Neural Network (ChIRo), with 2D and 3D GNNs to demonstrate that our model achieves state of the art performance when learning chiral-sensitive functions from molecular structures.",
        "conference": "ICLR",
        "中文标题": "学习分子手性的3D表示：对键旋转的不变性",
        "摘要翻译": "分子手性是一种立体化学形式，最常用于描述围绕四面体碳中心的键合邻居的相对空间排列，它影响了分子可访问的3D构象异构体集合，而不改变其2D图连接性。手性可以强烈改变（生物）化学相互作用，特别是蛋白质-药物结合。大多数设计用于分子性质预测的2D图神经网络（GNNs）最多使用原子标签来天真地处理手性，而E(3)不变的3D GNNs对手性完全不敏感。为了在具有明确立体化学的分子上进行表示学习，我们设计了一个SE(3)不变的模型，该模型处理3D分子构象异构体的扭转角。我们通过将一种新型的对内部分子键旋转的不变性整合到架构中，明确地模拟了构象灵活性，从而减少了对多构象异构体数据增强的需求。我们在四个基准上测试了我们的模型：对比学习以区分学习潜在空间中不同立体异构体的构象异构体，将手性中心分类为R/S，预测对映体如何旋转圆偏振光，以及通过其对映体在对手性敏感的蛋白质口袋中的对接分数来排名对映体。我们将我们的模型——手性内部旋转不变神经网络（ChIRo）与2D和3D GNNs进行比较，以证明我们的模型在从分子结构学习手性敏感功能时达到了最先进的性能。",
        "领域": "分子表示学习、药物发现、蛋白质-药物相互作用预测",
        "问题": "如何在分子表示学习中有效处理手性信息，同时保持对键旋转的不变性",
        "动机": "现有的2D和3D图神经网络在处理分子手性信息时存在不足，无法有效捕捉手性对分子性质的影响，特别是在蛋白质-药物结合等生物化学相互作用中。",
        "方法": "设计了一个SE(3)不变的模型，通过处理3D分子构象异构体的扭转角来学习分子手性的表示，并引入对内部分子键旋转的新型不变性以模拟构象灵活性。",
        "关键词": [
            "分子手性",
            "SE(3)不变性",
            "图神经网络",
            "药物发现",
            "蛋白质-药物相互作用"
        ],
        "涉及的技术概念": {
            "SE(3)不变性": "在模型中引入的对称性，确保模型在处理3D分子结构时对旋转和平移保持不变，从而有效捕捉分子手性信息。",
            "扭转角": "用于描述分子构象异构体中键旋转的角度，是模型处理分子手性的关键输入。",
            "对比学习": "用于在潜在空间中区分不同立体异构体的构象异构体，是模型学习手性敏感功能的一种方法。"
        },
        "success": true
    },
    {
        "order": 515,
        "title": "Learning Altruistic Behaviours in Reinforcement Learning without External Rewards",
        "html": "https://iclr.cc//virtual/2022/poster/6913",
        "abstract": "Can artificial agents learn to assist others in achieving their goals without knowing what those goals are? Generic reinforcement learning agents could be trained to behave altruistically towards others by rewarding them for altruistic behaviour, i.e., rewarding them for benefiting other agents in a given situation. Such an approach assumes that other agents' goals are known so that the altruistic agent can cooperate in achieving those goals. However, explicit knowledge of other agents' goals is often difficult to acquire. In the case of human agents, their goals and preferences may be difficult to express fully; they might be ambiguous or even contradictory. Thus, it is beneficial to develop agents that do not depend on external supervision and learn altruistic behaviour in a task-agnostic manner. We propose to act altruistically towards other agents by giving them more choice and allowing them to achieve their goals better. Some concrete examples include opening a door for others or safeguarding them to pursue their objectives without interference. We formalize this concept and propose an altruistic agent that learns to increase the choices another agent has by preferring to maximize the number of states that the other agent can reach in its future. We evaluate our approach in three different multi-agent environments where another agent's success depends on altruistic behaviour. Finally, we show that our unsupervised agents can perform comparably to agents explicitly trained to work cooperatively, in some cases even outperforming them.",
        "conference": "ICLR",
        "中文标题": "在无外部奖励的强化学习中学习利他行为",
        "摘要翻译": "人工智能体能否在不了解他人目标的情况下学会帮助他人实现目标？通用的强化学习代理可以通过奖励其利他行为来训练其表现出对他人的利他行为，即在特定情况下因使其他代理受益而获得奖励。这种方法假设其他代理的目标是已知的，以便利他代理可以合作实现这些目标。然而，明确了解其他代理的目标往往是难以获得的。在人类代理的情况下，他们的目标和偏好可能难以完全表达；它们可能是模糊的，甚至是矛盾的。因此，开发不依赖外部监督并以任务无关的方式学习利他行为的代理是有益的。我们提出通过给予其他代理更多选择并允许他们更好地实现目标来对他们采取利他行为。一些具体例子包括为他人开门或保护他们不受干扰地追求目标。我们将这一概念形式化，并提出了一种利他代理，它学会通过偏好最大化其他代理未来可达到的状态数量来增加其他代理的选择。我们在三种不同的多代理环境中评估了我们的方法，其中其他代理的成功依赖于利他行为。最后，我们展示了我们的无监督代理可以与明确训练用于合作的代理相媲美，在某些情况下甚至优于它们。",
        "领域": "多智能体系统、强化学习、行为建模",
        "问题": "如何在不知道其他智能体具体目标的情况下，训练智能体表现出利他行为",
        "动机": "开发不依赖外部监督并能以任务无关方式学习利他行为的智能体，以解决其他智能体目标难以明确表达的问题",
        "方法": "通过最大化其他智能体未来可达到的状态数量来增加其选择，从而学习利他行为",
        "关键词": [
            "利他行为",
            "强化学习",
            "多智能体系统",
            "无监督学习",
            "行为建模"
        ],
        "涉及的技术概念": {
            "利他行为": "智能体在不直接获得外部奖励的情况下，采取行动以帮助其他智能体实现其目标",
            "强化学习": "一种通过奖励机制来训练智能体做出决策的机器学习方法",
            "多智能体系统": "由多个智能体组成的系统，智能体之间可以相互作用和影响"
        },
        "success": true
    },
    {
        "order": 516,
        "title": "Learning a subspace of policies for online adaptation in Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6408",
        "abstract": "Deep Reinforcement Learning (RL) is mainly studied in a setting where the training and the testing environments are similar. But in many practical applications, these environments may differ. For instance, in control systems, the robot(s) on which a policy is learned might differ from the robot(s) on which a policy will run. It can be caused by different internal factors (e.g., calibration issues, system attrition, defective modules) or also by external changes (e.g., weather conditions). There is  a need to develop RL methods that generalize well to variations of the training conditions. In this article, we consider the simplest yet hard to tackle generalization setting where the test environment is unknown at train time, forcing the agent to adapt to the system's new dynamics. This online adaptation process can be computationally expensive (e.g., fine-tuning) and cannot rely on meta-RL techniques since there is just a single train environment. To do so, we propose an approach where we learn a subspace of policies within the parameter space. This subspace contains an infinite number of policies that are trained to solve the training environment while having different parameter values. As a consequence, two policies in that subspace process information differently and exhibit different behaviors when facing variations of the train environment. Our experiments carried out over a large variety of benchmarks compare our approach with baselines, including diversity-based methods. In comparison, our approach is simple to tune, does not need any extra component  (e.g., discriminator) and learns policies able to gather a high reward on unseen environments.",
        "conference": "ICLR",
        "中文标题": "学习策略子空间以实现强化学习中的在线适应",
        "摘要翻译": "深度强化学习（RL）主要在训练和测试环境相似的设定下进行研究。但在许多实际应用中，这些环境可能有所不同。例如，在控制系统中，学习策略的机器人可能与运行策略的机器人不同。这可能是由不同的内部因素（如校准问题、系统磨损、缺陷模块）或外部变化（如天气条件）引起的。因此，需要开发能够很好地适应训练条件变化的RL方法。在本文中，我们考虑了一个简单但难以处理的泛化设定，即测试环境在训练时是未知的，迫使智能体适应系统的新动态。这一在线适应过程可能在计算上非常昂贵（例如，微调），并且不能依赖元RL技术，因为只有一个训练环境。为此，我们提出了一种方法，在参数空间内学习一个策略子空间。这个子空间包含无限数量的策略，这些策略被训练来解决训练环境，同时具有不同的参数值。因此，该子空间中的两个策略在处理信息时表现不同，在面对训练环境的变化时表现出不同的行为。我们在各种基准测试上进行的实验将我们的方法与基线（包括基于多样性的方法）进行了比较。相比之下，我们的方法调参简单，不需要任何额外组件（例如，判别器），并且能够学习到在未见环境中获得高奖励的策略。",
        "领域": "强化学习、机器人控制、自适应系统",
        "问题": "解决强化学习在训练和测试环境不同时的泛化能力问题",
        "动机": "开发能够在训练条件变化时有效适应的强化学习方法，以应对实际应用中环境差异带来的挑战",
        "方法": "在参数空间内学习一个包含无限数量策略的子空间，这些策略能够适应训练环境的变化",
        "关键词": [
            "策略子空间",
            "在线适应",
            "强化学习",
            "泛化能力",
            "参数空间"
        ],
        "涉及的技术概念": {
            "策略子空间": "在参数空间内学习的一个包含无限数量策略的空间，用于适应训练环境的变化",
            "在线适应": "智能体在测试环境未知的情况下，实时适应系统新动态的过程",
            "参数空间": "策略参数的集合，通过调整参数值来生成不同的策略行为"
        },
        "success": true
    },
    {
        "order": 517,
        "title": "Learning Audio-Visual Speech Representation by Masked Multimodal Cluster Prediction",
        "html": "https://iclr.cc//virtual/2022/poster/6707",
        "abstract": "Video recordings of speech contain correlated audio and visual information, providing a strong signal for speech representation learning from the speaker’s lip movements and the produced sound. We introduce Audio-Visual Hidden Unit BERT (AV-HuBERT), a self-supervised representation learning framework for audio-visual speech, which masks multi-stream video input and predicts automatically discovered and iteratively refined multimodal hidden units. AV-HuBERT learns powerful audio-visual speech representation benefiting both lip-reading and automatic speech recognition. On the largest public lip-reading benchmark LRS3 (433 hours), AV-HuBERT achieves 32.5% WER with only 30 hours of labeled data, outperforming the former state-of-the-art approach (33.6%) trained with a thousand times more transcribed video data (31K hours) (Makino et al., 2019). The lip-reading WER is further reduced to 26.9% when using all 433 hours of labeled data from LRS3 and combined with self-training. Using our audio-visual representation on the same benchmark for audio-only speech recognition leads to a 40% relative WER reduction over the state-of-the-art performance (1.3% vs 2.3%). Our code and models are available at https://github.com/facebookresearch/av_hubert.",
        "conference": "ICLR",
        "中文标题": "通过掩码多模态聚类预测学习音频-视觉语音表示",
        "摘要翻译": "语音的视频记录包含相关的音频和视觉信息，为从说话者的唇部动作和产生的声音中学习语音表示提供了强有力的信号。我们介绍了音频-视觉隐藏单元BERT（AV-HuBERT），一个用于音频-视觉语音的自监督表示学习框架，该框架对多流视频输入进行掩码处理，并预测自动发现和迭代优化的多模态隐藏单元。AV-HuBERT学习到了强大的音频-视觉语音表示，有利于唇读和自动语音识别。在最大的公开唇读基准LRS3（433小时）上，AV-HuBERT仅用30小时的标记数据就实现了32.5%的词错误率（WER），优于之前使用千倍以上转录视频数据（31K小时）训练的最先进方法（33.6%）（Makino等人，2019年）。当使用LRS3的所有433小时标记数据并结合自训练时，唇读的WER进一步降低到26.9%。在同一基准上使用我们的音频-视觉表示进行仅音频的语音识别，相对于最先进性能（1.3% vs 2.3%），WER相对减少了40%。我们的代码和模型可在https://github.com/facebookresearch/av_hubert获取。",
        "领域": "唇读识别, 自动语音识别, 多模态学习",
        "问题": "如何有效地从音频和视觉信息中学习语音表示，以提高唇读和自动语音识别的性能。",
        "动机": "利用视频中的音频和视觉信息之间的相关性，开发一个自监督学习框架，以提升语音表示的质量和应用效果。",
        "方法": "提出AV-HuBERT框架，通过掩码多流视频输入并预测多模态隐藏单元，实现音频-视觉语音的自监督表示学习。",
        "关键词": [
            "音频-视觉语音表示",
            "自监督学习",
            "唇读识别",
            "自动语音识别",
            "多模态学习"
        ],
        "涉及的技术概念": {
            "AV-HuBERT": "一个自监督表示学习框架，用于音频-视觉语音，通过掩码处理和预测多模态隐藏单元来学习语音表示。",
            "多模态隐藏单元": "在AV-HuBERT框架中自动发现和迭代优化的单元，用于捕捉音频和视觉信息之间的相关性。",
            "自监督学习": "一种无需大量标记数据的学习方法，通过设计预测任务从数据本身学习有用的表示。"
        },
        "success": true
    },
    {
        "order": 518,
        "title": "Learning-Augmented $k$-means Clustering",
        "html": "https://iclr.cc//virtual/2022/poster/7143",
        "abstract": "$k$-means clustering is a well-studied problem due to its wide applicability. Unfortunately, there exist strong theoretical limits on the performance of any algorithm for the $k$-means problem on worst-case inputs. To overcome this barrier, we consider a scenario where ``advice'' is provided to help perform clustering. Specifically, we consider the $k$-means problem augmented with a predictor that, given any point, returns its cluster label in an approximately optimal clustering up to some, possibly adversarial, error. We present an algorithm whose performance improves along with the accuracy of the predictor, even though na\\'{i}vely following the accurate predictor can still lead to a high clustering cost. Thus if the predictor is sufficiently accurate, we can retrieve a close to optimal clustering with nearly optimal runtime, breaking known computational barriers for algorithms that do not have access to such advice. We evaluate our algorithms on real datasets and show significant improvements in the quality of clustering.",
        "conference": "ICLR",
        "中文标题": "学习增强的k均值聚类",
        "摘要翻译": "k均值聚类因其广泛的应用性而成为一个被深入研究的问题。不幸的是，对于任何算法在最坏情况输入下的k均值问题性能，存在强大的理论限制。为了克服这一障碍，我们考虑了一个提供“建议”以帮助执行聚类的场景。具体来说，我们考虑了一个k均值问题，该问题通过一个预测器增强，该预测器在给定任何点时，返回其在近似最优聚类中的簇标签，直到某些可能是对抗性的错误。我们提出了一种算法，其性能随着预测器准确性的提高而提高，尽管简单地遵循准确的预测器仍可能导致高聚类成本。因此，如果预测器足够准确，我们可以在几乎最优的运行时间内检索到接近最优的聚类，突破了已知的计算障碍，这些障碍是针对那些无法访问此类建议的算法。我们在真实数据集上评估了我们的算法，并展示了聚类质量的显著改善。",
        "领域": "聚类分析",
        "问题": "克服k均值聚类在最坏情况输入下的性能限制",
        "动机": "通过引入预测器提供的建议，提高k均值聚类的性能和效率",
        "方法": "提出了一种结合预测器的k均值聚类算法，该算法能够根据预测器的准确性动态调整聚类过程",
        "关键词": [
            "k均值聚类",
            "学习增强",
            "预测器",
            "聚类质量",
            "计算效率"
        ],
        "涉及的技术概念": {
            "k均值聚类": "一种广泛使用的聚类算法，旨在将数据点划分为k个簇，使得每个点与其所属簇中心的距离平方和最小",
            "学习增强": "通过引入外部知识或预测器来改进传统算法的性能",
            "预测器": "在给定数据点时，预测其所属簇的模型，用于指导聚类过程"
        },
        "success": true
    },
    {
        "order": 519,
        "title": "Learning by Directional Gradient Descent",
        "html": "https://iclr.cc//virtual/2022/poster/7001",
        "abstract": "How should state be constructed from a sequence of observations, so as to best achieve some objective? Most deep learning methods update the parameters of the state representation by gradient descent. However, no prior method for computing the gradient is fully satisfactory, for example consuming too much memory, introducing too much variance, or adding too much bias. In this work, we propose a new learning algorithm that addresses these limitations. The basic idea is to update the parameters of the representation by using the directional derivative along a candidate direction, a quantity that may be computed online with the same computational cost as the representation itself. We consider several different choices of candidate direction, including random selection and approximations to the true gradient, and investigate their performance on several synthetic tasks.  ",
        "conference": "ICLR",
        "中文标题": "通过方向梯度下降学习",
        "摘要翻译": "如何从一系列观察中构建状态，以最好地实现某些目标？大多数深度学习方法通过梯度下降来更新状态表示的参数。然而，之前计算梯度的方法都不完全令人满意，例如消耗太多内存、引入太多方差或增加太多偏差。在这项工作中，我们提出了一种新的学习算法，以解决这些限制。基本思想是通过使用沿候选方向的方向导数来更新表示的参数，这一数量可以在线计算，其计算成本与表示本身相同。我们考虑了几种不同的候选方向选择，包括随机选择和真实梯度的近似，并在几个合成任务上研究了它们的性能。",
        "领域": "深度学习优化、梯度下降算法、在线学习",
        "问题": "解决现有梯度计算方法在内存消耗、方差和偏差方面的不足",
        "动机": "改进深度学习中状态表示参数的更新方法，以提高计算效率和减少偏差",
        "方法": "提出一种新的学习算法，利用方向导数沿候选方向更新参数，支持在线计算",
        "关键词": [
            "方向梯度下降",
            "在线学习",
            "参数更新",
            "计算效率",
            "偏差减少"
        ],
        "涉及的技术概念": {
            "方向导数": "用于沿特定方向更新状态表示参数，减少计算资源消耗",
            "候选方向": "算法中考虑的不同更新方向，包括随机选择和梯度近似",
            "在线计算": "允许算法在数据流中实时更新参数，提高学习效率"
        },
        "success": true
    },
    {
        "order": 520,
        "title": "Learning Causal Models from Conditional Moment Restrictions by Importance Weighting",
        "html": "https://iclr.cc//virtual/2022/poster/6841",
        "abstract": "We consider learning causal relationships under conditional moment restrictions. Unlike causal inference under unconditional moment restrictions, conditional moment restrictions pose serious challenges for causal inference. To address this issue, we propose a method that transforms conditional moment restrictions to unconditional moment restrictions through importance weighting using a conditional density ratio estimator. Then, using this transformation, we propose a method that successfully estimate a parametric or nonparametric functions defined under the conditional moment restrictions. We analyze the estimation error and provide a bound on the structural function, providing theoretical support for our proposed method. In experiments, we confirm the soundness of our proposed method.",
        "conference": "ICLR",
        "中文标题": "通过重要性加权从条件矩限制中学习因果模型",
        "摘要翻译": "我们考虑在条件矩限制下学习因果关系。与无条件矩限制下的因果推断不同，条件矩限制对因果推断提出了严峻挑战。为了解决这一问题，我们提出了一种方法，通过使用条件密度比估计器的重要性加权，将条件矩限制转换为无条件矩限制。然后，利用这一转换，我们提出了一种方法，能够成功估计在条件矩限制下定义的参数或非参数函数。我们分析了估计误差，并提供了结构函数的界限，为我们提出的方法提供了理论支持。在实验中，我们证实了我们提出方法的合理性。",
        "领域": "因果推断、机器学习、统计学习",
        "问题": "在条件矩限制下进行因果推断的挑战",
        "动机": "解决条件矩限制对因果推断带来的挑战，提供一种有效的估计方法",
        "方法": "通过重要性加权将条件矩限制转换为无条件矩限制，并利用转换后的限制进行参数或非参数函数的估计",
        "关键词": [
            "因果推断",
            "条件矩限制",
            "重要性加权",
            "密度比估计",
            "结构函数"
        ],
        "涉及的技术概念": {
            "条件矩限制": "在因果推断中，用于描述变量间关系的数学限制条件",
            "重要性加权": "一种通过权重调整来转换或平衡数据分布的技术",
            "密度比估计": "估计两种概率密度函数比率的技术，用于重要性加权中的权重计算"
        },
        "success": true
    },
    {
        "order": 521,
        "title": "Learning Continuous Environment Fields via Implicit Functions",
        "html": "https://iclr.cc//virtual/2022/poster/6783",
        "abstract": "   We propose a novel scene representation that encodes reaching distance -- the distance between any position in the scene to a goal along a feasible trajectory. We demonstrate that this environment field representation can directly guide the dynamic behaviors of agents in 2D mazes or 3D indoor scenes. Our environment field is a continuous representation and learned via a neural implicit function using discretely sampled training data. We showcase its application for agent navigation in 2D mazes, and human trajectory prediction in 3D indoor environments. To produce physically plausible and natural trajectories for humans, we additionally learn a generative model that predicts regions where humans commonly appear, and enforce the environment field to be defined within such regions. Extensive experiments demonstrate that the proposed method can generate both feasible and plausible trajectories efficiently and accurately.",
        "conference": "ICLR",
        "中文标题": "通过隐函数学习连续环境场",
        "摘要翻译": "我们提出了一种新颖的场景表示方法，该方法编码了到达距离——场景中任意位置到目标沿可行轨迹的距离。我们证明了这种环境场表示可以直接指导代理在2D迷宫或3D室内场景中的动态行为。我们的环境场是一种连续表示，并通过使用离散采样训练数据的神经隐函数学习。我们展示了其在2D迷宫中的代理导航和3D室内环境中的人类轨迹预测的应用。为了为人类生成物理上合理且自然的轨迹，我们还学习了一个生成模型，预测人类常出现的区域，并强制环境场在这些区域内定义。大量实验证明，所提出的方法可以高效且准确地生成既可行又合理的轨迹。",
        "领域": "场景理解, 轨迹预测, 代理导航",
        "问题": "如何在复杂环境中高效准确地表示和预测可行轨迹",
        "动机": "为了在动态环境中为代理或人类生成可行且自然的轨迹",
        "方法": "使用神经隐函数学习连续环境场表示，并结合生成模型预测人类常出现的区域",
        "关键词": [
            "环境场",
            "隐函数",
            "轨迹预测",
            "代理导航",
            "生成模型"
        ],
        "涉及的技术概念": {
            "神经隐函数": "用于学习场景的连续表示，能够从离散采样数据中恢复连续环境场",
            "生成模型": "预测人类常出现的区域，确保环境场在这些区域内定义，以生成自然轨迹",
            "到达距离": "场景中任意位置到目标沿可行轨迹的距离，是环境场表示的核心"
        },
        "success": true
    },
    {
        "order": 522,
        "title": "Learning curves for continual learning in neural networks: Self-knowledge transfer and forgetting",
        "html": "https://iclr.cc//virtual/2022/poster/6690",
        "abstract": "Sequential training from task to task is becoming one of the major objects in deep learning applications such as continual learning and transfer learning. Nevertheless, it remains unclear under what conditions the trained model's performance improves or deteriorates. To deepen our understanding of sequential training, this study provides a theoretical analysis of generalization performance in a solvable case of continual learning.  We consider neural networks in the neural tangent kernel (NTK) regime that continually learn target functions from task to task, and investigate the generalization by using an established statistical mechanical analysis of kernel ridge-less regression. We first show characteristic transitions from positive to negative transfer. More similar targets above a specific critical value can achieve positive knowledge transfer for the subsequent task while catastrophic forgetting occurs even with very similar targets. Next, we investigate a variant of continual learning which supposes the same target function in multiple tasks. Even for the same target,  the trained model shows some transfer and forgetting depending on the sample size of each task.  We can guarantee that the generalization error monotonically decreases from task to task for equal sample sizes while unbalanced sample sizes  deteriorate the generalization. We respectively refer to these improvement and deterioration as self-knowledge transfer and forgetting, and empirically confirm them in realistic training of deep neural networks as well. ",
        "conference": "ICLR",
        "中文标题": "神经网络持续学习中的学习曲线：自我知识转移与遗忘",
        "摘要翻译": "从任务到任务的顺序训练正成为深度学习应用中的主要对象之一，如持续学习和迁移学习。然而，在什么条件下训练模型的性能会提高或恶化仍不明确。为了加深对顺序训练的理解，本研究提供了一个在持续学习可解案例中泛化性能的理论分析。我们考虑了在神经切线核（NTK）机制下从任务到任务持续学习目标函数的神经网络，并通过使用已建立的核无岭回归的统计力学分析来研究泛化。我们首先展示了从正转移到负转移的特征转变。超过特定临界值的更相似目标可以为后续任务实现正知识转移，而即使目标非常相似也会发生灾难性遗忘。接下来，我们研究了一种持续学习的变体，该变体假设在多个任务中有相同的目标函数。即使对于相同的目标，训练模型也会根据每个任务的样本大小显示出一定的转移和遗忘。我们可以保证，对于相等的样本大小，泛化误差从任务到任务单调减少，而不平衡的样本大小会恶化泛化。我们分别将这些改进和恶化称为自我知识转移和遗忘，并在深度神经网络的现实训练中也经验性地证实了它们。",
        "领域": "持续学习, 迁移学习, 神经网络理论",
        "问题": "理解在持续学习过程中，神经网络模型的性能如何随任务顺序训练而变化，以及什么条件下会发生知识转移或遗忘。",
        "动机": "为了揭示顺序训练中模型性能变化的机制，特别是在持续学习和迁移学习背景下，理解知识转移和遗忘的条件和原因。",
        "方法": "通过理论分析，在神经切线核（NTK）机制下研究神经网络持续学习目标函数的泛化性能，使用核无岭回归的统计力学分析方法。",
        "关键词": [
            "持续学习",
            "神经切线核",
            "知识转移",
            "遗忘",
            "泛化性能"
        ],
        "涉及的技术概念": {
            "神经切线核（NTK）": "用于分析神经网络在训练初期动态的理论框架，本研究中使用NTK机制来研究持续学习中的泛化性能。",
            "核无岭回归": "一种统计力学分析方法，用于研究在持续学习任务中神经网络的泛化行为。",
            "灾难性遗忘": "指神经网络在学习新任务时，对先前学习任务知识的快速丢失现象，本研究探讨了其发生的条件。"
        },
        "success": true
    },
    {
        "order": 523,
        "title": "Learning Curves for Gaussian Process Regression with Power-Law Priors and Targets",
        "html": "https://iclr.cc//virtual/2022/poster/6668",
        "abstract": "We characterize the power-law asymptotics of learning curves for Gaussian process regression (GPR) under the assumption that the eigenspectrum of the prior and the eigenexpansion coefficients of the target function follow a power law. Under similar assumptions, we leverage the equivalence between GPR and kernel ridge regression (KRR) to show the generalization error of KRR. Infinitely wide neural networks can be related to GPR with respect to the neural network GP kernel and the neural tangent kernel, which in several cases is known to have a power-law spectrum. Hence our methods can be applied to study the generalization error of infinitely wide neural networks. We present toy experiments demonstrating the theory.",
        "conference": "ICLR",
        "中文标题": "具有幂律先验和目标的高斯过程回归学习曲线研究",
        "摘要翻译": "我们刻画了高斯过程回归（GPR）在学习曲线下的幂律渐近性质，假设先验的特征谱和目标函数的特征展开系数遵循幂律。在类似假设下，我们利用GPR与核岭回归（KRR）之间的等价性来展示KRR的泛化误差。无限宽神经网络可以与GPR相关联，涉及神经网络GP核和神经切线核，在几种情况下已知具有幂律谱。因此，我们的方法可以应用于研究无限宽神经网络的泛化误差。我们展示了验证理论的玩具实验。",
        "领域": "高斯过程回归, 核岭回归, 无限宽神经网络",
        "问题": "研究高斯过程回归和核岭回归在幂律先验和目标函数下的学习曲线及其泛化误差",
        "动机": "探索无限宽神经网络的泛化误差，通过高斯过程回归和核岭回归的理论框架",
        "方法": "利用高斯过程回归与核岭回归的等价性，分析在幂律假设下的学习曲线和泛化误差",
        "关键词": [
            "高斯过程回归",
            "核岭回归",
            "无限宽神经网络",
            "泛化误差",
            "幂律谱"
        ],
        "涉及的技术概念": {
            "高斯过程回归": "一种非参数的贝叶斯方法，用于回归分析，假设数据服从高斯过程",
            "核岭回归": "一种正则化的线性回归方法，通过核技巧处理非线性问题",
            "神经切线核": "描述无限宽神经网络训练动态的核函数，用于分析神经网络的泛化性能"
        },
        "success": true
    },
    {
        "order": 524,
        "title": "Learning Curves for SGD on Structured Features",
        "html": "https://iclr.cc//virtual/2022/poster/6344",
        "abstract": "The generalization performance of a machine learning algorithm such as a neural network depends in a non-trivial way on the structure of the data distribution. To analyze the influence of data structure on test loss dynamics, we study an exactly solveable model of stochastic gradient descent (SGD) on the square loss which predicts test error when training on features with arbitrary covariance structure. We solve the theory exactly for both Gaussian features and arbitrary features and we show that the simpler Gaussian model accurately predicts test loss of nonlinear random-feature models and neural networks in the kernel regime trained with SGD on real datasets such as MNIST and CIFAR-10. We show that the optimal batch size at a fixed compute budget is typically small and depends on the feature correlation structure, demonstrating the computational benefits of SGD with small batch sizes. Lastly, we extend our theory to the more usual setting of stochastic gradient descent on a fixed subsampled training set, showing that both training and test error can be accurately predicted in our framework on real data.",
        "conference": "ICLR",
        "中文标题": "结构化特征上随机梯度下降的学习曲线",
        "摘要翻译": "机器学习算法（如神经网络）的泛化性能以一种非平凡的方式依赖于数据分布的结构。为了分析数据结构对测试损失动态的影响，我们研究了一个可精确求解的随机梯度下降（SGD）模型，该模型在平方损失上预测当训练具有任意协方差结构的特征时的测试误差。我们精确求解了高斯特征和任意特征的理论，并展示了更简单的高斯模型准确预测了在真实数据集（如MNIST和CIFAR-10）上使用SGD训练的非线性随机特征模型和核机制下神经网络的测试损失。我们表明，在固定的计算预算下，最优批次大小通常较小，并且依赖于特征的相关结构，这证明了使用小批次SGD的计算优势。最后，我们将我们的理论扩展到更常见的固定子采样训练集上的随机梯度下降设置，展示了在我们的框架下可以准确预测真实数据上的训练和测试误差。",
        "领域": "深度学习优化",
        "问题": "分析数据结构对随机梯度下降（SGD）算法泛化性能的影响",
        "动机": "理解数据结构的特性如何影响机器学习模型的泛化能力，以及如何优化SGD的批次大小以提高计算效率",
        "方法": "通过构建一个可精确求解的SGD模型，分析高斯和任意特征下的测试误差，并将理论应用于真实数据集",
        "关键词": [
            "随机梯度下降",
            "泛化性能",
            "特征结构",
            "批次大小优化",
            "核机制"
        ],
        "涉及的技术概念": {
            "随机梯度下降（SGD）": "一种优化算法，用于在机器学习中最小化损失函数，特别适用于大规模数据集",
            "泛化性能": "模型在未见数据上的表现能力，是衡量机器学习算法好坏的重要指标",
            "核机制": "一种将数据映射到高维空间的技术，使得在高维空间中线性不可分的问题变得可分"
        },
        "success": true
    },
    {
        "order": 525,
        "title": "Learning Discrete Structured Variational Auto-Encoder using Natural Evolution Strategies",
        "html": "https://iclr.cc//virtual/2022/poster/5972",
        "abstract": "Discrete variational auto-encoders (VAEs) are able to represent semantic latent spaces in generative learning. In many real-life settings, the discrete latent space consists of high-dimensional structures, and propagating gradients through the relevant structures often requires enumerating over an exponentially large latent space. Recently, various approaches were devised to propagate approximated gradients without enumerating over the space of possible structures. In this work, we use Natural Evolution Strategies (NES), a class of gradient-free black-box optimization algorithms, to learn discrete structured VAEs. The NES algorithms are computationally appealing as they estimate gradients with forward pass evaluations only, thus they do not require to propagate gradients through their discrete structures. We demonstrate empirically that optimizing discrete structured VAEs using NES is as effective as gradient-based approximations. Lastly, we prove NES converges for non-Lipschitz functions as appear in discrete structured VAEs.",
        "conference": "ICLR",
        "中文标题": "使用自然进化策略学习离散结构化变分自编码器",
        "摘要翻译": "离散变分自编码器（VAEs）能够在生成学习中表示语义潜在空间。在许多现实生活场景中，离散潜在空间由高维结构组成，而通过相关结构传播梯度通常需要枚举指数级大的潜在空间。最近，设计了各种方法来传播近似梯度而无需枚举可能的结构空间。在这项工作中，我们使用自然进化策略（NES），一类无梯度黑盒优化算法，来学习离散结构化VAEs。NES算法在计算上具有吸引力，因为它们仅通过前向传播评估来估计梯度，因此不需要通过其离散结构传播梯度。我们通过实证表明，使用NES优化离散结构化VAEs与基于梯度的近似方法同样有效。最后，我们证明了NES对于离散结构化VAEs中出现的非Lipschitz函数是收敛的。",
        "领域": "生成模型、优化算法、深度学习",
        "问题": "如何在离散结构化变分自编码器中高效传播梯度",
        "动机": "解决在离散高维潜在空间中传播梯度时计算成本高的问题",
        "方法": "采用自然进化策略（NES）作为无梯度优化方法，避免直接通过离散结构传播梯度",
        "关键词": [
            "离散变分自编码器",
            "自然进化策略",
            "无梯度优化",
            "生成学习",
            "高维结构"
        ],
        "涉及的技术概念": {
            "离散变分自编码器（VAEs）": "用于在生成学习中表示语义潜在空间的模型",
            "自然进化策略（NES）": "一类无梯度黑盒优化算法，用于估计梯度而无需通过离散结构传播",
            "非Lipschitz函数": "在离散结构化VAEs中出现的一类函数，NES被证明对此类函数收敛"
        },
        "success": true
    },
    {
        "order": 526,
        "title": "Learning Disentangled Representation by Exploiting Pretrained Generative Models:  A Contrastive Learning View",
        "html": "https://iclr.cc//virtual/2022/poster/5952",
        "abstract": "From the intuitive notion of disentanglement, the image variations corresponding to different generative factors should be distinct from each other, and the disentangled representation should reflect those variations with separate dimensions. To discover the generative factors and learn disentangled representation, previous methods typically leverage an extra regularization term when learning to generate realistic images. However, the term usually results in a trade-off between disentanglement and generation quality. For the generative models pretrained without any disentanglement term, the generated images show semantically meaningful variations when traversing along different directions in the latent space. Based on this observation, we argue that it is possible to mitigate the trade-off by (i) leveraging the pretrained generative models with high generation quality, (ii) focusing on discovering the traversal directions as generative factors for disentangled representation learning. To achieve this, we propose Disentaglement via Contrast (DisCo) as a framework to model the variations based on the target disentangled representations, and contrast the variations to jointly discover disentangled directions and learn disentangled representations. DisCo achieves the state-of-the-art disentangled representation learning and distinct direction discovering, given pretrained non-disentangled generative models including GAN, VAE, and Flow. Source code is at https://github.com/xrenaa/DisCo.",
        "conference": "ICLR",
        "中文标题": "利用预训练生成模型学习解耦表示：对比学习的视角",
        "摘要翻译": "从解耦的直观概念出发，对应于不同生成因素的图像变化应该彼此不同，解耦表示应该通过不同的维度反映这些变化。为了发现生成因素并学习解耦表示，先前的方法通常在生成真实图像的学习过程中利用额外的正则化项。然而，这一项通常会导致解耦和生成质量之间的权衡。对于那些没有任何解耦项预训练的生成模型，当沿着潜在空间中的不同方向遍历时，生成的图像显示出语义上有意义的变化。基于这一观察，我们认为通过（i）利用具有高生成质量的预训练生成模型，（ii）专注于发现遍历方向作为解耦表示学习的生成因素，可以缓解这种权衡。为了实现这一点，我们提出了通过对比解耦（DisCo）作为一个框架，基于目标解耦表示来建模变化，并对比这些变化以共同发现解耦方向和学习解耦表示。DisCo在给定包括GAN、VAE和Flow在内的预训练非解耦生成模型的情况下，实现了最先进的解耦表示学习和独特方向发现。源代码位于https://github.com/xrenaa/DisCo。",
        "领域": "生成对抗网络、变分自编码器、流模型",
        "问题": "如何在保持高生成质量的同时，学习解耦表示并发现生成因素",
        "动机": "缓解解耦表示学习与生成质量之间的权衡，利用预训练生成模型的高质量生成能力",
        "方法": "提出DisCo框架，通过对比学习建模变化，共同发现解耦方向和学习解耦表示",
        "关键词": [
            "解耦表示学习",
            "对比学习",
            "生成模型",
            "潜在空间遍历",
            "生成因素发现"
        ],
        "涉及的技术概念": {
            "解耦表示": "通过不同的维度反映图像变化，对应于不同的生成因素",
            "对比学习": "通过对比不同方向上的变化，共同发现解耦方向和学习解耦表示",
            "潜在空间遍历": "在生成模型的潜在空间中沿着不同方向移动，以发现语义上有意义的图像变化"
        },
        "success": true
    },
    {
        "order": 527,
        "title": "Learning Distributionally Robust Models at Scale via Composite Optimization",
        "html": "https://iclr.cc//virtual/2022/poster/6784",
        "abstract": "To train machine learning models that are robust to distribution shifts in the data, distributionally robust optimization (DRO) has been proven very effective. However, the existing approaches to learning a distributionally robust model either require solving complex optimization problems such as semidefinite programming or a first-order method whose convergence scales linearly with the number of data samples-- which hinders their scalability to large datasets.  In this paper, we show how different variants of DRO are simply instances of a finite-sum composite optimization for which we provide scalable methods.  We also provide empirical results that demonstrate the effectiveness of our proposed algorithm with respect to the prior art in order to learn robust models from very large datasets. ",
        "conference": "ICLR",
        "中文标题": "通过复合优化大规模学习分布鲁棒模型",
        "摘要翻译": "为了训练对数据分布变化具有鲁棒性的机器学习模型，分布鲁棒优化（DRO）已被证明非常有效。然而，现有的学习分布鲁棒模型的方法要么需要解决复杂的优化问题，如半定规划，要么采用收敛速度与数据样本数量线性相关的一阶方法——这阻碍了它们在大数据集上的可扩展性。在本文中，我们展示了DRO的不同变体如何简单地成为有限和复合优化的实例，我们为此提供了可扩展的方法。我们还提供了实证结果，证明了我们提出的算法在从非常大的数据集中学习鲁棒模型方面相对于现有技术的有效性。",
        "领域": "机器学习优化、鲁棒学习、大规模数据处理",
        "问题": "解决在大规模数据集上高效学习分布鲁棒模型的问题",
        "动机": "现有的分布鲁棒优化方法在大数据集上的可扩展性不足，需要更高效的算法",
        "方法": "将分布鲁棒优化的不同变体视为有限和复合优化的实例，并提出可扩展的解决方法",
        "关键词": [
            "分布鲁棒优化",
            "复合优化",
            "大规模学习",
            "机器学习",
            "数据分布变化"
        ],
        "涉及的技术概念": {
            "分布鲁棒优化（DRO）": "一种优化方法，旨在提高模型对数据分布变化的鲁棒性",
            "有限和复合优化": "一种优化问题的形式，适用于大规模数据集的高效处理",
            "半定规划": "一种复杂的优化问题，传统DRO方法需要解决此类问题"
        },
        "success": true
    },
    {
        "order": 528,
        "title": "Learning Efficient Image Super-Resolution Networks via Structure-Regularized Pruning",
        "html": "https://iclr.cc//virtual/2022/poster/5963",
        "abstract": "Several image super-resolution (SR) networks have been proposed of late for efficient SR, achieving promising results. However, they are still not lightweight enough and neglect to be extended to larger networks. At the same time, model compression techniques, like neural architecture search and knowledge distillation, typically consume considerable computation resources. In contrast, network pruning is a cheap and effective model compression technique. However, it is hard to be applied to SR networks directly because filter pruning for residual blocks is well-known tricky. To address the above issues, we propose structure-regularized pruning (SRP), which imposes regularization on the pruned structure to ensure the locations of pruned filters are aligned across different layers. Specifically, for the layers connected by the same residual, we select the filters of the same indices as unimportant filters. To transfer the expressive power in the unimportant filters to the rest of the network, we employ $L_2$ regularization to drive the weights towards zero so that eventually, their absence will cause minimal performance degradation. We apply SRP to train efficient image SR networks, resulting in a lightweight network SRPN-Lite and a very deep one SRPN. We conduct extensive comparisons with both lightweight and larger networks. SRPN-Lite and SRPN perform favorably against other recent efficient SR approaches quantitatively and visually.",
        "conference": "ICLR",
        "中文标题": "通过结构正则化剪枝学习高效图像超分辨率网络",
        "摘要翻译": "最近，几种图像超分辨率（SR）网络被提出用于高效SR，取得了令人鼓舞的结果。然而，它们仍然不够轻量级，并且未能扩展到更大的网络。同时，模型压缩技术，如神经架构搜索和知识蒸馏，通常消耗大量的计算资源。相比之下，网络剪枝是一种廉价且有效的模型压缩技术。然而，由于残差块的滤波器剪枝众所周知地棘手，它很难直接应用于SR网络。为了解决上述问题，我们提出了结构正则化剪枝（SRP），它对剪枝结构施加正则化，以确保剪枝滤波器的位置在不同层之间对齐。具体来说，对于由相同残差连接的层，我们选择相同索引的滤波器作为不重要滤波器。为了将不重要滤波器中的表达能力转移到网络的其余部分，我们使用L2正则化驱动权重趋近于零，以便最终它们的缺失将导致最小的性能下降。我们应用SRP来训练高效的图像SR网络，产生了一个轻量级网络SRPN-Lite和一个非常深的网络SRPN。我们与轻量级和更大的网络进行了广泛的比较。SRPN-Lite和SRPN在定量和视觉上都优于其他最近的高效SR方法。",
        "领域": "图像超分辨率",
        "问题": "如何在不牺牲性能的情况下，进一步轻量化图像超分辨率网络并扩展到更大的网络",
        "动机": "现有的图像超分辨率网络不够轻量级，且难以扩展到更大的网络，同时模型压缩技术消耗大量计算资源",
        "方法": "提出结构正则化剪枝（SRP）方法，通过正则化剪枝结构和对齐剪枝滤波器的位置，以及使用L2正则化驱动不重要滤波器的权重趋近于零，来训练高效的图像超分辨率网络",
        "关键词": [
            "图像超分辨率",
            "网络剪枝",
            "结构正则化",
            "轻量级网络",
            "模型压缩"
        ],
        "涉及的技术概念": {
            "结构正则化剪枝（SRP）": "一种对剪枝结构施加正则化以确保剪枝滤波器位置在不同层间对齐的技术，用于高效训练图像超分辨率网络",
            "L2正则化": "用于驱动不重要滤波器的权重趋近于零，以减少剪枝对网络性能的影响",
            "残差块": "网络中的基本构建块，剪枝其滤波器是技术上的挑战，SRP方法特别针对这一问题进行了优化"
        },
        "success": true
    },
    {
        "order": 529,
        "title": "Learning Efficient Online 3D Bin Packing on Packing Configuration Trees",
        "html": "https://iclr.cc//virtual/2022/poster/6490",
        "abstract": "Online 3D Bin Packing Problem (3D-BPP) has widespread applications in industrial automation and has aroused enthusiastic research interest recently. Existing methods usually solve the problem with limited resolution of spatial discretization, and/or cannot deal with complex practical constraints well. We propose to enhance the practical applicability of online 3D-BPP via learning on a novel hierarchical representation – packing configuration tree (PCT). PCT is a full-fledged description of the state and action space of bin packing which can support packing policy learning based on deep reinforcement learning (DRL). The size of the packing action space is proportional to the number of leaf nodes, making the DRL model easy to train and well-performing even with continuous solution space. During training, PCT expands based on heuristic rules, however, the DRL model learns a much more effective and robust packing policy than heuristic methods. Through extensive evaluation, we demonstrate that our method outperforms all existing online BPP methods and is versatile in terms of incorporating various practical constraints.",
        "conference": "ICLR",
        "中文标题": "学习在装箱配置树上进行高效的在线三维装箱",
        "摘要翻译": "在线三维装箱问题（3D-BPP）在工业自动化中有着广泛的应用，并且最近激起了热烈的研究兴趣。现有方法通常以有限的空间离散化分辨率解决该问题，和/或不能很好地处理复杂的实际约束。我们提出通过学习一种新颖的层次表示——装箱配置树（PCT）来增强在线3D-BPP的实际适用性。PCT是对装箱状态和动作空间的完整描述，可以支持基于深度强化学习（DRL）的装箱策略学习。装箱动作空间的大小与叶节点的数量成正比，使得DRL模型即使在连续解空间中也易于训练且表现良好。在训练过程中，PCT基于启发式规则扩展，然而，DRL模型学习到的装箱策略比启发式方法更有效且更稳健。通过广泛的评估，我们证明了我们的方法优于所有现有的在线BPP方法，并且在整合各种实际约束方面具有多功能性。",
        "领域": "工业自动化、深度强化学习、三维装箱",
        "问题": "解决在线三维装箱问题中空间离散化分辨率有限和复杂实际约束处理不佳的问题",
        "动机": "增强在线3D-BPP的实际适用性，通过学习一种新颖的层次表示——装箱配置树（PCT）来改进现有方法",
        "方法": "提出使用装箱配置树（PCT）作为状态和动作空间的完整描述，基于深度强化学习（DRL）进行装箱策略学习",
        "关键词": [
            "在线三维装箱",
            "装箱配置树",
            "深度强化学习",
            "工业自动化",
            "实际约束"
        ],
        "涉及的技术概念": {
            "装箱配置树（PCT）": "一种新颖的层次表示，用于完整描述装箱状态和动作空间，支持基于深度强化学习的装箱策略学习",
            "深度强化学习（DRL）": "用于学习装箱策略的技术，即使在连续解空间中也易于训练且表现良好",
            "启发式规则": "在训练过程中用于PCT扩展的规则，但DRL模型学习到的策略比启发式方法更有效且更稳健"
        },
        "success": true
    },
    {
        "order": 530,
        "title": "Learning Fast, Learning Slow: A General Continual Learning Method based on Complementary Learning System",
        "html": "https://iclr.cc//virtual/2022/poster/6559",
        "abstract": "Humans excel at continually learning from an ever-changing environment whereas it remains a challenge for deep neural networks which exhibit catastrophic forgetting. The complementary learning system (CLS) theory suggests that the interplay between rapid instance-based learning and slow structured learning in the brain is crucial for accumulating and retaining knowledge. Here, we propose CLS-ER, a novel dual memory experience replay (ER) method which maintains short-term and long-term semantic memories that interact with the episodic memory. Our method employs an effective replay mechanism whereby new knowledge is acquired while aligning the decision boundaries with the semantic memories. CLS-ER does not utilize the task boundaries or make any assumption about the distribution of the data which makes it versatile and suited for ``general continual learning''. Our approach achieves state-of-the-art performance on standard benchmarks as well as more realistic general continual learning settings.",
        "conference": "ICLR",
        "中文标题": "学习快，学习慢：基于互补学习系统的通用持续学习方法",
        "摘要翻译": "人类擅长从不断变化的环境中持续学习，而这对于表现出灾难性遗忘的深度神经网络来说仍然是一个挑战。互补学习系统（CLS）理论认为，大脑中基于实例的快速学习与结构化慢速学习之间的相互作用对于知识的积累和保留至关重要。在此，我们提出了CLS-ER，一种新颖的双重记忆经验回放（ER）方法，它维护了与情景记忆交互的短期和长期语义记忆。我们的方法采用了一种有效的回放机制，通过该机制在获取新知识的同时，将决策边界与语义记忆对齐。CLS-ER不利用任务边界或对数据的分布做出任何假设，这使其具有多功能性，适用于‘通用持续学习’。我们的方法在标准基准测试以及更现实的通用持续学习设置中实现了最先进的性能。",
        "领域": "持续学习、神经网络优化、记忆回放技术",
        "问题": "解决深度神经网络在持续学习过程中的灾难性遗忘问题",
        "动机": "受人类互补学习系统启发，探索如何在神经网络中实现知识的持续积累和保留",
        "方法": "提出CLS-ER方法，通过双重记忆经验回放机制，结合短期和长期语义记忆与情景记忆的交互，优化知识获取和决策边界对齐",
        "关键词": [
            "持续学习",
            "互补学习系统",
            "经验回放",
            "语义记忆",
            "灾难性遗忘"
        ],
        "涉及的技术概念": {
            "互补学习系统（CLS）": "理论框架，指导设计能够模拟人类学习快慢结合特性的神经网络",
            "双重记忆经验回放（ER）": "技术手段，通过维护和交互短期与长期记忆来优化学习过程",
            "灾难性遗忘": "问题描述，指神经网络在学习新知识时快速遗忘旧知识的现象"
        },
        "success": true
    },
    {
        "order": 531,
        "title": "Learning Fast Samplers for Diffusion Models by Differentiating Through Sample Quality",
        "html": "https://iclr.cc//virtual/2022/poster/6174",
        "abstract": "Diffusion models have emerged as an expressive family of generative models rivaling GANs in sample quality and autoregressive models in likelihood scores. Standard diffusion models typically require hundreds of forward passes through the model to generate a single high-fidelity sample. We introduce Differentiable Diffusion Sampler Search (DDSS): a method that optimizes fast samplers for any pre-trained diffusion model by differentiating through sample quality scores. We also present Generalized Gaussian Diffusion Models (GGDM), a family of flexible non-Markovian samplers for diffusion models. We show that optimizing the degrees of freedom of GGDM samplers by maximizing sample quality scores via gradient descent leads to improved sample quality. Our optimization procedure backpropagates through the sampling process using the reparametrization trick and gradient rematerialization. DDSS achieves strong results on unconditional image generation across various datasets (e.g., FID scores on LSUN church 128x128 of 11.6 with only 10 inference steps, and 4.82 with 20 steps, compared to 51.1 and 14.9 with strongest DDPM/DDIM baselines). Our method is compatible with any pre-trained diffusion model without fine-tuning or re-training required.",
        "conference": "ICLR",
        "中文标题": "通过学习样本质量微分快速采样器用于扩散模型",
        "摘要翻译": "扩散模型已成为一类表达能力强的生成模型，在样本质量上与GANs相媲美，在似然分数上与自回归模型相匹敌。标准的扩散模型通常需要数百次前向传递才能生成一个高保真样本。我们介绍了可微分扩散采样器搜索（DDSS）：一种通过样本质量分数的微分来优化任何预训练扩散模型的快速采样器的方法。我们还提出了广义高斯扩散模型（GGDM），一类灵活的非马尔可夫采样器用于扩散模型。我们展示了通过梯度下降最大化样本质量分数来优化GGDM采样器的自由度可以改善样本质量。我们的优化过程使用重参数化技巧和梯度重计算通过采样过程进行反向传播。DDSS在各种数据集上的无条件图像生成中取得了强劲的结果（例如，在LSUN教堂128x128上，仅用10次推理步骤就获得了11.6的FID分数，20步时为4.82，而最强的DDPM/DDIM基线分别为51.1和14.9）。我们的方法与任何预训练的扩散模型兼容，无需微调或重新训练。",
        "领域": "生成模型优化、图像生成、扩散模型",
        "问题": "如何减少扩散模型生成高保真样本所需的前向传递次数",
        "动机": "提高扩散模型生成样本的效率，减少计算资源消耗",
        "方法": "通过可微分扩散采样器搜索（DDSS）和广义高斯扩散模型（GGDM）优化采样过程，利用梯度下降最大化样本质量分数",
        "关键词": [
            "扩散模型",
            "快速采样",
            "样本质量",
            "梯度下降",
            "图像生成"
        ],
        "涉及的技术概念": {
            "可微分扩散采样器搜索（DDSS）": "一种通过样本质量分数的微分来优化任何预训练扩散模型的快速采样器的方法",
            "广义高斯扩散模型（GGDM）": "一类灵活的非马尔可夫采样器，用于扩散模型，通过优化自由度来改善样本质量",
            "重参数化技巧和梯度重计算": "在优化过程中使用，以通过采样过程进行有效的反向传播"
        },
        "success": true
    },
    {
        "order": 532,
        "title": "Learning Features with Parameter-Free Layers",
        "html": "https://iclr.cc//virtual/2022/poster/7139",
        "abstract": "Trainable layers such as convolutional building blocks are the standard network design choices by learning parameters to capture the global context through successive spatial operations. When designing an efficient network, trainable layers such as the depthwise convolution is the source of efficiency in the number of parameters and FLOPs, but there was little improvement to the model speed in practice. This paper argues that simple built-in parameter-free operations can be a favorable alternative to the efficient trainable layers replacing spatial operations in a network architecture. We aim to break the stereotype of organizing the spatial operations of building blocks into trainable layers. Extensive experimental analyses based on layer-level studies with fully-trained models and neural architecture searches are provided to investigate whether parameter-free operations such as the max-pool are functional. The studies eventually give us a simple yet effective idea for redesigning network architectures, where the parameter-free operations are heavily used as the main building block without sacrificing the model accuracy as much. Experimental results on the ImageNet dataset demonstrate that the network architectures with parameter-free operations could enjoy the advantages of further efficiency in terms of model speed, the number of the parameters, and FLOPs. Code and ImageNet pretrained models are available at https://github.com/naver-ai/PfLayer.",
        "conference": "ICLR",
        "中文标题": "学习无参数层的特征",
        "摘要翻译": "可训练层，如卷积构建块，通过学习参数通过连续的空间操作捕捉全局上下文，是标准的网络设计选择。在设计高效网络时，可训练层如深度卷积在参数数量和FLOPs上是效率的来源，但在实践中对模型速度的改进甚微。本文认为，简单的内置无参数操作可以成为替代网络架构中空间操作的高效可训练层的有利选择。我们旨在打破将构建块的空间操作组织成可训练层的刻板印象。提供了基于层级别研究的广泛实验分析，包括完全训练的模型和神经架构搜索，以研究诸如最大池化等无参数操作是否功能有效。这些研究最终为我们提供了一个简单而有效的重新设计网络架构的想法，其中无参数操作被大量用作主要构建块，而不牺牲太多模型准确性。在ImageNet数据集上的实验结果表明，采用无参数操作的网络架构可以在模型速度、参数数量和FLOPs方面享受进一步效率的优势。代码和ImageNet预训练模型可在https://github.com/naver-ai/PfLayer获取。",
        "领域": "卷积神经网络优化、网络架构设计、高效深度学习",
        "问题": "如何在不牺牲模型准确性的前提下，通过使用无参数操作来提高网络架构的效率",
        "动机": "打破传统网络设计中依赖可训练层进行空间操作的刻板印象，探索无参数操作在网络架构中的潜力",
        "方法": "通过层级别研究和神经架构搜索，评估无参数操作（如最大池化）的有效性，并基于此重新设计网络架构",
        "关键词": [
            "无参数操作",
            "网络架构设计",
            "模型效率",
            "深度卷积",
            "ImageNet"
        ],
        "涉及的技术概念": {
            "无参数操作": "在网络架构中使用的无需学习参数的操作，如最大池化，用于提高模型效率",
            "神经架构搜索": "一种自动化网络设计的方法，用于探索和评估不同网络架构的性能",
            "深度卷积": "一种可训练层，通过减少参数数量和FLOPs来提高网络效率"
        },
        "success": true
    },
    {
        "order": 533,
        "title": "Learning Generalizable Representations for Reinforcement Learning via Adaptive Meta-learner of Behavioral Similarities",
        "html": "https://iclr.cc//virtual/2022/poster/6007",
        "abstract": "How to learn an effective reinforcement learning-based model for control tasks from high-level visual observations is a practical and challenging problem. A key to solving this problem is to learn low-dimensional state representations from observations, from which an effective policy can be learned. In order to boost the learning of state encoding, recent works are focused on capturing behavioral similarities between state representations or applying data augmentation on visual observations. In this paper, we propose a novel meta-learner-based framework for representation learning regarding behavioral similarities for reinforcement learning. Specifically, our framework encodes the high-dimensional observations into two decomposed embeddings regarding reward and dynamics in a Markov Decision Process (MDP). A pair of meta-learners are developed, one of which quantifies the reward similarity and the other quantifies dynamics similarity over the correspondingly decomposed embeddings. The meta-learners are self-learned to update the state embeddings by approximating two disjoint terms in on-policy bisimulation metric. To incorporate the reward and dynamics terms, we further develop a strategy to adaptively balance their impacts based on different tasks or environments. We empirically demonstrate that our proposed framework outperforms state-of-the-art baselines on several benchmarks, including conventional DM Control Suite, Distracting DM Control Suite and a self-driving task CARLA.",
        "conference": "ICLR",
        "中文标题": "通过行为相似性的自适应元学习器学习强化学习的可泛化表示",
        "摘要翻译": "如何从高级视觉观察中学习一个有效的基于强化学习的控制任务模型，这是一个实际且具有挑战性的问题。解决这个问题的关键在于从观察中学习低维状态表示，从而可以学习到一个有效的策略。为了促进状态编码的学习，最近的工作集中在捕捉状态表示之间的行为相似性或对视觉观察应用数据增强。在本文中，我们提出了一种新颖的基于元学习器的框架，用于针对强化学习的行为相似性进行表示学习。具体来说，我们的框架将高维观察编码为关于马尔可夫决策过程（MDP）中奖励和动态的两个分解嵌入。开发了一对元学习器，其中一个量化奖励相似性，另一个量化相应分解嵌入上的动态相似性。元学习器通过近似策略上双模拟度量中的两个不相交项来自我学习更新状态嵌入。为了整合奖励和动态项，我们进一步开发了一种策略，根据不同任务或环境自适应地平衡它们的影响。我们通过实验证明，我们提出的框架在几个基准测试上优于最先进的基线，包括传统的DM控制套件、分散注意力的DM控制套件和自动驾驶任务CARLA。",
        "领域": "强化学习、自动驾驶、控制任务",
        "问题": "如何从高级视觉观察中学习有效的强化学习模型以解决控制任务",
        "动机": "为了解决从高维视觉观察中学习有效强化学习模型的挑战，特别是在捕捉状态表示之间的行为相似性和应用数据增强方面",
        "方法": "提出了一种基于元学习器的框架，通过分解嵌入奖励和动态，并开发一对元学习器来量化它们的相似性，进而自适应地平衡它们的影响",
        "关键词": [
            "强化学习",
            "元学习",
            "行为相似性",
            "自适应平衡",
            "自动驾驶"
        ],
        "涉及的技术概念": {
            "元学习器": "用于量化奖励和动态相似性，自我学习更新状态嵌入",
            "马尔可夫决策过程（MDP）": "框架中用于分解奖励和动态的理论基础",
            "策略上双模拟度量": "元学习器通过近似此度量中的两个不相交项来更新状态嵌入"
        },
        "success": true
    },
    {
        "order": 534,
        "title": "Learning Graphon Mean Field Games and Approximate Nash Equilibria",
        "html": "https://iclr.cc//virtual/2022/poster/7112",
        "abstract": "Recent advances at the intersection of dense large graph limits and mean field games have begun to enable the scalable analysis of a broad class of dynamical sequential games with large numbers of agents. So far, results have been largely limited to graphon mean field systems with continuous-time diffusive or jump dynamics, typically without control and with little focus on computational methods. We propose a novel discrete-time formulation for graphon mean field games as the limit of non-linear dense graph Markov games with weak interaction. On the theoretical side, we give extensive and rigorous existence and approximation properties of the graphon mean field solution in sufficiently large systems. On the practical side we provide general learning schemes for graphon mean field equilibria by either introducing agent equivalence classes or reformulating the graphon mean field system as a classical mean field system. By repeatedly finding a regularized optimal control solution and its generated mean field, we successfully obtain plausible approximate Nash equilibria in otherwise infeasible large dense graph games with many agents. Empirically, we are able to demonstrate on a number of examples that the finite-agent behavior comes increasingly close to the mean field behavior for our computed equilibria as the graph or system size grows, verifying our theory. More generally, we successfully apply policy gradient reinforcement learning in conjunction with sequential Monte Carlo methods.",
        "conference": "ICLR",
        "中文标题": "学习图平均场博弈与近似纳什均衡",
        "摘要翻译": "最近在密集大图极限与平均场博弈交叉领域的研究进展，开始使得对一类具有大量代理的动态序贯博弈的可扩展分析成为可能。迄今为止，结果主要局限于具有连续时间扩散或跳跃动态的图平均场系统，通常没有控制且很少关注计算方法。我们提出了一种新颖的离散时间图平均场博弈公式，作为具有弱相互作用的非线性密集图马尔可夫博弈的极限。在理论方面，我们给出了在足够大的系统中图平均场解的广泛且严格的存在性和近似性质。在实际方面，我们通过引入代理等价类或将图平均场系统重新表述为经典平均场系统，提供了图平均场均衡的一般学习方案。通过重复寻找正则化最优控制解及其生成的平均场，我们成功地在其他不可行的大型密集图博弈中获得了合理的近似纳什均衡，这些博弈涉及许多代理。经验上，我们能够在多个例子中证明，随着图或系统规模的增大，有限代理行为越来越接近我们计算的均衡的平均场行为，验证了我们的理论。更一般地，我们成功地应用了策略梯度强化学习与序贯蒙特卡罗方法的结合。",
        "领域": "博弈论、强化学习、大规模系统分析",
        "问题": "如何在具有大量代理的大型密集图博弈中有效地分析和计算近似纳什均衡",
        "动机": "为了解决在大型密集图博弈中分析和计算近似纳什均衡的挑战，特别是在缺乏有效计算方法的现有研究中",
        "方法": "提出了一种离散时间的图平均场博弈公式，结合理论分析和实际学习方案，包括代理等价类的引入和策略梯度强化学习与序贯蒙特卡罗方法的结合",
        "关键词": [
            "图平均场博弈",
            "近似纳什均衡",
            "强化学习",
            "大规模系统",
            "序贯蒙特卡罗"
        ],
        "涉及的技术概念": {
            "图平均场博弈": "用于分析和计算大型密集图博弈中代理行为的极限模型",
            "近似纳什均衡": "在大型博弈中寻找的近似解，反映了代理在均衡状态下的策略",
            "策略梯度强化学习": "用于优化代理策略的机器学习方法，特别适用于连续动作空间的问题"
        },
        "success": true
    },
    {
        "order": 535,
        "title": "LEARNING GUARANTEES FOR GRAPH CONVOLUTIONAL NETWORKS ON THE STOCHASTIC BLOCK MODEL",
        "html": "https://iclr.cc//virtual/2022/poster/7034",
        "abstract": "An abundance of neural network models and algorithms for diverse tasks on graphs have been developed in the past five years. However, very few provable guarantees have been available for the performance of graph neural network models. This state of affairs is in contrast with the steady progress on the theoretical underpinnings of traditional dense and convolutional neural networks. In this paper we present the first provable guarantees for one of the best-studied families of graph neural network models, Graph Convolutional Networks (GCNs), for semi- supervised community detection tasks. We show that with high probability over the initialization and training data, a GCN will efficiently learn to detect communities on graphs drawn from a stochastic block model. Our proof relies on a fine-grained analysis of the training dynamics in order to overcome the complexity of a non-convex optimization landscape with many poorly-performing local minima.",
        "conference": "ICLR",
        "中文标题": "随机块模型上图卷积网络的学习保证",
        "摘要翻译": "过去五年中，针对图上多样化任务的神经网络模型和算法层出不穷。然而，关于图神经网络模型性能的可证明保证却寥寥无几。这一现状与传统密集和卷积神经网络理论基础稳步进展形成鲜明对比。本文首次为图神经网络模型中最受研究的家族之一——图卷积网络（GCNs）在半监督社区检测任务上的表现提供了可证明的保证。我们证明，在初始化和训练数据的高概率下，GCN将有效学习检测来自随机块模型的图上的社区。我们的证明依赖于对训练动态的精细分析，以克服具有许多性能不佳局部最小值的非凸优化景观的复杂性。",
        "领域": "图神经网络、社区检测、半监督学习",
        "问题": "为图卷积网络在半监督社区检测任务上的表现提供可证明的保证",
        "动机": "填补图神经网络模型性能可证明保证的空白，与传统神经网络的理论进展形成对比",
        "方法": "通过对训练动态的精细分析，克服非凸优化景观的复杂性，证明GCN在随机块模型上的社区检测能力",
        "关键词": [
            "图卷积网络",
            "随机块模型",
            "社区检测",
            "半监督学习",
            "学习保证"
        ],
        "涉及的技术概念": {
            "图卷积网络": "用于处理图结构数据的神经网络模型，本文中用于半监督社区检测任务",
            "随机块模型": "一种生成具有社区结构的随机图的模型，本文中作为GCN性能分析的基础",
            "非凸优化景观": "描述优化问题中存在的多个局部最小值，本文中通过精细分析训练动态来克服其复杂性"
        },
        "success": true
    },
    {
        "order": 536,
        "title": "Learning Hierarchical Structures with Differentiable Nondeterministic Stacks",
        "html": "https://iclr.cc//virtual/2022/poster/6931",
        "abstract": "Learning hierarchical structures in sequential data -- from simple algorithmic patterns to natural language -- in a reliable, generalizable way remains a challenging problem for neural language models. Past work has shown that recurrent neural networks (RNNs) struggle to generalize on held-out algorithmic or syntactic patterns without supervision or some inductive bias. To remedy this, many papers have explored augmenting RNNs with various differentiable stacks, by analogy with finite automata and pushdown automata (PDAs). In this paper, we improve the performance of our recently proposed Nondeterministic Stack RNN (NS-RNN), which uses a differentiable data structure that simulates a nondeterministic PDA, with two important changes. First, the model now assigns unnormalized positive weights instead of probabilities to stack actions, and we provide an analysis of why this improves training. Second, the model can directly observe the state of the underlying PDA. Our model achieves lower cross-entropy than all previous stack RNNs on five context-free language modeling tasks (within 0.05 nats of the information-theoretic lower bound), including a task on which the NS-RNN previously failed to outperform a deterministic stack RNN baseline. Finally, we propose a restricted version of the NS-RNN that incrementally processes infinitely long sequences, and we present language modeling results on the Penn Treebank.",
        "conference": "ICLR",
        "中文标题": "学习具有可微分非确定性堆栈的层次结构",
        "摘要翻译": "从简单的算法模式到自然语言，以可靠、可推广的方式学习序列数据中的层次结构，对于神经语言模型来说仍然是一个具有挑战性的问题。过去的工作表明，循环神经网络（RNNs）在没有监督或某些归纳偏置的情况下，难以在保留的算法或句法模式上实现泛化。为了解决这个问题，许多论文通过类比有限自动机和下推自动机（PDAs），探索了用各种可微分堆栈增强RNNs的方法。在本文中，我们通过两个重要的改进，提升了我们最近提出的非确定性堆栈RNN（NS-RNN）的性能，该模型使用了一种模拟非确定性PDA的可微分数据结构。首先，模型现在为堆栈动作分配未归一化的正权重而非概率，我们分析了这为何能改善训练。其次，模型可以直接观察底层PDA的状态。我们的模型在五个上下文无关语言建模任务上实现了比所有先前堆栈RNN更低的交叉熵（接近信息论下界0.05纳特以内），包括一个NS-RNN先前未能超越确定性堆栈RNN基线的任务。最后，我们提出了一个限制版本的NS-RNN，它能够增量处理无限长序列，并在Penn Treebank上展示了语言建模的结果。",
        "领域": "自然语言处理与视觉结合, 序列建模, 语言模型",
        "问题": "神经语言模型在无监督或缺乏归纳偏置的情况下，难以可靠且泛化地学习序列数据中的层次结构。",
        "动机": "解决循环神经网络在泛化保留的算法或句法模式上的困难，通过改进非确定性堆栈RNN来提升性能。",
        "方法": "通过为堆栈动作分配未归一化的正权重和直接观察底层PDA的状态，改进非确定性堆栈RNN的性能。",
        "关键词": [
            "非确定性堆栈RNN",
            "上下文无关语言建模",
            "可微分数据结构"
        ],
        "涉及的技术概念": {
            "非确定性堆栈RNN": "一种使用可微分数据结构模拟非确定性下推自动机的循环神经网络，用于提升语言模型的性能。",
            "未归一化的正权重": "模型为堆栈动作分配的一种权重，替代了传统的概率分配，以改善训练过程。",
            "信息论下界": "在五个上下文无关语言建模任务中，模型实现的交叉熵接近理论上的最低可能值，表明其高效性。"
        },
        "success": true
    },
    {
        "order": 537,
        "title": "Learning Long-Term Reward Redistribution via Randomized Return Decomposition",
        "html": "https://iclr.cc//virtual/2022/poster/6587",
        "abstract": "Many practical applications of reinforcement learning require agents to learn from sparse and delayed rewards. It challenges the ability of agents to attribute their actions to future outcomes. In this paper, we consider the problem formulation of episodic reinforcement learning with trajectory feedback. It refers to an extreme delay of reward signals, in which the agent can only obtain one reward signal at the end of each trajectory. A popular paradigm for this problem setting is learning with a designed auxiliary dense reward function, namely proxy reward, instead of sparse environmental signals. Based on this framework, this paper proposes a novel reward redistribution algorithm, randomized return decomposition (RRD), to learn a proxy reward function for episodic reinforcement learning. We establish a surrogate problem by Monte-Carlo sampling that scales up least-squares-based reward redistribution to long-horizon problems. We analyze our surrogate loss function by connection with existing methods in the literature, which illustrates the algorithmic properties of our approach. In experiments, we extensively evaluate our proposed method on a variety of benchmark tasks with episodic rewards and demonstrate substantial improvement over baseline algorithms.",
        "conference": "ICLR",
        "中文标题": "通过随机回报分解学习长期奖励再分配",
        "摘要翻译": "强化学习的许多实际应用要求智能体从稀疏和延迟的奖励中学习。这挑战了智能体将其行为归因于未来结果的能力。在本文中，我们考虑了带有轨迹反馈的片段式强化学习的问题表述。它指的是奖励信号的极端延迟，其中智能体只能在每个轨迹结束时获得一个奖励信号。针对这一问题设定的流行范式是学习设计的辅助密集奖励函数，即代理奖励，而不是稀疏的环境信号。基于这一框架，本文提出了一种新颖的奖励再分配算法，随机回报分解（RRD），用于学习片段式强化学习的代理奖励函数。我们通过蒙特卡洛采样建立了一个替代问题，将基于最小二乘的奖励再分配扩展到长视野问题。我们通过与文献中现有方法的联系分析了我们的替代损失函数，这说明了我们方法的算法特性。在实验中，我们在多种带有片段奖励的基准任务上广泛评估了我们提出的方法，并展示了相对于基线算法的显著改进。",
        "领域": "强化学习、奖励设计、长期规划",
        "问题": "解决在稀疏和延迟奖励环境下，智能体难以将行为与未来结果关联的问题。",
        "动机": "研究动机是为了提高智能体在极端延迟奖励信号环境下的学习效率和性能。",
        "方法": "提出了一种名为随机回报分解（RRD）的新算法，通过蒙特卡洛采样建立替代问题，扩展基于最小二乘的奖励再分配方法至长视野问题。",
        "关键词": [
            "强化学习",
            "奖励再分配",
            "随机回报分解",
            "长期规划",
            "蒙特卡洛采样"
        ],
        "涉及的技术概念": {
            "随机回报分解（RRD）": "一种新颖的奖励再分配算法，用于学习片段式强化学习的代理奖励函数。",
            "蒙特卡洛采样": "用于建立替代问题，使基于最小二乘的奖励再分配方法能够应用于长视野问题。",
            "替代损失函数": "通过分析其与现有方法的联系，展示了所提方法的算法特性。"
        },
        "success": true
    },
    {
        "order": 538,
        "title": "Learning meta-features for AutoML",
        "html": "https://iclr.cc//virtual/2022/poster/6788",
        "abstract": "This paper tackles the AutoML problem, aimed to automatically select an ML algorithm and its hyper-parameter configuration most appropriate to the dataset at hand. The proposed approach, MetaBu, learns new meta-features via an Optimal Transport procedure, aligning the manually designed \\mf s with the space of distributions on the hyper-parameter configurations. MetaBu meta-features, learned once and for all, induce a topology on the set of datasets that is exploited to define a distribution of promising hyper-parameter configurations amenable to AutoML. Experiments on the OpenML CC-18 benchmark demonstrate that using MetaBu meta-features boosts the performance of state of the art AutoML systems, AutoSklearn (Feurer et al. 2015) and Probabilistic Matrix Factorization (Fusi et al. 2018). Furthermore, the inspection of MetaBu meta-features gives some hints into when an ML algorithm does well. Finally, the topology based on MetaBu meta-features enables to estimate the intrinsic dimensionality of the OpenML benchmark w.r.t. a given ML algorithm or pipeline.",
        "conference": "ICLR",
        "中文标题": "学习AutoML的元特征",
        "摘要翻译": "本文解决了AutoML问题，旨在自动选择最适合手头数据集的机器学习算法及其超参数配置。提出的方法MetaBu通过最优传输过程学习新的元特征，将手动设计的元特征与超参数配置的分布空间对齐。MetaBu元特征一经学习便可永久使用，它在数据集集合上诱导出一种拓扑结构，用于定义适合AutoML的有前景的超参数配置分布。在OpenML CC-18基准测试上的实验表明，使用MetaBu元特征提升了最先进的AutoML系统AutoSklearn（Feurer等人，2015年）和概率矩阵分解（Fusi等人，2018年）的性能。此外，对MetaBu元特征的检查提供了一些关于机器学习算法何时表现良好的线索。最后，基于MetaBu元特征的拓扑结构能够估计OpenML基准相对于给定机器学习算法或流程的内在维度。",
        "领域": "自动机器学习、超参数优化、机器学习算法选择",
        "问题": "自动选择最适合特定数据集的机器学习算法及其超参数配置",
        "动机": "提高AutoML系统的性能，通过元特征学习优化算法选择和超参数配置",
        "方法": "通过最优传输过程学习新的元特征，对齐手动设计的元特征与超参数配置的分布空间",
        "关键词": [
            "元特征学习",
            "最优传输",
            "AutoML",
            "超参数优化",
            "机器学习算法选择"
        ],
        "涉及的技术概念": {
            "最优传输": "用于对齐元特征与超参数配置分布空间的技术，以学习新的元特征",
            "元特征": "描述数据集特性的特征，用于指导机器学习算法和超参数的选择",
            "拓扑结构": "基于元特征在数据集集合上定义的结构，用于识别有前景的超参数配置"
        },
        "success": true
    },
    {
        "order": 539,
        "title": "Learning more skills through optimistic exploration",
        "html": "https://iclr.cc//virtual/2022/poster/6475",
        "abstract": "Unsupervised skill learning objectives (Eysenbach et al., 2019; Gregor et al., 2016) allow agents to learn rich repertoires of behavior in the absence of extrinsic rewards. They work by simultaneously training a policy to produce distinguishable latent-conditioned trajectories, and a discriminator to evaluate distinguishability by trying to infer latents from trajectories. The hope is for the agent to explore and master the environment by encouraging each skill (latent) to reliably reach different states. However, an inherent exploration problem lingers: when a novel state is actually encountered, the discriminator will necessarily not have seen enough training data to produce accurate and confident skill classifications, leading to low intrinsic reward for the agent and effective penalization of the sort of exploration needed to actually maximize the objective. To combat this inherent pessimism towards exploration, we derive an information gain auxiliary objective that involves training an ensemble of discriminators and rewarding the policy for their disagreement. Our objective directly estimates the epistemic uncertainty that comes from the discriminator not having seen enough training examples, thus providing an intrinsic reward more tailored to the true objective compared to pseudocount-based methods (Burda et al., 2019). We call this exploration bonus discriminator disagreement intrinsic reward, or DISDAIN. We demonstrate empirically that DISDAIN improves skill learning both in a tabular grid world (Four Rooms) and the 57 games of the Atari Suite (from pixels). Thus, we encourage researchers to treat pessimism with DISDAIN.",
        "conference": "ICLR",
        "中文标题": "通过乐观探索学习更多技能",
        "摘要翻译": "无监督技能学习目标（Eysenbach等人，2019；Gregor等人，2016）允许代理在缺乏外在奖励的情况下学习丰富的行为库。它们通过同时训练一个策略以产生可区分的潜在条件轨迹，以及一个鉴别器通过尝试从轨迹推断潜在来评估可区分性来工作。希望通过鼓励每种技能（潜在）可靠地达到不同状态，代理能够探索并掌握环境。然而，一个固有的探索问题仍然存在：当实际上遇到一个新状态时，鉴别器必然没有看到足够的训练数据来产生准确和自信的技能分类，导致代理的内在奖励低，并有效惩罚了实际最大化目标所需的探索类型。为了对抗这种对探索的固有悲观态度，我们推导了一个信息增益辅助目标，涉及训练一个鉴别器集合，并奖励策略因为它们的分歧。我们的目标直接估计了由于鉴别器没有看到足够的训练示例而产生的认知不确定性，从而提供了一个比基于伪计数的方法（Burda等人，2019）更符合真实目标的内在奖励。我们称这种探索奖励为鉴别器分歧内在奖励，或DISDAIN。我们通过实验证明，DISDAIN在表格网格世界（四室）和Atari套件的57个游戏（从像素）中都改进了技能学习。因此，我们鼓励研究人员用DISDAIN来对待悲观态度。",
        "领域": "强化学习、无监督学习、探索策略",
        "问题": "解决无监督技能学习中固有的探索问题，即在新状态下鉴别器因缺乏足够训练数据而无法准确分类技能，导致探索被惩罚的问题。",
        "动机": "通过开发一种新的内在奖励机制，鼓励代理在遇到新状态时进行探索，克服现有方法中对探索的悲观态度。",
        "方法": "提出了一种基于信息增益的辅助目标，通过训练一个鉴别器集合并利用它们的分歧作为内在奖励，直接估计由于缺乏训练数据而产生的认知不确定性。",
        "关键词": [
            "无监督技能学习",
            "探索策略",
            "内在奖励",
            "鉴别器分歧",
            "信息增益"
        ],
        "涉及的技术概念": {
            "无监督技能学习": "在缺乏外在奖励的情况下，通过训练策略和鉴别器来学习多样化的行为技能。",
            "鉴别器分歧": "通过训练多个鉴别器并利用它们之间的分岐作为内在奖励，鼓励探索新状态。",
            "信息增益": "用于估计由于缺乏训练数据而产生的认知不确定性，作为探索新状态的内在奖励。"
        },
        "success": true
    },
    {
        "order": 540,
        "title": "Learning Multimodal VAEs through Mutual Supervision",
        "html": "https://iclr.cc//virtual/2022/poster/6307",
        "abstract": "Multimodal VAEs seek to model the joint distribution over heterogeneous data (e.g.\\ vision, language), whilst also capturing a shared representation across such modalities. Prior work has typically combined information from the modalities by reconciling idiosyncratic representations directly in the recognition model through explicit products, mixtures, or other such factorisations. Here we introduce a novel alternative, the MEME, that avoids such explicit combinations by repurposing semi-supervised VAEs to combine information between modalities implicitly through mutual supervision. This formulation naturally allows learning from partially-observed data where some modalities can be entirely missing---something that most existing approaches either cannot handle, or do so to a limited extent. We demonstrate that MEME outperforms baselines on standard metrics across both partial and complete observation schemes on the MNIST-SVHN (image--image) and CUB (image--text) datasets. We also contrast the quality of the representations learnt by mutual supervision against standard approaches and observe interesting trends in its ability to capture relatedness between data.",
        "conference": "ICLR",
        "中文标题": "通过相互监督学习多模态VAE",
        "摘要翻译": "多模态VAE旨在模拟异构数据（如视觉、语言）的联合分布，同时捕捉跨模态的共享表示。先前的工作通常通过在识别模型中通过显式的乘积、混合或其他因子分解方式直接调和特异表示来结合来自各模态的信息。本文我们引入了一种新颖的替代方法——MEME，它通过重新利用半监督VAE，通过相互监督隐式地结合模态间的信息，避免了这种显式结合。这种表述自然地允许从部分观察到的数据中学习，其中某些模态可能完全缺失——这是大多数现有方法要么无法处理，要么处理能力有限的情况。我们证明，在MNIST-SVHN（图像-图像）和CUB（图像-文本）数据集上，MEME在部分和完全观察方案下的标准指标上均优于基线。我们还对比了通过相互监督学习的表示质量与标准方法，并观察了其在捕捉数据间相关性能力上的有趣趋势。",
        "领域": "多模态学习、表示学习、半监督学习",
        "问题": "如何在异构数据间建立共享表示并处理部分缺失的模态数据",
        "动机": "解决现有方法在处理多模态数据时显式结合模态信息的局限性，以及部分模态缺失情况下的学习问题",
        "方法": "提出MEME方法，利用半监督VAE通过相互监督隐式结合模态信息，支持部分缺失模态数据的学习",
        "关键词": [
            "多模态VAE",
            "相互监督",
            "半监督学习",
            "异构数据",
            "表示学习"
        ],
        "涉及的技术概念": {
            "多模态VAE": "用于模拟异构数据的联合分布并捕捉跨模态共享表示的变分自编码器",
            "相互监督": "通过半监督VAE隐式结合模态信息的方法，避免显式结合带来的限制",
            "半监督学习": "在部分模态缺失的情况下仍能有效学习的技术，支持不完全观测数据的学习"
        },
        "success": true
    },
    {
        "order": 541,
        "title": "Learning Neural Contextual Bandits through Perturbed Rewards",
        "html": "https://iclr.cc//virtual/2022/poster/6714",
        "abstract": "Thanks to the power of representation learning, neural contextual bandit algorithms demonstrate remarkable performance improvement against their classical counterparts. But because their exploration has to be performed in the entire neural network parameter space to obtain nearly optimal regret, the resulting computational cost is prohibitively high.  We propose to perturb the rewards when updating the neural network to eliminate the need of explicit exploration and the corresponding computational overhead. We prove that a $\\tilde{O}(\\tilde{d}\\sqrt{T})$ regret upper bound is still achievable under standard regularity conditions, where $T$ is the number of rounds of interactions and $\\tilde{d}$ is the effective dimension of a neural tangent kernel matrix. Extensive comparisons with several benchmark contextual bandit algorithms, including two recent neural contextual bandit models, demonstrate the effectiveness and computational efficiency of our proposed neural bandit algorithm.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "通过扰动奖励学习神经上下文Bandit算法",
        "摘要翻译": "得益于表征学习的能力，神经上下文bandit算法相较于传统的算法展现出显著的性能提升。但是，为了获得接近最优的遗憾值，它们的探索必须在整个神经网络参数空间中进行，这导致了极高的计算成本。我们提出在更新神经网络时扰动奖励，以消除显式探索的需要以及相应的计算开销。我们证明了在标准正则性条件下，仍然可以实现$\\tilde{O}(\\tilde{d}\\sqrt{T})$的遗憾值上界，其中$T$是交互轮数，$\\tilde{d}$是神经切线核矩阵的有效维度。与包括两个最新的神经上下文bandit模型在内的几个基准上下文bandit算法的大量比较表明，我们提出的神经bandit算法的有效性和计算效率。",
        "领域": "强化学习, 推荐系统, 神经Bandit",
        "问题": "如何在神经上下文bandit算法中降低探索带来的高计算成本，同时保持良好的性能。",
        "动机": "现有的神经上下文bandit算法需要在整个神经网络参数空间进行探索，导致计算成本过高，限制了其应用。",
        "方法": "通过扰动奖励来更新神经网络，从而消除显式探索的需求，并证明了该方法在标准正则性条件下仍能保证较好的遗憾值上界。",
        "关键词": [
            "神经上下文Bandit",
            "扰动奖励",
            "探索-利用",
            "强化学习",
            "推荐系统"
        ],
        "涉及的技术概念": {
            "神经上下文Bandit": "一种结合了神经网络和上下文bandit算法的强化学习方法，用于在具有上下文信息的情况下进行决策。",
            "扰动奖励": "通过在奖励信号中添加随机噪声来鼓励探索，避免模型陷入局部最优。"
        }
    },
    {
        "order": 542,
        "title": "Learning Object-Oriented Dynamics for Planning from Text",
        "html": "https://iclr.cc//virtual/2022/poster/7132",
        "abstract": "The advancement of dynamics models enables model-based planning in complex environments. Existing dynamics models commonly study image-based games with fully observable states. Generalizing these models to Text-Based Games (TBGs), which commonly describe the partially observable states with noisy text observations, is challenging. In this work, we propose an Object-Oriented Text Dynamics (OOTD) model that enables planning algorithms to solve decision-making problems in text domains. OOTD predicts a memory graph that dynamically remembers the history of object observations and filters object-irrelevant information.  To facilitate the robustness of dynamics, our OOTD model identifies the objects influenced by input actions and predicts the belief of object states with independently parameterized transition layers. We develop variational objectives under the object-supervised and self-supervised settings to model the stochasticity of predicted dynamics. Empirical results show OOTD-based planner significantly outperforms model-free baselines in terms of sample efficiency and running scores.",
        "conference": "ICLR",
        "中文标题": "从文本中学习面向对象的动态规划",
        "摘要翻译": "动态模型的进步使得在复杂环境中进行基于模型的规划成为可能。现有的动态模型通常研究具有完全可观察状态的基于图像的游戏。将这些模型推广到基于文本的游戏（TBGs）是具有挑战性的，因为基于文本的游戏通常用带有噪声的文本观察来描述部分可观察的状态。在这项工作中，我们提出了一个面向对象的文本动态（OOTD）模型，使规划算法能够解决文本领域的决策问题。OOTD预测一个记忆图，动态地记住对象观察的历史并过滤与对象无关的信息。为了提高动态的鲁棒性，我们的OOTD模型识别受输入动作影响的对象，并通过独立参数化的转换层预测对象状态的信念。我们在对象监督和自我监督设置下开发了变分目标，以建模预测动态的随机性。实证结果表明，基于OOTD的规划器在样本效率和运行分数方面显著优于无模型基线。",
        "领域": "自然语言处理与视觉结合、文本理解与推理、决策规划",
        "问题": "如何在部分可观察且带有噪声的文本环境中进行有效的决策规划",
        "动机": "解决现有动态模型难以推广到基于文本游戏的问题，提高在文本环境中的决策效率和准确性",
        "方法": "提出面向对象的文本动态（OOTD）模型，通过记忆图动态记录对象观察历史，独立参数化转换层预测对象状态，并开发变分目标建模动态随机性",
        "关键词": [
            "面向对象动态模型",
            "文本游戏",
            "决策规划",
            "变分目标",
            "记忆图"
        ],
        "涉及的技术概念": {
            "面向对象的文本动态（OOTD）模型": "用于在文本环境中进行决策规划的模型，通过记忆图动态记录对象观察历史并过滤无关信息",
            "独立参数化的转换层": "用于预测对象状态的信念，提高模型对输入动作影响的识别能力",
            "变分目标": "在对象监督和自我监督设置下开发，用于建模预测动态的随机性，提高模型的鲁棒性"
        },
        "success": true
    },
    {
        "order": 543,
        "title": "Learning Optimal Conformal Classifiers",
        "html": "https://iclr.cc//virtual/2022/poster/6836",
        "abstract": "Modern deep learning based classifiers show very high accuracy on test data but this does not provide sufficient guarantees for safe deployment, especially in high-stake AI applications such as medical diagnosis. Usually, predictions are obtained without a reliable uncertainty estimate or a formal guarantee. Conformal prediction (CP) addresses these issues by using the classifier's predictions, e.g., its probability estimates, to predict confidence sets containing the true class with a user-specified probability. However, using CP as a separate processing step after training prevents the underlying model from adapting to the prediction of confidence sets. Thus, this paper explores strategies to differentiate through CP during training with the goal of training model with the conformal wrapper end-to-end. In our approach, conformal training (ConfTr), we specifically ``simulate'' conformalization on mini-batches during training. Compared to standard training, ConfTr reduces the average confidence set size (inefficiency) of state-of-the-art CP methods applied after training. Moreover, it allows to ``shape'' the confidence sets predicted at test time, which is difficult for standard CP. On experiments with several datasets, we show ConfTr can influence how inefficiency is distributed across classes, or guide the composition of confidence sets in terms of the included classes, while retaining the guarantees offered by CP.",
        "conference": "ICLR",
        "中文标题": "学习最优的共形分类器",
        "摘要翻译": "现代基于深度学习的分类器在测试数据上显示出非常高的准确性，但这并不能为安全部署提供足够的保证，特别是在医疗诊断等高风险的AI应用中。通常，预测是在没有可靠的不确定性估计或正式保证的情况下获得的。共形预测（CP）通过使用分类器的预测（例如其概率估计）来预测包含真实类别的置信集，以用户指定的概率解决这些问题。然而，将CP作为训练后的单独处理步骤阻止了基础模型适应置信集的预测。因此，本文探索了在训练期间通过CP进行区分的策略，目的是端到端地训练带有共形包装器的模型。在我们的方法中，共形训练（ConfTr），我们特别在训练期间对小批量进行共形化“模拟”。与标准训练相比，ConfTr减少了训练后应用的最先进CP方法的平均置信集大小（低效率）。此外，它允许“塑造”测试时预测的置信集，这对于标准CP来说是困难的。在几个数据集的实验中，我们展示了ConfTr可以影响低效率如何在类别之间分布，或指导置信集的组成在包含的类别方面，同时保留CP提供的保证。",
        "领域": "深度学习安全、医疗AI、不确定性估计",
        "问题": "如何在深度学习分类器中集成共形预测以提供可靠的不确定性估计和正式保证",
        "动机": "提高深度学习分类器在高风险应用中的安全性和可靠性，通过集成共形预测来提供更准确的置信集预测",
        "方法": "提出共形训练（ConfTr）方法，在训练过程中模拟共形化，以实现端到端的模型训练和置信集预测的优化",
        "关键词": [
            "共形预测",
            "深度学习安全",
            "不确定性估计",
            "医疗AI",
            "端到端训练"
        ],
        "涉及的技术概念": {
            "共形预测（CP）": "一种提供预测置信集的方法，确保包含真实类别的概率达到用户指定的水平",
            "共形训练（ConfTr）": "在模型训练过程中集成共形预测，优化置信集的预测性能",
            "置信集": "预测时提供的一组可能类别，旨在以一定的概率包含真实类别"
        },
        "success": true
    },
    {
        "order": 544,
        "title": "Learning Prototype-oriented Set Representations for Meta-Learning ",
        "html": "https://iclr.cc//virtual/2022/poster/6720",
        "abstract": "Learning from set-structured data is a fundamental problem that has recently attracted increasing attention, where a series of summary networks are introduced to deal with the set input. In fact, many meta-learning problems can be treated as set-input tasks. Most existing summary networks aim to design different architectures for the input set in order to enforce permutation invariance. However, scant attention has been paid to the common cases where different sets in a meta distribution are closely related and share certain statistical properties. Viewing each set as a distribution over a set of global prototypes, this paper provides a novel prototype-oriented optimal transport (POT) framework to improve existing summary networks. To learn the distribution over the global prototypes, we minimize its regularized optimal transport distance to the set empirical distribution over data points, providing a natural unsupervised way to improve the summary network. Since our plug-and-play framework can be applied to many meta learning problems, we further instantiate it to the cases of few-shot classification and implicit meta generative modeling. Extensive experiments demonstrate that our framework significantly improves the existing summary networks on learning more powerful summary statistics from sets and can be successfully integrated into metric-based few-shot classification and generative modeling applications, providing a promising tool for addressing set-input and meta-learning problems.",
        "conference": "ICLR",
        "中文标题": "学习面向原型的集合表示以用于元学习",
        "摘要翻译": "从集合结构数据中学习是一个基本问题，最近引起了越来越多的关注，其中引入了一系列摘要网络来处理集合输入。实际上，许多元学习问题可以被视为集合输入任务。大多数现有的摘要网络旨在为输入集合设计不同的架构，以强制排列不变性。然而，对于元分布中不同集合密切相关并共享某些统计特性的常见情况，关注甚少。将每个集合视为一组全局原型的分布，本文提供了一个新颖的面向原型的最优传输（POT）框架来改进现有的摘要网络。为了学习全局原型的分布，我们最小化其与数据点集合经验分布的正则化最优传输距离，提供了一种自然的无监督方式来改进摘要网络。由于我们的即插即用框架可以应用于许多元学习问题，我们进一步将其实例化到少样本分类和隐式元生成建模的案例中。大量实验表明，我们的框架显著改进了现有的摘要网络，在从集合中学习更强大的摘要统计量方面，并且可以成功地集成到基于度量的少样本分类和生成建模应用中，为解决集合输入和元学习问题提供了一个有前途的工具。",
        "领域": "元学习",
        "问题": "如何从集合结构数据中学习更有效的摘要统计量",
        "动机": "改进现有的摘要网络，以更好地处理元分布中不同集合密切相关并共享统计特性的情况",
        "方法": "提出了一种面向原型的最优传输（POT）框架，通过最小化全局原型分布与数据点集合经验分布的正则化最优传输距离来改进摘要网络",
        "关键词": [
            "元学习",
            "集合表示",
            "最优传输",
            "少样本分类",
            "生成建模"
        ],
        "涉及的技术概念": {
            "面向原型的最优传输（POT）": "用于改进现有摘要网络的框架，通过最小化全局原型分布与数据点集合经验分布的正则化最优传输距离",
            "摘要网络": "处理集合输入的网络架构，旨在强制排列不变性",
            "少样本分类": "元学习的一个应用案例，旨在从少量样本中学习分类任务"
        },
        "success": true
    },
    {
        "order": 545,
        "title": "Learning Pruning-Friendly Networks via Frank-Wolfe: One-Shot, Any-Sparsity, And No Retraining",
        "html": "https://iclr.cc//virtual/2022/poster/6158",
        "abstract": "We present a novel framework to train a large deep neural network (DNN) for only $\\textit{once}$, which can then be pruned to $\\textit{any sparsity ratio}$ to preserve competitive accuracy $\\textit{without any re-training}$. Conventional methods often require (iterative) pruning followed by re-training, which not only incurs large overhead beyond the original DNN training but also can be sensitive to retraining hyperparameters. Our core idea is to re-cast the DNN training as an explicit $\\textit{pruning-aware}$ process: that is formulated with an auxiliary $K$-sparse polytope constraint, to encourage network weights to lie in a convex hull spanned by $K$-sparse vectors, potentially resulting in more sparse weight matrices. We then leverage a stochastic Frank-Wolfe (SFW) algorithm to solve this new constrained optimization, which naturally leads to sparse weight updates each time. We further note an overlooked fact that existing DNN initializations were derived to enhance SGD training (e.g., avoid gradient explosion or collapse), but was unaligned with the challenges of training with SFW. We hence also present the first learning-based initialization scheme specifically for boosting SFW-based DNN training. Experiments on CIFAR-10 and Tiny-ImageNet datasets demonstrate that our new framework named $\\textbf{SFW-pruning}$ consistently achieves the state-of-the-art performance on various benchmark DNNs over a wide range of pruning ratios. Moreover, SFW-pruning only needs to train once on the same model and dataset, for obtaining arbitrary ratios, while requiring neither iterative pruning nor retraining. All codes will be released to the public. ",
        "conference": "ICLR",
        "中文标题": "通过Frank-Wolfe学习剪枝友好型网络：一次性、任意稀疏度且无需重新训练",
        "摘要翻译": "我们提出了一种新颖的框架，用于仅训练一次大型深度神经网络（DNN），之后可以剪枝到任意稀疏度以保持竞争性准确度，而无需任何重新训练。传统方法通常需要（迭代）剪枝后进行重新训练，这不仅超出了原始DNN训练的大量开销，而且可能对重新训练的超参数敏感。我们的核心思想是将DNN训练重新定义为显式的剪枝感知过程：即通过一个辅助的K-稀疏多面体约束来制定，以鼓励网络权重位于由K-稀疏向量张成的凸包中，可能导致更稀疏的权重矩阵。然后，我们利用随机Frank-Wolfe（SFW）算法来解决这个新的约束优化问题，这自然导致每次权重更新都是稀疏的。我们进一步注意到一个被忽视的事实，即现有的DNN初始化是为了增强SGD训练（例如，避免梯度爆炸或消失）而设计的，但与使用SFW训练的挑战不一致。因此，我们还提出了第一个基于学习的初始化方案，专门用于促进基于SFW的DNN训练。在CIFAR-10和Tiny-ImageNet数据集上的实验表明，我们名为SFW-pruning的新框架在各种基准DNN上，在广泛的剪枝比例范围内，始终实现了最先进的性能。此外，SFW-pruning只需要在同一模型和数据集上训练一次，即可获得任意比例，既不需要迭代剪枝也不需要重新训练。所有代码将向公众发布。",
        "领域": "模型压缩、神经网络剪枝、深度学习优化",
        "问题": "如何在无需重新训练的情况下，训练一个可以剪枝到任意稀疏度的大型深度神经网络",
        "动机": "减少传统剪枝方法中迭代剪枝和重新训练带来的大量计算开销和超参数敏感性",
        "方法": "通过将DNN训练重新定义为剪枝感知过程，并利用随机Frank-Wolfe算法解决约束优化问题，以及开发专门用于SFW训练的初始化方案",
        "关键词": [
            "模型剪枝",
            "Frank-Wolfe算法",
            "稀疏优化",
            "深度学习",
            "神经网络训练"
        ],
        "涉及的技术概念": {
            "K-稀疏多面体约束": "用于鼓励网络权重位于由K-稀疏向量张成的凸包中，以实现更稀疏的权重矩阵",
            "随机Frank-Wolfe算法": "用于解决带有K-稀疏多面体约束的优化问题，自然导致稀疏权重更新",
            "基于学习的初始化方案": "专门设计用于促进基于SFW的DNN训练，解决了现有初始化方法与SFW训练挑战不一致的问题"
        },
        "success": true
    },
    {
        "order": 546,
        "title": "Learning Representation from Neural Fisher Kernel with Low-rank Approximation",
        "html": "https://iclr.cc//virtual/2022/poster/6511",
        "abstract": "In this paper, we study the representation of neural networks from the view of kernels. We first define the Neural Fisher Kernel (NFK), which is the Fisher Kernel applied to neural networks. We show that NFK can be computed for both supervised and unsupervised learning models, which can serve as a unified tool for representation extraction. Furthermore, we show that practical NFKs exhibit low-rank structures. We then propose an efficient algorithm that computes a low-rank approximation of NFK, which scales to large datasets and networks. We show that the low-rank approximation of NFKs derived from unsupervised generative models and supervised learning models gives rise to high-quality compact representations of data, achieving competitive results on a variety of machine learning tasks.",
        "conference": "ICLR",
        "中文标题": "基于低秩近似的神经费舍尔核学习表示",
        "摘要翻译": "在本文中，我们从核的角度研究了神经网络的表示。我们首先定义了神经费舍尔核（NFK），这是将费舍尔核应用于神经网络的结果。我们展示了NFK可以用于监督和非监督学习模型，作为一种统一的表示提取工具。此外，我们发现实际的NFK展现出低秩结构。接着，我们提出了一种高效算法，用于计算NFK的低秩近似，该算法能够扩展到大型数据集和网络。我们证明了来自非监督生成模型和监督学习模型的NFK的低秩近似能够产生高质量的数据紧凑表示，在多种机器学习任务上取得了竞争性的结果。",
        "领域": "表示学习, 核方法, 深度学习",
        "问题": "如何高效地从神经网络中提取高质量的表示，并适用于大规模数据集和网络。",
        "动机": "研究神经网络表示的统一提取方法，以及如何利用低秩结构提高表示提取的效率和质量。",
        "方法": "定义神经费舍尔核（NFK）作为统一的表示提取工具，提出一种计算NFK低秩近似的高效算法。",
        "关键词": [
            "神经费舍尔核",
            "低秩近似",
            "表示学习",
            "核方法",
            "深度学习"
        ],
        "涉及的技术概念": {
            "神经费舍尔核（NFK）": "将费舍尔核应用于神经网络，作为统一的表示提取工具。",
            "低秩近似": "利用NFK的低秩结构，提出高效算法计算其近似，以提高表示提取的效率和质量。",
            "表示学习": "研究如何从数据中学习有效的表示，以支持后续的机器学习任务。"
        },
        "success": true
    },
    {
        "order": 547,
        "title": "Learning Scenario Representation for Solving Two-stage Stochastic Integer Programs",
        "html": "https://iclr.cc//virtual/2022/poster/7065",
        "abstract": "Many practical combinatorial optimization problems under uncertainty can be modeled as stochastic integer programs (SIPs), which are extremely challenging to solve due to the high complexity. To solve two-stage SIPs efficiently, we propose a conditional variational autoencoder (CVAE) based method to learn scenario representation for a class of SIP instances. Specifically, we design a graph convolutional network based encoder to embed each scenario with the deterministic part of its instance (i.e. context) into a low-dimensional latent space, from which a decoder reconstructs the scenario from its latent representation conditioned on the context. Such a design effectively captures the dependencies of the scenarios on their corresponding instances. We apply the trained encoder to two tasks in typical SIP solving, i.e. scenario reduction and objective prediction. Experiments on two SIP problems show that the learned latent representation significantly boosts the solving performance to attain high-quality solutions in short computational time, and generalizes fairly well to problems of larger sizes or with more scenarios.",
        "conference": "ICLR",
        "中文标题": "学习场景表示以解决两阶段随机整数规划问题",
        "摘要翻译": "许多实际中的不确定性组合优化问题可以被建模为随机整数规划（SIPs），由于高复杂性，这些问题极难解决。为了高效解决两阶段SIPs，我们提出了一种基于条件变分自编码器（CVAE）的方法，用于学习一类SIP实例的场景表示。具体来说，我们设计了一个基于图卷积网络的编码器，将每个场景与其实例的确定性部分（即上下文）嵌入到一个低维潜在空间中，解码器则根据上下文从潜在表示中重构场景。这种设计有效地捕捉了场景与其对应实例之间的依赖关系。我们将训练好的编码器应用于典型SIP求解中的两个任务，即场景缩减和目标预测。在两个SIP问题上的实验表明，学习到的潜在表示显著提升了求解性能，能够在较短的计算时间内获得高质量的解，并且对于更大规模或更多场景的问题也表现出良好的泛化能力。",
        "领域": "组合优化、随机整数规划、图神经网络",
        "问题": "解决两阶段随机整数规划问题的高效方法",
        "动机": "随机整数规划问题由于高复杂性难以高效解决，需要一种能够捕捉场景与实例依赖关系的方法来提升求解性能。",
        "方法": "提出了一种基于条件变分自编码器和图卷积网络的方法，通过学习场景的潜在表示来提升两阶段随机整数规划的求解效率和泛化能力。",
        "关键词": [
            "随机整数规划",
            "条件变分自编码器",
            "图卷积网络",
            "场景表示",
            "组合优化"
        ],
        "涉及的技术概念": {
            "条件变分自编码器（CVAE）": "用于学习场景的潜在表示，捕捉场景与实例之间的依赖关系。",
            "图卷积网络": "作为编码器的基础结构，用于嵌入场景和上下文到潜在空间。",
            "潜在表示": "通过学习得到的低维表示，用于提升随机整数规划问题的求解效率和泛化能力。"
        },
        "success": true
    },
    {
        "order": 548,
        "title": "Learning State Representations via Retracing in Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2022/poster/7072",
        "abstract": "We propose learning via retracing, a novel self-supervised approach for learning the state representation (and the associated dynamics model) for reinforcement learning tasks. In addition to the predictive (reconstruction) supervision in the forward direction, we propose to include 'retraced' transitions for representation/model learning, by enforcing the cycle-consistency constraint between the original and retraced states, hence improve upon the sample efficiency of learning. Moreover, learning via retracing explicitly propagates information about future transitions backward for inferring previous states, thus facilitates stronger representation learning for the downstream reinforcement learning tasks. We introduce Cycle-Consistency World Model (CCWM), a concrete model-based instantiation of learning via retracing. Additionally we propose a novel adaptive 'truncation' mechanism for counteracting the negative impacts brought by 'irreversible' transitions such that learning via retracing can be maximally effective. Through extensive empirical studies on visual-based continuous control benchmarks, we demonstrate that CCWM achieves state-of-the-art performance in terms of sample efficiency and asymptotic performance, whilst exhibiting behaviours that are indicative of stronger representation learning. ",
        "conference": "ICLR",
        "中文标题": "通过回溯学习强化学习中的状态表示",
        "摘要翻译": "我们提出了一种名为‘通过回溯学习’的新型自监督方法，用于学习强化学习任务中的状态表示（及其相关的动态模型）。除了正向的预测（重建）监督外，我们建议通过强制原始状态和回溯状态之间的循环一致性约束，将‘回溯’转换纳入表示/模型学习中，从而提高学习的样本效率。此外，通过回溯学习显式地将关于未来转换的信息向后传播以推断先前状态，从而为下游强化学习任务促进更强的表示学习。我们介绍了循环一致性世界模型（CCWM），这是通过回溯学习的一个具体基于模型的实例化。此外，我们提出了一种新颖的自适应‘截断’机制，用于抵消由‘不可逆’转换带来的负面影响，从而使通过回溯学习能够最大限度地有效。通过在视觉基础的连续控制基准上进行广泛的实证研究，我们证明CCWM在样本效率和渐进性能方面达到了最先进的水平，同时表现出指示更强表示学习的行为。",
        "领域": "强化学习、自监督学习、模型预测控制",
        "问题": "如何在强化学习中更高效地学习状态表示和动态模型",
        "动机": "提高强化学习中状态表示和动态模型学习的样本效率，促进更强的表示学习",
        "方法": "提出通过回溯学习的方法，包括循环一致性约束和自适应截断机制，实例化为循环一致性世界模型（CCWM）",
        "关键词": [
            "状态表示",
            "循环一致性",
            "自监督学习",
            "强化学习",
            "模型预测"
        ],
        "涉及的技术概念": {
            "循环一致性约束": "用于确保原始状态和回溯状态之间的一致性，提高表示学习的效率",
            "自适应截断机制": "用于处理不可逆转换，最大化回溯学习的效果",
            "循环一致性世界模型（CCWM）": "通过回溯学习的具体实例化模型，用于提高强化学习的样本效率和渐进性能"
        },
        "success": true
    },
    {
        "order": 549,
        "title": "Learning Strides in Convolutional Neural Networks",
        "html": "https://iclr.cc//virtual/2022/poster/7068",
        "abstract": "Convolutional neural networks typically contain several downsampling operators, such as strided convolutions or pooling layers, that progressively reduce the resolution of intermediate representations. This provides some shift-invariance while reducing the computational complexity of the whole architecture. A critical hyperparameter of such layers is their stride: the integer factor of downsampling. As strides are not differentiable, finding the best configuration either requires cross-validation or discrete optimization (e.g. architecture search), which rapidly become prohibitive as the search space grows exponentially with the number of downsampling layers. Hence, exploring this search space by gradient descent would allow finding better configurations at a lower computational cost. This work introduces DiffStride, the first downsampling layer with learnable strides. Our layer learns the size of a cropping mask in the Fourier domain, that effectively performs resizing in a differentiable way. Experiments on audio and image classification show the generality and effectiveness of our solution: we use DiffStride as a drop-in replacement to standard downsampling layers and outperform them. In particular, we show that introducing our layer into a ResNet-18 architecture allows keeping consistent high performance on CIFAR10, CIFAR100 and ImageNet even when training starts from poor random stride configurations. Moreover, formulating strides as learnable variables allows us to introduce a regularization term that controls the computational complexity of the architecture. We show how this regularization allows trading off accuracy for efficiency on ImageNet.",
        "conference": "ICLR",
        "中文标题": "学习卷积神经网络中的步长",
        "摘要翻译": "卷积神经网络通常包含多个下采样操作，如步长卷积或池化层，这些操作逐步降低中间表示的分辨率。这在一定程度上提供了平移不变性，同时降低了整个架构的计算复杂度。这些层的一个关键超参数是它们的步长：下采样的整数因子。由于步长不可微分，寻找最佳配置需要通过交叉验证或离散优化（如架构搜索）来完成，随着搜索空间随着下采样层数的增加呈指数级增长，这些方法很快变得不可行。因此，通过梯度下降探索这一搜索空间将能够以更低的计算成本找到更好的配置。这项工作介绍了DiffStride，第一个具有可学习步长的下采样层。我们的层学习傅里叶域中裁剪掩码的大小，以可微分的方式有效地执行调整大小。音频和图像分类的实验展示了我们解决方案的通用性和有效性：我们将DiffStride作为标准下采样层的替代品，并超越了它们。特别是，我们展示了将我们的层引入ResNet-18架构中，即使在从较差的随机步长配置开始训练时，也能在CIFAR10、CIFAR100和ImageNet上保持一致的高性能。此外，将步长表述为可学习变量使我们能够引入一个控制架构计算复杂度的正则化项。我们展示了这种正则化如何在ImageNet上实现精度与效率的权衡。",
        "领域": "卷积神经网络优化、图像分类、音频分类",
        "问题": "如何在卷积神经网络中有效地学习和优化下采样步长，以避免昂贵的交叉验证或离散优化过程。",
        "动机": "传统的下采样步长优化方法计算成本高，且随着网络深度的增加，搜索空间急剧扩大，因此需要一种更高效的方法来优化步长配置。",
        "方法": "引入DiffStride，一种具有可学习步长的下采样层，通过在傅里叶域中学习裁剪掩码的大小，实现可微分的下采样。",
        "关键词": [
            "可学习步长",
            "下采样优化",
            "傅里叶域裁剪",
            "计算复杂度控制",
            "梯度下降优化"
        ],
        "涉及的技术概念": {
            "DiffStride": "一种新型的下采样层，能够通过梯度下降学习最优的步长配置，实现可微分的下采样。",
            "傅里叶域裁剪": "在傅里叶域中应用裁剪掩码，以实现图像或音频信号的可微分调整大小。",
            "计算复杂度正则化": "通过引入正则化项来控制网络的计算复杂度，实现精度与效率的平衡。"
        },
        "success": true
    },
    {
        "order": 550,
        "title": "Learning Super-Features for Image Retrieval",
        "html": "https://iclr.cc//virtual/2022/poster/6552",
        "abstract": "Methods that combine local and global features have recently shown excellent performance on multiple challenging deep image retrieval benchmarks, but their use of local features raises at least two issues. First, these local features simply boil down to the localized map activations of a neural network, and hence can be extremely redundant. Second, they are typically trained with a global loss that only acts on top of an aggregation of local features; by contrast, testing is based on local feature matching, which creates a discrepancy between training and testing. In this paper, we propose a novel architecture for deep image retrieval, based solely on mid-level features that we call Super-features. These Super-features are constructed by an iterative attention module and constitute an ordered set in which each element focuses on a localized and discriminant image pattern. For training, they require only image labels. A contrastive loss operates directly at the level of Super-features and focuses on those that match across images. A second complementary loss encourages diversity. Experiments on common landmark retrieval benchmarks validate that Super-features substantially outperform state-of-the-art methods when using the same number of features, and only require a significantly smaller memory footprint to match their performance. Code and models are available at: https://github.com/naver/FIRe.",
        "conference": "ICLR",
        "中文标题": "学习用于图像检索的超特征",
        "摘要翻译": "结合局部和全局特征的方法最近在多个具有挑战性的深度图像检索基准测试中表现出色，但它们对局部特征的使用至少引发了两个问题。首先，这些局部特征简单地归结为神经网络局部化映射的激活，因此可能极其冗余。其次，它们通常是通过一个全局损失函数训练的，该损失函数仅作用于局部特征的聚合之上；相比之下，测试是基于局部特征匹配进行的，这造成了训练和测试之间的不一致。在本文中，我们提出了一种新颖的深度图像检索架构，仅基于我们称之为超特征的中层特征。这些超特征通过一个迭代注意力模块构建，并构成一个有序集合，其中每个元素专注于一个局部化和判别性的图像模式。对于训练，它们仅需要图像标签。一个对比损失直接在超特征级别上操作，并专注于那些跨图像匹配的特征。第二个互补损失鼓励多样性。在常见的地标检索基准测试上的实验验证，当使用相同数量的特征时，超特征显著优于最先进的方法，并且仅需要显著更小的内存占用即可匹配其性能。代码和模型可在以下网址获取：https://github.com/naver/FIRe。",
        "领域": "图像检索、深度学习、注意力机制",
        "问题": "解决局部特征在图像检索中的冗余性和训练与测试不一致的问题",
        "动机": "通过引入超特征来减少局部特征的冗余性，并解决训练与测试之间的不一致问题",
        "方法": "提出了一种基于超特征的深度图像检索架构，使用迭代注意力模块构建超特征，并通过对比损失和多样性损失进行训练",
        "关键词": [
            "超特征",
            "图像检索",
            "注意力机制",
            "对比损失",
            "多样性损失"
        ],
        "涉及的技术概念": {
            "超特征": "通过迭代注意力模块构建的中层特征，专注于局部化和判别性的图像模式",
            "迭代注意力模块": "用于构建超特征的模块，通过迭代过程增强特征的判别性",
            "对比损失": "直接在超特征级别上操作的损失函数，专注于跨图像匹配的特征"
        },
        "success": true
    },
    {
        "order": 551,
        "title": "Learning Synthetic Environments and Reward Networks for Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6495",
        "abstract": "We introduce Synthetic Environments (SEs) and Reward Networks (RNs), represented by neural networks, as proxy environment models for training Reinforcement Learning (RL) agents. We show that an agent, after being trained exclusively on the SE, is able to solve the corresponding real environment. While an SE acts as a full proxy to a real environment by learning about its state dynamics and rewards, an RN is a partial proxy that learns to augment or replace rewards. We use bi-level optimization to evolve SEs and RNs: the inner loop trains the RL agent, and the outer loop trains the parameters of the SE / RN via an evolution strategy. We evaluate our proposed new concept on a broad range of RL algorithms and classic control environments. In a one-to-one comparison, learning an SE proxy requires more interactions with the real environment than training agents only on the real environment. However, once such an SE has been learned, we do not need any interactions with the real environment to train new agents. Moreover, the learned SE proxies allow us to train agents with fewer interactions while maintaining the original task performance. Our empirical results suggest that SEs achieve this result by learning informed representations that bias the agents towards relevant states. Moreover, we find that these proxies are robust against hyperparameter variation and can also transfer to unseen agents.",
        "conference": "ICLR",
        "中文标题": "学习合成环境与奖励网络以用于强化学习",
        "摘要翻译": "我们介绍了由神经网络表示的合成环境（SEs）和奖励网络（RNs），作为训练强化学习（RL）代理的代理环境模型。我们展示了在SE上独家训练的代理能够解决相应的真实环境。虽然SE通过学习其状态动态和奖励作为真实环境的完整代理，但RN是一个部分代理，学习增强或替换奖励。我们使用双层优化来进化SEs和RNs：内循环训练RL代理，外循环通过进化策略训练SE/RN的参数。我们在广泛的RL算法和经典控制环境上评估了我们提出的新概念。在一对一的比较中，学习SE代理比仅在真实环境上训练代理需要更多的与真实环境的交互。然而，一旦学习了这样的SE，我们就不需要与真实环境进行任何交互来训练新的代理。此外，学习到的SE代理允许我们以更少的交互训练代理，同时保持原始任务性能。我们的实证结果表明，SEs通过学习有信息的表示来实现这一结果，这些表示使代理偏向于相关状态。此外，我们发现这些代理对超参数变化具有鲁棒性，并且可以转移到未见过的代理。",
        "领域": "强化学习、代理环境建模、进化策略",
        "问题": "如何在减少与真实环境交互的同时，有效训练强化学习代理",
        "动机": "减少训练强化学习代理时对真实环境的依赖，提高训练效率和代理的泛化能力",
        "方法": "通过双层优化进化合成环境和奖励网络，内循环训练强化学习代理，外循环通过进化策略优化合成环境和奖励网络的参数",
        "关键词": [
            "合成环境",
            "奖励网络",
            "强化学习",
            "进化策略",
            "代理训练"
        ],
        "涉及的技术概念": {
            "合成环境（SEs）": "作为真实环境的完整代理，通过学习状态动态和奖励来模拟真实环境，用于训练强化学习代理",
            "奖励网络（RNs）": "作为真实环境的部分代理，专注于学习如何增强或替换奖励信号，以优化代理的学习过程",
            "双层优化": "一种优化策略，内循环专注于代理的训练，外循环通过进化策略优化合成环境和奖励网络的参数，以实现更高效的代理训练"
        },
        "success": true
    },
    {
        "order": 552,
        "title": "Learning Temporally Causal Latent Processes from General Temporal Data",
        "html": "https://iclr.cc//virtual/2022/poster/6675",
        "abstract": "Our goal is to recover time-delayed latent causal variables and identify their relations from measured temporal data. Estimating causally-related latent variables from observations is particularly challenging as the latent variables are not uniquely recoverable in the most general case. In this work, we consider both a nonparametric, nonstationary setting and a parametric setting for the latent processes and propose two provable conditions under which temporally causal latent processes can be identified from their nonlinear mixtures. We propose LEAP, a theoretically-grounded framework that extends Variational AutoEncoders (VAEs) by enforcing our conditions through proper constraints in causal process prior. Experimental results on various datasets demonstrate that temporally causal latent processes are reliably identified from observed variables under different dependency structures and that our approach considerably outperforms baselines that do not properly leverage history or nonstationarity information. This demonstrates that using temporal information to learn latent processes from their invertible nonlinear mixtures in an unsupervised manner, for which we believe our work is one of the first, seems promising even without sparsity or minimality assumptions. ",
        "conference": "ICLR",
        "中文标题": "从一般时间数据中学习时间因果潜在过程",
        "摘要翻译": "我们的目标是从测量的时间数据中恢复时间延迟的潜在因果变量并识别它们之间的关系。从观测中估计因果相关的潜在变量尤其具有挑战性，因为在最一般的情况下，潜在变量不是唯一可恢复的。在这项工作中，我们考虑了潜在过程的非参数、非平稳设置和参数设置，并提出了两个可证明的条件，在这些条件下，时间因果潜在过程可以从它们的非线性混合中被识别出来。我们提出了LEAP，这是一个理论基础坚实的框架，它通过因果过程先验中的适当约束来强制执行我们的条件，从而扩展了变分自编码器（VAEs）。在各种数据集上的实验结果表明，时间因果潜在过程在不同依赖结构下从观测变量中可靠地被识别出来，并且我们的方法大大优于那些没有适当利用历史或非平稳性信息的基线方法。这表明，利用时间信息以无监督的方式从它们的可逆非线性混合中学习潜在过程，我们认为我们的工作是其中的先驱之一，即使在没有稀疏性或最小性假设的情况下，也显得很有前景。",
        "领域": "时间序列分析、因果推理、深度学习",
        "问题": "从观测的时间数据中恢复时间延迟的潜在因果变量并识别它们之间的关系",
        "动机": "解决从观测中估计因果相关的潜在变量的挑战，尤其是在潜在变量不是唯一可恢复的最一般情况下",
        "方法": "提出了LEAP框架，扩展了变分自编码器（VAEs），通过在因果过程先验中施加适当约束来强制执行识别条件",
        "关键词": [
            "时间因果潜在过程",
            "非线性混合",
            "变分自编码器",
            "无监督学习",
            "非平稳性"
        ],
        "涉及的技术概念": {
            "变分自编码器（VAEs）": "用于从观测数据中学习潜在变量表示的基础框架",
            "时间因果潜在过程": "论文中研究的核心对象，指的是随时间变化且具有因果关系的潜在变量过程",
            "非线性混合": "观测数据被视为潜在变量的非线性混合，论文提出了在这些混合下识别潜在过程的条件"
        },
        "success": true
    },
    {
        "order": 553,
        "title": "Learning the Dynamics of Physical Systems from Sparse Observations with Finite Element Networks",
        "html": "https://iclr.cc//virtual/2022/poster/6609",
        "abstract": "We propose a new method for spatio-temporal forecasting on arbitrarily distributed points. Assuming that the observed system follows an unknown partial differential equation, we derive a continuous-time model for the dynamics of the data via the finite element method. The resulting graph neural network estimates the instantaneous effects of the unknown dynamics on each cell in a meshing of the spatial domain. Our model can incorporate prior knowledge via assumptions on the form of the unknown PDE, which induce a structural bias towards learning specific processes. Through this mechanism, we derive a transport variant of our model from the convection equation and show that it improves the transfer performance to higher-resolution meshes on sea surface temperature and gas flow forecasting against baseline models representing a selection of spatio-temporal forecasting methods. A qualitative analysis shows that our model disentangles the data dynamics into their constituent parts, which makes it uniquely interpretable.",
        "conference": "ICLR",
        "中文标题": "从稀疏观测中学习物理系统动力学的有限元网络方法",
        "摘要翻译": "我们提出了一种在任意分布点上进行时空预测的新方法。假设观测系统遵循一个未知的偏微分方程，我们通过有限元方法推导出数据动力学的连续时间模型。所得到的图神经网络估计了未知动力学对空间域网格中每个单元的瞬时影响。我们的模型可以通过对未知偏微分方程形式的假设来融入先验知识，这诱导了一种结构偏向，以学习特定过程。通过这一机制，我们从对流方程中推导出我们模型的一个传输变体，并表明在海洋表面温度和气流预测上，与代表一系列时空预测方法的基线模型相比，它提高了向更高分辨率网格的转移性能。定性分析显示，我们的模型将数据动力学分解为其组成部分，这使得它具有独特的可解释性。",
        "领域": "物理系统建模、时空预测、偏微分方程求解",
        "问题": "如何在稀疏观测数据下准确预测物理系统的时空动态",
        "动机": "开发一种能够从稀疏观测中学习物理系统动力学，并能够融入先验知识以提高预测准确性和可解释性的方法",
        "方法": "通过有限元方法和图神经网络构建连续时间模型，估计未知偏微分方程对空间域网格的瞬时影响，并利用先验知识优化模型",
        "关键词": [
            "有限元网络",
            "时空预测",
            "偏微分方程",
            "图神经网络",
            "物理系统建模"
        ],
        "涉及的技术概念": {
            "有限元方法": "用于将偏微分方程离散化，以便在计算机上进行数值求解的技术",
            "图神经网络": "用于处理图结构数据的神经网络，能够捕捉节点间的关系和动态变化",
            "偏微分方程": "描述物理系统动力学的基本数学工具，模型假设观测系统遵循未知的偏微分方程"
        },
        "success": true
    },
    {
        "order": 554,
        "title": "Learning to Annotate Part Segmentation with Gradient Matching",
        "html": "https://iclr.cc//virtual/2022/poster/6015",
        "abstract": "The success of state-of-the-art deep neural networks heavily relies on the presence of large-scale labelled datasets, which are extremely expensive and time-consuming to annotate. This paper focuses on tackling semi-supervised part segmentation tasks by generating high-quality images with a pre-trained GAN and labelling the generated images with an automatic annotator. In particular, we formulate the annotator learning as a learning-to-learn problem. Given a pre-trained GAN, the annotator learns to label object parts in a set of randomly generated images such that a part segmentation model trained on these synthetic images with their predicted labels obtains low segmentation error on a small validation set of manually labelled images. We further reduce this nested-loop optimization problem to a simple gradient matching problem and efficiently solve it with an iterative algorithm. We show that our method can learn annotators from a broad range of labelled images including real images, generated images, and even analytically rendered images. Our method is evaluated with semi-supervised part segmentation tasks and significantly outperforms other semi-supervised competitors when the amount of labelled examples is extremely limited.",
        "conference": "ICLR",
        "中文标题": "通过梯度匹配学习标注部分分割",
        "摘要翻译": "最先进的深度神经网络的成功很大程度上依赖于大规模标注数据集的存在，这些数据集的标注极其昂贵且耗时。本文专注于通过使用预训练的GAN生成高质量图像并用自动标注器标注生成的图像来解决半监督部分分割任务。特别是，我们将标注器学习表述为一个学习学习的问题。给定一个预训练的GAN，标注器学习在一组随机生成的图像中标注对象部分，使得在这些合成图像及其预测标签上训练的部分分割模型在手动标注的小型验证集上获得低分割误差。我们进一步将这个嵌套循环优化问题简化为一个简单的梯度匹配问题，并用迭代算法高效地解决它。我们展示了我们的方法可以从包括真实图像、生成图像甚至分析渲染图像在内的广泛标注图像中学习标注器。我们的方法在半监督部分分割任务中进行了评估，当标注示例数量极其有限时，显著优于其他半监督竞争者。",
        "领域": "图像分割, 半监督学习, 生成对抗网络",
        "问题": "解决在半监督环境下，标注数据稀缺时的部分分割任务。",
        "动机": "减少对大规模标注数据集的依赖，降低标注成本和时间。",
        "方法": "使用预训练的GAN生成图像，并通过学习学习的方法训练自动标注器，将问题简化为梯度匹配并采用迭代算法解决。",
        "关键词": [
            "部分分割",
            "半监督学习",
            "梯度匹配",
            "生成对抗网络",
            "自动标注"
        ],
        "涉及的技术概念": {
            "生成对抗网络（GAN）": "用于生成高质量图像，为半监督学习提供数据。",
            "学习学习（Learning-to-Learn）": "将标注器学习过程表述为一个元学习问题，优化标注器以提升分割模型的性能。",
            "梯度匹配": "将复杂的嵌套循环优化问题简化为梯度匹配问题，提高计算效率。"
        },
        "success": true
    },
    {
        "order": 555,
        "title": "Learning to Complete Code with Sketches",
        "html": "https://iclr.cc//virtual/2022/poster/6551",
        "abstract": "Code completion is usually cast as a language modelling problem, i.e., continuing an input in a left-to-right fashion. However, in practice, some parts of the completion (e.g., string literals) may be very hard to predict, whereas subsequent parts directly follow from the context.To handle this, we instead consider the scenario of generating code completions with 'holes' inserted in places where a model is uncertain. We develop Grammformer, a Transformer-based model that guides the code generation by the programming language grammar, and compare it to a variety of more standard sequence models.We train the models on code completion for C# and Python given partial code context. To evaluate models, we consider both ROUGE as well as a new metric RegexAcc that measures success of generating completions matching long outputs with as few holes as possible.In our experiments, Grammformer generates 10-50% more accurate completions compared to traditional generative models and 37-50% longer sketches compared to sketch-generating baselines trained with similar techniques.",
        "conference": "ICLR",
        "中文标题": "学习通过草图完成代码",
        "摘要翻译": "代码补全通常被视为一个语言建模问题，即以从左到右的方式继续输入。然而，在实践中，补全的某些部分（例如字符串文字）可能非常难以预测，而后续部分则直接跟随上下文。为了处理这一点，我们转而考虑在模型不确定的地方插入'空洞'来生成代码补全的场景。我们开发了Grammformer，这是一个基于Transformer的模型，通过编程语言语法指导代码生成，并将其与各种更标准的序列模型进行比较。我们在给定部分代码上下文的情况下，对C#和Python的代码补全进行了模型训练。为了评估模型，我们既考虑了ROUGE，也考虑了一个新的度量标准RegexAcc，它衡量了生成尽可能少空洞的长输出补全的成功率。在我们的实验中，Grammformer生成的补全比传统生成模型准确度高10-50%，比使用类似技术训练的草图生成基线生成的草图长37-50%。",
        "领域": "程序代码生成、自然语言处理与编程结合、机器学习在软件开发中的应用",
        "问题": "解决代码补全中难以预测部分的问题，提高补全的准确性和效率",
        "动机": "传统的代码补全方法在处理某些难以预测的部分时效率不高，研究旨在通过引入'空洞'和基于语法的指导来提高补全的质量",
        "方法": "开发基于Transformer的Grammformer模型，利用编程语言语法指导代码生成，并与标准序列模型进行比较",
        "关键词": [
            "代码补全",
            "Transformer模型",
            "编程语言语法",
            "空洞插入",
            "Grammformer"
        ],
        "涉及的技术概念": {
            "Transformer模型": "用于代码生成的深度学习模型，能够处理序列数据并捕捉长距离依赖关系",
            "编程语言语法": "指导模型生成符合语法规则的代码，提高补全的准确性",
            "空洞插入": "在模型不确定的地方插入空洞，允许后续更准确的补全，提高整体补全质量"
        },
        "success": true
    },
    {
        "order": 556,
        "title": "Learning to Dequantise with Truncated Flows",
        "html": "https://iclr.cc//virtual/2022/poster/6123",
        "abstract": "Dequantisation is a general technique used for transforming data described by a discrete random variable $x$ into a continuous (latent) random variable $z$, for the purpose of it being modeled by likelihood-based density models. Dequantisation was first introduced in the context of ordinal data, such as image pixel values.  However, when the data is categorical, the dequantisation scheme is not obvious.We learn such a dequantisation scheme $q(z | x)$, using variational inference with TRUncated FLows (TRUFL) --- a novel flow-based model that allows the dequantiser to have a learnable truncated support. Unlike previous work, the TRUFL dequantiser is (i) capable of embedding the data losslessly in certain cases, since the truncation allows the conditional distributions $q(z | x)$ to have non-overlapping bounded supports, while being (ii) trainable with back-propagation. Addtionally, since the support of the marginal $q(z)$ is bounded and the support of prior $p(z)$ is not, we propose renormalising the prior distribution over the support of $q(z)$. We derive a lower bound for training, and propose a rejection sampling scheme to account for the invalid samples during generation.Experimentally, we benchmark TRUFL on constrained generation tasks, and find that it outperforms prior approaches. In addition, we find that rejection sampling results in higher validity for the constrained problems.",
        "conference": "ICLR",
        "中文标题": "学习使用截断流进行去量化",
        "摘要翻译": "去量化是一种通用技术，用于将由离散随机变量x描述的数据转换为连续（潜在）随机变量z，以便通过基于似然的密度模型进行建模。去量化最初是在有序数据（如图像像素值）的背景下引入的。然而，当数据是分类数据时，去量化方案并不明显。我们学习这样一种去量化方案q(z | x)，使用变分推理与TRUncated FLows（TRUFL）——一种新颖的基于流的模型，允许去量化器具有可学习的截断支持。与之前的工作不同，TRUFL去量化器（i）在某些情况下能够无损地嵌入数据，因为截断允许条件分布q(z | x)具有非重叠的有界支持，同时（ii）可以通过反向传播进行训练。此外，由于边际q(z)的支持是有界的，而先验p(z)的支持不是，我们提出在先验分布q(z)的支持上重新归一化。我们推导了一个用于训练的下界，并提出了一个拒绝抽样方案，以考虑生成过程中的无效样本。实验上，我们在约束生成任务上对TRUFL进行了基准测试，发现它优于先前的方法。此外，我们发现拒绝抽样在约束问题上导致更高的有效性。",
        "领域": "生成模型、变分推理、密度估计",
        "问题": "如何在分类数据上实现有效的去量化，以便使用基于似然的密度模型进行建模",
        "动机": "解决分类数据去量化方案不明显的问题，提出一种能够无损嵌入数据且可训练的去量化方法",
        "方法": "使用变分推理与TRUncated FLows（TRUFL）学习去量化方案，提出重新归一化先验分布和拒绝抽样方案",
        "关键词": [
            "去量化",
            "截断流",
            "变分推理",
            "密度估计",
            "拒绝抽样"
        ],
        "涉及的技术概念": {
            "TRUncated FLows（TRUFL）": "一种新颖的基于流的模型，允许去量化器具有可学习的截断支持，实现无损数据嵌入和可训练性",
            "变分推理": "用于学习去量化方案q(z | x)的方法，通过优化下界来近似复杂的后验分布",
            "拒绝抽样": "在生成过程中考虑无效样本的方案，提高约束问题的有效性"
        },
        "success": true
    },
    {
        "order": 557,
        "title": "Learning to Downsample for Segmentation of Ultra-High Resolution Images",
        "html": "https://iclr.cc//virtual/2022/poster/6243",
        "abstract": "Many computer vision systems require low-cost segmentation algorithms based on deep learning, either because of the enormous size of input images or limited computational budget. Common solutions uniformly downsample the input images to meet memory constraints, assuming all pixels are equally informative. In this work, we demonstrate that this assumption can harm the segmentation performancebecause the segmentation difficulty varies spatially (see Figure 1 “Uniform”). We combat this problem by introducing a learnable downsampling module, which can be optimised together with the given segmentation model in an end-to-end fashion. We formulate the problem of training such downsampling module as optimisation of sampling density distributions over the input images given their low-resolution views. To defend against degenerate solutions (e.g. over-sampling trivial regions like the backgrounds), we propose a regularisation term that encourages the sampling locations to concentrate around the object boundaries. We find the downsamplingmodule learns to sample more densely at difficult locations, thereby improving the segmentation performance (see Figure 1 'Ours'). Our experiments on benchmarks of high-resolution street view, aerial and medical images demonstrate substantial improvements in terms of efficiency-and-accuracy trade-off compared to both uniform downsampling and two recent advanced downsampling techniques.",
        "conference": "ICLR",
        "中文标题": "学习下采样以实现超高分辨率图像的分割",
        "摘要翻译": "许多计算机视觉系统需要基于深度学习的低成本分割算法，这要么是因为输入图像的巨大尺寸，要么是因为有限的计算预算。常见的解决方案是统一对输入图像进行下采样以满足内存限制，假设所有像素的信息量相同。在这项工作中，我们证明这一假设可能会损害分割性能，因为分割难度在空间上是变化的（见图1“统一”）。我们通过引入一个可学习的下采样模块来解决这个问题，该模块可以与给定的分割模型以端到端的方式一起优化。我们将训练这种下采样模块的问题表述为在给定其低分辨率视图的情况下，对输入图像上的采样密度分布进行优化。为了防止退化解决方案（例如过度采样像背景这样的简单区域），我们提出了一个正则化项，鼓励采样位置集中在对象边界周围。我们发现下采样模块学会了在困难位置更密集地采样，从而提高了分割性能（见图1“我们的”）。我们在高分辨率街景、航空和医学图像的基准测试上的实验表明，与统一下采样和两种最近的高级下采样技术相比，在效率和准确性之间的权衡方面有显著改进。",
        "领域": "图像分割",
        "问题": "如何在有限的计算预算下，有效地对超高分辨率图像进行分割",
        "动机": "传统的统一下采样方法假设所有像素的信息量相同，这在分割难度空间变化的情况下会损害分割性能。",
        "方法": "引入一个可学习的下采样模块，与分割模型一起以端到端的方式优化，通过优化采样密度分布和引入正则化项来防止过度采样简单区域。",
        "关键词": [
            "可学习下采样",
            "超高分辨率图像分割",
            "端到端优化"
        ],
        "涉及的技术概念": {
            "可学习下采样模块": "用于动态调整采样密度，以适应图像不同区域的分割难度",
            "端到端优化": "将下采样模块和分割模型一起训练，以实现整体性能的最优化",
            "正则化项": "用于防止下采样模块过度采样简单区域，如背景，确保采样集中在对象边界周围"
        },
        "success": true
    },
    {
        "order": 558,
        "title": "Learning to Extend Molecular Scaffolds with Structural Motifs",
        "html": "https://iclr.cc//virtual/2022/poster/7209",
        "abstract": "Recent advancements in deep learning-based modeling of molecules promise to accelerate in silico drug discovery. A plethora of generative models is available, building molecules either atom-by-atom and bond-by-bond or fragment-by-fragment. However, many drug discovery projects require a fixed scaffold to be present in the generated molecule, and incorporating that constraint has only recently been explored. Here, we propose MoLeR, a graph-based model that naturally supports scaffolds as initial seed of the generative procedure, which is possible because it is not conditioned on the generation history. Our experiments show that MoLeR performs comparably to state-of-the-art methods on unconstrained molecular optimization tasks, and outperforms them on scaffold-based tasks, while being an order of magnitude faster to train and sample from than existing approaches. Furthermore, we show the influence of a number of seemingly minor design choices on the overall performance.",
        "conference": "ICLR",
        "中文标题": "学习利用结构基序扩展分子支架",
        "摘要翻译": "近年来，基于深度学习的分子建模进展有望加速计算机辅助药物发现。目前已有大量生成模型可用，这些模型可以原子接原子、键接键或片段接片段地构建分子。然而，许多药物发现项目要求生成的分子中包含固定的支架，而将这一约束条件纳入考虑的研究才刚刚开始。在此，我们提出了MoLeR，一种基于图的模型，它自然地支持将支架作为生成过程的初始种子，这是因为它不依赖于生成历史。我们的实验表明，在不受约束的分子优化任务上，MoLeR的表现与最先进的方法相当，而在基于支架的任务上则优于它们，同时训练和采样速度比现有方法快一个数量级。此外，我们还展示了一些看似微小的设计选择对整体性能的影响。",
        "领域": "分子生成模型、药物发现、深度学习应用",
        "问题": "如何在分子生成过程中固定支架并高效生成符合要求的分子",
        "动机": "解决药物发现项目中需要固定分子支架的约束条件下的分子生成问题",
        "方法": "提出了一种基于图的模型MoLeR，支持将支架作为生成过程的初始种子，不依赖于生成历史",
        "关键词": [
            "分子生成",
            "结构基序",
            "药物发现",
            "深度学习",
            "图模型"
        ],
        "涉及的技术概念": {
            "基于图的模型": "用于表示和生成分子结构，支持固定支架作为生成起点",
            "分子支架": "生成分子时必须包含的固定结构部分，是药物发现中的关键约束",
            "生成历史独立性": "模型不依赖于生成过程中的历史信息，使得固定支架成为可能"
        },
        "success": true
    },
    {
        "order": 559,
        "title": "Learning to Generalize across Domains on Single Test Samples",
        "html": "https://iclr.cc//virtual/2022/poster/5984",
        "abstract": "We strive to learn a model from a set of source domains that generalizes well to unseen target domains. The main challenge in such a domain generalization scenario is the unavailability of any target domain data during training, resulting in the learned model not being explicitly adapted to the unseen target domains. We propose learning to generalize across domains on single test samples. We leverage a meta-learning paradigm to learn our model to acquire the ability of adaptation with single samples at training time so as to further adapt itself to each single test sample at test time. We formulate the adaptation to the single test sample as a variational Bayesian inference problem, which incorporates the test sample as a conditional into the generation of model parameters. The adaptation to each test sample requires only one feed-forward computation at test time without any fine-tuning or self-supervised training on additional data from the unseen domains.  Extensive ablation studies demonstrate that our model learns the ability to adapt models to each single sample by mimicking domain shifts during training. Further, our model achieves at least comparable -- and often better -- performance than state-of-the-art methods on multiple benchmarks for domain generalization.",
        "conference": "ICLR",
        "中文标题": "学习在单个测试样本上跨域泛化",
        "摘要翻译": "我们致力于从一组源域中学习一个模型，该模型能够很好地泛化到未见过的目标域。在这种域泛化场景中，主要挑战在于训练期间无法获得任何目标域数据，导致学习到的模型无法明确适应未见过的目标域。我们提出了在单个测试样本上学习跨域泛化的方法。我们利用元学习范式，使我们的模型在训练时获得适应单个样本的能力，从而在测试时进一步适应每个单个测试样本。我们将对单个测试样本的适应表述为一个变分贝叶斯推理问题，该问题将测试样本作为条件纳入模型参数的生成中。对每个测试样本的适应在测试时仅需一次前向计算，无需对未见过的域中的额外数据进行任何微调或自监督训练。大量的消融研究表明，我们的模型通过学习在训练时模拟域偏移，获得了适应每个单个样本的能力。此外，我们的模型在多个域泛化基准测试中至少达到了与最先进方法相当——通常是更好的性能。",
        "领域": "域泛化、元学习、变分贝叶斯推理",
        "问题": "解决在训练阶段无法访问目标域数据的情况下，模型如何能够泛化到未见过的目标域的问题。",
        "动机": "研究动机是为了提高模型在未见过的目标域上的泛化能力，特别是在训练阶段无法获取目标域数据的情况下。",
        "方法": "采用元学习范式，通过变分贝叶斯推理将单个测试样本作为条件纳入模型参数的生成中，实现模型对每个测试样本的快速适应。",
        "关键词": [
            "域泛化",
            "元学习",
            "变分贝叶斯推理",
            "单个样本适应",
            "无监督适应"
        ],
        "涉及的技术概念": {
            "元学习": "用于训练模型获得适应单个样本的能力，使模型能够在测试时快速适应未见过的目标域。",
            "变分贝叶斯推理": "用于将单个测试样本作为条件纳入模型参数的生成中，实现对每个测试样本的适应。",
            "域偏移模拟": "在训练时模拟域偏移，使模型学习到适应不同域的能力。"
        },
        "success": true
    },
    {
        "order": 560,
        "title": "Learning to Guide and to be Guided in the Architect-Builder Problem",
        "html": "https://iclr.cc//virtual/2022/poster/6532",
        "abstract": "We are interested in interactive agents that learn to coordinate, namely, a $builder$ -- which performs actions but ignores the goal of the task, i.e. has no access to rewards -- and an $architect$ which guides the builder towards the goal of the task. We define and explore a formal setting where artificial agents are equipped with mechanisms that allow them to simultaneously learn a task while at the same time evolving a shared communication protocol.  Ideally, such learning should only rely on high-level communication priors and be able to handle a large variety of tasks and meanings while deriving communication protocols that can be reused across tasks.The field of Experimental Semiotics has shown the extent of human proficiency at learning from a priori unknown instructions meanings. Therefore, we take inspiration from it and present the Architect-Builder Problem (ABP): an asymmetrical setting in which an architect must learn to guide a builder towards constructing a specific structure. The architect knows the target structure but cannot act in the environment and can only send arbitrary messages to the builder. The builder on the other hand can act in the environment, but receives no rewards nor has any knowledge about the task, and must learn to solve it relying only on the messages sent by the architect. Crucially, the meaning of messages is initially not defined nor shared between the agents but must be negotiated throughout learning.Under these constraints, we propose Architect-Builder Iterated Guiding (ABIG), a solution to the Architect-Builder Problem where the architect leverages a learned model of the builder to guide it while the builder uses self-imitation learning to reinforce its guided behavior. To palliate to the non-stationarity induced by the two agents concurrently learning, ABIG structures the sequence of interactions between the agents into interaction frames. We analyze the key learning mechanisms of ABIG and test it in a 2-dimensional instantiation of the ABP where tasks involve grasping cubes, placing them at a given location, or building various shapes. In this environment, ABIG results in a low-level, high-frequency, guiding communication protocol that not only enables an architect-builder pair to solve the task at hand, but that can also generalize to unseen tasks. ",
        "conference": "ICLR",
        "success": true,
        "中文标题": "学习在建筑师-建造者问题中进行引导与被引导",
        "摘要翻译": "我们关注于学习协调的交互式智能体，即一个$建造者$——执行动作但不知道任务目标，即无法获得奖励——和一个$建筑师$，其引导建造者完成任务目标。我们定义并探索了一个正式的环境，其中人工智能体配备了允许它们同时学习任务和演化共享通信协议的机制。理想情况下，这种学习应仅依赖于高级通信先验，并能够处理各种任务和意义，同时推导出可跨任务重用的通信协议。实验符号学领域已经展示了人类在从先验未知的指令意义中学习的高超能力。因此，我们从中汲取灵感，提出了建筑师-建造者问题（ABP）：一个不对称的环境，其中建筑师必须学会引导建造者构建特定结构。建筑师知道目标结构但不能在环境中行动，只能向建造者发送任意消息。另一方面，建造者可以在环境中行动，但不接收任何奖励，也不了解任务，必须仅依靠建筑师发送的消息来学习解决任务。关键的是，消息的初始意义既未定义也未在智能体之间共享，必须在学习过程中协商。在这些约束下，我们提出了建筑师-建造者迭代引导（ABIG），作为建筑师-建造者问题的解决方案，其中建筑师利用学习到的建造者模型来引导它，而建造者使用自我模仿学习来加强其被引导的行为。为了缓解由两个智能体同时学习引起的非平稳性，ABIG将智能体之间的交互序列结构化为交互帧。我们分析了ABIG的关键学习机制，并在ABP的二维实例中测试了它，其中任务涉及抓取立方体、将它们放置在给定位置或构建各种形状。在这个环境中，ABIG产生了一种低级、高频率的引导通信协议，不仅使建筑师-建造者对能够解决手头的任务，而且还可以推广到未见过的任务。",
        "领域": "多智能体系统, 交互式学习, 通信协议学习",
        "问题": "如何在建筑师和建造者之间建立有效的通信和协调机制，以完成特定结构的构建任务",
        "动机": "探索智能体如何在缺乏明确奖励信号和任务知识的情况下，通过交互学习协调和通信，以解决复杂任务",
        "方法": "提出建筑师-建造者迭代引导（ABIG）方法，结合建筑师的引导模型和建造者的自我模仿学习，通过结构化交互帧来缓解学习过程中的非平稳性问题",
        "关键词": [
            "多智能体协调",
            "通信协议学习",
            "自我模仿学习",
            "交互式学习",
            "建筑师-建造者问题"
        ],
        "涉及的技术概念": {
            "建筑师-建造者问题（ABP）": "一个不对称的学习环境，建筑师知道目标但不能行动，建造者可以行动但不知道目标，必须通过通信协调",
            "自我模仿学习": "建造者通过模仿自己过去的成功行为来加强学习，无需外部奖励信号",
            "交互帧": "结构化智能体之间的交互序列，以缓解同时学习引起的非平稳性问题"
        }
    },
    {
        "order": 561,
        "title": "Learning to Map for Active Semantic Goal Navigation",
        "html": "https://iclr.cc//virtual/2022/poster/6293",
        "abstract": "We consider the problem of object goal navigation in unseen environments. Solving this problem requires learning of contextual semantic priors, a challenging endeavour given the spatial and semantic variability of indoor environments. Current methods learn to implicitly encode these priors through goal-oriented navigation policy functions operating on spatial representations that are limited to the agent's observable areas. In this work, we propose a novel framework that actively learns to generate semantic maps outside the field of view of the agent and leverages the uncertainty over the semantic classes in the unobserved areas to decide on long term goals. We demonstrate that through this spatial prediction strategy, we are able to learn semantic priors in scenes that can be leveraged in unknown environments. Additionally, we show how different objectives can be defined by balancing exploration with exploitation during searching for semantic targets. Our method is validated in the visually realistic environments of the Matterport3D dataset and show improved results on object goal navigation over competitive baselines.",
        "conference": "ICLR",
        "中文标题": "学习映射以实现主动语义目标导航",
        "摘要翻译": "我们考虑了在未知环境中进行物体目标导航的问题。解决这一问题需要学习上下文语义先验，鉴于室内环境的空间和语义变异性，这是一项具有挑战性的任务。当前的方法通过学习在空间表示上操作的目标导向导航策略函数来隐式编码这些先验，这些空间表示仅限于代理的可观察区域。在这项工作中，我们提出了一个新颖的框架，该框架主动学习生成代理视野之外的语义地图，并利用未观察区域中语义类别的不确定性来决定长期目标。我们证明，通过这种空间预测策略，我们能够在场景中学习语义先验，这些先验可以在未知环境中被利用。此外，我们还展示了如何通过在寻找语义目标时平衡探索与利用来定义不同的目标。我们的方法在Matterport3D数据集的视觉逼真环境中得到了验证，并在物体目标导航上展示了优于竞争基线的改进结果。",
        "领域": "语义导航、室内场景理解、机器人视觉",
        "问题": "在未知环境中进行物体目标导航的问题，特别是在空间和语义变异性大的室内环境中。",
        "动机": "当前方法在编码语义先验时仅限于代理的可观察区域，无法有效利用未观察区域的信息，限制了导航策略的效果。",
        "方法": "提出一个主动学习框架，生成代理视野之外的语义地图，并利用未观察区域的语义类别不确定性来决定长期目标，通过学习语义先验来提升未知环境中的导航效果。",
        "关键词": [
            "语义导航",
            "主动学习",
            "语义地图",
            "不确定性利用",
            "Matterport3D"
        ],
        "涉及的技术概念": {
            "语义先验": "在导航过程中利用的关于环境语义信息的先验知识，帮助代理理解未直接观察到的区域。",
            "空间预测策略": "通过预测未观察区域的空间和语义信息，来指导代理的导航决策。",
            "探索与利用平衡": "在寻找语义目标时，平衡对新区域的探索和对已知信息的利用，以优化导航路径。"
        },
        "success": true
    },
    {
        "order": 562,
        "title": "Learning to Remember Patterns: Pattern Matching Memory Networks for Traffic Forecasting",
        "html": "https://iclr.cc//virtual/2022/poster/6957",
        "abstract": "Traffic forecasting is a challenging problem due to complex road networks and sudden speed changes caused by various events on roads. Several models have been proposed to solve this challenging problem, with a focus on learning the spatio-temporal dependencies of roads. In this work, we propose a new perspective for converting the forecasting problem into a pattern-matching task, assuming that large traffic data can be represented by a set of patterns. To evaluate the validity of this new perspective, we design a novel traffic forecasting model called Pattern-Matching Memory Networks (PM-MemNet), which learns to match input data to representative patterns with a key-value memory structure. We first extract and cluster representative traffic patterns that serve as keys in the memory. Then, by matching the extracted keys and inputs, PM-MemNet acquires the necessary information on existing traffic patterns from the memory and uses it for forecasting. To model the spatio-temporal correlation of traffic, we proposed a novel memory architecture, GCMem, which integrates attention and graph convolution. The experimental results indicate that PM-MemNet is more accurate than state-of-the-art models, such as Graph WaveNet, with higher responsiveness. We also present a qualitative analysis describing how PM-MemNet works and achieves higher accuracy when road speed changes rapidly.",
        "conference": "ICLR",
        "中文标题": "学习记忆模式：用于交通预测的模式匹配记忆网络",
        "摘要翻译": "交通预测是一个具有挑战性的问题，原因在于复杂的道路网络以及道路上各种事件引起的速度突变。已有多个模型被提出来解决这一挑战性问题，主要集中在学习道路的时空依赖性上。在这项工作中，我们提出了一个新的视角，将预测问题转化为模式匹配任务，假设大量的交通数据可以通过一组模式来表示。为了评估这一新视角的有效性，我们设计了一个名为模式匹配记忆网络（PM-MemNet）的新型交通预测模型，该模型通过学习将输入数据与代表性模式匹配，采用键值记忆结构。我们首先提取并聚类作为记忆键的代表性交通模式。然后，通过匹配提取的键和输入，PM-MemNet从记忆中获取现有交通模式的必要信息，并将其用于预测。为了建模交通的时空相关性，我们提出了一种新颖的记忆架构GCMem，它集成了注意力和图卷积。实验结果表明，PM-MemNet比最先进的模型（如Graph WaveNet）更准确，响应速度更快。我们还进行了定性分析，描述了PM-MemNet如何在道路速度快速变化时工作并实现更高的准确性。",
        "领域": "交通预测、时空数据分析、模式识别",
        "问题": "解决交通预测中由于复杂道路网络和速度突变带来的挑战",
        "动机": "通过将交通预测问题转化为模式匹配任务，提高预测的准确性和响应速度",
        "方法": "设计模式匹配记忆网络（PM-MemNet），利用键值记忆结构匹配输入数据与代表性交通模式，结合注意力和图卷积建模时空相关性",
        "关键词": [
            "交通预测",
            "模式匹配",
            "记忆网络",
            "图卷积",
            "注意力机制"
        ],
        "涉及的技术概念": {
            "模式匹配记忆网络（PM-MemNet）": "一种新型交通预测模型，通过学习将输入数据与代表性模式匹配，采用键值记忆结构进行预测",
            "GCMem": "一种新颖的记忆架构，集成了注意力和图卷积，用于建模交通的时空相关性",
            "键值记忆结构": "用于存储和检索代表性交通模式的机制，通过匹配输入数据和记忆中的键来获取预测信息"
        },
        "success": true
    },
    {
        "order": 563,
        "title": "Learning to Schedule Learning rate with Graph Neural Networks",
        "html": "https://iclr.cc//virtual/2022/poster/6019",
        "abstract": "Recent decades have witnessed great development of stochastic optimization in training deep neural networks. Learning rate scheduling is one of the most important factors that influence the performance of stochastic optimizers like Adam. Traditional methods seek to find a relatively proper scheduling among a limited number of pre-defined rules and might not accommodate a particular target problem. Instead, we propose a novel Graph-Network-based Scheduler (GNS), aiming at learning a specific scheduling mechanism without restrictions to existing principles. By constructing a directed graph for the underlying neural network of the target problem, GNS encodes current dynamics with a graph message passing network and trains an agent to control the learning rate accordingly via reinforcement learning. The proposed scheduler can capture the intermediate layer information while being able to generalize to problems of varying scales. Besides, an efficient reward collection procedure is leveraged to speed up training. We evaluate our framework on benchmarking datasets, Fashion-MNIST and CIFAR10 for image classification, and GLUE for language understanding. GNS shows consistent improvement over popular baselines when training CNN and Transformer models. Moreover, GNS demonstrates great generalization to different datasets and network structures.",
        "conference": "ICLR",
        "中文标题": "学习使用图神经网络调度学习率",
        "摘要翻译": "近几十年来，随机优化在训练深度神经网络方面取得了巨大发展。学习率调度是影响如Adam等随机优化器性能的最重要因素之一。传统方法试图在有限数量的预定义规则中找到相对合适的调度，可能无法适应特定的目标问题。相反，我们提出了一种新颖的基于图网络的调度器（GNS），旨在学习一种不受现有原则限制的特定调度机制。通过为目标问题的底层神经网络构建有向图，GNS利用图消息传递网络编码当前动态，并通过强化学习训练一个代理来相应地控制学习率。所提出的调度器能够捕捉中间层信息，同时能够泛化到不同规模的问题。此外，利用高效的奖励收集程序来加速训练。我们在基准数据集上评估了我们的框架，包括用于图像分类的Fashion-MNIST和CIFAR10，以及用于语言理解的GLUE。在训练CNN和Transformer模型时，GNS显示出对流行基线的持续改进。此外，GNS对不同数据集和网络结构表现出极好的泛化能力。",
        "领域": "深度学习优化、图神经网络应用、自适应学习率调度",
        "问题": "如何自动化和优化深度神经网络训练过程中的学习率调度，以适应不同的问题和规模",
        "动机": "传统学习率调度方法依赖于预定义的规则，缺乏灵活性和适应性，无法针对特定问题自动调整",
        "方法": "提出基于图网络的调度器（GNS），通过构建神经网络的有向图，利用图消息传递网络和强化学习来自动调整学习率",
        "关键词": [
            "图神经网络",
            "学习率调度",
            "强化学习",
            "深度学习优化",
            "自适应训练"
        ],
        "涉及的技术概念": {
            "图消息传递网络": "用于编码神经网络当前动态的技术，帮助模型理解网络结构和状态",
            "强化学习": "用于训练代理自动调整学习率的方法，通过奖励机制优化调度策略",
            "自适应学习率调度": "根据训练过程中的动态自动调整学习率，以提高模型性能和训练效率"
        },
        "success": true
    },
    {
        "order": 564,
        "title": "Learning Towards The Largest Margins",
        "html": "https://iclr.cc//virtual/2022/poster/5901",
        "abstract": "One of the main challenges for feature representation in deep learning-based classification is the design of appropriate loss functions that exhibit strong discriminative power. The classical softmax loss does not explicitly encourage discriminative learning of features. A popular direction of research is to incorporate margins in well-established losses in order to enforce extra intra-class compactness and inter-class separability, which, however, were developed through heuristic means, as opposed to rigorous mathematical principles. In this work, we attempt to address this limitation by formulating the principled optimization objective as learning towards the largest margins. Specifically, we firstly propose to employ the class margin as the measure of inter-class separability, and the sample margin as the measure of intra-class compactness. Accordingly, to encourage discriminative representation of features, the loss function should promote the largest possible margins for both classes and samples. Furthermore, we derive a generalized margin softmax loss to draw general conclusions for the existing margin-based losses. Not only does this principled framework offer new perspectives to understand and interpret existing margin-based losses, but it also provides new insights that can guide the design of new tools, including \\textit{sample margin regularization} and \\textit{largest margin softmax loss} for class balanced cases, and \\textit{zero centroid regularization} for class imbalanced cases. Experimental results demonstrate the effectiveness of our strategy for multiple tasks including visual classification, imbalanced classification, person re-identification, and face verification.",
        "conference": "ICLR",
        "中文标题": "学习朝向最大边距",
        "摘要翻译": "在基于深度学习的分类中，特征表示的一个主要挑战是设计具有强判别力的适当损失函数。经典的softmax损失并未明确鼓励特征的判别性学习。一个流行的研究方向是在已建立的损失中融入边距，以强制额外的类内紧凑性和类间可分离性，然而这些方法是通过启发式手段开发的，而非严格的数学原理。在这项工作中，我们试图通过将原则性优化目标制定为学习朝向最大边距来解决这一限制。具体来说，我们首先提出使用类边距作为类间可分离性的度量，样本边距作为类内紧凑性的度量。相应地，为了鼓励特征的判别性表示，损失函数应促进类和样本的最大可能边距。此外，我们推导了一个广义边距softmax损失，以对现有的基于边距的损失得出一般性结论。这一原则性框架不仅为理解和解释现有的基于边距的损失提供了新的视角，而且还提供了可以指导新工具设计的新见解，包括用于类平衡情况的样本边距正则化和最大边距softmax损失，以及用于类不平衡情况的零质心正则化。实验结果证明了我们的策略在包括视觉分类、不平衡分类、人员重新识别和人脸验证在内的多个任务中的有效性。",
        "领域": "深度学习, 计算机视觉, 人脸识别",
        "问题": "设计具有强判别力的损失函数以提升深度学习分类的特征表示能力",
        "动机": "解决现有基于边距的损失函数设计缺乏严格数学原理支持的问题，通过原则性优化目标提升特征的判别性表示",
        "方法": "提出使用类边距和样本边距作为度量，推导广义边距softmax损失，并引入样本边距正则化和最大边距softmax损失等新工具",
        "关键词": [
            "损失函数",
            "边距学习",
            "判别性特征",
            "softmax损失",
            "正则化"
        ],
        "涉及的技术概念": {
            "类边距": "作为类间可分离性的度量，用于提升特征的判别性表示",
            "样本边距": "作为类内紧凑性的度量，用于增强同类样本间的相似性",
            "广义边距softmax损失": "推导出的损失函数，用于对现有基于边距的损失进行一般化，提供新的理解和设计指导"
        },
        "success": true
    },
    {
        "order": 565,
        "title": "Learning transferable motor skills with hierarchical latent mixture policies",
        "html": "https://iclr.cc//virtual/2022/poster/6750",
        "abstract": "For robots operating in the real world, it is desirable to learn reusable abstract behaviours that can effectively be transferred across numerous tasks and scenarios.We propose an approach to learn skills from data using a hierarchical mixture latent variable model.Our method exploits a multi-level hierarchy of both discrete and continuous latent variables, to model a discrete set of abstract high-level behaviours while allowing for variance in how they are executed.We demonstrate in manipulation domains that the method can effectively cluster offline data into distinct, executable behaviours, while retaining the flexibility of a continuous latent variable model.The resulting skills can be transferred to new tasks, unseen objects, and from state to vision-based policies, yielding significantly better sample efficiency and asymptotic performance compared to existing skill- and imitation-based methods.We also perform further analysis showing how and when the skills are most beneficial: they encourage directed exploration to cover large regions of the state space relevant to the task, making them most effective in challenging sparse-reward settings.",
        "conference": "ICLR",
        "中文标题": "学习可迁移运动技能的分层潜在混合策略",
        "摘要翻译": "对于在现实世界中操作的机器人来说，学习可重用的抽象行为是非常可取的，这些行为可以有效地在众多任务和场景中转移。我们提出了一种使用分层混合潜在变量模型从数据中学习技能的方法。我们的方法利用了离散和连续潜在变量的多层次层次结构，以建模一组离散的抽象高级行为，同时允许它们在执行时的变化。我们在操作领域证明，该方法可以有效地将离线数据聚类为不同的、可执行的行为，同时保留了连续潜在变量模型的灵活性。所得到的技能可以转移到新任务、未见过的对象，以及从基于状态的策略到基于视觉的策略，与现有的基于技能和模仿的方法相比，显著提高了样本效率和渐进性能。我们还进行了进一步的分析，展示了技能在何时以及如何最为有益：它们鼓励有向探索以覆盖与任务相关的状态空间的大区域，使它们在具有挑战性的稀疏奖励设置中最为有效。",
        "领域": "机器人学习、技能迁移、模仿学习",
        "问题": "如何从数据中学习可重用的抽象行为，以便在多种任务和场景中有效转移。",
        "动机": "提高机器人在现实世界操作中的样本效率和渐进性能，特别是在稀疏奖励设置下。",
        "方法": "采用分层混合潜在变量模型，结合离散和连续潜在变量的多层次层次结构，从离线数据中聚类出可执行的抽象行为。",
        "关键词": [
            "技能迁移",
            "分层潜在变量模型",
            "模仿学习",
            "机器人操作",
            "稀疏奖励"
        ],
        "涉及的技术概念": {
            "分层混合潜在变量模型": "用于从数据中学习抽象行为的多层次模型，结合离散和连续潜在变量。",
            "技能迁移": "将学习到的行为应用于新任务和场景的能力，提高样本效率和性能。",
            "稀疏奖励设置": "在奖励信号稀少的环境中，通过有向探索覆盖状态空间的相关区域，提高学习效率。"
        },
        "success": true
    },
    {
        "order": 566,
        "title": "Learning Transferable Reward for Query Object Localization with Policy Adaptation",
        "html": "https://iclr.cc//virtual/2022/poster/6128",
        "abstract": "We propose a reinforcement learning based approach to query object localization, for which an agent is trained to localize objects of interest specified by a small exemplary set. We learn a transferable reward signal formulated using the exemplary set by ordinal metric learning. Our proposed method enables test-time policy adaptation to new environments where the reward signals are not readily available, and outperforms fine-tuning approaches that are limited to annotated images. In addition, the transferable reward allows repurposing the trained agent from one specific class to another class. Experiments on corrupted MNIST, CU-Birds, and COCO datasets demonstrate the effectiveness of our approach.",
        "conference": "ICLR",
        "中文标题": "学习可转移奖励用于查询对象定位的策略适应",
        "摘要翻译": "我们提出了一种基于强化学习的查询对象定位方法，该方法训练一个智能体来定位由一个小型示例集指定的感兴趣对象。我们通过学习序数度量来制定一个可转移的奖励信号。我们提出的方法能够在奖励信号不易获得的新环境中进行测试时的策略适应，并且优于仅限于注释图像的微调方法。此外，可转移的奖励允许将训练好的智能体从一个特定类别重新用于另一个类别。在损坏的MNIST、CU-Birds和COCO数据集上的实验证明了我们方法的有效性。",
        "领域": "强化学习、对象定位、计算机视觉",
        "问题": "如何在奖励信号不易获得的新环境中进行有效的对象定位",
        "动机": "开发一种能够在没有现成奖励信号的新环境中进行对象定位的方法，并能够跨类别重新使用训练好的智能体",
        "方法": "基于强化学习的方法，通过学习序数度量来制定可转移的奖励信号，实现测试时的策略适应",
        "关键词": [
            "强化学习",
            "对象定位",
            "可转移奖励",
            "策略适应",
            "序数度量学习"
        ],
        "涉及的技术概念": {
            "强化学习": "用于训练智能体定位感兴趣对象的方法",
            "可转移奖励": "通过学习序数度量制定的奖励信号，允许智能体在新环境中进行策略适应",
            "序数度量学习": "用于制定可转移奖励信号的技术，帮助智能体理解对象之间的相对重要性"
        },
        "success": true
    },
    {
        "order": 567,
        "title": "Learning Value Functions from Undirected State-only Experience",
        "html": "https://iclr.cc//virtual/2022/poster/6973",
        "abstract": "This paper tackles the problem of learning value functions from undirected state-only experience (state transitions without action labels i.e. (s,s',r) tuples). We first theoretically characterize the applicability of Q-learning in this setting. We show that tabular Q-learning in discrete Markov decision processes (MDPs) learns the same value function under any arbitrary refinement of the action space. This theoretical result motivates the design of Latent Action Q-learning or LAQ, an offline RL method that can learn effective value functions from state-only experience. Latent Action Q-learning (LAQ) learns value functions using Q-learning on discrete latent actions obtained through a latent-variable future prediction model. We show that LAQ can recover value functions that have high correlation with value functions learned using ground truth actions. Value functions learned using LAQ lead to sample efficient acquisition of goal-directed behavior, can be used with domain-specific low-level controllers, and facilitate transfer across embodiments. Our experiments in 5 environments ranging from 2D grid world to 3D visual navigation in realistic environments demonstrate the benefits of LAQ over simpler alternatives, imitation learning oracles, and competing methods.",
        "conference": "ICLR",
        "中文标题": "从无向状态经验中学习价值函数",
        "摘要翻译": "本文解决了从无向状态经验（即没有动作标签的状态转移，如(s,s',r)元组）中学习价值函数的问题。我们首先从理论上描述了在这种设置下Q学习的适用性。我们表明，在离散马尔可夫决策过程（MDPs）中，表格Q学习在任何动作空间的任意细化下都能学习到相同的价值函数。这一理论结果激励了潜在动作Q学习（LAQ）的设计，这是一种可以从状态经验中学习有效价值函数的离线强化学习方法。潜在动作Q学习（LAQ）通过潜在变量未来预测模型获得的离散潜在动作上使用Q学习来学习价值函数。我们表明，LAQ可以恢复与使用真实动作学习的价值函数高度相关的价值函数。使用LAQ学习的价值函数可以高效地获取目标导向行为样本，可以与特定领域的低级控制器一起使用，并促进跨实现的转移。我们在从2D网格世界到现实环境中3D视觉导航的5个环境中的实验证明了LAQ相对于更简单的替代方案、模仿学习预言机以及竞争方法的优势。",
        "领域": "强化学习、离线强化学习、视觉导航",
        "问题": "如何从无动作标签的状态转移中学习有效的价值函数",
        "动机": "探索在缺乏动作标签的情况下，通过状态转移学习价值函数的可能性及其应用",
        "方法": "提出潜在动作Q学习（LAQ），一种利用潜在变量未来预测模型从状态经验中学习价值函数的离线强化学习方法",
        "关键词": [
            "潜在动作Q学习",
            "离线强化学习",
            "价值函数学习",
            "状态转移",
            "视觉导航"
        ],
        "涉及的技术概念": {
            "潜在动作Q学习（LAQ）": "一种从状态经验中学习价值函数的离线强化学习方法，通过潜在变量未来预测模型获得的离散潜在动作上使用Q学习",
            "马尔可夫决策过程（MDPs）": "用于建模决策过程的数学框架，其中决策的结果部分由决策者控制，部分由随机性决定",
            "价值函数": "在强化学习中，用于评估在给定状态下采取特定动作的长期回报的函数"
        },
        "success": true
    },
    {
        "order": 568,
        "title": "Learning Versatile Neural Architectures by Propagating Network Codes",
        "html": "https://iclr.cc//virtual/2022/poster/6377",
        "abstract": "This work explores how to design a single neural network capable of adapting to multiple heterogeneous vision tasks, such as image segmentation, 3D detection, and video recognition. This goal is challenging because both network architecture search (NAS) spaces and methods in different tasks are inconsistent. We solve this challenge from both sides. We first introduce a unified design space for multiple tasks and build a multitask NAS benchmark (NAS-Bench-MR) on many widely used datasets, including ImageNet, Cityscapes, KITTI, and HMDB51. We further propose Network Coding Propagation (NCP), which back-propagates gradients of neural predictors to directly update architecture codes along the desired gradient directions to solve various tasks. In this way, optimal architecture configurations can be found by NCP in our large search space in seconds.Unlike prior arts of NAS that typically focus on a single task, NCP has several unique benefits. (1) NCP transforms architecture optimization from data-driven to architecture-driven, enabling joint search an architecture among multitasks with different data distributions. (2) NCP learns from network codes but not original data, enabling it to update the architecture efficiently across datasets. (3) In addition to our NAS-Bench-MR, NCP performs well on other NAS benchmarks, such as NAS-Bench-201. (4) Thorough studies of NCP on inter-, cross-, and intra-tasks highlight the importance of cross-task neural architecture design, i.e., multitask neural architectures and architecture transferring between different tasks. Code is available at https://github.com/dingmyu/NCP.",
        "conference": "ICLR",
        "中文标题": "通过学习传播网络代码来学习多功能神经架构",
        "摘要翻译": "本研究探讨如何设计一个能够适应多种异构视觉任务的单一神经网络，如图像分割、3D检测和视频识别。这一目标具有挑战性，因为不同任务的网络架构搜索（NAS）空间和方法不一致。我们从两方面解决这一挑战。首先，我们为多任务引入了一个统一的设计空间，并在许多广泛使用的数据集上建立了一个多任务NAS基准（NAS-Bench-MR），包括ImageNet、Cityscapes、KITTI和HMDB51。我们进一步提出了网络编码传播（NCP），它通过反向传播神经预测器的梯度，直接沿着期望的梯度方向更新架构代码，以解决各种任务。这样，NCP可以在我们的大搜索空间中几秒钟内找到最优架构配置。与通常专注于单一任务的现有NAS技术不同，NCP有几个独特的优势。（1）NCP将架构优化从数据驱动转变为架构驱动，使得能够在不同数据分布的多任务中联合搜索架构。（2）NCP从网络代码而非原始数据中学习，使其能够跨数据集高效更新架构。（3）除了我们的NAS-Bench-MR，NCP在其他NAS基准测试中也表现良好，如NAS-Bench-201。（4）对NCP在任务间、跨任务和任务内的深入研究强调了跨任务神经架构设计的重要性，即多任务神经架构和不同任务间的架构迁移。代码可在https://github.com/dingmyu/NCP获取。",
        "领域": "神经网络架构搜索、多任务学习、计算机视觉",
        "问题": "设计一个能够适应多种异构视觉任务的单一神经网络",
        "动机": "解决不同视觉任务间网络架构搜索空间和方法不一致的挑战，实现多任务间的架构共享和迁移",
        "方法": "引入统一的多任务设计空间和NAS基准，提出网络编码传播（NCP）方法，通过反向传播梯度直接更新架构代码",
        "关键词": [
            "神经网络架构搜索",
            "多任务学习",
            "网络编码传播",
            "计算机视觉",
            "架构迁移"
        ],
        "涉及的技术概念": {
            "网络架构搜索（NAS）": "用于自动设计神经网络架构的技术，本研究中扩展到多任务场景",
            "网络编码传播（NCP）": "通过反向传播神经预测器的梯度直接更新架构代码的方法，实现跨任务的高效架构优化",
            "多任务学习": "同时学习多个相关任务以提高模型泛化能力的技术，本研究通过统一架构设计空间实现"
        },
        "success": true
    },
    {
        "order": 569,
        "title": "Learning Vision-Guided Quadrupedal Locomotion End-to-End with Cross-Modal Transformers",
        "html": "https://iclr.cc//virtual/2022/poster/6919",
        "abstract": "We propose to address quadrupedal locomotion tasks using Reinforcement Learning (RL) with a Transformer-based model that learns to combine proprioceptive information and high-dimensional depth sensor inputs. While learning-based locomotion has made great advances using RL, most methods still rely on domain randomization for training blind agents that generalize to challenging terrains. Our key insight is that proprioceptive states only offer contact measurements for immediate reaction, whereas an agent equipped with visual sensory observations can learn to proactively maneuver environments with obstacles and uneven terrain by anticipating changes in the environment many steps ahead. In this paper, we introduce LocoTransformer, an end-to-end RL method that leverages both proprioceptive states and visual observations for locomotion control. We evaluate our method in challenging simulated environments with different obstacles and uneven terrain. We transfer our learned policy from simulation to a real robot by running it indoor and in-the-wild with unseen obstacles and terrain. Our method not only significantly improves over baselines, but also achieves far better generalization performance, especially when transferred to the real robot. Our project page with videos is at https://rchalyang.github.io/LocoTransformer/.",
        "conference": "ICLR",
        "中文标题": "学习视觉引导的四足运动端到端与跨模态变换器",
        "摘要翻译": "我们提出使用强化学习（RL）与基于变换器的模型来解决四足运动任务，该模型学习结合本体感受信息和高维深度传感器输入。尽管基于学习的运动在使用RL方面取得了巨大进展，但大多数方法仍然依赖于领域随机化来训练能够推广到具有挑战性地形的盲代理。我们的关键见解是，本体感受状态仅提供用于即时反应的接触测量，而配备视觉感官观察的代理可以通过提前许多步预测环境变化来学习主动操纵具有障碍物和不平地形的环境。在本文中，我们介绍了LocoTransformer，一种端到端的RL方法，利用本体感受状态和视觉观察进行运动控制。我们在具有不同障碍物和不平地形的挑战性模拟环境中评估我们的方法。通过将我们学习到的策略从模拟转移到真实机器人，在室内和野外运行，面对未见过的障碍物和地形。我们的方法不仅显著优于基线，而且实现了更好的泛化性能，特别是在转移到真实机器人时。我们的项目页面与视频位于https://rchalyang.github.io/LocoTransformer/。",
        "领域": "机器人运动控制、强化学习、计算机视觉与机器人结合",
        "问题": "如何有效地结合本体感受信息和视觉输入，以提升四足机器人在复杂地形中的运动能力和泛化性能。",
        "动机": "现有的基于学习的运动方法大多依赖于领域随机化训练盲代理，缺乏对环境变化的预见性，限制了在复杂地形中的运动表现和泛化能力。",
        "方法": "提出LocoTransformer，一种端到端的强化学习方法，利用变换器模型结合本体感受状态和视觉观察，以实现对复杂地形的主动操纵和更好的泛化性能。",
        "关键词": [
            "四足运动",
            "强化学习",
            "跨模态变换器",
            "视觉引导",
            "机器人控制"
        ],
        "涉及的技术概念": {
            "强化学习（RL）": "用于训练机器人运动策略，通过奖励机制优化运动控制。",
            "变换器模型": "用于处理和分析来自本体感受器和视觉传感器的多模态输入，实现信息的有效融合。",
            "端到端学习": "直接从输入到输出学习控制策略，无需手动设计中间表示或特征提取步骤。"
        },
        "success": true
    },
    {
        "order": 570,
        "title": "Learning Weakly-supervised Contrastive Representations",
        "html": "https://iclr.cc//virtual/2022/poster/6060",
        "abstract": "We argue that a form of the valuable information provided by the auxiliary information is its implied data clustering information. For instance, considering hashtags as auxiliary information, we can hypothesize that an Instagram image will be semantically more similar with the same hashtags. With this intuition, we present a two-stage weakly-supervised contrastive learning approach. The first stage is to cluster data according to its auxiliary information. The second stage is to learn similar representations within the same cluster and dissimilar representations for data from different clusters. Our empirical experiments suggest the following three contributions. First, compared to conventional self-supervised representations, the auxiliary-information-infused representations bring the performance closer to the supervised representations, which use direct downstream labels as supervision signals. Second, our approach performs the best in most cases, when comparing our approach with other baseline representation learning methods that also leverage auxiliary data information. Third, we show that our approach also works well with unsupervised constructed clusters (e.g., no auxiliary information), resulting in a strong unsupervised representation learning approach. ",
        "conference": "ICLR",
        "中文标题": "学习弱监督对比表示",
        "摘要翻译": "我们认为辅助信息提供的一种有价值信息是其隐含的数据聚类信息。例如，将标签视为辅助信息，我们可以假设带有相同标签的Instagram图像在语义上更为相似。基于这一直觉，我们提出了一种两阶段的弱监督对比学习方法。第一阶段是根据辅助信息对数据进行聚类。第二阶段是学习同一聚类内数据的相似表示和不同聚类间数据的不相似表示。我们的实证实验提出了以下三点贡献。首先，与传统的自监督表示相比，融入辅助信息的表示使性能更接近使用直接下游标签作为监督信号的监督表示。其次，在比较我们的方法与其他同样利用辅助数据信息的基线表示学习方法时，我们的方法在大多数情况下表现最佳。第三，我们展示了我们的方法在无监督构建的聚类（例如，无辅助信息）下也表现良好，从而成为一种强大的无监督表示学习方法。",
        "领域": "自监督学习",
        "问题": "如何利用辅助信息提升表示学习的性能",
        "动机": "探索辅助信息中隐含的数据聚类信息对提升表示学习性能的潜力",
        "方法": "提出一种两阶段的弱监督对比学习方法，首先根据辅助信息聚类数据，然后学习聚类内相似和聚类间不相似的表示",
        "关键词": [
            "弱监督学习",
            "对比学习",
            "表示学习",
            "数据聚类",
            "辅助信息"
        ],
        "涉及的技术概念": {
            "弱监督对比学习": "一种利用辅助信息进行数据表示学习的方法，旨在通过聚类信息增强表示的区分能力",
            "数据聚类": "根据辅助信息将数据分组，为对比学习提供正负样本对",
            "表示学习": "学习数据的低维表示，以捕捉数据间的语义相似性"
        },
        "success": true
    },
    {
        "order": 571,
        "title": "Learning with Noisy Labels Revisited: A Study Using Real-World Human Annotations",
        "html": "https://iclr.cc//virtual/2022/poster/7085",
        "abstract": "Existing research on learning with noisy labels mainly focuses on synthetic label noise. The synthetic noise, though has clean structures which greatly enabled statistical analyses, often fails to model the real-world noise patterns. The recent literature has observed several efforts to offer real-world noisy datasets, e.g., Food-101N, WebVision, and Clothing1M. Yet the existing efforts suffer from two caveats: firstly, the lack of ground-truth verification makes it hard to theoretically study the property and treatment of real-world label noise. Secondly, these efforts are often of large scales, which may result in unfair comparisons of robust methods within reasonable and accessible computation power. To better understand real-world label noise, it is important to establish controllable, easy-to-use, and moderate-sized real-world noisy datasets with both ground-truth and noisy labels. This work presents two new benchmark datasets, which we name as CIFAR-10N, CIFAR-100N (jointly we call them CIFAR-N), equipping the training datasets of CIFAR-10 and CIFAR-100 with human-annotated real-world noisy labels we collected from Amazon Mechanical Turk. We quantitatively and qualitatively show that real-world noisy labels follow an instance-dependent pattern rather than the classically assumed and adopted ones (e.g.,  class-dependent label noise). We then initiate an effort to benchmarking a subset of the existing solutions using  CIFAR-10N and CIFAR-100N. We further proceed to study the memorization of correct and wrong predictions, which further illustrates the difference between human noise and class-dependent synthetic noise. We show indeed the real-world noise patterns impose new and outstanding challenges as compared to synthetic label noise. These observations require us to rethink the treatment of noisy labels, and we hope the availability of these two datasets would facilitate the development and evaluation of future learning with noisy label solutions. The corresponding datasets and the leaderboard are available at http://noisylabels.com. ",
        "conference": "ICLR",
        "中文标题": "重新审视带噪声标签的学习：一项使用真实世界人类标注的研究",
        "摘要翻译": "现有的带噪声标签学习研究主要集中在合成标签噪声上。尽管合成噪声具有清晰的结构，极大地促进了统计分析，但往往无法模拟真实世界的噪声模式。最近的文献中已经观察到了几项提供真实世界噪声数据集的努力，例如Food-101N、WebVision和Clothing1M。然而，现有的努力存在两个问题：首先，缺乏真实标签的验证使得难以从理论上研究真实世界标签噪声的性质和处理。其次，这些努力往往规模庞大，可能导致在合理和可访问的计算能力范围内对鲁棒方法进行不公平的比较。为了更好地理解真实世界的标签噪声，重要的是建立可控、易于使用且中等规模的带有真实标签和噪声标签的真实世界噪声数据集。这项工作提出了两个新的基准数据集，我们称之为CIFAR-10N和CIFAR-100N（我们统称为CIFAR-N），为CIFAR-10和CIFAR-100的训练数据集配备了从Amazon Mechanical Turk收集的人类标注的真实世界噪声标签。我们定量和定性地表明，真实世界的噪声标签遵循实例依赖的模式，而不是经典假设和采用的模式（例如，类依赖的标签噪声）。然后，我们开始努力使用CIFAR-10N和CIFAR-100N对现有解决方案的一个子集进行基准测试。我们进一步研究了正确和错误预测的记忆，这进一步说明了人类噪声和类依赖合成噪声之间的差异。我们确实表明，与合成标签噪声相比，真实世界的噪声模式提出了新的和突出的挑战。这些观察要求我们重新思考噪声标签的处理，我们希望这两个数据集的可用性将促进未来带噪声标签学习解决方案的开发和评估。相应的数据集和排行榜可在http://noisylabels.com上找到。",
        "领域": "深度学习噪声标签处理、计算机视觉数据集构建、机器学习鲁棒性研究",
        "问题": "如何更好地理解和处理真实世界中的标签噪声问题",
        "动机": "现有研究主要依赖合成噪声，无法准确模拟真实世界的噪声模式，且缺乏中等规模、易于使用的真实噪声数据集",
        "方法": "构建了两个新的基准数据集CIFAR-10N和CIFAR-100N，包含人类标注的真实噪声标签，并用于评估现有解决方案",
        "关键词": [
            "噪声标签学习",
            "真实世界噪声",
            "数据集构建",
            "实例依赖噪声",
            "鲁棒性评估"
        ],
        "涉及的技术概念": {
            "实例依赖噪声": "真实世界噪声标签遵循的模式，与传统的类依赖噪声不同，更复杂且难以处理",
            "基准数据集": "CIFAR-10N和CIFAR-100N数据集，用于评估带噪声标签学习方法的性能",
            "鲁棒性评估": "通过新数据集对现有带噪声标签学习解决方案进行测试，评估其在真实噪声下的表现"
        },
        "success": true
    },
    {
        "order": 572,
        "title": "Learn Locally, Correct Globally: A Distributed Algorithm for Training Graph Neural Networks",
        "html": "https://iclr.cc//virtual/2022/poster/7152",
        "abstract": "Despite the recent success of Graph Neural Networks (GNNs), training GNNs on large graphs remains challenging. The limited resource capacities of the existing servers, the dependency between nodes in a graph, and the privacy concern due to the centralized storage and model learning have spurred the need to design an effective distributed algorithm for GNN training. However, existing distributed GNN training methods impose either excessive communication costs or large memory overheads that hinders their scalability. To overcome these issues, we propose a communication-efficient distributed GNN training technique named $\\text{\\textit{Learn Locally, Correct Globally}}$ (LLCG). To reduce the communication and memory overhead, each local machine in LLCG first trains a GNN on its local data by ignoring the dependency between nodes among different machines, then sends the locally trained model to the server for periodic model averaging. However, ignoring node dependency could result in significant performance degradation. To solve the performance degradation, we propose to apply $\\text{\\textit{Global Server Corrections}}$ on the server to refine the locally learned models. We rigorously analyze the convergence of distributed methods  with periodic model averaging for training GNNs and show that naively applying periodic model averaging but ignoring the dependency between nodes will suffer from an irreducible residual error. However, this residual error can be eliminated  by utilizing the proposed global corrections to entail fast convergence rate. Extensive experiments on real-world datasets show that LLCG can significantly improve the efficiency without hurting the performance.",
        "conference": "ICLR",
        "中文标题": "局部学习，全局修正：一种训练图神经网络的分布式算法",
        "摘要翻译": "尽管图神经网络（GNNs）近年来取得了成功，但在大图上训练GNNs仍然具有挑战性。现有服务器的有限资源容量、图中节点间的依赖关系，以及由于集中式存储和模型学习引起的隐私问题，都促使设计一种有效的分布式算法用于GNN训练变得必要。然而，现有的分布式GNN训练方法要么带来过高的通信成本，要么产生大的内存开销，这阻碍了它们的可扩展性。为了克服这些问题，我们提出了一种通信高效的分布式GNN训练技术，名为‘局部学习，全局修正’（LLCG）。为了减少通信和内存开销，LLCG中的每台本地机器首先通过忽略不同机器间节点依赖关系的方式在其本地数据上训练一个GNN，然后将本地训练好的模型发送到服务器进行周期性模型平均。然而，忽略节点依赖可能导致显著的性能下降。为了解决性能下降问题，我们提出在服务器上应用‘全局服务器修正’来优化本地学习到的模型。我们严格分析了用于训练GNNs的周期性模型平均的分布式方法的收敛性，并表明，简单地应用周期性模型平均而忽略节点间的依赖关系将遭受不可约的残差误差。然而，通过利用提出的全局修正可以消除这一残差误差，从而实现快速收敛速率。在真实世界数据集上的大量实验表明，LLCG可以显著提高效率而不损害性能。",
        "领域": "图神经网络、分布式学习、隐私保护学习",
        "问题": "在大图上训练图神经网络时面临的通信成本高、内存开销大以及隐私问题",
        "动机": "设计一种高效的分布式算法，以解决现有方法在训练大规模图神经网络时的可扩展性和隐私问题",
        "方法": "提出了一种名为‘局部学习，全局修正’（LLCG）的通信高效分布式训练技术，通过局部训练和周期性模型平均减少通信和内存开销，并通过全局修正优化模型性能",
        "关键词": [
            "图神经网络",
            "分布式训练",
            "通信效率",
            "模型平均",
            "全局修正"
        ],
        "涉及的技术概念": {
            "周期性模型平均": "在分布式训练中，定期将各本地模型的参数进行平均，以减少通信开销和内存使用",
            "全局服务器修正": "在服务器端应用的技术，用于修正因忽略节点依赖关系而导致的模型性能下降，确保模型的准确性和收敛性",
            "残差误差": "在忽略节点依赖关系的情况下，周期性模型平均方法中无法避免的误差，通过全局修正可以消除"
        },
        "success": true
    },
    {
        "order": 573,
        "title": "Leveraging Automated Unit Tests for Unsupervised Code Translation",
        "html": "https://iclr.cc//virtual/2022/poster/6467",
        "abstract": "With little to no parallel data available for programming languages, unsupervised methods are well-suited to source code translation. However, the majority of unsupervised machine translation approaches rely on back-translation, a method developed in the context of natural language translation and one that inherently involves training on noisy inputs. Unfortunately, source code is highly sensitive to small changes; a single token can result in compilation failures or erroneous programs, unlike natural languages where small inaccuracies may not change the meaning of a sentence. To address this issue, we propose to leverage an automated unit-testing system to filter out invalid translations, thereby creating a fully tested parallel corpus. We found that fine-tuning an unsupervised model with this filtered data set significantly reduces the noise in the translations so-generated, comfortably outperforming the state-of-the-art for all language pairs studied. In particular, for Java→Python and Python→C++ we outperform the best previous methods by more than 16% and 24% respectively, reducing the error rate by more than 35%.",
        "conference": "ICLR",
        "中文标题": "利用自动化单元测试进行无监督代码翻译",
        "摘要翻译": "在编程语言之间几乎没有或完全没有平行数据可用的情况下，无监督方法非常适合源代码翻译。然而，大多数无监督机器翻译方法依赖于回译，这是一种在自然语言翻译背景下开发的方法，其本质涉及在噪声输入上进行训练。不幸的是，源代码对小的变化高度敏感；单个标记可能导致编译失败或错误程序，这与自然语言不同，在自然语言中小的不准确可能不会改变句子的含义。为了解决这个问题，我们提出利用自动化单元测试系统来过滤掉无效的翻译，从而创建一个完全测试过的平行语料库。我们发现，用这个过滤后的数据集微调无监督模型显著减少了生成的翻译中的噪声，轻松超越了所有研究语言对的最先进技术。特别是，对于Java→Python和Python→C++，我们分别比之前的最佳方法高出16%和24%，将错误率降低了35%以上。",
        "领域": "代码翻译、无监督学习、软件工程",
        "问题": "源代码翻译中由于缺乏平行数据和源代码对微小变化的高度敏感性导致的翻译质量问题。",
        "动机": "解决无监督代码翻译中因回译方法产生的噪声输入问题，提高翻译准确性和程序正确性。",
        "方法": "利用自动化单元测试系统过滤无效翻译，创建测试过的平行语料库，并用其微调无监督模型。",
        "关键词": [
            "无监督代码翻译",
            "自动化单元测试",
            "平行语料库",
            "回译",
            "噪声过滤"
        ],
        "涉及的技术概念": {
            "无监督学习": "在缺乏标记数据的情况下，利用未标记数据学习数据的内在结构和模式。",
            "回译": "一种机器翻译方法，通过将源语言翻译成目标语言再翻译回源语言来生成平行数据。",
            "自动化单元测试": "自动执行的测试，用于验证代码单元的正确性，此处用于过滤无效的代码翻译。"
        },
        "success": true
    },
    {
        "order": 574,
        "title": "Leveraging unlabeled data to predict out-of-distribution performance",
        "html": "https://iclr.cc//virtual/2022/poster/6847",
        "abstract": "Real-world machine learning deployments are characterized by mismatches between the source (training) and target (test) distributionsthat may cause performance drops. In this work, we investigate methods for predicting the target domain accuracy using only labeled source data and unlabeled target data. We propose Average Thresholded Confidence (ATC), a practical method that learns a \\emph{threshold} on the model's confidence, predicting accuracy as the fraction of unlabeled examples for which model confidence exceeds that threshold. ATC outperforms previous methods across several model architectures, types of distribution shifts (e.g., due to synthetic corruptions, dataset reproduction, or novel subpopulations), and datasets (\\textsc{Wilds}-FMoW, ImageNet, \\breeds, CIFAR, and MNIST).  In our experiments, ATC estimates target performance $2\\text{--}4\\times$ more accurately than prior methods. We also explore the theoretical foundations of the problem, proving that, in general, identifying the accuracy is just as hard as identifying the optimal predictor and thus, the efficacy of any method rests upon (perhaps unstated) assumptions on the nature of the shift. Finally, analyzing our method on some toy distributions, we provide insights concerning when it works.",
        "conference": "ICLR",
        "中文标题": "利用未标记数据预测分布外性能",
        "摘要翻译": "现实世界中的机器学习部署常常面临源（训练）分布与目标（测试）分布不匹配的问题，这可能导致性能下降。在本研究中，我们探索了仅使用标记的源数据和未标记的目标数据来预测目标域准确度的方法。我们提出了平均阈值置信度（ATC），这是一种实用的方法，它在模型的置信度上学习一个阈值，预测准确度为模型置信度超过该阈值的未标记样本的比例。ATC在多种模型架构、分布偏移类型（如由于合成损坏、数据集再现或新子群体引起）和数据集（Wilds-FMoW、ImageNet、BREEDS、CIFAR和MNIST）上优于先前的方法。在我们的实验中，ATC对目标性能的估计比先前方法准确2到4倍。我们还探讨了该问题的理论基础，证明在一般情况下，识别准确度与识别最优预测器同样困难，因此，任何方法的有效性都依赖于（可能是未声明的）关于偏移性质的假设。最后，通过在一些简单分布上分析我们的方法，我们提供了关于其何时有效的见解。",
        "领域": "机器学习泛化能力、分布偏移适应、无监督学习",
        "问题": "如何仅使用标记的源数据和未标记的目标数据来预测目标域的准确度",
        "动机": "解决源分布与目标分布不匹配导致的性能下降问题",
        "方法": "提出平均阈值置信度（ATC）方法，通过在模型置信度上学习阈值来预测目标域准确度",
        "关键词": [
            "分布偏移",
            "模型置信度",
            "无监督学习",
            "性能预测",
            "机器学习泛化"
        ],
        "涉及的技术概念": {
            "平均阈值置信度（ATC）": "一种通过模型置信度阈值预测目标域准确度的方法",
            "分布偏移": "源分布与目标分布之间的不匹配，影响模型性能",
            "模型置信度": "模型对其预测结果的确定性度量，用于ATC方法中预测准确度"
        },
        "success": true
    },
    {
        "order": 575,
        "title": "LFPT5: A Unified Framework for Lifelong Few-shot Language Learning Based on Prompt Tuning of T5",
        "html": "https://iclr.cc//virtual/2022/poster/6632",
        "abstract": "Existing approaches to lifelong language learning rely on plenty of labeled data for learning a new task, which is hard to obtain in most real scenarios. Considering that humans can continually learn new tasks from a handful of examples, we expect the models also to be able to generalize well on new few-shot tasks without forgetting the previous ones. In this work, we define this more challenging yet practical problem as Lifelong Few-shot Language Learning (LFLL) and propose a unified framework for it based on prompt tuning of T5. Our framework called LFPT5 takes full advantage of PT's strong few-shot learning ability, and simultaneously trains the model as a task solver and a data generator. Before learning a new domain of the same task type, LFPT5 generates pseudo (labeled) samples of previously learned domains, and later gets trained on those samples to alleviate forgetting of previous knowledge as it learns the new domain. In addition, a KL divergence loss is minimized to achieve label consistency between the previous and the current model. While adapting to a new task type, LFPT5 includes and tunes additional prompt embeddings for the new task. With extensive experiments, we demonstrate that LFPT5 can be applied to various different types of tasks and significantly outperform previous methods in different LFLL settings.",
        "conference": "ICLR",
        "中文标题": "LFPT5：基于T5提示调用的终身少样本语言学习统一框架",
        "摘要翻译": "现有的终身语言学习方法依赖于大量标记数据来学习新任务，这在实际场景中难以获得。考虑到人类可以从少量例子中持续学习新任务，我们也期望模型能够在新的少样本任务上表现出良好的泛化能力，同时不忘记之前学到的任务。在这项工作中，我们将这一更具挑战性但更实际的问题定义为终身少样本语言学习（LFLL），并提出了一个基于T5提示调用的统一框架。我们的框架LFPT5充分利用了提示调用（PT）强大的少样本学习能力，同时将模型训练为任务解决者和数据生成器。在学习同一任务类型的新领域之前，LFPT5生成先前学习领域的伪（标记）样本，随后在这些样本上进行训练，以在学习新领域时减轻对先前知识的遗忘。此外，通过最小化KL散度损失来实现先前模型与当前模型之间的标签一致性。在适应新任务类型时，LFPT5包含并调整新任务的额外提示嵌入。通过大量实验，我们证明LFPT5可以应用于各种不同类型的任务，并在不同的LFLL设置中显著优于以前的方法。",
        "领域": "自然语言处理与视觉结合, 少样本学习, 终身学习",
        "问题": "如何在少样本条件下实现终身语言学习，同时避免遗忘先前学到的知识",
        "动机": "解决现有终身语言学习方法需要大量标记数据的问题，模仿人类从少量例子中学习新任务的能力",
        "方法": "基于T5的提示调用框架，结合任务解决和数据生成，利用伪样本和KL散度损失减轻遗忘",
        "关键词": [
            "终身学习",
            "少样本学习",
            "提示调用",
            "T5模型",
            "KL散度"
        ],
        "涉及的技术概念": {
            "提示调用（Prompt Tuning）": "利用提示调用技术优化T5模型，以适应少样本学习任务",
            "KL散度损失": "用于确保模型在学习新任务时保持对先前任务知识的记忆，通过最小化新旧模型预测之间的差异",
            "伪样本生成": "生成先前学习任务的伪标记样本，用于模型训练以减轻知识遗忘"
        },
        "success": true
    },
    {
        "order": 576,
        "title": "LIGS: Learnable Intrinsic-Reward Generation Selection for Multi-Agent Learning ",
        "html": "https://iclr.cc//virtual/2022/poster/6617",
        "abstract": "Efficient exploration is important for reinforcement learners (RL) to achieve high rewards. In multi-agent systems, coordinated exploration and behaviour is critical for agents to jointly achieve optimal outcomes. In this paper, we introduce a new general framework for improving coordination and performance of multi-agent reinforcement learners (MARL). Our framework, named Learnable Intrinsic-Reward Generation Selection algorithm (LIGS) introduces an adaptive learner, Generator that observes the agents and learns to construct intrinsic rewards online that coordinate the agents’ joint exploration and joint behaviour. Using a novel combination of reinforcement learning (RL) and switching controls, LIGS determines the best states to learn to add intrinsic rewards which leads to a highly efficient learning process. LIGS can subdivide complex tasks making them easier to solve and enables systems of RL agents to quickly solve environments with sparse rewards. LIGS can seamlessly adopt existing multi-agent RL algorithms and our theory shows that it ensures convergence to joint policies that deliver higher system performance. We demonstrate the superior performance of the LIGS framework in challenging tasks in Foraging and StarCraft II and show LIGS is capable of tackling tasks previously unsolvable by MARL methods.",
        "conference": "ICLR",
        "中文标题": "LIGS：多智能体学习中可学习的内部奖励生成选择",
        "摘要翻译": "高效的探索对于强化学习者（RL）获得高奖励至关重要。在多智能体系统中，协调的探索和行为对于智能体共同实现最优结果至关重要。在本文中，我们引入了一个新的通用框架，用于提高多智能体强化学习者（MARL）的协调和性能。我们的框架名为可学习的内部奖励生成选择算法（LIGS），引入了一个自适应学习者——生成器，它观察智能体并学习在线构建内部奖励，以协调智能体的联合探索和联合行为。通过结合强化学习（RL）和切换控制的新颖方法，LIGS确定了学习添加内部奖励的最佳状态，从而实现了高效的学习过程。LIGS可以细分复杂任务，使其更易于解决，并使RL智能体系统能够快速解决奖励稀疏的环境。LIGS可以无缝采用现有的多智能体RL算法，我们的理论表明，它确保了收敛于提供更高系统性能的联合策略。我们在Foraging和StarCraft II的挑战性任务中展示了LIGS框架的卓越性能，并显示LIGS能够解决以前MARL方法无法解决的任务。",
        "领域": "多智能体强化学习",
        "问题": "提高多智能体系统中的协调探索和行为效率",
        "动机": "为了解决多智能体系统中协调探索和行为效率低下的问题，提高系统性能",
        "方法": "引入可学习的内部奖励生成选择算法（LIGS），结合强化学习和切换控制，动态生成内部奖励以协调智能体的行为",
        "关键词": [
            "多智能体强化学习",
            "内部奖励",
            "协调探索",
            "切换控制",
            "自适应学习"
        ],
        "涉及的技术概念": {
            "可学习的内部奖励生成选择算法（LIGS）": "一种自适应学习框架，用于在线构建内部奖励，以协调多智能体的联合探索和行为",
            "强化学习（RL）": "用于训练智能体在环境中通过试错学习最优行为策略的机器学习方法",
            "切换控制": "一种控制策略，用于在不同状态或条件下切换控制方法，以优化系统性能"
        },
        "success": true
    },
    {
        "order": 577,
        "title": "Likelihood Training of Schrödinger Bridge using Forward-Backward SDEs Theory",
        "html": "https://iclr.cc//virtual/2022/poster/6506",
        "abstract": "Schrödinger Bridge (SB) is an entropy-regularized optimal transport problem that has received increasing attention in deep generative modeling for its mathematical flexibility compared to the Scored-based Generative Model (SGM). However, it remains unclear whether the optimization principle of SB relates to the modern training of deep generative models, which often rely on constructing log-likelihood objectives.This raises questions on the suitability of SB models as a principled alternative for generative applications. In this work, we present a novel computational framework for likelihood training of SB models grounded on Forward-Backward Stochastic Differential Equations Theory – a mathematical methodology appeared in stochastic optimal control that transforms the optimality condition of SB into a set of SDEs. Crucially, these SDEs can be used to construct the likelihood objectives for SB that, surprisingly, generalizes the ones for SGM as special cases. This leads to a new optimization principle that inherits the same SB optimality yet without losing applications of modern generative training techniques, and we show that the resulting training algorithm achieves comparable results on generating realistic images on MNIST, CelebA, and CIFAR10. Our code is available at https://github.com/ghliu/SB-FBSDE.",
        "conference": "ICLR",
        "中文标题": "基于前向后向随机微分方程理论的薛定谔桥似然训练",
        "摘要翻译": "薛定谔桥（SB）是一种熵正则化的最优传输问题，与基于分数的生成模型（SGM）相比，因其数学上的灵活性在深度生成建模中受到越来越多的关注。然而，SB的优化原理是否与现代深度生成模型的训练相关仍不明确，后者通常依赖于构建对数似然目标。这引发了关于SB模型作为生成应用原则性替代的适用性问题。在本工作中，我们提出了一种基于前向后向随机微分方程理论的新计算框架，用于SB模型的似然训练——这是一种出现在随机最优控制中的数学方法，将SB的最优条件转化为一组随机微分方程。关键的是，这些随机微分方程可用于构建SB的似然目标，令人惊讶的是，它们将SGM的似然目标作为特例进行推广。这导致了一种新的优化原则，它继承了相同的SB最优性，同时不失去现代生成训练技术的应用，并且我们展示了在MNIST、CelebA和CIFAR10上生成逼真图像的训练算法取得了可比较的结果。我们的代码可在https://github.com/ghliu/SB-FBSDE获取。",
        "领域": "深度生成模型, 最优传输, 随机微分方程",
        "问题": "探索薛定谔桥（SB）模型在深度生成模型中的优化原理及其与现代对数似然训练方法的关联性。",
        "动机": "解决SB模型作为生成应用原则性替代的适用性问题，并探索其在现代深度生成训练技术中的应用潜力。",
        "方法": "提出了一种基于前向后向随机微分方程理论的新计算框架，用于SB模型的似然训练，通过将SB的最优条件转化为随机微分方程来构建似然目标。",
        "关键词": [
            "薛定谔桥",
            "随机微分方程",
            "深度生成模型",
            "最优传输",
            "似然训练"
        ],
        "涉及的技术概念": {
            "薛定谔桥": "一种熵正则化的最优传输问题，用于深度生成建模。",
            "前向后向随机微分方程理论": "一种数学方法，用于将薛定谔桥的最优条件转化为随机微分方程，进而构建似然目标。",
            "似然训练": "通过构建对数似然目标来训练深度生成模型的方法，本文将其应用于薛定谔桥模型。"
        },
        "success": true
    },
    {
        "order": 578,
        "title": "Linking Emergent and Natural Languages via Corpus Transfer",
        "html": "https://iclr.cc//virtual/2022/poster/6044",
        "abstract": "The study of language emergence aims to understand how human languages are shaped by perceptual grounding and communicative intent. Computational approaches to emergent communication (EC) predominantly consider referential games in limited domains and analyze the learned protocol within the game framework. As a result, it remains unclear how the emergent languages from these settings connect to natural languages or provide benefits in real-world language processing tasks, where statistical models trained on large text corpora dominate. In this work, we propose a novel way to establish such a link by corpus transfer, i.e. pretraining on a corpus of emergent language for downstream natural language tasks, which is in contrast to prior work that directly transfers speaker and listener parameters. Our approach showcases non-trivial transfer benefits for two different tasks – language modeling and image captioning. For example, in a low-resource setup (modeling 2 million natural language tokens), pre-training on an emergent language corpus with just 2 million tokens reduces model perplexity by 24.6% on average across ten natural languages. We also introduce a novel metric to predict the transferability of an emergent language by translating emergent messages to natural language captions grounded on the same images. We find that our translation-based metric highly correlates with the downstream performance on modeling natural languages (for instance $\\rho = 0.83$ on Hebrew), while topographic similarity, a popular metric in previous works, shows surprisingly low correlation ($\\rho = 0.003$), hinting that simple properties like attribute disentanglement from synthetic domains might not capture the full complexities of natural language. Our findings also indicate potential benefits of moving language emergence forward with natural language resources and models.",
        "conference": "ICLR",
        "中文标题": "通过语料库迁移连接涌现语言与自然语言",
        "摘要翻译": "语言涌现的研究旨在理解人类语言如何被感知基础和交际意图所塑造。涌现通信（EC）的计算方法主要考虑有限领域中的指称游戏，并在游戏框架内分析学习到的协议。因此，这些设置中涌现的语言如何与自然语言连接或在现实世界语言处理任务中提供优势仍不明确，在这些任务中，基于大型文本语料库训练的统计模型占主导地位。在这项工作中，我们提出了一种通过语料库迁移建立这种连接的新方法，即在下游自然语言任务上预训练涌现语言语料库，这与之前直接迁移说话者和听者参数的工作形成对比。我们的方法展示了两种不同任务——语言建模和图像字幕——的非平凡迁移优势。例如，在低资源设置（建模200万自然语言标记）中，仅用200万标记的涌现语言语料库进行预训练，平均在十种自然语言上将模型困惑度降低了24.6%。我们还引入了一种新的度量标准，通过将涌现消息翻译为基于相同图像的自然语言字幕，来预测涌现语言的可迁移性。我们发现，我们基于翻译的度量标准与自然语言建模的下游性能高度相关（例如希伯来语上的ρ=0.83），而先前工作中流行的度量标准——地形相似性显示出令人惊讶的低相关性（ρ=0.003），暗示从合成领域解耦属性等简单特性可能无法捕捉自然语言的全部复杂性。我们的发现还表明，利用自然语言资源和模型推进语言涌现研究具有潜在优势。",
        "领域": "自然语言处理与视觉结合, 语言模型, 图像字幕",
        "问题": "如何将涌现语言与自然语言连接，并在现实世界的语言处理任务中提供优势",
        "动机": "探索涌现语言与自然语言之间的联系，以及如何利用这种联系提升语言处理任务的性能",
        "方法": "通过语料库迁移的方法，在下游自然语言任务上预训练涌现语言语料库，并引入新的度量标准预测涌现语言的可迁移性",
        "关键词": [
            "语料库迁移",
            "涌现语言",
            "自然语言处理",
            "语言模型",
            "图像字幕"
        ],
        "涉及的技术概念": {
            "语料库迁移": "在下游自然语言任务上预训练涌现语言语料库，以建立涌现语言与自然语言之间的联系",
            "涌现语言": "通过计算模型在特定任务中自发形成的通信协议，研究其与自然语言的连接",
            "地形相似性": "先前工作中用于评估涌现语言与自然语言相似性的度量标准，本研究发现其与下游任务性能相关性低"
        },
        "success": true
    },
    {
        "order": 579,
        "title": "Lipschitz-constrained Unsupervised Skill Discovery",
        "html": "https://iclr.cc//virtual/2022/poster/6488",
        "abstract": "We study the problem of unsupervised skill discovery, whose goal is to learn a set of diverse and useful skills with no external reward. There have been a number of skill discovery methods based on maximizing the mutual information (MI) between skills and states. However, we point out that their MI objectives usually prefer static skills to dynamic ones, which may hinder the application for downstream tasks. To address this issue, we propose Lipschitz-constrained Skill Discovery (LSD), which encourages the agent to discover more diverse, dynamic, and far-reaching skills. Another benefit of LSD is that its learned representation function can be utilized for solving goal-following downstream tasks even in a zero-shot manner — i.e., without further training or complex planning. Through experiments on various MuJoCo robotic locomotion and manipulation environments, we demonstrate that LSD outperforms previous approaches in terms of skill diversity, state space coverage, and performance on seven downstream tasks including the challenging task of following multiple goals on Humanoid. Our code and videos are available at https://shpark.me/projects/lsd/.",
        "conference": "ICLR",
        "中文标题": "Lipschitz约束的无监督技能发现",
        "摘要翻译": "我们研究了无监督技能发现问题，其目标是在没有外部奖励的情况下学习一组多样且有用的技能。已有许多基于最大化技能与状态之间互信息（MI）的技能发现方法。然而，我们指出，它们的MI目标通常偏好静态技能而非动态技能，这可能阻碍下游任务的应用。为了解决这个问题，我们提出了Lipschitz约束的技能发现（LSD），鼓励智能体发现更多样、动态且影响深远的技能。LSD的另一个好处是其学习到的表示函数可以用于解决目标跟随的下游任务，甚至以零样本的方式——即无需进一步训练或复杂规划。通过在多种MuJoCo机器人运动和操作环境上的实验，我们证明LSD在技能多样性、状态空间覆盖率和七个下游任务（包括在Humanoid上跟随多个目标的挑战性任务）的性能上优于先前的方法。我们的代码和视频可在https://shpark.me/projects/lsd/获取。",
        "领域": "机器人学习、无监督学习、技能发现",
        "问题": "解决无监督技能发现中互信息目标偏好静态技能而非动态技能的问题",
        "动机": "鼓励智能体发现更多样、动态且影响深远的技能，以提升下游任务的适用性",
        "方法": "提出Lipschitz约束的技能发现（LSD）方法，通过约束技能发现的Lipschitz条件来促进多样性和动态性",
        "关键词": [
            "无监督学习",
            "技能发现",
            "Lipschitz约束",
            "机器人学习",
            "互信息最大化"
        ],
        "涉及的技术概念": {
            "互信息最大化": "用于技能发现的方法，通过最大化技能与状态之间的互信息来学习多样技能",
            "Lipschitz约束": "在技能发现过程中引入的约束，旨在鼓励发现动态且多样化的技能",
            "零样本学习": "指学习到的表示函数能够直接应用于下游任务，无需额外训练或复杂规划"
        },
        "success": true
    },
    {
        "order": 580,
        "title": "Local Feature Swapping for Generalization in Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2022/poster/5956",
        "abstract": "Over the past few years, the acceleration of computing resources and research in Deep Learning has led to significant practical successes in a range of tasks, including in particular in computer vision. Building on these advances, reinforcement learning has also seen a leap forward with the emergence of agents capable of making decisions directly from visual observations. Despite these successes, the over-parametrization of neural architectures leads to memorization of the data used during training and thus to a lack of generalization.Reinforcement learning agents based on visual inputs also suffer from this phenomenon by erroneously correlating rewards with unrelated visual features such as background elements. To alleviate this problem, we introduce a new regularization layer consisting of channel-consistent local permutations (CLOP) of the feature maps. The proposed permutations induce robustness to spatial correlations and help prevent overfitting behaviors in RL. We demonstrate, on the OpenAI Procgen Benchmark, that RL agents trained with the CLOP layer exhibit robustness to visual changes and better generalization properties than agents trained using other state-of-the-art regularization techniques.",
        "conference": "ICLR",
        "中文标题": "局部特征交换以增强强化学习的泛化能力",
        "摘要翻译": "过去几年中，计算资源的加速和深度学习研究的进展在一系列任务中取得了显著的实际成功，特别是在计算机视觉领域。基于这些进步，强化学习也取得了飞跃，出现了能够直接从视觉观察做出决策的智能体。尽管取得了这些成功，神经架构的过度参数化导致了训练数据记忆化，从而缺乏泛化能力。基于视觉输入的强化学习智能体也受到这一现象的影响，错误地将奖励与无关的视觉特征（如背景元素）相关联。为了缓解这一问题，我们引入了一种新的正则化层，该层由特征图的通道一致局部排列（CLOP）组成。所提出的排列增强了对空间相关性的鲁棒性，并有助于防止强化学习中的过拟合行为。我们在OpenAI Procgen Benchmark上证明，使用CLOP层训练的强化学习智能体对视觉变化表现出鲁棒性，并且比使用其他最先进的正则化技术训练的智能体具有更好的泛化性能。",
        "领域": "强化学习、计算机视觉、深度学习",
        "问题": "解决强化学习智能体在视觉输入下因过度参数化导致的泛化能力不足问题",
        "动机": "减少强化学习智能体对无关视觉特征的错误关联，提高其泛化能力",
        "方法": "引入通道一致局部排列（CLOP）作为新的正则化层，增强对空间相关性的鲁棒性",
        "关键词": [
            "强化学习",
            "泛化能力",
            "正则化",
            "局部特征交换",
            "视觉输入"
        ],
        "涉及的技术概念": {
            "通道一致局部排列（CLOP）": "一种新的正则化层，通过局部排列特征图来增强模型对空间相关性的鲁棒性",
            "过度参数化": "神经架构中参数过多导致模型记忆训练数据，影响泛化能力",
            "OpenAI Procgen Benchmark": "用于评估强化学习智能体泛化能力的基准测试"
        },
        "success": true
    },
    {
        "order": 581,
        "title": "Long Expressive Memory for Sequence Modeling",
        "html": "https://iclr.cc//virtual/2022/poster/6411",
        "abstract": "We propose a novel method called Long Expressive Memory (LEM) for learning long-term sequential dependencies. LEM is gradient-based, it can efficiently process sequential tasks with very long-term dependencies, and it is sufficiently expressive to be able to learn complicated input-output maps. To derive LEM, we consider a system of multiscale ordinary differential equations, as well as a suitable time-discretization of this system. For LEM, we derive rigorous bounds to show the mitigation of the exploding and vanishing gradients problem, a well-known challenge for gradient-based recurrent sequential learning methods. We also prove that LEM can approximate a large class of dynamical systems to high accuracy. Our empirical results, ranging from image and time-series classification through dynamical systems prediction to speech recognition and language modeling, demonstrate that LEM outperforms state-of-the-art recurrent neural networks, gated recurrent units, and long short-term memory models.",
        "conference": "ICLR",
        "中文标题": "长表达记忆用于序列建模",
        "摘要翻译": "我们提出了一种名为长表达记忆（LEM）的新方法，用于学习长期序列依赖关系。LEM基于梯度，能够高效处理具有极长期依赖关系的序列任务，并且具有足够的表达能力以学习复杂的输入-输出映射。为了推导LEM，我们考虑了一个多尺度常微分方程系统，以及该系统的一个合适的时间离散化。对于LEM，我们推导了严格的界限，以展示对爆炸和消失梯度问题的缓解，这是基于梯度的循环序列学习方法中一个众所周知的挑战。我们还证明了LEM可以高精度地近似一大类动态系统。我们的实证结果，从图像和时间序列分类到动态系统预测，再到语音识别和语言建模，表明LEM优于最先进的循环神经网络、门控循环单元和长短期记忆模型。",
        "领域": "序列建模、动态系统预测、语音识别",
        "问题": "解决在序列建模中学习长期依赖关系的挑战",
        "动机": "为了克服基于梯度的循环序列学习方法中爆炸和消失梯度问题，以及提高模型对复杂输入-输出映射的学习能力",
        "方法": "提出了一种基于多尺度常微分方程系统及其时间离散化的长表达记忆（LEM）方法",
        "关键词": [
            "长表达记忆",
            "序列建模",
            "动态系统预测",
            "梯度问题缓解",
            "多尺度常微分方程"
        ],
        "涉及的技术概念": {
            "长表达记忆（LEM）": "一种基于梯度的序列建模方法，旨在高效处理长期依赖关系并学习复杂映射",
            "多尺度常微分方程系统": "用于推导LEM的数学框架，通过不同时间尺度捕捉序列的动态特性",
            "爆炸和消失梯度问题": "循环序列学习中的常见挑战，LEM通过严格的数学界限缓解这一问题"
        },
        "success": true
    },
    {
        "order": 582,
        "title": "Looking Back on Learned Experiences  For Class/task Incremental Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6430",
        "abstract": "Classical deep neural networks are limited in their ability to learn from emerging streams of training data. When trained sequentially on new or evolving tasks, their performance degrades sharply, making them inappropriate in real-world use cases. Existing methods tackle it by either storing old data samples or only updating a parameter set of deep neural networks, which, however, demands a large memory budget or spoils the flexibility of models to learn the incremented task distribution. In this paper, we shed light on an on-call transfer set to provide past experiences whenever a new task arises in the data stream. In particular, we propose a Cost-Free Incremental Learning (CF-IL) not only to replay past experiences the model has learned but also to perform this in a cost free manner. Towards this end, we introduced a memory recovery paradigm in which we query the network to synthesize past exemplars whenever a new task emerges. Thus, our method needs no extra memory for data buffering or network growing, besides calls the proposed memory recovery paradigm to provide past exemplars, named a transfer set in order to mitigate catastrophically forgetting the former tasks in the Incremental Learning (IL) setup. Moreover, in contrast with recently proposed methods, the suggested paradigm does not desire a parallel architecture since it only relies on the learner network. Compared to the state-of-the-art data techniques without buffering past data samples, CF-IL demonstrates significantly better performance on the well-known datasets whether a task oracle is available in test time (Task-IL) or not (Class-IL).",
        "conference": "ICLR",
        "中文标题": "回顾学习经验用于类/任务增量学习",
        "摘要翻译": "传统的深度神经网络在学习来自不断涌现的训练数据流时存在局限性。当顺序训练新任务或演化任务时，它们的性能急剧下降，这使得它们不适合实际应用场景。现有方法通过存储旧数据样本或仅更新深度神经网络的参数集来解决这一问题，然而，这要么需要大量的内存预算，要么破坏了模型学习增量任务分布的灵活性。在本文中，我们提出了一种按需传输集的方法，以在数据流中出现新任务时提供过去的经验。特别是，我们提出了一种无成本增量学习（CF-IL），不仅能够回放模型已学习的过去经验，而且能够以无成本的方式进行。为此，我们引入了一种内存恢复范式，在新任务出现时查询网络以合成过去的样本。因此，我们的方法不需要额外的内存用于数据缓冲或网络增长，而是调用提出的内存恢复范式来提供过去的样本，称为传输集，以减轻在增量学习（IL）设置中对先前任务的灾难性遗忘。此外，与最近提出的方法相比，所建议的范式不需要并行架构，因为它仅依赖于学习网络。与不缓冲过去数据样本的最新数据技术相比，CF-IL在知名数据集上表现出显著更好的性能，无论测试时是否有任务预言（Task-IL）或没有（Class-IL）。",
        "领域": "增量学习",
        "问题": "解决深度神经网络在顺序学习新任务时性能下降的问题",
        "动机": "提高深度神经网络在增量学习中的灵活性和效率，减少对额外内存的需求",
        "方法": "提出一种无成本增量学习方法（CF-IL），通过内存恢复范式合成过去的样本，避免灾难性遗忘",
        "关键词": [
            "增量学习",
            "灾难性遗忘",
            "内存恢复范式"
        ],
        "涉及的技术概念": {
            "无成本增量学习（CF-IL）": "一种不需要额外内存或网络增长的增量学习方法，通过合成过去的样本来避免灾难性遗忘",
            "内存恢复范式": "在新任务出现时查询网络以合成过去的样本，用于提供过去的经验",
            "灾难性遗忘": "指神经网络在学习新任务时忘记先前学习任务的现象，CF-IL旨在减轻这一问题"
        },
        "success": true
    },
    {
        "order": 583,
        "title": "LoRA: Low-Rank Adaptation of Large Language Models",
        "html": "https://iclr.cc//virtual/2022/poster/6319",
        "abstract": "An important paradigm of natural language processing consists of large-scale pre-training on general domain data and adaptation to particular tasks or domains. As we pre-train larger models, full fine-tuning, which retrains all model parameters, becomes less feasible.Using GPT-3 175B as an example -- deploying independent instances of fine-tuned models, each with 175B parameters, is prohibitively expensive. We propose Low-Rank Adaptation, or LoRA, which freezes the pre-trained model weights and injects trainable rank decomposition matrices into each layer of the Transformer architecture, greatly reducing the number of trainable parameters for downstream tasks. Compared to GPT-3 175B fine-tuned with Adam, LoRA can reduce the number of trainable parameters by a factor of 10,000 and the GPU memory requirement by a factor of 3. LoRA performs on-par or better than fine-tuning in model quality on RoBERTa, DeBERTa, GPT-2, and GPT-3, despite having fewer trainable parameters, a higher training throughput, and, unlike adapters, no additional inference latency. We also provide an empirical investigation into rank-deficiency in language model adaptation, which sheds light on the efficacy of LoRA. We release a package that facilitates the integration of LoRA with PyTorch models and provide our implementations and model checkpoints for RoBERTa, DeBERTa, and GPT-2 at https://github.com/microsoft/LoRA.",
        "conference": "ICLR",
        "中文标题": "LoRA：大型语言模型的低秩适应",
        "摘要翻译": "自然语言处理的一个重要范式包括在通用领域数据上进行大规模预训练，并适应特定任务或领域。随着我们预训练的模型越来越大，完全微调（即重新训练所有模型参数）变得不太可行。以GPT-3 175B为例——部署独立的微调模型实例，每个实例有1750亿参数，成本极其高昂。我们提出了低秩适应（LoRA），它冻结了预训练模型的权重，并在Transformer架构的每一层注入了可训练的低秩分解矩阵，大大减少了用于下游任务的可训练参数数量。与使用Adam微调的GPT-3 175B相比，LoRA可以将可训练参数数量减少10,000倍，GPU内存需求减少3倍。尽管LoRA的可训练参数更少，训练吞吐量更高，并且与适配器不同，没有额外的推理延迟，但LoRA在模型质量上与微调相当或更好，适用于RoBERTa、DeBERTa、GPT-2和GPT-3。我们还对语言模型适应中的秩不足进行了实证研究，这揭示了LoRA的有效性。我们发布了一个包，便于将LoRA与PyTorch模型集成，并在https://github.com/microsoft/LoRA上提供了我们对RoBERTa、DeBERTa和GPT-2的实现和模型检查点。",
        "领域": "自然语言处理与视觉结合",
        "问题": "大型预训练语言模型在适应特定任务时的高成本和资源消耗问题",
        "动机": "减少大型语言模型在适应特定任务时的计算资源和内存需求，同时保持或提高模型性能",
        "方法": "提出低秩适应（LoRA）方法，通过冻结预训练模型权重并注入可训练的低秩分解矩阵来减少可训练参数数量",
        "关键词": [
            "低秩适应",
            "大型语言模型",
            "参数效率",
            "模型微调",
            "Transformer架构"
        ],
        "涉及的技术概念": {
            "低秩分解矩阵": "在Transformer架构的每一层注入的可训练矩阵，用于减少可训练参数数量而不显著影响模型性能",
            "模型微调": "调整预训练模型以适应特定任务的过程，LoRA通过减少需要调整的参数数量来提高效率",
            "Transformer架构": "一种用于处理序列数据的深度学习模型架构，LoRA通过在该架构的每一层注入低秩矩阵来实现高效适应"
        },
        "success": true
    },
    {
        "order": 584,
        "title": "LORD: Lower-Dimensional Embedding of Log-Signature in Neural Rough Differential Equations",
        "html": "https://iclr.cc//virtual/2022/poster/6473",
        "abstract": "The problem of processing very long time-series data (e.g., a length of more than 10,000) is a long-standing research problem in machine learning. Recently, one breakthrough, called neural rough differential equations (NRDEs), has been proposed and has shown that it is able to process such data. Their main concept is to use the log-signature transform, which is known to be more efficient than the Fourier transform for irregular long time-series, to convert a very long time-series sample into a relatively shorter series of feature vectors. However, the log-signature transform causes non-trivial spatial overheads. To this end, we present the method of LOweR-Dimensional embedding of log-signature (LORD), where we define an NRDE-based autoencoder to implant the higher-depth log-signature knowledge into the lower-depth log-signature. We show that the encoder successfully combines the higher-depth and the lower-depth log-signature knowledge, which greatly stabilizes the training process and increases the model accuracy. In our experiments with benchmark datasets, the improvement ratio by our method is up to 75\\% in terms of various classification and forecasting evaluation metrics.",
        "conference": "ICLR",
        "中文标题": "LORD：神经粗糙微分方程中对数签名的低维嵌入",
        "摘要翻译": "处理非常长的时间序列数据（例如，长度超过10,000）是机器学习中一个长期存在的研究问题。最近，一项被称为神经粗糙微分方程（NRDEs）的突破性进展被提出，并显示出其能够处理此类数据。其主要概念是使用对数签名变换，已知对于不规则长时序数据比傅里叶变换更有效，将非常长的时间序列样本转换为相对较短的特征向量序列。然而，对数签名变换会导致不小的空间开销。为此，我们提出了对数签名的低维嵌入方法（LORD），其中我们定义了一个基于NRDE的自编码器，将高深度对数签名知识植入低深度对数签名中。我们展示了编码器成功结合了高深度和低深度对数签名知识，极大地稳定了训练过程并提高了模型准确性。在我们对基准数据集的实验中，我们的方法在各种分类和预测评估指标上的改进比例高达75%。",
        "领域": "时序数据分析、深度学习、信号处理",
        "问题": "处理非常长的时间序列数据时，对数签名变换导致的空间开销问题",
        "动机": "解决神经粗糙微分方程在处理长时序数据时，因对数签名变换产生的高空间开销问题，以提高处理效率和模型性能",
        "方法": "提出了一种基于神经粗糙微分方程的自编码器方法（LORD），通过将高深度对数签名知识嵌入到低深度对数签名中，减少空间开销并提高模型性能",
        "关键词": [
            "神经粗糙微分方程",
            "对数签名变换",
            "时序数据处理",
            "自编码器",
            "低维嵌入"
        ],
        "涉及的技术概念": {
            "神经粗糙微分方程（NRDEs）": "用于处理非常长的时间序列数据的突破性方法，通过模拟粗糙路径理论中的微分方程来建模时序数据",
            "对数签名变换": "一种比傅里叶变换更有效的时序数据特征提取方法，特别适用于不规则长时序数据",
            "自编码器": "一种神经网络架构，用于将高维数据压缩到低维空间，同时保留重要信息，本文中用于实现高深度对数签名到低深度对数的知识迁移"
        },
        "success": true
    },
    {
        "order": 585,
        "title": "Lossless Compression with Probabilistic Circuits",
        "html": "https://iclr.cc//virtual/2022/poster/6879",
        "abstract": "Despite extensive progress on image generation, common deep generative model architectures are not easily applied to lossless compression. For example, VAEs suffer from a compression cost overhead due to their latent variables. This overhead can only be partially eliminated with elaborate schemes such as bits-back coding, often resulting in poor single-sample compression rates. To overcome such problems, we establish a new class of tractable lossless compression models that permit efficient encoding and decoding: Probabilistic Circuits (PCs). These are a class of neural networks involving $|p|$ computational units that support efficient marginalization over arbitrary subsets of the $D$ feature dimensions, enabling efficient arithmetic coding. We derive efficient encoding and decoding schemes that both have time complexity $\\mathcal{O} (\\log(D) \\cdot |p|)$, where a naive scheme would have linear costs in $D$ and $|p|$, making the approach highly scalable. Empirically, our PC-based (de)compression algorithm runs 5-40 times faster than neural compression algorithms that achieve similar bitrates. By scaling up the traditional PC structure learning pipeline, we achieve state-of-the-art results on image datasets such as MNIST. Furthermore, PCs can be naturally integrated with existing neural compression algorithms to improve the performance of these base models on natural image datasets. Our results highlight the potential impact that non-standard learning architectures may have on neural data compression.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "基于概率电路的无损压缩",
        "摘要翻译": "尽管图像生成领域取得了广泛进展，但常见的深度生成模型架构并不容易应用于无损压缩。例如，变分自编码器（VAEs）由于其潜在变量而遭受压缩成本开销。这种开销只能通过诸如bits-back编码等精巧方案部分消除，通常导致较差的单样本压缩率。为了克服这些问题，我们建立了一类新的可处理的无损压缩模型，允许高效的编码和解码：概率电路（PCs）。这些是一种包含|p|个计算单元的神经网络，支持对D个特征维度的任意子集进行有效的边缘化，从而实现高效的算术编码。我们推导出高效的编码和解码方案，它们的时间复杂度均为O(log(D) * |p|)，而简单的方案在D和|p|中具有线性成本，这使得该方法具有高度的可扩展性。在经验上，我们基于PC的（解）压缩算法比实现类似比特率的神经压缩算法快5-40倍。通过扩展传统的PC结构学习流程，我们在诸如MNIST等图像数据集上取得了最先进的结果。此外，PCs可以自然地与现有的神经压缩算法集成，以提高这些基本模型在自然图像数据集上的性能。我们的结果突出了非标准学习架构可能对神经数据压缩产生的潜在影响。",
        "领域": "图像压缩, 无损压缩, 神经数据压缩",
        "问题": "如何设计一种高效且可扩展的无损压缩模型，克服传统深度生成模型在压缩成本上的开销问题，并提高单样本压缩率。",
        "动机": "现有的深度生成模型（如VAEs）在无损图像压缩中存在压缩成本开销，导致单样本压缩率不佳。为了解决这个问题，需要探索新的模型架构和算法，以实现更高效的无损压缩。",
        "方法": "提出基于概率电路（PCs）的无损压缩模型，该模型支持对特征维度进行有效边缘化，实现高效算术编码。通过优化编码和解码方案，降低时间复杂度，并与现有神经压缩算法集成，提升整体压缩性能。",
        "关键词": [
            "概率电路",
            "无损压缩",
            "神经压缩",
            "算术编码",
            "图像压缩"
        ],
        "涉及的技术概念": {
            "概率电路（PCs）": "一种神经网络结构，支持对特征维度进行有效的边缘化，用于实现高效的算术编码。",
            "算术编码": "一种数据压缩方法，通过将整个消息表示为一个单一的实数区间来进行编码，概率电路的有效边缘化使其能够高效地进行算术编码。"
        }
    },
    {
        "order": 586,
        "title": "LOSSY COMPRESSION WITH DISTRIBUTION SHIFT AS ENTROPY CONSTRAINED OPTIMAL TRANSPORT",
        "html": "https://iclr.cc//virtual/2022/poster/6136",
        "abstract": "We study an extension of lossy compression where the reconstruction distribution is different from the source distribution in order to account for distributional shift due to processing. We formulate this as a generalization of optimal transport with an entropy bottleneck to account for the rate constraint due to compression. We provide expressions for the tradeoff between  compression rate and the achievable distortion with and without shared common randomness between the encoder and decoder.  We study the examples of binary, uniform and Gaussian sources (in an asymptotic setting) in detail and  demonstrate that shared randomness can strictly improve the tradeoff. For the case without common randomness and squared-Euclidean distortion, we show that the optimal solution partially decouples into the problem of optimal compression and transport and also characterize the penalty associated with fully decoupling them. We provide experimental results by training deep learning end-to-end compression systems for performing denoising on SVHN and super-resolution on MNIST suggesting consistency with our theoretical results.",
        "conference": "ICLR",
        "中文标题": "作为熵约束最优传输的分布偏移下的有损压缩",
        "摘要翻译": "我们研究了一种有损压缩的扩展形式，其中重建分布与源分布不同，以考虑由于处理引起的分布偏移。我们将此问题表述为带有熵瓶颈的最优传输的泛化，以考虑压缩带来的速率约束。我们提供了压缩率与可实现失真之间权衡的表达式，包括编码器和解码器之间是否共享共同随机性的情况。我们详细研究了二进制、均匀和高斯源（在渐近设置下）的例子，并证明共享随机性可以严格改善权衡。对于没有共同随机性和平方欧几里得失真的情况，我们展示了最优解部分解耦为最优压缩和传输的问题，并且还描述了完全解耦它们所带来的惩罚。我们通过训练深度学习端到端压缩系统在SVHN上进行去噪和在MNIST上进行超分辨率实验，提供了实验结果，表明与我们的理论结果一致。",
        "领域": "图像压缩、深度学习、信号处理",
        "问题": "研究在有损压缩中，当重建分布与源分布不同时，如何通过最优传输和熵约束来处理分布偏移，并探索压缩率与失真之间的权衡。",
        "动机": "探索在存在分布偏移的情况下，如何优化有损压缩的性能，特别是在编码器和解码器之间共享或不共享随机性时的不同表现。",
        "方法": "通过理论分析和实验验证，研究最优传输与熵约束在有损压缩中的应用，特别是在处理分布偏移时的表现。",
        "关键词": [
            "有损压缩",
            "最优传输",
            "熵约束",
            "分布偏移",
            "深度学习"
        ],
        "涉及的技术概念": {
            "最优传输": "用于在有损压缩中处理重建分布与源分布不同的情况，以实现有效的压缩和重建。",
            "熵约束": "在压缩过程中引入的约束，用于控制压缩率与失真之间的权衡。",
            "分布偏移": "指由于处理或传输过程中，数据的分布发生变化的现象，本研究探讨了在此情况下的压缩策略。"
        },
        "success": true
    },
    {
        "order": 587,
        "title": "Low-Budget Active Learning via Wasserstein Distance: An Integer Programming Approach",
        "html": "https://iclr.cc//virtual/2022/poster/6451",
        "abstract": "Active learning is the process of training a model with limited labeled data by selecting a core subset of an unlabeled data pool to label. The large scale of data sets used in deep learning forces most sample selection strategies to employ efficient heuristics. This paper introduces an integer optimization problem for selecting a core set that minimizes the discrete Wasserstein distance from the unlabeled pool. We demonstrate that this problem can be tractably solved with a Generalized Benders Decomposition algorithm. Our strategy uses high-quality latent features that can be obtained by unsupervised learning on the unlabeled pool. Numerical results on several data sets show that our optimization approach is competitive with baselines and particularly outperforms them in the low budget regime where less than one percent of the data set is labeled. ",
        "conference": "ICLR",
        "中文标题": "基于Wasserstein距离的低预算主动学习：一种整数规划方法",
        "摘要翻译": "主动学习是通过从无标签数据池中选择核心子集进行标注，以有限标注数据训练模型的过程。深度学习中使用的大规模数据集迫使大多数样本选择策略采用高效的启发式方法。本文引入了一个整数优化问题，用于选择最小化与无标签池离散Wasserstein距离的核心集。我们证明了这个问题可以通过广义Benders分解算法有效解决。我们的策略利用了可以通过无监督学习在无标签池上获得的高质量潜在特征。在多个数据集上的数值结果表明，我们的优化方法能够与基线方法竞争，特别是在数据集中标注数据不足百分之一的低预算情况下，表现尤为出色。",
        "领域": "主动学习、无监督学习、优化算法",
        "问题": "在低预算条件下，如何有效地选择核心子集进行标注以训练模型",
        "动机": "解决大规模数据集中标注成本高的问题，特别是在标注预算极低的情况下，提高模型训练的效率",
        "方法": "提出一个整数优化问题，通过最小化离散Wasserstein距离选择核心集，并采用广义Benders分解算法进行求解",
        "关键词": [
            "主动学习",
            "Wasserstein距离",
            "整数规划",
            "广义Benders分解",
            "无监督学习"
        ],
        "涉及的技术概念": {
            "Wasserstein距离": "用于衡量两个概率分布之间的距离，本文中用于优化核心集的选择，确保其分布与无标签池尽可能接近",
            "整数规划": "一种数学优化方法，用于在给定约束条件下寻找整数解的最优解，本文中用于选择最优的核心子集",
            "广义Benders分解算法": "一种解决复杂优化问题的算法，本文中用于有效求解提出的整数优化问题"
        },
        "success": true
    },
    {
        "order": 588,
        "title": "Machine Learning For Elliptic PDEs: Fast Rate Generalization Bound, Neural Scaling Law and Minimax Optimality",
        "html": "https://iclr.cc//virtual/2022/poster/6547",
        "abstract": "In this paper, we study the statistical limits of deep learning techniques for solving elliptic partial differential equations (PDEs) from random samples using the Deep Ritz Method (DRM) and Physics-Informed Neural Networks (PINNs). To simplify the problem, we focus on a prototype elliptic PDE: the Schr\\'odinger equation on a hypercube with zero Dirichlet boundary condition, which has wide application in the quantum-mechanical systems. We establish upper and lower bounds for both methods, which improves upon concurrently developed upper bounds for this problem via a fast rate generalization bound. We discover that the current Deep Ritz Methods is sub-optimal and propose a modified version of it. We also prove that PINN and the modified version of DRM can achieve minimax optimal bounds over Sobolev spaces. Empirically, following recent work which has shown that the deep model accuracy will improve with growing training sets according to a power law, we supply computational experiments to show a similar behavior of dimension dependent power law for deep PDE solvers.",
        "conference": "ICLR",
        "中文标题": "机器学习用于椭圆偏微分方程：快速率泛化边界、神经尺度定律及极小极大最优性",
        "摘要翻译": "本文研究了使用深度里茨方法（DRM）和物理信息神经网络（PINNs）从随机样本中解决椭圆偏微分方程（PDEs）的深度学习技术的统计极限。为了简化问题，我们专注于一个原型椭圆PDE：具有零Dirichlet边界条件的超立方体上的薛定谔方程，这在量子力学系统中有广泛应用。我们为这两种方法建立了上下界，通过快速率泛化边界改进了针对此问题同时开发的上界。我们发现当前的深度里茨方法是次优的，并提出了其改进版本。我们还证明了PINN和改进版的DRM可以在Sobolev空间上达到极小极大最优边界。根据最近显示深度模型精度将随训练集增长按照幂律提高的工作，我们提供了计算实验来展示深度PDE求解器类似的维度依赖幂律行为。",
        "领域": "偏微分方程数值解、量子力学计算、深度学习理论",
        "问题": "研究深度学习方法在解决椭圆偏微分方程时的统计极限和最优性。",
        "动机": "探索和提升深度学习方法在解决椭圆偏微分方程中的效率和准确性，特别是在量子力学系统中的应用。",
        "方法": "使用深度里茨方法和物理信息神经网络，建立上下界，提出改进的深度里茨方法，并证明其与PINN在Sobolev空间上的极小极大最优性。",
        "关键词": [
            "椭圆偏微分方程",
            "深度里茨方法",
            "物理信息神经网络",
            "极小极大最优性",
            "幂律行为"
        ],
        "涉及的技术概念": {
            "深度里茨方法（DRM）": "一种用于数值解决偏微分方程的深度学习方法，通过最小化能量泛函来近似解。",
            "物理信息神经网络（PINNs）": "结合物理定律的神经网络，用于解决偏微分方程，通过在损失函数中融入物理信息来指导学习过程。",
            "Sobolev空间": "一种函数空间，用于描述偏微分方程解的正则性，本文中用于证明方法的极小极大最优性。"
        },
        "success": true
    },
    {
        "order": 589,
        "title": "MaGNET: Uniform Sampling from Deep Generative Network Manifolds Without Retraining",
        "html": "https://iclr.cc//virtual/2022/poster/6820",
        "abstract": "Deep Generative Networks (DGNs) are extensively employed in Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and their variants to approximate the data manifold, and data distribution on that manifold. However, training samples are often obtained based on preferences, costs, or convenience producing artifacts in the empirical data distribution e.g. the large fraction of smiling faces in the CelebA dataset or the large fraction of dark-haired individuals in FFHQ). {\\em These inconsistencies will be reproduced when sampling from the trained DGN, which has far-reaching potential implications for fairness, data augmentation, anomaly detection, domain adaptation, and beyond.} In response, we develop a differential geometry based sampler -coined MaGNET- that, given any trained DGN, produces samples that are uniformly distributed on the learned manifold. We prove theoretically and empirically that our technique produces a uniform distribution on the manifold regardless of the training set distribution. We perform a range of experiments on various datasets and DGNs. One of them considers the state-of-the-art StyleGAN2 trained on FFHQ dataset, where uniform sampling via MaGNET increases distribution precision \\& recall by 4.12\\% \\& 3.01\\% and decreases gender bias by 41.2\\%, without requiring labels or retraining.",
        "conference": "ICLR",
        "中文标题": "MaGNET：无需重新训练即可从深度生成网络流形中均匀采样",
        "摘要翻译": "深度生成网络（DGNs）被广泛应用于生成对抗网络（GANs）、变分自编码器（VAEs）及其变体中，以近似数据流形及其上的数据分布。然而，训练样本往往基于偏好、成本或便利性获得，这会在经验数据分布中产生伪影（例如，CelebA数据集中大量微笑的面孔或FFHQ数据集中大量黑发个体）。这些不一致性在从训练好的DGN中采样时会被复制，这对公平性、数据增强、异常检测、领域适应等方面具有深远的影响。为此，我们开发了一种基于微分几何的采样器——MaGNET——它可以在任何训练好的DGN上产生在学习的流形上均匀分布的样本。我们从理论上和实证上证明了我们的技术能够在流形上产生均匀分布，而不受训练集分布的影响。我们在各种数据集和DGN上进行了一系列实验。其中之一考虑了在FFHQ数据集上训练的最先进的StyleGAN2，通过MaGNET进行均匀采样，分布精度和召回率分别提高了4.12%和3.01%，性别偏见减少了41.2%，且无需标签或重新训练。",
        "领域": "生成对抗网络, 变分自编码器, 数据增强",
        "问题": "解决从深度生成网络中采样时因训练数据分布不均导致的样本偏差问题",
        "动机": "为了消除深度生成网络在采样过程中复制训练数据分布不均的问题，提高样本的公平性和多样性",
        "方法": "开发了一种基于微分几何的采样器MaGNET，能够在学习的流形上产生均匀分布的样本",
        "关键词": [
            "均匀采样",
            "深度生成网络",
            "微分几何",
            "数据分布",
            "公平性"
        ],
        "涉及的技术概念": {
            "深度生成网络": "用于近似数据流形及其上的数据分布的网络，如GANs和VAEs",
            "微分几何": "用于开发MaGNET采样器的数学基础，确保样本在流形上的均匀分布",
            "均匀分布": "MaGNET采样器产生的样本分布特性，不受训练数据分布不均的影响"
        },
        "success": true
    },
    {
        "order": 590,
        "title": "MAML is a Noisy Contrastive Learner in Classification",
        "html": "https://iclr.cc//virtual/2022/poster/7032",
        "abstract": "Model-agnostic meta-learning (MAML) is one of the most popular and widely adopted meta-learning algorithms, achieving remarkable success in various learning problems. Yet, with the unique design of nested inner-loop and outer-loop updates, which govern the task-specific and meta-model-centric learning, respectively, the underlying learning objective of MAML remains implicit, impeding a more straightforward understanding of it. In this paper, we provide a new perspective of the working mechanism of MAML. We discover that MAML is analogous to a meta-learner using a supervised contrastive objective in classification. The query features are pulled towards the support features of the same class and against those of different classes. Such contrastiveness is experimentally verified via an analysis based on the cosine similarity. Moreover, we reveal that vanilla MAML has an undesirable interference term originating from the random initialization and the cross-task interaction. We thus propose a simple but effective technique, the zeroing trick, to alleviate the interference. Extensive experiments are conducted on both mini-ImageNet and Omniglot datasets to validate the consistent improvement brought by our proposed method.",
        "conference": "ICLR",
        "中文标题": "MAML在分类中是一种嘈杂的对比学习者",
        "摘要翻译": "模型无关的元学习（MAML）是最受欢迎和广泛采用的元学习算法之一，在各种学习问题中取得了显著成功。然而，由于其独特的嵌套内循环和外循环更新设计，分别控制任务特定和以元模型为中心的学习，MAML的潜在学习目标仍然隐含，阻碍了对它的更直接理解。在本文中，我们提供了MAML工作机制的新视角。我们发现MAML类似于在分类中使用有监督对比目标的元学习者。查询特征被拉向同一类的支持特征，并远离不同类的特征。这种对比性通过基于余弦相似度的分析得到了实验验证。此外，我们揭示了原始MAML存在一个不良干扰项，源于随机初始化和跨任务交互。因此，我们提出了一种简单但有效的技术——归零技巧，以减轻干扰。在mini-ImageNet和Omniglot数据集上进行了大量实验，以验证我们提出的方法带来的持续改进。",
        "领域": "元学习",
        "问题": "揭示MAML在分类任务中的工作机制及其潜在问题",
        "动机": "理解MAML的隐含学习目标及其在分类任务中的表现",
        "方法": "通过对比学习视角分析MAML，并提出归零技巧以减少干扰",
        "关键词": [
            "元学习",
            "对比学习",
            "分类任务",
            "MAML",
            "干扰减少"
        ],
        "涉及的技术概念": {
            "模型无关的元学习（MAML）": "一种广泛使用的元学习算法，通过嵌套循环更新适应新任务",
            "对比学习": "一种学习方法，通过拉近同类样本和推开不同类样本来学习特征表示",
            "归零技巧": "一种简单有效的技术，用于减少MAML中的干扰项，提高学习效率"
        },
        "success": true
    },
    {
        "order": 591,
        "title": "Map Induction: Compositional spatial submap learning for efficient exploration in novel environments",
        "html": "https://iclr.cc//virtual/2022/poster/6636",
        "abstract": "Humans are expert explorers and foragers. Understanding the computational cognitive mechanisms that support this capability can advance the study of the human mind and enable more efficient exploration algorithms. We hypothesize that humans explore new environments by inferring the structure of unobserved spaces through re-use of spatial information collected from previously explored spaces. Taking inspiration from the neuroscience of repeating map fragments and ideas about program induction, we present a novel ``Map Induction'' framework, which involves the generation of novel map proposals for unseen environments based on compositions of already-seen spaces in a Hierarchical Bayesian framework. The model thus explicitly reasons about unseen spaces through a distribution of strong spatial priors. We introduce a new behavioral Map Induction Task (MIT) that involves foraging for rewards to compare human performance with state-of-the-art existing models and Map Induction. We show that Map Induction better predicts human behavior than the non-inductive baselines. We also show that Map Induction, when used to augment state-of-the-art approximate planning algorithms, improves their performance.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "地图归纳：组合空间子地图学习以实现新环境中的高效探索",
        "摘要翻译": "人类是探索和觅食的专家。理解支持这种能力的计算认知机制可以推进对人类思维的研究，并实现更高效的探索算法。我们假设，人类通过重用从先前探索的空间收集的空间信息，推断未观察空间的结构来探索新环境。受到神经科学中重复地图片段和程序归纳思想的启发，我们提出了一种新颖的“地图归纳”框架，该框架涉及在分层贝叶斯框架中基于已见空间的组合生成未见环境的新地图提案。因此，该模型通过一组强空间先验的分布明确地推理未见空间。我们引入了一种新的行为地图归纳任务（MIT），涉及觅食奖励，以比较人类表现与现有最先进模型和地图归纳的表现。我们表明，地图归纳比非归纳基线更能预测人类行为。我们还表明，当用于增强最先进的近似规划算法时，地图归纳提高了它们的性能。",
        "领域": "空间认知建模, 探索算法, 行为任务设计",
        "问题": "如何在新环境中高效探索和推理未观察空间的结构",
        "动机": "通过理解人类探索和觅食的认知机制，开发更高效的探索算法",
        "方法": "提出地图归纳框架，基于已见空间的组合生成未见环境的地图提案，并在分层贝叶斯框架中进行推理",
        "关键词": [
            "地图归纳",
            "空间认知",
            "探索算法",
            "分层贝叶斯",
            "行为任务"
        ],
        "涉及的技术概念": {
            "地图归纳": "一种基于已见空间组合生成未见环境地图提案的框架",
            "分层贝叶斯框架": "用于推理未见空间的结构，通过一组强空间先验的分布",
            "行为地图归纳任务（MIT）": "一种新的行为任务，用于比较人类表现与现有模型和地图归纳的表现"
        }
    },
    {
        "order": 592,
        "title": "Mapping conditional distributions for domain adaptation under generalized target shift",
        "html": "https://iclr.cc//virtual/2022/poster/6951",
        "abstract": "We consider the problem of unsupervised domain adaptation (UDA) between a source and a target domain under conditional and label shift a.k.a Generalized Target Shift (GeTarS). Unlike simpler UDA settings, few works have addressed this challenging problem. Recent approaches learn domain-invariant representations, yet they have practical limitations and rely on strong assumptions that may not hold in practice. In this paper, we explore a novel and general approach to align pretrained representations, which circumvents existing drawbacks. Instead of constraining representation invariance, it learns an optimal transport map, implemented as a NN, which maps source representations onto target ones. Our approach is flexible and scalable, it preserves the problem's structure and it has strong theoretical guarantees under mild assumptions. In particular, our solution is unique, matches conditional distributions across domains, recovers target proportions and explicitly controls the target generalization risk. Through an exhaustive comparison on several datasets, we challenge the state-of-the-art in GeTarS.",
        "conference": "ICLR",
        "中文标题": "在广义目标偏移下映射条件分布以实现领域适应",
        "摘要翻译": "我们考虑了在条件偏移和标签偏移（即广义目标偏移，GeTarS）下源域和目标域之间的无监督领域适应（UDA）问题。与更简单的UDA设置不同，很少有工作解决这一具有挑战性的问题。最近的方法学习领域不变表示，但它们有实际限制，并依赖于在实践中可能不成立的强假设。在本文中，我们探索了一种新颖且通用的方法来对齐预训练表示，这规避了现有的缺点。它不限制表示不变性，而是学习一个最优传输映射，实现为神经网络（NN），将源表示映射到目标表示。我们的方法灵活且可扩展，它保留了问题的结构，并在温和假设下具有强大的理论保证。特别是，我们的解决方案是唯一的，跨领域匹配条件分布，恢复目标比例，并明确控制目标泛化风险。通过在几个数据集上的详尽比较，我们挑战了GeTarS的最新技术。",
        "领域": "无监督领域适应、条件分布对齐、广义目标偏移",
        "问题": "解决在广义目标偏移（GeTarS）条件下，源域和目标域之间的无监督领域适应问题",
        "动机": "现有的无监督领域适应方法在处理条件偏移和标签偏移时存在局限性，且依赖于不切实际的假设，需要一种更灵活和理论保证的方法",
        "方法": "通过学习一个最优传输映射（实现为神经网络）来对齐预训练表示，而不是强制表示不变性，从而匹配跨领域的条件分布并控制泛化风险",
        "关键词": [
            "无监督领域适应",
            "广义目标偏移",
            "最优传输",
            "条件分布对齐",
            "神经网络"
        ],
        "涉及的技术概念": {
            "最优传输": "用于将源域的表示映射到目标域，以实现条件分布的对齐",
            "广义目标偏移（GeTarS）": "描述在领域适应问题中同时存在条件偏移和标签偏移的情况",
            "神经网络（NN）": "实现最优传输映射的技术手段，用于灵活且可扩展地学习表示之间的映射关系"
        },
        "success": true
    },
    {
        "order": 593,
        "title": "Mapping Language Models to Grounded Conceptual Spaces",
        "html": "https://iclr.cc//virtual/2022/poster/5992",
        "abstract": "A fundamental criticism of text-only language models (LMs) is their lack of grounding---that is, the ability to tie a word for which they have learned a representation, to its actual use in the world. However, despite this limitation, large pre-trained LMs have been shown to have a remarkable grasp of the conceptual structure of language, as demonstrated by their ability to answer questions, generate fluent text, or make inferences about entities, objects, and properties that they have never physically observed. In this work we investigate the extent to which the rich conceptual structure that LMs learn indeed reflects the conceptual structure of the non-linguistic world---which is something that LMs have never observed. We do this by testing whether the LMs can learn to map an entire conceptual domain (e.g., direction or colour) onto a grounded world representation given only a small number of examples. For example, we show a model what the word ``left' means using a textual depiction of a grid world, and assess how well it can generalise to related concepts, for example, the word ``right', in a similar grid world. We investigate a range of generative language models of varying sizes (including GPT-2 and GPT-3), and see that although the smaller models struggle to perform this mapping, the largest model can not only learn to ground the concepts that it is explicitly taught, but appears to generalise to several instances of unseen concepts as well. Our results suggest an alternative means of building grounded language models: rather than learning grounded representations ``from scratch'', it is possible that large text-only models learn a sufficiently rich conceptual structure that could allow them to be grounded in a data-efficient way.",
        "conference": "ICLR",
        "中文标题": "将语言模型映射到基础概念空间",
        "摘要翻译": "对纯文本语言模型（LMs）的一个根本批评是它们缺乏基础性——即，将学习到的单词表示与其在现实世界中的实际使用联系起来的能力。然而，尽管存在这一限制，大型预训练LMs已被证明对语言的概念结构有着惊人的把握，这体现在它们能够回答问题、生成流畅的文本或对它们从未物理观察过的实体、对象和属性进行推理。在这项工作中，我们研究了LMs学习的丰富概念结构在多大程度上确实反映了非语言世界的概念结构——这是LMs从未观察过的。我们通过测试LMs是否能够在仅给出少量示例的情况下学习将整个概念领域（例如，方向或颜色）映射到基础世界表示上来做到这一点。例如，我们使用网格世界的文本描述向模型展示“左”这个词的含义，并评估它如何能够推广到相关概念，例如，在类似的网格世界中的“右”这个词。我们调查了一系列不同大小的生成语言模型（包括GPT-2和GPT-3），发现虽然较小的模型难以执行这种映射，但最大的模型不仅能够学习基础它被明确教授的概念，而且似乎还能够推广到几个未见过的概念实例。我们的结果提出了构建基础语言模型的另一种方法：与其“从零开始”学习基础表示，大型纯文本模型可能学习了一个足够丰富的概念结构，使它们能够以数据高效的方式进行基础。",
        "领域": "自然语言处理与视觉结合、语言模型基础性研究、概念学习",
        "问题": "研究语言模型是否能够将其学习到的概念结构映射到非语言世界的基础表示上。",
        "动机": "探索大型预训练语言模型是否能够在缺乏直接物理观察的情况下，理解和映射非语言世界的概念结构。",
        "方法": "通过向不同大小的生成语言模型（包括GPT-2和GPT-3）提供少量示例，测试其将概念领域映射到基础世界表示的能力。",
        "关键词": [
            "语言模型",
            "概念基础性",
            "GPT-3",
            "概念映射",
            "数据高效学习"
        ],
        "涉及的技术概念": {
            "语言模型（LMs）": "用于理解和生成人类语言的模型，本研究探讨其概念基础性能力。",
            "概念基础性": "指语言模型将学习到的语言表示与现实世界中的实际使用联系起来的能力。",
            "GPT-3": "一种大型生成语言模型，本研究显示其在概念映射和基础性方面表现出色。"
        },
        "success": true
    },
    {
        "order": 594,
        "title": "Mastering Visual Continuous Control: Improved Data-Augmented Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6275",
        "abstract": "We present DrQ-v2, a model-free reinforcement learning (RL) algorithm for visual continuous control. DrQ-v2 builds on DrQ, an off-policy actor-critic approach that uses data augmentation to learn directly from pixels. We introduce several improvements that yield state-of-the-art results on the DeepMind Control Suite. Notably, DrQ-v2 is able to solve complex humanoid locomotion tasks directly from pixel observations, previously unattained by model-free RL. DrQ-v2  is conceptually simple, easy to implement, and provides significantly better computational footprint compared to prior work, with the majority of tasks taking just 8 hours to train on a single GPU. Finally, we publicly release DrQ-v2 's implementation to  provide RL practitioners with a strong and computationally efficient baseline.",
        "conference": "ICLR",
        "中文标题": "掌握视觉连续控制：改进的数据增强强化学习",
        "摘要翻译": "我们提出了DrQ-v2，一种用于视觉连续控制的模型无关强化学习（RL）算法。DrQ-v2基于DrQ，这是一种使用数据增强直接从像素学习的离策略行动者-评论者方法。我们引入了几项改进，这些改进在DeepMind控制套件上取得了最先进的结果。值得注意的是，DrQ-v2能够直接从像素观察中解决复杂的人形运动任务，这是模型无关RL之前未曾达到的。DrQ-v2在概念上简单，易于实现，并且与之前的工作相比，提供了显著更好的计算足迹，大多数任务只需在单个GPU上训练8小时。最后，我们公开发布了DrQ-v2的实现，为RL实践者提供了一个强大且计算效率高的基线。",
        "领域": "强化学习、视觉连续控制、人形运动控制",
        "问题": "如何直接从像素观察中解决复杂的视觉连续控制任务，特别是人形运动任务。",
        "动机": "开发一种模型无关的强化学习算法，能够直接从像素中学习，解决复杂的视觉连续控制任务，同时保持计算效率。",
        "方法": "基于DrQ算法，引入数据增强和几项改进，开发出DrQ-v2算法，实现了从像素直接学习复杂任务的能力。",
        "关键词": [
            "强化学习",
            "视觉连续控制",
            "数据增强",
            "人形运动",
            "计算效率"
        ],
        "涉及的技术概念": {
            "模型无关强化学习": "一种不依赖于环境模型的强化学习方法，直接从经验中学习策略。",
            "数据增强": "通过对训练数据进行变换来增加数据多样性，提高模型的泛化能力。",
            "离策略行动者-评论者方法": "一种强化学习框架，其中行动者策略与生成数据的策略不同，评论者用于评估行动者策略的价值。"
        },
        "success": true
    },
    {
        "order": 595,
        "title": "Maximizing Ensemble Diversity in Deep Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6498",
        "abstract": "Modern deep reinforcement learning (DRL) has been successful in solving a range of challenging sequential decision-making problems. Most of these algorithms use an ensemble of neural networks as their backbone structure and benefit from the diversity among the neural networks to achieve optimal results. Unfortunately, the members of the ensemble can converge to the same point either the parametric space or representation space during the training phase, therefore, losing all the leverage of an ensemble. In this paper, we describe Maximize Ensemble Diversity in Reinforcement Learning (MED-RL), a set of regularization methods inspired from the economics and consensus optimization to improve diversity in the ensemble-based deep reinforcement learning methods by encouraging inequality between the networks during training. We integrated MED-RL in five of the most common ensemble-based deep RL algorithms for both continuous and discrete control tasks and evaluated on six Mujoco environments and six Atari games. Our results show that MED-RL augmented algorithms outperform their un-regularized counterparts significantly and in some cases achieved more than 300$\\%$ in performance gains.",
        "conference": "ICLR",
        "中文标题": "深度强化学习中最大化集成多样性",
        "摘要翻译": "现代深度强化学习（DRL）在解决一系列具有挑战性的序列决策问题方面取得了成功。大多数这些算法使用神经网络集成作为其骨干结构，并受益于神经网络之间的多样性以达到最佳结果。不幸的是，在训练阶段，集成的成员可能会在参数空间或表示空间中收敛到同一点，从而失去集成的所有优势。在本文中，我们描述了强化学习中的最大化集成多样性（MED-RL），这是一组受经济学和共识优化启发的正则化方法，通过在训练期间鼓励网络之间的不平等来提高基于集成的深度强化学习方法的多样性。我们将MED-RL集成到五种最常见的基于集成的深度强化学习算法中，用于连续和离散控制任务，并在六个Mujoco环境和六个Atari游戏上进行了评估。我们的结果表明，MED-RL增强的算法显著优于未正则化的对应算法，在某些情况下性能提升超过300%。",
        "领域": "深度强化学习、集成学习、游戏AI",
        "问题": "解决深度强化学习中集成神经网络在训练过程中可能收敛到同一点，导致集成多样性丧失的问题。",
        "动机": "通过提高集成中神经网络之间的多样性，增强深度强化学习算法的性能和鲁棒性。",
        "方法": "提出MED-RL，一组受经济学和共识优化启发的正则化方法，通过在训练期间鼓励网络之间的不平等来提高集成多样性。",
        "关键词": [
            "深度强化学习",
            "集成多样性",
            "正则化方法",
            "Mujoco环境",
            "Atari游戏"
        ],
        "涉及的技术概念": {
            "集成学习": "使用多个神经网络模型共同决策，以提高算法的性能和鲁棒性。",
            "正则化方法": "通过引入额外的约束或惩罚项，防止模型在训练过程中过拟合或失去多样性。",
            "共识优化": "一种优化策略，旨在通过协调不同模型或代理之间的决策，达到全局最优或共识。"
        },
        "success": true
    },
    {
        "order": 596,
        "title": "Maximum Entropy RL (Provably) Solves Some Robust RL Problems",
        "html": "https://iclr.cc//virtual/2022/poster/6782",
        "abstract": "Many potential applications of reinforcement learning (RL) require guarantees that the agent will perform well in the face of disturbances to the dynamics or reward function. In this paper, we prove theoretically that maximum entropy (MaxEnt) RL maximizes a lower bound on a robust RL objective, and thus can be used to learn policies that are robust to some disturbances in the dynamics and the reward function. While this capability of MaxEnt RL has been observed empirically in prior work, to the best of our knowledge our work provides the first rigorous proof and theoretical characterization of the MaxEnt RL robust set. While a number of prior robust RL algorithms have been designed to handle similar disturbances to the reward function or dynamics, these methods typically require additional moving parts and hyperparameters on top of a base RL algorithm. In contrast, our results suggest that MaxEnt RL by itself is robust to certain disturbances, without requiring any additional modifications. While this does not imply that MaxEnt RL is the best available robust RL method, MaxEnt RL is a simple robust RL method with appealing formal guarantees.",
        "conference": "ICLR",
        "中文标题": "最大熵强化学习（可证明地）解决某些鲁棒强化学习问题",
        "摘要翻译": "强化学习（RL）的许多潜在应用需要保证代理在面对动态或奖励函数的干扰时表现良好。在本文中，我们从理论上证明，最大熵（MaxEnt）RL最大化了一个鲁棒RL目标的下界，因此可以用来学习对动态和奖励函数中的某些干扰具有鲁棒性的策略。虽然MaxEnt RL的这种能力在先前的工作中已经被经验性地观察到，但据我们所知，我们的工作提供了MaxEnt RL鲁棒集的第一个严格证明和理论特征。虽然许多先前的鲁棒RL算法被设计用来处理奖励函数或动态的类似干扰，但这些方法通常需要在基础RL算法之上添加额外的移动部分和超参数。相比之下，我们的结果表明，MaxEnt RL本身对某些干扰具有鲁棒性，不需要任何额外的修改。虽然这并不意味着MaxEnt RL是目前可用的最佳鲁棒RL方法，但MaxEnt RL是一种具有吸引力的正式保证的简单鲁棒RL方法。",
        "领域": "强化学习、鲁棒控制、机器学习理论",
        "问题": "如何在面对动态或奖励函数的干扰时，保证强化学习代理的表现良好。",
        "动机": "探索最大熵强化学习在理论上对动态和奖励函数干扰的鲁棒性，提供严格的理论证明。",
        "方法": "通过理论证明最大熵强化学习能够最大化一个鲁棒强化学习目标的下界，从而学习出对特定干扰具有鲁棒性的策略。",
        "关键词": [
            "最大熵强化学习",
            "鲁棒强化学习",
            "动态干扰",
            "奖励函数干扰",
            "理论证明"
        ],
        "涉及的技术概念": {
            "最大熵强化学习": "一种强化学习方法，通过最大化策略的熵来鼓励探索，同时优化奖励。",
            "鲁棒强化学习": "旨在学习在面对环境动态或奖励函数的不确定性时仍能表现良好的策略的强化学习方法。",
            "理论证明": "通过数学方法验证最大熵强化学习在特定条件下对干扰的鲁棒性。"
        },
        "success": true
    },
    {
        "order": 597,
        "title": "Maximum n-times Coverage for Vaccine Design",
        "html": "https://iclr.cc//virtual/2022/poster/6394",
        "abstract": "We introduce the maximum $n$-times coverage problem that selects $k$ overlays to maximize the summed coverage of weighted elements, where each element must be covered at least $n$ times. We also define the min-cost $n$-times coverage problem where the objective is to select the minimum set of overlays such that the sum of the weights of elements that are covered at least $n$ times is at least $\\tau$. Maximum $n$-times coverage is a generalization of the multi-set multi-cover problem, is NP-complete, and is not submodular. We introduce two new practical solutions for $n$-times coverage based on integer linear programming and sequential greedy optimization. We show that maximum $n$-times coverage is a natural way to frame peptide vaccine design, and find that it produces a pan-strain COVID-19 vaccine design that is superior to 29 other published designs in predicted population coverage and the expected number of peptides displayed by each individual's HLA molecules.",
        "conference": "ICLR",
        "中文标题": "疫苗设计中的最大n次覆盖问题",
        "摘要翻译": "我们引入了最大n次覆盖问题，该问题选择k个覆盖层以最大化加权元素的总覆盖度，其中每个元素必须至少被覆盖n次。我们还定义了最小成本n次覆盖问题，其目标是选择最小的覆盖层集合，使得被覆盖至少n次的元素的权重之和至少为τ。最大n次覆盖问题是多集合多覆盖问题的推广，是NP完全的，并且不是子模的。我们介绍了两种基于整数线性规划和顺序贪婪优化的n次覆盖问题的实用解决方案。我们表明，最大n次覆盖问题是框架肽疫苗设计的自然方式，并且发现它在预测的人群覆盖度和每个个体的HLA分子预计显示的肽数量方面，产生了一种优于其他29种已发表设计的泛株COVID-19疫苗设计。",
        "领域": "疫苗设计优化、计算生物学、组合优化",
        "问题": "如何在疫苗设计中最大化加权元素的覆盖度，确保每个元素至少被覆盖n次，同时最小化所需的覆盖层数量。",
        "动机": "为了解决疫苗设计中如何有效覆盖多个目标元素（如病毒肽段）的问题，以提高疫苗的覆盖率和效果。",
        "方法": "提出了基于整数线性规划和顺序贪婪优化的两种解决方案，用于解决最大n次覆盖和最小成本n次覆盖问题。",
        "关键词": [
            "疫苗设计",
            "n次覆盖问题",
            "整数线性规划",
            "顺序贪婪优化",
            "COVID-19疫苗"
        ],
        "涉及的技术概念": {
            "最大n次覆盖问题": "选择k个覆盖层以最大化加权元素的总覆盖度，每个元素至少被覆盖n次。",
            "最小成本n次覆盖问题": "选择最小的覆盖层集合，使得被覆盖至少n次的元素的权重之和至少为τ。",
            "整数线性规划": "用于解决最大n次覆盖问题的数学优化方法，通过线性约束和整数变量寻找最优解。",
            "顺序贪婪优化": "一种启发式算法，逐步选择当前最优的覆盖层，以近似解决n次覆盖问题。"
        },
        "success": true
    },
    {
        "order": 598,
        "title": "MCMC Should Mix: Learning Energy-Based Model with Neural Transport Latent Space MCMC",
        "html": "https://iclr.cc//virtual/2022/poster/6004",
        "abstract": "Learning energy-based model (EBM) requires MCMC sampling of the learned model as an inner loop of the learning algorithm. However, MCMC sampling of EBMs in high-dimensional data space is generally not mixing, because the energy function, which is usually parametrized by deep network, is highly multi-modal in the data space. This is a serious handicap for both theory and practice of EBMs. In this paper, we propose to learn EBM with a flow-based model (or in general latent variable model) serving as a backbone, so that the EBM is a correction or an exponential tilting of the flow-based model. We show that the model has a particularly simple form in the space of the latent variables of the generative model, and MCMC sampling of the EBM in the latent space mixes well and traverses modes in the data space. This enables proper sampling and learning of EBMs.",
        "conference": "ICLR",
        "中文标题": "MCMC应当混合：基于神经传输潜在空间MCMC学习能量模型",
        "摘要翻译": "学习能量模型（EBM）需要将学习模型的MCMC采样作为学习算法的内循环。然而，在高维数据空间中，EBM的MCMC采样通常不混合，因为通常由深度网络参数化的能量函数在数据空间中具有高度多模态。这对EBM的理论和实践都是一个严重的障碍。在本文中，我们提出使用基于流的模型（或一般的潜在变量模型）作为骨干来学习EBM，因此EBM是基于流模型的修正或指数倾斜。我们展示了该模型在生成模型的潜在变量空间中具有特别简单的形式，并且在潜在空间中的EBM的MCMC采样混合良好并在数据空间中遍历模态。这使得EBM能够进行适当的采样和学习。",
        "领域": "生成模型、能量模型、MCMC采样",
        "问题": "解决在高维数据空间中EBM的MCMC采样不混合的问题",
        "动机": "由于能量函数在高维数据空间中的多模态特性，导致MCMC采样不混合，影响了EBM的学习和应用",
        "方法": "提出使用基于流的模型作为骨干来学习EBM，通过在潜在空间中进行MCMC采样，实现良好的混合和模态遍历",
        "关键词": [
            "能量模型",
            "MCMC采样",
            "潜在空间",
            "基于流的模型",
            "多模态"
        ],
        "涉及的技术概念": {
            "能量模型（EBM）": "一种通过能量函数定义概率分布的生成模型，本文中通过修正或指数倾斜基于流的模型来学习",
            "MCMC采样": "马尔可夫链蒙特卡罗采样，用于从概率分布中抽取样本，本文中在潜在空间中进行以实现良好的混合",
            "潜在空间": "由潜在变量构成的空间，本文中展示了EBM在此空间中的简单形式，并在此空间中进行MCMC采样"
        },
        "success": true
    },
    {
        "order": 599,
        "title": "Measuring CLEVRness: Black-box Testing of Visual Reasoning Models",
        "html": "https://iclr.cc//virtual/2022/poster/6011",
        "abstract": "How can we measure the reasoning capabilities of intelligence systems? Visual question answering provides a convenient framework for testing the model's abilities by interrogating the model through questions about the scene. However, despite scores of various visual QA datasets and architectures, which sometimes yield even a super-human performance, the question of whether those architectures can actually reason remains open to debate.To answer this, we extend the visual question answering framework and propose the following behavioral test in the form of a two-player game. We consider black-box neural models of CLEVR. These models are trained on a diagnostic dataset benchmarking reasoning. Next, we train an adversarial player that re-configures the scene to fool the CLEVR model. We show that CLEVR models, which otherwise could perform at a ``human-level'', can easily be fooled by our agent. Our results put in doubt whether data-driven approaches can do reasoning without exploiting the numerous biases that are often present in those datasets. Finally, we also propose a controlled experiment measuring the efficiency of such models to learn and perform reasoning.",
        "conference": "ICLR",
        "中文标题": "测量CLEVRness：视觉推理模型的黑盒测试",
        "摘要翻译": "我们如何衡量智能系统的推理能力？视觉问答提供了一个方便的框架，通过询问模型关于场景的问题来测试模型的能力。然而，尽管有各种视觉问答数据集和架构，有时甚至能达到超人的表现，但这些架构是否真的能够推理仍然是一个开放的问题。为了回答这个问题，我们扩展了视觉问答框架，并提出了以下行为测试，形式为一个双人游戏。我们考虑了CLEVR的黑盒神经模型。这些模型在一个基准推理的诊断数据集上进行了训练。接着，我们训练了一个对抗性玩家，该玩家重新配置场景以愚弄CLEVR模型。我们展示了那些在其他情况下可以达到“人类水平”的CLEVR模型，可以轻易被我们的代理愚弄。我们的结果让人怀疑数据驱动的方法是否能够在不利用那些数据集中经常存在的众多偏见的情况下进行推理。最后，我们还提出了一个控制实验，测量这些模型学习和执行推理的效率。",
        "领域": "视觉问答、模型测试与评估、对抗性学习",
        "问题": "评估视觉推理模型是否真正具备推理能力，而非仅仅依赖数据集中的偏见。",
        "动机": "当前视觉问答模型虽然在性能上有时能达到人类水平，但其是否真正具备推理能力尚不明确，研究旨在开发一种方法来测试和验证模型的真实推理能力。",
        "方法": "通过扩展视觉问答框架，设计一个双人游戏形式的测试，包括训练一个对抗性玩家来挑战CLEVR模型，以及进行控制实验来测量模型的推理效率。",
        "关键词": [
            "视觉推理",
            "黑盒测试",
            "对抗性学习",
            "CLEVR",
            "模型评估"
        ],
        "涉及的技术概念": {
            "视觉问答框架": "用于测试模型通过回答问题展示其理解和推理能力的框架。",
            "黑盒神经模型": "指那些内部工作机制不透明，仅通过输入和输出进行交互的模型，此处特指CLEVR模型。",
            "对抗性玩家": "一种通过学习重新配置场景来挑战和测试目标模型（如CLEVR模型）能力的代理，旨在揭示模型的潜在弱点和偏见。"
        },
        "success": true
    },
    {
        "order": 600,
        "title": "Measuring the Interpretability of Unsupervised Representations via Quantized Reversed Probing",
        "html": "https://iclr.cc//virtual/2022/poster/6146",
        "abstract": "Self-supervised visual representation learning has recently attracted significant research interest. While a common way to evaluate self-supervised representations is through transfer to various downstream tasks, we instead investigate the problem of measuring their interpretability, i.e. understanding the semantics encoded in raw representations. We formulate the latter as estimating the mutual information between the representation and a space of manually labelled concepts. To quantify this we introduce a decoding bottleneck: information must be captured by simple predictors, mapping concepts to clusters in representation space. This approach, which we call reverse linear probing, provides a single number sensitive to the semanticity of the representation. This measure is also able to detect when the representation contains combinations of concepts (e.g., 'red apple'') instead of just individual attributes ('red'' and 'apple'' independently). Finally, we propose to use supervised classifiers to automatically label large datasets in order to enrich the space of concepts used for probing. We use our method to evaluate a large number of self-supervised representations, ranking them by interpretability, highlight the differences that emerge compared to the standard evaluation with linear probes and discuss several qualitative insights. Code at: https://github.com/iro-cp/ssl-qrp.",
        "conference": "ICLR",
        "中文标题": "通过量化反向探测测量无监督表示的可解释性",
        "摘要翻译": "自监督视觉表示学习最近吸引了大量的研究兴趣。虽然评估自监督表示的常见方法是通过迁移到各种下游任务，但我们转而研究测量其可解释性的问题，即理解原始表示中编码的语义。我们将后者表述为估计表示与手动标记概念空间之间的互信息。为了量化这一点，我们引入了解码瓶颈：信息必须由简单的预测器捕获，将概念映射到表示空间中的聚类。这种方法，我们称之为反向线性探测，提供了一个对表示的语义性敏感的数字。这个度量还能够检测表示是否包含概念的组合（例如，‘红苹果’），而不仅仅是单个属性（‘红’和‘苹果’独立）。最后，我们建议使用监督分类器自动标记大型数据集，以丰富用于探测的概念空间。我们使用我们的方法评估了大量自监督表示，按可解释性排名，突出了与使用线性探测的标准评估相比出现的差异，并讨论了几个定性见解。代码位于：https://github.com/iro-cp/ssl-qrp。",
        "领域": "自监督学习、表示学习、计算机视觉",
        "问题": "如何测量和评估无监督学习得到的视觉表示的可解释性。",
        "动机": "研究动机是为了更好地理解自监督学习得到的视觉表示中编码的语义信息，以及如何量化这些表示的可解释性。",
        "方法": "提出了一种称为反向线性探测的方法，通过估计表示与手动标记概念空间之间的互信息，并使用简单的预测器将概念映射到表示空间中的聚类，来量化表示的可解释性。",
        "关键词": [
            "自监督学习",
            "表示可解释性",
            "反向线性探测",
            "互信息",
            "概念映射"
        ],
        "涉及的技术概念": {
            "反向线性探测": "一种通过简单预测器将手动标记的概念映射到表示空间中的聚类，以量化表示可解释性的方法。",
            "互信息": "用于估计表示与手动标记概念空间之间关系的信息理论度量，帮助量化表示中编码的语义信息。",
            "解码瓶颈": "在量化表示可解释性过程中引入的限制，要求信息必须由简单的预测器捕获，确保评估的简洁性和有效性。"
        },
        "success": true
    },
    {
        "order": 601,
        "title": "Memorizing Transformers",
        "html": "https://iclr.cc//virtual/2022/poster/6064",
        "abstract": "Language models typically need to be trained or finetuned in order to acquire new knowledge, which involves updating their weights.  We instead envision language models that can simply read and memorize new data at inference time, thus acquiring new knowledge immediately. In this work, we extend language models with the ability to memorize the internal representations of past inputs. We demonstrate that an approximate $k$NN lookup into a non-differentiable memory of recent (key, value) pairs improves language modeling across various benchmarks and tasks, including generic webtext (C4), math papers (arXiv), books (PG-19), code (Github), as well as formal theorems (Isabelle). We show that the performance steadily improves when we increase the size of memory up to 262K tokens. On benchmarks including code and mathematics, we find that the model is capable of making use of newly defined functions and theorems during test time.",
        "conference": "ICLR",
        "中文标题": "记忆变换器",
        "摘要翻译": "语言模型通常需要通过训练或微调来获取新知识，这涉及到更新它们的权重。我们设想语言模型能够在推理时简单地读取和记忆新数据，从而立即获取新知识。在这项工作中，我们扩展了语言模型的能力，使其能够记忆过去输入的内部表示。我们证明，通过对最近（键，值）对的非可微分记忆进行近似的$k$NN查找，可以在各种基准和任务上改进语言建模，包括通用网络文本（C4）、数学论文（arXiv）、书籍（PG-19）、代码（Github）以及形式定理（Isabelle）。我们发现，当我们将记忆的大小增加到262K个标记时，性能稳步提高。在包括代码和数学在内的基准测试中，我们发现模型能够在测试时利用新定义的函数和定理。",
        "领域": "自然语言处理与视觉结合",
        "问题": "如何使语言模型在推理时获取新知识而无需重新训练或微调",
        "动机": "探索语言模型在推理时直接读取和记忆新数据的能力，以立即获取新知识",
        "方法": "扩展语言模型的能力，使其能够记忆过去输入的内部表示，并通过近似的$k$NN查找改进语言建模",
        "关键词": [
            "记忆变换器",
            "语言模型",
            "知识获取",
            "推理时间学习",
            "kNN查找"
        ],
        "涉及的技术概念": {
            "记忆变换器": "扩展语言模型的能力，使其能够记忆过去输入的内部表示",
            "kNN查找": "用于在非可微分记忆中进行近似查找，以改进语言建模",
            "推理时间学习": "模型在推理时直接读取和记忆新数据的能力，以立即获取新知识"
        },
        "success": true
    },
    {
        "order": 602,
        "title": "Memory Augmented Optimizers for Deep Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6310",
        "abstract": "Popular approaches for minimizing loss in data-driven learning often involve an abstraction or an explicit retention of the history of gradients for efficient parameter updates. The aggregated history of gradients nudges the parameter updates in the right direction even when the gradients at any given step are not informative. Although the history of gradients summarized in meta-parameters or explicitly stored in memory has been shown effective in theory and practice, the question of whether $all$ or only a subset of the gradients in the history are sufficient in deciding the parameter updates remains unanswered. In this paper, we propose a framework of memory-augmented gradient descent optimizers that retain a limited view of their gradient history in their internal memory. Such optimizers scale well to large real-life datasets, and our experiments show that the memory augmented extensions of standard optimizers enjoy accelerated convergence and improved performance on a majority of computer vision and language tasks that we considered.Additionally, we prove that the proposed class of optimizers with fixed-size memory converge under assumptions of strong convexity, regardless of which gradients are selected or how they are linearly combined to form the update step.",
        "conference": "ICLR",
        "中文标题": "深度学习的内存增强优化器",
        "摘要翻译": "在数据驱动的学习中，最小化损失的流行方法通常涉及对梯度历史的抽象或显式保留，以实现有效的参数更新。即使在任何给定步骤的梯度信息不足，聚合的梯度历史也能推动参数更新朝着正确的方向前进。尽管在元参数中总结的或显式存储在内存中的梯度历史在理论和实践中已被证明是有效的，但关于历史梯度中的全部或仅一部分是否足以决定参数更新的问题仍未得到解答。在本文中，我们提出了一种内存增强梯度下降优化器的框架，这些优化器在其内部内存中保留了梯度历史的有限视图。此类优化器能够很好地扩展到大型现实生活数据集，我们的实验表明，标准优化器的内存增强扩展在大多数我们考虑的计算机视觉和语言任务上享有加速收敛和性能提升。此外，我们证明了在强凸性假设下，具有固定大小内存的优化器类无论选择哪些梯度或如何线性组合它们以形成更新步骤，都能收敛。",
        "领域": "深度学习优化、计算机视觉、自然语言处理",
        "问题": "如何有效地利用梯度历史来优化深度学习模型的参数更新",
        "动机": "探索梯度历史中哪些部分对参数更新最为关键，以提高优化效率和模型性能",
        "方法": "提出了一种内存增强梯度下降优化器的框架，通过保留有限的梯度历史视图来优化参数更新",
        "关键词": [
            "内存增强优化器",
            "梯度下降",
            "深度学习优化",
            "计算机视觉",
            "自然语言处理"
        ],
        "涉及的技术概念": {
            "梯度历史": "优化器中用于指导参数更新的过去梯度信息的集合",
            "内存增强优化器": "一种通过内部内存保留有限梯度历史视图以改进参数更新策略的优化器",
            "强凸性": "在优化理论中，保证优化算法收敛的一种数学性质"
        },
        "success": true
    },
    {
        "order": 603,
        "title": "Memory Replay with Data Compression for Continual Learning",
        "html": "https://iclr.cc//virtual/2022/poster/5928",
        "abstract": "Continual learning needs to overcome catastrophic forgetting of the past. Memory replay of representative old training samples has been shown as an effective solution, and achieves the state-of-the-art (SOTA) performance. However, existing work is mainly built on a small memory buffer containing a few original data, which cannot fully characterize the old data distribution. In this work, we propose memory replay with data compression to reduce the storage cost of old training samples and thus increase their amount that can be stored in the memory buffer. Observing that the trade-off between the quality and quantity of compressed data is highly nontrivial for the efficacy of memory replay, we propose a novel method based on determinantal point processes (DPPs) to efficiently determine an appropriate compression quality for currently-arrived training samples. In this way, using a naive data compression algorithm with a properly selected quality can largely boost recent strong baselines by saving more compressed data in a limited storage space. We extensively validate this across several benchmarks of class-incremental learning and in a realistic scenario of object detection for autonomous driving.",
        "conference": "ICLR",
        "中文标题": "用于持续学习的数据压缩记忆回放",
        "摘要翻译": "持续学习需要克服对过去的灾难性遗忘。代表性旧训练样本的记忆回放已被证明是一种有效的解决方案，并实现了最先进的（SOTA）性能。然而，现有的工作主要建立在包含少量原始数据的小型记忆缓冲区上，这无法完全表征旧数据的分布。在这项工作中，我们提出了数据压缩记忆回放，以减少旧训练样本的存储成本，从而增加可以存储在记忆缓冲区中的数量。观察到压缩数据的质量和数量之间的权衡对于记忆回放的效果非常重要，我们提出了一种基于确定性点过程（DPPs）的新方法，以有效确定当前到达的训练样本的适当压缩质量。通过这种方式，使用具有适当选择质量的简单数据压缩算法，可以在有限的存储空间中保存更多压缩数据，从而大大提升最近的强大基线。我们在几个类增量学习的基准测试和自动驾驶目标检测的现实场景中广泛验证了这一点。",
        "领域": "持续学习、类增量学习、目标检测",
        "问题": "如何在有限的存储空间内，通过数据压缩技术增加记忆缓冲区中旧训练样本的数量，以克服持续学习中的灾难性遗忘问题。",
        "动机": "现有的持续学习方法依赖于小型记忆缓冲区中的少量原始数据，无法充分表征旧数据的分布，限制了记忆回放的效果。",
        "方法": "提出了一种基于确定性点过程（DPPs）的方法，用于确定训练样本的适当压缩质量，以在有限的存储空间中保存更多压缩数据，从而提升记忆回放的效果。",
        "关键词": [
            "持续学习",
            "数据压缩",
            "记忆回放",
            "确定性点过程",
            "类增量学习"
        ],
        "涉及的技术概念": {
            "记忆回放": "通过回放代表性旧训练样本来克服持续学习中的灾难性遗忘问题。",
            "数据压缩": "减少旧训练样本的存储成本，增加记忆缓冲区中可以存储的数量。",
            "确定性点过程（DPPs）": "用于有效确定当前到达的训练样本的适当压缩质量，以优化记忆回放的效果。"
        },
        "success": true
    },
    {
        "order": 604,
        "title": "Mention Memory: incorporating textual knowledge into Transformers through entity mention attention",
        "html": "https://iclr.cc//virtual/2022/poster/6941",
        "abstract": "Natural language understanding tasks such as open-domain question answering often require retrieving and assimilating factual information from multiple sources. We propose to address this problem by integrating a semi-parametric representation of a large text corpus into a Transformer model as a source of factual knowledge. Specifically, our method represents knowledge with ``mention memory'', a table of dense vector representations of every entity mention in a corpus. The proposed model - TOME - is a Transformer that accesses the information through internal memory layers in which each entity mention in the input passage attends to the mention memory. This approach enables synthesis of and reasoning over many disparate sources of information within a single Transformer model. In experiments using a memory of 150 million Wikipedia mentions, TOME achieves strong  performance on several open-domain knowledge-intensive tasks, including the claim verification benchmarks HoVer and FEVER and several entity-based QA benchmarks. We also show that the model learns to attend to informative mentions without any direct supervision.  Finally we demonstrate that the model can generalize to new unseen entities by updating the memory without retraining.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "提及记忆：通过实体提及注意力将文本知识融入Transformer",
        "摘要翻译": "自然语言理解任务，如开放领域问答，通常需要从多个来源检索并整合事实信息。我们提出通过将大型文本语料库的半参数化表示作为事实知识源集成到Transformer模型中来解决这一问题。具体而言，我们的方法使用'提及记忆'来表示知识，这是一个包含语料库中每个实体提及的密集向量表示的表。提出的模型——TOME——是一个通过内部记忆层访问信息的Transformer，其中输入段落中的每个实体提及都会关注提及记忆。这种方法使得在单个Transformer模型内能够综合和推理多种不同的信息来源。在使用包含1.5亿个维基百科提及的记忆的实验中，TOME在多个开放领域知识密集型任务上表现出色，包括声明验证基准HoVer和FEVER以及几个基于实体的问答基准。我们还展示了模型能够在没有任何直接监督的情况下学会关注信息丰富的提及。最后，我们证明了模型可以通过更新记忆而不重新训练来泛化到新的未见实体。",
        "领域": "开放领域问答, 声明验证, 实体链接",
        "问题": "如何在自然语言理解任务中有效地检索和整合来自多个来源的事实信息。",
        "动机": "提高开放领域问答等任务中事实信息检索和整合的效率和准确性。",
        "方法": "提出了一种名为TOME的Transformer模型，通过内部记忆层访问包含语料库中每个实体提及的密集向量表示的'提及记忆'，以综合和推理多种不同的信息来源。",
        "关键词": [
            "提及记忆",
            "Transformer模型",
            "开放领域问答",
            "声明验证",
            "实体链接"
        ],
        "涉及的技术概念": {
            "提及记忆": "一个包含语料库中每个实体提及的密集向量表示的表，用于作为事实知识源集成到Transformer模型中。",
            "Transformer模型": "一种基于自注意力机制的深度学习模型，用于处理序列数据，如自然语言文本。",
            "内部记忆层": "模型中的特定层，用于访问和利用提及记忆中的信息，以支持信息的综合和推理。"
        }
    },
    {
        "order": 605,
        "title": "Message Passing Neural PDE Solvers",
        "html": "https://iclr.cc//virtual/2022/poster/7134",
        "abstract": "The numerical solution of partial differential equations (PDEs) is difficult, having led to a century of research so far. Recently, there have been pushes to build neural--numerical hybrid solvers, which piggy-backs the modern trend towards fully end-to-end learned systems. Most works so far can only generalize over a subset of properties to which a generic solver would be faced, including: resolution, topology, geometry, boundary conditions, domain discretization regularity, dimensionality, etc. In this work, we build a solver, satisfying these properties, where all the components are based on neural message passing, replacing all heuristically designed components in the computation graph with backprop-optimized neural function approximators. We show that neural message passing solvers representationally contain some classical methods, such as finite differences, finite volumes, and WENO schemes. In order to encourage stability in training autoregressive models, we put forward a method that is based on the principle of zero-stability, posing stability as a domain adaptation problem. We validate our method on various fluid-like flow problems, demonstrating fast, stable, and accurate performance across different domain topologies, discretization, etc. in 1D and 2D. Our model outperforms state-of-the-art numerical solvers in the low resolution regime in terms of speed, and accuracy.",
        "conference": "ICLR",
        "中文标题": "消息传递神经偏微分方程求解器",
        "摘要翻译": "偏微分方程（PDEs）的数值求解是一个难题，迄今为止已经引领了一个世纪的研究。最近，有推动构建神经-数值混合求解器的趋势，这顺应了现代向完全端到端学习系统的发展趋势。到目前为止，大多数工作只能泛化于通用求解器将面临的一部分属性，包括：分辨率、拓扑、几何、边界条件、域离散化规律性、维度等。在这项工作中，我们构建了一个满足这些属性的求解器，其中所有组件都基于神经消息传递，将计算图中所有启发式设计的组件替换为反向传播优化的神经函数近似器。我们展示了神经消息传递求解器在表示上包含一些经典方法，如有限差分、有限体积和WENO方案。为了在训练自回归模型时鼓励稳定性，我们提出了一种基于零稳定性原则的方法，将稳定性作为一个域适应问题提出。我们在各种流体流动问题上验证了我们的方法，在1D和2D中展示了跨不同域拓扑、离散化等的快速、稳定和准确的性能。我们的模型在低分辨率状态下在速度和准确性方面优于最先进的数值求解器。",
        "领域": "偏微分方程数值解、神经网络应用、计算流体力学",
        "问题": "解决偏微分方程数值求解中的泛化能力和计算效率问题",
        "动机": "构建一个能够泛化处理多种PDE属性的神经-数值混合求解器，以提升求解效率和准确性",
        "方法": "基于神经消息传递构建求解器，替换传统启发式组件，采用零稳定性原则优化训练稳定性",
        "关键词": [
            "神经消息传递",
            "偏微分方程求解",
            "计算流体力学",
            "零稳定性",
            "自回归模型"
        ],
        "涉及的技术概念": {
            "神经消息传递": "用于构建求解器的核心技术，通过优化神经函数近似器替换传统启发式组件",
            "零稳定性": "提出的一种训练自回归模型的方法，将稳定性视为域适应问题",
            "自回归模型": "在训练过程中用于预测下一步解，通过零稳定性原则优化以提高稳定性"
        },
        "success": true
    },
    {
        "order": 606,
        "title": "Meta Discovery: Learning to Discover Novel Classes given Very Limited Data",
        "html": "https://iclr.cc//virtual/2022/poster/6442",
        "abstract": "In novel class discovery (NCD), we are given labeled data from seen classes and unlabeled data from unseen classes, and we train clustering models for the unseen classes. However, the implicit assumptions behind NCD are still unclear. In this paper, we demystify assumptions behind NCD and find that high-level semantic features should be shared among the seen and unseen classes. Based on this finding, NCD is theoretically solvable under certain assumptions and can be naturally linked to meta-learning that has exactly the same assumption as NCD. Thus, we can empirically solve the NCD problem by meta-learning algorithms after slight modifications. This meta-learning-based methodology significantly reduces the amount of unlabeled data needed for training and makes it more practical, as demonstrated in experiments. The use of very limited data is also justified by the application scenario of NCD: since it is unnatural to label only seen-class data, NCD is sampling instead of labeling in causality. Therefore, unseen-class data should be collected on the way of collecting seen-class data, which is why they are novel and first need to be clustered.",
        "conference": "ICLR",
        "中文标题": "元发现：在数据极其有限的情况下学习发现新类别",
        "摘要翻译": "在新类别发现（NCD）中，我们拥有来自已知类别的标记数据和来自未知类别的未标记数据，我们为未知类别训练聚类模型。然而，NCD背后的隐含假设仍然不明确。在本文中，我们揭示了NCD背后的假设，并发现高级语义特征应该在已知和未知类别之间共享。基于这一发现，NCD在特定假设下理论上是可以解决的，并且可以自然地与具有完全相同假设的元学习联系起来。因此，我们可以通过稍作修改的元学习算法来实证解决NCD问题。这种基于元学习的方法显著减少了训练所需的未标记数据量，使其更加实用，如实验所示。使用非常有限的数据也由NCD的应用场景所证明：因为仅标记已知类别数据是不自然的，NCD在因果关系中是采样而非标记。因此，未知类别数据应该在收集已知类别数据的过程中被收集，这就是为什么它们是新的并且首先需要被聚类。",
        "领域": "元学习",
        "问题": "解决在新类别发现（NCD）中如何利用有限的未标记数据有效训练聚类模型的问题",
        "动机": "揭示NCD背后的隐含假设，并基于这些假设将NCD与元学习联系起来，以减少所需的未标记数据量",
        "方法": "通过将NCD问题与元学习联系起来，并稍作修改的元学习算法来实证解决NCD问题",
        "关键词": [
            "新类别发现",
            "元学习",
            "聚类模型",
            "语义特征",
            "有限数据"
        ],
        "涉及的技术概念": {
            "新类别发现（NCD）": "在新类别发现中，利用已知类别的标记数据和未知类别的未标记数据训练聚类模型",
            "元学习": "通过将NCD问题与元学习联系起来，利用元学习算法解决NCD问题",
            "语义特征共享": "高级语义特征在已知和未知类别之间共享，这是NCD理论上可解决的基础"
        },
        "success": true
    },
    {
        "order": 607,
        "title": "Meta-Imitation Learning by Watching Video Demonstrations",
        "html": "https://iclr.cc//virtual/2022/poster/6881",
        "abstract": "Meta-Imitation Learning is a promising technique for the robot to learn a new task from observing one or a few human demonstrations. However, it usually requires a significant number of demonstrations both from humans and robots during the meta-training phase, which is a laborious and hard work for data collection, especially in recording the actions and specifying the correspondence between human and robot. In this work, we present an approach of meta-imitation learning by watching video demonstrations from humans. In comparison to prior works, our approach is able to translate human videos into practical robot demonstrations and train the meta-policy with adaptive loss based on the quality of the translated data. Our approach relies only on human videos and does not require robot demonstration, which facilitates data collection and is more in line with human imitation behavior. Experiments reveal that our method achieves the comparable performance to the baseline on fast learning a set of vision-based tasks through watching a single video demonstration.",
        "conference": "ICLR",
        "中文标题": "通过观看视频演示进行元模仿学习",
        "摘要翻译": "元模仿学习是一种让机器人通过观察一个或几个人类演示来学习新任务的有前景的技术。然而，在元训练阶段，它通常需要大量的人类和机器人演示，这对于数据收集来说是一项费力且困难的工作，尤其是在记录动作和指定人类与机器人之间的对应关系时。在这项工作中，我们提出了一种通过观看人类视频演示进行元模仿学习的方法。与之前的工作相比，我们的方法能够将人类视频转化为实际的机器人演示，并根据转化数据的质量使用自适应损失训练元策略。我们的方法仅依赖于人类视频，不需要机器人演示，这简化了数据收集过程，更符合人类的模仿行为。实验表明，我们的方法在通过观看单个视频演示快速学习一组基于视觉的任务方面，达到了与基线相当的性能。",
        "领域": "机器人学习、视觉模仿学习、元学习",
        "问题": "减少元模仿学习在训练阶段对人类和机器人演示的依赖，简化数据收集过程。",
        "动机": "解决元模仿学习在数据收集上的高成本和复杂性，使其更接近人类的自然模仿行为。",
        "方法": "通过将人类视频转化为机器人演示，并使用基于转化数据质量的自适应损失训练元策略。",
        "关键词": [
            "元模仿学习",
            "视频演示",
            "自适应损失",
            "机器人学习",
            "视觉任务"
        ],
        "涉及的技术概念": {
            "元模仿学习": "一种让机器人通过观察演示学习新任务的技术，旨在减少对大量演示的依赖。",
            "自适应损失": "根据转化数据的质量调整损失函数，优化元策略的训练过程。",
            "视频转化": "将人类视频演示转化为机器人可执行的演示，减少对实际机器人演示的需求。"
        },
        "success": true
    },
    {
        "order": 608,
        "title": "Meta Learning Low Rank Covariance Factors for Energy Based Deterministic Uncertainty",
        "html": "https://iclr.cc//virtual/2022/poster/6127",
        "abstract": "Numerous recent works utilize bi-Lipschitz regularization of neural network layers to preserve relative distances between data instances in the feature spaces of each layer. This distance sensitivity with respect to the data aids in tasks such as uncertainty calibration and out-of-distribution (OOD) detection. In previous works, features extracted with a distance sensitive model are used to construct feature covariance matrices which are used in deterministic uncertainty estimation or OOD detection. However, in cases where there is a distribution over tasks, these methods result in covariances which are sub-optimal, as they may not leverage all of the meta information which can be shared among tasks. With the use of an attentive set encoder, we propose to meta learn either diagonal or diagonal plus low-rank factors to efficiently construct task specific covariance matrices. Additionally, we propose an inference procedure which utilizes scaled energy to achieve a final predictive distribution which is well calibrated under a distributional dataset shift. ",
        "conference": "ICLR",
        "中文标题": "元学习低秩协方差因子用于基于能量的确定性不确定性",
        "摘要翻译": "最近许多工作利用神经网络层的双Lipschitz正则化来保持数据实例在每一层特征空间中相对距离的敏感性。这种对数据的距离敏感性有助于诸如不确定性校准和分布外（OOD）检测等任务。在以往的工作中，使用距离敏感模型提取的特征被用来构建特征协方差矩阵，这些矩阵用于确定性不确定性估计或OOD检测。然而，在存在任务分布的情况下，这些方法产生的协方差矩阵可能不是最优的，因为它们可能没有利用可以在任务之间共享的所有元信息。通过使用一个注意力集合编码器，我们提出元学习对角线或对角线加低秩因子，以高效构建任务特定的协方差矩阵。此外，我们提出了一种推理过程，该过程利用缩放能量来实现一个在分布数据集偏移下校准良好的最终预测分布。",
        "领域": "不确定性估计, 元学习, 分布外检测",
        "问题": "在存在任务分布的情况下，如何构建最优的任务特定协方差矩阵以提高不确定性估计和OOD检测的性能",
        "动机": "现有的方法在任务分布情况下可能无法充分利用任务间可共享的元信息，导致协方差矩阵不是最优的",
        "方法": "通过注意力集合编码器元学习对角线或对角线加低秩因子，构建任务特定协方差矩阵，并提出基于缩放能量的推理过程",
        "关键词": [
            "元学习",
            "协方差矩阵",
            "不确定性估计",
            "分布外检测",
            "注意力机制"
        ],
        "涉及的技术概念": {
            "双Lipschitz正则化": "用于保持数据实例在特征空间中相对距离的敏感性，有助于不确定性校准和OOD检测",
            "注意力集合编码器": "用于元学习对角线或对角线加低秩因子，以高效构建任务特定的协方差矩阵",
            "缩放能量": "在推理过程中使用，以实现一个在分布数据集偏移下校准良好的最终预测分布"
        },
        "success": true
    },
    {
        "order": 609,
        "title": "Meta-Learning with Fewer Tasks through Task Interpolation",
        "html": "https://iclr.cc//virtual/2022/poster/7140",
        "abstract": "Meta-learning enables algorithms to quickly learn a newly encountered task with just a few labeled examples by transferring previously learned knowledge. However, the bottleneck of current meta-learning algorithms is the requirement of a large number of meta-training tasks, which may not be accessible in real-world scenarios. To address the challenge that available tasks may not densely sample the space of tasks, we propose to augment the task set through interpolation. By meta-learning with task interpolation (MLTI), our approach effectively generates additional tasks by randomly sampling a pair of tasks and interpolating the corresponding features and labels. Under both gradient-based and metric-based meta-learning settings, our theoretical analysis shows MLTI corresponds to a data-adaptive meta-regularization and further improves the generalization. Empirically, in our experiments on eight datasets from diverse domains including image recognition, pose prediction, molecule property prediction, and medical image classification, we find that the proposed general MLTI framework is compatible with representative meta-learning algorithms and consistently outperforms other state-of-the-art strategies.",
        "conference": "ICLR",
        "中文标题": "通过任务插值实现少量任务的元学习",
        "摘要翻译": "元学习使算法能够通过转移先前学到的知识，仅用少量标记示例快速学习新遇到的任务。然而，当前元学习算法的瓶颈是需要大量的元训练任务，这在现实场景中可能难以满足。为了解决可用任务可能无法密集采样任务空间的挑战，我们提出通过插值来增强任务集。通过任务插值的元学习（MLTI），我们的方法通过随机采样一对任务并插值相应的特征和标签，有效地生成额外的任务。在基于梯度和基于度量的元学习设置下，我们的理论分析表明MLTI对应于数据自适应的元正则化，并进一步提高了泛化能力。实证上，在我们对来自不同领域的八个数据集进行的实验中，包括图像识别、姿态预测、分子属性预测和医学图像分类，我们发现提出的通用MLTI框架与代表性的元学习算法兼容，并始终优于其他最先进的策略。",
        "领域": "元学习、图像识别、医学图像分类",
        "问题": "解决元学习算法在现实场景中因缺乏大量元训练任务而面临的性能瓶颈问题",
        "动机": "通过任务插值技术增强任务集，以在少量任务的情况下提高元学习算法的泛化能力",
        "方法": "提出任务插值的元学习（MLTI）方法，通过随机采样和插值任务对的特征和标签来生成额外任务，适用于基于梯度和基于度量的元学习设置",
        "关键词": [
            "元学习",
            "任务插值",
            "泛化能力",
            "数据自适应",
            "元正则化"
        ],
        "涉及的技术概念": {
            "任务插值": "通过随机采样一对任务并插值其特征和标签来生成额外任务，以增强任务集",
            "元正则化": "在元学习过程中引入的正则化技术，通过任务插值实现，旨在提高模型的泛化能力",
            "数据自适应": "指MLTI方法能够根据可用任务的特点自动调整插值策略，以适应不同的数据分布"
        },
        "success": true
    },
    {
        "order": 610,
        "title": "MetaMorph: Learning Universal Controllers with Transformers",
        "html": "https://iclr.cc//virtual/2022/poster/6939",
        "abstract": "Multiple domains like vision, natural language, and audio are witnessing tremendous progress by leveraging Transformers for large scale pre-training followed by task specific fine tuning. In contrast, in robotics we primarily train a single robot for a single task. However, modular robot systems now allow for the flexible combination of general-purpose building blocks into task optimized morphologies. However, given the exponentially large number of possible robot morphologies, training a controller for each new design is impractical. In this work, we propose MetaMorph, a Transformer based approach to learn a universal controller over a modular robot design space. MetaMorph is based on the insight that robot morphology is just another modality on which we can condition the output of a Transformer. Through extensive experiments we demonstrate that large scale pre-training on a variety of robot morphologies results in policies with combinatorial generalization capabilities, including zero shot generalization to unseen robot morphologies. We further demonstrate that our pre-trained policy can be used for sample-efficient transfer to completely new robot morphologies and tasks.",
        "conference": "ICLR",
        "中文标题": "MetaMorph：使用Transformers学习通用控制器",
        "摘要翻译": "在视觉、自然语言和音频等多个领域，通过利用Transformers进行大规模预训练后针对特定任务进行微调，见证了巨大的进步。相比之下，在机器人学中，我们主要针对单一任务训练单一机器人。然而，模块化机器人系统现在允许将通用构建块灵活组合成任务优化的形态。但是，考虑到可能的机器人形态数量呈指数级增长，为每个新设计训练一个控制器是不现实的。在这项工作中，我们提出了MetaMorph，一种基于Transformer的方法，用于在模块化机器人设计空间上学习通用控制器。MetaMorph基于这样的见解：机器人形态只是我们可以用来调节Transformer输出的另一种模态。通过大量实验，我们证明了对各种机器人形态进行大规模预训练可以产生具有组合泛化能力的策略，包括对未见过的机器人形态的零样本泛化。我们进一步证明，我们预训练的策略可以用于样本高效地迁移到完全新的机器人形态和任务上。",
        "领域": "机器人控制、模块化机器人、Transformer应用",
        "问题": "如何为数量呈指数级增长的模块化机器人形态高效地训练通用控制器",
        "动机": "解决为每种新设计的机器人形态单独训练控制器的不切实际问题，实现机器人控制的通用性和高效性",
        "方法": "提出基于Transformer的MetaMorph方法，通过在多种机器人形态上进行大规模预训练，学习通用控制器，实现组合泛化和零样本泛化能力",
        "关键词": [
            "模块化机器人",
            "通用控制器",
            "Transformer",
            "预训练",
            "零样本泛化"
        ],
        "涉及的技术概念": {
            "Transformer": "用于处理机器人形态作为一种模态，调节输出以实现通用控制",
            "大规模预训练": "在多种机器人形态上进行训练，以提高模型的泛化能力和效率",
            "零样本泛化": "模型能够对未见过的机器人形态进行有效控制，无需额外训练"
        },
        "success": true
    },
    {
        "order": 611,
        "title": "MetaShift: A Dataset of Datasets for Evaluating Contextual Distribution Shifts and Training Conflicts",
        "html": "https://iclr.cc//virtual/2022/poster/6433",
        "abstract": "Understanding the performance of machine learning models across diverse data distributions is critically important for reliable applications. Motivated by this, there is a growing focus on curating benchmark datasets that capture distribution shifts. While valuable, the existing benchmarks are limited in that many of them only contain a small number of shifts and they lack systematic annotation about what is different across different shifts. We present MetaShift—a collection of 12,868 sets of natural images across 410 classes—to address this challenge. We leverage the natural heterogeneity of Visual Genome and its annotations to construct MetaShift. The key construction idea is to cluster images using its metadata, which provides context for each image (e.g. “cats with cars” or “cats in bathroom”) that represent distinct data distributions. MetaShift has two important benefits: first, it contains orders of magnitude more natural data shifts than previously available. Second, it provides explicit explanations of what is unique about each of its data sets and a distance score that measures the amount of distribution shift between any two of its data sets. We demonstrate the utility of MetaShift in benchmarking several recent proposals for training models to be robust to data shifts. We find that the simple empirical risk minimization performs the best when shifts are moderate and no method had a systematic advantage for large shifts. We also show how MetaShift can help to visualize conflicts between data subsets during model training. ",
        "conference": "ICLR",
        "中文标题": "MetaShift：一个用于评估上下文分布偏移和训练冲突的数据集集合",
        "摘要翻译": "理解机器学习模型在不同数据分布下的性能对于可靠的应用至关重要。出于这一动机，人们越来越关注于策划能够捕捉分布变化的基准数据集。虽然现有的基准数据集很有价值，但它们存在局限性，即许多数据集仅包含少量的分布变化，并且缺乏对不同变化之间差异的系统性标注。我们提出了MetaShift——一个包含410个类别、12,868组自然图像的集合——以应对这一挑战。我们利用Visual Genome的自然异质性及其标注来构建MetaShift。关键的构建思想是使用图像的元数据进行聚类，这些元数据为每张图像提供了上下文（例如“与汽车在一起的猫”或“浴室中的猫”），代表了不同的数据分布。MetaShift有两个重要的优点：首先，它包含的自然数据变化比之前可用的数据集多出数量级。其次，它提供了对其每个数据集的独特之处以及衡量任意两个数据集之间分布变化量的距离分数的明确解释。我们展示了MetaShift在基准测试几种最近提出的训练模型以对数据变化具有鲁棒性的方法中的实用性。我们发现，当变化适中时，简单的经验风险最小化表现最佳，而对于大的变化，没有任何方法具有系统性优势。我们还展示了MetaShift如何帮助可视化模型训练期间数据子集之间的冲突。",
        "领域": "数据分布偏移分析、模型鲁棒性评估、计算机视觉数据集构建",
        "问题": "评估机器学习模型在不同数据分布下的性能，以及训练过程中的数据子集冲突问题",
        "动机": "为了解决现有基准数据集在捕捉分布变化方面的局限性，包括变化数量有限和缺乏系统性标注的问题",
        "方法": "利用Visual Genome的自然异质性及其标注，通过元数据聚类构建包含大量自然数据变化的MetaShift数据集，并提供每个数据集的独特解释和分布变化距离分数",
        "关键词": [
            "数据分布偏移",
            "模型鲁棒性",
            "数据集构建",
            "元数据聚类",
            "训练冲突"
        ],
        "涉及的技术概念": {
            "数据分布偏移": "指数据在不同上下文或条件下的分布变化，MetaShift通过聚类图像的元数据来捕捉和量化这些变化",
            "经验风险最小化": "一种简单的机器学习训练方法，MetaShift基准测试显示其在处理适中分布变化时表现最佳",
            "元数据聚类": "利用图像的上下文信息（如场景描述）进行聚类，MetaShift使用这一技术来构建代表不同数据分布的数据集"
        },
        "success": true
    },
    {
        "order": 612,
        "title": "MIDI-DDSP: Detailed Control of Musical Performance via Hierarchical Modeling",
        "html": "https://iclr.cc//virtual/2022/poster/6966",
        "abstract": "Musical expression requires control of both what notes that are played, and how they are performed. Conventional audio synthesizers provide detailed expressive controls, but at the cost of realism. Black-box neural audio synthesis and concatenative samplers can produce realistic audio, but have few mechanisms for control. In this work, we introduce MIDI-DDSP a hierarchical model of musical instruments that enables both realistic neural audio synthesis and detailed user control. Starting from interpretable Differentiable Digital Signal Processing (DDSP) synthesis parameters, we infer musical notes and high-level properties of their expressive performance (such as timbre, vibrato, dynamics, and articulation). This creates a 3-level hierarchy (notes, performance, synthesis) that affords individuals the option to intervene at each level, or utilize trained priors (performance given notes, synthesis given performance) for creative assistance. Through quantitative experiments and listening tests, we demonstrate that this hierarchy can reconstruct high-fidelity audio, accurately predict performance attributes for a note sequence, independently manipulate the attributes of a given performance,  and as a complete system, generate realistic audio from a novel note sequence. By utilizing an interpretable hierarchy, with multiple levels of granularity, MIDI-DDSP opens the door to assistive tools to empower individuals across a diverse range of musical experience.",
        "conference": "ICLR",
        "中文标题": "MIDI-DDSP：通过分层建模实现对音乐表演的精细控制",
        "摘要翻译": "音乐表达需要控制演奏的音符及其表演方式。传统的音频合成器提供了详细的表达控制，但以牺牲真实感为代价。黑盒神经音频合成和拼接采样器可以产生真实的音频，但控制机制较少。在这项工作中，我们介绍了MIDI-DDSP，一种音乐乐器的分层模型，既能实现真实的神经音频合成，又能提供详细的用户控制。从可解释的微分数字信号处理（DDSP）合成参数出发，我们推断出音符及其表达表演的高级属性（如音色、颤音、动态和发音）。这创建了一个三级层次结构（音符、表演、合成），使个人可以选择在每个级别进行干预，或利用训练好的先验（给定音符的表演，给定表演的合成）进行创意辅助。通过定量实验和听力测试，我们证明了这个层次结构可以重建高保真音频，准确预测音符序列的表演属性，独立操纵给定表演的属性，并作为一个完整系统，从新的音符序列生成真实的音频。通过利用具有多级粒度的可解释层次结构，MIDI-DDSP为跨多样音乐经验的个人提供了辅助工具的大门。",
        "领域": "音乐信息检索、神经音频合成、数字信号处理",
        "问题": "如何在保持音频真实感的同时，实现对音乐表演的精细控制",
        "动机": "解决传统音频合成器在真实感和控制性之间的权衡问题，以及黑盒神经音频合成和拼接采样器控制机制不足的问题",
        "方法": "采用分层模型MIDI-DDSP，结合可解释的微分数字信号处理（DDSP）合成参数，实现音符和表演属性的推断与控制",
        "关键词": [
            "MIDI-DDSP",
            "神经音频合成",
            "分层建模",
            "音乐表演控制",
            "微分数字信号处理"
        ],
        "涉及的技术概念": {
            "微分数字信号处理（DDSP）": "用于音频合成的技术，提供可解释的合成参数，支持对音乐表演的精细控制",
            "分层模型": "通过音符、表演和合成三个层次的建模，实现对音乐表演的多级控制",
            "神经音频合成": "利用神经网络生成高质量音频的技术，MIDI-DDSP在此基础上增加了控制机制"
        },
        "success": true
    },
    {
        "order": 613,
        "title": "Mind the Gap: Domain Gap Control for Single Shot Domain Adaptation for Generative Adversarial Networks",
        "html": "https://iclr.cc//virtual/2022/poster/6775",
        "abstract": "We present a new method for one shot domain adaptation. The input to our method is trained GAN that can produce images in domain A and a single reference image I_B from domain B. The proposed algorithm can translate any output of the trained GAN from domain A to domain B. There are two main advantages of our method compared to the current state of the art: First, our solution achieves higher visual quality, e.g. by noticeably reducing overfitting. Second, our solution allows for more degrees of freedom to control the domain gap, i.e. what aspects of image I_B are used to define the domain B. Technically, we realize the new method by building on a pre-trained StyleGAN generator as GAN and a pre-trained CLIP model for representing the domain gap. We propose several new regularizers for controlling the domain gap to optimize the weights of the pre-trained StyleGAN generator to output images in domain B instead of domain A. The regularizers prevent the optimization from taking on too many attributes of the single reference image. Our results show significant visual improvements over the state of the art as well as multiple applications that highlight improved control.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "注意差距：生成对抗网络的单次域适应的域差距控制",
        "摘要翻译": "我们提出了一种新的单次域适应方法。我们的方法的输入是一个可以生成域A图像的训练好的GAN和域B中的单个参考图像I_B。所提出的算法可以将训练好的GAN的任何输出从域A转换到域B。与当前最先进的技术相比，我们的方法有两个主要优势：首先，我们的解决方案实现了更高的视觉质量，例如通过显著减少过拟合。其次，我们的解决方案允许更多的自由度来控制域差距，即图像I_B的哪些方面用于定义域B。在技术上，我们通过在预训练的StyleGAN生成器作为GAN和预训练的CLIP模型来表示域差距的基础上实现了新方法。我们提出了几种新的正则化器来控制域差距，以优化预训练的StyleGAN生成器的权重，使其输出域B而不是域A的图像。正则化器防止优化过程中采用过多单个参考图像的属性。我们的结果显示，与最先进的技术相比，视觉上有显著改进，以及多个应用突出了改进的控制。",
        "领域": "生成对抗网络, 域适应, 图像生成",
        "问题": "解决在单次域适应中如何控制域差距以提高生成图像的质量和自由度的问题",
        "动机": "提高生成对抗网络在单次域适应中的视觉质量和控制域差距的能力",
        "方法": "基于预训练的StyleGAN生成器和CLIP模型，提出新的正则化器来控制域差距，优化生成器权重",
        "关键词": [
            "单次域适应",
            "域差距控制",
            "StyleGAN",
            "CLIP模型",
            "正则化器"
        ],
        "涉及的技术概念": {
            "StyleGAN": "预训练的生成对抗网络，用于生成高质量图像",
            "CLIP模型": "用于表示和衡量图像之间的域差距",
            "正则化器": "用于控制优化过程，防止过拟合和保持生成图像的多样性"
        }
    },
    {
        "order": 614,
        "title": "Minibatch vs Local SGD with Shuffling: Tight Convergence Bounds and Beyond",
        "html": "https://iclr.cc//virtual/2022/poster/7030",
        "abstract": "In distributed learning, local SGD (also known as federated averaging) and its simple baseline minibatch SGD are widely studied optimization methods. Most existing analyses of these methods assume independent and unbiased gradient estimates obtained via with-replacement sampling. In contrast, we study shuffling-based variants: minibatch and local Random Reshuffling, which draw stochastic gradients without replacement and are thus closer to practice. For smooth functions satisfying the Polyak-Łojasiewicz condition, we obtain convergence bounds (in the large epoch regime) which show that these shuffling-based variants converge faster than their with-replacement counterparts. Moreover, we prove matching lower bounds showing that our convergence analysis is tight. Finally, we propose an algorithmic modification called synchronized shuffling that leads to convergence rates faster than our lower bounds in near-homogeneous settings.",
        "conference": "ICLR",
        "中文标题": "小批量与局部随机重排SGD的比较：紧密收敛界限及超越",
        "摘要翻译": "在分布式学习中，局部SGD（也称为联邦平均）及其简单基线小批量SGD是被广泛研究的优化方法。大多数现有分析这些方法的研究假设通过有放回抽样获得独立且无偏的梯度估计。相反，我们研究了基于随机重排的变体：小批量和局部随机重排，它们通过无放回抽样抽取随机梯度，因此更接近实际应用。对于满足Polyak-Łojasiewicz条件的平滑函数，我们获得了收敛界限（在大周期制度下），这些界限显示这些基于随机重排的变体比它们的有放回对应物收敛得更快。此外，我们证明了匹配的下界，表明我们的收敛分析是紧密的。最后，我们提出了一种称为同步重排的算法修改，在接近同质性的设置中，这导致了比我们的下界更快的收敛速度。",
        "领域": "分布式学习优化、随机梯度下降、联邦学习",
        "问题": "比较和分析基于随机重排的小批量SGD和局部SGD的收敛性能",
        "动机": "研究更接近实际应用的无放回抽样梯度估计方法，以提升分布式学习中的优化效率和收敛速度",
        "方法": "通过理论分析和实验验证，比较基于随机重排的小批量SGD和局部SGD的收敛性能，并提出同步重排算法以进一步提升性能",
        "关键词": [
            "随机重排",
            "局部SGD",
            "小批量SGD",
            "收敛分析",
            "分布式学习"
        ],
        "涉及的技术概念": {
            "局部SGD（联邦平均）": "在分布式学习中，通过在多个本地更新步骤后平均模型参数来减少通信开销的优化方法",
            "随机重排": "一种无放回抽样的梯度估计方法，更接近实际应用场景，能够提升模型的收敛速度",
            "Polyak-Łojasiewicz条件": "一种用于分析优化算法收敛性的数学条件，确保目标函数在最优解附近有足够的曲率"
        },
        "success": true
    },
    {
        "order": 615,
        "title": "miniF2F: a cross-system benchmark for formal Olympiad-level mathematics",
        "html": "https://iclr.cc//virtual/2022/poster/6258",
        "abstract": "We present $\\textsf{miniF2F}$, a dataset of formal Olympiad-level mathematics problems statements intended to provide a unified cross-system benchmark for neural theorem proving. The $\\textsf{miniF2F}$ benchmark currently targets Metamath, Lean, Isabelle (partially) and HOL Light (partially) and consists of 488 problem statements drawn from the AIME, AMC, and the International Mathematical Olympiad (IMO), as well as material from high-school and undergraduate mathematics courses. We report baseline results using GPT-f, a neural theorem prover based on GPT-3 and provide an analysis of its performance. We intend for $\\textsf{miniF2F}$ to be a community-driven effort and hope that our benchmark will help spur advances in neural theorem proving.",
        "conference": "ICLR",
        "中文标题": "miniF2F：一个面向形式化奥林匹克级数学的跨系统基准测试",
        "摘要翻译": "我们介绍了miniF2F，一个旨在为神经定理证明提供统一跨系统基准测试的形式化奥林匹克级数学问题陈述数据集。miniF2F基准测试目前针对Metamath、Lean、Isabelle（部分）和HOL Light（部分），包含488个来自AIME、AMC和国际数学奥林匹克（IMO）的问题陈述，以及高中和本科数学课程的材料。我们报告了基于GPT-3的神经定理证明器GPT-f的基线结果，并对其性能进行了分析。我们希望miniF2F成为一个社区驱动的努力，并希望我们的基准测试能帮助推动神经定理证明的进步。",
        "领域": "自动定理证明、数学问题求解、教育技术",
        "问题": "为神经定理证明提供一个统一的跨系统基准测试数据集",
        "动机": "推动神经定理证明领域的研究进展，通过提供一个标准化的测试集来评估不同系统的性能",
        "方法": "收集并整理来自多个数学竞赛和课程的形式化数学问题，构建一个跨系统的基准测试数据集，并使用基于GPT-3的神经定理证明器进行基线测试",
        "关键词": [
            "神经定理证明",
            "数学竞赛",
            "基准测试",
            "形式化数学",
            "GPT-3"
        ],
        "涉及的技术概念": {
            "神经定理证明": "使用神经网络技术来自动化数学定理的证明过程",
            "形式化数学": "将数学问题严格编码为计算机可处理的形式，以便于自动化处理",
            "基准测试": "通过标准化的测试集来评估和比较不同系统或算法的性能"
        },
        "success": true
    },
    {
        "order": 616,
        "title": "Minimax Optimality (Probably) Doesn't Imply Distribution Learning for GANs",
        "html": "https://iclr.cc//virtual/2022/poster/7087",
        "abstract": "Arguably the most fundamental question in the theory of generative adversarial networks (GANs) is to understand when GANs can actually learn the underlying distribution. Theoretical and empirical evidence (see e.g. Arora-Risteski-Zhang '18) suggest local optimality of the empirical training objective is insufficient, yet it does not rule out the possibility that achieving a true population minimax optimal solution might imply distribution learning. In this paper, we show that standard cryptographic assumptions imply that this stronger condition is still insufficient. Namely, we show that if local pseudorandom generators (PRGs) exist, then for a large family of natural target distributions, there are ReLU network generators of constant depth and poly size which take Gaussian random seeds so that (i) the output is far in Wasserstein distance from the target distribution, but (ii) no polynomially large Lipschitz discriminator ReLU network can detect this. This implies that even achieving a population minimax optimal solution to the Wasserstein GAN objective is likely insufficient for distribution learning. Our techniques reveal a deep connection between GANs and PRGs, which we believe will lead to further insights into the computational landscape of GANs.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "极小极大最优性（可能）不意味着GANs的分布学习",
        "摘要翻译": "可以说，生成对抗网络（GANs）理论中最基本的问题是理解GANs何时能够真正学习底层分布。理论和实证证据（例如Arora-Risteski-Zhang '18）表明，经验训练目标的局部最优性是不够的，但这并不排除实现真正的总体极小极大最优解可能意味着分布学习的可能性。在本文中，我们表明，标准的密码学假设意味着这种更强的条件仍然不足。即，我们表明，如果存在局部伪随机生成器（PRGs），那么对于一大类自然目标分布，存在常数深度和多项式大小的ReLU网络生成器，这些生成器采用高斯随机种子，使得（i）输出在Wasserstein距离上远离目标分布，但（ii）没有多项式大的Lipschitz判别器ReLU网络能够检测到这一点。这意味着，即使实现了Wasserstein GAN目标的总体极小极大最优解，也可能不足以进行分布学习。我们的技术揭示了GANs和PRGs之间的深刻联系，我们相信这将进一步洞察GANs的计算景观。",
        "领域": "生成对抗网络、分布学习、密码学",
        "问题": "理解GANs在何种条件下能够学习底层分布",
        "动机": "探讨实现总体极小极大最优解是否足以保证GANs的分布学习能力",
        "方法": "利用局部伪随机生成器（PRGs）的存在性，构造特定条件下的ReLU网络生成器，分析其输出与目标分布的关系",
        "关键词": [
            "生成对抗网络",
            "分布学习",
            "极小极大最优性",
            "伪随机生成器",
            "Wasserstein距离"
        ],
        "涉及的技术概念": {
            "极小极大最优性": "在GANs中，指的是生成器和判别器在对抗训练过程中达到的平衡状态，理论上认为这种状态可能保证分布学习",
            "伪随机生成器（PRGs）": "密码学中的一种算法，能够生成看似随机的序列，用于构造特定条件下的生成器，证明GANs的学习限制",
            "Wasserstein距离": "用于衡量两个概率分布之间差异的度量，本文中用于量化生成器输出与目标分布之间的差异"
        }
    },
    {
        "order": 617,
        "title": "Minimax Optimization with Smooth Algorithmic Adversaries",
        "html": "https://iclr.cc//virtual/2022/poster/6354",
        "abstract": "This paper considers minimax optimization $\\min_x \\max_y f(x, y)$ in the challenging setting where $f$ can be both nonconvex in $x$ and nonconcave in $y$. Though such optimization problems arise in many machine learning paradigms including training generative adversarial networks (GANs) and adversarially robust models, from a theoretical point of view, two fundamental issues remain: (i) the absence of simple and efficiently computable optimality notions, and (ii) cyclic or diverging behavior of existing algorithms. This paper proposes a new theoretical framework for nonconvex-nonconcave minimax optimization that addresses both of the above issues. The starting point of this paper is the observation that, under a computational budget, the max-player can not fully maximize $f(x,\\cdot)$ since nonconcave maximization is NP-hard in general. So, we propose a new framework, and a corresponding algorithm, for the min-player to play against \\emph{smooth algorithms} deployed by the adversary (i.e., the max-player) instead of against full maximization. Our algorithm is guaranteed to make monotonic progress (thus having no limit cycles or diverging behavior), and to find an appropriate ``stationary point'' in a polynomial number of iterations. Our framework covers practically relevant settings where the smooth algorithms deployed by the adversary are multi-step stochastic gradient ascent, and its accelerated version. We further present experimental results that confirm our theoretical findings and demonstrate the effectiveness of the proposed approach in practice on simple, conceptual settings.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "基于平滑算法对抗的极小极大优化",
        "摘要翻译": "本文考虑了在具有挑战性的设置下的极小极大优化问题 min_x max_y f(x, y)，其中 f 在 x 中是非凸的，在 y 中是非凹的。尽管这种优化问题出现在许多机器学习范例中，包括训练生成对抗网络 (GANs) 和对抗鲁棒模型，但从理论的角度来看，仍然存在两个基本问题：(i) 缺乏简单且可有效计算的最优性概念，以及 (ii) 现有算法的循环或发散行为。本文提出了一个新的非凸-非凹极小极大优化的理论框架，解决了上述两个问题。本文的出发点是观察到，在计算预算下，max 参与者无法完全最大化 f(x,·)，因为非凹最大化通常是 NP 难的。因此，我们提出了一个新的框架和相应的算法，让 min 参与者与对抗者（即 max 参与者）部署的平滑算法对抗，而不是与完全最大化对抗。我们的算法保证能够取得单调进展（因此没有极限循环或发散行为），并在多项式次迭代中找到合适的“驻点”。我们的框架涵盖了实践相关的设置，其中对抗者部署的平滑算法是多步随机梯度上升及其加速版本。我们进一步展示了实验结果，这些结果证实了我们的理论发现，并证明了所提出的方法在简单概念设置中的有效性。",
        "领域": "生成对抗网络",
        "问题": "解决非凸-非凹极小极大优化中缺乏有效最优性概念和现有算法的循环或发散行为的问题。",
        "动机": "现有的非凸-非凹极小极大优化算法在理论上存在缺陷，且在实践中表现不稳定，促使研究者提出更稳定和有效的算法。",
        "方法": "提出了一种新的理论框架，该框架让min参与者与对抗者部署的平滑算法对抗，而不是完全最大化对抗。该算法保证单调进展，并在多项式次迭代中找到驻点。",
        "关键词": [
            "极小极大优化",
            "生成对抗网络",
            "平滑算法",
            "非凸优化",
            "非凹优化"
        ],
        "涉及的技术概念": {
            "极小极大优化": "一种优化方法，旨在找到一个点，在这个点上，目标函数对于一个变量最小化，对于另一个变量最大化。在GANs中，生成器和判别器的训练过程可以看作是极小极大优化。",
            "生成对抗网络 (GANs)": "一种深度学习模型，由生成器和判别器组成。生成器学习生成逼真的数据，判别器学习区分真实数据和生成数据。GANs的训练目标是找到一个纳什均衡点，即生成器和判别器都无法单独改进自己的策略。"
        }
    },
    {
        "order": 618,
        "title": "Mirror Descent Policy Optimization",
        "html": "https://iclr.cc//virtual/2022/poster/6402",
        "abstract": "Mirror descent (MD), a well-known first-order method in constrained convex optimization, has recently been shown as an important tool to analyze trust-region algorithms in reinforcement learning (RL). However, there remains a considerable gap between such theoretically analyzed algorithms and the ones used in practice. Inspired by this, we propose an efficient RL algorithm, called {\\em mirror descent policy optimization} (MDPO). MDPO iteratively updates the policy by {\\em approximately} solving a trust-region problem, whose objective function consists of two terms: a linearization of the standard RL objective and a proximity term that restricts two consecutive policies to be close to each other. Each update performs this approximation by taking multiple gradient steps on this objective function. We derive {\\em on-policy} and {\\em off-policy} variants of MDPO, while emphasizing important design choices motivated by the existing theory of MD in RL. We highlight the connections between on-policy MDPO and two popular trust-region RL algorithms: TRPO and PPO, and show that explicitly enforcing the trust-region constraint is in fact {\\em not} a necessity for high performance gains in TRPO. We then show how the popular soft actor-critic (SAC) algorithm can be derived by slight modifications of off-policy MDPO. Overall, MDPO is derived from the MD principles, offers a unified approach to viewing a number of popular RL algorithms, and performs better than or on-par with TRPO, PPO, and SAC in a number of continuous and discrete control tasks.",
        "conference": "ICLR",
        "中文标题": "镜像下降策略优化",
        "摘要翻译": "镜像下降（MD）是约束凸优化中著名的一阶方法，最近被证明是分析强化学习（RL）中信任区域算法的重要工具。然而，这些理论上分析的算法与实际使用的算法之间仍存在相当大的差距。受此启发，我们提出了一种高效的RL算法，称为镜像下降策略优化（MDPO）。MDPO通过近似解决一个信任区域问题来迭代更新策略，该问题的目标函数由两部分组成：标准RL目标的线性化和一个限制两个连续策略彼此接近的邻近项。每次更新通过对这个目标函数采取多个梯度步骤来执行这种近似。我们推导了MDPO的在线和离线变体，同时强调了由RL中MD现有理论激发的重要设计选择。我们强调了在线MDPO与两种流行的信任区域RL算法TRPO和PPO之间的联系，并表明在TRPO中明确强制执行信任区域约束实际上并不是高性能增益的必要条件。然后，我们展示了如何通过对离线MDPO进行轻微修改来推导出流行的软演员-评论家（SAC）算法。总体而言，MDPO源自MD原则，提供了一种统一的方法来查看许多流行的RL算法，并在许多连续和离散控制任务中表现优于或与TRPO、PPO和SAC相当。",
        "领域": "强化学习算法优化",
        "问题": "如何缩小理论分析的强化学习算法与实际应用之间的差距",
        "动机": "受镜像下降在强化学习信任区域算法分析中的应用启发，开发一种更高效的强化学习算法",
        "方法": "提出镜像下降策略优化（MDPO），通过近似解决信任区域问题迭代更新策略，结合标准RL目标的线性化和邻近项限制策略更新",
        "关键词": [
            "镜像下降",
            "策略优化",
            "强化学习",
            "信任区域",
            "算法统一"
        ],
        "涉及的技术概念": {
            "镜像下降": "一种在约束凸优化中使用的一阶方法，用于分析强化学习中的信任区域算法",
            "信任区域问题": "在强化学习中用于限制策略更新幅度的问题，确保更新后的策略不会偏离当前策略太远",
            "策略优化": "通过迭代更新策略来提高强化学习算法的性能，MDPO通过近似解决信任区域问题来实现这一点"
        },
        "success": true
    },
    {
        "order": 619,
        "title": "Missingness Bias in Model Debugging",
        "html": "https://iclr.cc//virtual/2022/poster/6930",
        "abstract": "Missingness, or the absence of features from an input, is a concept fundamental to many model debugging tools. However, in computer vision, pixels cannot simply be removed from an image. One thus tends to resort to heuristics such as blacking out pixels, which may in turn introduce bias into the debugging process. We study such biases and, in particular, show how transformer-based architectures can enable a more natural implementation of missingness, which side-steps these issues and improves the reliability of model debugging in practice.",
        "conference": "ICLR",
        "中文标题": "模型调试中的缺失性偏差",
        "摘要翻译": "缺失性，即输入中特征的缺失，是许多模型调试工具的基本概念。然而，在计算机视觉中，像素不能简单地从图像中移除。因此，人们倾向于采用诸如将像素涂黑等启发式方法，这可能会在调试过程中引入偏差。我们研究了这种偏差，特别是展示了基于变换器的架构如何能够实现更自然的缺失性实施，从而规避这些问题并提高实践中模型调试的可靠性。",
        "领域": "计算机视觉模型调试、变换器架构应用、模型可靠性分析",
        "问题": "解决在计算机视觉模型调试过程中，由于像素缺失处理不当引入的偏差问题。",
        "动机": "研究旨在揭示并解决传统像素缺失处理方法在模型调试中引入的偏差，以提高调试的准确性和可靠性。",
        "方法": "采用基于变换器的架构来实现更自然的缺失性处理，避免传统启发式方法带来的偏差。",
        "关键词": [
            "模型调试",
            "缺失性偏差",
            "变换器架构",
            "计算机视觉",
            "可靠性改进"
        ],
        "涉及的技术概念": {
            "缺失性": "指输入特征在模型调试过程中的缺失现象，是调试工具处理的核心问题。",
            "变换器架构": "用于实现更自然的缺失性处理，避免传统方法引入的偏差，提高调试的可靠性。",
            "模型调试": "指通过分析模型行为来识别和修正错误的过程，本文聚焦于处理缺失性带来的偏差问题。"
        },
        "success": true
    },
    {
        "order": 620,
        "title": "MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer",
        "html": "https://iclr.cc//virtual/2022/poster/6230",
        "abstract": "Light-weight convolutional neural networks (CNNs) are the de-facto for mobile vision tasks. Their spatial inductive biases allow them to learn representations with fewer parameters across different vision tasks. However, these networks are spatially local. To learn global representations, self-attention-based vision trans-formers (ViTs) have been adopted. Unlike CNNs, ViTs are heavy-weight. In this paper, we ask the following question: is it possible to combine the strengths of CNNs and ViTs to build a light-weight and low latency network for mobile vision tasks? Towards this end, we introduce MobileViT, a light-weight and general-purpose vision transformer for mobile devices. MobileViT presents a different perspective for the global processing of information with transformers, i.e., transformers as convolutions. Our results show that MobileViT significantly outperforms CNN- and ViT-based networks across different tasks and datasets. On the ImageNet-1k dataset, MobileViT achieves top-1 accuracy of 78.4% with about 6 million parameters, which is 3.2% and 6.2% more accurate than MobileNetv3 (CNN-based) and DeIT (ViT-based) for a similar number of parameters. On the MS-COCO object detection task, MobileViT is 5.7% more accurate than MobileNetv3 for a similar number of parameters. Our source code is open-source and available at: https://github.com/apple/ml-cvnets",
        "conference": "ICLR",
        "中文标题": "MobileViT：轻量级、通用且移动友好的视觉Transformer",
        "摘要翻译": "轻量级卷积神经网络（CNNs）是移动视觉任务的事实标准。它们的空间归纳偏差允许它们在不同视觉任务中以较少的参数学习表示。然而，这些网络在空间上是局部的。为了学习全局表示，基于自注意力的视觉Transformer（ViTs）被采用。与CNNs不同，ViTs是重量级的。在本文中，我们提出以下问题：是否有可能结合CNNs和ViTs的优势，为移动视觉任务构建一个轻量级且低延迟的网络？为此，我们引入了MobileViT，一种为移动设备设计的轻量级通用视觉Transformer。MobileViT为使用Transformer进行信息全局处理提供了一个不同的视角，即，将Transformer视为卷积。我们的结果表明，MobileViT在不同任务和数据集上显著优于基于CNN和ViT的网络。在ImageNet-1k数据集上，MobileViT以约600万参数实现了78.4%的top-1准确率，比参数数量相似的MobileNetv3（基于CNN）和DeIT（基于ViT）分别高出3.2%和6.2%。在MS-COCO目标检测任务上，MobileViT比参数数量相似的MobileNetv3准确率高5.7%。我们的源代码是开源的，可在以下网址获取：https://github.com/apple/ml-cvnets",
        "领域": "轻量级神经网络设计、移动视觉应用、视觉Transformer优化",
        "问题": "如何在移动设备上实现既轻量级又能进行全局信息处理的视觉网络",
        "动机": "结合卷积神经网络（CNNs）的轻量级优势和视觉Transformer（ViTs）的全局处理能力，为移动视觉任务开发高效网络",
        "方法": "提出MobileViT，一种新型轻量级视觉Transformer，通过将Transformer视为卷积来实现信息的全局处理，同时保持模型的轻量级和高效性",
        "关键词": [
            "MobileViT",
            "轻量级网络",
            "视觉Transformer",
            "移动视觉",
            "全局信息处理"
        ],
        "涉及的技术概念": {
            "视觉Transformer（ViTs）": "用于学习图像的全局表示，克服传统CNNs在空间上的局限性",
            "轻量级卷积神经网络（CNNs）": "作为移动视觉任务的基础，以其高效的参数利用和空间归纳偏差著称",
            "全局信息处理": "MobileViT通过将Transformer视为卷积的方式，实现了在轻量级网络中高效处理全局信息的能力"
        },
        "success": true
    },
    {
        "order": 621,
        "title": "Model Agnostic Interpretability for Multiple Instance Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6786",
        "abstract": "In Multiple Instance Learning (MIL), models are trained using bags of instances, where only a single label is provided for each bag. A bag label is often only determined by a handful of key instances within a bag, making it difficult to interpret what information a classifier is using to make decisions. In this work, we establish the key requirements for interpreting MIL models. We then go on to develop several model-agnostic approaches that meet these requirements. Our methods are compared against existing inherently interpretable MIL models on several datasets, and achieve an increase in interpretability accuracy of up to 30%. We also examine the ability of the methods to identify interactions between instances and scale to larger datasets, improving their applicability to real-world problems.",
        "conference": "ICLR",
        "中文标题": "模型无关的多实例学习可解释性",
        "摘要翻译": "在多实例学习（MIL）中，模型使用实例包进行训练，其中每个包仅提供一个标签。包标签通常仅由包内的少数关键实例决定，这使得难以解释分类器使用什么信息做出决策。在这项工作中，我们确立了解释MIL模型的关键要求。然后，我们开发了几种满足这些要求的模型无关方法。我们的方法在几个数据集上与现有的固有可解释MIL模型进行了比较，并将可解释性准确性提高了高达30%。我们还检查了这些方法识别实例间交互和扩展到更大数据集的能力，从而提高了它们对实际问题的适用性。",
        "领域": "多实例学习、模型可解释性、深度学习应用",
        "问题": "解决多实例学习模型中分类决策的可解释性问题",
        "动机": "提高多实例学习模型的可解释性，以便更好地理解模型决策的依据",
        "方法": "开发了几种模型无关的方法，用于解释MIL模型的决策过程，并与现有方法进行比较",
        "关键词": [
            "多实例学习",
            "模型可解释性",
            "模型无关方法",
            "分类决策",
            "实例交互"
        ],
        "涉及的技术概念": {
            "多实例学习": "一种机器学习范式，其中训练数据被组织成包，每个包包含多个实例，但仅有一个包级标签",
            "模型可解释性": "指理解和解释模型决策过程的能力，对于提高模型透明度和信任度至关重要",
            "模型无关方法": "不依赖于特定模型结构的技术，可以广泛应用于不同类型的模型以提高其可解释性"
        },
        "success": true
    },
    {
        "order": 622,
        "title": "Model-augmented Prioritized Experience Replay",
        "html": "https://iclr.cc//virtual/2022/poster/6032",
        "abstract": "Experience replay is an essential component in off-policy model-free reinforcement learning (MfRL). Due to its effectiveness, various methods for calculating priority scores on experiences have been proposed for sampling. Since critic networks are crucial to policy learning, TD-error, directly correlated to $Q$-values, is one of the most frequently used features to compute the scores. However, critic networks often under- or overestimate $Q$-values, so it is often ineffective to learn to predict $Q$-values by sampled experiences based heavily on TD-error. Accordingly, it is valuable to find auxiliary features, which positively support TD-error in calculating the scores for efficient sampling. Motivated by this, we propose a novel experience replay method, which we call model-augmented prioritized experience replay (MaPER), that employs new learnable features driven from components in model-based RL (MbRL) to calculate the scores on experiences. The proposed MaPER brings the effect of curriculum learning for predicting $Q$-values better by the critic network with negligible memory and computational overhead compared to the vanilla PER. Indeed, our experimental results on various tasks demonstrate that MaPER can significantly improve the performance of the state-of-the-art off-policy MfRL and MbRL which includes off-policy MfRL algorithms in its policy optimization procedure.",
        "conference": "ICLR",
        "中文标题": "模型增强的优先经验回放",
        "摘要翻译": "经验回放是无模型离线强化学习（MfRL）中的一个重要组成部分。由于其有效性，已经提出了各种方法来计算经验的优先级分数以进行采样。由于评论家网络对策略学习至关重要，与Q值直接相关的TD误差是最常用于计算这些分数的特征之一。然而，评论家网络经常低估或高估Q值，因此，主要基于TD误差采样的经验来预测Q值往往效果不佳。因此，寻找辅助特征以在计算分数时积极支持TD误差，对于高效采样具有重要价值。基于这一动机，我们提出了一种新颖的经验回放方法，称为模型增强的优先经验回放（MaPER），该方法利用基于模型的强化学习（MbRL）中的组件驱动的新可学习特征来计算经验的分数。与普通的PER相比，提出的MaPER在预测Q值方面带来了课程学习的效果，且内存和计算开销可以忽略不计。事实上，我们在各种任务上的实验结果表明，MaPER可以显著提高最先进的离线MfRL和MbRL的性能，其中包括在其策略优化过程中包含离线MfRL算法的MbRL。",
        "领域": "强化学习",
        "问题": "提高经验回放中优先级分数计算的效率和准确性",
        "动机": "解决评论家网络在预测Q值时因低估或高估而导致的效率低下问题",
        "方法": "提出模型增强的优先经验回放（MaPER），利用基于模型的强化学习中的组件驱动的新可学习特征来计算经验的优先级分数",
        "关键词": [
            "经验回放",
            "强化学习",
            "模型增强",
            "优先级分数",
            "课程学习"
        ],
        "涉及的技术概念": {
            "TD误差": "用于计算经验优先级分数的特征，直接关联于Q值",
            "模型增强的优先经验回放（MaPER）": "一种新颖的经验回放方法，利用基于模型的强化学习中的组件驱动的新可学习特征来计算经验的优先级分数",
            "课程学习": "通过逐步增加学习难度的方法来提高模型预测Q值的准确性"
        },
        "success": true
    },
    {
        "order": 623,
        "title": "Model-Based Offline Meta-Reinforcement Learning with Regularization",
        "html": "https://iclr.cc//virtual/2022/poster/6873",
        "abstract": "Existing offline reinforcement learning (RL) methods face a few major challenges, particularly the distributional shift between the learned policy and the behavior policy. Offline Meta-RL is emerging as a promising approach to address these challenges, aiming to learn an informative meta-policy from a collection of tasks. Nevertheless, as shown in our empirical studies, offline Meta-RL  could be outperformed  by offline single-task RL methods on tasks with good quality of datasets, indicating that a right balance has to be delicately calibrated  between 'exploring' the out-of-distribution state-actions by following the meta-policy and 'exploiting' the offline dataset by staying close to the behavior policy. Motivated by such empirical analysis, we propose model-based offline $\\text{\\bf Me}$ta-RL with $\\text{\\bf r}$egularized $\\text{\\bf P}$olicy $\\text{\\bf O}$ptimization (MerPO), which learns a meta-model for efficient task structure inference and an informative meta-policy for safe exploration of out-of-distribution state-actions. In particular, we devise a new meta-Regularized model-based Actor-Critic (RAC) method for within-task policy optimization, as a key building block  of MerPO, using both conservative policy evaluation and regularized policy improvement; and the intrinsic tradeoff therein is achieved via striking the right balance between two regularizers, one based on the behavior policy and the other on the meta-policy. We theoretically show that the learnt policy offers guaranteed improvement over both the behavior policy and the meta-policy, thus ensuring the performance improvement on new tasks via offline Meta-RL. Our experiments corroborate the superior performance of MerPO over existing offline Meta-RL methods.",
        "conference": "ICLR",
        "中文标题": "基于模型的正则化离线元强化学习",
        "摘要翻译": "现有的离线强化学习（RL）方法面临一些主要挑战，特别是学习策略与行为策略之间的分布偏移。离线元强化学习作为一种有前景的方法正在兴起，旨在从一系列任务中学习一个信息丰富的元策略。然而，正如我们的实证研究所示，离线元强化学习在数据集质量良好的任务上可能被离线单任务RL方法超越，这表明必须在遵循元策略'探索'分布外状态动作和通过接近行为策略'利用'离线数据集之间微妙地校准一个正确的平衡。受此实证分析的启发，我们提出了基于模型的正则化离线元强化学习（MerPO），它学习一个元模型以进行有效的任务结构推断和一个信息丰富的元策略以安全探索分布外状态动作。特别是，我们设计了一种新的元正则化基于模型的行动者-评论家（RAC）方法，用于任务内策略优化，作为MerPO的关键构建块，使用保守策略评估和正则化策略改进；其中的内在权衡是通过在两个正则化器之间找到正确的平衡来实现的，一个基于行为策略，另一个基于元策略。我们从理论上证明，学习到的策略提供了对行为策略和元策略的保证改进，从而确保了通过离线元强化学习在新任务上的性能提升。我们的实验证实了MerPO优于现有的离线元强化学习方法。",
        "领域": "强化学习、元学习、策略优化",
        "问题": "解决离线强化学习中学习策略与行为策略之间的分布偏移问题，以及在元强化学习中平衡探索与利用的挑战。",
        "动机": "实证研究表明，离线元强化学习在高质量数据集任务上可能不如单任务RL方法，因此需要一种方法来平衡探索分布外状态动作和利用离线数据集。",
        "方法": "提出基于模型的正则化离线元强化学习（MerPO），包括学习元模型进行任务结构推断和元策略进行安全探索，设计元正则化基于模型的行动者-评论家（RAC）方法进行任务内策略优化。",
        "关键词": [
            "离线强化学习",
            "元强化学习",
            "正则化策略优化",
            "模型基础学习",
            "行动者-评论家方法"
        ],
        "涉及的技术概念": {
            "元强化学习": "从一系列任务中学习一个信息丰富的元策略，以提高在新任务上的性能。",
            "正则化策略优化": "通过在策略优化过程中引入正则化器，平衡探索与利用，确保策略改进。",
            "模型基础学习": "学习一个元模型以进行有效的任务结构推断，支持策略的快速适应和安全探索。"
        },
        "success": true
    },
    {
        "order": 624,
        "title": "Modeling Label Space Interactions in Multi-label Classification using Box Embeddings",
        "html": "https://iclr.cc//virtual/2022/poster/6645",
        "abstract": "Multi-label classification is a challenging structured prediction task in which a set of output class labels are predicted for each input. Real-world datasets often have natural or latent taxonomic relationships between labels, making it desirable for models to employ label representations capable of capturing such taxonomies. Most existing multi-label classification methods do not do so, resulting in label predictions that are inconsistent with the taxonomic constraints, thus failing to accurately represent the fundamentals of problem setting. In this work, we introduce the multi-label box model (MBM), a multi-label classification method that combines the encoding power of neural networks with the inductive bias and probabilistic semantics of box embeddings (Vilnis, et al 2018).  Box embeddings can be understood as trainable Venn-diagrams based on hyper-rectangles.  Representing labels by boxes rather than vectors, MBM is able to capture taxonomic relations among labels.  Furthermore, since box embeddings allow these relations to be learned by stochastic gradient descent from data, and to be read as calibrated conditional probabilities, our model is endowed with a high degree of interpretability. This interpretability also facilitates the injection of partial information about label-label relationships into model training, to further improve its consistency. We provide theoretical grounding for our method and show experimentally the model's ability to learn the true latent taxonomic structure from data. Through extensive empirical evaluations on both small and large-scale multi-label classification datasets, we show that BBM can significantly improve taxonomic consistency while preserving or surpassing the state-of-the-art predictive performance.",
        "conference": "ICLR",
        "中文标题": "使用盒嵌入建模多标签分类中的标签空间交互",
        "摘要翻译": "多标签分类是一项具有挑战性的结构化预测任务，其中为每个输入预测一组输出类别标签。现实世界的数据集通常在标签之间存在自然或潜在的分类学关系，因此希望模型能够采用能够捕捉此类分类学的标签表示。大多数现有的多标签分类方法未能做到这一点，导致标签预测与分类学约束不一致，从而未能准确表示问题设置的基础。在这项工作中，我们介绍了多标签盒模型（MBM），这是一种多标签分类方法，它结合了神经网络的编码能力与盒嵌入的归纳偏置和概率语义（Vilnis等人，2018年）。盒嵌入可以理解为基于超矩形的可训练维恩图。通过用盒子而不是向量表示标签，MBM能够捕捉标签之间的分类学关系。此外，由于盒嵌入允许这些关系通过随机梯度下降从数据中学习，并可以读取为校准的条件概率，我们的模型具有高度的可解释性。这种可解释性还有助于将关于标签-标签关系的部分信息注入模型训练中，以进一步提高其一致性。我们为我们的方法提供了理论基础，并通过实验展示了模型从数据中学习真实潜在分类结构的能力。通过对小型和大型多标签分类数据集的广泛实证评估，我们表明BBM可以显著提高分类学一致性，同时保持或超越最先进的预测性能。",
        "领域": "多标签分类",
        "问题": "现有方法未能有效捕捉标签间的分类学关系，导致预测结果与分类学约束不一致。",
        "动机": "开发一种能够捕捉标签间分类学关系并提高预测一致性的多标签分类方法。",
        "方法": "结合神经网络的编码能力和盒嵌入的归纳偏置与概率语义，提出多标签盒模型（MBM），通过盒嵌入表示标签以捕捉分类学关系。",
        "关键词": [
            "多标签分类",
            "盒嵌入",
            "分类学关系"
        ],
        "涉及的技术概念": {
            "盒嵌入": "基于超矩形的可训练维恩图，用于表示标签并捕捉标签间的分类学关系。",
            "随机梯度下降": "用于从数据中学习盒嵌入表示的关系，优化模型训练。",
            "校准的条件概率": "盒嵌入允许读取为校准的条件概率，增强模型的可解释性。"
        },
        "success": true
    },
    {
        "order": 625,
        "title": "Model Zoo: A Growing Brain That Learns Continually",
        "html": "https://iclr.cc//virtual/2022/poster/6649",
        "abstract": "This paper argues that continual learning methods can benefit by splitting the capacity of the learner across multiple models. We use statistical learning theory and experimental analysis to show how multiple tasks can interact with each other in a non-trivial fashion when a single model is trained on them. The generalization error on a particular task can improve when it is trained with synergistic tasks, but can also deteriorate when trained with competing tasks. This theory motivates our method named Model Zoo which, inspired from the boosting literature, grows an ensemble of small models, each of which is trained during one episode of continual learning. We demonstrate that Model Zoo obtains large gains in accuracy on a wide variety of continual learning benchmark problems.",
        "conference": "ICLR",
        "中文标题": "模型动物园：一个持续学习的成长大脑",
        "摘要翻译": "本文认为，通过将学习者的能力分散到多个模型中，持续学习方法可以受益。我们使用统计学习理论和实验分析来展示当单个模型在多个任务上训练时，这些任务如何以非平凡的方式相互作用。特定任务的泛化误差在与协同任务一起训练时可以改善，但在与竞争任务一起训练时也可能恶化。这一理论激发了我们的方法，名为模型动物园，它受到提升文献的启发，增长了一个小型模型的集合，每个模型在持续学习的一个阶段中被训练。我们证明，模型动物园在各种持续学习基准问题上获得了准确率的大幅提升。",
        "领域": "持续学习",
        "问题": "如何通过分散学习能力到多个模型来提高持续学习的效果",
        "动机": "探索多个任务在单个模型上训练时的相互作用，以及如何通过模型集合来优化持续学习的性能",
        "方法": "提出模型动物园方法，通过增长小型模型集合，每个模型在持续学习的一个阶段中被训练，以提高准确率",
        "关键词": [
            "持续学习",
            "模型集合",
            "统计学习理论"
        ],
        "涉及的技术概念": {
            "持续学习": "在多个任务上连续学习而不忘记之前学到的知识",
            "模型集合": "通过组合多个模型的预测来提高整体性能",
            "统计学习理论": "用于分析学习算法的性能和泛化能力的理论框架"
        },
        "success": true
    },
    {
        "order": 626,
        "title": "Modular Lifelong Reinforcement Learning via Neural Composition",
        "html": "https://iclr.cc//virtual/2022/poster/6937",
        "abstract": "Humans commonly solve complex problems by decomposing them into easier subproblems and then combining the subproblem solutions. This type of compositional reasoning permits reuse of the subproblem solutions when tackling future tasks that share part of the underlying compositional structure. In a continual or lifelong reinforcement learning (RL) setting, this ability to decompose knowledge into reusable components would enable agents to quickly learn new RL tasks by leveraging accumulated compositional structures. We explore a particular form of composition based on neural modules and present a set of RL problems that intuitively admit compositional solutions. Empirically, we demonstrate that neural composition indeed captures the underlying structure of this space of problems. We further propose a compositional lifelong RL method that leverages accumulated neural components to accelerate the learning of future tasks while retaining performance on previous tasks via off-line RL over replayed experiences.",
        "conference": "ICLR",
        "中文标题": "模块化终身强化学习通过神经组合实现",
        "摘要翻译": "人类通常通过将复杂问题分解为更简单的子问题，然后结合子问题的解决方案来解决复杂问题。这种类型的组合推理允许在解决未来共享部分基础组合结构的任务时重用子问题的解决方案。在持续或终身强化学习（RL）设置中，这种将知识分解为可重用组件的能力将使代理能够通过利用积累的组合结构快速学习新的RL任务。我们探索了一种基于神经模块的特定形式的组合，并提出了一组直观上允许组合解决方案的RL问题。实证上，我们证明了神经组合确实捕捉了这些问题空间的基础结构。我们进一步提出了一种组合终身RL方法，该方法利用积累的神经组件加速未来任务的学习，同时通过离线RL重放经验保留先前任务的性能。",
        "领域": "终身学习、强化学习、模块化神经网络",
        "问题": "如何在终身强化学习中有效地分解和重用知识以加速新任务的学习",
        "动机": "利用组合推理的能力，通过分解知识为可重用组件，以在终身强化学习中快速学习新任务并保留旧任务的性能",
        "方法": "提出了一种基于神经模块的组合方法，并通过离线RL重放经验来加速未来任务的学习同时保留先前任务的性能",
        "关键词": [
            "终身强化学习",
            "神经组合",
            "模块化学习",
            "离线RL",
            "知识重用"
        ],
        "涉及的技术概念": {
            "神经模块": "用于构建可重用和组合的知识组件，以支持终身学习",
            "离线强化学习": "通过重放过去的经验来保留和优化先前学习到的任务性能",
            "组合推理": "通过分解问题为子问题并组合解决方案，以支持知识的重用和新任务的快速学习"
        },
        "success": true
    },
    {
        "order": 627,
        "title": "MonoDistill: Learning Spatial Features for Monocular 3D Object Detection",
        "html": "https://iclr.cc//virtual/2022/poster/6677",
        "abstract": "3D object detection is a fundamental and challenging task for 3D scene understanding, and the monocular-based methods can serve as an economical alternative to the stereo-based or LiDAR-based methods. However, accurately locating objects in the 3D space from a single image is extremely difficult due to the lack of spatial cues. To mitigate this issue, we propose a simple and effective scheme to introduce the spatial information from LiDAR signals to the monocular 3D detectors, without introducing any extra cost in the inference phase. In particular, we first project the LiDAR signals into the image plane and align them with the RGB images. After that, we use the resulting data to train a 3D detector (LiDAR Net) using the same architecture as the baseline model. Finally, this LiDAR Net can serve as the teacher to transfer the learned knowledge to the baseline model. Experimental results show that the proposed method can significantly boost the performance of the baseline model and ranks the $1^{st}$ place among all monocular-based methods on the KITTI benchmark. Besides, extensive ablation studies are conducted, which further prove the effectiveness of each part of our designs and illustrate what the baseline model has learned from the LiDAR Net.",
        "conference": "ICLR",
        "中文标题": "MonoDistill：学习单目3D目标检测的空间特征",
        "摘要翻译": "3D目标检测是3D场景理解中的一项基础且具有挑战性的任务，而基于单目的方法可以作为基于立体或LiDAR方法的经济替代方案。然而，由于缺乏空间线索，从单张图像中准确地在3D空间中定位物体极为困难。为了缓解这一问题，我们提出了一种简单有效的方案，将LiDAR信号的空间信息引入到单目3D检测器中，而无需在推理阶段引入任何额外成本。具体来说，我们首先将LiDAR信号投影到图像平面并与RGB图像对齐。之后，我们使用得到的数据来训练一个3D检测器（LiDAR Net），其架构与基线模型相同。最后，这个LiDAR Net可以作为教师，将学到的知识转移到基线模型中。实验结果表明，所提出的方法可以显著提升基线模型的性能，并在KITTI基准测试中排名第一。此外，还进行了广泛的消融研究，进一步证明了我们设计每一部分的有效性，并说明了基线模型从LiDAR Net中学到了什么。",
        "领域": "单目3D目标检测",
        "问题": "从单张图像中准确地在3D空间中定位物体",
        "动机": "解决单目3D目标检测中由于缺乏空间线索导致的定位困难问题",
        "方法": "通过将LiDAR信号的空间信息引入到单目3D检测器中，利用LiDAR Net作为教师模型进行知识蒸馏",
        "关键词": [
            "单目3D目标检测",
            "知识蒸馏",
            "LiDAR信号",
            "KITTI基准",
            "空间特征学习"
        ],
        "涉及的技术概念": {
            "知识蒸馏": "通过教师模型（LiDAR Net）将学到的空间信息知识转移到学生模型（基线模型）中，以提升单目3D目标检测的性能",
            "LiDAR信号": "用于提供丰富的空间信息，帮助单目3D检测器更准确地定位物体",
            "空间特征学习": "通过学习LiDAR信号中的空间特征，增强单目3D检测器对物体在3D空间中位置的理解"
        },
        "success": true
    },
    {
        "order": 628,
        "title": "Monotonic Differentiable Sorting Networks",
        "html": "https://iclr.cc//virtual/2022/poster/5925",
        "abstract": "Differentiable sorting algorithms allow training with sorting and ranking supervision, where only the ordering or ranking of samples is known. Various methods have been proposed to address this challenge, ranging from optimal transport-based differentiable Sinkhorn sorting algorithms to making classic sorting networks differentiable. One problem of current differentiable sorting methods is that they are non-monotonic. To address this issue, we propose a novel relaxation of conditional swap operations that guarantees monotonicity in differentiable sorting networks. We introduce a family of sigmoid functions and prove that they produce differentiable sorting networks that are monotonic. Monotonicity ensures that the gradients always have the correct sign, which is an advantage in gradient-based optimization. We demonstrate that monotonic differentiable sorting networks improve upon previous differentiable sorting methods.",
        "conference": "ICLR",
        "中文标题": "单调可微分排序网络",
        "摘要翻译": "可微分排序算法允许使用排序和排名监督进行训练，其中仅知道样本的排序或排名。已经提出了各种方法来解决这一挑战，从基于最优传输的可微分Sinkhorn排序算法到使经典排序网络可微分。当前可微分排序方法的一个问题是它们是非单调的。为了解决这个问题，我们提出了一种新的条件交换操作的松弛方法，保证了可微分排序网络的单调性。我们引入了一族sigmoid函数，并证明它们产生的可微分排序网络是单调的。单调性确保了梯度始终具有正确的符号，这是在基于梯度的优化中的一个优势。我们证明了单调可微分排序网络改进了之前的可微分排序方法。",
        "领域": "机器学习优化、排序算法、深度学习理论",
        "问题": "解决当前可微分排序方法的非单调性问题",
        "动机": "为了提高可微分排序算法在梯度优化中的效率和准确性，通过确保梯度的正确符号来优化训练过程",
        "方法": "提出了一种新的条件交换操作的松弛方法，引入了一族sigmoid函数来保证可微分排序网络的单调性",
        "关键词": [
            "可微分排序",
            "单调性",
            "sigmoid函数",
            "梯度优化",
            "排序网络"
        ],
        "涉及的技术概念": {
            "可微分排序算法": "允许算法在排序和排名监督下进行训练，使得仅知道样本的排序或排名时也能进行优化",
            "单调性": "确保梯度始终具有正确的符号，提高梯度优化过程的效率和准确性",
            "sigmoid函数": "用于产生单调的可微分排序网络，保证条件交换操作的松弛方法有效"
        },
        "success": true
    },
    {
        "order": 629,
        "title": "MoReL: Multi-omics Relational Learning",
        "html": "https://iclr.cc//virtual/2022/poster/7199",
        "abstract": "Multi-omics data analysis has the potential to discover hidden molecular interactions, revealing potential regulatory and/or signal transduction pathways for cellular processes of interest when studying life and disease systems. One of critical challenges when dealing with real-world multi-omics data is that they may manifest heterogeneous structures and data quality as often existing data may be collected from different subjects under different conditions for each type of omics data. We propose a novel deep Bayesian generative model to efficiently infer a multi-partite graph encoding molecular interactions across such heterogeneous views, using a fused Gromov-Wasserstein (FGW) regularization between latent representations of corresponding views for integrative analysis. With such an optimal transport regularization in the deep Bayesian generative model, it not only allows incorporating view-specific side information, either with graph-structured or unstructured data in different views, but also increases the model flexibility with the distribution-based regularization. This allows efficient alignment of heterogeneous latent variable distributions to derive reliable interaction predictions compared to the existing point-based graph embedding methods. Our experiments on several real-world datasets demonstrate enhanced performance of MoReL in inferring meaningful interactions compared to existing baselines.",
        "conference": "ICLR",
        "中文标题": "MoReL: 多组学关系学习",
        "摘要翻译": "多组学数据分析有潜力发现隐藏的分子相互作用，揭示在研究生命和疾病系统时感兴趣的细胞过程的潜在调控和/或信号转导途径。处理现实世界的多组学数据时的一个关键挑战是，它们可能表现出异构结构和数据质量，因为现有的数据可能是从不同条件下的不同受试者收集的，针对每种类型的组学数据。我们提出了一种新颖的深度贝叶斯生成模型，通过使用对应视图潜在表示之间的融合Gromov-Wasserstein（FGW）正则化进行综合分析，有效地推断出编码跨这些异构视图的分子相互作用的多部图。在深度贝叶斯生成模型中加入这种最优传输正则化，不仅允许纳入视图特定的侧信息，无论是具有图结构还是非结构化数据，在不同的视图中，而且还通过基于分布的正则化增加了模型的灵活性。与现有的基于点的图嵌入方法相比，这允许有效地对齐异构潜在变量分布，以得出可靠的相互作用预测。我们在几个真实世界数据集上的实验表明，与现有基线相比，MoReL在推断有意义的相互作用方面表现出增强的性能。",
        "领域": "多组学数据分析、生物信息学、深度学习",
        "问题": "处理异构结构和数据质量的多组学数据，以发现隐藏的分子相互作用。",
        "动机": "解决多组学数据因来源不同而导致的异构性和数据质量问题，以更准确地揭示分子间的相互作用。",
        "方法": "提出了一种深度贝叶斯生成模型，利用融合Gromov-Wasserstein正则化进行综合分析，有效推断跨异构视图的分子相互作用。",
        "关键词": [
            "多组学数据分析",
            "深度贝叶斯生成模型",
            "Gromov-Wasserstein正则化",
            "分子相互作用",
            "异构数据整合"
        ],
        "涉及的技术概念": {
            "深度贝叶斯生成模型": "用于推断多组学数据中的分子相互作用，能够处理数据的异构性和不确定性。",
            "融合Gromov-Wasserstein正则化": "用于在潜在表示之间进行综合分析，促进异构数据视图间的对齐和整合。",
            "最优传输正则化": "增加模型灵活性，允许有效对齐异构潜在变量分布，提高相互作用预测的可靠性。"
        },
        "success": true
    },
    {
        "order": 630,
        "title": "MT3: Multi-Task Multitrack Music Transcription",
        "html": "https://iclr.cc//virtual/2022/poster/6969",
        "abstract": "Automatic Music Transcription (AMT), inferring musical notes from raw audio, is a challenging task at the core of music understanding. Unlike Automatic Speech Recognition (ASR), which typically focuses on the words of a single speaker, AMT often requires transcribing multiple instruments simultaneously, all while preserving fine-scale pitch and timing information. Further, many AMT datasets are ``low-resource'', as even expert musicians find music transcription difficult and time-consuming. Thus, prior work has focused on task-specific architectures, tailored to the individual instruments of each task. In this work, motivated by the promising results of sequence-to-sequence transfer learning for low-resource Natural Language Processing (NLP), we demonstrate that a general-purpose Transformer model can perform multi-task AMT, jointly transcribing arbitrary combinations of musical instruments across several transcription datasets. We show this unified training framework achieves high-quality transcription results across a range of datasets, dramatically improving performance for low-resource instruments (such as guitar), while preserving strong performance for abundant instruments (such as piano). Finally, by expanding the scope of AMT, we expose the need for more consistent evaluation metrics and better dataset alignment, and provide a strong baseline for this new direction of multi-task AMT.",
        "conference": "ICLR",
        "中文标题": "MT3：多任务多音轨音乐转录",
        "摘要翻译": "自动音乐转录（AMT）是从原始音频中推断出音符，这是音乐理解中的一项核心挑战性任务。与通常专注于单个说话者词语的自动语音识别（ASR）不同，AMT通常需要同时转录多种乐器，同时保留精细的音高和时序信息。此外，许多AMT数据集是“低资源”的，因为即使是专业音乐家也发现音乐转录既困难又耗时。因此，先前的工作主要集中在针对每个任务的个别乐器量身定制的任务特定架构上。在这项工作中，受到序列到序列迁移学习在低资源自然语言处理（NLP）中取得的令人鼓舞结果的启发，我们证明了一个通用Transformer模型可以执行多任务AMT，联合转录多个转录数据集中的任意乐器组合。我们展示了这种统一的训练框架在一系列数据集上实现了高质量的转录结果，显著提高了低资源乐器（如吉他）的性能，同时保持了丰富乐器（如钢琴）的强劲表现。最后，通过扩大AMT的范围，我们揭示了需要更一致的评估指标和更好的数据集对齐，并为这一多任务AMT的新方向提供了一个强有力的基线。",
        "领域": "音乐信息检索、音频信号处理、多任务学习",
        "问题": "解决自动音乐转录（AMT）中同时转录多种乐器并保留精细音高和时序信息的挑战，特别是在低资源数据集上的性能问题。",
        "动机": "受到序列到序列迁移学习在低资源自然语言处理中成功应用的启发，探索通用Transformer模型在多任务AMT中的应用，以提高低资源乐器的转录性能。",
        "方法": "采用通用Transformer模型进行多任务学习，联合转录多个数据集中的任意乐器组合，实现高质量的音乐转录。",
        "关键词": [
            "自动音乐转录",
            "多任务学习",
            "Transformer模型",
            "低资源处理",
            "音乐信息检索"
        ],
        "涉及的技术概念": {
            "自动音乐转录（AMT）": "从原始音频中推断出音符的核心技术，用于音乐理解。",
            "Transformer模型": "一种基于自注意力机制的深度学习模型，用于处理序列数据，在本研究中用于多任务音乐转录。",
            "多任务学习": "一种机器学习方法，通过同时学习多个相关任务来提高模型的泛化能力和效率，本研究应用于同时转录多种乐器。"
        },
        "success": true
    },
    {
        "order": 631,
        "title": "Multi-Agent MDP Homomorphic Networks",
        "html": "https://iclr.cc//virtual/2022/poster/6821",
        "abstract": "This paper introduces Multi-Agent MDP Homomorphic Networks, a class of networks that allows distributed execution using only local information, yet is able to share experience between global symmetries in the joint state-action space of cooperative multi-agent systems. In cooperative multi-agent systems, complex symmetries arise between different configurations of the agents and their local observations. For example, consider a group of agents navigating: rotating the state globally results in a permutation of the optimal joint policy. Existing work on symmetries in single agent reinforcement learning can only be generalized to the fully centralized setting, because such approaches rely on the global symmetry in the full state-action spaces, and these can result in correspondences across agents. To encode such symmetries while still allowing distributed execution we propose a factorization that decomposes global symmetries into local transformations. Our proposed factorization allows for distributing the computation that enforces global symmetries over local agents and local interactions. We introduce a multi-agent equivariant policy network based on this factorization. We show empirically on symmetric multi-agent problems that globally symmetric distributable policies improve data efficiency compared to non-equivariant baselines.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "多智能体MDP同构网络",
        "摘要翻译": "本文介绍了多智能体MDP同构网络，这类网络允许仅使用局部信息进行分布式执行，同时能够在合作多智能体系统的联合状态-动作空间中共享全局对称性之间的经验。在合作多智能体系统中，不同智能体配置及其局部观察之间会出现复杂的对称性。例如，考虑一组导航的智能体：全局旋转状态会导致最优联合策略的排列。现有关于单智能体强化学习中对称性的工作只能推广到完全集中式设置，因为这些方法依赖于完整状态-动作空间中的全局对称性，而这些对称性可能导致跨智能体的对应关系。为了编码这种对称性同时仍允许分布式执行，我们提出了一种将全局对称性分解为局部变换的因子分解方法。我们提出的因子分解方法允许将强制执行全局对称性的计算分布在局部智能体和局部交互上。基于这种因子分解，我们引入了一种多智能体等变策略网络。我们在对称多智能体问题上实证表明，与非等变基线相比，全局对称可分布策略提高了数据效率。",
        "领域": "多智能体系统, 强化学习, 分布式计算",
        "问题": "如何在合作多智能体系统中有效利用全局对称性进行分布式执行",
        "动机": "解决现有单智能体强化学习对称性方法无法直接应用于多智能体系统的问题，特别是在分布式执行环境中",
        "方法": "提出一种将全局对称性分解为局部变换的因子分解方法，并基于此构建多智能体等变策略网络",
        "关键词": [
            "多智能体系统",
            "强化学习",
            "对称性",
            "分布式执行",
            "等变策略"
        ],
        "涉及的技术概念": {
            "多智能体MDP同构网络": "一类允许分布式执行并共享全局对称性经验的网络",
            "全局对称性分解": "将全局对称性分解为局部变换的因子分解方法，以支持分布式计算",
            "多智能体等变策略网络": "基于全局对称性分解构建的策略网络，能够在多智能体系统中实现等变性"
        }
    },
    {
        "order": 632,
        "title": "Multi-Critic Actor Learning: Teaching RL Policies to Act with Style",
        "html": "https://iclr.cc//virtual/2022/poster/6568",
        "abstract": "Using a single value function (critic) shared over multiple tasks in Actor-Critic multi-task reinforcement learning (MTRL) can result in negative interference between tasks, which can compromise learning performance. Multi-Critic Actor Learning (MultiCriticAL) proposes instead maintaining separate critics for each task being trained while training a single multi-task actor. Explicitly distinguishing between tasks also eliminates the need for critics to learn to do so and mitigates interference between task-value estimates. MultiCriticAL is tested in the context of multi-style learning, a special case of MTRL where agents are trained to behave with different distinct behavior styles, and yields up to 56% performance gains over the single-critic baselines and even successfully learns behavior styles in cases where single-critic approaches may simply fail to learn. In a simulated real-world use case, MultiCriticAL enables learning policies that smoothly transition between multiple fighting styles on an experimental build of EA’s UFC game.",
        "conference": "ICLR",
        "中文标题": "多评论家演员学习：教授强化学习策略以风格化行动",
        "摘要翻译": "在演员-评论家多任务强化学习（MTRL）中，使用一个在多个任务间共享的单一价值函数（评论家）可能会导致任务间的负面干扰，从而影响学习性能。多评论家演员学习（MultiCriticAL）提出，改为为每个训练任务维护单独的评论家，同时训练一个多任务演员。明确区分任务还消除了评论家学习这样做的需要，并减轻了任务价值估计之间的干扰。MultiCriticAL在多风格学习的背景下进行了测试，这是MTRL的一个特例，其中代理被训练以表现出不同的行为风格，与单一评论家基线相比，性能提升了高达56%，甚至在单一评论家方法可能完全无法学习的情况下成功学习了行为风格。在一个模拟的现实世界用例中，MultiCriticAL使得在EA的UFC游戏的实验版本上学习能够平滑过渡于多种战斗风格之间的策略成为可能。",
        "领域": "多任务强化学习, 行为风格学习, 游戏AI",
        "问题": "解决多任务强化学习中单一评论家导致的负面干扰问题",
        "动机": "提高多任务强化学习的性能，特别是在需要学习多种行为风格的任务中",
        "方法": "为每个任务维护单独的评论家，同时训练一个多任务演员，以减少任务间的干扰",
        "关键词": [
            "多任务强化学习",
            "行为风格",
            "多评论家",
            "演员-评论家",
            "游戏AI"
        ],
        "涉及的技术概念": {
            "多任务强化学习": "一种强化学习方法，旨在同时学习解决多个相关任务",
            "演员-评论家架构": "结合了价值函数（评论家）和策略（演员）的强化学习框架，用于评估和优化策略",
            "行为风格学习": "在多任务强化学习中，训练代理以表现出多样化和特定的行为模式"
        },
        "success": true
    },
    {
        "order": 633,
        "title": "Multimeasurement Generative Models",
        "html": "https://iclr.cc//virtual/2022/poster/7044",
        "abstract": "We formally map the problem of sampling from an unknown distribution with a density in $\\mathbb{R}^d$ to the problem of learning and sampling a smoother density in $\\mathbb{R}^{Md}$ obtained by convolution with a fixed factorial kernel: the new density is referred to as M-density and the kernel as multimeasurement noise model (MNM). The M-density in $\\mathbb{R}^{Md}$ is smoother than the original density in $\\mathbb{R}^d$, easier to learn and sample from, yet for large $M$ the two problems are mathematically equivalent since clean data can be estimated exactly given a multimeasurement noisy observation using the Bayes estimator. To formulate the problem, we derive the Bayes estimator for Poisson and Gaussian MNMs in closed form in terms of the unnormalized M-density. This leads to a simple least-squares objective for learning parametric energy and score functions. We present various parametrization schemes of interest including one in which studying Gaussian M-densities directly leads to multidenoising autoencoders—this is the first theoretical connection made between denoising autoencoders and empirical Bayes in the literature.  Samples in $\\mathbb{R}^d$ are obtained by walk-jump sampling (Saremi & Hyvarinen, 2019) via underdamped Langevin MCMC (walk) to sample from M-density and the multimeasurement Bayes estimation (jump). We study permutation invariant Gaussian M-densities on MNIST, CIFAR-10, and FFHQ-256 datasets, and demonstrate the effectiveness of this framework for realizing fast-mixing stable Markov chains in high dimensions.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "多重测量生成模型",
        "摘要翻译": "我们正式将从具有密度函数的未知分布中采样的 d 维空间问题，映射到学习和采样一个更平滑的 Md 维空间密度函数的问题，该函数通过与一个固定的阶乘核卷积得到：新的密度函数被称为 M-密度函数，核被称为多重测量噪声模型（MNM）。Md 维空间中的 M-密度函数比 d 维空间中的原始密度函数更平滑，更容易学习和采样，然而对于较大的 M，这两个问题在数学上是等价的，因为可以使用贝叶斯估计器根据多重测量噪声观测精确估计干净的数据。为了公式化这个问题，我们推导了泊松和高斯 MNM 的贝叶斯估计器，用未归一化的 M-密度函数来表示闭式形式。这产生了一个简单的最小二乘目标，用于学习参数化的能量和得分函数。我们提出了各种感兴趣的参数化方案，包括一种直接研究高斯 M-密度函数导致多重去噪自编码器的方案——这是文献中首次建立去噪自编码器和经验贝叶斯之间的理论联系。通过欠阻尼朗之万 MCMC（游走）从 M-密度函数中采样，以及多重测量贝叶斯估计（跳跃），获得 d 维空间中的样本。我们研究了 MNIST、CIFAR-10 和 FFHQ-256 数据集上的置换不变高斯 M-密度函数，并证明了该框架在实现高维快速混合稳定马尔可夫链方面的有效性。",
        "领域": "生成模型、概率图模型、图像生成",
        "问题": "如何从未知的复杂分布中有效采样，特别是在高维空间中？",
        "动机": "在高维空间中，直接从复杂的未知分布中采样非常困难。通过引入多重测量噪声模型，将原始采样问题转化为一个更平滑、更容易学习和采样的密度函数，从而简化采样过程。",
        "方法": "论文提出了一种基于多重测量噪声模型（MNM）的生成框架，通过与固定的阶乘核卷积，将原始密度函数转换为更平滑的M-密度函数。然后，利用贝叶斯估计器进行数据估计，并使用欠阻尼朗之万MCMC和多重测量贝叶斯估计进行采样。",
        "关键词": [
            "生成模型",
            "多重测量噪声模型",
            "贝叶斯估计",
            "朗之万MCMC",
            "去噪自编码器"
        ],
        "涉及的技术概念": {
            "多重测量噪声模型（MNM）": "通过卷积操作将原始密度函数转换为更平滑的M-密度函数，简化了采样过程。",
            "贝叶斯估计器": "用于根据多重测量噪声观测精确估计原始数据，是连接噪声数据和原始数据的桥梁。"
        }
    },
    {
        "order": 634,
        "title": "Multi-Mode Deep Matrix and Tensor Factorization",
        "html": "https://iclr.cc//virtual/2022/poster/6972",
        "abstract": "Recently, deep linear and nonlinear matrix factorizations gain increasing attention in the area of machine learning. Existing deep nonlinear matrix factorization methods can only exploit partial nonlinearity of the data and are not effective in handling matrices of which the number of rows is comparable to the number of columns. On the other hand, there is still a gap between deep learning and tensor decomposition. This paper presents a framework of multi-mode deep matrix and tensor factorizations to explore and exploit the full nonlinearity of the data in matrices and tensors. We use the factorization methods to solve matrix and tensor completion problems and prove that our methods have tighter generalization error bounds than conventional matrix and tensor factorization methods. The experiments on synthetic data and real datasets showed that the proposed methods have much higher recovery accuracy than many baselines.",
        "conference": "ICLR",
        "中文标题": "多模态深度矩阵与张量分解",
        "摘要翻译": "近年来，深度线性和非线性矩阵分解在机器学习领域获得了越来越多的关注。现有的深度非线性矩阵分解方法只能利用数据的部分非线性，并且在处理行数与列数相当的矩阵时效果不佳。另一方面，深度学习与张量分解之间仍存在差距。本文提出了一个多模态深度矩阵与张量分解框架，以探索和利用矩阵和张量数据的全部非线性。我们使用这些分解方法来解决矩阵和张量补全问题，并证明我们的方法比传统的矩阵和张量分解方法具有更紧的泛化误差界。在合成数据和真实数据集上的实验表明，所提出的方法比许多基线方法具有更高的恢复精度。",
        "领域": "张量分解、矩阵补全、深度学习",
        "问题": "解决现有深度非线性矩阵分解方法无法充分利用数据非线性以及在处理行列数相近矩阵时的不足，以及深度学习与张量分解之间的差距问题。",
        "动机": "探索和利用矩阵和张量数据的全部非线性，提高矩阵和张量补全问题的解决效率和精度。",
        "方法": "提出多模态深度矩阵与张量分解框架，通过深度学习方法探索数据的非线性，应用于矩阵和张量补全问题，并证明其泛化误差界优于传统方法。",
        "关键词": [
            "多模态分解",
            "深度矩阵分解",
            "张量分解",
            "矩阵补全",
            "非线性探索"
        ],
        "涉及的技术概念": {
            "多模态深度矩阵与张量分解": "提出的框架，用于探索和利用矩阵和张量数据的全部非线性。",
            "泛化误差界": "论文中证明所提方法比传统方法具有更紧的泛化误差界，表明其更好的泛化能力。",
            "矩阵和张量补全": "应用所提方法解决的具体问题，旨在恢复缺失的矩阵和张量数据。"
        },
        "success": true
    },
    {
        "order": 635,
        "title": "Multi-objective Optimization by Learning Space Partition",
        "html": "https://iclr.cc//virtual/2022/poster/5994",
        "abstract": "In contrast to single-objective optimization (SOO), multi-objective optimization (MOO) requires an optimizer to find the Pareto frontier, a subset of feasible solutions that are not dominated by other feasible solutions. In this paper, we propose LaMOO, a novel multi-objective optimizer that learns a model from observed samples to partition the search space and then focus on promising regions that are likely to contain a subset of the Pareto frontier. The partitioning is based on the dominance number, which measures 'how close'' a data point is to the Pareto frontier among existing samples. To account for possible partition errors due to limited samples and model mismatch, we leverage Monte Carlo Tree Search (MCTS) to exploit promising regions while exploring suboptimal regions that may turn out to contain good solutions later. Theoretically, we prove the efficacy of learning space partitioning via LaMOO under certain assumptions. Empirically, on the HyperVolume (HV) benchmark, a popular MOO metric, LaMOO substantially outperforms strong baselines on multiple real-world MOO tasks, by up to 225% in sample efficiency for neural architecture search on Nasbench201, and up to 10% for molecular design.",
        "conference": "ICLR",
        "中文标题": "通过学习空间划分进行多目标优化",
        "摘要翻译": "与单目标优化（SOO）相比，多目标优化（MOO）要求优化器找到帕累托前沿，即不被其他可行解支配的可行解子集。在本文中，我们提出了LaMOO，一种新颖的多目标优化器，它从观察到的样本中学习模型以划分搜索空间，然后专注于可能包含帕累托前沿子集的有希望区域。划分基于支配数，该数衡量数据点在现有样本中‘有多接近’帕累托前沿。为了考虑由于样本有限和模型不匹配可能导致的分区错误，我们利用蒙特卡洛树搜索（MCTS）在探索可能后来发现包含良好解决方案的次优区域的同时，开发有希望的区域。理论上，我们在某些假设下证明了通过LaMOO学习空间划分的有效性。实证上，在HyperVolume（HV）基准测试中，这是一个流行的MOO指标，LaMOO在多个真实世界的MOO任务上大幅优于强基线，在Nasbench201上的神经架构搜索样本效率提高了高达225%，在分子设计上提高了高达10%。",
        "领域": "多目标优化、神经架构搜索、分子设计",
        "问题": "如何在多目标优化问题中高效地找到帕累托前沿",
        "动机": "解决多目标优化问题中寻找帕累托前沿的效率和效果问题",
        "方法": "提出LaMOO方法，通过学习空间划分和利用蒙特卡洛树搜索（MCTS）来专注于有希望的区域",
        "关键词": [
            "多目标优化",
            "帕累托前沿",
            "蒙特卡洛树搜索",
            "神经架构搜索",
            "分子设计"
        ],
        "涉及的技术概念": {
            "帕累托前沿": "在多目标优化中，指不被其他任何可行解支配的解集，代表了最优解的集合",
            "蒙特卡洛树搜索（MCTS）": "一种用于决策过程的搜索算法，通过模拟随机采样来评估和选择最优的决策路径",
            "支配数": "衡量一个解在现有样本中接近帕累托前沿程度的指标，用于指导搜索空间的划分"
        },
        "success": true
    },
    {
        "order": 636,
        "title": "Multiset-Equivariant Set Prediction with Approximate Implicit Differentiation",
        "html": "https://iclr.cc//virtual/2022/poster/6515",
        "abstract": "Most set prediction models in deep learning use set-equivariant operations, but they actually operate on multisets. We show that set-equivariant functions cannot represent certain functions on multisets, so we introduce the more appropriate notion of multiset-equivariance. We identify that the existing Deep Set Prediction Network (DSPN) can be multiset-equivariant without being hindered by set-equivariance and improve it with approximate implicit differentiation, allowing for better optimization while being faster and saving memory. In a range of toy experiments, we show that the perspective of multiset-equivariance is beneficial and that our changes to DSPN achieve better results in most cases. On CLEVR object property prediction, we substantially improve over the state-of-the-art Slot Attention from 8% to 77% in one of the strictest evaluation metrics because of the benefits made possible by implicit differentiation.",
        "conference": "ICLR",
        "中文标题": "多集等变集合预测与近似隐式微分",
        "摘要翻译": "深度学习中的大多数集合预测模型使用集合等变操作，但它们实际上是在多集上操作。我们表明，集合等变函数不能表示多集上的某些函数，因此我们引入了更合适的多集等变概念。我们发现现有的深度集合预测网络（DSPN）可以在不受集合等变性阻碍的情况下实现多集等变，并通过近似隐式微分对其进行改进，从而在更快和节省内存的同时实现更好的优化。在一系列玩具实验中，我们展示了多集等变的视角是有益的，并且我们对DSPN的改进在大多数情况下取得了更好的结果。在CLEVR对象属性预测上，由于隐式微分带来的好处，我们在最严格的评估指标之一中，将最先进的Slot Attention从8%大幅提高到77%。",
        "领域": "集合预测、多集处理、隐式微分优化",
        "问题": "解决集合预测模型中集合等变操作无法充分表示多集函数的问题",
        "动机": "提升深度学习模型在多集预测任务中的表现，通过引入多集等变概念和改进现有技术",
        "方法": "引入多集等变概念，改进深度集合预测网络（DSPN）并应用近似隐式微分优化",
        "关键词": [
            "多集等变",
            "集合预测",
            "隐式微分",
            "DSPN",
            "优化"
        ],
        "涉及的技术概念": {
            "多集等变": "在多集上操作的函数，能够正确处理重复元素，解决了集合等变函数在多集上的局限性",
            "深度集合预测网络（DSPN）": "一种用于集合预测的深度学习模型，通过改进实现多集等变",
            "近似隐式微分": "一种优化技术，用于改进DSPN的训练过程，提高效率和性能"
        },
        "success": true
    },
    {
        "order": 637,
        "title": "Multi-Stage Episodic Control for Strategic Exploration in Text Games",
        "html": "https://iclr.cc//virtual/2022/poster/6725",
        "abstract": "Text adventure games present unique challenges to reinforcement learning methods due to their combinatorially large action spaces and sparse rewards. The interplay of these two factors is particularly demanding because large action spaces require extensive exploration, while sparse rewards provide limited feedback. This work proposes to tackle the explore-vs-exploit dilemma using a multi-stage approach that explicitly disentangles these two strategies within each episode. Our algorithm, called eXploit-Then-eXplore (XTX), begins each episode using an exploitation policy that imitates a set of promising trajectories from the past, and then switches over to an exploration policy aimed at discovering novel actions that lead to unseen state spaces. This policy decomposition allows us to combine global decisions about which parts of the game space to return to with curiosity-based local exploration in that space, motivated by how a human may approach these games. Our method significantly outperforms prior approaches by 27% and 11% average normalized score over 12 games from the Jericho benchmark (Hausknecht et al., 2020) in both deterministic and stochastic settings, respectively. On the game of Zork1, in particular, XTX obtains a score of 103, more than a 2x improvement over prior methods, and pushes past several known bottlenecks in the game that have plagued previous state-of-the-art methods.",
        "conference": "ICLR",
        "中文标题": "多阶段情景控制用于文本游戏中的战略探索",
        "摘要翻译": "文本冒险游戏由于其组合上巨大的动作空间和稀疏的奖励，对强化学习方法提出了独特的挑战。这两个因素的相互作用尤其具有挑战性，因为大的动作空间需要广泛的探索，而稀疏的奖励提供的反馈有限。这项工作提出使用多阶段方法来处理探索与利用的困境，明确在每个情景中分离这两种策略。我们的算法，称为eXploit-Then-eXplore（XTX），每个情景开始时使用利用策略模仿过去一组有希望的轨迹，然后切换到旨在发现导致未见状态空间的新动作的探索策略。这种策略分解使我们能够结合关于游戏空间哪些部分返回的全局决策与基于好奇心的局部探索，这是受到人类如何接近这些游戏的启发。我们的方法在Jericho基准测试（Hausknecht等人，2020）中的12个游戏中，分别在确定性和随机性设置下，平均归一化得分比先前方法高出27%和11%。特别是在Zork1游戏中，XTX获得了103分，比先前方法提高了2倍以上，并突破了游戏中几个已知的瓶颈，这些瓶颈一直困扰着先前的最先进方法。",
        "领域": "强化学习、游戏AI、自然语言处理与视觉结合",
        "问题": "解决文本冒险游戏中由于巨大的动作空间和稀疏奖励带来的探索与利用的困境",
        "动机": "受到人类如何接近文本冒险游戏的启发，旨在通过分离探索与利用策略，提高游戏中的探索效率和性能",
        "方法": "提出多阶段方法eXploit-Then-eXplore（XTX），在每个情景中先利用过去的成功轨迹，再切换到探索新动作的策略",
        "关键词": [
            "文本游戏",
            "战略探索",
            "强化学习",
            "多阶段控制",
            "XTX算法"
        ],
        "涉及的技术概念": {
            "多阶段情景控制": "在每个游戏情景中明确分离探索与利用策略，以提高探索效率和性能",
            "eXploit-Then-eXplore（XTX）算法": "先利用过去的成功轨迹，再探索新动作的策略分解方法",
            "Jericho基准测试": "用于评估文本游戏AI性能的标准测试集，包含多种文本冒险游戏"
        },
        "success": true
    },
    {
        "order": 638,
        "title": "Multi-Task Processes",
        "html": "https://iclr.cc//virtual/2022/poster/6487",
        "abstract": "Neural Processes (NPs) consider a task as a function realized from a stochastic process and flexibly adapt to unseen tasks through inference on functions. However, naive NPs can model data from only a single stochastic process and are designed to infer each task independently. Since many real-world data represent a set of correlated tasks from multiple sources (e.g., multiple attributes and multi-sensor data), it is beneficial to infer them jointly and exploit the underlying correlation to improve the predictive performance.To this end, we propose Multi-Task Neural Processes (MTNPs), an extension of NPs designed to jointly infer tasks realized from multiple stochastic processes. We build MTNPs in a hierarchical way such that inter-task correlation is considered by conditioning all per-task latent variables on a single global latent variable. In addition, we further design our MTNPs so that they can address multi-task settings with incomplete data (i.e., not all tasks share the same set of input points), which has high practical demands in various applications.Experiments demonstrate that MTNPs can successfully model multiple tasks jointly by discovering and exploiting their correlations in various real-world data such as time series of weather attributes and pixel-aligned visual modalities. We release our code at https://github.com/GitGyun/multi_task_neural_processes.",
        "conference": "ICLR",
        "中文标题": "多任务神经过程",
        "摘要翻译": "神经过程（NPs）将任务视为从随机过程中实现的函数，并通过函数推断灵活适应未见过的任务。然而，原始的NPs只能建模来自单一随机过程的数据，并且设计为独立推断每个任务。由于许多现实世界的数据表示来自多个源的关联任务集（例如，多个属性和多传感器数据），联合推断它们并利用潜在的相关性来提高预测性能是有益的。为此，我们提出了多任务神经过程（MTNPs），这是NPs的一个扩展，旨在联合推断从多个随机过程实现的任务。我们以分层的方式构建MTNPs，使得通过将所有每任务潜在变量条件化在一个单一的全局潜在变量上来考虑任务间的相关性。此外，我们进一步设计MTNPs，使其能够处理具有不完整数据的多任务设置（即，并非所有任务共享相同的输入点集），这在各种应用中具有高度的实际需求。实验表明，MTNPs可以通过发现和利用各种现实世界数据（如天气属性的时间序列和像素对齐的视觉模态）中的相关性，成功地联合建模多个任务。我们在https://github.com/GitGyun/multi_task_neural_processes发布了我们的代码。",
        "领域": "多任务学习, 随机过程建模, 时间序列预测",
        "问题": "如何联合建模和推断来自多个随机过程的关联任务，以提高预测性能",
        "动机": "现实世界中的数据往往来自多个相关任务，独立处理这些任务无法利用它们之间的潜在相关性，限制了预测性能的提升",
        "方法": "提出多任务神经过程（MTNPs），通过分层结构将各任务的潜在变量条件化在一个全局潜在变量上，以考虑任务间的相关性，并支持不完整数据的多任务设置",
        "关键词": [
            "多任务神经过程",
            "随机过程",
            "分层建模",
            "不完整数据",
            "联合推断"
        ],
        "涉及的技术概念": {
            "神经过程（NPs）": "一种将任务视为从随机过程中实现的函数的模型，能够灵活适应未见过的任务",
            "多任务神经过程（MTNPs）": "NPs的扩展，旨在联合推断从多个随机过程实现的任务，通过分层结构考虑任务间的相关性",
            "全局潜在变量": "在MTNPs中，用于条件化所有每任务潜在变量的单一变量，以捕捉和利用任务间的相关性"
        },
        "success": true
    },
    {
        "order": 639,
        "title": "Multitask Prompted Training Enables Zero-Shot Task Generalization",
        "html": "https://iclr.cc//virtual/2022/poster/7101",
        "abstract": "Large language models have recently been shown to attain reasonable zero-shot generalization on a diverse set of tasks (Brown et al., 2020). It has been hypothesized that this is a consequence of implicit multitask learning in language models’ pretraining (Radford et al., 2019). Can zero-shot generalization instead be directly induced by explicit multitask learning? To test this question at scale, we develop a system for easily mapping any natural language tasks into a human-readable prompted form. We convert a large set of supervised datasets, each with multiple prompts with diverse wording. These prompted datasets allow for benchmarking the ability of a model to perform completely unseen tasks specified in natural language. We fine-tune a pretrained encoder-decoder model (Raffel et al., 2020; Lester et al., 2021) on this multitask mixture covering a wide variety of tasks. The model attains strong zero-shot performance on several datasets, often outperforming models 16× its size. Further, our model attains strong performance on a subset of tasks from the BIG-Bench benchmark, outperforming models 6× its size. All trained models are available at https://github.com/bigscience-workshop/t-zero, and all prompts are available at https://github.com/bigscience-workshop/promptsource.",
        "conference": "ICLR",
        "中文标题": "多任务提示训练实现零样本任务泛化",
        "摘要翻译": "最近，大型语言模型已被证明能够在多样化的任务集上实现合理的零样本泛化（Brown等人，2020）。有假设认为这是语言模型预训练中隐式多任务学习的结果（Radford等人，2019）。那么，零样本泛化是否可以通过显式多任务学习直接诱导呢？为了大规模测试这个问题，我们开发了一个系统，能够轻松将任何自然语言任务映射为人类可读的提示形式。我们转换了大量监督数据集，每个数据集包含多个措辞多样的提示。这些提示数据集允许对模型执行完全未见过的、以自然语言指定的任务的能力进行基准测试。我们在覆盖广泛任务的多任务混合上对预训练的编码器-解码器模型（Raffel等人，2020；Lester等人，2021）进行了微调。该模型在多个数据集上实现了强大的零样本性能，通常优于其16倍大小的模型。此外，我们的模型在BIG-Bench基准测试的一部分任务上实现了强大的性能，优于其6倍大小的模型。所有训练好的模型都可以在https://github.com/bigscience-workshop/t-zero获取，所有提示可以在https://github.com/bigscience-workshop/promptsource获取。",
        "领域": "自然语言处理与视觉结合",
        "问题": "如何通过显式多任务学习直接诱导零样本泛化",
        "动机": "探索显式多任务学习是否能够直接诱导零样本泛化，以提升模型在未见任务上的表现",
        "方法": "开发系统将自然语言任务映射为提示形式，转换监督数据集为多提示形式，并在多任务混合上微调预训练的编码器-解码器模型",
        "关键词": [
            "零样本泛化",
            "多任务学习",
            "自然语言处理"
        ],
        "涉及的技术概念": {
            "零样本泛化": "模型在没有直接训练数据的情况下执行新任务的能力",
            "多任务学习": "同时学习多个相关任务以提高模型泛化能力的方法",
            "编码器-解码器模型": "一种模型架构，用于将输入数据编码为中间表示，然后解码为输出数据"
        },
        "success": true
    },
    {
        "order": 640,
        "title": "NAS-Bench-Suite: NAS Evaluation is (Now) Surprisingly Easy",
        "html": "https://iclr.cc//virtual/2022/poster/7126",
        "abstract": "The release of tabular benchmarks, such as NAS-Bench-101 and NAS-Bench-201, has significantly lowered the computational overhead for conducting scientific research in neural architecture search (NAS). Although they have been widely adopted and used to tune real-world NAS algorithms, these benchmarks are limited to small search spaces and focus solely on image classification. Recently, several new NAS benchmarks have been introduced that cover significantly larger search spaces over a wide range of tasks, including object detection, speech recognition, and natural language processing. However, substantial differences among these NAS benchmarks have so far prevented their widespread adoption, limiting researchers to using just a few benchmarks. In this work, we present an in-depth analysis of popular NAS algorithms and performance prediction methods across 25 different combinations of search spaces and datasets, finding that many conclusions drawn from a few NAS benchmarks do \\emph{not} generalize to other benchmarks. To help remedy this problem, we introduce \\nasbs, a comprehensive and extensible collection of NAS benchmarks, accessible through a unified interface, created with the aim to facilitate reproducible, generalizable, and rapid NAS research. Our code is available at https://github.com/automl/naslib.",
        "conference": "ICLR",
        "中文标题": "NAS-Bench-Suite：NAS评估（现在）出奇地简单",
        "摘要翻译": "表格化基准测试的发布，如NAS-Bench-101和NAS-Bench-201，显著降低了进行神经架构搜索（NAS）科学研究的计算开销。尽管它们已被广泛采用并用于调整现实世界的NAS算法，但这些基准测试仅限于小型搜索空间，并且仅专注于图像分类。最近，引入了几个新的NAS基准测试，涵盖了从目标检测、语音识别到自然语言处理等多种任务的更大搜索空间。然而，这些NAS基准测试之间的显著差异迄今为止阻碍了它们的广泛采用，限制了研究人员仅使用少数基准测试。在这项工作中，我们对25种不同的搜索空间和数据集组合中的流行NAS算法和性能预测方法进行了深入分析，发现从少数NAS基准测试得出的许多结论并不能推广到其他基准测试。为了帮助解决这个问题，我们介绍了NAS-Bench-Suite（NASBS），一个全面且可扩展的NAS基准测试集合，通过统一接口访问，旨在促进可重复、可推广和快速的NAS研究。我们的代码可在https://github.com/automl/naslib获取。",
        "领域": "神经架构搜索、性能预测、多任务学习",
        "问题": "现有NAS基准测试的局限性和差异阻碍了神经架构搜索研究的广泛采用和推广性。",
        "动机": "为了解决现有NAS基准测试在搜索空间大小和任务多样性上的限制，以及促进NAS研究的可重复性和推广性。",
        "方法": "通过分析25种不同的搜索空间和数据集组合中的NAS算法和性能预测方法，引入一个全面且可扩展的NAS基准测试集合NAS-Bench-Suite（NASBS），提供统一接口。",
        "关键词": [
            "神经架构搜索",
            "基准测试",
            "性能预测",
            "多任务学习",
            "可重复研究"
        ],
        "涉及的技术概念": {
            "神经架构搜索（NAS）": "自动化设计神经网络架构的技术，旨在减少人工设计的工作量并提高模型性能。",
            "性能预测方法": "用于预测不同神经网络架构在特定任务上性能的技术，帮助快速评估架构优劣。",
            "统一接口": "提供标准化访问方式，使得不同基准测试可以方便地被比较和集成，促进研究的一致性和可重复性。"
        },
        "success": true
    },
    {
        "order": 641,
        "title": "NASI: Label- and Data-agnostic Neural Architecture Search at Initialization",
        "html": "https://iclr.cc//virtual/2022/poster/6257",
        "abstract": "Recent years have witnessed a surging interest in Neural Architecture Search (NAS). Various algorithms have been proposed to improve the search efficiency and effectiveness of NAS, i.e., to reduce the search cost and improve the generalization performance of the selected architectures, respectively. However, the search efficiency of these algorithms is severely limited by the need for model training during the search process. To overcome this limitation, we propose a novel NAS algorithm called NAS at Initialization (NASI) that exploits the capability of a Neural Tangent Kernel in being able to characterize the performance of candidate architectures at initialization, hence allowing model training to be completely avoided to boost the search efficiency. Besides the improved search efficiency, NASI also achieves competitive search effectiveness on various datasets like CIFAR-10/100 and ImageNet. Further, NASI is shown to be label- and data-agnostic under mild conditions, which guarantees the transferability of architectures selected by our NASI over different datasets.",
        "conference": "ICLR",
        "中文标题": "NASI：初始阶段的无标签和数据依赖的神经架构搜索",
        "摘要翻译": "近年来，神经架构搜索（NAS）引起了广泛关注。为了提高NAS的搜索效率和效果，即分别减少搜索成本和提高所选架构的泛化性能，已经提出了各种算法。然而，这些算法的搜索效率由于在搜索过程中需要进行模型训练而受到严重限制。为了克服这一限制，我们提出了一种名为初始阶段神经架构搜索（NASI）的新型NAS算法，该算法利用神经切线核的能力，能够在初始化阶段表征候选架构的性能，从而完全避免模型训练以提高搜索效率。除了提高搜索效率外，NASI在CIFAR-10/100和ImageNet等各种数据集上也实现了具有竞争力的搜索效果。此外，NASI在温和条件下被证明是无标签和数据依赖的，这保证了由我们的NASI选择的架构在不同数据集上的可转移性。",
        "领域": "神经架构搜索、深度学习优化、自动化机器学习",
        "问题": "如何在不需要模型训练的情况下，高效且有效地进行神经架构搜索。",
        "动机": "减少神经架构搜索过程中的计算成本和时间消耗，同时保持或提高搜索到的架构的性能。",
        "方法": "利用神经切线核在初始化阶段评估候选架构的性能，避免传统NAS中必需的模型训练步骤。",
        "关键词": [
            "神经架构搜索",
            "神经切线核",
            "初始化搜索",
            "无标签依赖",
            "数据不可知"
        ],
        "涉及的技术概念": {
            "神经架构搜索（NAS）": "一种自动化设计神经网络架构的技术，旨在减少人工设计架构的需求。",
            "神经切线核（NTK）": "用于在神经网络初始化阶段预测其训练后性能的数学工具，NASI利用它来评估候选架构而无需实际训练。",
            "无标签和数据依赖": "指NASI算法在搜索过程中不依赖于特定的标签或数据集，提高了算法的通用性和可转移性。"
        },
        "success": true
    },
    {
        "order": 642,
        "title": "NASPY: Automated Extraction of Automated Machine Learning Models",
        "html": "https://iclr.cc//virtual/2022/poster/7170",
        "abstract": "We present NASPY, an end-to-end adversarial framework to extract the networkarchitecture of deep learning models from Neural Architecture Search (NAS). Existing works about model extraction attacks mainly focus on conventional DNN models with very simple operations, or require heavy manual analysis with lots of domain knowledge.  In contrast, NASPY introduces seq2seq models to automatically identify novel and complicated operations (e.g., separable convolution,dilated convolution) from hardware side-channel sequences. We design two models (RNN-CTC and transformer), which can achieve only 3.2% and 11.3% error rates for operation prediction.  We further present methods to recover the model hyper-parameters and topology from the operation sequence .  With these techniques, NASPY is able to extract the complete NAS model architecture with high fidelity and automation, which are rarely analyzed before.",
        "conference": "ICLR",
        "中文标题": "NASPY：自动化机器学习模型的自动提取",
        "摘要翻译": "我们提出了NASPY，一个端到端的对抗性框架，用于从神经架构搜索（NAS）中提取深度学习模型的网络架构。现有的模型提取攻击工作主要集中在具有非常简单操作的传统DNN模型上，或者需要大量领域知识的手动分析。相比之下，NASPY引入了序列到序列模型，以自动从硬件侧信道序列中识别新颖且复杂的操作（例如，可分离卷积、扩张卷积）。我们设计了两种模型（RNN-CTC和transformer），它们在操作预测上的错误率仅为3.2%和11.3%。我们进一步提出了从操作序列中恢复模型超参数和拓扑结构的方法。通过这些技术，NASPY能够以高保真度和自动化程度提取完整的NAS模型架构，这在之前很少被分析过。",
        "领域": "神经架构搜索、模型提取攻击、深度学习安全",
        "问题": "如何自动化地从神经架构搜索中提取深度学习模型的网络架构",
        "动机": "现有的模型提取攻击方法要么局限于简单操作的传统DNN模型，要么需要大量手动分析和领域知识，无法有效处理NAS中新颖且复杂的操作。",
        "方法": "引入序列到序列模型自动识别复杂操作，设计RNN-CTC和transformer模型进行高效预测，并提出恢复模型超参数和拓扑结构的方法。",
        "关键词": [
            "神经架构搜索",
            "模型提取攻击",
            "序列到序列模型",
            "深度学习安全",
            "自动化提取"
        ],
        "涉及的技术概念": {
            "序列到序列模型": "用于自动从硬件侧信道序列中识别新颖且复杂的操作，如可分离卷积和扩张卷积。",
            "RNN-CTC和transformer": "设计的两种模型，用于高效预测操作序列，错误率低。",
            "模型超参数和拓扑结构恢复": "从识别的操作序列中恢复出完整的模型架构，实现高保真度和自动化提取。"
        },
        "success": true
    },
    {
        "order": 643,
        "title": "NASViT: Neural Architecture Search for Efficient Vision Transformers with Gradient Conflict aware Supernet Training",
        "html": "https://iclr.cc//virtual/2022/poster/6085",
        "abstract": "Designing accurate and efficient vision transformers (ViTs) is a highly important but challenging task. Supernet-based one-shot neural architecture search (NAS) enables fast architecture optimization and has achieved state-of-the-art (SOTA) results on convolutional neural networks (CNNs). However, directly applying the supernet-based NAS to optimize ViTs leads to poor performance - even worse compared to training single ViTs. In this work, we observe that the poor performance is due to a gradient conflict issue: the gradients of different sub-networks conflict with that of the supernet more severely in ViTs than CNNs, which leads to early saturation in training and inferior convergence. To alleviate this issue, we propose a series of techniques, including a gradient projection algorithm, a switchable layer scaling design, and a simplified data augmentation and regularization training recipe. The proposed techniques significantly improve the convergence and the performance of all sub-networks. Our discovered hybrid ViT model family, dubbed NASViT, achieves top-1 accuracy from 78.2% to 81.8% on ImageNet from 200M to 800M FLOPs, and outperforms all the prior art CNNs and ViTs, including AlphaNet and LeViT, etc. When transferred to semantic segmentation tasks, NASViTs also outperform previous backbones on both Cityscape and ADE20K datasets, achieving 73.2% and 37.9% mIoU with only 5G FLOPs, respectively. Code is available athttps://github.com/facebookresearch/NASViT.",
        "conference": "ICLR",
        "中文标题": "NASViT：基于梯度冲突感知超网络训练的高效视觉变换器神经架构搜索",
        "摘要翻译": "设计准确且高效的视觉变换器（ViTs）是一项非常重要但具有挑战性的任务。基于超网络的一站式神经架构搜索（NAS）能够快速优化架构，并在卷积神经网络（CNNs）上取得了最先进的（SOTA）结果。然而，直接将基于超网络的NAS应用于优化ViTs会导致性能不佳——甚至比训练单个ViTs还要差。在这项工作中，我们观察到性能不佳的原因是梯度冲突问题：不同子网络的梯度与超网络的梯度在ViTs中的冲突比在CNNs中更为严重，这导致训练早期饱和和收敛性差。为了缓解这一问题，我们提出了一系列技术，包括梯度投影算法、可切换层缩放设计以及简化的数据增强和正则化训练方案。所提出的技术显著提高了所有子网络的收敛性和性能。我们发现的混合ViT模型家族，称为NASViT，在ImageNet上从200M到800M FLOPs的范围内实现了78.2%到81.8%的top-1准确率，并且优于所有先前的CNNs和ViTs，包括AlphaNet和LeViT等。当转移到语义分割任务时，NASViTs在Cityscape和ADE20K数据集上也优于之前的骨干网络，仅用5G FLOPs就分别实现了73.2%和37.9%的mIoU。代码可在https://github.com/facebookresearch/NASViT获取。",
        "领域": "神经架构搜索、视觉变换器、语义分割",
        "问题": "解决在视觉变换器（ViTs）中直接应用基于超网络的神经架构搜索（NAS）导致的性能不佳问题",
        "动机": "观察到梯度冲突问题是导致性能不佳的主要原因，旨在通过技术改进提升ViTs的性能和效率",
        "方法": "提出包括梯度投影算法、可切换层缩放设计以及简化的数据增强和正则化训练方案在内的一系列技术",
        "关键词": [
            "神经架构搜索",
            "视觉变换器",
            "梯度冲突",
            "超网络训练",
            "语义分割"
        ],
        "涉及的技术概念": {
            "梯度投影算法": "用于减少不同子网络梯度与超网络梯度之间的冲突，提升训练效率和模型性能",
            "可切换层缩放设计": "允许网络动态调整层的大小和复杂度，以适应不同的计算需求和性能目标",
            "简化的数据增强和正则化训练方案": "通过优化训练过程，减少过拟合，提高模型的泛化能力和性能"
        },
        "success": true
    },
    {
        "order": 644,
        "title": "Natural Language Descriptions of Deep Features",
        "html": "https://iclr.cc//virtual/2022/poster/5988",
        "abstract": "Some neurons in deep networks specialize in recognizing highly specific perceptual, structural, or semantic features of inputs. In computer vision, techniques exist for identifying neurons that respond to individual concept categories like colors, textures, and object classes. But these techniques are limited in scope, labeling only a small subset of neurons and behaviors in any network. Is a richer characterization of neuron-level computation possible? We introduce a procedure (called MILAN, for mutual information-guided linguistic annotation of neurons) that automatically labels neurons with open-ended, compositional, natural language descriptions. Given a neuron, MILAN generates a description by searching for a natural language string that maximizes pointwise mutual information with the image regions in which the neuron is active. MILAN produces fine-grained descriptions that capture categorical, relational, and logical structure in learned features. These descriptions obtain high agreement with human-generated feature descriptions across a diverse set of model architectures and tasks, and can aid in understanding and controlling learned models. We highlight three applications of natural language neuron descriptions. First, we use MILAN for analysis, characterizing the distribution and importance of neurons selective for attribute, category, and relational information in vision models. Second, we use MILAN for auditing, surfacing neurons sensitive to human faces in datasets designed to obscure them. Finally, we use MILAN for editing, improving robustness in an image classifier by deleting neurons sensitive to text features spuriously correlated with class labels.",
        "conference": "ICLR",
        "中文标题": "深度特征的自然语言描述",
        "摘要翻译": "深度网络中的一些神经元专门用于识别输入的高度特定的感知、结构或语义特征。在计算机视觉领域，存在识别对个别概念类别（如颜色、纹理和对象类别）响应的神经元的技术。但这些技术在范围上有限，仅标记任何网络中的一小部分神经元和行为。是否可能对神经元级计算进行更丰富的表征？我们引入了一个程序（称为MILAN，即神经元的互信息引导语言注释），该程序自动用开放式、组合式的自然语言描述标记神经元。给定一个神经元，MILAN通过搜索与神经元活跃的图像区域具有点互信息最大化的自然语言字符串来生成描述。MILAN产生的细粒度描述捕捉了学习特征中的类别、关系和逻辑结构。这些描述在多样化的模型架构和任务中与人类生成的特征描述高度一致，并有助于理解和控制学习模型。我们强调了自然语言神经元描述的三种应用。首先，我们使用MILAN进行分析，表征视觉模型中选择性对属性、类别和关系信息敏感的神经元的分布和重要性。其次，我们使用MILAN进行审计，发现在设计用于隐藏人类面孔的数据集中对之敏感的神经元。最后，我们使用MILAN进行编辑，通过删除与类别标签虚假相关的文本特征敏感的神经元，提高图像分类器的鲁棒性。",
        "领域": "计算机视觉与自然语言处理结合、深度学习模型解释性、神经网络可视化",
        "问题": "如何自动生成对深度神经网络中神经元功能的自然语言描述，以增强模型的可解释性和控制能力。",
        "动机": "现有的神经元标记技术范围有限，无法全面描述神经元的行为和功能，限制了深度神经网络的理解和应用。",
        "方法": "引入MILAN程序，通过最大化神经元活跃区域与自然语言描述之间的点互信息，自动生成开放式、组合式的神经元描述。",
        "关键词": [
            "神经元描述",
            "模型解释性",
            "自然语言处理",
            "计算机视觉",
            "深度学习"
        ],
        "涉及的技术概念": {
            "点互信息": "用于衡量神经元活跃区域与自然语言描述之间关联强度的统计量，是MILAN生成描述的基础。",
            "细粒度描述": "MILAN生成的描述能够捕捉学习特征中的详细结构，如类别、关系和逻辑结构。",
            "模型审计": "利用MILAN发现和标记对特定敏感信息（如人类面孔）响应的神经元，用于模型行为的审查和改进。"
        },
        "success": true
    },
    {
        "order": 645,
        "title": "Natural Posterior Network: Deep Bayesian Predictive Uncertainty for Exponential Family Distributions",
        "html": "https://iclr.cc//virtual/2022/poster/6370",
        "abstract": "Uncertainty awareness is crucial to develop reliable machine learning models. In this work, we propose the Natural Posterior Network (NatPN) for fast and high-quality uncertainty estimation for any task where the target distribution belongs to the exponential family. Thus, NatPN finds application for both classification and general regression settings. Unlike many previous approaches, NatPN does not require out-of-distribution (OOD) data at training time. Instead, it leverages Normalizing Flows to fit a single density on a learned low-dimensional and task-dependent latent space. For any input sample, NatPN uses the predicted likelihood to perform a Bayesian update over the target distribution. Theoretically, NatPN assigns high uncertainty far away from training data. Empirically, our extensive experiments on calibration and OOD detection show that NatPN delivers highly competitive performance for classification, regression and count prediction tasks.",
        "conference": "ICLR",
        "中文标题": "自然后验网络：针对指数族分布的深度贝叶斯预测不确定性",
        "摘要翻译": "不确定性意识对于开发可靠的机器学习模型至关重要。在这项工作中，我们提出了自然后验网络（NatPN），用于对目标分布属于指数族的任何任务进行快速且高质量的不确定性估计。因此，NatPN可应用于分类和一般回归设置。与许多先前的方法不同，NatPN在训练时不需要分布外（OOD）数据。相反，它利用归一化流在学习的低维和任务相关潜在空间上拟合单一密度。对于任何输入样本，NatPN使用预测的似然对目标分布进行贝叶斯更新。理论上，NatPN在远离训练数据的地方分配高不确定性。实证上，我们在校准和OOD检测上的大量实验表明，NatPN在分类、回归和计数预测任务中提供了极具竞争力的性能。",
        "领域": "不确定性估计、贝叶斯深度学习、归一化流",
        "问题": "如何在不需要分布外数据的情况下，为属于指数族分布的任务提供快速且高质量的不确定性估计。",
        "动机": "开发一种能够在不需要分布外数据的情况下，有效估计机器学习模型预测不确定性的方法，以提高模型的可靠性。",
        "方法": "利用归一化流在学习的低维和任务相关潜在空间上拟合单一密度，并通过预测的似然对目标分布进行贝叶斯更新。",
        "关键词": [
            "自然后验网络",
            "不确定性估计",
            "贝叶斯深度学习",
            "归一化流",
            "指数族分布"
        ],
        "涉及的技术概念": {
            "自然后验网络（NatPN）": "一种用于快速且高质量不确定性估计的深度贝叶斯方法，适用于目标分布属于指数族的任务。",
            "归一化流": "用于在学习的低维和任务相关潜在空间上拟合单一密度的技术，支持高效的不确定性估计。",
            "贝叶斯更新": "利用预测的似然对目标分布进行更新的过程，使得模型能够根据新数据调整其预测不确定性。"
        },
        "success": true
    },
    {
        "order": 646,
        "title": "Near-optimal Offline Reinforcement Learning with Linear Representation: Leveraging Variance Information with Pessimism",
        "html": "https://iclr.cc//virtual/2022/poster/6643",
        "abstract": "Offline reinforcement learning, which seeks to utilize offline/historical data to optimize sequential decision-making strategies, has gained surging prominence in recent studies. Due to the advantage that appropriate function approximators can help mitigate the sample complexity burden in modern reinforcement learning problems, existing endeavors usually enforce powerful function representation models (e.g. neural networks) to learn the optimal policies. However, a precise understanding of the statistical limits with function representations, remains elusive, even when such a representation is linear.Towards this goal, we study the statistical limits of offline reinforcement learning with linear model representations. To derive the tight offline learning bound, we design the variance-aware pessimistic value iteration (VAPVI), which adopts the conditional variance information of the value function for time-inhomogeneous episodic linear Markov decision processes (MDPs). VAPVI leverages estimated variances of the value functions to reweight the Bellman residuals in the least-square pessimistic value iteration and provides improved offline learning bounds over the best-known existing results (whereas the Bellman residuals are equally weighted by design). More importantly, our learning bounds are expressed in terms of system quantities, which provide natural instance-dependent characterizations that previous results are short of. We hope our results draw a clearer picture of what offline learning should look like when linear representations are provided.",
        "conference": "ICLR",
        "中文标题": "利用线性表示实现近乎最优的离线强化学习：通过悲观主义利用方差信息",
        "摘要翻译": "离线强化学习旨在利用离线/历史数据优化序列决策策略，近年来在研究中获得了越来越多的关注。由于适当的函数逼近器可以帮助减轻现代强化学习问题中的样本复杂性负担，现有的努力通常强制使用强大的函数表示模型（如神经网络）来学习最优策略。然而，即使在这样的表示是线性的情况下，对函数表示的统计限制的精确理解仍然难以捉摸。为了实现这一目标，我们研究了具有线性模型表示的离线强化学习的统计限制。为了推导出紧密的离线学习界限，我们设计了方差感知悲观值迭代（VAPVI），该方法采用了时间非齐次片段线性马尔可夫决策过程（MDPs）值函数的条件方差信息。VAPVI利用值函数的估计方差来重新加权最小二乘悲观值迭代中的贝尔曼残差，并提供了比现有最知名结果改进的离线学习界限（而贝尔曼残差在设计上是等权重的）。更重要的是，我们的学习界限是用系统量表示的，这提供了先前结果所缺乏的自然实例依赖性特征。我们希望我们的结果能够更清晰地描绘出当提供线性表示时离线学习应该是什么样子。",
        "领域": "离线强化学习、马尔可夫决策过程、函数逼近",
        "问题": "理解并优化离线强化学习在具有线性模型表示时的统计效率",
        "动机": "探索在提供线性表示的情况下，离线强化学习的统计限制，以更高效地利用历史数据优化决策策略",
        "方法": "设计方差感知悲观值迭代（VAPVI）方法，利用值函数的条件方差信息重新加权贝尔曼残差，以改进离线学习界限",
        "关键词": [
            "离线强化学习",
            "线性表示",
            "方差感知",
            "悲观值迭代",
            "马尔可夫决策过程"
        ],
        "涉及的技术概念": {
            "方差感知悲观值迭代（VAPVI）": "一种利用值函数的估计方差来重新加权贝尔曼残差的方法，以提高离线强化学习的效率",
            "线性马尔可夫决策过程（MDPs）": "在时间非齐次片段中，使用线性模型表示的状态转移和奖励函数，用于描述序列决策问题",
            "贝尔曼残差": "在强化学习中，用于衡量当前值函数估计与贝尔曼方程预测之间差异的指标，VAPVI通过重新加权这些残差来优化学习过程"
        },
        "success": true
    },
    {
        "order": 647,
        "title": "Near-Optimal Reward-Free Exploration for Linear Mixture MDPs with Plug-in Solver",
        "html": "https://iclr.cc//virtual/2022/poster/6961",
        "abstract": "Although model-based reinforcement learning (RL) approaches are considered more sample efficient, existing algorithms are usually relying on sophisticated planning algorithm to couple tightly with the model-learning procedure. Hence the learned models may lack the ability of being re-used with more specialized planners. In this paper we address this issue and provide approaches to learn an RL model efficiently without the guidance of a reward signal. In particular, we take a plug-in solver approach, where we focus on learning a model in the exploration phase and demand that \\emph{any planning algorithm} on the learned model can give a near-optimal policy. Specicially, we focus on the linear mixture MDP setting, where the probability transition matrix is a (unknown) convex combination of a set of existing models. We show that, by establishing a novel exploration algorithm, the plug-in approach learns a model by taking $\\tilde{O}(d^2H^3/\\epsilon^2)$ interactions with the environment and \\emph{any} $\\epsilon$-optimal planner on the model gives an $O(\\epsilon)$-optimal policy on the original model. This sample complexity matches lower bounds for non-plug-in approaches and is \\emph{statistically optimal}. We achieve this result by leveraging a careful maximum total-variance bound using Bernstein inequality and properties specified to linear mixture MDP.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "线性混合MDPs近乎最优的无奖励探索与插件式求解器",
        "摘要翻译": "尽管基于模型的强化学习（RL）方法被认为更具有样本效率，但现有的算法通常依赖于复杂的规划算法，与模型学习过程紧密结合。因此，学习到的模型可能缺乏与更专业的规划器重复使用的能力。在本文中，我们解决了这个问题，并提供了有效学习RL模型的方法，而无需奖励信号的指导。特别地，我们采用插件式求解器方法，侧重于在探索阶段学习模型，并要求在学习到的模型上使用*任何规划算法*都可以给出近乎最优的策略。具体而言，我们专注于线性混合MDP设置，其中概率转移矩阵是现有模型集合的（未知）凸组合。我们证明，通过建立一种新颖的探索算法，插件式方法通过与环境进行$\\\\tilde{O}(d^2H^3/\\\\epsilon^2)$次交互来学习模型，并且模型上的*任何*$\\\\epsilon$-最优规划器都会在原始模型上给出$O(\\\\epsilon)$-最优策略。此样本复杂度与非插件方法的下限相匹配，并且在*统计上是最优的*。我们通过利用使用Bernstein不等式和线性混合MDP指定的属性的仔细的最大总方差界来实现此结果。",
        "领域": "强化学习、模型学习、无奖励探索",
        "问题": "如何高效地学习强化学习模型，使其能够与任何规划算法结合，并获得近乎最优的策略，同时避免对奖励信号的依赖。",
        "动机": "现有基于模型的强化学习算法通常与特定的规划算法紧密耦合，导致学习到的模型缺乏通用性，无法与更专业的规划器重复使用。 因此，需要研究一种无奖励的探索方式，学习到的模型能够兼容任何规划算法，提升模型的可复用性。",
        "方法": "采用插件式求解器方法，在探索阶段专注于学习模型，并证明通过新颖的探索算法，学习到的模型可以与任何规划算法结合，从而实现近乎最优的策略。并利用Bernstein不等式和线性混合MDP的特性，建立最大总方差界。",
        "关键词": [
            "无奖励探索",
            "强化学习",
            "线性混合MDP",
            "插件式求解器",
            "模型学习"
        ],
        "涉及的技术概念": {
            "线性混合MDP": "一种马尔可夫决策过程的设置，其中状态转移概率是多个已知模型的凸组合。论文关注在此类环境中进行无奖励探索。",
            "插件式求解器": "一种将模型学习和规划算法解耦的方法，允许使用任何规划算法在学习到的模型上进行策略优化。论文采用此方法来实现模型的通用性。"
        }
    },
    {
        "order": 648,
        "title": "Network Augmentation for Tiny Deep Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6878",
        "abstract": "We introduce Network Augmentation (NetAug), a new training method for improving the performance of tiny neural networks. Existing regularization techniques (e.g., data augmentation, dropout) have shown much success on large neural networks by adding noise to overcome over-fitting. However, we found these techniques hurt the performance of tiny neural networks. We argue that training tiny models are different from large models: rather than augmenting the data, we should augment the model, since tiny models tend to suffer from under-fitting rather than over-fitting due to limited capacity. To alleviate this issue, NetAug augments the network (reverse dropout) instead of inserting noise into the dataset or the network. It puts the tiny model into larger models and encourages it to work as a sub-model of larger models to get extra supervision, in addition to functioning as an independent model. At test time, only the tiny model is used for inference, incurring zero inference overhead. We demonstrate the effectiveness of NetAug on image classification and object detection. NetAug consistently improves the performance of tiny models, achieving up to 2.2% accuracy improvement on ImageNet. On object detection, achieving the same level of performance, NetAug requires 41% fewer MACs on Pascal VOC and 38% fewer MACs on COCO than the baseline.",
        "conference": "ICLR",
        "中文标题": "网络增强用于微型深度学习",
        "摘要翻译": "我们介绍了网络增强（NetAug），一种新的训练方法，用于提高微型神经网络的性能。现有的正则化技术（如数据增强、dropout）通过添加噪声来克服过拟合，在大型神经网络上取得了很大成功。然而，我们发现这些技术会损害微型神经网络的性能。我们认为训练微型模型与大型模型不同：与其增强数据，不如增强模型，因为微型模型由于容量有限，往往遭受的是欠拟合而非过拟合。为了缓解这个问题，NetAug增强网络（反向dropout），而不是在数据集或网络中插入噪声。它将微型模型置于更大的模型中，并鼓励其作为更大模型的子模型工作，以获得额外的监督，同时还能作为独立模型运行。在测试时，仅使用微型模型进行推理，不产生任何推理开销。我们在图像分类和目标检测上证明了NetAug的有效性。NetAug持续提高了微型模型的性能，在ImageNet上实现了高达2.2%的准确率提升。在目标检测方面，达到相同性能水平时，NetAug在Pascal VOC上需要的MACs比基线少41%，在COCO上少38%。",
        "领域": "微型神经网络优化、图像分类、目标检测",
        "问题": "如何提高微型神经网络的性能，解决其因容量有限而导致的欠拟合问题",
        "动机": "现有的正则化技术对大型神经网络有效，但对微型神经网络性能有损害，需要一种新的方法来提升微型模型的性能",
        "方法": "提出网络增强（NetAug）方法，通过将微型模型置于更大的模型中并作为其子模型工作，以获得额外的监督，同时保持独立模型的功能",
        "关键词": [
            "网络增强",
            "微型神经网络",
            "反向dropout",
            "图像分类",
            "目标检测"
        ],
        "涉及的技术概念": {
            "网络增强（NetAug）": "一种新的训练方法，通过增强网络而非数据来提升微型神经网络的性能",
            "反向dropout": "NetAug中采用的技术，不同于传统的dropout，它通过增强网络结构而非插入噪声来提升模型性能",
            "微型神经网络": "指那些参数少、计算资源需求低的神经网络模型，NetAug旨在提升这类模型的性能"
        },
        "success": true
    },
    {
        "order": 649,
        "title": "NETWORK INSENSITIVITY TO PARAMETER NOISE VIA PARAMETER ATTACK DURING TRAINING",
        "html": "https://iclr.cc//virtual/2022/poster/7062",
        "abstract": "Neuromorphic neural network processors, in the form of compute-in-memory crossbar arrays of memristors, or in the form of subthreshold analog and mixed-signal ASICs, promise enormous advantages in compute density and energy efficiency for NN-based ML tasks. However, these technologies are prone to computational non-idealities, due to process variation and intrinsic device physics. This degrades the task performance of networks deployed to the processor, by introducing parameter noise into the deployed model. While it is possible to calibrate each device, or train networks individually for each processor, these approaches are expensive and impractical for commercial deployment. Alternative methods are therefore needed to train networks that are inherently robust against parameter variation, as a consequence of network architecture and parameters. We present a new network training algorithm that attacks network parameters during training, and promotes robust performance during inference in the face of random parameter variation. Our approach introduces a loss regularization term that penalizes the susceptibility of a network to weight perturbation. We compare against previous approaches for producing parameter insensitivity such as dropout, weight smoothing and introducing parameter noise during training. We show that our approach produces models that are more robust to random mismatch-induced parameter variation as well as to targeted parameter variation. Our approach finds minima in flatter locations in the weight-loss landscape compared with other approaches, highlighting that the networks found by our technique are less sensitive to parameter perturbation. Our work provides an approach to deploy neural network architectures to inference devices that suffer from computational non-idealities, with minimal loss of performance. This method will enable deployment at scale to novel energy-efficient computational substrates, promoting cheaper and more prevalent edge inference.",
        "conference": "ICLR",
        "中文标题": "通过训练期间的参数攻击实现网络对参数噪声的不敏感性",
        "摘要翻译": "神经形态神经网络处理器，无论是以忆阻器的内存计算交叉阵列形式，还是以亚阈值模拟和混合信号ASIC形式，都为基于神经网络的机器学习任务在计算密度和能源效率方面提供了巨大优势。然而，由于工艺变化和固有器件物理特性，这些技术容易产生计算非理想性。这通过向部署的模型中引入参数噪声，降低了部署到处理器上的网络的任务性能。虽然可以校准每个设备，或为每个处理器单独训练网络，但这些方法成本高昂，对于商业部署不切实际。因此，需要替代方法来训练对参数变化具有固有鲁棒性的网络，这是网络架构和参数的结果。我们提出了一种新的网络训练算法，该算法在训练期间攻击网络参数，并在面对随机参数变化时促进推理过程中的鲁棒性能。我们的方法引入了一个损失正则化项，惩罚网络对权重扰动的敏感性。我们与之前产生参数不敏感性的方法如dropout、权重平滑和在训练期间引入参数噪声进行了比较。我们表明，我们的方法产生的模型对随机失配引起的参数变化以及目标参数变化更加鲁棒。与其他方法相比，我们的方法在权重损失景观中找到了更平坦位置的极小值，突出了通过我们的技术找到的网络对参数扰动不那么敏感。我们的工作提供了一种方法，将神经网络架构部署到遭受计算非理想性的推理设备上，性能损失最小。这种方法将使得能够大规模部署到新型节能计算基底上，促进更便宜和更普遍的边缘推理。",
        "领域": "神经网络鲁棒性训练, 边缘计算, 神经形态计算",
        "问题": "解决神经形态神经网络处理器由于工艺和器件物理特性导致的参数噪声问题，提高网络在参数变化下的鲁棒性。",
        "动机": "为了在商业部署中实现高效、低成本的神经网络推理，需要开发对参数变化具有固有鲁棒性的训练方法。",
        "方法": "提出一种新的网络训练算法，通过在训练期间攻击网络参数并引入损失正则化项，惩罚网络对权重扰动的敏感性，从而提升网络对参数变化的鲁棒性。",
        "关键词": [
            "参数噪声",
            "鲁棒性训练",
            "神经形态计算",
            "边缘推理",
            "损失正则化"
        ],
        "涉及的技术概念": {
            "参数攻击": "在训练期间故意扰动网络参数，以增强网络对参数变化的鲁棒性。",
            "损失正则化": "通过引入额外的损失项，惩罚网络对权重扰动的敏感性，从而提升模型的鲁棒性。",
            "权重损失景观": "描述了模型权重与损失函数之间的关系，平坦的极小值意味着模型对参数扰动不那么敏感。"
        },
        "success": true
    },
    {
        "order": 650,
        "title": "NeuPL: Neural Population Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6950",
        "abstract": "Learning in strategy games (e.g. StarCraft, poker) requires the discovery of diverse policies. This is often achieved by iteratively training new policies against existing ones, growing a policy population that is robust to exploit. This iterative approach suffers from two issues in real-world games: a) under finite budget, approximate best-response operators at each iteration needs truncating, resulting in under-trained good-responses populating the population; b) repeated learning of basic skills at each iteration is wasteful and becomes intractable in the presence of increasingly strong opponents. In this work, we propose Neural Population Learning (NeuPL) as a solution to both issues. NeuPL offers convergence guarantees to a population of best-responses under mild assumptions. By representing a population of policies within a single conditional model, NeuPL enables transfer learning across policies. Empirically, we show the generality, improved performance and efficiency of NeuPL across several test domains. Most interestingly, we show that novel strategies become more accessible, not less, as the neural population expands.",
        "conference": "ICLR",
        "中文标题": "NeuPL：神经群体学习",
        "摘要翻译": "在策略游戏（如《星际争霸》、扑克）中学习需要发现多样化的策略。这通常通过迭代训练新策略对抗现有策略来实现，从而培养出一个能够抵抗利用的策略群体。这种迭代方法在现实世界的游戏中存在两个问题：a) 在有限预算下，每次迭代的近似最佳响应操作需要截断，导致群体中存在训练不足的良好响应；b) 每次迭代重复学习基本技能是浪费的，并且在面对越来越强的对手时变得难以处理。在这项工作中，我们提出了神经群体学习（NeuPL）作为这两个问题的解决方案。NeuPL在温和假设下提供了对最佳响应群体的收敛保证。通过在一个条件模型中表示一组策略，NeuPL实现了跨策略的迁移学习。实证上，我们在多个测试领域展示了NeuPL的通用性、改进的性能和效率。最有趣的是，我们发现随着神经群体的扩展，新颖策略变得更加容易获得，而不是更难。",
        "领域": "强化学习、策略游戏AI、迁移学习",
        "问题": "解决策略游戏中迭代训练策略群体时遇到的训练不足和技能重复学习问题。",
        "动机": "提高策略游戏中策略群体的训练效率和效果，减少资源浪费，并增强对抗强对手的能力。",
        "方法": "提出神经群体学习（NeuPL），通过在单一条件模型中表示策略群体，实现跨策略的迁移学习，并提供收敛保证。",
        "关键词": [
            "神经群体学习",
            "策略游戏",
            "迁移学习",
            "强化学习",
            "策略多样性"
        ],
        "涉及的技术概念": {
            "神经群体学习（NeuPL）": "一种在单一条件模型中表示策略群体的方法，旨在解决策略游戏中的训练不足和技能重复学习问题。",
            "迁移学习": "NeuPL通过在一个模型中表示多个策略，实现了跨策略的知识共享和转移，提高了学习效率。",
            "收敛保证": "在温和假设下，NeuPL能够保证策略群体向最佳响应收敛，确保训练的有效性和稳定性。"
        },
        "success": true
    },
    {
        "order": 651,
        "title": "Neural Collapse Under MSE Loss: Proximity to and Dynamics on the Central Path",
        "html": "https://iclr.cc//virtual/2022/poster/6352",
        "abstract": "The recently discovered Neural Collapse (NC) phenomenon occurs pervasively in today's deep net training paradigm of driving cross-entropy (CE) loss towards zero. During NC, last-layer features collapse to their class-means, both classifiers and class-means collapse to the same Simplex Equiangular Tight Frame, and classifier behavior collapses to the nearest-class-mean decision rule. Recent works demonstrated that deep nets trained with mean squared error (MSE) loss perform comparably to those trained with CE. As a preliminary, we empirically establish that NC emerges in such MSE-trained deep nets as well through experiments on three canonical networks and five benchmark datasets. We provide, in a Google Colab notebook, PyTorch code for reproducing MSE-NC and CE-NC: https://colab.research.google.com/github/neuralcollapse/neuralcollapse/blob/main/neuralcollapse.ipynb. The analytically-tractable MSE loss offers more mathematical opportunities than the hard-to-analyze CE loss, inspiring us to leverage MSE loss towards the theoretical investigation of NC. We develop three main contributions: (I) We show a new decomposition of the MSE loss into (A) terms directly interpretable through the lens of NC and which assume the last-layer classifier is exactly the least-squares classifier; and (B) a term capturing the deviation from this least-squares classifier. (II) We exhibit experiments on canonical datasets and networks demonstrating that term-(B) is negligible during training. This motivates us to introduce a new theoretical construct: the central path, where the linear classifier stays MSE-optimal for feature activations throughout the dynamics. (III) By studying renormalized gradient flow along the central path, we derive exact dynamics that predict NC.",
        "conference": "ICLR",
        "中文标题": "MSE损失下的神经崩溃：中心路径的邻近性与动力学",
        "摘要翻译": "最近发现的神经崩溃（NC）现象在当今深度网络训练范式中普遍存在，该范式旨在将交叉熵（CE）损失驱动至零。在NC过程中，最后一层特征崩溃至其类均值，分类器和类均值均崩溃至相同的单纯形等角紧框架，分类器行为崩溃至最近类均值决策规则。近期工作表明，使用均方误差（MSE）损失训练的深度网络性能与使用CE训练的相当。作为初步工作，我们通过三个典型网络和五个基准数据集的实验，实证地建立了MSE训练的深度网络中也出现NC的现象。我们在Google Colab笔记本中提供了用于重现MSE-NC和CE-NC的PyTorch代码：https://colab.research.google.com/github/neuralcollapse/neuralcollapse/blob/main/neuralcollapse.ipynb。分析上易于处理的MSE损失比难以分析的CE损失提供了更多的数学机会，激励我们利用MSE损失对NC进行理论研究。我们提出了三个主要贡献：（I）我们展示了MSE损失的新分解，分为（A）通过NC视角直接可解释的项，这些项假设最后一层分类器恰好是最小二乘分类器；和（B）捕捉与这个最小二乘分类器偏差的项。（II）我们在标准数据集和网络上展示了实验，证明项（B）在训练过程中可以忽略不计。这激励我们引入一个新的理论构建：中心路径，其中线性分类器在整个动力学过程中对特征激活保持MSE最优。（III）通过研究沿中心路径的重新归一化梯度流，我们推导出预测NC的精确动力学。",
        "领域": "深度学习理论、神经网络优化、分类算法",
        "问题": "理解并理论分析在MSE损失下训练的深度网络中神经崩溃现象的出现及其动力学行为。",
        "动机": "探索MSE损失下神经崩溃现象的普遍性及其背后的数学机制，以提供比CE损失更易于分析的理论框架。",
        "方法": "通过实验验证MSE损失下NC现象的存在，提出MSE损失的新分解方法，引入中心路径概念，并利用重新归一化梯度流推导NC的精确动力学。",
        "关键词": [
            "神经崩溃",
            "MSE损失",
            "中心路径",
            "梯度流",
            "最小二乘分类器"
        ],
        "涉及的技术概念": {
            "神经崩溃": "指在深度网络训练过程中，最后一层特征、分类器和类均值趋向于特定几何结构（如单纯形等角紧框架）的现象。",
            "中心路径": "理论构建，指在训练过程中线性分类器对特征激活保持MSE最优的路径。",
            "重新归一化梯度流": "用于研究沿中心路径的动力学行为，以预测神经崩溃现象的技术。"
        },
        "success": true
    },
    {
        "order": 652,
        "title": "Neural Contextual Bandits with Deep Representation and Shallow Exploration",
        "html": "https://iclr.cc//virtual/2022/poster/6858",
        "abstract": "We study neural contextual bandits, a general class of contextual bandits, where each context-action pair is associated with a raw feature vector, but the specific reward generating function is unknown. We propose a novel learning algorithm that transforms the raw feature vector using the last hidden layer of a deep ReLU neural network (deep representation learning), and uses an upper confidence bound (UCB) approach to explore in the last linear layer (shallow exploration). We prove that under standard assumptions, our proposed algorithm achieves $\\tilde{O}(\\sqrt{T})$ finite-time regret, where $T$ is the learning time horizon. Compared with existing neural contextual bandit algorithms, our approach is computationally much more efficient since it only needs to explore in the last layer of the deep neural network.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "基于深度表示和浅层探索的神经上下文老虎机",
        "摘要翻译": "我们研究神经上下文老虎机，这是一类通用的上下文老虎机，其中每个上下文-动作对都与一个原始特征向量相关联，但具体的奖励生成函数是未知的。我们提出了一种新的学习算法，该算法使用深度ReLU神经网络的最后一个隐藏层来转换原始特征向量（深度表示学习），并使用上限置信度（UCB）方法在最后一个线性层中进行探索（浅层探索）。我们证明，在标准假设下，我们提出的算法实现了$\\tilde{O}(\\sqrt{T})$的有限时间遗憾，其中$T$是学习时间范围。与现有的神经上下文老虎机算法相比，我们的方法在计算上效率更高，因为它只需要在深度神经网络的最后一层进行探索。",
        "领域": "强化学习, 推荐系统, 表示学习",
        "问题": "如何在神经上下文老虎机中实现有效的探索与利用，同时保持计算效率。",
        "动机": "现有的神经上下文老虎机算法通常计算成本高昂，限制了它们在实际应用中的可行性。这项研究旨在通过结合深度表示学习和浅层探索来提高神经上下文老虎机算法的计算效率。",
        "方法": "提出一种新颖的算法，该算法使用深度ReLU神经网络的最后一个隐藏层进行深度表示学习，然后使用上限置信度（UCB）在最后一层进行浅层探索。并通过理论分析证明了算法的遗憾界。",
        "关键词": [
            "神经上下文老虎机",
            "深度表示学习",
            "上限置信度",
            "浅层探索",
            "强化学习"
        ],
        "涉及的技术概念": {
            "深度表示学习": "利用深度神经网络学习原始特征向量的有效表示，以便更好地进行决策。",
            "上限置信度(UCB)": "一种探索策略，通过维护对每个动作奖励的置信区间上界来平衡探索和利用。"
        }
    },
    {
        "order": 653,
        "title": "Neural Deep Equilibrium Solvers",
        "html": "https://iclr.cc//virtual/2022/poster/5919",
        "abstract": "A deep equilibrium (DEQ) model abandons traditional depth by solving for the fixed point of a single nonlinear layer $f_\\theta$. This structure enables decoupling the internal structure of the layer (which controls representational capacity) from how the fixed point is actually computed (which impacts inference-time efficiency), which is usually via classic techniques such as Broyden's method or Anderson acceleration.  In this paper, we show that one can exploit such decoupling and substantially enhance this fixed point computation using a custom neural solver. Specifically, our solver uses a parameterized network to both guess an initial value of the optimization and perform iterative updates, in a method that generalizes a learnable form of Anderson acceleration and can be trained end-to-end in an unsupervised manner. Such a solution is particularly well suited to the implicit model setting, because inference in these models requires repeatedly solving for a fixed point of the same nonlinear layer for different inputs, a task at which our network excels. Our experiments show that these neural equilibrium solvers are fast to train (only taking an extra 0.9-1.1% over the original DEQ's training time), require few additional parameters (1-3% of the original model size), yet lead to a $2\\times$ speedup in DEQ network inference without any degradation in accuracy across numerous domains and tasks.",
        "conference": "ICLR",
        "中文标题": "神经深度均衡求解器",
        "摘要翻译": "深度均衡（DEQ）模型通过求解单个非线性层$f_\theta$的不动点，摒弃了传统的深度。这种结构使得层的内部结构（控制表示能力）与不动点的实际计算方式（影响推理时间效率）解耦，后者通常通过经典技术如Broyden方法或Anderson加速来实现。在本文中，我们展示了可以利用这种解耦，并通过定制的神经求解器显著增强这种不动点计算。具体来说，我们的求解器使用参数化网络来猜测优化的初始值并执行迭代更新，这种方法推广了可学习形式的Anderson加速，并且可以以无监督的方式进行端到端训练。这种解决方案特别适合隐式模型设置，因为这些模型的推理需要为不同输入重复求解同一非线性层的不动点，这是我们的网络擅长的任务。我们的实验表明，这些神经均衡求解器训练速度快（仅比原始DEQ的训练时间多0.9-1.1%），需要很少的额外参数（原始模型大小的1-3%），但在多个领域和任务中，DEQ网络的推理速度提高了2倍，且准确性没有任何下降。",
        "领域": "深度学习优化、隐式模型、非线性系统求解",
        "问题": "如何提高深度均衡模型中不动点计算的效率和速度",
        "动机": "深度均衡模型在推理时需要重复求解同一非线性层的不动点，传统方法效率不高，研究动机是通过神经求解器提高这一过程的效率。",
        "方法": "使用参数化网络进行初始值猜测和迭代更新，推广可学习形式的Anderson加速，实现端到端无监督训练。",
        "关键词": [
            "深度均衡模型",
            "神经求解器",
            "不动点计算",
            "Anderson加速",
            "隐式模型"
        ],
        "涉及的技术概念": {
            "深度均衡模型": "通过求解单个非线性层的不动点来摒弃传统深度，实现表示能力与计算效率的解耦。",
            "神经求解器": "使用参数化网络进行优化初始值猜测和迭代更新，提高不动点计算的效率。",
            "Anderson加速": "一种经典的不动点迭代加速技术，本文中推广为可学习形式，用于神经求解器的训练。"
        },
        "success": true
    },
    {
        "order": 654,
        "title": "Neural graphical modelling in continuous-time: consistency guarantees and algorithms",
        "html": "https://iclr.cc//virtual/2022/poster/6517",
        "abstract": "The discovery of structure from time series data is a key problem in fields of study working with complex systems. Most identifiability results and learning algorithms assume the underlying dynamics to be discrete in time. Comparatively few, in contrast, explicitly define dependencies in infinitesimal intervals of time, independently of the scale of observation and of the regularity of sampling. In this paper, we consider score-based structure learning for the study of dynamical systems. We prove that for vector fields parameterized in a large class of neural networks, least squares optimization with adaptive regularization schemes consistently recovers directed graphs of local independencies in systems of stochastic differential equations. Using this insight, we propose a score-based learning algorithm based on penalized Neural Ordinary Differential Equations (modelling the mean process) that we show to be applicable to the general setting of irregularly-sampled multivariate time series and to outperform the state of the art across a range of dynamical systems.",
        "conference": "ICLR",
        "中文标题": "连续时间神经图建模：一致性保证与算法",
        "摘要翻译": "从时间序列数据中发现结构是研究复杂系统的关键问题。大多数可识别性结果和学习算法假设基础动态是离散时间的。相比之下，明确在无限小时间间隔内定义依赖关系的研究相对较少，这些定义独立于观察尺度和采样的规律性。在本文中，我们考虑基于分数的结构学习用于研究动态系统。我们证明，对于一大类神经网络参数化的向量场，带有自适应正则化方案的最小二乘优化能够一致地恢复随机微分方程系统中局部独立性的有向图。利用这一见解，我们提出了一种基于惩罚神经普通微分方程（建模平均过程）的基于分数的学习算法，我们证明该算法适用于不规则采样多元时间序列的一般设置，并且在一系列动态系统中优于现有技术。",
        "领域": "时间序列分析、动态系统建模、神经网络应用",
        "问题": "如何在连续时间框架下从时间序列数据中发现和建模动态系统的结构",
        "动机": "解决现有大多数方法局限于离散时间动态的不足，探索在无限小时间间隔内定义依赖关系的方法，以适应不同观察尺度和采样规律性的需求",
        "方法": "采用基于分数的结构学习方法，结合最小二乘优化和自适应正则化方案，以及惩罚神经普通微分方程来建模动态系统",
        "关键词": [
            "连续时间建模",
            "神经图模型",
            "动态系统",
            "时间序列分析",
            "神经网络"
        ],
        "涉及的技术概念": {
            "神经图模型": "用于在连续时间框架下建模动态系统的结构，能够捕捉时间序列数据中的复杂依赖关系",
            "自适应正则化": "在最小二乘优化中应用，以提高模型在恢复动态系统结构时的一致性和准确性",
            "惩罚神经普通微分方程": "用于建模动态系统的平均过程，特别适用于处理不规则采样的多元时间序列数据"
        },
        "success": true
    },
    {
        "order": 655,
        "title": "Neural Link Prediction with Walk Pooling",
        "html": "https://iclr.cc//virtual/2022/poster/7079",
        "abstract": "Graph neural networks achieve high accuracy in link prediction by jointly leveraging graph topology and node attributes. Topology, however, is represented indirectly; state-of-the-art methods based on subgraph classification label nodes with distance to the target link, so that, although topological information is present, it is tempered by pooling. This makes it challenging to leverage features like loops and motifs associated with network formation mechanisms. We propose a link prediction algorithm based on a new pooling scheme called WalkPool. WalkPool combines the expressivity of topological heuristics with the feature-learning ability of neural networks. It summarizes a putative link by random walk probabilities of adjacent paths. Instead of extracting transition probabilities from the original graph, it computes the transition matrix of a ``predictive'' latent graph by applying attention to learned features; this may be interpreted as feature-sensitive topology fingerprinting. WalkPool can leverage unsupervised node features or be combined with GNNs and trained end-to-end. It outperforms state-of-the-art methods on all common link prediction benchmarks, both homophilic and heterophilic, with and without node attributes. Applying WalkPool to a set of unsupervised GNNs significantly improves prediction accuracy, suggesting that it may be used as a general-purpose graph pooling scheme.   ",
        "conference": "ICLR",
        "中文标题": "神经链接预测与游走池化",
        "摘要翻译": "图神经网络通过联合利用图拓扑和节点属性，在链接预测中实现了高准确率。然而，拓扑是间接表示的；基于子图分类的最先进方法用与目标链接的距离来标记节点，因此，尽管存在拓扑信息，但它被池化所调和。这使得利用与网络形成机制相关的循环和模体等特征变得具有挑战性。我们提出了一种基于新池化方案WalkPool的链接预测算法。WalkPool将拓扑启发式的表达力与神经网络的特征学习能力结合起来。它通过相邻路径的随机游走概率来总结一个假定的链接。它不是从原始图中提取转移概率，而是通过将注意力应用于学习到的特征来计算一个'预测性'潜在图的转移矩阵；这可以被解释为特征敏感的拓扑指纹。WalkPool可以利用无监督节点特征，也可以与GNNs结合并端到端训练。它在所有常见的链接预测基准测试中，无论是同质性还是异质性，有或没有节点属性，都优于最先进的方法。将WalkPool应用于一组无监督GNNs显著提高了预测准确性，表明它可以作为一种通用的图池化方案。",
        "领域": "图神经网络、链接预测、网络表示学习",
        "问题": "如何更有效地利用图的拓扑结构和节点属性进行链接预测",
        "动机": "现有方法在链接预测中间接表示拓扑结构，限制了利用网络形成机制相关特征的能力",
        "方法": "提出了一种新的池化方案WalkPool，结合拓扑启发式和神经网络的特征学习能力，通过随机游走概率和注意力机制来预测链接",
        "关键词": [
            "图神经网络",
            "链接预测",
            "WalkPool",
            "随机游走",
            "注意力机制"
        ],
        "涉及的技术概念": {
            "WalkPool": "一种新的池化方案，结合拓扑启发式和神经网络的特征学习能力，用于链接预测",
            "随机游走概率": "用于总结假定链接的相邻路径的随机游走概率，作为拓扑指纹",
            "注意力机制": "应用于学习到的特征，计算潜在图的转移矩阵，实现特征敏感的拓扑指纹"
        },
        "success": true
    },
    {
        "order": 656,
        "title": "Neural Markov Controlled SDE: Stochastic Optimization for Continuous-Time Data",
        "html": "https://iclr.cc//virtual/2022/poster/6440",
        "abstract": "We propose a novel probabilistic framework for modeling stochastic dynamics with the rigorous use of stochastic optimal control theory. The proposed model called the neural Markov controlled stochastic differential equation (CSDE) overcomes the fundamental and structural limitations of conventional dynamical models by introducing the following two components: (1) Markov dynamic programming to efficiently train the proposed CSDE and (2) multi-conditional forward-backward losses to provide rich information for accurate inference and to assure theoretical optimality. We demonstrate that our dynamical model efficiently generates a complex time series in the data space without extra networks while showing comparable performance against existing model-based methods on several datasets.",
        "conference": "ICLR",
        "中文标题": "神经马尔可夫控制随机微分方程：连续时间数据的随机优化",
        "摘要翻译": "我们提出了一种新颖的概率框架，用于建模随机动态，严格运用了随机最优控制理论。所提出的模型称为神经马尔可夫控制随机微分方程（CSDE），通过引入以下两个组件克服了传统动态模型的基本和结构限制：（1）马尔可夫动态编程以高效训练提出的CSDE；（2）多条件前向-后向损失，为准确推断提供丰富信息并确保理论最优性。我们证明，我们的动态模型能够在数据空间中高效生成复杂的时间序列，而无需额外的网络，同时在多个数据集上显示出与现有基于模型的方法相当的性能。",
        "领域": "随机过程建模、时间序列分析、最优控制理论",
        "问题": "克服传统动态模型在建模随机动态时的基本和结构限制",
        "动机": "为了更高效和准确地建模和生成复杂的时间序列数据",
        "方法": "引入马尔可夫动态编程和多条件前向-后向损失，构建神经马尔可夫控制随机微分方程",
        "关键词": [
            "随机微分方程",
            "马尔可夫动态编程",
            "多条件损失",
            "时间序列生成",
            "最优控制"
        ],
        "涉及的技术概念": {
            "神经马尔可夫控制随机微分方程": "结合神经网络和马尔可夫决策过程的随机微分方程模型，用于高效建模和生成时间序列数据",
            "马尔可夫动态编程": "用于训练模型的技术，通过动态编程方法优化模型参数",
            "多条件前向-后向损失": "设计用于提供丰富信息和确保理论最优性的损失函数，支持模型的准确推断"
        },
        "success": true
    },
    {
        "order": 657,
        "title": "Neural Methods for Logical Reasoning over Knowledge Graphs",
        "html": "https://iclr.cc//virtual/2022/poster/5976",
        "abstract": "Reasoning is a fundamental problem for computers and deeply studied in Artificial Intelligence. In this paper, we specifically focus on answering multi-hop logical queries on Knowledge Graphs (KGs). This is a complicated task because, in real world scenarios, the graphs tend to be large and incomplete. Most previous works have been unable to create models that accept full First-Order Logical (FOL) queries, which includes negative queries, and have only been able to process a limited set of query structures. Additionally, most methods present logic operators that can only perform the logical operation they are made for. We introduce a set of models that use Neural Networks to create one-point vector embeddings to answer the queries. The versatility of neural networks allows the framework to  handle FOL queries with Conjunction, Disjunction and Negation operators. We demonstrate experimentally the performance of our models through extensive experimentation on well-known benchmarking datasets. Besides having more versatile operators, the models achieve a 10% relative increase over best performing state of the art and more than 30% over the original method based on single-point vector embeddings.",
        "conference": "ICLR",
        "中文标题": "知识图谱上逻辑推理的神经方法",
        "摘要翻译": "推理是计算机科学中的一个基本问题，并在人工智能领域得到了深入研究。本文特别关注于回答知识图谱（KGs）上的多跳逻辑查询。这是一项复杂的任务，因为在现实世界场景中，图谱往往规模庞大且不完整。大多数先前的工作未能创建能够接受完整一阶逻辑（FOL）查询的模型，包括否定查询，并且只能处理有限的查询结构集。此外，大多数方法提出的逻辑运算符只能执行它们被设计用于的逻辑操作。我们引入了一组使用神经网络创建单点向量嵌入以回答查询的模型。神经网络的多样性使得该框架能够处理带有合取、析取和否定运算符的FOL查询。我们通过在知名基准数据集上的广泛实验，展示了我们模型的性能。除了拥有更多样化的运算符外，这些模型相对于性能最佳的最新方法实现了10%的相对提升，相对于基于单点向量嵌入的原始方法提升了30%以上。",
        "领域": "知识图谱推理、神经网络应用、逻辑查询处理",
        "问题": "解决在大型且不完整的知识图谱上进行多跳逻辑查询的复杂问题，特别是处理完整的一阶逻辑查询，包括否定查询。",
        "动机": "现有方法在处理完整的一阶逻辑查询和多跳逻辑查询时存在限制，无法有效处理知识图谱的不完整性和大规模性。",
        "方法": "使用神经网络创建单点向量嵌入来回答查询，支持处理带有合取、析取和否定运算符的一阶逻辑查询。",
        "关键词": [
            "知识图谱推理",
            "神经网络",
            "逻辑查询",
            "一阶逻辑",
            "向量嵌入"
        ],
        "涉及的技术概念": {
            "一阶逻辑（FOL）查询": "论文中用于描述复杂逻辑查询的框架，包括合取、析取和否定运算符。",
            "单点向量嵌入": "论文中采用的技术，通过神经网络将查询转换为向量表示，以便于处理和回答。",
            "神经网络": "论文中用于创建和处理查询向量嵌入的核心技术，支持多样化的逻辑操作。"
        },
        "success": true
    },
    {
        "order": 658,
        "title": "Neural Models for Output-Space Invariance in Combinatorial Problems",
        "html": "https://iclr.cc//virtual/2022/poster/6908",
        "abstract": "Recently many neural models have been proposed to solve combinatorial puzzles by implicitly learning underlying constraints using their solved instances, such as sudoku or graph coloring (GCP). One drawback of the proposed architectures, which are often based on Graph Neural Networks (GNN) (Zhou et al., 2020), is that they cannot generalize across the size of the output space from which variables are assigned a value, for example, set of colors in a GCP, or board-size in sudoku. We call the output space for the variables as ‘value-set’. While many works have demonstrated generalization of GNNs across graph size, there has been no study on how to design a GNN for achieving value-set invariance for problems that come from the same domain. For example, learning to solve 16 x 16 sudoku after being trained on only 9 x 9 sudokus, or coloring a 7 colorable graph after training on 4 colorable graphs.  In this work, we propose novel methods to extend GNN based architectures to achieve value-set invariance. Specifically, our model builds on recently proposed Recurrent Relational Networks (RRN) (Palm et al., 2018). Our first approach exploits the graph-size invariance of GNNs by converting a multi-class node classification problem into a binary node classification problem. Our second approach works directly with multiple classes by adding multiple nodes corresponding to the values in the value-set, and then connecting variable nodes to value nodes depending on the problem initialization. Our experimental evaluation on three different combinatorial problems demonstrates that both our models perform well on our novel problem, compared to a generic neural reasoner. Between two of our models, we observe an inherent trade-off: while the binarized model gives better performance when trained on smaller value-sets, multi-valued model is much more memory efficient, resulting in improved performance when trained on larger value-sets, where binarized model fails to train.",
        "conference": "ICLR",
        "中文标题": "组合问题中输出空间不变性的神经模型",
        "摘要翻译": "最近，许多神经模型被提出来通过隐式学习已解决实例（如数独或图着色（GCP）中的基础约束来解决组合难题。这些通常基于图神经网络（GNN）（Zhou等人，2020年）的架构的一个缺点是，它们无法从变量被赋值的输出空间（例如GCP中的颜色集或数独中的棋盘大小）的大小中进行泛化。我们将变量的输出空间称为‘值集’。虽然许多工作已经证明了GNN在图大小上的泛化能力，但如何设计一个GNN以实现来自同一领域问题的值集不变性尚未有研究。例如，在仅训练于9x9数独后学习解决16x16数独，或在训练于4色图后着色7色图。在这项工作中，我们提出了新方法，以扩展基于GNN的架构来实现值集不变性。具体来说，我们的模型建立在最近提出的循环关系网络（RRN）（Palm等人，2018年）的基础上。我们的第一种方法通过将多类节点分类问题转化为二进制节点分类问题，利用了GNN的图大小不变性。我们的第二种方法直接处理多类问题，通过添加对应于值集中值的多个节点，然后根据问题初始化将变量节点连接到值节点。我们在三种不同组合问题上的实验评估表明，与通用神经推理器相比，我们的两种模型在我们的新问题上表现良好。在我们的两个模型之间，我们观察到一个固有的权衡：虽然二值化模型在训练于较小的值集时表现更好，但多值模型在内存效率上更高，从而在训练于较大的值集时表现更佳，而二值化模型则无法训练。",
        "领域": "图神经网络、组合优化、机器学习",
        "问题": "解决图神经网络在组合问题中无法泛化到不同大小的输出空间的问题",
        "动机": "研究如何设计图神经网络以实现对来自同一领域问题的值集不变性，例如在不同大小的数独或图着色问题中的泛化能力",
        "方法": "提出了两种基于循环关系网络的扩展方法：一种是将多类节点分类问题转化为二进制节点分类问题；另一种是直接处理多类问题，通过添加对应于值集中值的多个节点并连接变量节点和值节点",
        "关键词": [
            "图神经网络",
            "组合优化",
            "值集不变性",
            "循环关系网络",
            "节点分类"
        ],
        "涉及的技术概念": {
            "图神经网络": "用于处理和预测图结构数据的神经网络，本文中用于解决组合问题",
            "值集不变性": "指模型能够处理不同大小的输出空间的能力，本文中研究如何实现这一特性",
            "循环关系网络": "一种特殊的图神经网络，本文中作为基础架构进行扩展以实现值集不变性"
        },
        "success": true
    },
    {
        "order": 659,
        "title": "Neural Network Approximation based on Hausdorff distance of Tropical Zonotopes",
        "html": "https://iclr.cc//virtual/2022/poster/5971",
        "abstract": "In this work we theoretically contribute to neural network approximation by providing a novel tropical geometrical viewpoint to structured neural network compression. In particular, we show that the approximation error between two neural networks with ReLU activations and one hidden layer depends on the Hausdorff distance of the tropical zonotopes of the networks. This theorem comes as a first step towards a purely geometrical interpretation of neural network approximation. Based on this theoretical contribution, we propose geometrical methods that employ the K-means algorithm to compress the fully connected parts of ReLU activated deep neural networks. We analyze the error bounds of our algorithms theoretically based on our approximation theorem and evaluate them empirically on neural network compression. Our experiments follow a proof-of-concept strategy and indicate that our geometrical tools achieve improved performance over relevant tropical geometry techniques and can be competitive against non-tropical methods. ",
        "conference": "ICLR",
        "中文标题": "基于热带Zonotopes Hausdorff距离的神经网络近似",
        "摘要翻译": "在这项工作中，我们通过提供一个新颖的热带几何视角来结构化神经网络压缩，从而在理论上对神经网络近似做出了贡献。特别是，我们证明了具有ReLU激活函数和一层隐藏层的两个神经网络之间的近似误差取决于网络热带zonotopes的Hausdorff距离。这一定理是朝着神经网络近似的纯粹几何解释迈出的第一步。基于这一理论贡献，我们提出了几何方法，利用K-means算法来压缩ReLU激活的深度神经网络的完全连接部分。我们基于我们的近似定理从理论上分析了我们算法的误差界限，并在神经网络压缩上进行了实证评估。我们的实验遵循概念验证策略，结果表明我们的几何工具比相关的热带几何技术实现了更好的性能，并且可以与非热带方法竞争。",
        "领域": "神经网络压缩、热带几何、深度学习理论",
        "问题": "如何从热带几何的角度理解和改进神经网络的结构化压缩",
        "动机": "探索神经网络近似的几何解释，提出基于热带几何的结构化压缩方法",
        "方法": "利用热带几何理论，特别是热带zonotopes的Hausdorff距离，结合K-means算法进行神经网络压缩",
        "关键词": [
            "热带几何",
            "神经网络压缩",
            "Hausdorff距离",
            "K-means算法",
            "ReLU激活函数"
        ],
        "涉及的技术概念": {
            "热带zonotopes": "在热带几何中用于描述神经网络结构的几何对象，本文中用于衡量神经网络之间的近似误差",
            "Hausdorff距离": "衡量两个热带zonotopes之间距离的度量，本文中用于量化神经网络近似误差",
            "K-means算法": "一种聚类算法，本文中用于压缩神经网络的完全连接部分，以减少模型复杂度"
        },
        "success": true
    },
    {
        "order": 660,
        "title": "Neural Networks as Kernel Learners: The Silent Alignment Effect",
        "html": "https://iclr.cc//virtual/2022/poster/7005",
        "abstract": "Neural networks in the lazy training regime converge to kernel machines. Can neural networks in the rich feature learning regime learn a kernel machine with a data-dependent kernel? We demonstrate that this can indeed happen due to a phenomenon we term silent alignment, which requires that the tangent kernel of a network evolves in eigenstructure while small and before the loss appreciably decreases, and grows only in overall scale afterwards. We show that such an effect takes place in homogenous neural networks with small initialization and whitened data. We provide an analytical treatment of this effect in the linear network case. In general, we find that the kernel develops a low-rank contribution in the early phase of training, and then evolves in overall scale, yielding a function equivalent to a kernel regression solution with the final network's tangent kernel. The early spectral learning of the kernel depends on the depth. We also demonstrate that non-whitened data can weaken the silent alignment effect.",
        "conference": "ICLR",
        "中文标题": "神经网络作为核学习器：静默对齐效应",
        "摘要翻译": "在懒惰训练机制下，神经网络收敛于核机器。在丰富的特征学习机制下，神经网络能否学习一个依赖于数据的核机器？我们证明，由于我们称之为静默对齐的现象，这确实可以发生。这种现象要求网络的切线核在特征结构上演变，同时保持较小且在损失显著减少之前，之后仅在整体规模上增长。我们展示了这种现象在具有小初始化和白化数据的同质神经网络中发生。我们在线性网络情况下提供了这一效应的分析处理。总的来说，我们发现核在训练的早期阶段发展出一个低秩贡献，然后在整体规模上演变，产生一个与最终网络的切线核的核回归解等价的函数。核的早期谱学习依赖于深度。我们还证明了非白化数据可以削弱静默对齐效应。",
        "领域": "深度学习理论、核方法、神经网络训练动态",
        "问题": "探讨在丰富的特征学习机制下，神经网络是否能够学习一个依赖于数据的核机器，以及这一过程中的静默对齐效应。",
        "动机": "研究神经网络在特征学习机制下如何通过静默对齐效应学习数据依赖的核，以及这一现象对网络训练动态的影响。",
        "方法": "通过理论分析和实验验证，研究同质神经网络在小初始化和白化数据条件下的静默对齐效应，以及这一效应如何影响核的演变和网络的学习过程。",
        "关键词": [
            "静默对齐",
            "核学习",
            "神经网络训练",
            "特征学习",
            "切线核"
        ],
        "涉及的技术概念": {
            "静默对齐": "指神经网络在训练早期，切线核在特征结构上演变而整体规模保持较小的现象，随后仅在规模上增长。",
            "切线核": "用于描述神经网络在训练过程中局部线性近似的核，其演变反映了网络学习动态。",
            "白化数据": "预处理步骤，旨在使输入数据的特征具有零均值和单位方差，以减少训练中的协方差偏移。"
        },
        "success": true
    },
    {
        "order": 661,
        "title": "Neural Parameter Allocation Search",
        "html": "https://iclr.cc//virtual/2022/poster/6399",
        "abstract": "Training neural networks requires increasing amounts of memory. Parameter sharing can reduce memory and communication costs, but existing methods assume networks have many identical layers and utilize hand-crafted sharing strategies that fail to generalize. We introduce Neural Parameter Allocation Search (NPAS), a novel task where the goal is to train a neural network given an arbitrary, fixed parameter budget. NPAS covers both low-budget regimes, which produce compact networks, as well as a novel high-budget regime, where additional capacity can be added to boost performance without increasing inference FLOPs.  To address NPAS, we introduce Shapeshifter Networks (SSNs), which automatically learn where and how to share parameters in a network to support any parameter budget without requiring any changes to the architecture or loss function. NPAS and SSNs provide a complete framework for addressing generalized parameter sharing, and can also be combined with prior work for additional performance gains. We demonstrate the effectiveness of our approach using nine network architectures across four diverse tasks, including ImageNet classification and transformers.",
        "conference": "ICLR",
        "中文标题": "神经参数分配搜索",
        "摘要翻译": "训练神经网络需要越来越多的内存。参数共享可以减少内存和通信成本，但现有方法假设网络有许多相同的层，并利用手工制作的共享策略，这些策略无法泛化。我们引入了神经参数分配搜索（NPAS），这是一个新颖的任务，目标是在给定任意固定参数预算的情况下训练神经网络。NPAS既包括产生紧凑网络的低预算机制，也包括一种新颖的高预算机制，其中可以增加额外的容量以提高性能，而不会增加推理的FLOPs。为了解决NPAS，我们引入了变形网络（SSNs），它自动学习在网络的何处以及如何共享参数，以支持任何参数预算，而无需对架构或损失函数进行任何更改。NPAS和SSNs提供了一个完整的框架，用于解决广义参数共享问题，并且还可以与先前的工作结合以获得额外的性能提升。我们通过在四个不同的任务中使用九种网络架构，包括ImageNet分类和变换器，证明了我们方法的有效性。",
        "领域": "神经网络优化, 参数共享, 深度学习效率",
        "问题": "如何在固定参数预算下高效训练神经网络，同时实现参数共享以降低内存和通信成本。",
        "动机": "现有参数共享方法依赖于手工策略和网络层相同性的假设，限制了其泛化能力和应用范围。",
        "方法": "提出了神经参数分配搜索（NPAS）任务和变形网络（SSNs），自动学习参数共享策略，支持任意参数预算，无需修改网络架构或损失函数。",
        "关键词": [
            "神经参数分配搜索",
            "变形网络",
            "参数共享",
            "深度学习效率",
            "固定参数预算"
        ],
        "涉及的技术概念": {
            "神经参数分配搜索（NPAS）": "一种新颖的任务，旨在在固定参数预算下训练神经网络，涵盖低预算和高预算机制。",
            "变形网络（SSNs）": "自动学习参数共享策略的网络，支持任何参数预算，无需对架构或损失函数进行更改。",
            "参数共享": "一种减少神经网络内存和通信成本的技术，通过在不同部分重用参数来实现。"
        },
        "success": true
    },
    {
        "order": 662,
        "title": "Neural Processes with Stochastic Attention: Paying more attention to the context dataset",
        "html": "https://iclr.cc//virtual/2022/poster/6815",
        "abstract": "Neural processes (NPs) aim to stochastically complete unseen data points based on a given context dataset. NPs essentially leverage a given dataset as a context representation to derive a suitable identifier for a novel task. To improve the prediction accuracy, many variants of NPs have investigated context embedding approaches that generally design novel network architectures and aggregation functions satisfying permutation invariant. In this work, we propose a stochastic attention mechanism for NPs to capture appropriate context information. From the perspective of information theory, we demonstrate that the proposed method encourages context embedding to be differentiated from a target dataset, allowing NPs to consider features in a target dataset and context embedding independently. We observe that the proposed method can appropriately capture context embedding even under noisy data sets and restricted task distributions, where typical NPs suffer from a lack of context embeddings. We empirically show that our approach substantially outperforms conventional NPs in various domains through 1D regression, predator-prey model, and image completion. Moreover, the proposed method is also validated by MovieLens-10k dataset, a real-world problem.",
        "conference": "ICLR",
        "中文标题": "随机注意力神经过程：更加关注上下文数据集",
        "摘要翻译": "神经过程（NPs）旨在基于给定的上下文数据集随机完成未见过的数据点。NPs本质上利用给定的数据集作为上下文表示，以推导出新任务的合适标识符。为了提高预测准确性，NPs的许多变体研究了上下文嵌入方法，这些方法通常设计满足排列不变性的新颖网络架构和聚合函数。在这项工作中，我们为NPs提出了一种随机注意力机制，以捕捉适当的上下文信息。从信息论的角度，我们证明了所提出的方法鼓励上下文嵌入与目标数据集区分开来，使得NPs能够独立考虑目标数据集中的特征和上下文嵌入。我们观察到，即使在噪声数据集和受限的任务分布下，所提出的方法也能适当捕捉上下文嵌入，而典型的NPs在这些情况下往往缺乏上下文嵌入。我们通过一维回归、捕食者-猎物模型和图像完成等多种领域的实验证明，我们的方法显著优于传统的NPs。此外，所提出的方法也通过MovieLens-10k数据集这一实际问题得到了验证。",
        "领域": "深度学习与概率建模、图像完成、推荐系统",
        "问题": "提高神经过程在未见数据点上的预测准确性，特别是在噪声数据集和受限任务分布下的性能。",
        "动机": "传统的神经过程在处理噪声数据和受限任务时，往往缺乏有效的上下文嵌入，导致预测性能不佳。",
        "方法": "提出了一种随机注意力机制，通过信息论的角度优化上下文嵌入，使其与目标数据集区分开来，从而独立考虑目标特征和上下文嵌入。",
        "关键词": [
            "神经过程",
            "随机注意力",
            "上下文嵌入",
            "信息论",
            "图像完成"
        ],
        "涉及的技术概念": {
            "神经过程": "一种基于概率的模型，用于在给定上下文数据集的情况下预测未见数据点的分布。",
            "随机注意力机制": "一种动态选择上下文信息的方法，旨在提高模型对重要上下文特征的关注。",
            "信息论": "用于分析和优化上下文嵌入与目标数据集之间的关系，确保嵌入的有效性和独立性。"
        },
        "success": true
    },
    {
        "order": 663,
        "title": "Neural Program Synthesis with Query",
        "html": "https://iclr.cc//virtual/2022/poster/7064",
        "abstract": "Aiming to find a program satisfying the user intent given input-output examples, program synthesis has attracted increasing interest in the area of machine learning. Despite the promising performance of existing methods, most of their success comes from the privileged information of well-designed input-output examples. However, providing such input-output examples is unrealistic because it requires the users to have the ability to describe the underlying program with a few input-output examples under the training distribution. In this work, we propose a query-based framework that trains a query neural network to generate informative input-output examples automatically and interactively from a large query space. The quality of the query depends on the amount of the mutual information between the query and the corresponding program, which can guide the optimization of the query framework. To estimate the mutual information more accurately, we introduce the functional space (F-space) which models the relevance between the input-output examples and the programs in a differentiable way. We evaluate the effectiveness and generalization of the proposed query-based framework on the Karel task and the list processing task. Experimental results show that the query-based framework can generate informative input-output examples which achieveand even outperform well-designed input-output examples.",
        "conference": "ICLR",
        "中文标题": "基于查询的神经程序合成",
        "摘要翻译": "程序合成的目标是根据输入输出示例找到满足用户意图的程序，这一领域在机器学习中引起了越来越多的兴趣。尽管现有方法表现出了令人鼓舞的性能，但它们的成功大多来自于精心设计的输入输出示例的特权信息。然而，提供这样的输入输出示例是不现实的，因为这要求用户有能力在训练分布下用少数输入输出示例描述底层程序。在这项工作中，我们提出了一个基于查询的框架，该框架训练一个查询神经网络，从一个大的查询空间中自动且交互式地生成信息丰富的输入输出示例。查询的质量取决于查询与相应程序之间的互信息量，这可以指导查询框架的优化。为了更准确地估计互信息，我们引入了功能空间（F-space），它以可微分的方式建模输入输出示例与程序之间的相关性。我们在Karel任务和列表处理任务上评估了所提出的基于查询的框架的有效性和泛化能力。实验结果表明，基于查询的框架可以生成信息丰富的输入输出示例，这些示例达到甚至超过了精心设计的输入输出示例的性能。",
        "领域": "程序合成、机器学习、自动编程",
        "问题": "如何在不需要用户提供精心设计的输入输出示例的情况下，自动合成满足用户意图的程序。",
        "动机": "现有的程序合成方法依赖于精心设计的输入输出示例，这在实际应用中不现实，因为用户可能无法提供这样的示例。",
        "方法": "提出一个基于查询的框架，通过训练查询神经网络自动生成信息丰富的输入输出示例，并引入功能空间（F-space）来更准确地估计输入输出示例与程序之间的互信息。",
        "关键词": [
            "程序合成",
            "查询神经网络",
            "功能空间",
            "互信息",
            "自动编程"
        ],
        "涉及的技术概念": {
            "查询神经网络": "用于从大的查询空间中自动生成信息丰富的输入输出示例的神经网络。",
            "功能空间（F-space）": "以可微分的方式建模输入输出示例与程序之间相关性的空间，用于更准确地估计互信息。",
            "互信息": "衡量查询与相应程序之间信息量的指标，用于指导查询框架的优化。"
        },
        "success": true
    },
    {
        "order": 664,
        "title": "Neural Relational Inference with Node-Specific Information ",
        "html": "https://iclr.cc//virtual/2022/poster/5937",
        "abstract": "Inferring interactions among entities is an important problem in studying dynamical systems, which greatly impacts the performance of downstream tasks, such as prediction. In this paper, we tackle the relational inference problem in a setting where each entity can potentially have a set of individualized information that other entities cannot have access to. Specifically, we represent the system using a graph in which the individualized information become node-specific information (NSI). We build our model in the framework of Neural Relation Inference (NRI), where the interaction among entities are uncovered using variational inference. We adopt NRI model to incorporate the individualized information by introducing private nodes in the graph that represent NSI. Such representation enables us to uncover more accurate relations among the agents and therefore leads to better performance on the downstream tasks. Our experiment results over real-world datasets validate the merit of our proposed algorithm. ",
        "conference": "ICLR",
        "中文标题": "神经关系推理与节点特定信息",
        "摘要翻译": "在动态系统的研究中，推断实体间的相互作用是一个重要问题，这对下游任务（如预测）的性能有很大影响。本文中，我们解决了一个关系推理问题，其中每个实体可能拥有一组其他实体无法访问的个性化信息。具体来说，我们使用图来表示系统，其中个性化信息成为节点特定信息（NSI）。我们在神经关系推理（NRI）框架下构建我们的模型，其中实体间的相互作用通过变分推理揭示。我们通过引入代表NSI的图中的私有节点，采用NRI模型来纳入个性化信息。这种表示使我们能够揭示代理间更准确的关系，从而在下游任务上获得更好的性能。我们在真实世界数据集上的实验结果验证了我们提出算法的优点。",
        "领域": "图神经网络、动态系统建模、关系推理",
        "问题": "如何在每个实体拥有个性化信息的情况下，准确推断动态系统中实体间的相互作用关系。",
        "动机": "研究动机在于探索和利用实体个性化信息对动态系统中关系推理的影响，以提高下游任务的性能。",
        "方法": "在神经关系推理（NRI）框架下，通过引入代表节点特定信息（NSI）的私有节点，采用变分推理方法揭示实体间的相互作用关系。",
        "关键词": [
            "神经关系推理",
            "节点特定信息",
            "变分推理",
            "动态系统",
            "图神经网络"
        ],
        "涉及的技术概念": {
            "神经关系推理（NRI）": "用于推断动态系统中实体间相互作用关系的框架，通过变分推理揭示关系。",
            "节点特定信息（NSI）": "图中代表实体个性化信息的私有节点，用于提高关系推理的准确性。",
            "变分推理": "一种概率推理方法，用于在NRI框架下推断实体间的潜在关系。"
        },
        "success": true
    },
    {
        "order": 665,
        "title": "Neural Solvers for Fast and Accurate Numerical Optimal Control",
        "html": "https://iclr.cc//virtual/2022/poster/6968",
        "abstract": "Synthesizing optimal controllers for dynamical systems often involves solving optimization problems with hard real-time constraints. These constraints determine the class of numerical methods that can be applied: computationally expensive but accurate numerical routines are replaced by fast and inaccurate methods, trading inference time for solution accuracy. This paper provides techniques to improve the quality of optimized control policies given a fixed computational budget. We achieve the above via a hypersolvers approach, which hybridizes a differential equation solver and a neural network. The performance is evaluated in direct and receding-horizon optimal control tasks in both low and high dimensions, where the proposed approach shows consistent Pareto improvements in solution accuracy and control performance.",
        "conference": "ICLR",
        "中文标题": "神经求解器：快速且精确的数值最优控制",
        "摘要翻译": "为动态系统合成最优控制器通常涉及解决具有严格实时约束的优化问题。这些约束决定了可以应用的数值方法类别：计算成本高但精确的数值例程被快速但不精确的方法所取代，以推理时间换取解决方案的准确性。本文提供了在给定固定计算预算的情况下提高优化控制策略质量的技术。我们通过超求解器方法实现上述目标，该方法将微分方程求解器和神经网络混合在一起。在低维和高维的直接和滚动时域最优控制任务中评估了性能，其中所提出的方法在解决方案准确性和控制性能方面显示出一致的帕累托改进。",
        "领域": "最优控制, 动态系统, 神经网络应用",
        "问题": "如何在固定计算预算下提高优化控制策略的质量",
        "动机": "解决动态系统最优控制中计算成本与解决方案准确性之间的权衡问题",
        "方法": "采用超求解器方法，混合微分方程求解器和神经网络",
        "关键词": [
            "最优控制",
            "神经求解器",
            "动态系统",
            "超求解器",
            "帕累托改进"
        ],
        "涉及的技术概念": {
            "超求解器": "混合微分方程求解器和神经网络的方法，用于在固定计算预算下提高控制策略的质量",
            "帕累托改进": "在解决方案准确性和控制性能方面实现一致的改进，而不牺牲其他方面",
            "动态系统": "需要合成最优控制器的系统，其行为随时间变化"
        },
        "success": true
    },
    {
        "order": 666,
        "title": "Neural Spectral Marked Point Processes",
        "html": "https://iclr.cc//virtual/2022/poster/6311",
        "abstract": "Self- and mutually-exciting point processes are popular models in machine learning and statistics for dependent discrete event data. To date, most existing models assume stationary kernels (including the classical Hawkes processes) and simple parametric models. Modern applications with complex event data require more general point process models that can incorporate contextual information of the events, called marks, besides the temporal and location information. Moreover, such applications often require non-stationary models to capture more complex spatio-temporal dependence. To tackle these challenges, a key question is to devise a versatile influence kernel in the point process model. In this paper, we introduce a novel and general neural network-based non-stationary influence kernel with high expressiveness for handling complex discrete events data while providing theoretical performance guarantees. We demonstrate the superior performance of our proposed method compared with the state-of-the-art on synthetic and real data.",
        "conference": "ICLR",
        "中文标题": "神经频谱标记点过程",
        "摘要翻译": "自激和互激点过程是机器学习和统计学中用于依赖离散事件数据的流行模型。迄今为止，大多数现有模型假设平稳核（包括经典的霍克斯过程）和简单的参数模型。具有复杂事件数据的现代应用需要更一般的点过程模型，这些模型除了时间和位置信息外，还能结合事件的上下文信息，称为标记。此外，此类应用通常需要非平稳模型来捕捉更复杂的时空依赖性。为了应对这些挑战，一个关键问题是在点过程模型中设计一个多功能的影响核。在本文中，我们引入了一种新颖且通用的基于神经网络的非平稳影响核，具有高表达能力，用于处理复杂的离散事件数据，同时提供理论性能保证。我们展示了我们提出的方法在合成和真实数据上与最先进技术相比的优越性能。",
        "领域": "时空数据分析, 点过程模型, 神经网络应用",
        "问题": "如何设计一个多功能的影响核来处理复杂的离散事件数据，同时结合事件的上下文信息和非平稳的时空依赖性。",
        "动机": "现代应用中复杂事件数据的处理需要超越传统平稳核和简单参数模型的点过程模型，以捕捉更丰富的上下文信息和时空依赖性。",
        "方法": "引入了一种基于神经网络的非平稳影响核，该核具有高表达能力，能够处理复杂的离散事件数据，并提供理论性能保证。",
        "关键词": [
            "神经频谱",
            "标记点过程",
            "非平稳模型",
            "时空依赖性",
            "神经网络"
        ],
        "涉及的技术概念": {
            "神经频谱": "在点过程模型中引入的一种基于神经网络的影响核，用于提高模型对复杂事件数据的表达能力。",
            "标记点过程": "一种能够结合事件上下文信息的点过程模型，用于更全面地描述事件数据。",
            "非平稳模型": "用于捕捉事件数据中复杂时空依赖性的模型，超越了传统平稳核的限制。"
        },
        "success": true
    },
    {
        "order": 667,
        "title": "Neural Stochastic Dual Dynamic Programming",
        "html": "https://iclr.cc//virtual/2022/poster/6655",
        "abstract": "Stochastic dual dynamic programming (SDDP) is a state-of-the-art method for solving multi-stage stochastic optimization, widely used for modeling real-world process optimization tasks. Unfortunately, SDDP has a worst-case complexity that scales exponentially in the number of decision variables, which severely limits applicability to only low dimensional problems. To overcome this limitation, we extend SDDP by introducing a trainable neural model that learns to map problem instances to a piece-wise linear value function within intrinsic low-dimension space, which is architected specifically to interact with a base SDDP solver, so that can accelerate optimization performance on new instances. The proposed Neural Stochastic Dual Dynamic Programming ($$\\nu$$-SDDP) continually self-improves by solving successive problems. An empirical investigation demonstrates that $$\\nu$$-SDDP can significantly reduce problem solving cost without sacrificing solution quality over competitors such as SDDP and reinforcement learning algorithms, across a range of synthetic and real-world process optimization problems.",
        "conference": "ICLR",
        "中文标题": "神经随机对偶动态规划",
        "摘要翻译": "随机对偶动态规划（SDDP）是解决多阶段随机优化问题的最先进方法，广泛用于建模现实世界的流程优化任务。然而，SDDP在最坏情况下的复杂度随决策变量数量的增加而指数级增长，这严重限制了其仅适用于低维问题。为了克服这一限制，我们通过引入一个可训练的神经模型来扩展SDDP，该模型学习将问题实例映射到内在低维空间中的分段线性价值函数，该空间专门设计用于与基础SDDP求解器交互，从而加速对新实例的优化性能。提出的神经随机对偶动态规划（ν-SDDP）通过解决连续问题不断自我改进。实证研究表明，在一系列合成和现实世界的流程优化问题中，ν-SDDP能够在不牺牲解决方案质量的情况下，显著降低问题解决成本，优于SDDP和强化学习算法等竞争对手。",
        "领域": "随机优化、流程优化、强化学习",
        "问题": "SDDP方法在处理高维问题时复杂度指数级增长，限制了其应用范围。",
        "动机": "扩展SDDP方法，使其能够有效处理高维问题，提高优化性能。",
        "方法": "引入可训练的神经模型，将问题实例映射到低维空间的分段线性价值函数，与基础SDDP求解器交互以加速优化。",
        "关键词": [
            "神经随机对偶动态规划",
            "多阶段随机优化",
            "流程优化",
            "强化学习",
            "低维空间映射"
        ],
        "涉及的技术概念": {
            "随机对偶动态规划（SDDP）": "用于解决多阶段随机优化问题的方法，但在高维问题上效率低下。",
            "神经模型": "可训练的模型，用于学习将高维问题映射到低维空间，以提高优化效率。",
            "分段线性价值函数": "在低维空间中表示问题实例的方法，便于与SDDP求解器交互，加速优化过程。"
        },
        "success": true
    },
    {
        "order": 668,
        "title": "Neural Structured Prediction for Inductive Node Classification",
        "html": "https://iclr.cc//virtual/2022/poster/5947",
        "abstract": "This paper studies node classification in the inductive setting, i.e., aiming to learn a model on labeled training graphs and generalize it to infer node labels on unlabeled test graphs. This problem has been extensively studied with graph neural networks (GNNs) by learning effective node representations, as well as traditional structured prediction methods for modeling the structured output of node labels, e.g., conditional random fields (CRFs). In this paper, we present a new approach called the Structured Proxy Network (SPN), which combines the advantages of both worlds. SPN defines flexible potential functions of CRFs with GNNs. However, learning such a model is nontrivial as it involves optimizing a maximin game with high-cost inference. Inspired by the underlying connection between joint and marginal distributions defined by Markov networks, we propose to solve an approximate version of the optimization problem as a proxy, which yields a near-optimal solution, making learning more efficient. Extensive experiments on two settings show that our approach outperforms many competitive baselines.",
        "conference": "ICLR",
        "中文标题": "用于归纳式节点分类的神经结构化预测",
        "摘要翻译": "本文研究了归纳式设置下的节点分类问题，即旨在通过标记的训练图学习模型，并将其推广到未标记的测试图上推断节点标签。这一问题已通过图神经网络（GNNs）学习有效的节点表示，以及传统的结构化预测方法（如条件随机场（CRFs））来建模节点标签的结构化输出，得到了广泛研究。在本文中，我们提出了一种称为结构化代理网络（SPN）的新方法，它结合了两者的优势。SPN利用GNNs定义了CRFs的灵活势函数。然而，学习这样的模型并非易事，因为它涉及优化一个具有高成本推理的最大最小博弈。受到马尔可夫网络定义的联合分布与边缘分布之间潜在联系的启发，我们提出将优化问题的近似版本作为代理来解决，这产生了一个接近最优的解，使学习更加高效。在两个设置上的大量实验表明，我们的方法优于许多竞争基线。",
        "领域": "图神经网络、结构化预测、节点分类",
        "问题": "如何在归纳式设置下有效地进行节点分类，结合图神经网络和结构化预测方法的优势。",
        "动机": "结合图神经网络和结构化预测方法的优势，解决归纳式节点分类问题，提高模型的泛化能力和效率。",
        "方法": "提出结构化代理网络（SPN），通过图神经网络定义条件随机场的灵活势函数，并采用近似优化方法高效学习模型。",
        "关键词": [
            "结构化代理网络",
            "图神经网络",
            "条件随机场",
            "节点分类",
            "归纳学习"
        ],
        "涉及的技术概念": {
            "结构化代理网络（SPN）": "结合图神经网络和条件随机场的新方法，用于高效解决归纳式节点分类问题。",
            "图神经网络（GNNs）": "用于学习节点表示的深度学习模型，能够捕捉图结构中的复杂关系。",
            "条件随机场（CRFs）": "一种结构化预测方法，用于建模节点标签之间的依赖关系，提高分类准确性。"
        },
        "success": true
    },
    {
        "order": 669,
        "title": "Neural Variational Dropout Processes",
        "html": "https://iclr.cc//virtual/2022/poster/6082",
        "abstract": "Learning to infer the conditional posterior model is a key step for robust meta-learning. This paper presents a new Bayesian meta-learning approach called Neural Variational Dropout Processes (NVDPs). NVDPs model the conditional posterior distribution based on a task-specific dropout; a low-rank product of Bernoulli experts meta-model is utilized for a memory-efficient mapping of dropout rates from a few observed contexts. It allows for a quick reconfiguration of a globally learned and shared neural network for new tasks in multi-task few-shot learning. In addition, NVDPs utilize a novel prior conditioned on the whole task data to optimize the conditional dropout posterior in the amortized variational inference. Surprisingly, this enables the robust approximation of task-specific dropout rates that can deal with a wide range of functional ambiguities and uncertainties. We compared the proposed method with other meta-learning approaches in the few-shot learning tasks such as 1D stochastic regression, image inpainting, and classification. The results show the excellent performance of NVDPs.",
        "conference": "ICLR",
        "中文标题": "神经变分丢弃过程",
        "摘要翻译": "学习推断条件后验模型是鲁棒元学习的关键步骤。本文提出了一种新的贝叶斯元学习方法，称为神经变分丢弃过程（NVDPs）。NVDPs基于任务特定的丢弃率建模条件后验分布；利用低秩伯努利专家元模型进行内存高效的丢弃率映射，从少量观察到的上下文中。这使得在多任务少样本学习中，可以快速重新配置全局学习和共享的神经网络以适应新任务。此外，NVDPs利用了一种新颖的先验条件，该条件基于整个任务数据，以在摊销变分推断中优化条件丢弃后验。令人惊讶的是，这使得能够鲁棒地近似任务特定的丢弃率，可以处理广泛的功能模糊性和不确定性。我们将所提出的方法与其他元学习方法在少样本学习任务中进行了比较，如1D随机回归、图像修复和分类。结果显示NVDPs的卓越性能。",
        "领域": "元学习、少样本学习、贝叶斯深度学习",
        "问题": "如何在多任务少样本学习中快速适应新任务并处理功能模糊性和不确定性",
        "动机": "提高元学习在少样本学习任务中的适应性和鲁棒性",
        "方法": "提出神经变分丢弃过程（NVDPs），利用任务特定的丢弃率和低秩伯努利专家元模型进行条件后验建模，以及基于整个任务数据的新颖先验条件优化",
        "关键词": [
            "神经变分丢弃过程",
            "元学习",
            "少样本学习",
            "贝叶斯深度学习",
            "条件后验建模"
        ],
        "涉及的技术概念": {
            "神经变分丢弃过程（NVDPs）": "一种新的贝叶斯元学习方法，通过任务特定的丢弃率建模条件后验分布，以提高少样本学习中的适应性和鲁棒性",
            "低秩伯努利专家元模型": "用于内存高效的丢弃率映射，从少量观察到的上下文中快速适应新任务",
            "摊销变分推断": "在NVDPs中用于优化条件丢弃后验的方法，允许鲁棒地近似任务特定的丢弃率"
        },
        "success": true
    },
    {
        "order": 670,
        "title": "New Insights on Reducing Abrupt Representation Change in Online Continual Learning",
        "html": "https://iclr.cc//virtual/2022/poster/7188",
        "abstract": "In the online continual learning paradigm, agents must learn from a changing distribution while respecting memory and compute constraints. Experience Replay (ER), where a small subset of past data is stored and replayed alongside new data, has emerged as a simple and effective learning strategy. In this work, we focus on the change in representations of observed data that arises when previously unobserved classes appear in the incoming data stream, and new classes must be distinguished from previous ones. We shed new light on this question by showing that applying ER causes the newly added classes’ representations to overlap significantly with the previous classes, leading to highly disruptive parameter updates.  Based on this empirical analysis, we propose a new method which mitigates this issue by shielding the learned representations from drastic adaptation to accommodate new classes. We show that using an asymmetric update rule pushes new classes to adapt to the older ones (rather than the reverse), which is more effective especially at task boundaries, where much of the forgetting typically occurs. Empirical results show significant gains over strong baselines on standard continual learning benchmarks.",
        "conference": "ICLR",
        "中文标题": "在线持续学习中减少表征突变的新见解",
        "摘要翻译": "在在线持续学习范式中，智能体必须从变化的分布中学习，同时遵守内存和计算限制。经验回放（ER）作为一种简单有效的学习策略，存储并重放一小部分过去数据与新数据一起学习。在这项工作中，我们关注的是当输入数据流中出现之前未观察到的类别时，观察数据的表征变化，以及新类别必须与之前的类别区分开来的问题。我们通过展示应用ER导致新增类别的表征与之前类别显著重叠，从而引发高度破坏性的参数更新，为这一问题提供了新的见解。基于这一实证分析，我们提出了一种新方法，通过保护已学习的表征免受剧烈适应以容纳新类别，从而缓解这一问题。我们展示了使用非对称更新规则推动新类别适应旧类别（而非相反），这在任务边界处尤为有效，大多数遗忘通常发生于此。实证结果显示，在标准持续学习基准上，与强基线相比有显著提升。",
        "领域": "持续学习",
        "问题": "在线持续学习中新增类别导致表征重叠和参数更新的破坏性问题",
        "动机": "解决在线持续学习中因新增类别引起的表征突变和参数更新破坏性问题",
        "方法": "提出一种非对称更新规则，保护已学习表征免受剧烈适应，推动新类别适应旧类别",
        "关键词": [
            "在线持续学习",
            "经验回放",
            "表征重叠",
            "非对称更新",
            "任务边界"
        ],
        "涉及的技术概念": {
            "经验回放（ER）": "存储并重放一小部分过去数据与新数据一起学习，以缓解遗忘问题",
            "表征重叠": "新增类别的表征与之前类别显著重叠，导致破坏性参数更新",
            "非对称更新规则": "推动新类别适应旧类别，减少表征突变，特别是在任务边界处"
        },
        "success": true
    },
    {
        "order": 671,
        "title": "Node Feature Extraction by Self-Supervised Multi-scale Neighborhood Prediction",
        "html": "https://iclr.cc//virtual/2022/poster/7187",
        "abstract": "Learning on graphs has attracted significant attention in the learning community due to numerous real-world applications. In particular, graph neural networks (GNNs), which take \\emph{numerical} node features and graph structure as inputs, have been shown to achieve state-of-the-art performance on various graph-related learning tasks. Recent works exploring the correlation between numerical node features and graph structure via self-supervised learning have paved the way for further performance improvements of GNNs. However, methods used for extracting numerical node features from \\emph{raw data} are still \\emph{graph-agnostic} within standard GNN pipelines. This practice is sub-optimal as it prevents one from fully utilizing potential correlations between graph topology and node attributes. To mitigate this issue, we propose a new self-supervised learning framework, Graph Information Aided Node feature exTraction (GIANT). GIANT makes use of the eXtreme Multi-label Classification (XMC) formalism, which is crucial for fine-tuning the language model based on graph information, and scales to large datasets. We also provide a theoretical analysis that justifies the use of XMC over link prediction and motivates integrating XR-Transformers, a powerful method for solving XMC problems, into the GIANT framework. We demonstrate the superior performance of GIANT over the standard GNN pipeline on Open Graph Benchmark datasets: For example, we improve the accuracy of the top-ranked method GAMLP from $68.25\\%$ to $69.67\\%$, SGC from $63.29\\%$ to $66.10\\%$ and MLP from $47.24\\%$ to $61.10\\%$ on the ogbn-papers100M dataset by leveraging GIANT.",
        "conference": "ICLR",
        "中文标题": "通过自监督多尺度邻域预测进行节点特征提取",
        "摘要翻译": "由于众多实际应用，图上的学习在学术界引起了广泛关注。特别是图神经网络（GNNs），它以数值节点特征和图结构作为输入，已被证明在各种与图相关的学习任务上达到了最先进的性能。最近通过自监督学习探索数值节点特征与图结构之间相关性的工作，为GNNs性能的进一步提升铺平了道路。然而，在标准的GNN流程中，用于从原始数据中提取数值节点特征的方法仍然是图无关的。这种做法不是最优的，因为它阻碍了人们充分利用图拓扑与节点属性之间潜在的相关性。为了缓解这一问题，我们提出了一种新的自监督学习框架，图信息辅助节点特征提取（GIANT）。GIANT利用了极端多标签分类（XMC）的形式主义，这对于基于图信息微调语言模型至关重要，并且能够扩展到大型数据集。我们还提供了理论分析，证明了XMC相对于链接预测的优势，并激励将XR-Transformers（一种解决XMC问题的强大方法）集成到GIANT框架中。我们在Open Graph Benchmark数据集上展示了GIANT相对于标准GNN流程的优越性能：例如，在ogbn-papers100M数据集上，我们通过利用GIANT，将排名第一的方法GAMLP的准确率从68.25%提高到69.67%，SGC从63.29%提高到66.10%，MLP从47.24%提高到61.10%。",
        "领域": "图神经网络、自监督学习、极端多标签分类",
        "问题": "解决在标准图神经网络流程中，节点特征提取方法图无关的问题，以充分利用图拓扑与节点属性之间的潜在相关性。",
        "动机": "为了提升图神经网络的性能，通过自监督学习探索数值节点特征与图结构之间的相关性，并优化节点特征提取方法。",
        "方法": "提出了一种新的自监督学习框架GIANT，利用极端多标签分类（XMC）的形式主义微调语言模型，并集成XR-Transformers方法。",
        "关键词": [
            "图神经网络",
            "自监督学习",
            "极端多标签分类",
            "节点特征提取",
            "图信息辅助"
        ],
        "涉及的技术概念": {
            "图神经网络（GNNs）": "用于处理图结构数据的深度学习模型，能够捕捉节点间的关系和图的拓扑结构。",
            "自监督学习": "一种无需人工标注数据的学习方法，通过数据本身生成监督信号来训练模型。",
            "极端多标签分类（XMC）": "处理具有极多类别标签的分类问题的方法，适用于大规模数据集。"
        },
        "success": true
    },
    {
        "order": 672,
        "title": "NODE-GAM: Neural Generalized Additive Model for Interpretable Deep Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6355",
        "abstract": "Deployment of machine learning models in real high-risk settings (e.g. healthcare) often depends not only on the model's accuracy but also on its fairness, robustness, and interpretability. Generalized Additive Models (GAMs) are a class of interpretable models with a long history of use in these high-risk domains, but they lack desirable features of deep learning such as differentiability and scalability. In this work, we propose a neural GAM (NODE-GAM) and neural GA$^2$M (NODE-GA$^2$M) that scale well and perform better than other GAMs on large datasets, while remaining interpretable compared to other ensemble and deep learning models. We demonstrate that our models find interesting patterns in the data. Lastly, we show that we are able to improve model accuracy via self-supervised pre-training, an improvement that is not possible for non-differentiable GAMs.",
        "conference": "ICLR",
        "中文标题": "NODE-GAM：可解释深度学习的神经广义加性模型",
        "摘要翻译": "在现实高风险环境（如医疗保健）中部署机器学习模型，往往不仅取决于模型的准确性，还取决于其公平性、鲁棒性和可解释性。广义加性模型（GAMs）是一类在这些高风险领域有长期使用历史的可解释模型，但它们缺乏深度学习的一些理想特性，如可微分性和可扩展性。在这项工作中，我们提出了一种神经GAM（NODE-GAM）和神经GA²M（NODE-GA²M），这些模型在大数据集上比其他GAMs表现更好，同时与其他集成和深度学习模型相比仍保持可解释性。我们证明了我们的模型能够在数据中发现有趣的模式。最后，我们展示了通过自监督预训练能够提高模型准确性，这一改进对于不可微分的GAMs是不可能的。",
        "领域": "可解释人工智能、医疗健康数据分析、深度学习模型优化",
        "问题": "如何在保持模型可解释性的同时，提高广义加性模型在大数据集上的性能和可扩展性。",
        "动机": "为了在高风险领域（如医疗保健）中部署既准确又可解释的机器学习模型，需要克服传统广义加性模型在可微分性和可扩展性方面的限制。",
        "方法": "提出神经广义加性模型（NODE-GAM）和神经GA²M（NODE-GA²M），通过结合深度学习的可微分性和可扩展性优势，同时保持模型的可解释性。",
        "关键词": [
            "可解释人工智能",
            "广义加性模型",
            "深度学习",
            "自监督学习",
            "模型可解释性"
        ],
        "涉及的技术概念": {
            "神经广义加性模型（NODE-GAM）": "结合了深度学习的可微分性和可扩展性优势的广义加性模型，旨在提高在大数据集上的性能同时保持可解释性。",
            "神经GA²M（NODE-GA²M）": "NODE-GAM的扩展版本，进一步提高了模型的表达能力和性能。",
            "自监督预训练": "通过自监督学习技术预训练模型，以提高模型的准确性和性能，这一方法对于传统不可微分的GAMs不可行。"
        },
        "success": true
    },
    {
        "order": 673,
        "title": "NodePiece: Compositional and Parameter-Efficient Representations of Large Knowledge Graphs",
        "html": "https://iclr.cc//virtual/2022/poster/6306",
        "abstract": "Conventional representation learning algorithms for knowledge graphs (KG) map each entity to a unique embedding vector. Such a shallow lookup results in a linear growth of memory consumption for storing the embedding matrix and incurs high computational costs of working with real-world KGs.Drawing parallels with subword tokenization commonly used in NLP, we explore the landscape of more parameter-efficient node embedding strategies with possibly sublinear memory requirements. To this end, we propose NodePiece, an anchor-based approach to learn a fixed-size entity vocabulary. In NodePiece, a vocabulary of subword/sub-entity units is constructed from anchor nodes in a graph with known relation types. Given such a fixed-size vocabulary, it is possible to bootstrap an encoding and embedding for any entity, including those unseen during training.Experiments show that NodePiece performs competitively in node classification, link prediction, and relation prediction tasks retaining less than 10% of explicit nodes in a graph as anchors and often having 10x fewer parameters. To this end, we show that a NodePiece-enabled model outperforms existing shallow models on a large OGB WikiKG 2 graph having 70x fewer parameters.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "NodePiece：大型知识图谱的组合式与参数高效表示",
        "摘要翻译": "传统的知识图谱（KG）表示学习算法将每个实体映射到一个唯一的嵌入向量。这种浅层的查找方式导致存储嵌入矩阵的内存消耗线性增长，并且在处理现实世界中的知识图谱时产生高计算成本。借鉴自然语言处理中常用的子词标记化方法，我们探索了具有可能亚线性内存需求的更参数高效的节点嵌入策略。为此，我们提出了NodePiece，一种基于锚点的方法来学习固定大小的实体词汇表。在NodePiece中，子词/子实体单元的词汇表是从具有已知关系类型的图中的锚节点构建的。给定这样一个固定大小的词汇表，可以为任何实体（包括训练期间未见过的实体）引导编码和嵌入。实验表明，NodePiece在节点分类、链接预测和关系预测任务中表现优异，仅保留图中显式节点的不到10%作为锚点，并且通常参数数量减少10倍。因此，我们展示了基于NodePiece的模型在大型OGB WikiKG 2图上优于现有的浅层模型，参数数量减少了70倍。",
        "领域": "知识图谱表示学习, 自然语言处理与知识图谱结合, 参数高效模型",
        "问题": "解决知识图谱表示学习中内存消耗线性增长和计算成本高的问题",
        "动机": "探索更参数高效的节点嵌入策略，以减少内存消耗和计算成本",
        "方法": "提出NodePiece，一种基于锚点的方法来学习固定大小的实体词汇表，实现参数高效的节点嵌入",
        "关键词": [
            "知识图谱",
            "参数高效",
            "节点嵌入",
            "子词标记化",
            "锚点"
        ],
        "涉及的技术概念": {
            "子词标记化": "借鉴自然语言处理中的技术，用于构建子词/子实体单元的词汇表",
            "锚节点": "图中具有已知关系类型的节点，用于构建固定大小的实体词汇表",
            "参数高效模型": "通过减少参数数量来降低模型的内存消耗和计算成本"
        }
    },
    {
        "order": 674,
        "title": "Noisy Feature Mixup",
        "html": "https://iclr.cc//virtual/2022/poster/6227",
        "abstract": "We introduce Noisy Feature Mixup (NFM), an inexpensive yet effective method for data augmentation that combines the best of interpolation based training and noise injection schemes. Rather than training with convex combinations of pairs of examples and their labels, we use noise-perturbed convex combinations of pairs of data points in both input and feature space. This method includes mixup and manifold mixup as special cases, but it has additional advantages, including better smoothing of decision boundaries and enabling improved model robustness. We provide theory to understand this as well as the implicit regularization effects of NFM. Our theory is supported by empirical results, demonstrating the advantage of NFM, as compared to mixup and manifold mixup. We show that residual networks and vision transformers trained with NFM have favorable trade-offs between predictive accuracy on clean data and robustness with respect to various types of data perturbation across a range of computer vision benchmark datasets.",
        "conference": "ICLR",
        "中文标题": "噪声特征混合",
        "摘要翻译": "我们介绍了噪声特征混合（NFM），这是一种成本低廉但有效的数据增强方法，它结合了基于插值的训练和噪声注入方案的最佳特性。与使用示例及其标签的凸组合进行训练不同，我们在输入和特征空间中使用噪声扰动的数据点对的凸组合。该方法包括mixup和manifold mixup作为特例，但它具有额外的优势，包括更好地平滑决策边界和提高模型的鲁棒性。我们提供了理论来理解这一点以及NFM的隐式正则化效应。我们的理论得到了实证结果的支持，证明了与mixup和manifold mixup相比，NFM的优势。我们展示了使用NFM训练的残差网络和视觉变换器在一系列计算机视觉基准数据集上，在干净数据的预测准确性和对各种类型数据扰动的鲁棒性之间具有有利的权衡。",
        "领域": "数据增强、模型鲁棒性、计算机视觉",
        "问题": "如何在数据增强中结合插值训练和噪声注入的优势，以提高模型的鲁棒性和预测准确性。",
        "动机": "探索一种更有效的数据增强方法，以结合插值训练和噪声注入的优点，从而提升模型在面对数据扰动时的鲁棒性和在干净数据上的预测准确性。",
        "方法": "提出噪声特征混合（NFM）方法，通过在输入和特征空间中使用噪声扰动的数据点对的凸组合进行训练，结合了mixup和manifold mixup的优点，并进一步提高了模型的性能。",
        "关键词": [
            "噪声特征混合",
            "数据增强",
            "模型鲁棒性",
            "计算机视觉",
            "隐式正则化"
        ],
        "涉及的技术概念": {
            "噪声特征混合（NFM）": "一种结合了插值训练和噪声注入的数据增强方法，通过在输入和特征空间中使用噪声扰动的数据点对的凸组合进行训练。",
            "隐式正则化": "NFM方法中通过噪声扰动和数据混合自然引入的正则化效应，有助于提高模型的泛化能力和鲁棒性。",
            "决策边界平滑": "NFM方法通过噪声扰动和数据混合，使得模型的决策边界更加平滑，从而提高模型对数据扰动的鲁棒性。"
        },
        "success": true
    },
    {
        "order": 675,
        "title": "Nonlinear ICA Using Volume-Preserving Transformations",
        "html": "https://iclr.cc//virtual/2022/poster/6091",
        "abstract": "Nonlinear ICA is a fundamental problem in machine learning, aiming to identify the underlying independent components (sources) from data which is assumed to be a nonlinear function (mixing function) of these sources. Recent works prove that if the sources have some particular structures (e.g. temporal structure), they are theoretically identifiable even if the mixing function is arbitrary. However, in many cases such restrictions on the sources are difficult to satisfy or even verify, hence it inhibits the applicability of the proposed methods. Different from these works, we propose a general framework for nonlinear ICA, in which the mixing function is assumed to be a volume-preserving transformation, and meanwhile the conditions on the sources can be much looser. We provide an insightful proof of the identifiability of the proposed framework. We implement the framework by volume-preserving Flow-based models, and verify our theory by experiments on artificial data and synthesized images. Moreover, results on real-world images indicate that our framework can disentangle interpretable features.",
        "conference": "ICLR",
        "中文标题": "使用保体积变换的非线性独立成分分析",
        "摘要翻译": "非线性独立成分分析（ICA）是机器学习中的一个基本问题，旨在从数据中识别出潜在的独立成分（源），这些数据被假设为这些源的非线性函数（混合函数）。最近的研究证明，如果源具有某些特定的结构（例如时间结构），即使混合函数是任意的，理论上也可以识别出这些源。然而，在许多情况下，对源的这些限制难以满足甚至验证，因此限制了所提出方法的适用性。与这些工作不同，我们提出了一个非线性ICA的通用框架，其中假设混合函数是一个保体积变换，同时对源的条件可以宽松得多。我们为所提出框架的可识别性提供了一个深刻的证明。我们通过基于保体积流的模型实现了该框架，并通过人工数据和合成图像的实验验证了我们的理论。此外，真实世界图像的结果表明，我们的框架可以解耦出可解释的特征。",
        "领域": "独立成分分析、非线性变换、特征解耦",
        "问题": "解决在非线性混合函数下独立成分的可识别性问题，特别是在源数据不满足特定结构限制时的适用性问题。",
        "动机": "为了扩展非线性ICA的适用性，减少对源数据结构的限制，提出一个更通用的框架。",
        "方法": "提出一个基于保体积变换的非线性ICA框架，通过保体积流模型实现，并在理论和实验上验证其有效性。",
        "关键词": [
            "非线性ICA",
            "保体积变换",
            "特征解耦",
            "独立成分分析",
            "流模型"
        ],
        "涉及的技术概念": {
            "保体积变换": "在非线性ICA框架中，假设混合函数为保体积变换，使得在变换过程中保持体积不变，从而放宽对源数据结构的限制。",
            "独立成分分析（ICA）": "一种统计和计算技术，用于揭示随机变量、测量数据或信号中的隐藏因素。在本文中，特别关注于非线性情况下的ICA问题。",
            "流模型": "一种生成模型，通过一系列可逆变换将简单分布转换为复杂分布。在本文中，用于实现基于保体积变换的非线性ICA框架。"
        },
        "success": true
    },
    {
        "order": 676,
        "title": "Non-Linear Operator Approximations for Initial Value Problems",
        "html": "https://iclr.cc//virtual/2022/poster/7107",
        "abstract": "Time-evolution of partial differential equations is the key to model several dynamical processes, events forecasting but the operators associated with such problems are non-linear. We propose a Padé approximation based exponential neural operator scheme for efficiently learning the map between a given initial condition and activities at a later time. The multiwavelets bases are used for space discretization. By explicitly embedding the exponential operators in the model, we reduce the training parameters and make it more data-efficient which is essential in dealing with scarce real-world datasets. The Padé exponential operator uses a $\\textit{recurrent structure with shared parameters}$ to model the non-linearity compared to recent neural operators that rely on using multiple linear operator layers in succession. We show theoretically that the gradients associated with the recurrent Padé network are bounded across the recurrent horizon. We perform experiments on non-linear systems such as Korteweg-de Vries (KdV) and Kuramoto–Sivashinsky (KS) equations to show that the proposed approach achieves the best performance and at the same time is data-efficient. We also show that urgent real-world problems like Epidemic forecasting (for example, COVID-19) can be formulated as a 2D time-varying operator problem. The proposed Padé exponential operators yield better prediction results ($\\textbf{53\\%} (\\textbf{52\\%})$ better MAE than best neural operator (non-neural operator deep learning model)) compared to state-of-the-art forecasting models.",
        "conference": "ICLR",
        "中文标题": "初值问题的非线性算子近似方法",
        "摘要翻译": "偏微分方程的时间演化是建模多个动态过程和事件预测的关键，但与此类问题相关的算子是非线性的。我们提出了一种基于Padé近似的指数神经算子方案，用于高效学习给定初始条件与后期活动之间的映射。多小波基用于空间离散化。通过在模型中显式嵌入指数算子，我们减少了训练参数，使其更加数据高效，这对于处理稀缺的真实世界数据集至关重要。与最近依赖连续使用多个线性算子层的神经算子相比，Padé指数算子使用具有共享参数的递归结构来建模非线性。我们从理论上证明了与递归Padé网络相关的梯度在递归范围内是有界的。我们在非线性系统如Korteweg-de Vries (KdV)和Kuramoto–Sivashinsky (KS)方程上进行了实验，结果表明所提出的方法实现了最佳性能，同时数据效率高。我们还展示了紧急的现实世界问题如流行病预测（例如，COVID-19）可以表述为一个二维时变算子问题。与最先进的预测模型相比，提出的Padé指数算子产生了更好的预测结果（比最佳神经算子（非神经算子深度学习模型）的MAE好53%（52%））。",
        "领域": "偏微分方程数值解、动态系统建模、流行病预测",
        "问题": "高效学习和预测非线性偏微分方程的时间演化问题",
        "动机": "解决非线性偏微分方程时间演化问题中算子非线性的挑战，提高模型的数据效率和预测性能",
        "方法": "提出基于Padé近似的指数神经算子方案，利用多小波基进行空间离散化，显式嵌入指数算子以减少训练参数",
        "关键词": [
            "Padé近似",
            "指数神经算子",
            "多小波基",
            "非线性偏微分方程",
            "流行病预测"
        ],
        "涉及的技术概念": {
            "Padé近似": "用于近似非线性算子，提高模型对非线性动态系统的建模能力",
            "指数神经算子": "通过显式嵌入指数算子减少训练参数，提高数据效率",
            "多小波基": "用于空间离散化，帮助模型更有效地处理空间维度上的信息"
        },
        "success": true
    },
    {
        "order": 677,
        "title": "Non-Parallel Text Style Transfer with Self-Parallel Supervision",
        "html": "https://iclr.cc//virtual/2022/poster/6175",
        "abstract": "The performance of existing text style transfer models is severely limited by the non-parallel datasets on which the models are trained. In non-parallel datasets, no direct mapping exists between sentences of the source and target style; the style transfer models thus only receive weak supervision of the target sentences during training, which often leads the model to discard too much style-independent information, or utterly fail to transfer the style.In this work, we propose LaMer, a novel text style transfer framework based on large-scale language models. LaMer first mines the roughly parallel expressions in the non-parallel datasets with scene graphs, and then employs MLE training, followed by imitation learning refinement, to leverage the intrinsic parallelism within the data. On two benchmark tasks (sentiment & formality transfer) and a newly proposed challenging task (political stance transfer), our model achieves qualitative advances in transfer accuracy, content preservation, and fluency. Further empirical and human evaluations demonstrate that our model not only makes training more efficient, but also generates more readable and diverse expressions than previous models.",
        "conference": "ICLR",
        "中文标题": "非平行文本风格转换与自平行监督",
        "摘要翻译": "现有文本风格转换模型的性能严重受限于训练所用的非平行数据集。在非平行数据集中，源风格和目标风格的句子之间不存在直接映射；因此，风格转换模型在训练过程中仅接收到目标句子的弱监督，这常常导致模型丢弃过多的风格无关信息，或完全无法转换风格。在这项工作中，我们提出了LaMer，一个基于大规模语言模型的新型文本风格转换框架。LaMer首先利用场景图挖掘非平行数据集中的大致平行表达，然后采用最大似然估计（MLE）训练，接着通过模仿学习细化，以利用数据内在的平行性。在两个基准任务（情感和正式度转换）和一个新提出的挑战性任务（政治立场转换）上，我们的模型在转换准确性、内容保留和流畅性方面实现了质的飞跃。进一步的实证和人工评估表明，我们的模型不仅使训练更加高效，而且生成的表达比之前的模型更具可读性和多样性。",
        "领域": "自然语言处理与视觉结合、文本风格转换、语言模型应用",
        "问题": "解决非平行数据集中文本风格转换模型性能受限的问题",
        "动机": "提升文本风格转换模型在非平行数据集上的性能，减少风格无关信息的丢失和提高风格转换的准确性",
        "方法": "提出基于大规模语言模型的框架LaMer，通过挖掘非平行数据集中的大致平行表达，并采用MLE训练和模仿学习细化来利用数据内在的平行性",
        "关键词": [
            "文本风格转换",
            "非平行数据集",
            "语言模型",
            "模仿学习",
            "场景图"
        ],
        "涉及的技术概念": {
            "场景图": "用于挖掘非平行数据集中的大致平行表达，帮助模型理解句子结构和内容",
            "最大似然估计（MLE）训练": "用于初步训练模型，优化模型参数以最大化数据的似然概率",
            "模仿学习": "在MLE训练之后进一步细化模型，通过模仿高质量的表达来提升模型的性能"
        },
        "success": true
    },
    {
        "order": 678,
        "title": "Non-Transferable Learning: A New Approach for Model Ownership Verification and Applicability Authorization",
        "html": "https://iclr.cc//virtual/2022/poster/6143",
        "abstract": "As Artificial Intelligence as a Service gains popularity, protecting well-trained models as intellectual property is becoming increasingly important. There are two common types of protection methods: ownership verification and usage authorization. In this paper, we propose Non-Transferable Learning (NTL), a novel approach that captures the exclusive data representation in the learned model and restricts the model generalization ability to certain domains. This approach provides effective solutions to both model verification and authorization. Specifically: 1) For ownership verification, watermarking techniques are commonly used but are often vulnerable to sophisticated watermark removal methods. By comparison, our NTL-based ownership verification provides robust resistance to state-of-the-art watermark removal methods, as shown in extensive experiments with 6 removal approaches over the digits, CIFAR10 & STL10, and VisDA datasets. 2) For usage authorization, prior solutions focus on authorizing specific users to access the model, but authorized users can still apply the model to any data without restriction. Our NTL-based authorization approach instead provides data-centric protection, which we call applicability authorization, by significantly degrading the performance of the model on unauthorized data. Its effectiveness is also shown through experiments on aforementioned datasets. ",
        "conference": "ICLR",
        "中文标题": "不可迁移学习：模型所有权验证与适用性授权的新方法",
        "摘要翻译": "随着人工智能即服务的普及，保护训练有素的模型作为知识产权变得越来越重要。常见的保护方法有两种：所有权验证和使用授权。本文提出了一种新方法——不可迁移学习（NTL），它能够捕捉学习模型中的独家数据表示，并限制模型在特定领域的泛化能力。这种方法为模型验证和授权提供了有效的解决方案。具体来说：1）对于所有权验证，水印技术虽然常用，但往往容易受到复杂水印去除方法的攻击。相比之下，我们基于NTL的所有权验证提供了对最新水印去除方法的强大抵抗力，如在数字、CIFAR10和STL10以及VisDA数据集上进行的6种去除方法的广泛实验所示。2）对于使用授权，先前的解决方案侧重于授权特定用户访问模型，但授权用户仍然可以无限制地将模型应用于任何数据。我们的基于NTL的授权方法通过显著降低模型在未授权数据上的性能，提供了以数据为中心的保护，我们称之为适用性授权。其有效性也在上述数据集的实验中得到了展示。",
        "领域": "模型保护、深度学习安全、知识产权保护",
        "问题": "如何有效保护训练好的AI模型不被未经授权使用或复制",
        "动机": "随着AI服务的普及，保护模型知识产权和限制其使用范围变得尤为重要",
        "方法": "提出不可迁移学习（NTL）方法，通过限制模型的泛化能力来实现模型所有权验证和适用性授权",
        "关键词": [
            "不可迁移学习",
            "模型所有权验证",
            "适用性授权",
            "深度学习安全",
            "知识产权保护"
        ],
        "涉及的技术概念": {
            "不可迁移学习（NTL）": "一种新方法，通过捕捉模型的独家数据表示并限制其泛化能力，用于模型所有权验证和适用性授权",
            "所有权验证": "验证模型所有权的方法，基于NTL的方法比传统水印技术更抗攻击",
            "适用性授权": "一种以数据为中心的保护方法，通过NTL限制模型在未授权数据上的性能，实现使用授权"
        },
        "success": true
    },
    {
        "order": 679,
        "title": "No One Representation to Rule Them All: Overlapping Features of Training Methods",
        "html": "https://iclr.cc//virtual/2022/poster/6754",
        "abstract": "Despite being able to capture a range of features of the data, high accuracy models trained with supervision tend to make similar predictions. This seemingly implies that high-performing models share similar biases regardless of training methodology, which would limit ensembling benefits and render low-accuracy models as having little practical use. Against this backdrop, recent work has developed quite different training techniques, such as large-scale contrastive learning, yielding competitively high accuracy on generalization and robustness benchmarks. This motivates us to revisit the assumption that models necessarily learn similar functions. We conduct a large-scale empirical study of models across hyper-parameters, architectures, frameworks, and datasets. We find that model pairs that diverge more in training methodology display categorically different generalization behavior, producing increasingly uncorrelated errors. We show these models specialize in subdomains of the data, leading to higher ensemble performance: with just 2 models (each with ImageNet accuracy \\~76.5\\%), we can create ensembles with 83.4\\% (+7\\% boost). Surprisingly, we find that even significantly low-accuracy models can be used to improve high-accuracy models. Finally, we show diverging training methodology yield representations that capture overlapping (but not supersetting) feature sets which, when combined, lead to increased downstream performance.",
        "conference": "ICLR",
        "中文标题": "没有一种表征能统治一切：训练方法的重叠特征",
        "摘要翻译": "尽管能够捕捉数据的多种特征，通过监督学习训练的高准确度模型往往做出相似的预测。这似乎意味着无论采用何种训练方法，高性能模型都共享相似的偏差，这将限制集成学习的益处，并使低准确度模型几乎没有实际用途。在此背景下，最近的研究开发了相当不同的训练技术，如大规模对比学习，在泛化性和鲁棒性基准测试中取得了竞争性的高准确度。这促使我们重新审视模型必然学习相似功能的假设。我们对模型进行了大规模实证研究，涵盖了超参数、架构、框架和数据集。我们发现，训练方法差异更大的模型对显示出截然不同的泛化行为，产生越来越不相关的错误。我们展示这些模型在数据的子领域中专门化，从而带来更高的集成性能：仅用两个模型（每个模型的ImageNet准确度约为76.5%），我们可以创建准确度达到83.4%（提升7%）的集成。令人惊讶的是，我们发现即使是显著低准确度的模型也可以用来提高高准确度模型的性能。最后，我们展示了不同的训练方法产生的表征捕捉了重叠（但不超集）的特征集，当这些特征集被结合时，会提高下游性能。",
        "领域": "深度学习模型集成、对比学习、模型泛化性研究",
        "问题": "高性能模型在训练过程中倾向于学习相似的功能，限制了模型集成的效果和低准确度模型的实用性。",
        "动机": "探索不同训练方法是否能产生具有不同泛化行为的模型，以提高模型集成的性能和低准确度模型的价值。",
        "方法": "通过大规模实证研究，分析不同超参数、架构、框架和数据集下模型的泛化行为，并研究模型集成对性能的影响。",
        "关键词": [
            "模型集成",
            "对比学习",
            "泛化性",
            "训练方法",
            "表征学习"
        ],
        "涉及的技术概念": {
            "对比学习": "用于开发与监督学习不同的训练技术，以提高模型的泛化性和鲁棒性。",
            "模型集成": "通过结合多个模型的预测来提高整体性能，特别是在模型具有不相关错误时效果更佳。",
            "表征学习": "研究不同训练方法如何捕捉数据的重叠特征集，以及这些特征集如何影响下游任务的性能。"
        },
        "success": true
    },
    {
        "order": 680,
        "title": "No Parameters Left Behind: Sensitivity Guided Adaptive Learning Rate for Training Large Transformer Models",
        "html": "https://iclr.cc//virtual/2022/poster/6667",
        "abstract": "Recent research has shown the existence of significant redundancy in large Transformer models. One can prune the redundant parameters without significantly sacrificing the generalization performance. However, we question whether the redundant parameters could have contributed more if they were properly trained. To answer this question, we propose a novel training strategy that encourages all parameters to be trained sufficiently. Specifically, we adaptively adjust the learning rate for each parameter according to its sensitivity, a robust gradient-based measure reflecting this parameter's contribution to the model performance. A parameter with low sensitivity is redundant, and we improve its fitting by increasing its learning rate. In contrast, a parameter with high sensitivity is well-trained, and we regularize it by decreasing its learning rate to prevent further overfitting. We conduct extensive experiments on natural language understanding, neural machine translation, and image classification to demonstrate the effectiveness of the proposed schedule. Analysis shows that the proposed schedule indeed reduces the redundancy and improves generalization performance.",
        "conference": "ICLR",
        "中文标题": "无参数被遗忘：基于敏感度指导的自适应学习率用于训练大型Transformer模型",
        "摘要翻译": "最近的研究表明，大型Transformer模型存在显著的冗余性。人们可以在不明显牺牲泛化性能的情况下修剪冗余参数。然而，我们质疑如果这些冗余参数得到适当训练，它们是否能够做出更多贡献。为了回答这个问题，我们提出了一种新颖的训练策略，鼓励所有参数得到充分训练。具体来说，我们根据每个参数的敏感度自适应地调整其学习率，敏感度是一种基于梯度的鲁棒性度量，反映了该参数对模型性能的贡献。敏感度低的参数是冗余的，我们通过增加其学习率来提高其拟合度。相反，敏感度高的参数训练良好，我们通过降低其学习率来正则化它，以防止进一步的过拟合。我们在自然语言理解、神经机器翻译和图像分类上进行了大量实验，以证明所提出计划的有效性。分析表明，所提出的计划确实减少了冗余并提高了泛化性能。",
        "领域": "自然语言处理与视觉结合, 神经机器翻译, 图像分类",
        "问题": "如何有效训练大型Transformer模型中的冗余参数以提高模型性能",
        "动机": "探索冗余参数在适当训练条件下对模型性能的潜在贡献，并提出一种训练策略以充分利用这些参数",
        "方法": "提出一种基于参数敏感度的自适应学习率调整策略，通过增加冗余参数的学习率和降低敏感参数的学习率来优化模型训练",
        "关键词": [
            "Transformer模型",
            "自适应学习率",
            "参数敏感度",
            "模型冗余",
            "泛化性能"
        ],
        "涉及的技术概念": {
            "敏感度": "一种基于梯度的鲁棒性度量，用于评估参数对模型性能的贡献程度",
            "自适应学习率": "根据参数的敏感度动态调整学习率，以优化参数训练过程",
            "模型冗余": "指模型中存在的不对最终性能产生显著影响的参数，通过适当训练可提高其贡献"
        },
        "success": true
    },
    {
        "order": 681,
        "title": "Normalization of Language Embeddings for Cross-Lingual Alignment",
        "html": "https://iclr.cc//virtual/2022/poster/6548",
        "abstract": "Learning a good transfer function to map the word vectors from two languages into a shared cross-lingual word vector space plays a crucial role in cross-lingual NLP. It is useful in translation tasks and important in allowing complex models built on a high-resource language like English to be directly applied on an aligned low resource language.  While Procrustes and other techniques can align language models with some success, it has recently been identified that structural differences (for instance, due to differing word frequency) create different profiles for various monolingual embedding. When these profiles differ across languages, it correlates with how well languages can align and their performance on cross-lingual downstream tasks.  In this work, we develop a very general language embedding normalization procedure, building and subsuming various previous approaches, which removes these structural profiles across languages without destroying their intrinsic meaning.  We demonstrate that meaning is retained and alignment is improved on similarity, translation, and cross-language classification tasks.  Our proposed normalization clearly outperforms all prior approaches like centering and vector normalization on each task and with each alignment approach. ",
        "conference": "ICLR",
        "中文标题": "语言嵌入的归一化用于跨语言对齐",
        "摘要翻译": "学习一个良好的转移函数，将两种语言的词向量映射到一个共享的跨语言词向量空间，在跨语言自然语言处理中扮演着至关重要的角色。这对于翻译任务非常有用，并且对于允许建立在像英语这样的高资源语言上的复杂模型直接应用于对齐的低资源语言上非常重要。虽然Procrustes和其他技术可以成功地对齐语言模型，但最近已经发现，结构差异（例如，由于不同的词频）为各种单语嵌入创造了不同的轮廓。当这些轮廓在不同语言之间存在差异时，它与语言对齐的好坏以及它们在跨语言下游任务上的表现相关。在这项工作中，我们开发了一个非常通用的语言嵌入归一化程序，构建并包含了各种先前的方法，这些方法消除了跨语言的结构轮廓，而不破坏它们的内在意义。我们证明了意义被保留，并且在相似性、翻译和跨语言分类任务上的对齐得到了改善。我们提出的归一化方法在每个任务和每种对齐方法上都明显优于所有先前的方法，如居中和向量归一化。",
        "领域": "自然语言处理与视觉结合, 跨语言学习, 词向量表示",
        "问题": "解决跨语言词向量对齐中由于结构差异导致的对齐效果不佳的问题",
        "动机": "提高跨语言词向量对齐的效果，使得基于高资源语言构建的模型能够更好地应用于低资源语言",
        "方法": "开发了一种通用的语言嵌入归一化程序，消除跨语言的结构轮廓而不破坏其内在意义",
        "关键词": [
            "跨语言对齐",
            "词向量归一化",
            "语言嵌入",
            "结构差异",
            "下游任务"
        ],
        "涉及的技术概念": {
            "语言嵌入归一化": "消除跨语言的结构轮廓，而不破坏其内在意义的技术",
            "Procrustes技术": "一种用于语言模型对齐的技术",
            "跨语言词向量空间": "共享的词向量空间，用于映射不同语言的词向量"
        },
        "success": true
    },
    {
        "order": 682,
        "title": "OBJECT DYNAMICS DISTILLATION FOR SCENE DECOMPOSITION AND REPRESENTATION",
        "html": "https://iclr.cc//virtual/2022/poster/6826",
        "abstract": "The ability to perceive scenes in terms of abstract entities is crucial for us toachieve higher-level intelligence. Recently, several methods have been proposedto learn object-centric representations of scenes with multiple objects, yet mostof which focus on static scenes. In this paper, we work on object dynamics andpropose Object Dynamics Distillation Network (ODDN), a framework that distillates explicit object dynamics (e.g., velocity) from sequential static representations. ODDN also builds a relation module to model object interactions. We verifyour approach on tasks of video reasoning and video prediction, which are two important evaluations for video understanding. The results show that the reasoningmodel with visual representations of ODDN performs better in answering reasoning questions around physical events in a video compared to the previous state-of-the-art methods. The distilled object dynamics also could be used to predictfuture video frames given two input frames, involving occlusion and objects collision. In addition, our architecture brings better segmentation quality and higherreconstruction accuracy.",
        "conference": "ICLR",
        "中文标题": "物体动态蒸馏用于场景分解与表示",
        "摘要翻译": "以抽象实体感知场景的能力对我们实现更高层次的智能至关重要。最近，已有几种方法被提出来学习包含多个物体的场景的物体中心表示，但大多数方法都集中在静态场景上。在本文中，我们致力于物体动态，并提出了物体动态蒸馏网络（ODDN），这是一个从序列静态表示中蒸馏出显式物体动态（如速度）的框架。ODDN还构建了一个关系模块来建模物体间的相互作用。我们在视频推理和视频预测这两个对视频理解至关重要的评估任务上验证了我们的方法。结果表明，与之前的最先进方法相比，使用ODDN视觉表示的推理模型在回答围绕视频中物理事件的推理问题时表现更好。蒸馏出的物体动态也可以用于在给定两帧输入帧的情况下预测未来的视频帧，包括遮挡和物体碰撞。此外，我们的架构带来了更好的分割质量和更高的重建准确性。",
        "领域": "视频理解、物体动态建模、场景分解",
        "问题": "如何从静态场景表示中提取和利用物体动态信息以提升视频理解和预测的能力",
        "动机": "探索物体动态信息在视频理解和预测任务中的重要性，以及如何有效提取和利用这些信息",
        "方法": "提出物体动态蒸馏网络（ODDN），通过从序列静态表示中蒸馏出显式物体动态，并构建关系模块来建模物体间的相互作用",
        "关键词": [
            "物体动态蒸馏",
            "场景分解",
            "视频推理",
            "视频预测",
            "物体交互"
        ],
        "涉及的技术概念": {
            "物体动态蒸馏": "从序列静态表示中提取显式物体动态（如速度）的过程，用于提升视频理解和预测的能力",
            "关系模块": "建模物体间相互作用的模块，帮助理解物体在动态场景中的行为",
            "视频推理": "利用提取的物体动态信息回答围绕视频中物理事件的推理问题，评估模型对视频内容的理解能力"
        },
        "success": true
    },
    {
        "order": 683,
        "title": "Object Pursuit: Building a Space of Objects via Discriminative Weight Generation",
        "html": "https://iclr.cc//virtual/2022/poster/6713",
        "abstract": "We propose a framework to continuously learn object-centric representations for visual learning and understanding. Existing object-centric representations either rely on supervisions that individualize objects in the scene, or perform unsupervised disentanglement that can hardly deal with complex scenes in the real world. To mitigate the annotation burden and relax the constraints on the statistical complexity of the data, our method leverages interactions to effectively sample diverse variations of an object and the corresponding training signals while learning the object-centric representations. Throughout learning, objects are streamed one by one in random order with unknown identities, and are associated with latent codes that can synthesize discriminative weights for each object through a convolutional hypernetwork. Moreover, re-identification of learned objects and forgetting prevention are employed to make the learning process efficient and robust. We perform an extensive study of the key features of the proposed framework and analyze the characteristics of the learned representations. Furthermore, we demonstrate the capability of the proposed framework in learning representations that can improve label efficiency in downstream tasks. Our code and trained models are made publicly available at: https://github.com/pptrick/Object-Pursuit.",
        "conference": "ICLR",
        "中文标题": "物体追踪：通过判别性权重生成构建物体空间",
        "摘要翻译": "我们提出了一个框架，用于持续学习以物体为中心的表示，以支持视觉学习和理解。现有的以物体为中心的表示要么依赖于对场景中物体个体化的监督，要么执行难以处理现实世界中复杂场景的无监督解缠。为了减轻标注负担并放松对数据统计复杂性的限制，我们的方法利用交互作用，在学习以物体为中心的表示时，有效地采样物体的多样变化及相应的训练信号。在整个学习过程中，物体以随机顺序和未知身份逐一流入，并与潜在代码相关联，这些代码可以通过卷积超网络为每个物体合成判别性权重。此外，采用已学习物体的重新识别和遗忘预防，使学习过程既高效又稳健。我们对所提出框架的关键特征进行了广泛研究，并分析了学习表示的特性。此外，我们还展示了所提出框架在学习能够提高下游任务标签效率的表示方面的能力。我们的代码和训练模型已在https://github.com/pptrick/Object-Pursuit公开提供。",
        "领域": "物体中心表示学习、无监督学习、视觉理解",
        "问题": "如何在减轻标注负担和放松数据统计复杂性限制的同时，持续学习有效的以物体为中心的视觉表示。",
        "动机": "解决现有物体中心表示学习方法依赖强监督或难以处理复杂场景的问题，通过交互学习和潜在代码关联，实现高效稳健的物体表示学习。",
        "方法": "利用交互作用采样物体变化和训练信号，通过卷积超网络为每个物体合成判别性权重，结合重新识别和遗忘预防机制优化学习过程。",
        "关键词": [
            "物体中心表示",
            "无监督学习",
            "卷积超网络",
            "判别性权重",
            "视觉理解"
        ],
        "涉及的技术概念": {
            "卷积超网络": "用于为每个物体合成判别性权重，支持物体特定表示的生成。",
            "潜在代码": "与物体相关联，用于在超网络中生成特定于该物体的权重，实现物体表示的个性化。",
            "重新识别与遗忘预防": "确保学习过程中对已学习物体的有效记忆和防止遗忘，提高学习效率和稳健性。"
        },
        "success": true
    },
    {
        "order": 684,
        "title": "Objects in Semantic Topology",
        "html": "https://iclr.cc//virtual/2022/poster/6223",
        "abstract": "A more realistic object detection paradigm, Open-World Object Detection, has arised increasing research interests in the community recently. A qualified open-world object detector can not only identify objects of known categories, but also discover unknown objects, and incrementally learn to categorize them when their annotations progressively arrive. Previous works rely on independent modules to recognize unknown categories and perform incremental learning, respectively. In this paper, we provide a unified perspective: Semantic Topology. During the life-long learning of an open-world object detector, all object instances from the same category are assigned to their corresponding pre-defined node in the semantic topology, including the `unknown' category. This constraint builds up discriminative feature representations and consistent relationships among objects, thus enabling the detector to distinguish unknown objects out of the known categories, as well as making learned features of known objects undistorted when learning new categories incrementally. Extensive experiments demonstrate that semantic topology, either randomly-generated or derived from a well-trained language model, could outperform the current state-of-the-art open-world object detectors by a large margin, e.g., the absolute open-set error (the number of unknown instances that are wrongly labeled as known) is reduced from 7832 to 2546, exhibiting the inherent superiority of semantic topology on open-world object detection.",
        "conference": "ICLR",
        "中文标题": "语义拓扑中的对象",
        "摘要翻译": "一个更现实的物体检测范式，开放世界物体检测，最近在社区中引起了越来越多的研究兴趣。一个合格的开放世界物体检测器不仅能识别已知类别的物体，还能发现未知物体，并在其注释逐渐到达时逐步学习对它们进行分类。以前的工作依赖于独立的模块来分别识别未知类别和执行增量学习。在本文中，我们提供了一个统一的视角：语义拓扑。在开放世界物体检测器的终身学习过程中，来自同一类别的所有物体实例都被分配到语义拓扑中对应的预定义节点，包括‘未知’类别。这种约束建立了物体之间的区分性特征表示和一致关系，从而使检测器能够区分已知类别之外的未知物体，以及在增量学习新类别时不扭曲已知物体的学习特征。大量实验表明，无论是随机生成的还是从训练良好的语言模型导出的语义拓扑，都可以大幅超越当前最先进的开放世界物体检测器，例如，绝对开放集错误（被错误标记为已知的未知实例数量）从7832减少到2546，展示了语义拓扑在开放世界物体检测上的固有优势。",
        "领域": "开放世界物体检测",
        "问题": "如何在开放世界物体检测中识别未知物体并增量学习新类别",
        "动机": "解决开放世界物体检测中识别未知物体和增量学习新类别的挑战",
        "方法": "提出语义拓扑的统一视角，通过将物体实例分配到语义拓扑中的预定义节点来建立区分性特征表示和一致关系",
        "关键词": [
            "开放世界物体检测",
            "语义拓扑",
            "增量学习"
        ],
        "涉及的技术概念": {
            "语义拓扑": "用于在开放世界物体检测中建立物体之间的区分性特征表示和一致关系的结构",
            "开放世界物体检测": "一种物体检测范式，旨在识别已知类别的物体并发现未知物体",
            "增量学习": "在模型已经学习了一定知识的基础上，继续学习新知识而不忘记旧知识的技术"
        },
        "success": true
    },
    {
        "order": 685,
        "title": "Offline Neural Contextual Bandits: Pessimism, Optimization and Generalization",
        "html": "https://iclr.cc//virtual/2022/poster/7136",
        "abstract": "Offline policy learning (OPL) leverages existing data collected a priori for policy optimization without any active exploration. Despite the prevalence and recent interest in this problem, its theoretical and algorithmic foundations in function approximation settings remain under-developed. In this paper, we consider this problem on the axes of distributional shift, optimization, and generalization in offline contextual bandits with neural networks. In particular, we propose a provably efficient offline contextual bandit with neural network function approximation that does not require any functional assumption on the reward. We show that our method provably generalizes over unseen contexts under a milder condition for distributional shift than the existing OPL works. Notably, unlike any other OPL method, our method learns from the offline data in an online manner using stochastic gradient descent, allowing us to leverage the benefits of online learning into an offline setting. Moreover, we show that our method is more computationally efficient and has a better dependence on the effective dimension of the neural network than an online counterpart. Finally, we demonstrate the empirical effectiveness of our method in a range of synthetic and real-world OPL problems.",
        "conference": "ICLR",
        "中文标题": "离线神经上下文赌博机：悲观主义、优化与泛化",
        "摘要翻译": "离线策略学习（OPL）利用事先收集的现有数据进行策略优化，无需任何主动探索。尽管这一问题普遍存在且近期受到关注，但在函数近似设置下的理论和算法基础仍不完善。在本文中，我们从分布偏移、优化和泛化的角度考虑了离线上下文赌博机与神经网络的问题。特别是，我们提出了一种可证明高效的离线上下文赌博机方法，该方法采用神经网络函数近似，且不需要对奖励函数做任何功能性假设。我们表明，在比现有OPL工作更温和的分布偏移条件下，我们的方法能够对未见过的上下文进行泛化。值得注意的是，与任何其他OPL方法不同，我们的方法通过随机梯度下降以在线方式从离线数据中学习，从而将在线学习的优势引入离线设置。此外，我们表明，与在线对应方法相比，我们的方法在计算上更高效，并且对神经网络的有效维度有更好的依赖性。最后，我们在一系列合成和真实世界的OPL问题中展示了我们方法的实证有效性。",
        "领域": "强化学习、离线学习、上下文赌博机",
        "问题": "在离线策略学习中，如何有效利用现有数据进行策略优化，同时处理分布偏移、优化和泛化问题。",
        "动机": "解决离线策略学习在函数近似设置下理论和算法基础不足的问题，特别是在神经网络中的应用。",
        "方法": "提出了一种基于神经网络的离线上下文赌博机方法，通过随机梯度下降以在线方式学习，无需对奖励函数做任何功能性假设。",
        "关键词": [
            "离线策略学习",
            "上下文赌博机",
            "神经网络",
            "随机梯度下降",
            "分布偏移"
        ],
        "涉及的技术概念": {
            "离线策略学习（OPL）": "利用事先收集的数据进行策略优化，无需主动探索。",
            "上下文赌博机": "一种强化学习框架，用于在特定上下文中做出决策以最大化奖励。",
            "随机梯度下降": "一种优化算法，用于在离线数据中以在线方式学习，提高计算效率和泛化能力。"
        },
        "success": true
    },
    {
        "order": 686,
        "title": "Offline Reinforcement Learning with Implicit Q-Learning",
        "html": "https://iclr.cc//virtual/2022/poster/5941",
        "abstract": "Offline reinforcement learning requires reconciling two conflicting aims: learning a policy that improves over the behavior policy that collected the dataset, while at the same time minimizing the deviation from the behavior policy so as to avoid errors due to distributional shift. This tradeoff is critical, because most current offline reinforcement learning methods need to query the value of unseen actions during training to improve the policy, and therefore need to either constrain these actions to be in-distribution, or else regularize their values. We propose a new offline RL method that never needs to evaluate actions outside of the dataset, but still enables the learned policy to improve substantially over the best behavior in the data through generalization. The main insight in our work is that, instead of evaluating unseen actions from the latest policy, we can approximate the policy improvement step implicitly by treating the state value function as a random variable, with randomness determined by the action (while still integrating over the dynamics to avoid excessive optimism), and then taking a state conditional upper expectile of this random variable to estimate the value of the best actions in that state. This leverages the generalization capacity of the function approximator to estimate the value of the best available action at a given state without ever directly querying a Q-function with this unseen action. Our algorithm alternates between fitting this upper expectile value function and backing it up into a Q-function, without any explicit policy. Then, we extract the policy via advantage-weighted behavioral cloning, which also avoids querying out-of-sample actions. We dub our method Implicit Q-learning (IQL).  IQL is easy to implement, computationally efficient, and only requires fitting an additional critic with an asymmetric L2 loss. IQL demonstrates the state-of-the-art performance on D4RL, a standard benchmark for offline reinforcement learning. We also demonstrate that IQL achieves strong performance fine-tuning using online interaction after offline initialization.",
        "conference": "ICLR",
        "中文标题": "隐式Q学习的离线强化学习",
        "摘要翻译": "离线强化学习需要调和两个相互冲突的目标：学习一个比收集数据集的行为策略有所改进的策略，同时最小化与行为策略的偏差，以避免由于分布偏移引起的错误。这种权衡至关重要，因为当前大多数离线强化学习方法在训练期间需要查询未见动作的价值以改进策略，因此需要将这些动作限制在分布内，或者对其价值进行正则化。我们提出了一种新的离线强化学习方法，该方法从不需要评估数据集之外的动作，但仍然能够通过学习到的策略在数据中通过泛化显著改进最佳行为。我们工作的主要见解是，与其评估来自最新策略的未见动作，我们可以通过将状态价值函数视为一个随机变量来隐式地近似策略改进步骤，随机性由动作决定（同时仍然对动态进行积分以避免过度乐观），然后取这个随机变量的状态条件上期望来估计该状态下最佳动作的价值。这利用了函数逼近器的泛化能力来估计给定状态下最佳可用动作的价值，而无需直接使用这个未见动作查询Q函数。我们的算法在拟合这个上期望价值函数和将其备份到Q函数之间交替进行，没有任何明确的策略。然后，我们通过优势加权行为克隆提取策略，这也避免了查询样本外动作。我们将我们的方法称为隐式Q学习（IQL）。IQL易于实现，计算效率高，并且只需要拟合一个带有非对称L2损失的额外评论家。IQL在D4RL（离线强化学习的标准基准）上展示了最先进的性能。我们还展示了IQL在离线初始化后使用在线交互进行微调时实现了强大的性能。",
        "领域": "强化学习、离线学习、策略优化",
        "问题": "如何在离线强化学习中改进策略而不评估未见动作以避免分布偏移引起的错误。",
        "动机": "解决离线强化学习中策略改进与避免分布偏移之间的冲突，提出一种不直接评估未见动作的方法。",
        "方法": "提出隐式Q学习（IQL）方法，通过将状态价值函数视为随机变量并利用上期望来估计最佳动作价值，避免直接查询未见动作的Q值。",
        "关键词": [
            "离线强化学习",
            "隐式Q学习",
            "策略改进",
            "分布偏移",
            "行为克隆"
        ],
        "涉及的技术概念": {
            "隐式Q学习（IQL）": "一种离线强化学习方法，通过隐式地近似策略改进步骤，避免直接评估未见动作。",
            "上期望": "用于估计随机变量（如状态价值函数）的上界期望，以隐式地评估最佳动作价值。",
            "优势加权行为克隆": "一种策略提取方法，通过加权行为克隆避免查询样本外动作，同时利用优势函数优化策略。"
        },
        "success": true
    },
    {
        "order": 687,
        "title": "Offline Reinforcement Learning with Value-based Episodic Memory",
        "html": "https://iclr.cc//virtual/2022/poster/6918",
        "abstract": "Offline reinforcement learning (RL) shows promise of applying RL to real-world problems by effectively utilizing previously collected data. Most existing offline RL algorithms use regularization or constraints to suppress extrapolation error for actions outside the dataset. In this paper, we adopt a different framework, which learns the V-function instead of the Q-function to naturally keep the learning procedure within the support of an offline dataset. To enable effective generalization while maintaining proper conservatism in offline learning, we propose Expectile V-Learning (EVL), which smoothly interpolates between the optimal value learning and behavior cloning. Further, we introduce implicit planning along offline trajectories to enhance learned V-values and accelerate convergence. Together, we present a new offline method called Value-based Episodic Memory (VEM). We provide theoretical analysis for the convergence properties of our proposed VEM method, and empirical results in the D4RL benchmark show that our method achieves superior performance in most tasks, particularly in sparse-reward tasks.",
        "conference": "ICLR",
        "中文标题": "基于价值的片段记忆的离线强化学习",
        "摘要翻译": "离线强化学习（RL）通过有效利用先前收集的数据，展现了将RL应用于现实世界问题的潜力。大多数现有的离线RL算法使用正则化或约束来抑制数据集中未包含动作的外推误差。在本文中，我们采用了一个不同的框架，该框架学习V函数而非Q函数，以自然地将学习过程保持在离线数据集的支持范围内。为了在离线学习中实现有效的泛化同时保持适当的保守性，我们提出了期望V学习（EVL），它在最优值学习和行为克隆之间平滑插值。此外，我们引入了沿离线轨迹的隐式规划，以增强学习的V值并加速收敛。综合这些，我们提出了一种名为基于价值的片段记忆（VEM）的新离线方法。我们为我们提出的VEM方法的收敛性质提供了理论分析，D4RL基准测试中的实证结果表明，我们的方法在大多数任务中实现了卓越的性能，特别是在稀疏奖励任务中。",
        "领域": "离线强化学习、深度强化学习、稀疏奖励任务",
        "问题": "如何在离线强化学习中有效利用先前收集的数据，同时抑制外推误差并保持适当的保守性。",
        "动机": "解决离线强化学习中的数据利用和外推误差问题，通过V函数学习保持学习过程在数据集支持范围内。",
        "方法": "提出期望V学习（EVL）方法，在最优值学习和行为克隆之间平滑插值，并引入沿离线轨迹的隐式规划以增强V值和加速收敛。",
        "关键词": [
            "离线强化学习",
            "V函数学习",
            "期望V学习",
            "隐式规划",
            "稀疏奖励任务"
        ],
        "涉及的技术概念": {
            "V函数学习": "论文中用于替代传统的Q函数学习，以自然地将学习过程保持在离线数据集的支持范围内。",
            "期望V学习（EVL）": "在最优值学习和行为克隆之间平滑插值的方法，旨在实现有效的泛化同时保持适当的保守性。",
            "隐式规划": "沿离线轨迹进行规划，以增强学习的V值并加速收敛的技术。"
        },
        "success": true
    },
    {
        "order": 688,
        "title": "Omni-Dimensional Dynamic Convolution",
        "html": "https://iclr.cc//virtual/2022/poster/6455",
        "abstract": "Learning a single static convolutional kernel in each convolutional layer is the common training paradigm of modern Convolutional Neural Networks (CNNs). Instead, recent research in dynamic convolution shows that learning a linear combination of n convolutional kernels weighted with their input-dependent attentions can significantly improve the accuracy of light-weight CNNs, while maintaining efficient inference. However, we observe that existing works endow convolutional kernels with the dynamic property through one dimension (regarding the convolutional kernel number) of the kernel space, but the other three dimensions (regarding the spatial size, the input channel number and the output channel number for each convolutional kernel) are overlooked. Inspired by this, we present Omni-dimensional Dynamic Convolution (ODConv), a more generalized yet elegant dynamic convolution design, to advance this line of research. ODConv leverages a novel multi-dimensional attention mechanism with a parallel strategy to learn complementary attentions for convolutional kernels along all four dimensions of the kernel space at any convolutional layer. As a drop-in replacement of regular convolutions, ODConv can be plugged into many CNN architectures. Extensive experiments on the ImageNet and MS-COCO datasets show that ODConv brings solid accuracy boosts for various prevailing CNN backbones including both light-weight and large ones, e.g., 3.77%~5.71%|1.86%~3.72% absolute top-1 improvements to MobivleNetV2|ResNet family on the ImageNet dataset. Intriguingly, thanks to its improved feature learning ability, ODConv with even one single kernel can compete with or outperform existing dynamic convolution counterparts with multiple kernels, substantially reducing extra parameters. Furthermore, ODConv is also superior to other attention modules for modulating the output features or the convolutional weights. Code and models will be available at https://github.com/OSVAI/ODConv.",
        "conference": "ICLR",
        "中文标题": "全维度动态卷积",
        "摘要翻译": "在现代卷积神经网络（CNNs）中，每个卷积层学习单一的静态卷积核是常见的训练范式。然而，动态卷积的最新研究表明，通过学习n个卷积核的线性组合，并根据输入依赖的注意力进行加权，可以显著提高轻量级CNNs的准确性，同时保持高效的推理。然而，我们观察到现有工作通过卷积核空间的一个维度（关于卷积核数量）赋予卷积核动态特性，但忽略了其他三个维度（关于空间大小、输入通道数和每个卷积核的输出通道数）。受此启发，我们提出了全维度动态卷积（ODConv），这是一种更通用且优雅的动态卷积设计，以推动这一研究方向。ODConv利用一种新颖的多维注意力机制与并行策略，学习卷积核在卷积层所有四个维度上的互补注意力。作为常规卷积的即插即用替代品，ODConv可以嵌入到许多CNN架构中。在ImageNet和MS-COCO数据集上的大量实验表明，ODConv为各种流行的CNN骨干网络（包括轻量级和大型网络）带来了显著的准确性提升，例如，在ImageNet数据集上，MobileNetV2|ResNet家族的绝对top-1改进为3.77%~5.71%|1.86%~3.72%。有趣的是，由于其改进的特征学习能力，即使只有一个卷积核的ODConv也可以与现有的具有多个卷积核的动态卷积相媲美或超越，大大减少了额外参数。此外，ODConv在调节输出特征或卷积权重方面也优于其他注意力模块。代码和模型将在https://github.com/OSVAI/ODConv上提供。",
        "领域": "动态卷积、轻量级神经网络、注意力机制",
        "问题": "如何通过动态卷积提高卷积神经网络的准确性和效率",
        "动机": "现有动态卷积方法仅关注卷积核数量的动态性，忽略了卷积核空间的其他三个维度，限制了性能提升的潜力",
        "方法": "提出全维度动态卷积（ODConv），通过多维注意力机制并行学习卷积核在所有四个维度上的动态特性",
        "关键词": [
            "全维度动态卷积",
            "多维注意力机制",
            "轻量级神经网络",
            "卷积核优化",
            "特征学习"
        ],
        "涉及的技术概念": {
            "全维度动态卷积": "一种新型动态卷积设计，通过多维注意力机制同时优化卷积核的多个维度特性",
            "多维注意力机制": "用于并行学习卷积核在空间大小、输入输出通道数等多个维度上的动态权重",
            "轻量级神经网络": "ODConv特别适用于轻量级CNN架构，能在保持高效推理的同时显著提升模型准确性"
        },
        "success": true
    },
    {
        "order": 689,
        "title": "Omni-Scale CNNs: a simple and effective kernel size configuration for time series classification",
        "html": "https://iclr.cc//virtual/2022/poster/7148",
        "abstract": "The size of the receptive field has been one of the most important factors for One Dimensional Convolutional Neural Networks (1D-CNNs) on time series classification tasks. Large efforts have been taken to choose the appropriate receptive field size, for it has a huge influence on the performance and differs significantly for each dataset. In this paper, we propose an Omni-Scale block (OS-block) for 1D-CNNs, where the kernel sizes are set by a simple and universal rule. OS-block can efficiently cover the best size of the receptive field across different datasets. This set of kernel sizes consists of multiple prime numbers according to the length of the time series. We experimentally show 1D-CNNs built from OS-block can consistently achieve the state-of-the-art accuracy with a smaller model size on five time series benchmarks, including both univariate and multivariate data from multiple domains. Comprehensive analysis and ablation studies shed light on how our rule finds the best receptive field size and demonstrate the consistency of our OS-block for multiple 1D-CNN structures.",
        "conference": "ICLR",
        "中文标题": "全尺度卷积神经网络：一种简单有效的时间序列分类核大小配置方法",
        "摘要翻译": "感受野的大小对于一维卷积神经网络（1D-CNNs）在时间序列分类任务中一直是最重要的因素之一。为了选择适当的感受野大小，人们付出了巨大的努力，因为它对性能有着巨大影响，并且对于每个数据集都有显著差异。在本文中，我们为1D-CNNs提出了一种全尺度块（OS-block），其中核大小由一个简单且通用的规则设置。OS-block能够有效地覆盖不同数据集上最佳的感受野大小。这组核大小根据时间序列的长度由多个素数组成。我们通过实验证明，由OS-block构建的1D-CNNs在五个时间序列基准测试中，包括来自多个领域的单变量和多变量数据，能够以较小的模型大小一致地达到最先进的准确率。全面的分析和消融研究揭示了我们的规则如何找到最佳的感受野大小，并证明了我们的OS-block对于多种1D-CNN结构的一致性。",
        "领域": "时间序列分类、一维卷积神经网络、深度学习模型优化",
        "问题": "如何为一维卷积神经网络（1D-CNNs）在时间序列分类任务中选择合适的感受野大小",
        "动机": "感受野大小对1D-CNNs的性能有巨大影响，且不同数据集间差异显著，需要一种简单通用的方法来配置核大小",
        "方法": "提出全尺度块（OS-block），通过一组根据时间序列长度由多个素数组成的核大小，有效覆盖不同数据集的最佳感受野大小",
        "关键词": [
            "全尺度卷积神经网络",
            "时间序列分类",
            "感受野大小",
            "一维卷积神经网络",
            "模型优化"
        ],
        "涉及的技术概念": {
            "全尺度块（OS-block）": "一种为1D-CNNs设计的块结构，通过一组素数核大小有效覆盖不同数据集的最佳感受野大小",
            "感受野大小": "影响1D-CNNs性能的关键因素，不同数据集间差异显著",
            "一维卷积神经网络（1D-CNNs）": "用于时间序列分类任务的深度学习模型，本文通过OS-block优化其核大小配置"
        },
        "success": true
    },
    {
        "order": 690,
        "title": "On Bridging Generic and Personalized Federated Learning for Image Classification",
        "html": "https://iclr.cc//virtual/2022/poster/6129",
        "abstract": "Federated learning is promising for its capability to collaboratively train models with multiple clients without accessing their data, but vulnerable when clients' data distributions diverge from each other. This divergence further leads to a dilemma: 'Should we prioritize the learned model's generic performance (for future use at the server) or its personalized performance (for each client)?' These two, seemingly competing goals have divided the community to focus on one or the other, yet in this paper we show that it is possible to approach both at the same time. Concretely, we propose a novel federated learning framework that explicitly decouples a model's dual duties with two prediction tasks. On the one hand, we introduce a family of losses that are robust to non-identical class distributions, enabling clients to train a generic predictor with a consistent objective across them. On the other hand, we formulate the personalized predictor as a lightweight adaptive module that is learned to minimize each client's empirical risk on top of the generic predictor. With this two-loss, two-predictor framework which we name Federated Robust Decoupling (Fed-RoD), the learned model can simultaneously achieve state-of-the-art generic and personalized performance, essentially bridging the two tasks. ",
        "conference": "ICLR",
        "中文标题": "关于桥接通用与个性化联邦学习在图像分类中的应用",
        "摘要翻译": "联邦学习因其能够在无需访问客户端数据的情况下与多个客户端协同训练模型而备受期待，但当客户端的数据分布彼此不同时，它显得脆弱。这种差异进一步导致了一个困境：'我们应该优先考虑学习模型的通用性能（供服务器未来使用）还是其个性化性能（为每个客户端）？'这两个看似相互竞争的目标使得研究社区专注于其中之一，然而在本文中，我们展示了同时接近这两个目标是可能的。具体来说，我们提出了一种新颖的联邦学习框架，该框架通过两个预测任务明确解耦模型的双重职责。一方面，我们引入了一系列对非相同类别分布具有鲁棒性的损失函数，使客户端能够以一致的客观性训练一个通用预测器。另一方面，我们将个性化预测器制定为一个轻量级的自适应模块，该模块在通用预测器的基础上学习以最小化每个客户端的经验风险。通过这个我们命名为联邦鲁棒解耦（Fed-RoD）的双损失、双预测器框架，学习模型可以同时实现最先进的通用和个性化性能，本质上桥接了这两个任务。",
        "领域": "联邦学习、图像分类、个性化学习",
        "问题": "解决联邦学习中通用性能与个性化性能之间的权衡问题",
        "动机": "研究旨在同时优化联邦学习模型的通用性能和个性化性能，以克服数据分布差异带来的挑战",
        "方法": "提出了一种名为联邦鲁棒解耦（Fed-RoD）的框架，通过解耦模型的通用和个性化职责，使用双损失和双预测器的方法来同时优化两种性能",
        "关键词": [
            "联邦学习",
            "个性化学习",
            "图像分类",
            "鲁棒性",
            "解耦学习"
        ],
        "涉及的技术概念": {
            "联邦鲁棒解耦（Fed-RoD）": "一种新颖的联邦学习框架，通过解耦模型的通用和个性化职责，使用双损失和双预测器的方法来同时优化两种性能",
            "非相同类别分布的鲁棒性损失": "一系列损失函数，旨在使客户端能够以一致的客观性训练一个通用预测器，即使数据分布不同",
            "轻量级自适应模块": "个性化预测器的一种实现方式，作为通用预测器之上的一个轻量级模块，旨在最小化每个客户端的经验风险"
        },
        "success": true
    },
    {
        "order": 691,
        "title": "On Covariate Shift of Latent Confounders in Imitation and Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2022/poster/7100",
        "abstract": "We consider the problem of using expert data with unobserved confounders for imitation and reinforcement learning. We begin by defining the problem of learning from confounded expert data in a contextual MDP setup. We analyze the limitations of learning from such data with and without external reward and propose an adjustment of standard imitation learning algorithms to fit this setup. In addition, we discuss the problem of distribution shift between the expert data and the online environment when partial observability is present in the data. We prove possibility and impossibility results for imitation learning under arbitrary distribution shift of the missing covariates. When additional external reward is provided, we propose a sampling procedure that addresses the unknown shift and prove convergence to an optimal solution. Finally, we validate our claims empirically on challenging assistive healthcare and recommender system simulation tasks.",
        "conference": "ICLR",
        "中文标题": "论模仿与强化学习中潜在混杂因素的协变量偏移",
        "摘要翻译": "我们考虑了在模仿学习和强化学习中使用具有未观测混杂因素的专家数据的问题。首先，我们在上下文MDP设置中定义了从混杂专家数据中学习的问题。我们分析了在有和没有外部奖励的情况下从此类数据中学习的局限性，并提出了调整标准模仿学习算法以适应此设置的方法。此外，我们讨论了当数据中存在部分可观测性时，专家数据与在线环境之间的分布偏移问题。我们证明了在缺失协变量任意分布偏移下模仿学习的可能性和不可能性结果。当提供额外的外部奖励时，我们提出了一种解决未知偏移的采样程序，并证明了收敛于最优解。最后，我们在具有挑战性的辅助医疗和推荐系统模拟任务上实证验证了我们的主张。",
        "领域": "模仿学习, 强化学习, 推荐系统",
        "问题": "解决在模仿学习和强化学习中使用具有未观测混杂因素的专家数据时遇到的协变量偏移问题",
        "动机": "研究如何有效利用混杂专家数据进行学习，特别是在存在部分可观测性和分布偏移的情况下",
        "方法": "调整标准模仿学习算法以处理混杂数据，提出解决未知偏移的采样程序，并验证方法的有效性",
        "关键词": [
            "协变量偏移",
            "模仿学习",
            "强化学习",
            "混杂因素",
            "分布偏移"
        ],
        "涉及的技术概念": {
            "混杂因素": "在数据分析中，混杂因素是指那些未被观测到但影响结果和预测变量之间关系的变量",
            "协变量偏移": "指训练数据和测试数据中协变量的分布不同，但在给定协变量的条件下输出的条件分布相同的情况",
            "模仿学习": "一种通过模仿专家行为来学习策略的机器学习方法"
        },
        "success": true
    },
    {
        "order": 692,
        "title": "On Distributed Adaptive Optimization with Gradient Compression",
        "html": "https://iclr.cc//virtual/2022/poster/6171",
        "abstract": "We study COMP-AMS, a distributed optimization framework based on gradient averaging and adaptive AMSGrad algorithm. Gradient compression with error feedback is applied to reduce the communication cost in the gradient transmission process. Our convergence analysis of COMP-AMS shows that such compressed gradient averaging strategy yields same convergence rate as standard AMSGrad, and also exhibits linear speedup effect w.r.t. the number of local workers. Compared with recently proposed protocols on distributed adaptive methods, COMP-AMS is simple and convenient. Numerical experiments are conducted to justify the theoretical findings, and demonstrate that the proposed method can achieve same test accuracy as full-gradient AMSGrad with substantial communication savings. With its simplicity and efficiency, COMP-AMS can serve as a useful distributed training framework for adaptive methods.",
        "conference": "ICLR",
        "中文标题": "关于带有梯度压缩的分布式自适应优化",
        "摘要翻译": "我们研究了COMP-AMS，一个基于梯度平均和自适应AMSGrad算法的分布式优化框架。应用带有误差反馈的梯度压缩以减少梯度传输过程中的通信成本。我们对COMP-AMS的收敛性分析表明，这种压缩梯度平均策略产生了与标准AMSGrad相同的收敛速率，并且相对于本地工作者的数量也表现出线性加速效应。与最近提出的分布式自适应方法协议相比，COMP-AMS简单且方便。进行了数值实验以证明理论发现，并证明所提出的方法可以在大幅节省通信的情况下实现与全梯度AMSGrad相同的测试精度。凭借其简单性和效率，COMP-AMS可以作为自适应方法的有用分布式训练框架。",
        "领域": "分布式优化、自适应优化算法、梯度压缩",
        "问题": "减少分布式优化中的通信成本，同时保持算法的收敛性和效率",
        "动机": "为了解决分布式优化中高通信成本的问题，同时保持或提升算法的性能",
        "方法": "结合梯度压缩和误差反馈技术，基于AMSGrad算法开发了COMP-AMS框架",
        "关键词": [
            "分布式优化",
            "梯度压缩",
            "AMSGrad",
            "误差反馈",
            "通信效率"
        ],
        "涉及的技术概念": {
            "梯度压缩": "用于减少梯度传输过程中的数据量，从而降低通信成本",
            "误差反馈": "在梯度压缩过程中应用，以补偿压缩带来的信息损失，保持算法的收敛性",
            "AMSGrad算法": "一种自适应优化算法，COMP-AMS框架基于此算法开发，用于保证优化过程的收敛性"
        },
        "success": true
    },
    {
        "order": 693,
        "title": "One After Another: Learning Incremental Skills for a Changing World",
        "html": "https://iclr.cc//virtual/2022/poster/6026",
        "abstract": "Reward-free, unsupervised discovery of skills is an attractive alternative to the bottleneck of hand-designing rewards in environments where task supervision is scarce or expensive. However, current skill pre-training methods, like many RL techniques, make a fundamental assumption -- stationary environments during training. Traditional methods learn all their skills simultaneously, which makes it difficult for them to both quickly adapt to changes in the environment, and to not forget earlier skills after such adaptation. On the other hand, in an evolving or expanding environment, skill learning must be able to adapt fast to new environment situations while not forgetting previously learned skills. These two conditions make it difficult for classic skill discovery to do well in an evolving environment. In this work, we propose a new framework for skill discovery, where skills are learned one after another in an incremental fashion. This framework allows newly learned skills to adapt to new environment or agent dynamics, while the fixed old skills ensure the agent doesn't forget a learned skill. We demonstrate experimentally that in both evolving and static environments, incremental skills significantly outperform current state-of-the-art skill discovery methods on both skill quality and the ability to solve downstream tasks. Videos for learned skills and code are made public on https://notmahi.github.io/disk",
        "conference": "ICLR",
        "中文标题": "一个接一个：学习适应变化世界的增量技能",
        "摘要翻译": "在任务监督稀缺或昂贵的环境中，无奖励、无监督的技能发现是手工设计奖励瓶颈的一个有吸引力的替代方案。然而，当前的技能预训练方法，像许多强化学习技术一样，做出了一个基本假设——训练期间环境是静止的。传统方法同时学习所有技能，这使得它们难以快速适应环境的变化，并且在适应后不忘掉早期学习的技能。另一方面，在一个不断演变或扩展的环境中，技能学习必须能够快速适应新的环境情况，同时不忘掉之前学习的技能。这两个条件使得经典技能发现在演变环境中难以表现良好。在这项工作中，我们提出了一个新的技能发现框架，其中技能以增量方式一个接一个地学习。这个框架允许新学习的技能适应新的环境或代理动态，而固定的旧技能确保代理不忘掉已学习的技能。我们通过实验证明，在演变和静态环境中，增量技能在技能质量和解决下游任务的能力上都显著优于当前最先进的技能发现方法。学习技能的视频和代码已在https://notmahi.github.io/disk公开。",
        "领域": "强化学习、技能发现、自适应学习",
        "问题": "在环境不断变化的情况下，如何有效地学习和保持技能，同时快速适应新环境",
        "动机": "解决传统技能学习方法在非静态环境中适应性差和技能遗忘的问题",
        "方法": "提出一个增量式技能学习框架，按顺序学习技能，新技能适应新环境，旧技能保持不变以防止遗忘",
        "关键词": [
            "增量学习",
            "技能发现",
            "强化学习",
            "自适应学习",
            "非静态环境"
        ],
        "涉及的技术概念": {
            "增量学习": "按顺序学习技能，允许新技能适应环境变化，同时保留旧技能",
            "技能发现": "在无监督或奖励稀缺的环境中自动发现有用的技能",
            "强化学习": "通过与环境交互学习最优行为策略的机器学习方法"
        },
        "success": true
    },
    {
        "order": 694,
        "title": "On Evaluation Metrics for Graph Generative Models",
        "html": "https://iclr.cc//virtual/2022/poster/6661",
        "abstract": "In image generation, generative models can be evaluated naturally by visually inspecting model outputs. However, this is not always the case for graph generative models (GGMs), making their evaluation challenging. Currently, the standard process for evaluating GGMs suffers from three critical limitations: i) it does not produce a single score which makes model selection challenging, ii) in many cases it fails to consider underlying edge and node features, and iii) it is prohibitively slow to perform. In this work, we mitigate these issues by searching for \\emph{scalar, domain-agnostic, and scalable metrics} for evaluating and ranking GGMs. To this end, we study existing GGM metrics and neural-network-based metrics emerging from generative models of images that use embeddings extracted from a task-specific network. Motivated by the power of Graph Neural Networks (GNNs) to extract meaningful graph representations \\emph{without any training}, we introduce several metrics based on the features extracted by an untrained random GNN. We design experiments to thoroughly test and objectively score metrics on their ability to measure the diversity and fidelity of generated graphs, as well as their sample and computational efficiency. Depending on the quantity of samples, we recommend one of two metrics from our collection of random-GNN-based metrics. We show these two metrics to be more expressive than pre-existing and alternative random-GNN-based metrics using our objective scoring. While we focus on applying these metrics to GGM evaluation, in practice this enables the ability to easily compute the dissimilarity between any two sets of graphs \\emph{regardless of domain}. Our code is released at: https://github.com/uoguelph-mlrg/GGM-metrics.",
        "conference": "ICLR",
        "中文标题": "关于图生成模型的评估指标",
        "摘要翻译": "在图像生成中，生成模型可以通过视觉检查模型输出自然地进行评估。然而，对于图生成模型（GGMs）来说，情况并非总是如此，这使得它们的评估具有挑战性。目前，评估GGMs的标准过程存在三个关键限制：i）它不产生单一分数，这使得模型选择具有挑战性，ii）在许多情况下，它未能考虑潜在的边和节点特征，iii）执行速度极慢。在这项工作中，我们通过寻找用于评估和排名GGMs的标量、领域无关和可扩展的指标来缓解这些问题。为此，我们研究了现有的GGM指标和基于神经网络的指标，这些指标来自使用从特定任务网络中提取的嵌入的图像生成模型。受到图神经网络（GNNs）无需任何训练即可提取有意义的图表示的能力的启发，我们引入了几个基于未经训练的随机GNN提取的特征的指标。我们设计了实验来全面测试并客观评分这些指标在测量生成图的多样性和保真度以及它们的样本和计算效率方面的能力。根据样本数量，我们从我们的随机GNN基于指标集合中推荐两个指标之一。我们使用我们的客观评分显示这两个指标比现有的和替代的随机GNN基于指标更具表现力。虽然我们专注于将这些指标应用于GGM评估，但在实践中，这使得能够轻松计算任何两组图之间的差异，无论领域如何。我们的代码发布于：https://github.com/uoguelph-mlrg/GGM-metrics。",
        "领域": "图生成模型、图神经网络、生成模型评估",
        "问题": "解决图生成模型评估过程中的三个关键限制：缺乏单一评分标准、忽视边和节点特征、评估速度慢。",
        "动机": "寻找标量、领域无关和可扩展的指标来评估和排名图生成模型，以克服现有评估方法的局限性。",
        "方法": "研究现有的图生成模型指标和基于神经网络的指标，引入基于未经训练的随机图神经网络提取的特征的新指标，并通过实验测试这些指标的性能。",
        "关键词": [
            "图生成模型",
            "评估指标",
            "图神经网络",
            "多样性",
            "保真度"
        ],
        "涉及的技术概念": {
            "图生成模型（GGMs）": "用于生成图结构的模型，评估这些模型的性能是研究的核心。",
            "图神经网络（GNNs）": "用于提取图的有意义表示的技术，无需训练即可用于评估图生成模型的性能。",
            "评估指标": "用于量化图生成模型性能的标准，研究重点是开发标量、领域无关和可扩展的指标。"
        },
        "success": true
    },
    {
        "order": 695,
        "title": "On feature learning in neural networks with global convergence guarantees",
        "html": "https://iclr.cc//virtual/2022/poster/6698",
        "abstract": "We study the gradient flow optimization of over-parameterized neural networks (NNs) in a setup that allows feature learning while admitting non-asymptotic global convergence guarantees. First, we prove that for wide shallow NNs under the mean-field (MF) scaling and with a general class of activation functions, when the input dimension is at least the size of the training set, the training loss converges to zero at a linear rate under gradient flow. Building upon this analysis, we study a model of wide multi-layer NNs with random and untrained weights in earlier layers, and also prove a linear-rate convergence of the training loss to zero, regardless of the input dimension. We also show empirically that, unlike in the Neural Tangent Kernel (NTK) regime, our multi-layer model exhibits feature learning and can achieve better generalization performance than its NTK counterpart.",
        "conference": "ICLR",
        "中文标题": "神经网络中具有全局收敛保证的特征学习研究",
        "摘要翻译": "我们研究了过参数化神经网络（NNs）在梯度流优化中的表现，该设置允许特征学习同时接受非渐近全局收敛保证。首先，我们证明，在均值场（MF）缩放下，对于具有广泛浅层NNs和一类通用激活函数的情况，当输入维度至少等于训练集大小时，训练损失在梯度流下以线性速率收敛到零。基于这一分析，我们研究了一个具有随机和未训练权重的宽多层NNs模型，并同样证明了训练损失以线性速率收敛到零，无论输入维度如何。我们还通过实验表明，与神经切线核（NTK）机制不同，我们的多层模型展示了特征学习，并且能够比其NTK对应物获得更好的泛化性能。",
        "领域": "深度学习理论、神经网络优化、特征学习",
        "问题": "研究过参数化神经网络在梯度流优化中的特征学习能力及其全局收敛性",
        "动机": "探索神经网络在特征学习过程中的优化行为，特别是在过参数化条件下，如何保证训练的全局收敛性",
        "方法": "通过理论分析和实验验证，研究在均值场缩放下的浅层和宽多层神经网络在梯度流优化中的表现，比较其与神经切线核机制的不同",
        "关键词": [
            "过参数化神经网络",
            "梯度流优化",
            "特征学习",
            "全局收敛",
            "均值场理论"
        ],
        "涉及的技术概念": {
            "梯度流优化": "用于研究神经网络训练过程中的优化行为，特别是在过参数化条件下的收敛性",
            "均值场缩放": "一种理论框架，用于分析宽神经网络的动态和行为，特别是在无限宽度极限下的表现",
            "神经切线核（NTK）": "一种描述神经网络在训练初期动态的理论工具，用于理解网络的优化和泛化行为"
        },
        "success": true
    },
    {
        "order": 696,
        "title": "On Improving Adversarial Transferability of Vision Transformers ",
        "html": "https://iclr.cc//virtual/2022/poster/6341",
        "abstract": "Vision transformers (ViTs) process input images as sequences of patches via self-attention; a radically different architecture than convolutional neural networks (CNNs).  This makes it interesting to study the adversarial feature space of ViT models and their transferability. In particular, we observe that adversarial patterns found via conventional adversarial attacks show very \\emph{low} black-box transferability even for large ViT models. We show that this phenomenon is only due to the sub-optimal attack procedures that do not leverage the true representation potential of ViTs. A deep ViT is composed of multiple blocks, with a consistent architecture comprising of self-attention and feed-forward layers, where each block is capable of independently producing a class token. Formulating an attack using only the last class token (conventional approach) does not directly leverage the discriminative information stored in the earlier tokens, leading to poor adversarial transferability of ViTs.Using the compositional nature of ViT models, we enhance transferability of existing attacks by introducing two novel strategies specific to the architecture of ViT models.  \\emph{(i) Self-Ensemble:} We propose a method to find multiple discriminative pathways by dissecting a single ViT model into an ensemble of networks. This allows explicitly utilizing class-specific information at each ViT block. \\emph{(ii) Token Refinement:} We then propose to refine the tokens to further enhance the discriminative capacity at each block of ViT.Our token refinement systematically combines the class tokens with structural information preserved within the patch tokens. An adversarial attack when applied to such refined tokens within the ensemble of classifiers found in a single vision transformer has significantly higher transferability and thereby brings out the true generalization potential of the ViT's adversarial space. Code: https://t.ly/hBbW.",
        "conference": "ICLR",
        "中文标题": "关于提升视觉变换器对抗迁移性的研究",
        "摘要翻译": "视觉变换器（ViTs）通过自注意力机制将输入图像处理为一系列补丁；这是一种与卷积神经网络（CNNs）截然不同的架构。这使得研究ViT模型的对抗性特征空间及其迁移性变得有趣。特别是，我们观察到，通过传统的对抗攻击发现的对抗模式即使对于大型ViT模型也显示出非常低的黑盒迁移性。我们表明，这一现象仅是由于未充分利用ViTs真正表示潜力的次优攻击程序所致。一个深度ViT由多个块组成，每个块具有一致的自注意力和前馈层架构，每个块能够独立产生一个类别令牌。仅使用最后一个类别令牌（传统方法）制定攻击不直接利用早期令牌中存储的判别信息，导致ViTs的对抗迁移性差。利用ViT模型的组合性质，我们通过引入两种针对ViT模型架构的新策略来增强现有攻击的迁移性。（i）自集成：我们提出了一种通过将单个ViT模型分解为网络集成来找到多个判别路径的方法。这允许在每个ViT块明确利用类别特定信息。（ii）令牌精炼：然后我们提出精炼令牌以进一步增强ViT每个块的判别能力。我们的令牌精炼系统地将类别令牌与补丁令牌中保留的结构信息结合起来。当应用于单个视觉变换器中发现的分类器集成中的此类精炼令牌时，对抗攻击具有显著更高的迁移性，从而展现出ViT对抗空间的真正泛化潜力。代码：https://t.ly/hBbW。",
        "领域": "对抗性攻击、视觉变换器、深度学习安全",
        "问题": "提升视觉变换器（ViTs）对抗攻击的迁移性",
        "动机": "研究ViT模型的对抗性特征空间及其迁移性，发现传统对抗攻击方法在ViT模型上迁移性低的问题",
        "方法": "通过自集成和令牌精炼两种策略，增强ViT模型对抗攻击的迁移性",
        "关键词": [
            "视觉变换器",
            "对抗迁移性",
            "自集成",
            "令牌精炼",
            "深度学习安全"
        ],
        "涉及的技术概念": {
            "自注意力": "ViT模型中用于处理输入图像序列的机制，通过计算序列中各个部分之间的关系来捕捉图像特征",
            "对抗迁移性": "指对抗样本从一个模型迁移到另一个模型的能力，是评估对抗攻击效果的重要指标",
            "令牌精炼": "一种通过结合类别令牌和补丁令牌中的结构信息来增强ViT模型判别能力的技术"
        },
        "success": true
    },
    {
        "order": 697,
        "title": "On Incorporating Inductive Biases into VAEs",
        "html": "https://iclr.cc//virtual/2022/poster/6009",
        "abstract": "We explain why directly changing the prior can be a surprisingly ineffective mechanism for incorporating inductive biases into variational auto-encoders (VAEs), and introduce a simple and effective alternative approach: Intermediary Latent Space VAEs (InteL-VAEs). InteL-VAEs use an intermediary set of latent variables to control the stochasticity of the encoding process, before mapping these in turn to the latent representation using a parametric function that encapsulates our desired inductive bias(es). This allows us to impose properties like sparsity or clustering on learned representations, and incorporate human knowledge into the generative model. Whereas changing the prior only indirectly encourages behavior through regularizing the encoder, InteL-VAEs are able to directly enforce desired characteristics. Moreover, they bypass the computation and encoder design issues caused by non-Gaussian priors, while allowing for additional flexibility through training of the parametric mapping function. We show that these advantages, in turn, lead to both better generative models and better representations being learned.",
        "conference": "ICLR",
        "中文标题": "关于将归纳偏置融入变分自编码器的研究",
        "摘要翻译": "我们解释了为什么直接改变先验可能是将归纳偏置融入变分自编码器（VAEs）的一个出人意料地无效的机制，并介绍了一种简单而有效的替代方法：中介潜在空间变分自编码器（InteL-VAEs）。InteL-VAEs使用一组中介潜在变量来控制编码过程的随机性，然后通过一个封装了我们期望的归纳偏置的参数函数将这些变量映射到潜在表示。这使我们能够在学习到的表示上施加如稀疏性或聚类等属性，并将人类知识融入生成模型中。而改变先验仅通过正则化编码器间接鼓励行为，InteL-VAEs能够直接强制执行期望的特性。此外，它们绕过了由非高斯先验引起的计算和编码器设计问题，同时通过参数映射函数的训练允许额外的灵活性。我们展示了这些优势反过来导致了更好的生成模型和更好的表示学习。",
        "领域": "生成模型、变分自编码器、表示学习",
        "问题": "如何有效地将归纳偏置融入变分自编码器中",
        "动机": "直接改变先验在融入归纳偏置时效果不佳，需要一种更直接和有效的方法",
        "方法": "引入中介潜在空间变分自编码器（InteL-VAEs），通过中介潜在变量和控制编码过程的随机性，直接施加期望的特性",
        "关键词": [
            "归纳偏置",
            "变分自编码器",
            "中介潜在空间",
            "生成模型",
            "表示学习"
        ],
        "涉及的技术概念": {
            "归纳偏置": "在模型中引入的先验知识或假设，用于指导模型学习期望的特性",
            "变分自编码器": "一种生成模型，通过学习数据的潜在表示来生成新的数据样本",
            "中介潜在空间": "在编码过程中引入的额外潜在变量层，用于更直接地控制表示的特性"
        },
        "success": true
    },
    {
        "order": 698,
        "title": "Online Ad Hoc Teamwork under Partial Observability",
        "html": "https://iclr.cc//virtual/2022/poster/7013",
        "abstract": "Autonomous agents often need to work together as a team to accomplish complex cooperative tasks. Due to privacy and other realistic constraints, agents might need to collaborate with previously unknown teammates on the fly. This problem is known as ad hoc teamwork, which remains a core research challenge. Prior works usually rely heavily on strong assumptions like full observability, fixed and predefined teammates' types. This paper relaxes these assumptions with a novel reinforcement learning framework called ODITS, which allows the autonomous agent to adapt to arbitrary teammates in an online fashion. Instead of limiting teammates into a finite set of predefined types, ODITS automatically learns latent variables of teammates' behaviors to infer how to cooperate with new teammates effectively. To overcome partial observability, we introduce an information-based regularizer to derive proxy representations of the learned variables from local observations. Extensive experimental results show that ODITS significantly outperforms various baselines in widely used ad hoc teamwork tasks.",
        "conference": "ICLR",
        "中文标题": "部分可观测性下的在线临时团队协作",
        "摘要翻译": "自主智能体经常需要作为一个团队共同完成复杂的协作任务。由于隐私和其他现实约束，智能体可能需要与之前未知的队友即时协作。这一问题被称为临时团队协作，仍然是一个核心研究挑战。先前的工作通常严重依赖于强假设，如完全可观测性、固定和预定义的队友类型。本文通过一种名为ODITS的新型强化学习框架放松了这些假设，该框架允许自主智能体以在线方式适应任意队友。ODITS不是将队友限制在一组有限的预定义类型中，而是自动学习队友行为的潜在变量，以推断如何与新队友有效合作。为了克服部分可观测性，我们引入了一个基于信息的正则化器，从局部观测中推导出学习变量的代理表示。大量实验结果表明，ODITS在广泛使用的临时团队协作任务中显著优于各种基线方法。",
        "领域": "多智能体系统、强化学习、协作策略学习",
        "问题": "在部分可观测环境下，自主智能体如何与未知队友进行有效的在线临时团队协作。",
        "动机": "解决现有临时团队协作研究中依赖强假设（如完全可观测性和固定队友类型）的局限性，提出一种更灵活、适应性更强的协作框架。",
        "方法": "提出了一种名为ODITS的新型强化学习框架，通过自动学习队友行为的潜在变量和引入基于信息的正则化器来适应未知队友并克服部分可观测性。",
        "关键词": [
            "临时团队协作",
            "强化学习",
            "部分可观测性",
            "多智能体系统",
            "在线适应"
        ],
        "涉及的技术概念": {
            "ODITS框架": "一种新型强化学习框架，用于在线适应未知队友的行为，通过自动学习潜在变量来实现有效协作。",
            "潜在变量学习": "在ODITS框架中，用于推断队友行为的潜在变量，以便智能体能够理解和适应新队友的策略。",
            "基于信息的正则化器": "一种技术手段，用于从局部观测中推导出队友行为的代理表示，以克服部分可观测性带来的挑战。"
        },
        "success": true
    },
    {
        "order": 699,
        "title": "Online Adversarial Attacks",
        "html": "https://iclr.cc//virtual/2022/poster/6381",
        "abstract": "Adversarial attacks expose important vulnerabilities of deep learning models, yet little attention has been paid to settings where data arrives as a stream. In this paper, we formalize the online adversarial attack problem, emphasizing two key elements found in real-world use-cases: attackers must operate under partial knowledge of the target model, and the decisions made by the attacker are irrevocable since they operate on a transient data stream. We first rigorously analyze a deterministic variant of the online threat model by drawing parallels to the well-studied $k$-secretary problem in theoretical computer science and propose Virtual+, a simple yet practical online algorithm. Our main theoretical result shows Virtual+ yields provably the best competitive ratio over all single-threshold algorithms for $k<5$---extending the previous analysis of the $k$-secretary problem. We also introduce the \\textit{stochastic $k$-secretary}---effectively reducing online blackbox transfer attacks to a $k$-secretary problem under noise---and prove theoretical bounds on the performance of Virtual+ adapted to this setting. Finally, we complement our theoretical results by conducting experiments on MNIST, CIFAR-10, and Imagenet classifiers, revealing the necessity of online algorithms in achieving near-optimal performance and also the rich interplay between attack strategies and online attack selection, enabling simple strategies like FGSM to outperform stronger adversaries.",
        "conference": "ICLR",
        "中文标题": "在线对抗攻击",
        "摘要翻译": "对抗攻击暴露了深度学习模型的重要脆弱性，然而对于数据以流形式到达的场景却鲜少关注。在本文中，我们形式化了在线对抗攻击问题，强调了现实世界用例中的两个关键要素：攻击者必须在目标模型的部分知识下操作，且攻击者做出的决策是不可撤销的，因为它们作用于瞬态数据流。我们首先通过将在线威胁模型的确定性变体与理论计算机科学中广泛研究的k-秘书问题相类比，进行了严格分析，并提出了Virtual+，一个简单而实用的在线算法。我们的主要理论结果表明，对于k<5，Virtual+在所有单阈值算法中提供了可证明的最佳竞争比——扩展了k-秘书问题的先前分析。我们还引入了随机k-秘书——有效地将在线黑盒转移攻击减少为噪声下的k-秘书问题——并证明了Virtual+在此设置下性能的理论界限。最后，我们通过在MNIST、CIFAR-10和Imagenet分类器上进行的实验补充了我们的理论结果，揭示了在线算法在实现接近最优性能中的必要性，以及攻击策略与在线攻击选择之间丰富的相互作用，使得像FGSM这样的简单策略能够超越更强的对手。",
        "领域": "对抗攻击、深度学习安全、在线学习",
        "问题": "如何在数据流环境下对深度学习模型进行有效的对抗攻击，特别是在攻击者对目标模型只有部分了解且决策不可撤销的情况下。",
        "动机": "研究动机在于探索和解决在数据流环境下进行对抗攻击的挑战，特别是在攻击者信息有限和决策不可逆的条件下，如何设计和分析有效的在线攻击算法。",
        "方法": "通过将在线对抗攻击问题与k-秘书问题相类比，提出并分析了一个名为Virtual+的在线算法，该算法在特定条件下提供了最佳竞争比，并引入了随机k-秘书问题来处理噪声环境下的攻击。",
        "关键词": [
            "在线对抗攻击",
            "k-秘书问题",
            "Virtual+算法",
            "黑盒转移攻击",
            "FGSM"
        ],
        "涉及的技术概念": {
            "在线对抗攻击": "在数据流环境下对深度学习模型进行的对抗攻击，强调攻击者在部分知识和不可逆决策条件下的操作。",
            "k-秘书问题": "理论计算机科学中的一个经典问题，用于类比和分析在线对抗攻击问题，特别是在选择最佳攻击时机方面。",
            "Virtual+算法": "本文提出的一个简单而实用的在线算法，用于在特定条件下进行对抗攻击，提供了可证明的最佳竞争比。"
        },
        "success": true
    },
    {
        "order": 700,
        "title": "Online Continual Learning on Class Incremental Blurry Task Configuration with Anytime Inference",
        "html": "https://iclr.cc//virtual/2022/poster/6797",
        "abstract": "Despite rapid advances in continual learning, a large body of research is devoted to improving performance in the existing setups.While a handful of work do propose new continual learning setups, they still lack practicality in certain aspects.For better practicality, we first propose a novel continual learning setup that is online, task-free, class-incremental, of blurry task boundaries and subject to inference queries at any moment.We additionally propose a new metric to better measure the performance of the continual learning methods subject to inference queries at any moment.To address the challenging setup and evaluation protocol, we propose an effective method that employs a new memory management scheme and novel learning techniques.Our empirical validation demonstrates that the proposed method outperforms prior arts by large margins. Code and data splits are available at https://github.com/naver-ai/i-Blurry.",
        "conference": "ICLR",
        "中文标题": "在线持续学习在类增量模糊任务配置中的随时推理",
        "摘要翻译": "尽管持续学习领域取得了快速进展，但大量研究致力于提高现有设置下的性能。虽然少数工作确实提出了新的持续学习设置，但它们在某些方面仍缺乏实用性。为了更好的实用性，我们首先提出了一种新颖的持续学习设置，它是在线的、无任务的、类增量的、具有模糊任务边界，并且可以在任何时候进行推理查询。此外，我们提出了一种新的度量标准，以更好地衡量在任意时刻进行推理查询的持续学习方法的性能。为了应对这一具有挑战性的设置和评估协议，我们提出了一种有效的方法，该方法采用了新的内存管理方案和创新的学习技术。我们的实证验证表明，所提出的方法大幅优于现有技术。代码和数据分割可在https://github.com/naver-ai/i-Blurry获取。",
        "领域": "持续学习、类增量学习、模糊任务边界处理",
        "问题": "如何在在线、无任务、类增量且具有模糊任务边界的持续学习环境中，实现高效的随时推理。",
        "动机": "提高持续学习在实际应用中的实用性，特别是在处理模糊任务边界和随时推理查询时的性能。",
        "方法": "提出了一种新的内存管理方案和创新的学习技术，以应对在线持续学习中的类增量模糊任务配置和随时推理挑战。",
        "关键词": [
            "持续学习",
            "类增量学习",
            "模糊任务边界",
            "随时推理",
            "内存管理"
        ],
        "涉及的技术概念": {
            "持续学习": "一种机器学习范式，旨在使模型能够从连续的数据流中学习，而不会忘记之前学到的知识。",
            "类增量学习": "持续学习的一种形式，其中新类别的数据随时间逐步引入，模型需要适应这些新类别而不忘记旧类别。",
            "模糊任务边界": "指在持续学习中，任务之间的界限不明确，使得模型难以区分不同任务的数据。"
        },
        "success": true
    },
    {
        "order": 701,
        "title": "Online Coreset Selection for Rehearsal-based Continual Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6362",
        "abstract": "A dataset is a shred of crucial evidence to describe a task. However, each data point in the dataset does not have the same potential, as some of the data points can be more representative or informative than others. This unequal importance among the data points may have a large impact in rehearsal-based continual learning, where we store a subset of the training examples (coreset) to be replayed later to alleviate catastrophic forgetting. In continual learning, the quality of the samples stored in the coreset directly affects the model's effectiveness and efficiency. The coreset selection problem becomes even more important under realistic settings, such as imbalanced continual learning or noisy data scenarios. To tackle this problem, we propose Online Coreset Selection (OCS), a simple yet effective method that selects the most representative and informative coreset at each iteration and trains them in an online manner. Our proposed method maximizes the model's adaptation to a target dataset while selecting high-affinity samples to past tasks, which directly inhibits catastrophic forgetting. We validate the effectiveness of our coreset selection mechanism over various standard, imbalanced, and noisy datasets against strong continual learning baselines, demonstrating that it improves task adaptation and prevents catastrophic forgetting in a sample-efficient manner. ",
        "conference": "ICLR",
        "中文标题": "在线核心集选择用于基于排练的持续学习",
        "摘要翻译": "数据集是描述任务的关键证据之一。然而，数据集中的每个数据点并不具有相同的潜力，因为某些数据点可能比其他数据点更具代表性或信息量。这种数据点之间的不平等重要性在基于排练的持续学习中可能产生重大影响，在这种学习中，我们存储训练示例的一个子集（核心集），以便稍后重放以减轻灾难性遗忘。在持续学习中，存储在核心集中的样本质量直接影响模型的有效性和效率。在现实设置下，如不平衡的持续学习或噪声数据场景中，核心集选择问题变得更加重要。为了解决这个问题，我们提出了在线核心集选择（OCS），这是一种简单而有效的方法，它在每次迭代中选择最具代表性和信息量的核心集，并以在线方式训练它们。我们提出的方法最大化模型对目标数据集的适应，同时选择与过去任务高亲和力的样本，这直接抑制了灾难性遗忘。我们在各种标准、不平衡和噪声数据集上验证了我们核心集选择机制的有效性，与强大的持续学习基线相比，证明了它以样本高效的方式改进了任务适应并防止了灾难性遗忘。",
        "领域": "持续学习",
        "问题": "如何在持续学习中有效地选择和训练核心集以减轻灾难性遗忘",
        "动机": "解决在持续学习中由于数据点不平等重要性导致的灾难性遗忘问题",
        "方法": "提出在线核心集选择（OCS）方法，动态选择最具代表性和信息量的核心集进行在线训练",
        "关键词": [
            "持续学习",
            "核心集选择",
            "灾难性遗忘",
            "在线学习",
            "样本效率"
        ],
        "涉及的技术概念": {
            "核心集": "在持续学习中存储的训练示例子集，用于后续重放以减轻灾难性遗忘",
            "灾难性遗忘": "机器学习模型在学习新任务时忘记旧任务知识的现象",
            "在线学习": "一种学习方式，模型在接收数据时即时更新，适用于动态选择核心集"
        },
        "success": true
    },
    {
        "order": 702,
        "title": "Online Facility Location with Predictions",
        "html": "https://iclr.cc//virtual/2022/poster/7174",
        "abstract": "We provide nearly optimal algorithms for online facility location (OFL) with predictions. In OFL, $n$ demand points arrive in order and the algorithm must irrevocably assign each demand point to an open facility upon its arrival. The objective is to minimize the total connection costs from demand points to assigned facilities plus the facility opening cost. We further assume the algorithm is additionally given for each demand point $x_i$ a natural prediction $f_{x_i}^{\\mathrm{pred}}$ which is supposed to be the facility $f_{x_i}^{\\mathrm{opt}}$ that serves $x_i$ in the offline optimal solution.Our main result is an $O(\\min\\{\\log {\\frac{n\\eta_\\infty}{\\mathrm{OPT}}}, \\log{n} \\})$-competitive algorithm where $\\eta_\\infty$ is the maximum prediction error (i.e., the distance between $f_{x_i}^{\\mathrm{pred}}$ and $f_{x_i}^{\\mathrm{opt}}$). Our algorithm overcomes the fundamental $\\Omega(\\frac{\\log n}{\\log \\log n})$ lower bound of OFL (without predictions) when $\\eta_\\infty$ is small, and it still maintains $O(\\log n)$ ratio even when $\\eta_\\infty$ is unbounded. Furthermore, our theoretical analysis is supported by empirical evaluations for the tradeoffs between $\\eta_\\infty$ and the competitive ratio on various real datasets of different types.",
        "conference": "ICLR",
        "中文标题": "基于预测的在线设施选址",
        "摘要翻译": "我们为基于预测的在线设施选址（OFL）问题提供了近乎最优的算法。在OFL问题中，n个需求点按顺序到达，算法必须在每个需求点到达时不可逆地将其分配到一个开放的设施。目标是最小化从需求点到分配设施的总连接成本加上设施的开放成本。我们进一步假设算法还为每个需求点xi提供了一个自然预测fxipred，该预测应该是离线最优解中服务于xi的设施fxiopt。我们的主要结果是一个O(min{log(nη∞/OPT), logn})-竞争算法，其中η∞是最大预测误差（即fxipred和fxiopt之间的距离）。当η∞较小时，我们的算法克服了OFL（无预测）的基本Ω(logn/loglogn)下限，并且即使η∞无界时，仍保持O(logn)的比率。此外，我们的理论分析得到了对不同类型真实数据集上η∞与竞争比率之间权衡的实证评估的支持。",
        "领域": "在线算法、设施选址问题、预测模型",
        "问题": "在线设施选址问题中如何利用预测信息来优化设施开放和需求点分配的决策，以最小化总成本。",
        "动机": "研究如何通过引入预测信息来克服在线设施选址问题中的性能下限，提高算法的竞争比率。",
        "方法": "提出了一种基于预测的在线算法，该算法根据预测误差调整策略，以实现对不同预测误差情况下的高效应对。",
        "关键词": [
            "在线设施选址",
            "预测模型",
            "竞争分析",
            "算法优化",
            "实证评估"
        ],
        "涉及的技术概念": {
            "在线设施选址（OFL）": "一种需求点按顺序到达并需要即时分配到设施的优化问题，目标是最小化总成本。",
            "预测误差（η∞）": "预测设施与实际最优设施之间的距离，用于衡量预测的准确性。",
            "竞争比率": "用于评估在线算法性能的指标，表示算法成本与最优离线成本的最大比率。"
        },
        "success": true
    },
    {
        "order": 703,
        "title": "Online Hyperparameter Meta-Learning with Hypergradient Distillation",
        "html": "https://iclr.cc//virtual/2022/poster/6204",
        "abstract": "Many gradient-based meta-learning methods assume a set of parameters that do not participate in inner-optimization, which can be considered as hyperparameters. Although such hyperparameters can be optimized using the existing gradient-based hyperparameter optimization (HO) methods, they suffer from the following issues. Unrolled differentiation methods do not scale well to high-dimensional hyperparameters or horizon length, Implicit Function Theorem (IFT) based methods are restrictive for online optimization, and short horizon approximations suffer from short horizon bias. In this work, we propose a novel HO method that can overcome these limitations, by approximating the second-order term with knowledge distillation. Specifically, we parameterize a single Jacobian-vector product (JVP) for each HO step and minimize the distance from the true second-order term. Our method allows online optimization and also is scalable to the hyperparameter dimension and the horizon length. We demonstrate the effectiveness of our method on three different meta-learning methods and two benchmark datasets.",
        "conference": "ICLR",
        "中文标题": "在线超参数元学习与超梯度蒸馏",
        "摘要翻译": "许多基于梯度的元学习方法假设存在一组不参与内部优化的参数，这些参数可以被视为超参数。尽管这些超参数可以使用现有的基于梯度的超参数优化（HO）方法进行优化，但它们存在以下问题。展开微分方法在高维超参数或时间长度上扩展性不佳，基于隐函数定理（IFT）的方法对在线优化有限制，而短时间近似则受到短时间偏差的影响。在这项工作中，我们提出了一种新的HO方法，通过知识蒸馏近似二阶项，从而克服这些限制。具体来说，我们为每个HO步骤参数化一个单一的雅可比向量积（JVP），并最小化与真实二阶项的距离。我们的方法允许在线优化，并且对超参数维度和时间长度的扩展性良好。我们在三种不同的元学习方法和两个基准数据集上证明了我们方法的有效性。",
        "领域": "元学习、超参数优化、深度学习优化",
        "问题": "解决现有基于梯度的超参数优化方法在高维超参数、长时间长度和在线优化方面的限制。",
        "动机": "克服现有超参数优化方法在扩展性和在线优化方面的不足，提出一种更高效、更灵活的优化策略。",
        "方法": "通过知识蒸馏近似二阶项，参数化雅可比向量积（JVP）并最小化与真实二阶项的距离，实现高效的在线超参数优化。",
        "关键词": [
            "超参数优化",
            "元学习",
            "知识蒸馏",
            "在线优化",
            "雅可比向量积"
        ],
        "涉及的技术概念": {
            "超参数优化（HO）": "在元学习中优化不参与内部优化的参数，以提高模型性能。",
            "知识蒸馏": "用于近似复杂的二阶项，简化计算过程，提高优化效率。",
            "雅可比向量积（JVP）": "在优化过程中用于参数化梯度信息，支持高效的在线优化。"
        },
        "success": true
    },
    {
        "order": 704,
        "title": "Online Target Q-learning with Reverse Experience Replay: Efficiently finding the Optimal Policy for Linear MDPs",
        "html": "https://iclr.cc//virtual/2022/poster/7207",
        "abstract": "Q-learning is a popular Reinforcement Learning (RL) algorithm which is widely used in practice with function approximation (Mnih et al., 2015). In contrast, existing theoretical results are pessimistic about Q-learning. For example, (Baird, 1995) shows that Q-learning does not converge even with linear function approximation for linear MDPs. Furthermore, even for tabular MDPs with synchronous updates, Q-learning was shown to have sub-optimal sample complexity (Li et al., 2021, Azar et al., 2013). The goal of this work is to bridge the gap between practical success of Q-learning and the relatively pessimistic theoretical results. The starting point of our work is the observation that in practice, Q-learning is used with two important modifications: (i) training with two networks, called online network and target network simultaneously (online target learning, or OTL) , and (ii) experience replay (ER) (Mnih et al., 2015). While they have been observed to play a significant role in the practical success of Q-learning, a thorough theoretical understanding of how these two modifications improve the convergence behavior of Q-learning has been missing in literature. By carefully combining the Q-learning with OTL and reverse experience replay (RER) (a form of experience replay), we present novel methods Q-Rex and Q-RexDaRe (Q-Rex+data reuse). We show that Q-Rex efficiently finds the optimal policy for linear MDPs and provide non-asymptotic bounds on sample complexity -- the first such result for a Q-learning method with linear MDPs. Furthermore, we demonstrate that Q-RexDaRe in fact achieves near optimal sample complexity in the tabular setting, improving upon the existing results for vanilla Q-learning. ",
        "conference": "ICLR",
        "中文标题": "在线目标Q学习与反向经验回放：高效寻找线性MDP的最优策略",
        "摘要翻译": "Q学习是一种流行的强化学习（RL）算法，在实践中广泛用于函数逼近（Mnih等人，2015年）。相比之下，现有的理论结果对Q学习持悲观态度。例如，（Baird，1995年）显示，即使对于线性MDP使用线性函数逼近，Q学习也不会收敛。此外，即使对于具有同步更新的表格MDP，Q学习也被证明具有次优的样本复杂度（Li等人，2021年，Azar等人，2013年）。这项工作的目标是弥合Q学习在实际成功与相对悲观的理论结果之间的差距。我们工作的出发点是观察到在实践中，Q学习使用了两个重要的修改：（i）同时使用两个网络进行训练，称为在线网络和目标网络（在线目标学习，或OTL），以及（ii）经验回放（ER）（Mnih等人，2015年）。虽然已经观察到它们在Q学习的实际成功中发挥了重要作用，但文献中缺乏对这两种修改如何改善Q学习收敛行为的彻底理论理解。通过仔细地将Q学习与OTL和反向经验回放（RER）（一种经验回放形式）结合，我们提出了新方法Q-Rex和Q-RexDaRe（Q-Rex+数据重用）。我们展示了Q-Rex高效地找到了线性MDP的最优策略，并提供了样本复杂度的非渐近边界——这是第一个针对具有线性MDP的Q学习方法的结果。此外，我们证明了Q-RexDaRe在表格设置中实际上实现了接近最优的样本复杂度，改进了现有普通Q学习的结果。",
        "领域": "强化学习、函数逼近、样本复杂度优化",
        "问题": "Q学习在理论上的悲观结果与实际应用中的成功之间存在差距",
        "动机": "弥合Q学习在实际应用中的成功与理论上的悲观结果之间的差距，通过结合在线目标学习和反向经验回放来提高Q学习的效率和收敛性",
        "方法": "结合在线目标学习（OTL）和反向经验回放（RER）提出了Q-Rex和Q-RexDaRe方法，用于高效寻找线性MDP的最优策略，并提供了样本复杂度的非渐近边界",
        "关键词": [
            "在线目标学习",
            "反向经验回放",
            "Q-Rex",
            "Q-RexDaRe",
            "样本复杂度"
        ],
        "涉及的技术概念": {
            "在线目标学习（OTL）": "同时使用在线网络和目标网络进行训练，以提高Q学习的稳定性和效率",
            "反向经验回放（RER）": "一种经验回放的形式，用于改善Q学习的收敛行为",
            "样本复杂度": "衡量算法在达到一定性能水平所需的样本数量，Q-Rex和Q-RexDaRe在这方面提供了改进"
        },
        "success": true
    },
    {
        "order": 705,
        "title": "On Lottery Tickets and Minimal Task Representations in Deep Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2022/poster/7077",
        "abstract": "The lottery ticket hypothesis questions the role of overparameterization in supervised deep learning. But how is the performance of winning lottery tickets affected by the distributional shift inherent to reinforcement learning problems? In this work, we address this question by comparing sparse agents who have to address the non-stationarity of the exploration-exploitation problem with supervised agents trained to imitate an expert. We show that feed-forward networks trained with behavioural cloning compared to reinforcement learning can be pruned to higher levels of sparsity without performance degradation. This suggests that in order to solve the RL-specific distributional shift agents require more degrees of freedom. Using a set of carefully designed baseline conditions, we find that the majority of the lottery ticket effect in both learning paradigms can be attributed to the identified mask rather than the weight initialization. The input layer mask selectively prunes entire input dimensions that turn out to be irrelevant for the task at hand. At a moderate level of sparsity the mask identified by iterative magnitude pruning yields minimal task-relevant representations, i.e., an interpretable inductive bias. Finally, we propose a simple initialization rescaling which promotes the robust identification of sparse task representations in low-dimensional control tasks.",
        "conference": "ICLR",
        "中文标题": "论深度强化学习中的彩票假设与最小任务表示",
        "摘要翻译": "彩票假设质疑了监督式深度学习中过度参数化的作用。但是，强化学习问题固有的分布偏移如何影响中奖彩票的性能？在这项工作中，我们通过比较必须解决探索-开发问题非平稳性的稀疏代理与模仿专家训练的监督代理来探讨这个问题。我们表明，与强化学习相比，使用行为克隆训练的前馈网络可以修剪到更高的稀疏度而不会降低性能。这表明，为了解决强化学习特有的分布偏移，代理需要更多的自由度。通过一组精心设计的基线条件，我们发现两种学习范式中的大部分彩票效应可以归因于已识别的掩码而非权重初始化。输入层掩码选择性地修剪掉对当前任务无关的整个输入维度。在中等稀疏度下，通过迭代幅度修剪识别的掩码产生最小的任务相关表示，即可解释的归纳偏置。最后，我们提出了一种简单的初始化重新缩放方法，以促进在低维控制任务中稳健地识别稀疏任务表示。",
        "领域": "深度强化学习、稀疏网络、行为克隆",
        "问题": "探讨在强化学习中，分布偏移如何影响稀疏网络（彩票假设中的中奖彩票）的性能。",
        "动机": "研究强化学习特有的分布偏移对稀疏网络性能的影响，以及如何通过稀疏化提高模型的解释性和效率。",
        "方法": "通过比较使用行为克隆训练的监督代理和强化学习代理的稀疏化效果，分析彩票效应在两种学习范式中的表现，并提出一种初始化重新缩放方法来优化稀疏任务表示的识别。",
        "关键词": [
            "彩票假设",
            "稀疏网络",
            "行为克隆",
            "强化学习",
            "分布偏移"
        ],
        "涉及的技术概念": {
            "彩票假设": "指在深度学习中，存在一个子网络（中奖彩票），当单独训练时，可以达到与原网络相当的性能。",
            "行为克隆": "一种监督学习方法，通过模仿专家的行为来训练代理，用于与强化学习方法进行比较。",
            "迭代幅度修剪": "一种网络稀疏化技术，通过迭代地修剪网络中幅度最小的权重来识别重要的网络结构。"
        },
        "success": true
    },
    {
        "order": 706,
        "title": "On Non-Random Missing Labels in Semi-Supervised Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6177",
        "abstract": "Semi-Supervised Learning (SSL) is fundamentally a missing label problem, in which the label Missing Not At Random (MNAR) problem is more realistic and challenging, compared to the widely-adopted yet naive Missing Completely At Random assumption where both labeled and unlabeled data share the same class distribution. Different from existing SSL solutions that overlook the role of  ''class'' in causing the non-randomness, e.g., users are more likely to label popular classes, we explicitly incorporate ''class'' into SSL. Our method is three-fold: 1) We propose Class-Aware Propensity (CAP) that exploits the unlabeled data to train an improved classifier using the biased labeled data. 2) To encourage rare class training, whose model is low-recall but high-precision that discards too many pseudo-labeled data, we propose Class-Aware Imputation (CAI) that dynamically decreases (or increases) the pseudo-label assignment threshold for rare (or frequent) classes. 3) Overall, we integrate CAP and CAI into a Class-Aware Doubly Robust (CADR) estimator for training an unbiased SSL model. Under various MNAR settings and ablations, our method not only significantly outperforms existing baselines, but also surpasses other label bias removal SSL methods.",
        "conference": "ICLR",
        "中文标题": "半监督学习中的非随机缺失标签问题研究",
        "摘要翻译": "半监督学习（SSL）本质上是一个缺失标签的问题，其中标签的‘非随机缺失’（MNAR）问题相比广泛采用但较为天真的‘完全随机缺失’假设更为现实和具有挑战性，后者假设标记和未标记数据共享相同的类别分布。与现有的SSL解决方案不同，这些方案忽视了‘类别’在导致非随机性中的作用，例如用户更倾向于标记流行类别，我们明确将‘类别’纳入SSL中。我们的方法包括三个方面：1）我们提出了类别感知倾向（CAP），利用未标记数据通过有偏标记数据训练一个改进的分类器。2）为了鼓励稀有类别的训练，其模型召回率低但精确度高，导致丢弃了太多伪标记数据，我们提出了类别感知插补（CAI），动态降低（或提高）稀有（或频繁）类别的伪标签分配阈值。3）总体而言，我们将CAP和CAI整合到一个类别感知双重稳健（CADR）估计器中，用于训练一个无偏的SSL模型。在各种MNAR设置和消融实验下，我们的方法不仅显著优于现有基线，而且超越了其他标签偏差去除的SSL方法。",
        "领域": "半监督学习",
        "问题": "解决半监督学习中的非随机缺失标签问题，特别是在类别分布不均的情况下如何有效利用有偏标记数据。",
        "动机": "现有的半监督学习方法忽视了类别在导致标签非随机缺失中的作用，导致模型在有偏标记数据上表现不佳。",
        "方法": "提出类别感知倾向（CAP）和类别感知插补（CAI）方法，并将其整合到类别感知双重稳健（CADR）估计器中，以训练一个无偏的SSL模型。",
        "关键词": [
            "半监督学习",
            "非随机缺失标签",
            "类别感知",
            "双重稳健估计",
            "标签偏差去除"
        ],
        "涉及的技术概念": {
            "类别感知倾向（CAP）": "利用未标记数据通过有偏标记数据训练一个改进的分类器。",
            "类别感知插补（CAI）": "动态调整稀有和频繁类别的伪标签分配阈值，以鼓励稀有类别的训练。",
            "类别感知双重稳健（CADR）估计器": "整合CAP和CAI，用于训练一个无偏的SSL模型，有效处理标签偏差问题。"
        },
        "success": true
    },
    {
        "order": 707,
        "title": "On-Policy Model Errors in Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2022/poster/7133",
        "abstract": "Model-free reinforcement learning algorithms can compute policy gradients given sampled environment transitions, but require large amounts of data. In contrast, model-based methods can use the learned model to generate new data, but model errors and bias can render learning unstable or suboptimal. In this paper, we present a novel method that combines real-world data and a learned model in order to get the best of both worlds. The core idea is to exploit the real-world data for on-policy predictions and use the learned model only to generalize to different actions. Specifically, we use the data as time-dependent on-policy correction terms on top of a learned model, to retain the ability to generate data without accumulating errors over long prediction horizons. We motivate this method theoretically and show that it counteracts an error term for model-based policy improvement. Experiments on MuJoCo- and PyBullet-benchmarks show that our method can drastically improve existing model-based approaches without introducing additional tuning parameters.",
        "conference": "ICLR",
        "中文标题": "强化学习中的策略模型误差",
        "摘要翻译": "无模型强化学习算法可以根据采样的环境转换计算策略梯度，但需要大量数据。相比之下，基于模型的方法可以利用学习到的模型生成新数据，但模型误差和偏差可能导致学习不稳定或次优。在本文中，我们提出了一种新方法，结合了真实世界数据和学习到的模型，以获得两者的最佳效果。核心思想是利用真实世界数据进行策略预测，并仅使用学习到的模型来泛化到不同的动作。具体来说，我们将数据作为时间依赖的策略校正项应用于学习到的模型之上，以保留生成数据的能力，而不会在长期预测范围内累积误差。我们从理论上激励了这一方法，并表明它抵消了基于模型的策略改进的一个误差项。在MuJoCo和PyBullet基准测试上的实验表明，我们的方法可以显著改进现有的基于模型的方法，而无需引入额外的调参参数。",
        "领域": "强化学习、模型预测控制、策略优化",
        "问题": "解决基于模型强化学习中模型误差和偏差导致的学习不稳定或次优问题",
        "动机": "结合无模型和基于模型强化学习的优势，减少模型误差对策略改进的影响",
        "方法": "利用真实世界数据作为时间依赖的策略校正项，结合学习到的模型进行策略预测和动作泛化",
        "关键词": [
            "强化学习",
            "模型误差",
            "策略优化",
            "数据校正",
            "模型预测"
        ],
        "涉及的技术概念": {
            "策略梯度": "用于计算策略改进方向的方法，基于采样的环境转换",
            "模型预测控制": "利用学习到的模型预测未来状态和奖励，以优化策略",
            "时间依赖校正": "通过真实数据对模型预测进行即时校正，减少长期预测误差的累积"
        },
        "success": true
    },
    {
        "order": 708,
        "title": "On Predicting Generalization using GANs",
        "html": "https://iclr.cc//virtual/2022/poster/6778",
        "abstract": "Research on generalization bounds for deep networks seeks to give ways to predict test error using just the training dataset and the network parameters. While generalization bounds can give many insights about architecture design, training algorithms etc., what they do not currently do is yield good predictions for actual test error. A recently introduced Predicting Generalization in Deep Learning competition aims to encourage discovery of methods to better predict test error. The current paper investigates a simple idea: can test error be predicted using {\\em synthetic data,} produced using a Generative Adversarial Network (GAN) that was trained on the same training dataset? Upon investigating several GAN models and architectures, we find that this turns out to be the case. In fact, using GANs pre-trained on standard datasets, the test error can be predicted without requiring any additional hyper-parameter tuning. This result is surprising because GANs have well-known limitations (e.g. mode collapse) and are known to not learn the data distribution accurately. Yet the generated samples are good enough to substitute for test data. Several additional experiments are presented to explore reasons why GANs do well at this task. In addition to a new approach for predicting generalization, the counter-intuitive phenomena presented in our work may also call for a better understanding of GANs' strengths and limitations.",
        "conference": "ICLR",
        "中文标题": "关于使用生成对抗网络预测泛化能力的研究",
        "摘要翻译": "深度网络泛化界限的研究旨在仅利用训练数据集和网络参数来预测测试误差。虽然泛化界限可以为架构设计、训练算法等提供许多见解，但它们目前并不能很好地预测实际的测试误差。最近引入的‘深度学习中的泛化预测’竞赛旨在鼓励发现更好的测试误差预测方法。本文研究了一个简单的想法：是否可以使用生成对抗网络（GAN）在同训练数据集上生成的合成数据来预测测试误差？在调查了几种GAN模型和架构后，我们发现这确实是可行的。事实上，使用在标准数据集上预训练的GAN，无需任何额外的超参数调整即可预测测试误差。这一结果令人惊讶，因为GAN存在众所周知的局限性（例如模式崩溃），并且已知不能准确学习数据分布。然而生成的样本足以替代测试数据。本文还提出了几项额外的实验来探索GAN在此任务中表现良好的原因。除了提出一种预测泛化能力的新方法外，我们工作中提出的反直觉现象也可能要求对GAN的优势和局限性有更好的理解。",
        "领域": "深度学习理论、生成对抗网络、模型泛化能力评估",
        "问题": "如何仅利用训练数据和网络参数准确预测深度网络的测试误差",
        "动机": "探索使用生成对抗网络生成的合成数据来预测深度网络的泛化能力，以解决现有泛化界限方法无法准确预测测试误差的问题",
        "方法": "利用在相同训练数据集上训练的生成对抗网络（GAN）生成合成数据，通过实验验证使用这些数据预测测试误差的可行性",
        "关键词": [
            "泛化能力预测",
            "生成对抗网络",
            "深度学习",
            "测试误差",
            "合成数据"
        ],
        "涉及的技术概念": {
            "生成对抗网络（GAN）": "用于生成与训练数据分布相似的合成数据，作为预测测试误差的替代数据",
            "泛化界限": "理论工具，用于分析模型在未见数据上的表现，本文探讨其在实际预测测试误差中的局限性",
            "模式崩溃": "GAN训练中的一种常见问题，指生成器仅能生成有限多样性的样本，本文发现即使存在此问题，GAN生成的样本仍可用于有效预测测试误差"
        },
        "success": true
    },
    {
        "order": 709,
        "title": "On Redundancy and Diversity in Cell-based Neural Architecture Search",
        "html": "https://iclr.cc//virtual/2022/poster/6911",
        "abstract": "Searching for the architecture cells is a dominant paradigm in NAS. However, little attention has been devoted to the analysis of the cell-based search spaces even though it is highly important for the continual development of NAS. In this work, we conduct an empirical post-hoc analysis of architectures from the popular cell-based search spaces and find that the existing search spaces contain a high degree of redundancy: the architecture performance is less sensitive to changes at large parts of the cells, and universally adopted design rules, like the explicit search for a reduction cell, significantly increase the complexities but have very limited impact on the performance.Across architectures found by a diverse set of search strategies, we consistently find that the parts of the cells that do matter for architecture performance often follow similar and simple patterns. By constraining cells to include these patterns, randomly sampled architectures can match or even outperform the state of the art.These findings cast doubts into our ability to discover truly novel architectures in the existing cell-based search spaces and, inspire our suggestions for improvement to guide future NAS research.Code is available at https://github.com/xingchenwan/cell-based-NAS-analysis.",
        "conference": "ICLR",
        "中文标题": "基于细胞的神经架构搜索中的冗余性与多样性研究",
        "摘要翻译": "在神经架构搜索（NAS）中，寻找架构细胞是一种主导范式。然而，尽管这对于NAS的持续发展极为重要，但基于细胞的搜索空间的分析却鲜少受到关注。在这项工作中，我们对流行的基于细胞的搜索空间中的架构进行了经验性的事后分析，发现现有的搜索空间存在高度的冗余性：架构性能对细胞大部分变化的敏感性较低，普遍采用的设计规则，如显式搜索减少细胞，显著增加了复杂性但对性能的影响非常有限。通过一系列不同的搜索策略发现的架构中，我们一致发现，对架构性能真正重要的细胞部分往往遵循相似且简单的模式。通过限制细胞包含这些模式，随机采样的架构可以匹配甚至超越现有技术。这些发现对我们能否在现有的基于细胞的搜索空间中发现真正新颖的架构提出了质疑，并激发了我们对未来NAS研究改进的建议。代码可在https://github.com/xingchenwan/cell-based-NAS-analysis获取。",
        "领域": "神经架构搜索、自动化机器学习、深度学习优化",
        "问题": "分析基于细胞的神经架构搜索空间中的冗余性问题及其对发现新颖架构能力的影响。",
        "动机": "探索现有基于细胞的神经架构搜索空间中的冗余性和设计规则的有效性，以指导未来NAS研究的改进方向。",
        "方法": "对流行的基于细胞的搜索空间中的架构进行经验性的事后分析，识别冗余性和性能关键模式，并通过限制细胞包含这些模式来验证其有效性。",
        "关键词": [
            "神经架构搜索",
            "冗余性分析",
            "架构模式",
            "自动化机器学习",
            "深度学习优化"
        ],
        "涉及的技术概念": {
            "神经架构搜索（NAS）": "一种自动化设计神经网络架构的技术，旨在减少人工设计的工作量并提高模型性能。",
            "冗余性": "指在基于细胞的搜索空间中，架构性能对大部分变化的低敏感性，表明存在不必要的复杂性。",
            "架构模式": "在神经架构搜索中，对架构性能有显著影响的细胞部分遵循的简单且相似的设计规则。"
        },
        "success": true
    },
    {
        "order": 710,
        "title": "On Robust Prefix-Tuning for Text Classification",
        "html": "https://iclr.cc//virtual/2022/poster/5987",
        "abstract": "Recently, prefix-tuning has gained increasing attention as a parameter-efficient finetuning method for large-scale pretrained language models. The method keeps the pretrained models fixed and only updates the prefix token parameters for each downstream task. Despite being lightweight and modular, prefix-tuning still lacks robustness to textual adversarial attacks. However, most currently developed defense techniques necessitate auxiliary model update and storage, which inevitably hamper the modularity and low storage of prefix-tuning. In this work, we propose a robust prefix-tuning framework that preserves the efficiency and modularity of prefix-tuning. The core idea of our framework is leveraging the layerwise activations of the language model by correctly-classified training data as the standard for additional prefix finetuning. During the test phase, an extra batch-level prefix is tuned for each batch and added to the original prefix for robustness enhancement. Extensive experiments on three text classification benchmarks show that our framework substantially improves robustness over several strong baselines against five textual attacks of different types while maintaining comparable accuracy on clean texts. We also interpret our robust prefix-tuning framework from the optimal control perspective and pose several directions for future research.",
        "conference": "ICLR",
        "中文标题": "关于文本分类的鲁棒前缀调优",
        "摘要翻译": "最近，前缀调优作为一种参数高效的大规模预训练语言模型微调方法，受到了越来越多的关注。该方法保持预训练模型固定，仅针对每个下游任务更新前缀令牌参数。尽管前缀调优轻量且模块化，但它仍然缺乏对文本对抗攻击的鲁棒性。然而，目前开发的大多数防御技术需要辅助模型更新和存储，这不可避免地损害了前缀调优的模块化和低存储特性。在这项工作中，我们提出了一个鲁棒的前缀调优框架，该框架保留了前缀调优的效率和模块化。我们框架的核心思想是利用语言模型通过正确分类的训练数据的层级激活作为额外前缀微调的标准。在测试阶段，为每个批次调整一个额外的批次级前缀，并将其添加到原始前缀中以增强鲁棒性。在三个文本分类基准上的大量实验表明，我们的框架在保持对干净文本的准确性的同时，显著提高了针对五种不同类型文本攻击的鲁棒性，优于几个强基线。我们还从最优控制的角度解释了我们的鲁棒前缀调优框架，并提出了几个未来研究的方向。",
        "领域": "自然语言处理与视觉结合",
        "问题": "提高前缀调优方法对文本对抗攻击的鲁棒性",
        "动机": "当前的前缀调优方法虽然参数高效且模块化，但在面对文本对抗攻击时缺乏足够的鲁棒性，且现有防御技术损害了其模块化和低存储特性。",
        "方法": "提出一个鲁棒的前缀调优框架，利用正确分类训练数据的层级激活作为额外前缀微调的标准，并在测试阶段为每个批次调整一个额外的批次级前缀以增强鲁棒性。",
        "关键词": [
            "前缀调优",
            "文本分类",
            "鲁棒性",
            "对抗攻击",
            "最优控制"
        ],
        "涉及的技术概念": {
            "前缀调优": "一种参数高效的微调方法，仅更新前缀令牌参数以适应下游任务，保持预训练模型固定。",
            "层级激活": "利用语言模型中不同层的激活状态作为微调的标准，以提高模型对特定任务的适应性。",
            "最优控制": "从控制理论的角度解释和优化前缀调优过程，以提高模型的鲁棒性和性能。"
        },
        "success": true
    },
    {
        "order": 711,
        "title": "On the approximation properties of recurrent encoder-decoder architectures",
        "html": "https://iclr.cc//virtual/2022/poster/7137",
        "abstract": "Encoder-decoder architectures have recently gained popularity in sequence to sequence modelling, featuring in state-of-the-art models such as transformers. However, a mathematical understanding of their working principles still remains limited. In this paper, we study the approximation properties of recurrent encoder-decoder architectures. Prior work established theoretical results for RNNs in the linear setting, where approximation capabilities can be related to smoothness and memory of target temporal relationships. Here, we uncover that the encoder and decoder together form a particular “temporal product structure” which determines the approximation efficiency. Moreover, the encoder-decoder architecture generalises RNNs with the capability to learn time-inhomogeneous relationships. Our results provide the theoretical understanding of approximation properties of the recurrent encoder-decoder architecture, which precisely characterises, in the considered setting, the types of temporal relationships that can be efficiently learned.",
        "conference": "ICLR",
        "中文标题": "关于循环编码器-解码器架构的近似性质研究",
        "摘要翻译": "编码器-解码器架构最近在序列到序列建模中变得流行，出现在如变换器等最先进的模型中。然而，对其工作原理的数学理解仍然有限。在本文中，我们研究了循环编码器-解码器架构的近似性质。先前的工作在线性设置中为RNNs建立了理论结果，其中近似能力可以与目标时间关系的平滑性和记忆性相关联。在这里，我们发现编码器和解码器共同形成了一种特定的‘时间积结构’，这决定了近似效率。此外，编码器-解码器架构通过能够学习时间非齐次关系而推广了RNNs。我们的结果提供了对循环编码器-解码器架构近似性质的理论理解，在所考虑的设置中精确描述了可以高效学习的时间关系类型。",
        "领域": "序列建模、循环神经网络、时间序列分析",
        "问题": "理解循环编码器-解码器架构在序列到序列建模中的近似性质和效率",
        "动机": "尽管编码器-解码器架构在序列建模中表现出色，但其数学理论基础仍然不足，本研究旨在填补这一空白",
        "方法": "通过理论分析，研究循环编码器-解码器架构的近似性质，特别是其形成的时间积结构及其对学习时间非齐次关系的能力",
        "关键词": [
            "循环编码器-解码器",
            "时间积结构",
            "时间非齐次关系",
            "近似性质",
            "序列建模"
        ],
        "涉及的技术概念": {
            "时间积结构": "编码器和解码器共同形成的一种结构，决定了模型对时间关系的近似效率",
            "时间非齐次关系": "编码器-解码器架构能够学习的时间关系类型，推广了传统RNNs的能力",
            "近似性质": "研究循环编码器-解码器架构能够多好地近似目标时间关系的理论特性"
        },
        "success": true
    },
    {
        "order": 712,
        "title": "On the benefits of maximum likelihood estimation for Regression and Forecasting",
        "html": "https://iclr.cc//virtual/2022/poster/7096",
        "abstract": "We advocate for a practical Maximum Likelihood Estimation (MLE) approach towards designing loss functions for regression and forecasting, as an alternative to the typical approach of direct empirical risk minimization on a specific target metric. The MLE approach is better suited to capture inductive biases such as prior domain knowledge in datasets, and can output post-hoc estimators at inference time that can optimize different types of target metrics. We present theoretical results to demonstrate that our approach is competitive with any estimator for the target metric under some general conditions. In two example practical settings, Poisson and Pareto regression, we show that our competitive results can be used to prove that the MLE approach has better excess risk bounds than directly minimizing the target metric. We also demonstrate empirically that our method instantiated with a well-designed general purpose mixture likelihood family can obtain superior performance for a variety of tasks across time-series forecasting and regression datasets with different data distributions.",
        "conference": "ICLR",
        "中文标题": "最大似然估计在回归与预测中的优势",
        "摘要翻译": "我们提倡一种实用的最大似然估计（MLE）方法，用于设计回归和预测的损失函数，作为在特定目标指标上直接经验风险最小化的典型方法的替代方案。MLE方法更适合捕捉数据集中的归纳偏差，如先前的领域知识，并且可以在推理时输出事后估计器，以优化不同类型的目标指标。我们提出了理论结果，以证明在某些一般条件下，我们的方法与任何目标指标的估计器相比具有竞争力。在两个实际设置的例子中，泊松和帕累托回归，我们展示了我们的竞争性结果可以用来证明MLE方法比直接最小化目标指标具有更好的超额风险界限。我们还通过实证表明，我们的方法实例化了一个设计良好的通用混合似然族，可以在具有不同数据分布的时间序列预测和回归数据集的各种任务中获得卓越的性能。",
        "领域": "时间序列预测, 回归分析, 统计学习",
        "问题": "如何设计更有效的损失函数用于回归和预测任务，以替代直接经验风险最小化的方法。",
        "动机": "探索最大似然估计方法在捕捉数据集中的归纳偏差和优化不同类型目标指标方面的潜力，以提高回归和预测任务的性能。",
        "方法": "采用最大似然估计（MLE）方法设计损失函数，通过理论分析和实证研究验证其在回归和预测任务中的有效性和优越性。",
        "关键词": [
            "最大似然估计",
            "回归分析",
            "时间序列预测",
            "损失函数设计",
            "统计学习"
        ],
        "涉及的技术概念": {
            "最大似然估计（MLE）": "用于设计损失函数的核心方法，旨在通过最大化似然函数来估计模型参数，更好地捕捉数据中的归纳偏差。",
            "归纳偏差": "指模型在学习过程中对某些假设的偏好，MLE方法能够有效利用先验领域知识作为归纳偏差。",
            "超额风险界限": "用于衡量估计器性能的理论工具，MLE方法在此方面展现出优于直接最小化目标指标的性能。"
        },
        "success": true
    },
    {
        "order": 713,
        "title": "On the Certified Robustness for Ensemble Models and Beyond",
        "html": "https://iclr.cc//virtual/2022/poster/6874",
        "abstract": "Recent studies show that deep neural networks (DNN) are vulnerable to adversarial examples, which aim to mislead DNNs by adding perturbations with small magnitude. To defend against such attacks, both empirical and theoretical defense approaches have been extensively studied for a single ML model. In this work, we aim to analyze and provide the certified robustness for ensemble ML models, together with the sufficient and necessary conditions of robustness for different ensemble protocols. Although ensemble models are shown more robust than a single model empirically; surprisingly, we find that in terms of the certified robustness the standard ensemble models only achieve marginal improvement compared to a single model. Thus, to explore the conditions that guarantee to provide certifiably robust ensemble ML models, we first prove that diversified gradient and large confidence margin are sufficient and necessary conditions for certifiably robust ensemble models under the model-smoothness assumption. We then provide the bounded model-smoothness analysis based on the proposed Ensemble-before-Smoothing strategy. We also prove that an ensemble model can always achieve higher certified robustness than a single base model under mild conditions. Inspired by the theoretical findings, we propose the lightweight Diversity Regularized Training (DRT) to train certifiably robust ensemble ML models. Extensive experiments show that our DRT enhanced ensembles can consistently achieve higher certified robustness than existing single and ensemble ML models, demonstrating the state-of-the-art certified $L_2$-robustness on MNIST, CIFAR-10, and ImageNet datasets.",
        "conference": "ICLR",
        "中文标题": "论集成模型及其之外的认证鲁棒性",
        "摘要翻译": "最近的研究表明，深度神经网络（DNN）容易受到对抗性示例的攻击，这些示例旨在通过添加小幅度的扰动来误导DNN。为了防御此类攻击，针对单个机器学习模型，已经广泛研究了经验和理论防御方法。在这项工作中，我们旨在分析和提供集成机器学习模型的认证鲁棒性，以及不同集成协议的鲁棒性的充分必要条件。尽管经验上显示集成模型比单个模型更鲁棒；令人惊讶的是，我们发现就认证鲁棒性而言，标准集成模型与单个模型相比仅实现了边际改进。因此，为了探索保证提供认证鲁棒集成机器学习模型的条件，我们首先证明在模型平滑性假设下，多样化梯度和大置信度边际是认证鲁棒集成模型的充分必要条件。然后，我们基于提出的“平滑前集成”策略提供了有界的模型平滑性分析。我们还证明，在温和条件下，集成模型总能比单个基础模型实现更高的认证鲁棒性。受理论发现的启发，我们提出了轻量级的多样性正则化训练（DRT）来训练认证鲁棒的集成机器学习模型。大量实验表明，我们的DRT增强的集成模型能够一致地实现比现有单个和集成机器学习模型更高的认证鲁棒性，在MNIST、CIFAR-10和ImageNet数据集上展示了最先进的认证L2鲁棒性。",
        "领域": "对抗性机器学习, 模型鲁棒性, 集成学习",
        "问题": "分析和提高集成机器学习模型对抗对抗性攻击的认证鲁棒性",
        "动机": "尽管集成模型在经验上显示出比单个模型更高的鲁棒性，但在认证鲁棒性方面仅实现了边际改进，因此需要探索保证认证鲁棒性的条件",
        "方法": "通过理论分析确定认证鲁棒性的充分必要条件，提出多样性正则化训练（DRT）方法来训练鲁棒的集成模型",
        "关键词": [
            "认证鲁棒性",
            "集成学习",
            "对抗性防御",
            "多样性正则化",
            "模型平滑性"
        ],
        "涉及的技术概念": {
            "认证鲁棒性": "在对抗性攻击下，模型能够保证正确分类的扰动范围",
            "集成学习": "通过组合多个模型来提高整体性能的技术",
            "多样性正则化训练（DRT）": "一种训练方法，通过促进模型间的多样性来提高集成模型的鲁棒性"
        },
        "success": true
    },
    {
        "order": 714,
        "title": "On the Connection between Local Attention and Dynamic Depth-wise Convolution",
        "html": "https://iclr.cc//virtual/2022/poster/6438",
        "abstract": "Vision Transformer (ViT) attains state-of-the-art performance in visual recognition, and the variant, Local Vision Transformer, makes further improvements. The major component in Local Vision Transformer, local attention, performs the attention separately over small local windows. We rephrase local attention as a channel-wise locally-connected layer and analyze it from two network regularization manners, sparse connectivity and weight sharing, as well as dynamic weight computation. We point out that local attention resembles depth-wise convolution and its dynamic variants in sparse connectivity: there is no connection across channels, and each position is connected to the positions within a small local window. The main differences lie in (i) weight sharing - depth-wise convolution shares connection weights (kernel weights) across spatial positions and attention shares the connection weights across channels, and (ii) dynamic weight computation manners - local attention is based on dot-products between pairwise positions in the local window, and dynamic convolution is based on linear projections conducted on the center representation or the globally pooled representation. The connection between local attention and dynamic depth-wise convolution is empirically verified by the ablation study about weight sharing and dynamic weight computation in Local Vision Transformer and (dynamic) depth-wise convolution. We empirically observe that the models based on depth-wise convolution and the dynamic variants with lower computation complexity perform on-par with or slightly better than Swin Transformer, an instance of Local Vision Transformer, for ImageNet classification, COCO object detection and ADE semantic segmentation. Code is available at https://github.com/Atten4Vis/DemystifyLocalViT.",
        "conference": "ICLR",
        "中文标题": "论局部注意力与动态深度可分离卷积之间的联系",
        "摘要翻译": "视觉变换器（ViT）在视觉识别任务中达到了最先进的性能，其变体——局部视觉变换器进一步提升了性能。局部视觉变换器中的主要组件——局部注意力，是在小的局部窗口内分别执行注意力操作。我们将局部注意力重新表述为通道级的局部连接层，并从两种网络正则化方式（稀疏连接和权重共享）以及动态权重计算的角度对其进行分析。我们指出，局部注意力在稀疏连接方面类似于深度可分离卷积及其动态变体：通道间没有连接，每个位置仅与小的局部窗口内的位置相连。主要差异在于（i）权重共享——深度可分离卷积在空间位置上共享连接权重（核权重），而注意力在通道间共享连接权重；（ii）动态权重计算方式——局部注意力基于局部窗口内成对位置的点积，而动态卷积基于中心表示或全局池化表示的线性投影。通过关于局部视觉变换器和（动态）深度可分离卷积中权重共享和动态权重计算的消融研究，我们实证验证了局部注意力与动态深度可分离卷积之间的联系。我们实证观察到，基于深度可分离卷积及其动态变体的模型，在计算复杂度较低的情况下，在ImageNet分类、COCO目标检测和ADE语义分割任务上的表现与局部视觉变换器的一个实例——Swin变换器相当或略优。代码可在https://github.com/Atten4Vis/DemystifyLocalViT获取。",
        "领域": "视觉变换器, 深度可分离卷积, 动态卷积",
        "问题": "探讨局部注意力机制与动态深度可分离卷积之间的联系及其在视觉任务中的应用效果",
        "动机": "理解局部注意力机制与动态深度可分离卷积之间的相似性和差异，以优化视觉变换器的设计和性能",
        "方法": "通过重新表述局部注意力为通道级局部连接层，并从稀疏连接、权重共享及动态权重计算的角度进行分析，实证比较局部注意力与动态深度可分离卷积的性能",
        "关键词": [
            "局部注意力",
            "动态深度可分离卷积",
            "视觉变换器",
            "权重共享",
            "动态权重计算"
        ],
        "涉及的技术概念": {
            "局部注意力": "在小的局部窗口内执行注意力操作，提升模型对图像局部特征的关注",
            "动态深度可分离卷积": "一种卷积操作，其在通道间不共享权重，且权重可以动态计算，用于降低模型复杂度",
            "权重共享": "在模型的不同部分共享权重参数，以减少模型参数数量并提升泛化能力"
        },
        "success": true
    },
    {
        "order": 715,
        "title": "On the Convergence of Certified Robust Training with Interval Bound Propagation",
        "html": "https://iclr.cc//virtual/2022/poster/7086",
        "abstract": "Interval Bound Propagation (IBP) is so far the base of state-of-the-art methods for training neural networks with certifiable robustness guarantees when potential adversarial perturbations present, while the convergence of IBP training remains unknown in existing literature. In this paper, we present a theoretical analysis on the convergence of IBP training. With an overparameterized assumption, we analyze the convergence of IBP robust training. We show that when using  IBP training to train a randomly initialized two-layer ReLU neural network with logistic loss, gradient descent can linearly converge to zero robust training error with a high probability if  we have sufficiently small perturbation radius and large network width.",
        "conference": "ICLR",
        "中文标题": "关于使用区间边界传播进行认证鲁棒训练的收敛性研究",
        "摘要翻译": "区间边界传播（IBP）是目前在存在潜在对抗扰动时，训练具有可证明鲁棒性保证的神经网络的最先进方法的基础，而IBP训练的收敛性在现有文献中尚属未知。本文中，我们对IBP训练的收敛性进行了理论分析。在过参数化的假设下，我们分析了IBP鲁棒训练的收敛性。我们表明，当使用IBP训练来训练一个随机初始化的两层ReLU神经网络，并采用逻辑损失时，如果我们有足够小的扰动半径和大的网络宽度，梯度下降可以以高概率线性收敛到零鲁棒训练误差。",
        "领域": "对抗性机器学习、神经网络训练、鲁棒性认证",
        "问题": "研究区间边界传播（IBP）训练方法的收敛性，特别是在对抗性扰动存在的情况下。",
        "动机": "尽管IBP是当前训练具有可证明鲁棒性保证的神经网络的最先进方法，但其训练的收敛性尚未被充分研究。",
        "方法": "在过参数化的假设下，通过理论分析研究IBP训练的收敛性，特别是在两层ReLU神经网络中使用逻辑损失和梯度下降的情况。",
        "关键词": [
            "区间边界传播",
            "鲁棒训练",
            "对抗性机器学习",
            "神经网络收敛性",
            "梯度下降"
        ],
        "涉及的技术概念": {
            "区间边界传播（IBP）": "一种用于训练具有可证明鲁棒性保证的神经网络的方法，特别是在对抗性扰动存在的情况下。",
            "过参数化": "指神经网络的参数数量远大于训练样本数量的情况，这在理论分析中常用于简化模型行为的研究。",
            "梯度下降": "一种优化算法，用于最小化损失函数，通过迭代地调整模型参数以减少预测误差。"
        },
        "success": true
    },
    {
        "order": 716,
        "title": "On the Convergence of mSGD and AdaGrad for Stochastic Optimization",
        "html": "https://iclr.cc//virtual/2022/poster/6933",
        "abstract": "As one of the most fundamental stochastic optimization algorithms, stochastic gradient descent (SGD) has been intensively developed and extensively applied in machine learning in the past decade. There have been some modified SGD-type algorithms, which outperform the SGD in many competitions and applications in terms of convergence rate and accuracy, such as momentum-based SGD (mSGD) and adaptive gradient algorithm (AdaGrad). Despite these empirical successes, the theoretical properties of these algorithms have not been well established due to technical difficulties. With this motivation, we focus on convergence analysis of mSGD and AdaGrad for any smooth (possibly non-convex) loss functions in stochastic optimization. First, we prove that the iterates of mSGD are asymptotically convergent to a connected set of stationary points with probability one, which is more general than existing works on subsequence convergence or convergence of time averages. Moreover, we prove that the loss function of mSGD decays at a certain rate faster than that of SGD. In addition, we prove the iterates of AdaGrad are asymptotically convergent to a connected set of stationary points with probability one. Also, this result extends the results from the literature on subsequence convergence and the convergence of time averages. Despite the generality of the above convergence results, we have relaxed some assumptions of gradient noises, convexity of loss functions, as well as boundedness of iterates.",
        "conference": "ICLR",
        "中文标题": "关于mSGD和AdaGrad在随机优化中的收敛性",
        "摘要翻译": "作为最基本的随机优化算法之一，随机梯度下降（SGD）在过去十年中在机器学习领域得到了深入发展和广泛应用。已经有一些改进的SGD类型算法，在许多竞赛和应用中，在收敛速度和准确性方面优于SGD，例如基于动量的SGD（mSGD）和自适应梯度算法（AdaGrad）。尽管这些算法在经验上取得了成功，但由于技术上的困难，这些算法的理论性质尚未得到很好的确立。出于这一动机，我们专注于分析mSGD和AdaGrad在随机优化中对于任何平滑（可能非凸）损失函数的收敛性。首先，我们证明了mSGD的迭代以概率一渐近收敛到一个平稳点的连通集，这比现有关于子序列收敛或时间平均收敛的工作更为一般。此外，我们证明了mSGD的损失函数以比SGD更快的速率衰减。另外，我们证明了AdaGrad的迭代以概率一渐近收敛到一个平稳点的连通集。这一结果也扩展了文献中关于子序列收敛和时间平均收敛的结果。尽管上述收敛结果具有一般性，但我们放宽了关于梯度噪声、损失函数的凸性以及迭代的有界性的一些假设。",
        "领域": "随机优化、深度学习优化算法、非凸优化",
        "问题": "分析mSGD和AdaGrad在随机优化中的收敛性，特别是在非凸损失函数下的表现。",
        "动机": "尽管mSGD和AdaGrad在应用中表现出色，但其理论性质尚未充分研究，特别是在非凸优化中的收敛性。",
        "方法": "通过理论分析，证明了mSGD和AdaGrad在非凸损失函数下的渐近收敛性，并比较了它们的收敛速率。",
        "关键词": [
            "随机梯度下降",
            "动量SGD",
            "自适应梯度算法",
            "非凸优化",
            "收敛性分析"
        ],
        "涉及的技术概念": {
            "随机梯度下降（SGD）": "一种基本的随机优化算法，用于在机器学习中最小化损失函数。",
            "动量SGD（mSGD）": "SGD的一种变体，通过引入动量项来加速收敛并减少震荡。",
            "自适应梯度算法（AdaGrad）": "一种自适应学习率的优化算法，能够自动调整每个参数的学习率。"
        },
        "success": true
    },
    {
        "order": 717,
        "title": "On the Convergence of the Monte Carlo Exploring Starts Algorithm for Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6619",
        "abstract": "A simple and natural algorithm for reinforcement learning (RL) is Monte Carlo Exploring Starts (MCES), where the Q-function is estimated by averaging the Monte Carlo returns, and the policy is improved by choosing actions that maximize the current estimate of the Q-function. Exploration is performed by 'exploring starts', that is, each episode begins with a randomly chosen state and action, and then follows the current policy to the terminal state. In the classic book on RL by Sutton & Barto (2018), it is stated that establishing convergence for the MCES algorithm is one of the most important remaining open theoretical problems in RL. However, the convergence question for MCES turns out to be quite nuanced. Bertsekas & Tsitsiklis (1996) provide a counter-example showing that the MCES algorithm does not necessarily converge. Tsitsiklis (2002) further shows that if the original MCES algorithm is modified so that the Q-function estimates are updated at the same rate for all state-action pairs, and the discount factor is strictly less than one, then the MCES algorithm converges. In this paper we make headway with the original and more efficient MCES algorithm given in Sutton et al. (1998), establishing almost sure convergence for Optimal Policy Feed-Forward MDPs, which are MDPs whose states are not revisited within any episode when using an optimal policy. Such MDPs include a large class of environments such as all deterministic environments and all episodic environments with a timestep or any monotonically changing values as part of the state. Different from the previous proofs using stochastic approximations, we introduce a novel inductive approach, which is very simple and only makes use of the strong law of large numbers.",
        "conference": "ICLR",
        "中文标题": "关于强化学习中蒙特卡洛探索起点算法的收敛性",
        "摘要翻译": "强化学习（RL）中一个简单而自然的算法是蒙特卡洛探索起点（MCES），其中Q函数通过平均蒙特卡洛回报来估计，策略通过选择最大化当前Q函数估计值的动作来改进。探索是通过'探索起点'进行的，即每个情节开始时随机选择一个状态和动作，然后遵循当前策略到达终止状态。在Sutton & Barto（2018）的经典RL书籍中，指出建立MCES算法的收敛性是RL中最重要的未解决理论问题之一。然而，MCES的收敛性问题实际上相当微妙。Bertsekas & Tsitsiklis（1996）提供了一个反例，显示MCES算法不一定收敛。Tsitsiklis（2002）进一步表明，如果修改原始MCES算法，使得所有状态-动作对的Q函数估计以相同的速率更新，并且折扣因子严格小于一，则MCES算法收敛。在本文中，我们在Sutton等人（1998）提出的原始且更高效的MCES算法上取得进展，为最优策略前馈MDP建立了几乎确定的收敛性，这些MDP在使用最优策略时，在任何情节中都不会重新访问状态。这类MDP包括一大类环境，如所有确定性环境和所有具有时间步长或任何单调变化值作为状态一部分的情节环境。不同于之前使用随机逼近的证明，我们引入了一种新颖的归纳方法，这种方法非常简单，仅利用了大数定律。",
        "领域": "强化学习",
        "问题": "蒙特卡洛探索起点算法的收敛性问题",
        "动机": "解决强化学习中蒙特卡洛探索起点算法的收敛性这一重要理论问题",
        "方法": "引入一种新颖的归纳方法，利用大数定律证明最优策略前馈MDP的几乎确定收敛性",
        "关键词": [
            "蒙特卡洛探索起点",
            "强化学习",
            "收敛性",
            "最优策略前馈MDP",
            "大数定律"
        ],
        "涉及的技术概念": {
            "蒙特卡洛探索起点（MCES）": "一种强化学习算法，通过平均蒙特卡洛回报估计Q函数，并通过选择最大化当前Q函数估计值的动作改进策略",
            "最优策略前馈MDP": "一类MDP，其状态在使用最优策略时不会在任何情节中被重新访问",
            "大数定律": "在本文中用于证明MCES算法在最优策略前馈MDP上的几乎确定收敛性"
        },
        "success": true
    },
    {
        "order": 718,
        "title": "On the Existence of Universal Lottery Tickets",
        "html": "https://iclr.cc//virtual/2022/poster/6834",
        "abstract": "The lottery ticket hypothesis conjectures the existence of sparse subnetworks of large randomly initialized deep neural networks that can be successfully trained in isolation. Recent work has experimentally observed that some of these tickets can be practically reused across a variety of tasks, hinting at some form of universality. We formalize this concept and theoretically prove that not only do such universal tickets exist but they also do not require further training. Our proofs introduce a couple of technical innovations related to pruning for strong lottery tickets, including extensions of subset sum results and a strategy to leverage higher amounts of depth. Our explicit sparse constructions of universal function families might be of independent interest, as they highlight representational benefits induced by univariate convolutional architectures. ",
        "conference": "ICLR",
        "中文标题": "论通用彩票券的存在性",
        "摘要翻译": "彩票券假说推测，大型随机初始化的深度神经网络中存在稀疏子网络，这些子网络可以独立成功训练。最近的工作通过实验观察到，其中一些彩票券实际上可以在多种任务中重复使用，暗示了某种形式的普遍性。我们形式化了这一概念，并从理论上证明了不仅存在这样的通用彩票券，而且它们不需要进一步训练。我们的证明引入了与强彩票券剪枝相关的几项技术创新，包括子集和结果的扩展以及利用更深层次结构的策略。我们对通用函数家族的显式稀疏构造可能具有独立的意义，因为它们突出了由单变量卷积架构引起的表示优势。",
        "领域": "深度学习理论、神经网络剪枝、卷积神经网络",
        "问题": "探讨深度神经网络中是否存在无需进一步训练即可跨任务通用的稀疏子网络（即通用彩票券）",
        "动机": "验证彩票券假说中关于存在可跨任务通用的稀疏子网络的理论可能性，并探索其在实际应用中的潜力",
        "方法": "通过理论证明和稀疏构造方法，验证通用彩票券的存在性，并引入子集和结果的扩展及深度利用策略作为技术支撑",
        "关键词": [
            "彩票券假说",
            "稀疏子网络",
            "通用性",
            "神经网络剪枝",
            "卷积架构"
        ],
        "涉及的技术概念": {
            "彩票券假说": "指大型随机初始化深度神经网络中存在可独立训练且性能优异的稀疏子网络的理论",
            "稀疏子网络": "在大型神经网络中通过剪枝得到的、连接稀疏的子网络，保持或提升原网络性能",
            "子集和结果扩展": "一种数学方法，用于在剪枝过程中优化子网络的选择，确保其性能"
        },
        "success": true
    },
    {
        "order": 719,
        "title": "On the Generalization of Models Trained with SGD: Information-Theoretic Bounds and Implications",
        "html": "https://iclr.cc//virtual/2022/poster/6184",
        "abstract": "This paper follows up on a recent work of Neu et al. (2021) and presents some new information-theoretic upper bounds for the generalization error of machine learning models, such as neural networks, trained with SGD. We apply these bounds to analyzing the generalization behaviour of linear and two-layer ReLU networks. Experimental study of these bounds provide some insights on the SGD training of neural networks. They also point to a new and simple regularization scheme which we show performs comparably to the current state of the art. ",
        "conference": "ICLR",
        "中文标题": "关于使用SGD训练的模型的泛化性：信息论界限及其影响",
        "摘要翻译": "本文继Neu等人（2021年）的最新工作之后，提出了一些新的信息论上界，用于机器学习模型（如神经网络）使用SGD训练时的泛化误差。我们将这些界限应用于分析线性和两层ReLU网络的泛化行为。对这些界限的实验研究提供了关于神经网络SGD训练的一些见解。它们还指向了一种新的简单正则化方案，我们展示了其与当前最先进技术相当的性能。",
        "领域": "深度学习理论、神经网络优化、泛化性分析",
        "问题": "分析使用SGD训练的机器学习模型的泛化误差界限",
        "动机": "为了更深入地理解SGD训练神经网络的泛化行为，并探索新的正则化方法",
        "方法": "提出新的信息论上界，应用于线性和两层ReLU网络的分析，并通过实验研究验证界限的有效性",
        "关键词": [
            "泛化误差",
            "SGD训练",
            "信息论界限",
            "神经网络",
            "正则化"
        ],
        "涉及的技术概念": {
            "信息论界限": "用于量化机器学习模型泛化误差的理论工具",
            "SGD训练": "随机梯度下降，一种常用的神经网络优化方法",
            "正则化方案": "用于防止模型过拟合的技术，本文提出了一种新的简单方案"
        },
        "success": true
    },
    {
        "order": 720,
        "title": "On the Importance of Difficulty Calibration in Membership Inference Attacks",
        "html": "https://iclr.cc//virtual/2022/poster/7213",
        "abstract": "The vulnerability of machine learning models to membership inference attacks has received much attention in recent years. However, existing attacks mostly remain impractical due to having high false positive rates, where non-member samples are often erroneously predicted as members. This type of error makes the predicted membership signal unreliable, especially since most samples are non-members in real world applications. In this work, we argue that membership inference attacks can benefit drastically from difficulty calibration, where an attack's predicted membership score is adjusted to the difficulty of correctly classifying the target sample. We show that difficulty calibration can significantly reduce the false positive rate of a variety of existing attacks without a loss in accuracy.",
        "conference": "ICLR",
        "中文标题": "论难度校准在成员推理攻击中的重要性",
        "摘要翻译": "近年来，机器学习模型对成员推理攻击的脆弱性受到了广泛关注。然而，现有的攻击大多由于具有较高的误报率而显得不切实际，即非成员样本经常被错误地预测为成员。这种类型的错误使得预测的成员信号不可靠，尤其是在现实世界应用中大多数样本都是非成员的情况下。在这项工作中，我们认为成员推理攻击可以极大地受益于难度校准，即攻击的预测成员分数会根据正确分类目标样本的难度进行调整。我们表明，难度校准可以显著降低多种现有攻击的误报率，而不会损失准确性。",
        "领域": "隐私保护机器学习, 对抗性攻击, 成员推理攻击",
        "问题": "降低成员推理攻击中的误报率，提高攻击的实用性。",
        "动机": "现有的成员推理攻击由于高误报率而不切实际，影响了成员信号的可信度。",
        "方法": "通过难度校准调整攻击的预测成员分数，以适应正确分类目标样本的难度。",
        "关键词": [
            "成员推理攻击",
            "难度校准",
            "误报率",
            "隐私保护",
            "机器学习安全"
        ],
        "涉及的技术概念": {
            "成员推理攻击": "一种旨在确定特定数据样本是否用于训练目标机器学习模型的攻击方法。",
            "难度校准": "调整攻击的预测成员分数，以反映正确分类目标样本的难度，旨在降低误报率。",
            "误报率": "在成员推理攻击中，非成员样本被错误地预测为成员的比例，高误报率会降低攻击的实用性。"
        },
        "success": true
    },
    {
        "order": 721,
        "title": "On the Importance of Firth Bias Reduction in Few-Shot Classification",
        "html": "https://iclr.cc//virtual/2022/poster/6221",
        "abstract": "Learning accurate classifiers for novel categories from very few examples, known as few-shot image classification, is a challenging task in statistical machine learning and computer vision. The performance in few-shot classification suffers from the bias in the estimation of classifier parameters; however, an effective underlying bias reduction technique that could alleviate this issue in training few-shot classifiers has been overlooked. In this work, we demonstrate the effectiveness of Firth bias reduction in few-shot classification. Theoretically, Firth bias reduction removes the $O(N^{-1})$ first order term from the small-sample bias of the Maximum Likelihood Estimator. Here we show that the general Firth bias reduction technique simplifies to encouraging uniform class assignment probabilities for multinomial logistic classification, and almost has the same effect in cosine classifiers. We derive an easy-to-implement optimization objective for Firth penalized multinomial logistic and cosine classifiers, which is equivalent to penalizing the cross-entropy loss with a KL-divergence between the predictions and the uniform label distribution. Then, we empirically evaluate that it is consistently effective across the board for few-shot image classification, regardless of (1) the feature representations from different backbones, (2) the number of samples per class, and (3) the number of classes. Finally, we show the robustness of Firth bias reduction, in the case of imbalanced data distribution. Our implementation is available at https://github.com/ehsansaleh/firth_bias_reduction.",
        "conference": "ICLR",
        "中文标题": "论Firth偏差减少在小样本分类中的重要性",
        "摘要翻译": "从极少数的例子中学习新类别的准确分类器，即小样本图像分类，是统计机器学习和计算机视觉中的一项挑战性任务。小样本分类的性能受到分类器参数估计偏差的影响；然而，一个有效的潜在偏差减少技术，可以在训练小样本分类器时缓解这一问题，却被忽视了。在这项工作中，我们展示了Firth偏差减少在小样本分类中的有效性。理论上，Firth偏差减少从最大似然估计器的小样本偏差中移除了$O(N^{-1})$一阶项。在这里，我们展示了通用的Firth偏差减少技术简化为鼓励多项式逻辑分类的均匀类别分配概率，并且在余弦分类器中几乎具有相同的效果。我们为Firth惩罚的多项式逻辑和余弦分类器推导了一个易于实现的优化目标，这相当于用预测和均匀标签分布之间的KL散度惩罚交叉熵损失。然后，我们通过实证评估表明，无论（1）来自不同骨干的特征表示，（2）每类样本的数量，还是（3）类别数量，它对于小样本图像分类都是普遍有效的。最后，我们展示了Firth偏差减少在数据分布不平衡情况下的鲁棒性。我们的实现可在https://github.com/ehsansaleh/firth_bias_reduction找到。",
        "领域": "小样本学习、图像分类、统计机器学习",
        "问题": "解决小样本图像分类中分类器参数估计偏差的问题",
        "动机": "探索和验证Firth偏差减少技术在小样本分类中的有效性，以缓解分类器参数估计偏差带来的性能问题",
        "方法": "采用Firth偏差减少技术，推导出易于实现的优化目标，通过惩罚交叉熵损失与均匀标签分布之间的KL散度来优化分类器",
        "关键词": [
            "小样本学习",
            "Firth偏差减少",
            "图像分类",
            "统计机器学习",
            "KL散度"
        ],
        "涉及的技术概念": {
            "Firth偏差减少": "一种统计技术，用于减少最大似然估计中的小样本偏差，通过移除偏差的一阶项来提高估计的准确性",
            "KL散度": "用于衡量两个概率分布之间的差异，在本研究中用于惩罚预测分布与均匀标签分布之间的差异",
            "交叉熵损失": "一种常用的损失函数，用于衡量模型预测概率分布与真实标签分布之间的差异，本研究通过KL散度对其进行惩罚以优化模型"
        },
        "success": true
    },
    {
        "order": 722,
        "title": "On the Learning and Learnability of Quasimetrics",
        "html": "https://iclr.cc//virtual/2022/poster/7182",
        "abstract": "Our world is full of asymmetries. Gravity and wind can make reaching a place easier than coming back. Social artifacts such as genealogy charts and citation graphs are inherently directed. In reinforcement learning and control, optimal goal-reaching strategies are rarely reversible (symmetrical). Distance functions supported on these asymmetrical structures are called quasimetrics. Despite their common appearance, little research has been done on the learning of quasimetrics. Our theoretical analysis reveals that a common class of learning algorithms, including unconstrained multilayer perceptrons (MLPs), provably fails to learn a quasimetric consistent with training data. In contrast, our proposed Poisson Quasimetric Embedding (PQE) is the first quasimetric learning formulation that both is learnable with gradient-based optimization and enjoys strong performance guarantees. Experiments on random graphs, social graphs, and offline Q-learning demonstrate its effectiveness over many common baselines.",
        "conference": "ICLR",
        "中文标题": "关于拟度量的学习与可学习性",
        "摘要翻译": "我们的世界充满了不对称性。重力和风可以使到达一个地方比返回更容易。诸如家谱图和引用图等社会产物本质上是定向的。在强化学习和控制中，最优目标达成策略很少是可逆的（对称的）。支持这些不对称结构的距离函数被称为拟度量。尽管它们普遍存在，但关于拟度量的学习研究却很少。我们的理论分析揭示了一类常见的学习算法，包括无约束的多层感知机（MLPs），被证明无法学习与训练数据一致的拟度量。相比之下，我们提出的泊松拟度量嵌入（PQE）是第一个既可以通过基于梯度的优化学习，又享有强大性能保证的拟度量学习公式。在随机图、社会图和离线Q学习上的实验证明了其相对于许多常见基线的有效性。",
        "领域": "强化学习、图表示学习、优化算法",
        "问题": "如何有效地学习和应用拟度量以处理现实世界中的不对称性问题",
        "动机": "现实世界中存在大量不对称性结构，而现有的学习算法在处理这些结构的拟度量学习上存在不足，需要开发新的方法来解决这一问题",
        "方法": "提出泊松拟度量嵌入（PQE）方法，该方法通过基于梯度的优化学习拟度量，并在多种图上验证其有效性",
        "关键词": [
            "拟度量学习",
            "泊松嵌入",
            "梯度优化",
            "不对称性处理",
            "强化学习"
        ],
        "涉及的技术概念": {
            "拟度量": "一种支持不对称结构的距离函数，用于衡量不同点之间的距离",
            "多层感知机（MLPs）": "一种常见的神经网络结构，被证明无法有效学习拟度量",
            "泊松拟度量嵌入（PQE）": "一种新的拟度量学习方法，能够通过梯度优化学习并保证性能"
        },
        "success": true
    },
    {
        "order": 723,
        "title": "On the Limitations of Multimodal VAEs",
        "html": "https://iclr.cc//virtual/2022/poster/6996",
        "abstract": "Multimodal variational autoencoders (VAEs) have shown promise as efficient generative models for weakly-supervised data. Yet, despite their advantage of weak supervision, they exhibit a gap in generative quality compared to unimodal VAEs, which are completely unsupervised. In an attempt to explain this gap, we uncover a fundamental limitation that applies to a large family of mixture-based multimodal VAEs. We prove that the sub-sampling of modalities enforces an undesirable upper bound on the multimodal ELBO and thereby limits the generative quality of the respective models.  Empirically, we showcase the generative quality gap on both synthetic and real data and present the tradeoffs between different variants of multimodal VAEs. We find that none of the existing approaches fulfills all desired criteria of an effective multimodal generative model when applied on more complex datasets than those used in previous benchmarks. In summary, we identify, formalize, and validate fundamental limitations of VAE-based approaches for modeling weakly-supervised data and discuss implications for real-world applications.",
        "conference": "ICLR",
        "中文标题": "论多模态变分自编码器的局限性",
        "摘要翻译": "多模态变分自编码器（VAEs）作为弱监督数据的高效生成模型显示出了潜力。然而，尽管它们具有弱监督的优势，与完全无监督的单模态VAEs相比，它们在生成质量上存在差距。为了解释这一差距，我们发现了一个适用于大量基于混合的多模态VAEs的基本限制。我们证明了模态的子采样强制了一个不理想的多模态ELBO上界，从而限制了相应模型的生成质量。实证上，我们在合成数据和真实数据上展示了生成质量的差距，并提出了不同多模态VAEs变体之间的权衡。我们发现，当应用于比先前基准测试中使用的更复杂的数据集时，现有的方法没有一个能满足有效多模态生成模型的所有期望标准。总之，我们识别、形式化并验证了基于VAE的方法在建模弱监督数据时的基本限制，并讨论了其对现实世界应用的影响。",
        "领域": "生成模型、多模态学习、弱监督学习",
        "问题": "多模态变分自编码器在生成质量上与单模态变分自编码器存在差距的问题",
        "动机": "解释多模态变分自编码器在生成质量上存在差距的原因，并探索其基本限制",
        "方法": "通过理论证明和实证分析，揭示模态子采样对多模态ELBO上界的影响，并评估不同多模态VAEs变体的性能",
        "关键词": [
            "多模态变分自编码器",
            "生成质量",
            "弱监督学习",
            "模态子采样",
            "ELBO上界"
        ],
        "涉及的技术概念": {
            "多模态变分自编码器": "一种能够处理来自多种模态数据的生成模型，旨在通过弱监督学习提高数据生成效率",
            "模态子采样": "在多模态数据处理中，选择性地忽略某些模态的数据，可能导致生成模型性能的限制",
            "ELBO上界": "变分自编码器中证据下界（ELBO）的理论上限，影响模型的生成质量和学习效率"
        },
        "success": true
    },
    {
        "order": 724,
        "title": "On the Optimal Memorization Power of ReLU Neural Networks",
        "html": "https://iclr.cc//virtual/2022/poster/7214",
        "abstract": "We study the memorization power of feedforward ReLU neural networks. We show that such networks can memorize any $N$ points that satisfy a mild separability assumption using $\\tilde{O}\\left(\\sqrt{N}\\right)$ parameters. Known VC-dimension upper bounds imply that memorizing $N$ samples requires $\\Omega(\\sqrt{N})$ parameters, and hence our construction is optimal up to logarithmic factors. We also give a generalized construction for networks with depth bounded by $1 \\leq L \\leq \\sqrt{N}$, for memorizing $N$ samples using $\\tilde{O}(N/L)$ parameters. This bound is also optimal up to logarithmic factors. Our construction uses weights with large bit complexity. We prove that having such a large bit complexity is both necessary and sufficient for memorization with a sub-linear number of parameters.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "论ReLU神经网络的最优记忆能力",
        "摘要翻译": "我们研究了前馈ReLU神经网络的记忆能力。我们证明，这类网络能够记忆满足温和可分性假设的任何N个点，使用的参数数量为O(√N)（对数因子忽略不计）。已知的VC维上界表明，记忆N个样本需要Ω(√N)个参数，因此我们的构造在对数因子内是最优的。我们还给出了一个广义构造，用于深度限制在1≤L≤√N的网络，记忆N个样本使用O(N/L)个参数（对数因子忽略不计）。这个界限在对数因子内也是最优的。我们的构造使用了具有大位复杂度的权重。我们证明了，对于使用亚线性数量的参数进行记忆，拥有如此大的位复杂度既是必要的也是充分的。",
        "领域": "深度学习理论、神经网络优化、计算学习理论",
        "问题": "研究ReLU神经网络在记忆任意N个满足温和可分性假设的点时的最优参数效率问题。",
        "动机": "探索ReLU神经网络在记忆任务中的参数效率极限，以验证其在实际应用中的潜力与限制。",
        "方法": "通过理论分析和构造性证明，展示了使用O(√N)参数记忆N个点的最优性，并扩展到不同深度网络的广义构造。",
        "关键词": [
            "ReLU神经网络",
            "记忆能力",
            "参数效率",
            "VC维",
            "位复杂度"
        ],
        "涉及的技术概念": {
            "ReLU神经网络": "使用线性整流单元作为激活函数的前馈神经网络，本文研究其在记忆任务中的表现。",
            "VC维": "用于衡量模型复杂度的概念，本文中用于证明记忆N个样本所需参数的下界。",
            "位复杂度": "指权重表示所需的位数，本文证明了大位复杂度对于实现亚线性参数记忆的必要性和充分性。"
        }
    },
    {
        "order": 725,
        "title": "On the Pitfalls of Analyzing Individual Neurons in Language Models",
        "html": "https://iclr.cc//virtual/2022/poster/6897",
        "abstract": "While many studies have shown that linguistic information is encoded in hidden word representations, few have studied individual neurons, to show how and in which neurons it is encoded.Among these, the common approach is to use an external probe to rank neurons according to their relevance to some linguistic attribute, and to evaluate the obtained ranking using the same probe that produced it.We show two pitfalls in this methodology:    1. It confounds distinct factors: probe quality and ranking quality.    We separate them and draw conclusions on each.    2. It focuses on encoded information, rather than information that is used by the model.    We show that these are not the same.We compare two recent ranking methods and a simple one we introduce, and evaluate them with regard to both of these aspects.",
        "conference": "ICLR",
        "中文标题": "论语言模型中分析单个神经元的陷阱",
        "摘要翻译": "虽然许多研究表明语言信息被编码在隐藏的词表示中，但很少有研究关注单个神经元，以展示信息是如何以及在哪些神经元中被编码的。在这些研究中，常见的方法是使用外部探针根据神经元与某些语言属性的相关性对神经元进行排序，并使用产生该排序的同一探针来评估所获得的排序。我们展示了这种方法论中的两个陷阱：1. 它混淆了不同的因素：探针质量和排序质量。我们将它们分开并对每个因素得出结论。2. 它关注的是编码的信息，而不是模型使用的信息。我们表明这两者并不相同。我们比较了两种最近的排序方法和我们引入的一种简单方法，并就这两个方面对它们进行了评估。",
        "领域": "自然语言处理与视觉结合、语言模型分析、神经元编码研究",
        "问题": "分析语言模型中单个神经元编码语言信息的方法论陷阱",
        "动机": "揭示当前研究方法中混淆探针质量与排序质量、以及忽视模型实际使用信息的问题",
        "方法": "比较两种现有排序方法和一种新引入的简单方法，从探针质量和排序质量两个维度进行评估",
        "关键词": [
            "语言模型",
            "神经元分析",
            "探针质量",
            "排序方法",
            "信息编码"
        ],
        "涉及的技术概念": {
            "外部探针": "用于评估神经元与语言属性相关性的工具，但可能混淆探针本身的质量和排序的有效性",
            "神经元排序": "根据神经元对特定语言属性的贡献进行排序，但需区分编码信息与模型实际使用信息",
            "信息编码与使用": "研究中需区分神经元编码的信息和模型实际利用的信息，二者可能不一致"
        },
        "success": true
    },
    {
        "order": 726,
        "title": "On the Pitfalls of Heteroscedastic Uncertainty Estimation with Probabilistic Neural Networks",
        "html": "https://iclr.cc//virtual/2022/poster/6755",
        "abstract": "Capturing aleatoric uncertainty is a critical part of many machine learning systems. In deep learning, a common approach to this end is to train a neural network to estimate the parameters of a heteroscedastic Gaussian distribution by maximizing the logarithm of the likelihood function under the observed data. In this work, we examine this approach and identify potential hazards associated with the use of log-likelihood in conjunction with gradient-based optimizers. First, we present a synthetic example illustrating how this approach can lead to very poor but stable parameter estimates. Second, we identify the culprit to be the log-likelihood loss, along with certain conditions that exacerbate the issue. Third, we present an alternative formulation, termed $\\beta$-NLL, in which each data point's contribution to the loss is weighted by the $\\beta$-exponentiated variance estimate. We show that using an appropriate $\\beta$ largely mitigates the issue in our illustrative example. Fourth, we evaluate this approach on a range of domains and tasks and show that it achieves considerable improvements and performs more robustly concerning hyperparameters, both in predictive RMSE and log-likelihood criteria.",
        "conference": "ICLR",
        "中文标题": "关于概率神经网络中异方差不确定性估计的陷阱",
        "摘要翻译": "捕捉偶然不确定性是许多机器学习系统的关键部分。在深度学习中，实现这一目标的常见方法是通过最大化观测数据下的对数似然函数来训练神经网络估计异方差高斯分布的参数。在这项工作中，我们研究了这种方法，并确定了与使用对数似然结合基于梯度的优化器相关的潜在危险。首先，我们提出了一个合成示例，说明这种方法如何导致非常差但稳定的参数估计。其次，我们确定罪魁祸首是对数似然损失，以及某些加剧问题的条件。第三，我们提出了一种替代方案，称为β-NLL，其中每个数据点对损失的贡献由β指数化的方差估计加权。我们表明，在我们的示例中，使用适当的β在很大程度上缓解了这个问题。第四，我们在多个领域和任务上评估了这种方法，并表明它在预测RMSE和对数似然标准上都实现了相当大的改进，并且在超参数方面表现得更加强健。",
        "领域": "概率深度学习, 不确定性估计, 机器学习优化",
        "问题": "研究揭示了在使用对数似然结合基于梯度的优化器进行异方差不确定性估计时可能遇到的陷阱和问题。",
        "动机": "为了解决在概率神经网络中估计异方差不确定性时，使用对数似然损失可能导致的不良但稳定的参数估计问题。",
        "方法": "提出了一种名为β-NLL的替代损失函数，通过为每个数据点的损失贡献加权来缓解问题，并在多个领域和任务上进行了评估。",
        "关键词": [
            "异方差不确定性",
            "概率神经网络",
            "对数似然",
            "β-NLL",
            "机器学习优化"
        ],
        "涉及的技术概念": {
            "异方差不确定性": "在概率神经网络中，异方差不确定性指的是模型预测的不确定性随输入数据的变化而变化。",
            "对数似然损失": "用于训练概率神经网络以估计参数的标准损失函数，可能导致不良的参数估计。",
            "β-NLL": "一种改进的损失函数，通过为每个数据点的损失贡献加权来缓解标准对数似然损失的问题。"
        },
        "success": true
    },
    {
        "order": 727,
        "title": "On the relation between statistical learning and perceptual distances",
        "html": "https://iclr.cc//virtual/2022/poster/6765",
        "abstract": "It has been demonstrated many times that the behavior of the human visual system is connected to the statistics of natural images. Since machine learning relies on the statistics of training data as well, the above connection has interesting implications when using perceptual distances (which mimic the behavior of the human visual system) as a loss function. In this paper, we aim to unravel the non-trivial relationships between the probability distribution of the data, perceptual distances, and unsupervised machine learning. To this end, we show that perceptual sensitivity is correlated with the probability of an image in its close neighborhood. We also explore the relation between distances induced by autoencoders and the probability distribution of the training data, as well as how these induced distances are correlated with human perception. Finally, we find perceptual distances do not always lead to noticeable gains in performance over Euclidean distance in common image processing tasks, except when data is scarce and the perceptual distance provides regularization. We propose this may be due to a double-counting effect of the image statistics, once in the perceptual distance and once in the training procedure.",
        "conference": "ICLR",
        "中文标题": "论统计学习与感知距离之间的关系",
        "摘要翻译": "已有多次研究表明，人类视觉系统的行为与自然图像的统计特性相关。由于机器学习同样依赖于训练数据的统计特性，当使用感知距离（模仿人类视觉系统的行为）作为损失函数时，上述关联具有有趣的启示。在本文中，我们旨在揭示数据的概率分布、感知距离和无监督机器学习之间非平凡的关系。为此，我们展示了感知敏感性与图像在其邻近区域内的概率相关。我们还探讨了自编码器诱导的距离与训练数据概率分布之间的关系，以及这些诱导距离如何与人类感知相关。最后，我们发现，在常见的图像处理任务中，感知距离并不总是比欧几里得距离带来显著的性能提升，除非数据稀缺且感知距离提供了正则化。我们提出，这可能是由于图像统计在感知距离和训练过程中被双重计数的影响。",
        "领域": "计算机视觉与感知模型、无监督学习、图像处理",
        "问题": "揭示数据的概率分布、感知距离和无监督机器学习之间的复杂关系",
        "动机": "探索人类视觉系统行为与自然图像统计特性之间的联系，以及这种联系在机器学习中的应用和影响",
        "方法": "分析感知敏感性与图像概率的关系，研究自编码器诱导距离与数据分布及人类感知的关联，评估感知距离在图像处理任务中的效果",
        "关键词": [
            "感知距离",
            "统计学习",
            "无监督学习",
            "自编码器",
            "图像处理"
        ],
        "涉及的技术概念": {
            "感知距离": "模仿人类视觉系统行为的距离度量，用于作为损失函数",
            "自编码器": "一种无监督学习模型，用于学习数据的有效表示并诱导距离度量",
            "双重计数效应": "指图像统计特性在感知距离和训练过程中被重复考虑，可能影响模型性能的现象"
        },
        "success": true
    },
    {
        "order": 728,
        "title": "On the Role of Neural Collapse in Transfer Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6574",
        "abstract": "We study the ability of foundation models to learn representations for classification that are transferable to new, unseen classes. Recent results in the literature show that representations learned by a single classifier over many classes are competitive on few-shot learning problems with representations learned by special-purpose algorithms designed for such problems. In this paper, we provide an explanation for this behavior based on the recently observed phenomenon that the features learned by overparameterized classification networks show an interesting clustering property, called neural collapse. We demonstrate both theoretically and empirically that neural collapse generalizes to new samples from the training classes, and -- more importantly -- to new classes as well, allowing foundation models to provide feature maps that work well in transfer learning and, specifically, in the few-shot setting.",
        "conference": "ICLR",
        "中文标题": "论神经崩溃在迁移学习中的作用",
        "摘要翻译": "我们研究了基础模型在学习分类表示方面的能力，这些表示能够迁移到新的、未见过的类别中。文献中的最新结果表明，通过单一分类器在许多类别上学习到的表示，与专为此类问题设计的特殊算法学习到的表示相比，在少样本学习问题上具有竞争力。在本文中，我们基于最近观察到的现象，即通过过参数化分类网络学习的特征显示出一种有趣的聚类特性，称为神经崩溃，为这种行为提供了解释。我们从理论上和经验上证明了神经崩溃不仅能够推广到训练类别的新样本，更重要的是，也能够推广到新类别，这使得基础模型能够提供在迁移学习中，特别是在少样本设置中表现良好的特征映射。",
        "领域": "迁移学习",
        "问题": "解释基础模型在少样本学习中的表现为何能与专为少样本学习设计的算法相竞争",
        "动机": "探索神经崩溃现象如何促进基础模型在迁移学习中的表现",
        "方法": "通过理论和实证分析，研究神经崩溃现象在迁移学习中的应用",
        "关键词": [
            "神经崩溃",
            "迁移学习",
            "少样本学习",
            "基础模型",
            "过参数化网络"
        ],
        "涉及的技术概念": {
            "神经崩溃": "指过参数化分类网络学习到的特征在训练过程中自发形成的聚类现象，有助于模型在迁移学习中表现优异",
            "迁移学习": "利用在一个任务上学到的知识来帮助解决另一个相关任务的技术",
            "少样本学习": "在仅有少量样本的情况下进行有效学习的技术"
        },
        "success": true
    },
    {
        "order": 729,
        "title": "On the role of population heterogeneity in emergent communication",
        "html": "https://iclr.cc//virtual/2022/poster/6605",
        "abstract": "Populations have often been perceived as a structuring component for language to emerge and evolve: the larger the population, the more systematic the language. While this observation is widespread in the sociolinguistic literature, it has not been reproduced in computer simulations with neural agents. In this paper, we thus aim to clarify this apparent contradiction. We explore emergent language properties by varying agent population size in the speaker-listener Lewis Game. After reproducing the experimental paradox, we challenge the simulation assumption that the agent community is homogeneous. We first investigate how speaker-listener asymmetry alters language structure to examine two potential diversity factors: training speed and network capacity. We find out that emergent language properties are only altered by the relative difference of factors between speaker and listener, and not by their absolute values. From then, we leverage this observation to control population heterogeneity without introducing confounding factors. We finally show that introducing such training speed heterogeneities naturally sort out the initial paradox: larger simulated communities start developing more systematic and structured languages.",
        "conference": "ICLR",
        "中文标题": "论人口异质性在涌现通信中的作用",
        "摘要翻译": "人口常被视为语言涌现和演化的结构化组成部分：人口规模越大，语言越系统化。尽管这一观察在社会语言学文献中广泛存在，但在使用神经代理的计算机模拟中尚未重现。因此，本文旨在澄清这一明显的矛盾。我们通过在说话者-听者Lewis游戏中变化代理人口规模来探索涌现语言的性质。在重现实验悖论后，我们挑战了代理社区是同质的模拟假设。我们首先研究了说话者-听者不对称如何改变语言结构，以考察两个潜在的多样性因素：训练速度和网络容量。我们发现，涌现语言的性质仅由说话者和听者之间因素的相对差异改变，而非它们的绝对值。由此，我们利用这一观察来控制人口异质性，而不引入混淆因素。最后，我们展示了引入这种训练速度异质性自然地解决了初始悖论：更大的模拟社区开始发展出更系统和结构化的语言。",
        "领域": "自然语言处理与视觉结合, 多智能体系统, 社会语言学计算模型",
        "问题": "澄清人口规模与语言系统化之间在社会语言学观察与计算机模拟中的矛盾",
        "动机": "探索人口异质性如何影响涌现通信的性质，特别是在说话者-听者不对称的情况下",
        "方法": "通过变化代理人口规模和引入训练速度异质性，研究其对涌现语言系统化和结构化的影响",
        "关键词": [
            "涌现通信",
            "人口异质性",
            "说话者-听者不对称",
            "训练速度",
            "网络容量"
        ],
        "涉及的技术概念": {
            "涌现通信": "研究在无预先定义通信协议的情况下，代理之间如何通过交互发展出通信系统",
            "说话者-听者不对称": "探讨说话者和听者在通信过程中的不同角色和能力如何影响通信系统的结构",
            "训练速度异质性": "通过控制代理之间的训练速度差异，研究其对通信系统发展的影响"
        },
        "success": true
    },
    {
        "order": 730,
        "title": "On the Uncomputability of Partition Functions in Energy-Based Sequence Models",
        "html": "https://iclr.cc//virtual/2022/poster/7146",
        "abstract": "In this paper, we argue that energy-based sequence models backed by expressive parametric families can result in uncomputable and inapproximable partition functions. Among other things, this makes model selection--and therefore learning model parameters--not only difficult, but generally _undecidable_. The reason is that there are no good deterministic or randomized estimates of partition functions. Specifically, we exhibit a pathological example where under common assumptions, _no_ useful importance sampling estimates of the partition function can guarantee to have variance bounded below a rational number. As alternatives, we consider sequence model families whose partition functions are computable (if they exist), but at the cost of reduced expressiveness. Our theoretical results suggest that statistical procedures with asymptotic guarantees and sheer (but finite) amounts of compute are not the only things that make sequence modeling work; computability concerns must not be neglected as we consider more expressive model parametrizations.",
        "conference": "ICLR",
        "中文标题": "基于能量的序列模型中配分函数的不可计算性",
        "摘要翻译": "在本文中，我们认为，由表达性参数族支持的基于能量的序列模型可能导致配分函数的不可计算和不可近似性。除此之外，这使得模型选择——进而学习模型参数——不仅困难，而且通常是_不可判定的_。原因是没有好的确定性或随机性估计配分函数的方法。具体来说，我们展示了一个病理例子，在常见假设下，_没有_有用的重要性采样估计配分函数可以保证方差低于有理数。作为替代方案，我们考虑了配分函数可计算的序列模型家族（如果它们存在的话），但代价是降低了表达性。我们的理论结果表明，具有渐近保证和大量（但有限）计算的统计程序不是使序列建模工作的唯一因素；在我们考虑更具表达性的模型参数化时，不可计算性问题不容忽视。",
        "领域": "序列建模、统计机器学习、计算复杂性理论",
        "问题": "基于能量的序列模型中配分函数的不可计算性和不可近似性问题",
        "动机": "探讨在表达性参数族支持的基于能量的序列模型中，配分函数的不可计算性如何影响模型选择和参数学习",
        "方法": "通过理论分析展示配分函数估计的困难，并提出配分函数可计算的序列模型家族作为替代方案",
        "关键词": [
            "配分函数",
            "不可计算性",
            "序列模型",
            "重要性采样",
            "模型选择"
        ],
        "涉及的技术概念": {
            "配分函数": "在基于能量的序列模型中用于归一化概率分布的函数，本文探讨其不可计算性",
            "重要性采样": "一种估计配分函数的随机方法，本文展示其在某些情况下无法提供有用的估计",
            "不可判定性": "指在某些基于能量的序列模型中，模型选择和参数学习问题无法通过算法解决"
        },
        "success": true
    },
    {
        "order": 731,
        "title": "OntoProtein: Protein Pretraining With Gene Ontology Embedding",
        "html": "https://iclr.cc//virtual/2022/poster/6505",
        "abstract": "Self-supervised protein language models have proved their effectiveness in learning the proteins representations. With the increasing computational power, current protein language models pre-trained with millions of diverse sequences can advance the parameter scale from million-level to billion-level and achieve remarkable improvement. However, those prevailing approaches rarely consider incorporating knowledge graphs (KGs), which can provide rich structured knowledge facts for better protein representations. We argue that informative biology knowledge in KGs can enhance protein representation with external knowledge. In this work, we propose OntoProtein, the first general framework that makes use of structure in GO (Gene Ontology) into protein pre-training models. We construct a novel large-scale knowledge graph that consists of GO and its related proteins, and gene annotation texts or protein sequences describe all nodes in the graph. We propose novel contrastive learning with knowledge-aware negative sampling to jointly optimize the knowledge graph and protein embedding during pre-training.  Experimental results show that OntoProtein can surpass state-of-the-art methods with pre-trained protein language models in TAPE benchmark and yield better performance compared with baselines in protein-protein interaction and protein function prediction.",
        "conference": "ICLR",
        "中文标题": "OntoProtein：基于基因本体嵌入的蛋白质预训练",
        "摘要翻译": "自监督蛋白质语言模型已证明其在学习蛋白质表示方面的有效性。随着计算能力的提升，当前利用数百万条多样化序列预训练的蛋白质语言模型可以将参数规模从百万级提升到十亿级，并实现显著的性能改进。然而，这些主流方法很少考虑融入知识图谱（KGs），而知识图谱可以提供丰富的结构化知识事实，以获得更好的蛋白质表示。我们认为，知识图谱中的信息性生物学知识可以通过外部知识增强蛋白质表示。在这项工作中，我们提出了OntoProtein，这是第一个利用基因本体（GO）结构到蛋白质预训练模型中的通用框架。我们构建了一个新颖的大规模知识图谱，该图谱由GO及其相关蛋白质组成，并且图中的所有节点都由基因注释文本或蛋白质序列描述。我们提出了新颖的对比学习与知识感知负采样方法，以在预训练期间联合优化知识图谱和蛋白质嵌入。实验结果表明，OntoProtein在TAPE基准测试中可以超越最先进的预训练蛋白质语言模型方法，并且在蛋白质-蛋白质相互作用和蛋白质功能预测方面与基线相比具有更好的性能。",
        "领域": "蛋白质语言模型、知识图谱与生物信息学结合、蛋白质功能预测",
        "问题": "如何将基因本体（GO）的结构化知识融入蛋白质预训练模型中，以增强蛋白质表示。",
        "动机": "利用知识图谱中的结构化生物学知识来增强蛋白质语言模型的表示能力，以提升蛋白质相关任务的性能。",
        "方法": "提出OntoProtein框架，构建包含GO及其相关蛋白质的大规模知识图谱，并采用知识感知负采样的对比学习方法联合优化知识图谱和蛋白质嵌入。",
        "关键词": [
            "蛋白质预训练",
            "基因本体",
            "知识图谱",
            "对比学习",
            "蛋白质功能预测"
        ],
        "涉及的技术概念": {
            "基因本体（GO）": "一种用于统一表示基因和基因产物属性的生物学术语系统，OntoProtein利用其结构化知识来增强蛋白质表示。",
            "知识感知负采样": "一种在对比学习中使用的技术，通过考虑知识图谱中的信息来生成负样本，以优化蛋白质和知识图谱的嵌入。",
            "对比学习": "一种自监督学习方法，通过比较正负样本来学习数据的表示，OntoProtein中用于联合优化知识图谱和蛋白质嵌入。"
        },
        "success": true
    },
    {
        "order": 732,
        "title": "Open-Set Recognition: A Good Closed-Set Classifier is All You Need",
        "html": "https://iclr.cc//virtual/2022/poster/6727",
        "abstract": "The ability to identify whether or not a test sample belongs to one of the semantic classes in a classifier's training set is critical to practical deployment of the model. This task is termed open-set recognition (OSR) and has received significant attention in recent years. In this paper, we first demonstrate that the ability of a classifier to make the 'none-of-above' decision is highly correlated with its accuracy on the closed-set classes. We find that this relationship holds across loss objectives and architectures, and further demonstrate the trend both on the standard OSR benchmarks as well as on a large-scale ImageNet evaluation. Second, we use this correlation to boost the performance of the maximum softmax probability OSR 'baseline' by improving its closed-set accuracy, and with this strong baseline achieve state-of-the-art on a number of OSR benchmarks. Similarly, we boost the performance of the existing state-of-the-art method by improving its closed-set accuracy, but the resulting discrepancy with the strong baseline is marginal. Our third contribution is to present the 'Semantic Shift Benchmark' (SSB), which better respects the task of detecting semantic novelty, as opposed to low-level distributional shifts as tackled by neighbouring machine learning fields. On this new evaluation, we again demonstrate that there is negligible difference between the strong baseline and the existing state-of-the-art. Code available at: https://github.com/sgvaze/osr_closed_set_all_you_need.",
        "conference": "ICLR",
        "中文标题": "开放集识别：一个好的封闭集分类器就是你所需的一切",
        "摘要翻译": "识别测试样本是否属于分类器训练集中的某个语义类别对于模型的实际部署至关重要。这项任务被称为开放集识别（OSR），近年来受到了广泛关注。在本文中，我们首先证明了分类器做出‘以上都不是’决定的能力与其在封闭集类别上的准确性高度相关。我们发现这种关系在不同的损失目标和架构中都成立，并在标准OSR基准测试和大规模ImageNet评估中进一步证明了这一趋势。其次，我们利用这种相关性通过提高其封闭集准确性来提升最大softmax概率OSR‘基线’的性能，并通过这一强大基线在多个OSR基准测试中实现了最先进的性能。同样，我们通过提高现有最先进方法的封闭集准确性来提升其性能，但由此产生的与强大基线的差异微乎其微。我们的第三个贡献是提出了‘语义转移基准’（SSB），它更好地尊重了检测语义新颖性的任务，而不是邻近机器学习领域所处理的低级分布转移。在这一新的评估中，我们再次证明了强大基线与现有最先进方法之间的差异可以忽略不计。代码可在https://github.com/sgvaze/osr_closed_set_all_you_need获取。",
        "领域": "开放集识别",
        "问题": "如何提高分类器在开放集识别任务中的性能",
        "动机": "探索分类器在封闭集上的准确性与开放集识别能力之间的关系，并基于此提升开放集识别的性能",
        "方法": "通过提高封闭集分类器的准确性来增强开放集识别的性能，并提出新的语义转移基准（SSB）来评估模型",
        "关键词": [
            "开放集识别",
            "封闭集分类器",
            "语义转移基准"
        ],
        "涉及的技术概念": {
            "开放集识别（OSR）": "识别测试样本是否属于分类器训练集中的某个语义类别的任务",
            "封闭集准确性": "分类器在已知类别上的识别准确率，与开放集识别能力高度相关",
            "语义转移基准（SSB）": "一个新的评估基准，专注于检测语义新颖性，而非低级分布转移"
        },
        "success": true
    },
    {
        "order": 733,
        "title": "Open-vocabulary Object Detection via Vision and Language Knowledge Distillation",
        "html": "https://iclr.cc//virtual/2022/poster/6372",
        "abstract": "We aim at advancing open-vocabulary object detection, which detects objects described by arbitrary text inputs. The fundamental challenge is the availability of training data.  It is costly to further scale up the number of classes contained in existing object detection datasets. To overcome this challenge, we propose ViLD, a training method via Vision and Language knowledge Distillation. Our method distills the knowledge from a pretrained open-vocabulary image classification model (teacher) into a two-stage detector (student). Specifically, we use the teacher model to encode category texts and image regions of object proposals. Then we train a student detector, whose region embeddings of detected boxes are aligned with the text and image embeddings inferred by the teacher. We benchmark on LVIS by holding out all rare categories as novel categories that are not seen during training. ViLD obtains 16.1 mask APr with a ResNet-50 backbone, even outperforming the supervised counterpart by 3.8. When trained with a stronger teacher model ALIGN, ViLD achieves 26.3 APr. The model can directly transfer to other datasets without finetuning, achieving 72.2 AP50 on PASCAL VOC, 36.6 AP on COCO and 11.8 AP on Objects365. On COCO, ViLD outperforms the previous state-of-the-art (Zareian et al., 2021) by 4.8 on novel AP and 11.4 on overall AP. Code and demo are open-sourced at https://github.com/tensorflow/tpu/tree/master/models/official/detection/projects/vild.",
        "conference": "ICLR",
        "中文标题": "通过视觉与语言知识蒸馏实现开放词汇目标检测",
        "摘要翻译": "我们的目标是推进开放词汇目标检测，即检测由任意文本输入描述的对象。根本的挑战在于训练数据的可用性。进一步扩大现有目标检测数据集中包含的类别数量成本高昂。为了克服这一挑战，我们提出了ViLD，一种通过视觉与语言知识蒸馏的训练方法。我们的方法从一个预训练的开放词汇图像分类模型（教师）中蒸馏知识到一个两阶段检测器（学生）中。具体来说，我们使用教师模型来编码类别文本和对象提议的图像区域。然后我们训练一个学生检测器，其检测框的区域嵌入与教师推断的文本和图像嵌入对齐。我们在LVIS上进行了基准测试，将所有稀有类别作为训练期间未见的新类别保留。ViLD使用ResNet-50骨干网络获得了16.1的掩码APr，甚至比监督对应物高出3.8。当使用更强的教师模型ALIGN训练时，ViLD达到了26.3 APr。该模型可以直接迁移到其他数据集而无需微调，在PASCAL VOC上达到72.2 AP50，在COCO上达到36.6 AP，在Objects365上达到11.8 AP。在COCO上，ViLD在新AP上比之前的最先进技术（Zareian等人，2021年）高出4.8，在整体AP上高出11.4。代码和演示已在https://github.com/tensorflow/tpu/tree/master/models/official/detection/projects/vild开源。",
        "领域": "开放词汇目标检测",
        "问题": "解决开放词汇目标检测中训练数据稀缺的问题",
        "动机": "扩大目标检测的类别范围，使其能够检测由任意文本描述的对象",
        "方法": "通过视觉与语言知识蒸馏，从预训练的开放词汇图像分类模型中提取知识，训练两阶段检测器",
        "关键词": [
            "开放词汇目标检测",
            "知识蒸馏",
            "视觉与语言模型"
        ],
        "涉及的技术概念": {
            "知识蒸馏": "从教师模型中提取知识，用于训练学生模型，以解决训练数据稀缺的问题",
            "两阶段检测器": "一种目标检测方法，首先生成对象提议，然后对这些提议进行分类和边界框回归",
            "开放词汇图像分类模型": "能够识别和分类由任意文本描述的对象的预训练模型"
        },
        "success": true
    },
    {
        "order": 734,
        "title": "Open-World Semi-Supervised Learning",
        "html": "https://iclr.cc//virtual/2022/poster/7118",
        "abstract": "A fundamental limitation of applying semi-supervised learning in real-world settings is the assumption that unlabeled test data contains only classes previously encountered in the labeled training data. However, this assumption rarely holds for data in-the-wild, where instances belonging to novel classes may appear at testing time. Here, we introduce a novel open-world semi-supervised learning setting that formalizes the notion that novel classes may appear in the unlabeled test data. In this novel setting, the goal is to solve the class distribution mismatch problem between labeled and unlabeled data, where at the test time every input instance either needs to be classified into one of the existing classes or a new unseen class needs to be initialized and the instance assigned to it. To tackle this challenging problem, we propose ORCA, an end-to-end approach that assigns instances to previously seen classes or  forms novel classes by grouping similar instances without assuming any prior knowledge. The key idea in ORCA is to utilize uncertainty adaptive margin to circumvent the bias towards seen classes caused by learning seen classes faster than the novel classes. In this way, ORCA gradually increases the discriminability of the model during the training and reduces the gap between intra-class variance of seen with respect to novel classes. Extensive experiments on image classification datasets and a single-cell dataset demonstrate that ORCA consistently outperforms alternative baselines, achieving 25% improvement on seen and 96% improvement on novel classes of the ImageNet dataset. ",
        "conference": "ICLR",
        "中文标题": "开放世界的半监督学习",
        "摘要翻译": "在半监督学习应用于现实世界场景时，一个基本的限制是假设未标记的测试数据仅包含先前在标记训练数据中遇到的类别。然而，这一假设很少适用于野外数据，因为在测试时可能会出现属于新类别的实例。在这里，我们引入了一种新颖的开放世界半监督学习设置，该设置形式化了未标记测试数据中可能出现新类别的概念。在这一新设置中，目标是解决标记和未标记数据之间的类别分布不匹配问题，其中在测试时，每个输入实例要么需要被分类到现有类别之一，要么需要初始化一个新的未见类别并将实例分配给它。为了应对这一挑战性问题，我们提出了ORCA，一种端到端的方法，该方法将实例分配给先前见过的类别或通过在没有假设任何先验知识的情况下将相似实例分组来形成新类别。ORCA中的关键思想是利用不确定性自适应边际来规避由于学习见过的类别比新类别更快而导致的偏向于见过类别的问题。通过这种方式，ORCA在训练过程中逐渐增加模型的可区分性，并减少见过类别相对于新类别的类内方差差距。在图像分类数据集和单细胞数据集上的大量实验表明，ORCA始终优于替代基线，在ImageNet数据集的见过类别上实现了25%的改进，在新类别上实现了96%的改进。",
        "领域": "半监督学习",
        "问题": "解决在开放世界场景中，未标记测试数据可能包含新类别时的半监督学习问题",
        "动机": "现实世界中的数据往往包含训练时未见的新类别，传统的半监督学习方法无法有效处理这种情况",
        "方法": "提出ORCA方法，通过不确定性自适应边际减少对见过类别的偏向，逐步提高模型对新类别的识别能力",
        "关键词": [
            "开放世界学习",
            "半监督学习",
            "类别分布不匹配",
            "不确定性自适应边际",
            "ORCA"
        ],
        "涉及的技术概念": {
            "开放世界半监督学习": "一种新的学习设置，允许在测试时出现训练时未见的新类别",
            "不确定性自适应边际": "用于减少模型对见过类别的偏向，平衡新旧类别的学习速度",
            "ORCA": "一种端到端的开放世界半监督学习方法，能够识别新类别并分配实例"
        },
        "success": true
    },
    {
        "order": 735,
        "title": "Optimal ANN-SNN Conversion for High-accuracy and Ultra-low-latency Spiking Neural Networks",
        "html": "https://iclr.cc//virtual/2022/poster/5899",
        "abstract": "Spiking Neural Networks (SNNs) have gained great attraction due to their distinctive properties of low power consumption and fast inference on neuromorphic hardware. As the most effective method to get deep SNNs, ANN-SNN conversion has achieved comparable performance as ANNs on large-scale datasets. Despite this, it requires long time-steps to match the firing rates of SNNs to the activation of ANNs. As a result, the converted SNN suffers severe performance degradation problems with short time-steps, which hamper the practical application of SNNs. In this paper, we theoretically analyze ANN-SNN conversion error and derive the estimated activation function of SNNs. Then we propose the quantization clip-floor-shift activation function to replace the ReLU activation function in source ANNs, which can better approximate the activation function of SNNs. We prove that the expected conversion error between SNNs and ANNs is zero, enabling us to achieve high-accuracy and ultra-low-latency SNNs. We evaluate our method on CIFAR-10/100 and ImageNet datasets, and show that it outperforms the state-of-the-art ANN-SNN and directly trained SNNs in both accuracy and time-steps. To the best of our knowledge, this is the first time to explore high-performance ANN-SNN conversion with ultra-low latency (4 time-steps). Code is available at https://github.com/putshua/SNN_conversion_QCFS",
        "conference": "ICLR",
        "中文标题": "实现高精度和超低延迟脉冲神经网络的最优ANN-SNN转换方法",
        "摘要翻译": "脉冲神经网络（SNNs）因其在神经形态硬件上的低功耗和快速推理特性而受到广泛关注。作为获取深度SNNs的最有效方法，ANN-SNN转换已在大规模数据集上实现了与人工神经网络（ANNs）相当的性能。尽管如此，它需要长时间步来匹配SNNs的发放率与ANNs的激活。因此，转换后的SNN在短时间步下会遭受严重的性能下降问题，这阻碍了SNNs的实际应用。在本文中，我们从理论上分析了ANN-SNN转换误差，并推导了SNNs的估计激活函数。然后，我们提出了量化clip-floor-shift激活函数来替代源ANNs中的ReLU激活函数，这可以更好地近似SNNs的激活函数。我们证明了SNNs和ANNs之间的预期转换误差为零，使我们能够实现高精度和超低延迟的SNNs。我们在CIFAR-10/100和ImageNet数据集上评估了我们的方法，并表明它在准确性和时间步上都优于最先进的ANN-SNN和直接训练的SNNs。据我们所知，这是首次探索具有超低延迟（4个时间步）的高性能ANN-SNN转换。代码可在https://github.com/putshua/SNN_conversion_QCFS获取。",
        "领域": "神经形态计算、脉冲神经网络、深度学习优化",
        "问题": "解决ANN-SNN转换在短时间步下性能下降的问题",
        "动机": "探索实现高精度和超低延迟的SNNs，以促进其在实际应用中的使用",
        "方法": "提出量化clip-floor-shift激活函数替代ReLU，理论上分析并减少转换误差",
        "关键词": [
            "脉冲神经网络",
            "ANN-SNN转换",
            "超低延迟",
            "量化激活函数",
            "神经形态计算"
        ],
        "涉及的技术概念": {
            "ANN-SNN转换": "将人工神经网络转换为脉冲神经网络的技术，以实现低功耗和快速推理",
            "量化clip-floor-shift激活函数": "用于替代ReLU激活函数，以更好地近似SNNs的激活行为，减少转换误差",
            "神经形态硬件": "专为模拟生物神经系统设计的硬件，能够高效运行SNNs，实现低功耗和快速处理"
        },
        "success": true
    },
    {
        "order": 736,
        "title": "Optimal Representations for Covariate Shift",
        "html": "https://iclr.cc//virtual/2022/poster/6901",
        "abstract": "Machine learning systems often experience a distribution shift between training and testing. In this paper, we introduce a simple variational objective whose optima are exactly the set of all representations on which risk minimizers are guaranteed to be robust to any distribution shift that preserves the Bayes predictor, e.g., covariate shifts. Our objective has two components. First, a representation must remain discriminative for the task, i.e., some predictor must be able to simultaneously minimize the source and target risk. Second, the representation's marginal support needs to be the same across source and target. We make this practical by designing self-supervised objectives that only use unlabelled data and augmentations to train robust representations. Our objectives give insights into the robustness of CLIP, and further improve CLIP's representations to achieve SOTA results on DomainBed.",
        "conference": "ICLR",
        "中文标题": "协变量偏移的最优表示",
        "摘要翻译": "机器学习系统经常在训练和测试之间经历分布偏移。在本文中，我们引入了一个简单的变分目标，其最优解恰好是所有表示的集合，这些表示上的风险最小化器保证对任何保留贝叶斯预测器的分布偏移（例如协变量偏移）都具有鲁棒性。我们的目标有两个组成部分。首先，表示必须对任务保持区分性，即某些预测器必须能够同时最小化源和目标风险。其次，表示的边际支持在源和目标之间需要相同。我们通过设计仅使用未标记数据和增强来训练鲁棒表示的自监督目标，使这一点变得实用。我们的目标提供了对CLIP鲁棒性的见解，并进一步改进了CLIP的表示，以在DomainBed上实现最先进的结果。",
        "领域": "自监督学习, 表示学习, 领域适应",
        "问题": "如何在分布偏移（特别是协变量偏移）的情况下，学习到能够保证风险最小化器鲁棒性的最优表示。",
        "动机": "为了解决机器学习系统在训练和测试数据分布不一致时的性能下降问题，特别是在协变量偏移的情况下，寻找能够保持预测性能的最优表示。",
        "方法": "引入一个变分目标，该目标通过确保表示的区分性和边际支持的一致性，来学习对分布偏移鲁棒的表示，并通过自监督学习仅使用未标记数据和数据增强来实现。",
        "关键词": [
            "协变量偏移",
            "自监督学习",
            "表示学习",
            "领域适应",
            "变分目标"
        ],
        "涉及的技术概念": {
            "变分目标": "用于学习对分布偏移鲁棒的最优表示的目标函数，确保表示的区分性和边际支持的一致性。",
            "自监督学习": "仅使用未标记数据和数据增强来训练模型的方法，用于学习鲁棒的表示。",
            "协变量偏移": "输入变量的分布发生变化，但条件分布保持不变的情况，是本文研究的主要分布偏移类型。"
        },
        "success": true
    },
    {
        "order": 737,
        "title": "Optimal Transport for Causal Discovery",
        "html": "https://iclr.cc//virtual/2022/poster/6780",
        "abstract": "To determine causal relationships between two variables, approaches based on Functional Causal Models (FCMs) have been proposed by properly restricting model classes; however, the performance is sensitive to the model assumptions, which makes it difficult to use. In this paper, we provide a novel dynamical-system view of FCMs and propose a new framework for identifying causal direction in the bivariate case. We first show the connection between FCMs and optimal transport, and then study optimal transport under the constraints of FCMs. Furthermore, by exploiting the dynamical interpretation of optimal transport under the FCM constraints, we determine the corresponding underlying dynamical process of the static cause-effect pair data. It provides a new dimension for describing static causal discovery tasks while enjoying more freedom for modeling the quantitative causal influences. In particular, we show that Additive Noise Models (ANMs) correspond to volume-preserving pressureless flows. Consequently, based on their velocity field divergence, we introduce a criterion for determining causal direction. With this criterion, we propose a novel optimal transport-based algorithm for ANMs which is robust to the choice of models and extend it to post-nonlinear models. Our method demonstrated state-of-the-art results on both synthetic and causal discovery benchmark datasets.",
        "conference": "ICLR",
        "中文标题": "最优传输在因果发现中的应用",
        "摘要翻译": "为了确定两个变量之间的因果关系，基于功能因果模型（FCMs）的方法已被提出，通过适当限制模型类别；然而，性能对模型假设敏感，这使得其难以使用。在本文中，我们提供了FCMs的新动态系统视角，并提出了一个用于双变量情况下识别因果方向的新框架。我们首先展示了FCMs与最优传输之间的联系，然后研究了在FCMs约束下的最优传输。此外，通过利用FCMs约束下最优传输的动态解释，我们确定了静态因果对数据对应的潜在动态过程。它为描述静态因果发现任务提供了新的维度，同时在建模定量因果影响方面享有更多的自由度。特别是，我们展示了加性噪声模型（ANMs）对应于体积保持的无压流动。因此，基于它们的速度场散度，我们引入了一个确定因果方向的准则。利用这一准则，我们提出了一种新的基于最优传输的ANMs算法，该算法对模型的选择具有鲁棒性，并将其扩展到后非线性模型。我们的方法在合成和因果发现基准数据集上都展示了最先进的结果。",
        "领域": "因果发现、最优传输理论、动态系统建模",
        "问题": "如何在不依赖严格的模型假设下，有效地确定两个变量之间的因果关系。",
        "动机": "现有的基于功能因果模型（FCMs）的方法对模型假设敏感，限制了其在实际中的应用。",
        "方法": "通过将FCMs与最优传输理论结合，提出了一种新的动态系统视角下的因果发现框架，并基于速度场散度引入了确定因果方向的准则。",
        "关键词": [
            "最优传输",
            "因果发现",
            "动态系统",
            "加性噪声模型",
            "后非线性模型"
        ],
        "涉及的技术概念": {
            "最优传输": "用于在FCMs约束下研究因果关系的数学框架，提供了描述静态因果发现任务的新维度。",
            "功能因果模型（FCMs）": "用于确定变量间因果关系的模型，本文通过动态系统视角重新解释。",
            "加性噪声模型（ANMs）": "一种特定的FCMs，对应于体积保持的无压流动，本文基于其速度场散度提出了确定因果方向的准则。"
        },
        "success": true
    },
    {
        "order": 738,
        "title": "Optimal Transport for Long-Tailed Recognition with Learnable Cost Matrix",
        "html": "https://iclr.cc//virtual/2022/poster/6454",
        "abstract": "It is attracting attention to the long-tailed recognition problem, a burning issue that has become very popular recently. Distinctive from conventional recognition is that it posits that the allocation of the training set is supremely distorted. Predictably, it will pose challenges to the generalisation behaviour of the model. Approaches to these challenges revolve into two groups: firstly, training-aware methods, with the aim of enhancing the generalisability of the model by exploiting its potential in the training period; and secondly, post-hoc correction, liberally coupled with training-aware methods, which is intended to refine the predictions to the extent possible in the post-processing stage, offering the advantages of simplicity and effectiveness. This paper introduces an alternative direction to do the post-hoc correction, which goes beyond the statistical methods. Mathematically, we approach this issue from the perspective of optimal transport (OT), yet, choosing the exact cost matrix when applying OT is challenging and requires expert knowledge of various tasks. To overcome this limitation, we propose to employ linear mapping to learn the cost matrix without necessary configurations adaptively. Testing our methods in practice, along with high efficiency and excellent performance, our method surpasses all previous methods and has the best performance to date.",
        "conference": "ICLR",
        "中文标题": "可学习成本矩阵的最优传输用于长尾识别",
        "摘要翻译": "长尾识别问题近来引起了广泛关注，这是一个近期变得非常热门的问题。与传统识别不同，它假设训练集的分配极度扭曲。可以预见，这将给模型的泛化行为带来挑战。应对这些挑战的方法主要分为两类：第一类是训练感知方法，旨在通过挖掘模型在训练期间的潜力来增强其泛化能力；第二类是事后校正方法，通常与训练感知方法自由结合，旨在后处理阶段尽可能细化预测，具有简单有效的优势。本文介绍了一种超越统计方法的事后校正新方向。数学上，我们从最优传输（OT）的角度来处理这个问题，然而，在应用OT时选择精确的成本矩阵具有挑战性，并且需要各种任务的专家知识。为了克服这一限制，我们提出使用线性映射自适应地学习成本矩阵，而无需必要的配置。在实践中测试我们的方法，除了高效率和高性能外，我们的方法超越了所有先前的方法，并取得了迄今为止的最佳性能。",
        "领域": "长尾识别",
        "问题": "解决长尾数据分布下的模型泛化能力问题",
        "动机": "长尾数据分布对模型泛化能力构成挑战，需要开发新的方法来提高模型在长尾识别任务中的性能",
        "方法": "提出一种基于最优传输（OT）的事后校正方法，通过线性映射自适应地学习成本矩阵，无需专家知识配置",
        "关键词": [
            "长尾识别",
            "最优传输",
            "成本矩阵学习",
            "事后校正",
            "模型泛化"
        ],
        "涉及的技术概念": {
            "最优传输（OT）": "用于从数学角度处理长尾识别问题，通过最小化传输成本来优化模型预测",
            "成本矩阵学习": "通过线性映射自适应地学习成本矩阵，克服了传统方法需要专家知识配置的限制",
            "事后校正": "在后处理阶段细化模型预测，提高模型在长尾识别任务中的性能"
        },
        "success": true
    },
    {
        "order": 739,
        "title": "Optimization and Adaptive Generalization of Three layer Neural Networks",
        "html": "https://iclr.cc//virtual/2022/poster/6848",
        "abstract": "While there has been substantial recent work studying  generalization of neural networks, the ability of deep nets in automating the process of feature extraction still evades a thorough mathematical understanding.  As a step toward this goal, we analyze learning and generalization of a three-layer neural network with ReLU activations in a regime that goes beyond the linear approximation of the network, and is hence not captured by the common Neural Tangent Kernel. We show that despite nonconvexity of the empirical loss, a variant of SGD converges in polynomially many iterations to a good solution that generalizes. In particular, our generalization bounds are adaptive: they automatically optimize over a family of kernels that includes the Neural Tangent Kernel, to provide the tightest bound.  ",
        "conference": "ICLR",
        "中文标题": "三层神经网络的优化与自适应泛化",
        "摘要翻译": "尽管近期有大量工作研究神经网络的泛化能力，但深度网络在自动化特征提取过程中的能力仍然缺乏彻底的数学理解。作为实现这一目标的一步，我们分析了具有ReLU激活函数的三层神经网络在超越网络线性近似范围的学习和泛化能力，这一范围因此未被常见的神经切线核所捕获。我们表明，尽管经验损失是非凸的，但一种随机梯度下降的变体能够在多项式次数的迭代中收敛到一个泛化良好的解。特别是，我们的泛化界限是自适应的：它们自动在一系列包括神经切线核的核中进行优化，以提供最紧的界限。",
        "领域": "深度学习理论、神经网络优化、自适应学习",
        "问题": "理解深度神经网络在特征提取自动化过程中的能力，并提供数学上的解释。",
        "动机": "当前对深度神经网络泛化能力的数学理解不足，特别是在超越线性近似范围的情况下。",
        "方法": "分析具有ReLU激活函数的三层神经网络的学习和泛化能力，使用一种随机梯度下降的变体进行优化。",
        "关键词": [
            "神经网络优化",
            "自适应泛化",
            "ReLU激活函数",
            "随机梯度下降",
            "神经切线核"
        ],
        "涉及的技术概念": {
            "ReLU激活函数": "在神经网络中引入非线性，使得网络能够学习复杂的模式。",
            "随机梯度下降(SGD)": "一种优化算法，用于最小化损失函数，特别适用于大规模数据集。",
            "神经切线核(NTK)": "描述无限宽度神经网络在训练初期动态的理论工具，用于分析网络的泛化能力。"
        },
        "success": true
    },
    {
        "order": 740,
        "title": "Optimization inspired Multi-Branch Equilibrium Models",
        "html": "https://iclr.cc//virtual/2022/poster/6461",
        "abstract": "Works have shown the strong connections between some implicit models and optimization problems. However, explorations on such relationships are limited. Most works pay attention to some common mathematical properties, such as sparsity. In this work, we propose a new type of implicit model inspired by the designing of the systems' hidden objective functions, called the Multi-branch Optimization induced Equilibrium networks~(MOptEqs). The model architecture is designed based on modelling the hidden objective function for the multi-resolution recognition task. Furthermore, we also propose a new training strategy inspired by our understandings of the hidden objective function. In this manner, the proposed model can better utilize the hierarchical patterns for recognition tasks and retain the abilities for interpreting the whole structure as trying to obtain the minima of the problem's goal. Comparing with the state-of-the-art models, our MOptEqs not only enjoys better explainability but are also superior to MDEQ with less parameter consumption and better performance on practical tasks. Furthermore, we also implement various experiments to demonstrate the effectiveness of our new methods and explore the applicability of the model's hidden objective function.",
        "conference": "ICLR",
        "中文标题": "优化启发的多分支均衡模型",
        "摘要翻译": "已有工作表明某些隐式模型与优化问题之间存在紧密联系。然而，对此类关系的探索仍然有限。大多数工作关注于一些常见的数学属性，如稀疏性。在本工作中，我们提出了一种新型的隐式模型，其灵感来源于系统隐藏目标函数的设计，称为多分支优化诱导均衡网络（MOptEqs）。该模型架构基于为多分辨率识别任务建模隐藏目标函数而设计。此外，我们还提出了一种新的训练策略，灵感来源于我们对隐藏目标函数的理解。通过这种方式，所提出的模型能够更好地利用层次模式进行识别任务，并保留将整个结构解释为试图获得问题目标的最小值的能力。与最先进的模型相比，我们的MOptEqs不仅具有更好的可解释性，而且在参数消耗更少的情况下优于MDEQ，并在实际任务中表现更佳。此外，我们还实施了各种实验来证明我们新方法的有效性，并探索模型隐藏目标函数的适用性。",
        "领域": "深度学习与优化理论结合、多分辨率图像识别、隐式模型设计",
        "问题": "探索隐式模型与优化问题之间的关系，并设计一种新型的隐式模型以更好地利用层次模式进行识别任务。",
        "动机": "现有对隐式模型与优化问题关系的研究有限，大多数工作仅关注于一些常见的数学属性，如稀疏性，缺乏对隐藏目标函数设计的深入探索。",
        "方法": "提出多分支优化诱导均衡网络（MOptEqs），基于为多分辨率识别任务建模隐藏目标函数设计模型架构，并提出新的训练策略以更好地理解和利用隐藏目标函数。",
        "关键词": [
            "多分支均衡模型",
            "优化诱导",
            "隐式模型",
            "多分辨率识别",
            "隐藏目标函数"
        ],
        "涉及的技术概念": {
            "多分支优化诱导均衡网络（MOptEqs）": "一种新型的隐式模型，通过建模隐藏目标函数来设计，用于多分辨率识别任务。",
            "隐藏目标函数": "模型设计中未直接表示但通过模型架构和训练策略间接优化的目标函数，用于指导模型学习。",
            "层次模式利用": "通过理解隐藏目标函数，模型能够更有效地利用数据中的层次结构信息进行识别任务。"
        },
        "success": true
    },
    {
        "order": 741,
        "title": "Optimizer Amalgamation",
        "html": "https://iclr.cc//virtual/2022/poster/6427",
        "abstract": "Selecting an appropriate optimizer for a given problem is of major interest for researchers and practitioners. Many analytical optimizers have been proposed using a variety of theoretical and empirical approaches; however, none can offer a universal advantage over other competitive optimizers. We are thus motivated to study a new problem named Optimizer Amalgamation: how can we best combine a pool of 'teacher' optimizers into a single 'student' optimizer that can have stronger problem-specific performance? In this paper, we draw inspiration from the field of 'learning to optimize' to use a learnable amalgamation target. First, we define three differentiable amalgamation mechanisms to amalgamate a pool of analytical optimizers by gradient descent. Then, in order to reduce variance of the amalgamation process, we also explore methods to stabilize the amalgamation process by perturbing the amalgamation target. Finally, we present experiments showing the superiority of our amalgamated optimizer compared to its amalgamated components and learning to optimize baselines, and the efficacy of our variance reducing perturbations.",
        "conference": "ICLR",
        "中文标题": "优化器融合",
        "摘要翻译": "为给定问题选择合适的优化器对研究人员和实践者来说至关重要。已经提出了许多使用各种理论和经验方法的分析优化器；然而，没有一个能在所有问题上都优于其他竞争优化器。因此，我们受到启发研究一个名为优化器融合的新问题：如何最好地将一组'教师'优化器融合成一个单一的'学生'优化器，使其在特定问题上具有更强的性能？在本文中，我们从'学习优化'领域汲取灵感，使用可学习的融合目标。首先，我们定义了三种可微分的融合机制，通过梯度下降来融合一组分析优化器。然后，为了减少融合过程的方差，我们还探索了通过扰动融合目标来稳定融合过程的方法。最后，我们展示了实验，证明了我们的融合优化器相较于其融合组件和学习优化基线方法的优越性，以及我们减少方差的扰动方法的有效性。",
        "领域": "深度学习优化方法、自动机器学习、优化算法",
        "问题": "如何将多个优化器融合成一个在特定问题上表现更优的单一优化器",
        "动机": "现有的优化器各有优势，但没有一个能在所有问题上都表现最佳，因此研究如何融合多个优化器的优势成为一个重要问题",
        "方法": "定义了三种可微分的融合机制通过梯度下降融合优化器，并探索通过扰动融合目标来减少方差的方法",
        "关键词": [
            "优化器融合",
            "学习优化",
            "梯度下降",
            "方差减少",
            "深度学习优化"
        ],
        "涉及的技术概念": {
            "优化器融合": "将多个优化器的优势融合成一个单一的优化器，以提高在特定问题上的性能",
            "学习优化": "利用机器学习方法来自动化优化过程的技术",
            "梯度下降": "一种通过沿着目标函数的梯度方向迭代更新参数以最小化目标函数的优化方法"
        },
        "success": true
    },
    {
        "order": 742,
        "title": "Optimizing Neural Networks with Gradient Lexicase Selection",
        "html": "https://iclr.cc//virtual/2022/poster/5996",
        "abstract": "One potential drawback of using aggregated performance measurement in machine learning is that models may learn to accept higher errors on some training cases as compromises for lower errors on others, with the lower errors actually being instances of overfitting. This can lead both to stagnation at local optima and to poor generalization. Lexicase selection is an uncompromising method developed in evolutionary computation, which selects models on the basis of sequences of individual training case errors instead of using aggregated metrics such as loss and accuracy. In this paper, we investigate how the general idea of lexicase selection can fit into the context of deep learning to improve generalization. We propose Gradient Lexicase Selection, an optimization framework that combines gradient descent and lexicase selection in an evolutionary fashion. Experimental results show that the proposed method improves the generalization performance of various popular deep neural network architectures on three image classification benchmarks. Qualitative analysis also indicates that our method helps the networks learn more diverse representations.",
        "conference": "ICLR",
        "中文标题": "使用梯度字典选择优化神经网络",
        "摘要翻译": "在机器学习中使用聚合性能测量的一个潜在缺点是，模型可能学会接受在某些训练案例上的较高错误，以换取在其他案例上的较低错误，而这些较低错误实际上是过拟合的实例。这既可能导致在局部最优处停滞不前，也可能导致泛化能力差。字典选择是进化计算中开发的一种不妥协的方法，它基于单个训练案例错误的序列来选择模型，而不是使用诸如损失和准确性之类的聚合指标。在本文中，我们研究了字典选择的一般思想如何适应深度学习的背景以提高泛化能力。我们提出了梯度字典选择，这是一个将梯度下降和字典选择以进化方式结合的优化框架。实验结果表明，所提出的方法在三个图像分类基准上提高了各种流行的深度神经网络架构的泛化性能。定性分析还表明，我们的方法有助于网络学习更多样化的表示。",
        "领域": "深度学习优化、图像分类、进化计算",
        "问题": "解决机器学习中因使用聚合性能测量导致的模型泛化能力差和局部最优停滞问题",
        "动机": "通过引入进化计算中的字典选择方法，提高深度学习模型的泛化能力和避免过拟合",
        "方法": "提出梯度字典选择框架，结合梯度下降和字典选择，以进化方式优化神经网络",
        "关键词": [
            "梯度字典选择",
            "深度学习优化",
            "图像分类",
            "泛化能力",
            "进化计算"
        ],
        "涉及的技术概念": {
            "字典选择": "一种基于单个训练案例错误序列选择模型的方法，避免使用聚合指标，以提高泛化能力",
            "梯度下降": "用于优化神经网络权重的标准方法，与字典选择结合以进化方式提升性能",
            "泛化能力": "模型在未见数据上的表现能力，本文通过新方法旨在提高这一能力"
        },
        "success": true
    },
    {
        "order": 743,
        "title": "Orchestrated Value Mapping for Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6000",
        "abstract": "We present a general convergent class of reinforcement learning algorithms that is founded on two distinct principles: (1) mapping value estimates to a different space using arbitrary functions from a broad class, and (2) linearly decomposing the reward signal into multiple channels. The first principle enables incorporating specific properties into the value estimator that can enhance learning. The second principle, on the other hand, allows for the value function to be represented as a composition of multiple utility functions. This can be leveraged for various purposes, e.g. dealing with highly varying reward scales, incorporating a priori knowledge about the sources of reward, and ensemble learning. Combining the two principles yields a general blueprint for instantiating convergent algorithms by orchestrating diverse mapping functions over multiple reward channels. This blueprint generalizes and subsumes algorithms such as Q-Learning, Log Q-Learning, and Q-Decomposition. In addition, our convergence proof for this general class relaxes certain required assumptions in some of these algorithms. Based on our theory, we discuss several interesting configurations as special cases. Finally, to illustrate the potential of the design space that our theory opens up, we instantiate a particular algorithm and evaluate its performance on the Atari suite.",
        "conference": "ICLR",
        "中文标题": "强化学习中的协调价值映射",
        "摘要翻译": "我们提出了一类基于两个不同原则的通用收敛强化学习算法：（1）使用来自广泛类别的任意函数将价值估计映射到不同的空间，（2）将奖励信号线性分解为多个通道。第一个原则使得能够将特定属性纳入价值估计器，从而增强学习。另一方面，第二个原则允许价值函数表示为多个效用函数的组合。这可以用于多种目的，例如处理高度变化的奖励尺度、纳入关于奖励来源的先验知识以及集成学习。将这两个原则结合起来，产生了一个通过在多个奖励通道上协调不同映射函数来实例化收敛算法的通用蓝图。这个蓝图概括并包含了诸如Q学习、对数Q学习和Q分解等算法。此外，我们对这一通用类的收敛证明放宽了其中一些算法中所需的某些假设。基于我们的理论，我们讨论了几个有趣的特殊案例配置。最后，为了说明我们的理论开辟的设计空间的潜力，我们实例化了一个特定的算法，并在Atari套件上评估了其性能。",
        "领域": "强化学习、算法优化、多任务学习",
        "问题": "如何在强化学习中更有效地利用价值估计和奖励信号以提升学习效率和性能",
        "动机": "通过协调不同的映射函数和奖励通道，开发一类更通用、更灵活的强化学习算法，以克服现有算法在处理高度变化的奖励尺度和集成学习等方面的限制",
        "方法": "结合价值估计的空间映射和奖励信号的线性分解，提出一个通用的算法框架，并通过实例化算法验证其有效性",
        "关键词": [
            "强化学习",
            "价值映射",
            "奖励分解",
            "算法收敛",
            "Atari游戏"
        ],
        "涉及的技术概念": {
            "价值映射": "将价值估计通过特定函数映射到不同空间，以增强学习效率和性能",
            "奖励分解": "将奖励信号线性分解为多个通道，便于处理复杂奖励结构和集成学习",
            "算法收敛": "通过理论证明，确保提出的算法框架在广泛条件下能够收敛"
        },
        "success": true
    },
    {
        "order": 744,
        "title": "Out-of-distribution Generalization in the Presence of Nuisance-Induced Spurious Correlations",
        "html": "https://iclr.cc//virtual/2022/poster/6290",
        "abstract": "In many prediction problems, spurious correlations are induced by a changing relationship between the label and a nuisance variable that is also correlated with the covariates. For example, in classifying animals in natural images, the background, which is a nuisance, can predict the type of animal. This nuisance-label relationship does not always hold, and the performance of a model trained under one such relationship may be poor on data with a different nuisance-label relationship. To build predictive models that perform well regardless of the nuisance-label relationship, we develop Nuisance-Randomized Distillation (NURD). We introduce the nuisance-randomized distribution, a distribution where the nuisance and the label are independent. Under this distribution, we define the set of representations such that conditioning on any member, the nuisance and the label remain independent. We prove that the representations in this set always perform better than chance, while representations outside of this set may not. NURD finds a representation from this set that is most informative of the label under the nuisance-randomized distribution, and we prove that this representation achieves the highest performance regardless of the nuisance-label relationship. We evaluate NURD on several tasks including chest X-ray classification where, using non-lung patches as the nuisance, NURD produces models that predict pneumonia under strong spurious correlations.",
        "conference": "ICLR",
        "中文标题": "在存在干扰引起的虚假相关性情况下的分布外泛化",
        "摘要翻译": "在许多预测问题中，标签与干扰变量之间变化的关系会诱导出虚假相关性，这种干扰变量也与协变量相关。例如，在自然图像中对动物进行分类时，背景（作为一种干扰）可以预测动物的类型。这种干扰与标签的关系并不总是成立，在一个这样的关系下训练的模型在具有不同干扰-标签关系的数据上可能表现不佳。为了构建无论干扰-标签关系如何都能表现良好的预测模型，我们开发了干扰随机蒸馏（NURD）。我们引入了干扰随机分布，这是一种干扰和标签独立的分布。在这种分布下，我们定义了一组表示，使得在给定任何成员的情况下，干扰和标签保持独立。我们证明，这个集合中的表示总是比随机表现更好，而集合之外的表示可能不会。NURD从这个集合中找到一个在干扰随机分布下对标签信息量最大的表示，我们证明这种表示无论干扰-标签关系如何都能达到最高性能。我们在包括胸部X光分类在内的多个任务上评估了NURD，其中使用非肺部区域作为干扰，NURD在强虚假相关性下预测肺炎的模型。",
        "领域": "医学图像分析",
        "问题": "解决在存在干扰变量引起的虚假相关性时，模型在分布外数据上泛化能力差的问题",
        "动机": "开发能够在不同干扰-标签关系下保持高性能的预测模型",
        "方法": "引入干扰随机分布，开发干扰随机蒸馏（NURD）方法，寻找在干扰随机分布下对标签信息量最大的表示",
        "关键词": [
            "干扰随机蒸馏",
            "虚假相关性",
            "分布外泛化",
            "医学图像分类"
        ],
        "涉及的技术概念": {
            "干扰随机分布": "一种干扰和标签独立的分布，用于定义一组表示，使得在给定任何成员的情况下，干扰和标签保持独立",
            "NURD方法": "干扰随机蒸馏方法，用于从干扰随机分布中寻找对标签信息量最大的表示",
            "虚假相关性": "由干扰变量和标签之间变化的关系诱导出的相关性，可能导致模型在分布外数据上表现不佳"
        },
        "success": true
    },
    {
        "order": 745,
        "title": "Overcoming The Spectral Bias of Neural Value Approximation",
        "html": "https://iclr.cc//virtual/2022/poster/6564",
        "abstract": "Value approximation using deep neural networks is at the heart of off-policy deep reinforcement learning, and is often the primary module that provides learning signals to the rest of the algorithm.  While multi-layer perceptrons are universal function approximators, recent works in neural kernel regression suggest the presence of a \\textit{spectral bias}, where fitting high-frequency components of the value function requires exponentially more gradient update steps than the low-frequency ones. In this work, we re-examine off-policy reinforcement learning through the lens of kernel regression and propose to overcome such bias via a composite neural tangent kernel. With just a single line-change, our approach, the Fourier feature networks (FFN) produce state-of-the-art performance on challenging continuous control domains with only a fraction of the compute. Faster convergence and better off-policy stability also make it possible to remove the target network without suffering catastrophic divergences, which further reduces \\(\\text{TD}(0)\\)'s bias to over-estimate the value.",
        "conference": "ICLR",
        "中文标题": "克服神经价值近似的光谱偏差",
        "摘要翻译": "使用深度神经网络进行价值近似是离策略深度强化学习的核心，通常是向算法的其余部分提供学习信号的主要模块。虽然多层感知器是通用的函数逼近器，但最近在神经核回归中的研究表明存在一种光谱偏差，即拟合价值函数的高频成分比低频成分需要指数级更多的梯度更新步骤。在这项工作中，我们通过核回归的视角重新审视离策略强化学习，并提出通过复合神经切线核来克服这种偏差。仅需一行代码的改变，我们的方法——傅里叶特征网络（FFN）就在具有挑战性的连续控制领域实现了最先进的性能，且仅需一小部分计算量。更快的收敛速度和更好的离策略稳定性也使得移除目标网络而不遭受灾难性发散成为可能，这进一步减少了TD(0)对价值高估的偏差。",
        "领域": "深度强化学习、连续控制、价值函数近似",
        "问题": "解决深度神经网络在价值近似中存在的光谱偏差问题，即高频成分拟合效率低下的问题。",
        "动机": "提高深度强化学习算法中价值近似的效率和稳定性，特别是在处理高频成分时。",
        "方法": "提出使用复合神经切线核和傅里叶特征网络（FFN）来克服光谱偏差，实现更高效的价值近似。",
        "关键词": [
            "光谱偏差",
            "傅里叶特征网络",
            "神经切线核",
            "离策略强化学习",
            "连续控制"
        ],
        "涉及的技术概念": {
            "光谱偏差": "指在神经核回归中，拟合价值函数的高频成分比低频成分需要更多的梯度更新步骤的现象。",
            "傅里叶特征网络（FFN）": "一种通过引入傅里叶特征来增强神经网络对高频成分拟合能力的方法。",
            "神经切线核": "用于分析神经网络训练动态的理论工具，本文中用于设计克服光谱偏差的方法。"
        },
        "success": true
    },
    {
        "order": 746,
        "title": "PAC-Bayes Information Bottleneck",
        "html": "https://iclr.cc//virtual/2022/poster/6238",
        "abstract": "Understanding the source of the superior generalization ability of NNs remains one of the most important problems in ML research. There have been a series of theoretical works trying to derive non-vacuous bounds for NNs. Recently, the compression of information stored in weights (IIW) is proved to play a key role in NNs generalization based on the PAC-Bayes theorem. However, no solution of IIW has ever been provided, which builds a barrier for further investigation of the IIW's property and its potential in practical deep learning. In this paper, we propose an algorithm for the efficient approximation of IIW. Then, we build an IIW-based information bottleneck on the trade-off between accuracy and information complexity of NNs, namely PIB. From PIB, we can empirically identify the fitting to compressing phase transition during NNs' training and the concrete connection between the IIW compression and the generalization. Besides, we verify that IIW is able to explain NNs in broad cases, e.g., varying batch sizes, over-parameterization, and noisy labels. Moreover, we propose an MCMC-based algorithm to sample from the optimal weight posterior characterized by PIB, which fulfills the potential of IIW in enhancing NNs in practice.",
        "conference": "ICLR",
        "中文标题": "PAC-Bayes信息瓶颈",
        "摘要翻译": "理解神经网络（NNs）卓越泛化能力的来源仍然是机器学习研究中最重要的问题之一。已有系列理论工作尝试为NNs推导非空泛的界限。最近，基于PAC-Bayes定理，权重中存储的信息（IIW）的压缩被证明在NNs的泛化中扮演关键角色。然而，尚未提供IIW的解决方案，这为进一步研究IIW的性质及其在实际深度学习中的潜力设置了障碍。在本文中，我们提出了一种高效近似IIW的算法。然后，我们在NNs的准确性与信息复杂性之间的权衡上构建了一个基于IIW的信息瓶颈，即PIB。通过PIB，我们可以经验性地识别NNs训练过程中的拟合到压缩阶段转变，以及IIW压缩与泛化之间的具体联系。此外，我们验证了IIW能够解释NNs在广泛情况下的行为，例如变化的批量大小、过参数化和噪声标签。此外，我们提出了一种基于MCMC的算法，从PIB表征的最优权重后验中采样，这实现了IIW在增强NNs实践中的潜力。",
        "领域": "深度学习理论、神经网络泛化、信息瓶颈方法",
        "问题": "解决神经网络泛化能力的理论解释和实际应用中的信息压缩问题",
        "动机": "探索神经网络权重中信息压缩（IIW）对泛化能力的影响，并提出实际可行的解决方案",
        "方法": "提出高效近似IIW的算法，构建基于IIW的信息瓶颈（PIB），并通过MCMC算法采样最优权重后验",
        "关键词": [
            "信息压缩",
            "PAC-Bayes定理",
            "神经网络泛化",
            "信息瓶颈",
            "MCMC采样"
        ],
        "涉及的技术概念": {
            "PAC-Bayes定理": "用于推导神经网络泛化能力的非空泛界限，理论基础",
            "信息瓶颈（PIB）": "在神经网络准确性与信息复杂性之间建立权衡，核心方法",
            "MCMC采样": "用于从最优权重后验中采样，实现IIW在实际深度学习中的应用"
        },
        "success": true
    },
    {
        "order": 747,
        "title": "PAC Prediction Sets Under Covariate Shift",
        "html": "https://iclr.cc//virtual/2022/poster/6314",
        "abstract": "An important challenge facing modern machine learning is how to rigorously quantify the uncertainty of model predictions. Conveying uncertainty is especially important when there are changes to the underlying data distribution that might invalidate the predictive model. Yet, most existing uncertainty quantification algorithms break down in the presence of such shifts. We propose a novel approach that addresses this challenge by constructing \\emph{probably approximately correct (PAC)} prediction sets in the presence of covariate shift. Our approach focuses on the setting where there is a covariate shift from the source distribution (where we have labeled training examples) to the target distribution (for which we want to quantify uncertainty). Our algorithm assumes given importance weights that encode how the probabilities of the training examples change under the covariate shift. In practice, importance weights typically need to be estimated; thus, we extend our algorithm to the setting where we are given confidence intervals for the importance weights. We demonstrate the effectiveness of our approach on covariate shifts based on DomainNet and ImageNet. Our algorithm satisfies the PAC constraint, and gives prediction sets with the smallest average normalized size among approaches that always satisfy the PAC constraint.",
        "conference": "ICLR",
        "中文标题": "协变量偏移下的PAC预测集",
        "摘要翻译": "现代机器学习面临的一个重要挑战是如何严格量化模型预测的不确定性。当基础数据分布发生变化可能使预测模型失效时，传达不确定性尤为重要。然而，大多数现有的不确定性量化算法在这种偏移存在时会失效。我们提出了一种新方法，通过在协变量偏移存在的情况下构建可能近似正确（PAC）预测集来解决这一挑战。我们的方法专注于从源分布（我们有标记的训练示例）到目标分布（我们想要量化不确定性）存在协变量偏移的设置。我们的算法假设给定重要性权重，这些权重编码了训练示例在协变量偏移下概率如何变化。在实践中，重要性权重通常需要估计；因此，我们将算法扩展到给定重要性权重置信区间的设置。我们在基于DomainNet和ImageNet的协变量偏移上展示了我们方法的有效性。我们的算法满足PAC约束，并且在始终满足PAC约束的方法中，给出了平均归一化大小最小的预测集。",
        "领域": "不确定性量化、协变量适应、预测集构建",
        "问题": "在数据分布变化（协变量偏移）的情况下，如何严格量化模型预测的不确定性",
        "动机": "解决现有不确定性量化算法在协变量偏移存在时失效的问题，提供一种能够在这种条件下有效工作的不确定性量化方法",
        "方法": "构建可能近似正确（PAC）预测集，利用重要性权重调整训练示例在协变量偏移下的概率变化，扩展到重要性权重置信区间给定的情况",
        "关键词": [
            "PAC预测集",
            "协变量偏移",
            "不确定性量化",
            "重要性权重",
            "DomainNet"
        ],
        "涉及的技术概念": {
            "可能近似正确（PAC）预测集": "在协变量偏移存在的情况下构建的预测集，旨在严格量化模型预测的不确定性",
            "重要性权重": "编码训练示例在协变量偏移下概率变化的权重，用于调整模型以适应目标分布",
            "协变量偏移": "从源分布到目标分布的数据分布变化，可能导致预测模型失效"
        },
        "success": true
    },
    {
        "order": 748,
        "title": "P-Adapters: Robustly Extracting Factual Information from Language Models with Diverse Prompts",
        "html": "https://iclr.cc//virtual/2022/poster/6900",
        "abstract": "Recent work (e.g. LAMA (Petroni et al., 2019)) has found that the quality of the factual information extracted from Large Language Models (LLMs) depends on the prompts used to query them. This inconsistency is problematic because different users will query LLMs for the same information using different wording, but should receive the same, accurate responses regardless. In this work we aim to address this shortcoming by introducing P-Adapters: lightweight models that sit between the embedding layer and first attention layer of LLMs. They take LLM embeddings as input and output continuous prompts that are used to query the LLM. Additionally, we investigate Mixture of Experts (MoE) models that learn a set of continuous prompts (the 'experts') and select one to query the LLM. These require a separate classifier trained on human-annotated data to map natural language prompts to the continuous ones. P-Adapters perform comparably to the more complex MoE models in extracting factual information from BERT and RoBERTa while eliminating the need for additional annotations. P-Adapters show between 12-26% absolute improvement in precision and 36-50% absolute improvement in consistency over a baseline of just using natural language queries alone. Finally, we investigate what makes P-Adapters successful and conclude that a significant factor is access to the LLM's embeddings of the original natural language prompt, particularly the subject of the entity pair being queried.",
        "conference": "ICLR",
        "中文标题": "P-适配器：通过多样化提示从语言模型中稳健提取事实信息",
        "摘要翻译": "近期研究（例如LAMA（Petroni等人，2019））发现，从大型语言模型（LLMs）中提取的事实信息的质量取决于用于查询它们的提示。这种不一致性是有问题的，因为不同的用户会使用不同的措辞查询LLMs以获取相同的信息，但无论措辞如何，都应接收到相同且准确的响应。在这项工作中，我们旨在通过引入P-适配器来解决这一不足：P-适配器是轻量级模型，位于LLMs的嵌入层和第一个注意力层之间。它们以LLM嵌入作为输入，并输出用于查询LLM的连续提示。此外，我们研究了专家混合（MoE）模型，这些模型学习一组连续提示（'专家'）并选择一个来查询LLM。这些需要一个基于人类注释数据训练的单独分类器，将自然语言提示映射到连续提示。在从BERT和RoBERTa提取事实信息方面，P-适配器的表现与更复杂的MoE模型相当，同时消除了对额外注释的需求。与仅使用自然语言查询的基线相比，P-适配器在精确度上显示出12-26%的绝对改进，在一致性上显示出36-50%的绝对改进。最后，我们研究了P-适配器成功的原因，并得出结论，一个重要因素是能够访问LLM对原始自然语言提示的嵌入，特别是被查询实体对的主题。",
        "领域": "自然语言处理与视觉结合、大型语言模型应用、信息提取",
        "问题": "解决从大型语言模型中提取事实信息时因提示多样性导致的不一致性问题",
        "动机": "确保不同用户使用不同措辞查询同一信息时，能够获得一致且准确的事实信息",
        "方法": "引入P-适配器，轻量级模型位于嵌入层和第一个注意力层之间，输出连续提示用于查询；研究专家混合模型学习连续提示集合并选择查询",
        "关键词": [
            "P-适配器",
            "大型语言模型",
            "事实信息提取",
            "连续提示",
            "专家混合模型"
        ],
        "涉及的技术概念": {
            "P-适配器": "轻量级模型，位于LLMs的嵌入层和第一个注意力层之间，用于生成连续提示以提高信息提取的一致性和准确性",
            "专家混合模型": "学习一组连续提示（专家）并选择其一用于查询LLM，需要额外分类器将自然语言提示映射到连续提示",
            "连续提示": "由P-适配器或专家混合模型生成的提示，用于查询LLM，以提高提取事实信息的准确性和一致性"
        },
        "success": true
    },
    {
        "order": 749,
        "title": "Parallel Training of GRU Networks with a Multi-Grid Solver for Long Sequences",
        "html": "https://iclr.cc//virtual/2022/poster/6016",
        "abstract": "Parallelizing Gated Recurrent Unit (GRU) is a challenging task, as the training procedure of GRU is inherently sequential. Prior efforts to parallelize GRU have largely focused on conventional parallelization strategies such as data-parallel and model-parallel training algorithms. However, when the given sequences are very long, existing approaches are still inevitably performance limited in terms of both training time and model accuracy. In this paper, we present a novel parallel training scheme (called  parallel-in-time) for GRU based on a multigrid reduction in time (MGRIT) solver. MGRIT partitions a sequence into multiple shorter sub-sequences and trains the sub-sequences on different processors in parallel. The key to achieving speedup is a hierarchical correction of the hidden state to accelerate end-to-end communication in both the forward and backward propagation phases of gradient descent. Experimental results on the HMDB51 dataset, where each video is an image sequence, demonstrate that a new parallel training scheme of GRU achieves up to $6.5 \\times$ speedup over a serial approach. As efficiency of our new parallelization strategy is associated with the sequence length, our parallel GRU algorithm achieves significant performance improvement as the length of sequence increases. Further, the proposed approach can be applied simultaneously with batch and other forms of model parallelism.",
        "conference": "ICLR",
        "中文标题": "使用多重网格求解器并行训练GRU网络以处理长序列",
        "摘要翻译": "并行化门控循环单元（GRU）是一项具有挑战性的任务，因为GRU的训练过程本质上是顺序的。之前并行化GRU的努力主要集中在传统的并行化策略上，如数据并行和模型并行训练算法。然而，当给定的序列非常长时，现有方法在训练时间和模型准确性方面仍然不可避免地受到性能限制。在本文中，我们提出了一种基于时间多重网格减少（MGRIT）求解器的GRU新颖并行训练方案（称为时间并行）。MGRIT将一个序列分割成多个较短的子序列，并在不同的处理器上并行训练这些子序列。实现加速的关键是在梯度下降的前向和后向传播阶段对隐藏状态进行分层校正，以加速端到端的通信。在HMDB51数据集上的实验结果表明，新的GRU并行训练方案比串行方法实现了高达6.5倍的加速。由于我们新的并行化策略的效率与序列长度相关，我们的并行GRU算法随着序列长度的增加实现了显著的性能提升。此外，所提出的方法可以同时与批次和其他形式的模型并行性一起应用。",
        "领域": "序列建模",
        "问题": "如何有效地并行化GRU网络的训练过程以处理长序列",
        "动机": "解决现有并行化方法在处理长序列时在训练时间和模型准确性方面的性能限制",
        "方法": "提出了一种基于时间多重网格减少（MGRIT）求解器的GRU并行训练方案，通过将序列分割成多个较短的子序列并在不同处理器上并行训练，同时在梯度下降的前向和后向传播阶段对隐藏状态进行分层校正以加速端到端的通信",
        "关键词": [
            "GRU网络",
            "并行训练",
            "多重网格求解器",
            "长序列处理",
            "时间并行"
        ],
        "涉及的技术概念": {
            "时间多重网格减少（MGRIT）求解器": "用于将长序列分割成多个较短的子序列，实现并行训练",
            "隐藏状态分层校正": "在梯度下降的前向和后向传播阶段加速端到端的通信",
            "并行训练方案": "通过在不同处理器上并行训练子序列，提高训练效率和模型准确性"
        },
        "success": true
    },
    {
        "order": 750,
        "title": "Pareto Policy Adaptation",
        "html": "https://iclr.cc//virtual/2022/poster/6886",
        "abstract": "We present a policy gradient method for Multi-Objective Reinforcement Learning under unknown, linear preferences. By enforcing Pareto stationarity, a first-order condition for Pareto optimality, we are able to design a simple policy gradient algorithm that approximates the Pareto front and infers the unknown preferences. Our method relies on a projected gradient descent solver that identifies common ascent directions for all objectives. Leveraging the solution of that solver, we introduce Pareto Policy Adaptation (PPA), a loss function that adapts the policy to be optimal with respect to any distribution over preferences. PPA uses implicit differentiation to back-propagate the loss gradient bypassing the operations of the projected gradient descent solver. Our approach is straightforward, easy to implement and can be used with all existing policy gradient and actor-critic methods. We evaluate our method in a series of reinforcement learning tasks",
        "conference": "ICLR",
        "中文标题": "帕累托策略适应",
        "摘要翻译": "我们提出了一种用于未知线性偏好下的多目标强化学习的策略梯度方法。通过强制执行帕累托平稳性，即帕累托最优性的一阶条件，我们能够设计一个简单的策略梯度算法，该算法近似帕累托前沿并推断未知偏好。我们的方法依赖于一个投影梯度下降求解器，该求解器识别所有目标的共同上升方向。利用该求解器的解，我们引入了帕累托策略适应（PPA），这是一种使策略适应于任何偏好分布的最优性的损失函数。PPA使用隐式微分来反向传播损失梯度，绕过投影梯度下降求解器的操作。我们的方法直接、易于实现，并且可以与所有现有的策略梯度和演员-评论家方法一起使用。我们在一系列强化学习任务中评估了我们的方法。",
        "领域": "多目标强化学习、策略优化、演员-评论家方法",
        "问题": "在未知线性偏好下进行多目标强化学习的问题",
        "动机": "设计一种能够适应任何偏好分布的策略梯度方法，以近似帕累托前沿并推断未知偏好",
        "方法": "通过强制执行帕累托平稳性，设计一个简单的策略梯度算法，利用投影梯度下降求解器识别共同上升方向，并引入帕累托策略适应（PPA）损失函数",
        "关键词": [
            "多目标强化学习",
            "策略梯度",
            "帕累托最优",
            "隐式微分",
            "演员-评论家方法"
        ],
        "涉及的技术概念": {
            "帕累托平稳性": "帕累托最优性的一阶条件，用于设计策略梯度算法",
            "投影梯度下降求解器": "用于识别所有目标的共同上升方向的技术",
            "隐式微分": "用于反向传播损失梯度，绕过投影梯度下降求解器的操作"
        },
        "success": true
    },
    {
        "order": 751,
        "title": "Pareto Policy Pool for Model-based Offline Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6152",
        "abstract": "Online reinforcement learning (RL) can suffer from poor exploration, sparse reward, insufficient data, and overhead caused by inefficient interactions between an immature policy and a complicated environment. Model-based offline RL instead trains an environment model using a dataset of pre-collected experiences so online RL methods can learn in an offline manner by solely interacting with the model. However, the uncertainty and accuracy of the environment model can drastically vary across different state-action pairs so the RL agent may achieve high model return but perform poorly in the true environment. Unlike previous works that need to carefully tune the trade-off between the model return and uncertainty in a single objective, we study a bi-objective formulation for model-based offline RL that aims at producing a pool of diverse policies on the Pareto front performing different levels of trade-offs, which provides the flexibility to select the best policy for each realistic environment from the pool. Our method, ''Pareto policy pool (P3)'', does not need to tune the trade-off weight but can produce policies allocated at different regions of the Pareto front. For this purpose, we develop an efficient algorithm that solves multiple bi-objective optimization problems with distinct constraints defined by reference vectors targeting diverse regions of the Pareto front. We theoretically prove that our algorithm can converge to the targeted regions. In order to obtain more Pareto optimal policies without linearly increasing the cost, we leverage the achieved policies as initialization to find more Pareto optimal policies in their neighborhoods. On the D4RL benchmark for offline RL, P3 substantially outperforms several recent baseline methods over multiple tasks, especially when the quality of pre-collected experiences is low.",
        "conference": "ICLR",
        "中文标题": "基于模型的离线强化学习的帕累托策略池",
        "摘要翻译": "在线强化学习（RL）可能会受到探索不足、奖励稀疏、数据不足以及不成熟策略与复杂环境之间低效交互引起的开销的影响。基于模型的离线RL则使用预先收集的经验数据集训练环境模型，使得在线RL方法可以通过仅与模型交互以离线方式学习。然而，环境模型的不确定性和准确性在不同的状态-动作对之间可能会有很大差异，因此RL代理可能在模型中获得高回报但在真实环境中表现不佳。与之前需要在一个单一目标中仔细调整模型回报和不确定性之间权衡的工作不同，我们研究了基于模型的离线RL的双目标公式，旨在产生一个在帕累托前沿上执行不同权衡水平的多样化策略池，这为从池中选择每个现实环境的最佳策略提供了灵活性。我们的方法“帕累托策略池（P3）”不需要调整权衡权重，但可以产生分配在帕累托前沿不同区域的策略。为此，我们开发了一种高效算法，解决了多个双目标优化问题，这些问题由针对帕累托前沿不同区域的参考向量定义的独特约束条件所定义。我们从理论上证明了我们的算法可以收敛到目标区域。为了在不线性增加成本的情况下获得更多的帕累托最优策略，我们利用已实现的策略作为初始化，在其邻域中找到更多的帕累托最优策略。在离线RL的D4RL基准测试中，P3在多个任务上大幅优于几种最近的基线方法，特别是当预先收集的经验质量较低时。",
        "领域": "强化学习、离线学习、模型优化",
        "问题": "解决基于模型的离线强化学习中模型不确定性和准确性在不同状态-动作对间差异大导致的高模型回报但真实环境表现差的问题",
        "动机": "通过产生一个在帕累托前沿上执行不同权衡水平的多样化策略池，为从池中选择每个现实环境的最佳策略提供灵活性",
        "方法": "开发了一种高效算法，解决了多个双目标优化问题，这些问题由针对帕累托前沿不同区域的参考向量定义的独特约束条件所定义，并利用已实现的策略作为初始化，在其邻域中找到更多的帕累托最优策略",
        "关键词": [
            "帕累托策略池",
            "离线强化学习",
            "双目标优化",
            "模型不确定性",
            "D4RL基准测试"
        ],
        "涉及的技术概念": {
            "帕累托前沿": "在双目标优化中表示不同权衡水平的最优解集合，用于产生多样化策略池",
            "双目标优化": "同时优化模型回报和模型不确定性两个目标，以产生在帕累托前沿上的策略",
            "参考向量": "用于定义双目标优化问题的约束条件，针对帕累托前沿的不同区域"
        },
        "success": true
    },
    {
        "order": 752,
        "title": "Pareto Set Learning for Neural Multi-Objective Combinatorial Optimization",
        "html": "https://iclr.cc//virtual/2022/poster/7076",
        "abstract": "Multiobjective combinatorial optimization (MOCO) problems can be found in many real-world applications. However, exactly solving these problems would be very challenging, particularly when they are NP-hard. Many handcrafted heuristic methods have been proposed to tackle different MOCO problems over the past decades. In this work, we generalize the idea of neural combinatorial optimization, and develop a learning-based approach to approximate the whole Pareto set for a given MOCO problem without further search procedure. We propose a single preference-conditioned model to directly generate approximate Pareto solutions for any trade-off preference, and design an efficient multiobjective reinforcement learning algorithm to train this model. Our proposed method can be treated as a learning-based extension for the widely-used decomposition-based multiobjective evolutionary algorithm (MOEA/D). It uses a single model to accommodate all the possible preferences, whereas other methods use a finite number of solution to approximate the Pareto set. Experimental results show that our proposed method significantly outperforms some other methods on the multiobjective traveling salesman problem, multiobjective vehicle routing problem and multiobjective knapsack problem in terms of solution quality, speed, and model efficiency.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "帕累托集学习用于神经多目标组合优化",
        "摘要翻译": "多目标组合优化（MOCO）问题在许多实际应用中都能找到。然而，精确解决这些问题非常具有挑战性，尤其是当它们是NP难问题时。过去几十年中，已经提出了许多手工制作的启发式方法来处理不同的MOCO问题。在这项工作中，我们概括了神经组合优化的思想，并开发了一种基于学习的方法来近似给定MOCO问题的整个帕累托集，而无需进一步的搜索过程。我们提出了一个单一偏好条件模型，直接为任何权衡偏好生成近似帕累托解，并设计了一种高效的多目标强化学习算法来训练这个模型。我们提出的方法可以被视为广泛使用的基于分解的多目标进化算法（MOEA/D）的一种基于学习的扩展。它使用单一模型来适应所有可能的偏好，而其他方法使用有限数量的解来近似帕累托集。实验结果表明，我们提出的方法在多目标旅行商问题、多目标车辆路径问题和多目标背包问题上，在解的质量、速度和模型效率方面显著优于其他一些方法。",
        "领域": "多目标优化, 组合优化, 强化学习",
        "问题": "解决多目标组合优化问题的挑战，特别是在NP难问题中，如何高效近似整个帕累托集。",
        "动机": "概括神经组合优化的思想，开发一种无需进一步搜索过程即可近似给定MOCO问题整个帕累托集的学习方法。",
        "方法": "提出一个单一偏好条件模型直接生成近似帕累托解，并设计一种高效的多目标强化学习算法来训练这个模型。",
        "关键词": [
            "多目标组合优化",
            "帕累托集",
            "强化学习",
            "神经组合优化",
            "偏好条件模型"
        ],
        "涉及的技术概念": {
            "帕累托集": "在多目标优化中，帕累托集是指在不牺牲任何目标的情况下无法进一步改进的解的集合。",
            "神经组合优化": "利用神经网络来解决组合优化问题的方法，通过学习来近似最优解。",
            "多目标强化学习": "一种强化学习方法，专门用于处理具有多个冲突目标的优化问题。"
        }
    },
    {
        "order": 753,
        "title": "Partial Wasserstein Adversarial Network for Non-rigid Point Set Registration",
        "html": "https://iclr.cc//virtual/2022/poster/7018",
        "abstract": "Given two point sets, the problem of registration is to recover a transformation that matches one set to the other. This task is challenging due to the presence of large number of outliers, the unknown non-rigid deformations and the large sizes of point sets. To obtain strong robustness against outliers, we formulate the registration problem as a partial distribution matching (PDM) problem, where the goal is to partially match the distributions represented by point sets in a metric space. To handle large point sets, we propose a scalable PDM algorithm by utilizing the efficient partial Wasserstein-1 (PW) discrepancy. Specifically, we derive the Kantorovich-Rubinstein duality for the PW discrepancy, and show its gradient can be explicitly computed. Based on these results, we propose a partial Wasserstein adversarial network (PWAN),  which is able to approximate the PW discrepancy by a neural network, and minimize it by gradient descent. In addition,it also incorporates an efficient coherence regularizer for non-rigid transformations to avoid unrealistic deformations. We evaluate PWAN on practical point set registration tasks, and show that the proposed PWAN is robust, scalable and performs more favorably than the state-of-the-art methods.",
        "conference": "ICLR",
        "中文标题": "部分Wasserstein对抗网络用于非刚性点集配准",
        "摘要翻译": "给定两个点集，配准问题的目标是恢复一个将一个点集匹配到另一个点集的变换。由于存在大量异常值、未知的非刚性变形以及点集的大尺寸，这一任务具有挑战性。为了获得对异常值的强鲁棒性，我们将配准问题表述为部分分布匹配（PDM）问题，其目标是在度量空间中部分匹配由点集表示的分布。为了处理大尺寸点集，我们通过利用高效的部分Wasserstein-1（PW）差异，提出了一种可扩展的PDM算法。具体来说，我们推导了PW差异的Kantorovich-Rubinstein对偶性，并展示了其梯度可以显式计算。基于这些结果，我们提出了一种部分Wasserstein对抗网络（PWAN），它能够通过神经网络近似PW差异，并通过梯度下降法最小化它。此外，它还包含了一个高效的非刚性变换一致性正则化器，以避免不现实的变形。我们在实际的点集配准任务上评估了PWAN，并表明所提出的PWAN具有鲁棒性、可扩展性，并且比现有技术方法表现更优。",
        "领域": "非刚性点集配准",
        "问题": "解决在存在大量异常值、未知非刚性变形和大尺寸点集情况下的点集配准问题",
        "动机": "提高点集配准任务对异常值的鲁棒性，处理大尺寸点集，并准确恢复非刚性变形",
        "方法": "提出部分Wasserstein对抗网络（PWAN），利用部分Wasserstein-1差异进行部分分布匹配，结合梯度下降法和一致性正则化器优化非刚性变换",
        "关键词": [
            "非刚性点集配准",
            "部分Wasserstein差异",
            "对抗网络",
            "梯度下降",
            "一致性正则化"
        ],
        "涉及的技术概念": {
            "部分Wasserstein-1（PW）差异": "用于度量部分分布匹配的差异，提高对异常值的鲁棒性",
            "Kantorovich-Rubinstein对偶性": "用于推导PW差异的梯度，使得梯度可以显式计算",
            "部分Wasserstein对抗网络（PWAN）": "通过神经网络近似PW差异，并通过梯度下降法最小化差异，同时加入一致性正则化器避免不现实的非刚性变形"
        },
        "success": true
    },
    {
        "order": 754,
        "title": "Particle Stochastic Dual Coordinate Ascent: Exponential convergent algorithm for mean field neural network optimization",
        "html": "https://iclr.cc//virtual/2022/poster/6575",
        "abstract": "We introduce Particle-SDCA, a gradient-based optimization algorithm for two-layer neural networks in the mean field regime that achieves exponential convergence rate in regularized empirical risk minimization. The proposed algorithm can be regarded as an infinite dimensional extension of Stochastic Dual Coordinate Ascent (SDCA) in the probability space: we exploit the convexity of the dual problem, for which the coordinate-wise proximal gradient method can be applied. Our proposed method inherits advantages of the original SDCA, including (i) exponential convergence (with respect to the outer iteration steps), and (ii) better dependency on the sample size and condition number than the full-batch gradient method. One technical challenge in implementing the SDCA update is the intractable integral over the entire parameter space at every step. To overcome this limitation, we propose a tractable \\textit{particle method} that approximately solves the dual problem, and an importance re-weighted technique to reduce the computational cost. The convergence rate of our method is verified by numerical experiments.",
        "conference": "ICLR",
        "中文标题": "粒子随机双坐标上升：均值场神经网络优化的指数收敛算法",
        "摘要翻译": "我们介绍了Particle-SDCA，一种针对均值场体系中两层神经网络的基于梯度的优化算法，该算法在正则化经验风险最小化中实现了指数收敛速度。所提出的算法可以被视为概率空间中随机双坐标上升（SDCA）的无限维扩展：我们利用了双问题的凸性，可以应用坐标近端梯度方法。我们提出的方法继承了原始SDCA的优点，包括（i）指数收敛（相对于外部迭代步骤），以及（ii）与全批量梯度方法相比，对样本大小和条件数的更好依赖性。实现SDCA更新的一个技术挑战是在每一步对整个参数空间的难以处理的积分。为了克服这一限制，我们提出了一种可处理的粒子方法，近似解决双问题，以及一种重要性重加权技术以减少计算成本。我们方法的收敛速度通过数值实验得到了验证。",
        "领域": "深度学习优化算法、神经网络训练、随机优化方法",
        "问题": "解决在均值场体系中两层神经网络的正则化经验风险最小化问题，实现指数收敛速度。",
        "动机": "为了克服传统梯度方法在样本大小和条件数上的限制，以及解决SDCA更新中难以处理的积分问题。",
        "方法": "提出了一种基于粒子方法的随机双坐标上升算法（Particle-SDCA），利用双问题的凸性和坐标近端梯度方法，结合重要性重加权技术以减少计算成本。",
        "关键词": [
            "粒子方法",
            "随机双坐标上升",
            "均值场神经网络",
            "指数收敛",
            "重要性重加权"
        ],
        "涉及的技术概念": {
            "随机双坐标上升（SDCA）": "一种优化算法，通过利用双问题的凸性，实现指数收敛速度。",
            "粒子方法": "用于近似解决双问题的技术，通过模拟粒子动态来克服难以处理的积分问题。",
            "重要性重加权技术": "一种减少计算成本的方法，通过重新加权粒子来优化算法的效率。"
        },
        "success": true
    },
    {
        "order": 755,
        "title": "Patch-Fool: Are Vision Transformers Always Robust Against Adversarial Perturbations?",
        "html": "https://iclr.cc//virtual/2022/poster/6624",
        "abstract": "Vision transformers (ViTs) have recently set off a new wave in neural architecture design thanks to their record-breaking performance in various vision tasks. In parallel, to fulfill the goal of deploying ViTs into real-world vision applications, their robustness against potential malicious attacks has gained increasing attention. In particular, recent works show that ViTs are more robust against adversarial attacks as compared with convolutional neural networks (CNNs), and conjecture that this is because ViTs focus more on capturing global interactions among different input/feature patches, leading to their improved robustness to local perturbations imposed by adversarial attacks. In this work, we ask an intriguing question: 'Under what kinds of perturbations do ViTs become more vulnerable learners compared to CNNs?' Driven by this question, we first conduct a comprehensive experiment regarding the robustness of both ViTs and CNNs under various existing adversarial attacks to understand the underlying reason favoring their robustness. Based on the drawn insights, we then propose a dedicated attack framework, dubbed Patch-Fool, that fools the self-attention mechanism by attacking its basic component (i.e., a single patch) with a series of attention-aware optimization techniques. Interestingly, our Patch-Fool framework shows for the first time that ViTs are not necessarily more robust than CNNs against adversarial perturbations. In particular, we find that ViTs are more vulnerable learners compared with CNNs against our Patch-Fool attack which is consistent across extensive experiments, and the observations from Sparse/Mild Patch-Fool, two variants of Patch-Fool, indicate an intriguing insight that the perturbation density and strength on each patch seem to be the key factors that influence the robustness ranking between ViTs and CNNs. It can be expected that our Patch-Fool framework will shed light on both future architecture designs and training schemes for robustifying ViTs towards their real-world deployment. Our codes are available at https://github.com/RICE-EIC/Patch-Fool.",
        "conference": "ICLR",
        "中文标题": "Patch-Fool：视觉变换器是否总是对抗性扰动鲁棒？",
        "摘要翻译": "视觉变换器（ViTs）最近在神经架构设计中掀起了一波新浪潮，得益于其在各种视觉任务中的破纪录表现。同时，为了实现将ViTs部署到现实世界视觉应用中的目标，它们对潜在恶意攻击的鲁棒性越来越受到关注。特别是，最近的工作表明，与卷积神经网络（CNNs）相比，ViTs对对抗性攻击更为鲁棒，并推测这是因为ViTs更注重捕捉不同输入/特征补丁之间的全局交互，从而提高了对对抗性攻击施加的局部扰动的鲁棒性。在这项工作中，我们提出了一个有趣的问题：'在什么样的扰动下，ViTs比CNNs更容易受到攻击？'受此问题驱动，我们首先对ViTs和CNNs在各种现有对抗性攻击下的鲁棒性进行了全面实验，以理解支持它们鲁棒性的潜在原因。基于所获得的见解，我们随后提出了一个专门的攻击框架，称为Patch-Fool，该框架通过一系列注意力感知优化技术攻击其基本组件（即单个补丁）来愚弄自注意力机制。有趣的是，我们的Patch-Fool框架首次表明，ViTs不一定比CNNs对对抗性扰动更鲁棒。特别是，我们发现，与CNNs相比，ViTs对我们的Patch-Fool攻击更为脆弱，这在广泛的实验中是一致的，并且从Patch-Fool的两个变体Sparse/Mild Patch-Fool的观察中得出的见解表明，每个补丁上的扰动密度和强度似乎是影响ViTs和CNNs之间鲁棒性排名的关键因素。可以预见，我们的Patch-Fool框架将为未来架构设计和训练方案提供启示，以使ViTs在现实世界部署中更加鲁棒。我们的代码可在https://github.com/RICE-EIC/Patch-Fool获取。",
        "领域": "对抗性攻击防御、视觉变换器、卷积神经网络",
        "问题": "视觉变换器（ViTs）在特定对抗性扰动下的脆弱性问题",
        "动机": "探究ViTs在何种对抗性扰动下比CNNs更脆弱，以促进ViTs在现实世界应用中的鲁棒性提升",
        "方法": "提出Patch-Fool攻击框架，通过注意力感知优化技术攻击ViTs的自注意力机制的基本组件",
        "关键词": [
            "对抗性攻击",
            "视觉变换器",
            "卷积神经网络",
            "自注意力机制",
            "鲁棒性"
        ],
        "涉及的技术概念": {
            "视觉变换器（ViTs）": "一种基于自注意力机制的神经网络架构，用于处理视觉任务",
            "对抗性攻击": "旨在欺骗机器学习模型的恶意输入，导致模型做出错误预测",
            "自注意力机制": "ViTs中的核心技术，用于捕捉输入数据中不同部分之间的全局依赖关系"
        },
        "success": true
    },
    {
        "order": 756,
        "title": "Path Auxiliary Proposal for MCMC in Discrete Space",
        "html": "https://iclr.cc//virtual/2022/poster/7060",
        "abstract": "Energy-based Model (EBM) offers a powerful approach for modeling discrete structure, but both inference and learning of EBM are hard as it involves sampling from discrete distributions. Recent work shows Markov Chain Monte Carlo (MCMC) with the informed proposal is a powerful tool for such sampling. However, an informed proposal only allows local updates as it requires evaluating all energy changes in the neighborhood.In this work, we present a path auxiliary algorithm that uses a composition of local moves to efficiently explore large neighborhoods. We also give a fast version of our algorithm that only queries the evaluation of energy function twice for each proposal via linearization of the energy function. Empirically, we show that our path auxiliary algorithms considerably outperform other generic samplers on various discrete models for sampling, inference, and learning. Our method can also be used to train deep EBMs for high-dimensional discrete data.",
        "conference": "ICLR",
        "中文标题": "离散空间中马尔可夫链蒙特卡洛的路径辅助提案",
        "摘要翻译": "基于能量的模型（EBM）为建模离散结构提供了一种强大的方法，但EBM的推理和学习都很困难，因为它涉及从离散分布中采样。最近的工作表明，带有知情提案的马尔可夫链蒙特卡洛（MCMC）是进行此类采样的有力工具。然而，知情提案只允许局部更新，因为它需要评估邻域内的所有能量变化。在这项工作中，我们提出了一种路径辅助算法，该算法使用局部移动的组合来高效探索大邻域。我们还给出了我们算法的一个快速版本，该版本通过能量函数的线性化，每个提案仅需查询能量函数的两次评估。实证上，我们展示了我们的路径辅助算法在各种离散模型的采样、推理和学习上显著优于其他通用采样器。我们的方法也可以用于训练高维离散数据的深度EBM。",
        "领域": "概率图模型、深度学习优化、离散数据建模",
        "问题": "解决在离散空间中基于能量的模型（EBM）的采样、推理和学习的效率问题",
        "动机": "提高在离散空间中进行马尔可夫链蒙特卡洛（MCMC）采样的效率，特别是在大邻域探索方面",
        "方法": "提出了一种路径辅助算法，通过局部移动的组合高效探索大邻域，并开发了一个快速版本，通过能量函数的线性化减少计算量",
        "关键词": [
            "路径辅助算法",
            "马尔可夫链蒙特卡洛",
            "基于能量的模型",
            "离散数据",
            "高效采样"
        ],
        "涉及的技术概念": {
            "基于能量的模型（EBM）": "用于建模离散结构的强大方法，但采样和推理困难",
            "马尔可夫链蒙特卡洛（MCMC）": "用于从离散分布中采样的技术，特别是带有知情提案的MCMC",
            "路径辅助算法": "通过局部移动的组合高效探索大邻域，提高采样效率"
        },
        "success": true
    },
    {
        "order": 757,
        "title": "Path Integral Sampler: A Stochastic Control Approach For Sampling",
        "html": "https://iclr.cc//virtual/2022/poster/7195",
        "abstract": "We present Path Integral Sampler~(PIS), a novel algorithm to draw samples from unnormalized probability density functions. The PIS is built on the Schr\\'odinger bridge problem which aims to recover the most likely evolution of a diffusion process given its initial distribution and terminal distribution. The PIS draws samples from the initial distribution and then propagates the samples through the Schr\\'odinger bridge to reach the terminal distribution. Applying the Girsanov theorem, with a simple prior diffusion, we formulate the PIS as a stochastic optimal control problem whose running cost is the control energy and terminal cost is chosen according to the target distribution. By modeling the control as a neural network, we establish a sampling algorithm that can be trained end-to-end. We provide theoretical justification of the sampling quality of PIS in terms of Wasserstein distance when sub-optimal control is used. Moreover, the path integrals theory is used to compute importance weights of the samples to compensate for the bias induced by the sub-optimality of the controller and the time-discretization. We experimentally demonstrate the advantages of PIS compared with other start-of-the-art sampling methods on a variety of tasks.",
        "conference": "ICLR",
        "中文标题": "路径积分采样器：一种用于采样的随机控制方法",
        "摘要翻译": "我们提出了路径积分采样器（PIS），这是一种从非归一化概率密度函数中抽取样本的新算法。PIS建立在薛定谔桥问题之上，该问题旨在恢复给定初始分布和终端分布的扩散过程的最可能演化。PIS从初始分布中抽取样本，然后通过薛定谔桥传播样本以达到终端分布。应用Girsanov定理，通过一个简单的先验扩散，我们将PIS表述为一个随机最优控制问题，其运行成本是控制能量，终端成本根据目标分布选择。通过将控制建模为神经网络，我们建立了一个可以端到端训练的采样算法。我们提供了在次优控制使用时，PIS采样质量在Wasserstein距离方面的理论证明。此外，路径积分理论用于计算样本的重要性权重，以补偿由控制器的次优性和时间离散化引起的偏差。我们通过实验证明了PIS在各种任务上与其他最先进采样方法相比的优势。",
        "领域": "概率密度估计、随机控制、扩散模型",
        "问题": "如何从非归一化的概率密度函数中高效地抽取样本",
        "动机": "开发一种新的采样算法，能够有效地从复杂的非归一化概率密度中抽取样本，以解决传统采样方法在高维空间中的效率问题",
        "方法": "基于薛定谔桥问题和随机最优控制理论，构建一个端到端可训练的神经网络模型，用于从初始分布到目标分布的样本传播",
        "关键词": [
            "路径积分采样器",
            "薛定谔桥问题",
            "随机最优控制",
            "Girsanov定理",
            "Wasserstein距离"
        ],
        "涉及的技术概念": {
            "薛定谔桥问题": "用于恢复给定初始和终端分布的扩散过程的最可能演化，是PIS算法的理论基础",
            "Girsanov定理": "用于将PIS表述为一个随机最优控制问题，其中运行成本是控制能量，终端成本根据目标分布选择",
            "Wasserstein距离": "用于衡量在次优控制下PIS采样质量的理论标准"
        },
        "success": true
    },
    {
        "order": 758,
        "title": "PEARL: Data Synthesis via Private Embeddings and Adversarial Reconstruction Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6335",
        "abstract": "We propose a new framework of synthesizing data using deep generative models in a differentially private manner.Within our framework, sensitive data are sanitized with rigorous privacy guarantees in a one-shot fashion, such that training deep generative models is possible without re-using the original data.Hence, no extra privacy costs or model constraints are incurred, in contrast to popular gradient sanitization approaches, which, among other issues, cause degradation in privacy guarantees as the training iteration increases.We demonstrate a realization of our framework by making use of the characteristic function and an adversarial re-weighting objective, which are of independent interest as well.Our proposal has theoretical guarantees of performance, and empirical evaluations on multiple datasets show that our approach outperforms other methods at reasonable levels of privacy.",
        "conference": "ICLR",
        "中文标题": "PEARL：通过私有嵌入和对抗性重构学习进行数据合成",
        "摘要翻译": "我们提出了一种新的框架，用于以差分隐私的方式使用深度生成模型合成数据。在我们的框架内，敏感数据通过一次性方式进行了严格的隐私保证处理，从而可以在不重复使用原始数据的情况下训练深度生成模型。因此，与流行的梯度净化方法相比，不会产生额外的隐私成本或模型约束，这些方法在训练迭代增加时会导致隐私保证的降低。我们通过利用特征函数和对抗性重加权目标来实现我们的框架，这些方法本身也具有独立的意义。我们的提案具有理论上的性能保证，并且在多个数据集上的实证评估表明，在合理的隐私水平下，我们的方法优于其他方法。",
        "领域": "差分隐私数据生成、对抗性学习、深度生成模型",
        "问题": "如何在保证差分隐私的前提下，高效地合成数据用于训练深度生成模型",
        "动机": "解决现有梯度净化方法在训练过程中隐私保证逐渐降低的问题，提供一种不重复使用原始数据且不增加额外隐私成本的解决方案",
        "方法": "利用特征函数和对抗性重加权目标，实现一次性隐私保证的数据合成框架",
        "关键词": [
            "差分隐私",
            "数据合成",
            "对抗性学习",
            "深度生成模型",
            "特征函数"
        ],
        "涉及的技术概念": {
            "差分隐私": "在数据处理过程中提供严格的数学隐私保证，确保个体数据不被泄露",
            "对抗性重加权目标": "通过对抗性学习调整数据权重，优化生成模型的表现",
            "特征函数": "用于捕捉数据的统计特性，支持在隐私保护下的数据合成"
        },
        "success": true
    },
    {
        "order": 759,
        "title": "Peek-a-Boo: What (More) is Disguised in a Randomly Weighted Neural Network, and How to Find It Efficiently",
        "html": "https://iclr.cc//virtual/2022/poster/6586",
        "abstract": "Sparse neural networks (NNs) are intensively investigated in literature due to their appeal in saving storage, memory, and computational costs. A recent work (Ramanujan et al., 2020) showed that, different from conventional pruning-and-finetuning pipeline, there exist hidden subnetworks in randomly initialized NNs that have good performance without training the weights. However, such 'hidden subnetworks' have mediocre performances and require an expensive edge-popup algorithm to search for them. In this work, we define an extended class of subnetworks in randomly initialized NNs called disguised subnetworks, which are not only 'hidden' in the random networks but also 'disguised' -- hence can only be 'unmasked' with certain transformations on weights. We argue that the unmasking process plays an important role in enlarging the capacity of the subnetworks and thus grants two major benefits: (i) the disguised subnetworks easily outperform the hidden counterparts; (ii) the unmasking process helps to relax the quality requirement on the sparse subnetwork mask so that the expensive edge-popup algorithm can be replaced with more efficient alternatives. On top of this new concept, we propose a novel two-stage algorithm that plays a Peek-a-Boo (PaB) game to identify the disguised subnetworks with a combination of two operations: (1) searching efficiently for a subnetwork at random initialization; (2) unmasking the disguise by learning to transform the resulting subnetwork's remaining weights. Furthermore, we show that the unmasking process can be efficiently implemented (a) without referring to any latent weights or scores; and (b) by only leveraging approximated gradients, so that the whole training algorithm is computationally light. Extensive experiments with several large models (ResNet-18, ResNet-50, and WideResNet-28) and datasets (CIFAR-10, CIFAR-100 and ImageNet) demonstrate the competency of PaB over edge-popup and other counterparts. Our codes are available at: https://github.com/VITA-Group/Peek-a-Boo.",
        "conference": "ICLR",
        "中文标题": "捉迷藏：随机加权神经网络中隐藏（更多）的内容及其高效发现方法",
        "摘要翻译": "稀疏神经网络（NNs）因其在节省存储、内存和计算成本方面的吸引力而在文献中被深入研究。最近的一项工作（Ramanujan等人，2020年）表明，不同于传统的修剪和微调流程，随机初始化的神经网络中存在隐藏的子网络，这些子网络无需训练权重即可表现出良好的性能。然而，这样的'隐藏子网络'性能平平，且需要昂贵的边缘弹出算法来搜索它们。在这项工作中，我们在随机初始化的神经网络中定义了一类扩展的子网络，称为伪装子网络，它们不仅在随机网络中'隐藏'，而且'伪装'——因此只能通过对权重进行某些变换来'揭露'。我们认为，揭露过程在扩大子网络容量方面起着重要作用，从而带来两大好处：（i）伪装子网络轻易超越隐藏子网络；（ii）揭露过程有助于放松对稀疏子网络掩码的质量要求，从而可以用更高效的替代方案取代昂贵的边缘弹出算法。基于这一新概念，我们提出了一种新颖的两阶段算法，通过玩捉迷藏（PaB）游戏来识别伪装子网络，结合两种操作：（1）在随机初始化时高效搜索子网络；（2）通过学习变换剩余权重来揭露伪装。此外，我们展示了揭露过程可以高效实现（a）无需参考任何潜在权重或分数；（b）仅利用近似梯度，从而使整个训练算法计算量轻。使用几种大型模型（ResNet-18、ResNet-50和WideResNet-28）和数据集（CIFAR-10、CIFAR-100和ImageNet）的广泛实验证明了PaB相对于边缘弹出和其他对应方法的竞争力。我们的代码可在https://github.com/VITA-Group/Peek-a-Boo获取。",
        "领域": "神经网络剪枝、模型压缩、深度学习优化",
        "问题": "如何高效发现随机初始化神经网络中的高性能子网络，避免昂贵的搜索算法",
        "动机": "探索随机初始化神经网络中隐藏的高性能子网络，减少模型训练和优化的计算成本",
        "方法": "提出一种两阶段算法，结合高效子网络搜索和权重变换揭露伪装子网络",
        "关键词": [
            "稀疏神经网络",
            "伪装子网络",
            "高效搜索",
            "权重变换",
            "模型压缩"
        ],
        "涉及的技术概念": {
            "伪装子网络": "在随机初始化的神经网络中隐藏且需要特定权重变换才能揭露的高性能子网络",
            "边缘弹出算法": "一种用于搜索神经网络中子网络的昂贵算法，PaB算法旨在替代它",
            "近似梯度": "在揭露过程中使用的一种计算量轻的梯度近似方法，以提高算法效率"
        },
        "success": true
    },
    {
        "order": 760,
        "title": "Perceiver IO: A General Architecture for Structured Inputs & Outputs",
        "html": "https://iclr.cc//virtual/2022/poster/6269",
        "abstract": "A central goal of machine learning is the development of systems that can solve many problems in as many data domains as possible. Current architectures, however, cannot be applied beyond a small set of stereotyped settings, as they bake in domain & task assumptions or scale poorly to large inputs or outputs. In this work, we propose Perceiver IO, a general-purpose architecture that handles data from arbitrary settings while scaling linearly with the size of inputs and outputs. Our model augments the Perceiver with a flexible querying mechanism that enables outputs of various sizes and semantics, doing away with the need for task-specific architecture engineering. The same architecture achieves strong results on tasks spanning natural language and visual understanding, multi-task and multi-modal reasoning, and StarCraft II. As highlights, Perceiver IO outperforms a Transformer-based BERT baseline on the GLUE language benchmark despite removing input tokenization and achieves state-of-the-art performance on Sintel optical flow estimation with no explicit mechanisms for multiscale correspondence.",
        "conference": "ICLR",
        "中文标题": "感知器IO：一种用于结构化输入与输出的通用架构",
        "摘要翻译": "机器学习的一个核心目标是开发能够解决尽可能多数据领域中尽可能多问题的系统。然而，当前的架构只能应用于一小部分固定设置，因为它们内置了领域和任务假设，或者对大规模输入或输出的扩展性差。在这项工作中，我们提出了感知器IO，一种通用架构，能够处理任意设置的数据，同时输入和输出的大小线性扩展。我们的模型通过灵活的查询机制增强了感知器，使得可以输出各种大小和语义的内容，从而无需进行特定任务的架构工程。同一架构在自然语言和视觉理解、多任务和多模态推理以及《星际争霸II》等任务上取得了强劲的结果。作为亮点，感知器IO在GLUE语言基准测试中优于基于Transformer的BERT基线，尽管去除了输入标记化，并且在Sintel光流估计上实现了最先进的性能，无需显式的多尺度对应机制。",
        "领域": "自然语言处理与视觉结合, 多模态学习, 通用机器学习架构",
        "问题": "当前机器学习架构在跨领域、跨任务应用中的局限性和扩展性问题",
        "动机": "开发一种能够灵活处理多种数据领域和任务，且能有效扩展到大规模输入输出的通用机器学习架构",
        "方法": "提出感知器IO架构，通过引入灵活的查询机制，支持不同大小和语义的输出，无需针对特定任务设计架构",
        "关键词": [
            "通用架构",
            "多模态学习",
            "线性扩展",
            "灵活查询",
            "跨领域应用"
        ],
        "涉及的技术概念": {
            "感知器IO": "一种通用架构，能够处理任意设置的数据，同时输入和输出的大小线性扩展",
            "灵活的查询机制": "使得模型能够输出各种大小和语义的内容，无需进行特定任务的架构工程",
            "多尺度对应": "在光流估计等任务中，无需显式机制即可处理不同尺度的对应关系"
        },
        "success": true
    },
    {
        "order": 761,
        "title": "PER-ETD: A Polynomially Efficient Emphatic Temporal Difference Learning Method",
        "html": "https://iclr.cc//virtual/2022/poster/6938",
        "abstract": "Emphatic temporal difference (ETD) learning (Sutton et al., 2016) is a successful method to conduct the off-policy value function evaluation with function approximation. Although ETD has been shown to converge asymptotically to a desirable value function, it is well-known that ETD often encounters a large variance so that its sample complexity can increase exponentially fast with the number of iterations. In this work, we propose a new ETD method, called PER-ETD (i.e., PEriodically Restarted-ETD), which restarts and updates the follow-on trace only for a finite period for each iteration of the evaluation parameter. Further, PER-ETD features a design of the logarithmical increase of the restart period with the number of iterations, which guarantees the best trade-off between the variance and bias and keeps both vanishing sublinearly. We show that PER-ETD converges to the same desirable fixed point as ETD, but improves the exponential sample complexity of ETD to be polynomials. Our experiments validate the superior performance of PER-ETD and its advantage over ETD.",
        "conference": "ICLR",
        "中文标题": "PER-ETD：一种多项式效率的强调时序差分学习方法",
        "摘要翻译": "强调时序差分（ETD）学习（Sutton等人，2016）是一种成功的函数逼近方法，用于进行离策略价值函数评估。尽管ETD已被证明能够渐近收敛于一个理想的价值函数，但众所周知，ETD经常会遇到较大的方差，以至于其样本复杂度可以随着迭代次数的增加而指数级增长。在这项工作中，我们提出了一种新的ETD方法，称为PER-ETD（即周期性重启-ETD），该方法在每次评估参数的迭代中，仅对后续跟踪进行有限周期的重启和更新。此外，PER-ETD设计了重启周期随迭代次数对数增长的特性，这保证了方差和偏差之间的最佳权衡，并使两者都保持亚线性消失。我们证明，PER-ETD收敛于与ETD相同的理想固定点，但将ETD的指数样本复杂度改进为多项式。我们的实验验证了PER-ETD的优越性能及其相对于ETD的优势。",
        "领域": "强化学习、时序差分学习、函数逼近",
        "问题": "解决ETD方法在离策略价值函数评估中遇到的样本复杂度指数级增长问题",
        "动机": "ETD方法虽然能够渐近收敛于理想价值函数，但其样本复杂度随迭代次数指数级增长，限制了其实际应用",
        "方法": "提出周期性重启的ETD方法（PER-ETD），通过有限周期重启和更新后续跟踪，以及重启周期对数增长的设计，优化方差和偏差的权衡",
        "关键词": [
            "PER-ETD",
            "强调时序差分学习",
            "离策略学习",
            "样本复杂度",
            "函数逼近"
        ],
        "涉及的技术概念": {
            "强调时序差分学习（ETD）": "一种用于离策略价值函数评估的方法，能够渐近收敛于理想价值函数",
            "周期性重启（PER）": "在PER-ETD中，通过周期性重启后续跟踪来优化方差和偏差的权衡",
            "样本复杂度": "衡量算法性能的指标，PER-ETD将其从指数级改进为多项式级"
        },
        "success": true
    },
    {
        "order": 762,
        "title": "Permutation-Based SGD: Is Random Optimal?",
        "html": "https://iclr.cc//virtual/2022/poster/6386",
        "abstract": "A recent line of ground-breaking results for permutation-based SGD  has corroborated a widely observed phenomenon: random permutations offer faster convergence than with-replacement sampling. However, is random optimal? We show that this depends heavily on what functions we are optimizing, and the convergence gap between optimal and random permutations can vary from exponential to nonexistent. We first show that for 1-dimensional strongly convex functions, with smooth second derivatives, there exist optimal permutations that offer exponentially faster convergence compared to random. However, for general strongly convex functions, random permutations are optimal. Finally, we show that for quadratic, strongly-convex functions, there are easy-to-construct permutations that lead to accelerated convergence compared to random. Our results suggest that a general convergence characterization of optimal permutations cannot capture the nuances of individual function classes, and can  mistakenly indicate that one cannot do much better than random.",
        "conference": "ICLR",
        "中文标题": "基于排列的随机梯度下降：随机是最优的吗？",
        "摘要翻译": "最近一系列关于基于排列的随机梯度下降（SGD）的突破性结果证实了一个广泛观察到的现象：随机排列比有放回采样提供更快的收敛速度。然而，随机是最优的吗？我们表明，这在很大程度上取决于我们优化的函数，最优排列和随机排列之间的收敛差距可以从指数级到不存在。我们首先表明，对于具有平滑二阶导数的一维强凸函数，存在比随机排列提供指数级更快收敛的最优排列。然而，对于一般的强凸函数，随机排列是最优的。最后，我们表明，对于二次强凸函数，存在易于构建的排列，可以比随机排列带来加速收敛。我们的结果表明，最优排列的一般收敛特征无法捕捉到各个函数类的细微差别，并可能错误地表明人们无法做得比随机更好。",
        "领域": "优化算法、机器学习理论、随机梯度下降",
        "问题": "探讨在随机梯度下降（SGD）中，随机排列是否总是最优的收敛策略，以及不同函数类下最优排列与随机排列的收敛性能差异。",
        "动机": "研究动机是为了理解在SGD中排列策略对收敛速度的影响，以及是否存在比随机排列更优的排列策略，特别是在不同函数类下的表现。",
        "方法": "通过理论分析，比较了在一维强凸函数、一般强凸函数和二次强凸函数下，最优排列与随机排列的收敛性能，并构造了易于实现的加速排列策略。",
        "关键词": [
            "随机梯度下降",
            "排列策略",
            "收敛速度",
            "强凸函数",
            "优化算法"
        ],
        "涉及的技术概念": {
            "随机梯度下降（SGD）": "一种优化算法，通过随机采样数据点来估计梯度，用于大规模数据集的模型训练。",
            "强凸函数": "具有严格凸性质的函数，保证了优化问题有唯一的全局最小值。",
            "排列策略": "在SGD中决定数据点被访问顺序的策略，影响算法的收敛速度和性能。"
        },
        "success": true
    },
    {
        "order": 763,
        "title": "Permutation Compressors for Provably Faster Distributed Nonconvex Optimization",
        "html": "https://iclr.cc//virtual/2022/poster/7208",
        "abstract": "In this work we study the MARINA method of Gorbunov et al (ICML, 2021) -- the current state-of-the-art distributed non-convex optimization method in terms of theoretical communication complexity. Theoretical superiority of this method can be largely attributed to two sources: a carefully engineered biased stochastic gradient estimator, which leads to a reduction in the number of communication rounds, and  the reliance on {\\em independent} stochastic communication compression, which leads to a reduction in the number of  transmitted bits within each communication round. In this paper we  i) extend the theory of MARINA to support a much wider class of potentially {\\em correlated} compressors, extending the reach of the method beyond the classical independent compressors setting,  ii) show that a new quantity, for which we coin the name {\\em Hessian variance}, allows us to significantly refine the original analysis of MARINA without any additional assumptions, and iii) identify a special class of correlated compressors based on the idea of {\\em random  permutations}, for which we coin the term Perm$K$, the use of which leads to up to $O(\\sqrt{n})$ (resp. $O(1 + d/\\sqrt{n})$) improvement in the theoretical communication complexity of MARINA in the low Hessian variance regime when $d\\geq n$ (resp. $d \\leq n$), where $n$ is the number of workers and $d$ is the number of parameters describing the model we are learning. We corroborate our theoretical results with carefully engineered synthetic experiments with minimizing the average of nonconvex quadratics, and on autoencoder training with the MNIST dataset.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "用于可证明更快的分布式非凸优化的置换压缩器",
        "摘要翻译": "本文研究了Gorbunov等人（ICML, 2021）提出的MARINA方法——目前在理论通信复杂度方面最先进的分布式非凸优化方法。该方法在理论上的优越性主要归功于两个方面：精心设计的有偏随机梯度估计器，它可以减少通信轮数；以及对{\\\\em 独立}随机通信压缩的依赖，它可以减少每轮通信中传输的比特数。在本文中，我们 i) 扩展了MARINA的理论，以支持更广泛的潜在{\\\\em 相关}压缩器，从而将该方法的范围扩展到经典的独立压缩器设置之外；ii) 表明一个新的量，我们称之为{\\\\em Hessian方差}，允许我们显著改进MARINA的原始分析，而无需任何额外的假设；iii) 识别了一种基于{\\\\em 随机置换}思想的特殊相关压缩器，我们称之为Perm$K$，当$d\\\\geq n$（或$d \\\\leq n$）时，使用它可以使MARINA在低Hessian方差情况下的理论通信复杂度提高高达$O(\\\\sqrt{n})$（或$O(1 + d/\\\\sqrt{n})$），其中$n$是worker的数量，$d$是描述我们正在学习的模型的参数数量。我们通过精心设计的合成实验（最小化非凸二次函数的平均值）以及使用MNIST数据集进行自编码器训练，来证实我们的理论结果。",
        "领域": "分布式优化, 非凸优化, 通信压缩",
        "问题": "如何降低分布式非凸优化中通信的复杂度，提高优化速度。",
        "动机": "现有的MARINA方法依赖于独立的随机通信压缩来减少通信量，但可能存在局限性。希望通过允许相关压缩器和利用Hessian方差的概念，进一步降低通信复杂度。",
        "方法": "1. 扩展MARINA的理论，支持相关压缩器；2. 引入Hessian方差的概念来改进MARINA的分析；3. 设计了一种基于随机置换的Perm$K$压缩器；4. 通过理论分析和实验验证，证明了Perm$K$压缩器在降低通信复杂度方面的优势。",
        "关键词": [
            "分布式优化",
            "非凸优化",
            "通信压缩",
            "随机置换",
            "Hessian方差"
        ],
        "涉及的技术概念": {
            "有偏随机梯度估计器": "用于减少通信轮数，降低通信复杂度。",
            "通信压缩": "通过减少每轮通信中传输的比特数来降低通信开销。"
        }
    },
    {
        "order": 764,
        "title": "Pessimistic Bootstrapping for Uncertainty-Driven Offline Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6030",
        "abstract": "Offline Reinforcement Learning (RL) aims to learn policies from previously collected datasets without exploring the environment. Directly applying off-policy algorithms to offline RL usually fails due to the extrapolation error caused by the out-of-distribution (OOD) actions. Previous methods tackle such problem by penalizing the Q-values of OOD actions or constraining the trained policy to be close to the behavior policy. Nevertheless, such methods typically prevent the generalization of value functions beyond the offline data and also lack precise characterization of OOD data. In this paper, we propose Pessimistic Bootstrapping for offline RL (PBRL), a purely uncertainty-driven offline algorithm without explicit policy constraints. Specifically, PBRL conducts uncertainty quantification via the disagreement of bootstrapped Q-functions, and performs pessimistic updates by penalizing the value function based on the estimated uncertainty. To tackle the extrapolating error, we further propose a novel OOD sampling method. We show that such OOD sampling and pessimistic bootstrapping yields provable uncertainty quantifier in linear MDPs, thus providing the theoretical underpinning for PBRL. Extensive experiments on D4RL benchmark show that PBRL has better performance compared to the state-of-the-art algorithms.",
        "conference": "ICLR",
        "中文标题": "悲观自助法用于不确定性驱动的离线强化学习",
        "摘要翻译": "离线强化学习（RL）旨在不探索环境的情况下，从先前收集的数据集中学习策略。直接将离策略算法应用于离线RL通常会由于分布外（OOD）动作引起的外推误差而失败。先前的方法通过惩罚OOD动作的Q值或将训练策略约束为接近行为策略来解决这一问题。然而，这些方法通常阻止了价值函数在离线数据之外的泛化，并且缺乏对OOD数据的精确描述。在本文中，我们提出了用于离线RL的悲观自助法（PBRL），这是一种纯粹由不确定性驱动的离线算法，没有明确的策略约束。具体来说，PBRL通过自助Q函数的分歧进行不确定性量化，并根据估计的不确定性通过惩罚价值函数执行悲观更新。为了解决外推误差，我们进一步提出了一种新颖的OOD采样方法。我们表明，这种OOD采样和悲观自助法在线性MDP中产生了可证明的不确定性量化器，从而为PBRL提供了理论基础。在D4RL基准上的大量实验表明，PBRL与最先进的算法相比具有更好的性能。",
        "领域": "离线强化学习、不确定性量化、策略优化",
        "问题": "解决离线强化学习中由于分布外动作引起的外推误差问题",
        "动机": "提高离线强化学习算法的性能，通过不确定性量化来更精确地处理分布外数据",
        "方法": "提出悲观自助法（PBRL），通过自助Q函数的分歧进行不确定性量化，并执行悲观更新；提出新颖的OOD采样方法",
        "关键词": [
            "离线强化学习",
            "不确定性量化",
            "悲观自助法",
            "OOD采样",
            "D4RL基准"
        ],
        "涉及的技术概念": {
            "悲观自助法（PBRL）": "一种纯粹由不确定性驱动的离线算法，通过自助Q函数的分歧进行不确定性量化，并执行悲观更新",
            "OOD采样": "一种新颖的采样方法，用于解决离线强化学习中的外推误差问题",
            "自助Q函数": "用于量化不确定性的技术，通过多个Q函数的分歧来估计不确定性"
        },
        "success": true
    },
    {
        "order": 765,
        "title": "Pessimistic Model-based Offline Reinforcement Learning under Partial Coverage",
        "html": "https://iclr.cc//virtual/2022/poster/7210",
        "abstract": "We study model-based offline Reinforcement Learning with general function approximation without a full coverage assumption on the offline data distribution. We present an algorithm named Constrained Pessimistic Policy Optimization (CPPO) which leverages a general function class and uses a constraint over the models to encode pessimism. Under the assumption that the ground truth model belongs to our function class (i.e., realizability in the function class), CPPO has a PAC guarantee with offline data only providing partial coverage, i.e., it can learn a policy that competes against any policy covered by the offline data. We then demonstrate that this algorithmic framework can be applied to many specialized Markov Decision Processes where the additional structural assumptions can further refine the concept of partial coverage. Two notable examples are: (1) low- rank MDP with representation learning where the partial coverage condition is defined using a relative condition number measured by the unknown ground truth feature representation; (2) factored MDP where the partial coverage condition is defined using density-ratio based concentrability coefficients associated with individual factors.",
        "conference": "ICLR",
        "中文标题": "部分覆盖下的悲观模型离线强化学习",
        "摘要翻译": "我们研究了基于模型的离线强化学习，该学习采用一般函数逼近方法，且不假设离线数据分布具有完全覆盖性。我们提出了一种名为约束悲观策略优化（CPPO）的算法，该算法利用一般函数类，并通过在模型上施加约束来编码悲观主义。在假设真实模型属于我们的函数类（即函数类可实现性）的条件下，CPPO具有仅提供部分覆盖的离线数据的PAC保证，即它可以学习到一个与离线数据覆盖的任何策略相竞争的策略。然后，我们证明了这个算法框架可以应用于许多专门的马尔可夫决策过程，其中额外的结构假设可以进一步细化部分覆盖的概念。两个显著的例子是：（1）具有表示学习的低秩MDP，其中部分覆盖条件是通过未知真实特征表示测量的相对条件数定义的；（2）因子MDP，其中部分覆盖条件是通过与个体因子相关的基于密度比的集中系数定义的。",
        "领域": "离线强化学习、模型优化、马尔可夫决策过程",
        "问题": "在离线数据分布不满足完全覆盖假设的情况下，如何利用一般函数逼近进行有效的模型离线强化学习。",
        "动机": "研究在离线数据仅提供部分覆盖的情况下，如何通过悲观模型优化方法学习到与任何被覆盖策略相竞争的策略。",
        "方法": "提出约束悲观策略优化（CPPO）算法，利用一般函数类并通过模型约束编码悲观主义，实现在部分覆盖条件下的有效学习。",
        "关键词": [
            "离线强化学习",
            "悲观模型优化",
            "部分覆盖",
            "约束悲观策略优化",
            "马尔可夫决策过程"
        ],
        "涉及的技术概念": {
            "约束悲观策略优化（CPPO）": "一种利用一般函数类并通过在模型上施加约束来编码悲观主义的算法，用于在部分覆盖条件下进行离线强化学习。",
            "部分覆盖": "指离线数据分布不完全覆盖所有可能的状态-动作对，CPPO算法能在这种条件下有效学习。",
            "低秩MDP": "一种马尔可夫决策过程，其转移矩阵具有低秩特性，CPPO算法通过表示学习细化部分覆盖条件。"
        },
        "success": true
    },
    {
        "order": 766,
        "title": "PF-GNN: Differentiable particle filtering based approximation of universal graph representations",
        "html": "https://iclr.cc//virtual/2022/poster/5982",
        "abstract": "Message passing Graph Neural Networks (GNNs) are known to be limited in expressive power by the 1-WL color-refinement test for graph isomorphism. Other more expressive models either are computationally expensive or need preprocessing to extract structural features from the graph. In this work, we propose to make GNNs universal by guiding the learning process with exact isomorphism solver techniques which operate on the paradigm of $\\textit{Individualization and refinement}$ (IR), a method to artificially introduce asymmetry and further refine the coloring when 1-WL stops. Isomorphism solvers generate a search-tree of colorings whose leaves uniquely identify the graph. However, the tree grows exponentially large and needs hand-crafted pruning techniques which are not desirable from a learning perspective. We take a probabilistic view and approximate the search tree of colorings ( i.e. embeddings) by sampling multiple paths from root to leaves of the search-tree. To learn more discriminative representations, we guide the sampling process with $\\textit{particle filter}$ updates, a principled approach for sequential state estimation. Our algorithm is end-to-end differentiable, can be applied with any GNN as backbone and learns richer graph representations with only linear increase in runtime. Experimental evaluation shows that our approach consistently outperforms leading GNN models on both synthetic benchmarks for isomorphism detection as well as real-world datasets.",
        "conference": "ICLR",
        "中文标题": "PF-GNN：基于可微分粒子滤波的通用图表示近似方法",
        "摘要翻译": "消息传递图神经网络（GNNs）的表达能力被图同构的1-WL颜色细化测试所限制。其他表达能力更强的模型要么计算成本高昂，要么需要预处理以从图中提取结构特征。在这项工作中，我们提出通过使用精确的同构求解器技术来指导学习过程，从而使GNNs具有通用性，这些技术操作于“个体化和细化”（IR）范式，这是一种在1-WL停止时人为引入不对称性并进一步细化着色的方法。同构求解器生成一个着色搜索树，其叶子唯一标识图。然而，该树呈指数级增长，并且需要手工剪枝技术，这在学习角度上并不理想。我们采用概率视角，通过从搜索树的根到叶子采样多条路径来近似着色（即嵌入）的搜索树。为了学习更具区分性的表示，我们使用粒子滤波更新来指导采样过程，这是一种用于序列状态估计的原则性方法。我们的算法是端到端可微分的，可以与任何GNN作为骨干网络一起应用，并且仅以线性增加的运行时间学习更丰富的图表示。实验评估表明，我们的方法在同构检测的合成基准测试和真实世界数据集上都持续优于领先的GNN模型。",
        "领域": "图神经网络、图同构检测、图表示学习",
        "问题": "提高图神经网络的表达能力，使其能够更准确地识别和区分不同的图结构。",
        "动机": "现有的图神经网络在表达能力上受到限制，无法有效区分某些图结构，而更复杂的模型又存在计算成本高或需要复杂预处理的问题。",
        "方法": "采用可微分粒子滤波技术近似同构求解器的搜索树，通过采样多条路径来学习更丰富的图表示，同时保持算法的可微分性和计算效率。",
        "关键词": [
            "图神经网络",
            "粒子滤波",
            "图同构",
            "图表示学习",
            "可微分算法"
        ],
        "涉及的技术概念": {
            "个体化和细化（IR）": "一种人为引入不对称性并细化着色的方法，用于在同构求解器中生成唯一标识图的搜索树。",
            "粒子滤波": "一种用于序列状态估计的概率方法，在本研究中用于指导采样过程，以学习更具区分性的图表示。",
            "可微分算法": "允许算法中的所有操作都是可微分的，使得整个模型可以通过梯度下降等方法进行端到端的训练。"
        },
        "success": true
    },
    {
        "order": 767,
        "title": "Phase Collapse in Neural Networks",
        "html": "https://iclr.cc//virtual/2022/poster/6415",
        "abstract": "Deep convolutional classifiers linearly separate image classes and improve accuracy as depth increases. They progressively reduce the spatial dimension whereas the number of channels grows with depth. Spatial variability is therefore transformed into variability along channels. A fundamental challenge is to understand the role of non-linearities together with convolutional filters in this transformation. ReLUs with biases are often interpreted as thresholding operators that improve discrimination through sparsity. This paper demonstrates that it is a different mechanism called \\emph{phase collapse} which eliminates spatial variability while linearly separating classes. We show that collapsing the phases of complex wavelet coefficients is sufficient to reach the classification accuracy of ResNets of similar depths. However, replacing the phase collapses with thresholding operators that enforce sparsity considerably degrades the performance. We explain these numerical results by showing that the iteration of phase collapses progressively improves separation of classes, as opposed to thresholding non-linearities.",
        "conference": "ICLR",
        "中文标题": "神经网络中的相位崩溃",
        "摘要翻译": "深度卷积分类器随着深度的增加线性分离图像类别并提高准确率。它们逐步减少空间维度，而通道数量随深度增加。因此，空间变异性被转化为沿通道的变异性。一个基本挑战是理解非线性与卷积滤波器在这一转换中的作用。带有偏置的ReLU通常被解释为通过稀疏性改善识别的阈值操作符。本文证明了一种称为相位崩溃的不同机制，它在线性分离类别时消除了空间变异性。我们展示了崩溃复杂小波系数的相位足以达到与类似深度ResNets的分类准确率。然而，用强制稀疏性的阈值操作符替换相位崩溃会显著降低性能。我们通过展示相位崩溃的迭代逐步改善类别的分离，与阈值非线性相反，来解释这些数值结果。",
        "领域": "深度学习、计算机视觉、图像分类",
        "问题": "理解非线性与卷积滤波器在将空间变异性转化为通道变异性中的作用",
        "动机": "探索和解释深度卷积分类器中非线性操作符（如ReLU）与卷积滤波器共同作用的机制，特别是相位崩溃在提高分类准确率中的作用",
        "方法": "通过分析相位崩溃机制及其对分类准确率的影响，与传统的阈值操作符进行比较，展示相位崩溃在改善类别分离中的有效性",
        "关键词": [
            "相位崩溃",
            "深度卷积分类器",
            "非线性操作符",
            "图像分类",
            "小波系数"
        ],
        "涉及的技术概念": {
            "相位崩溃": "一种在深度卷积分类器中消除空间变异性同时线性分离类别的机制",
            "ReLU": "带有偏置的线性整流单元，通常用于增加网络的非线性",
            "小波系数": "在图像处理中用于表示图像的多尺度空间和频率特性的系数，相位崩溃作用于这些系数以改善分类性能"
        },
        "success": true
    },
    {
        "order": 768,
        "title": "Phenomenology of Double Descent in Finite-Width Neural Networks",
        "html": "https://iclr.cc//virtual/2022/poster/6861",
        "abstract": "`Double descent' delineates the generalization behaviour of models depending on the regime they belong to: under- or over-parameterized. The current theoretical understanding behind the occurrence of this phenomenon is primarily based on linear and kernel regression models --- with informal parallels to neural networks via the Neural Tangent Kernel. Therefore such analyses do not adequately capture the mechanisms behind double descent in finite-width neural networks, as well as, disregard crucial components --- such as the choice of the loss function. We address these shortcomings by leveraging influence functions in order to derive suitable expressions of the population loss and its lower bound, while imposing minimal assumptions on the form of the parametric model. Our derived bounds bear an intimate connection with the spectrum of the Hessian at the optimum, and importantly, exhibit a double descent behaviour at the interpolation threshold. Building on our analysis, we further investigate how the loss function affects double descent --- and thus uncover interesting properties of neural networks and their Hessian spectra near the interpolation threshold.",
        "conference": "ICLR",
        "中文标题": "有限宽度神经网络中双下降现象的现象学研究",
        "摘要翻译": "'双下降'描述了模型根据其所属的体系（欠参数化或过参数化）的泛化行为。目前对这一现象发生的理论理解主要基于线性和核回归模型——通过与神经切线核的非正式类比扩展到神经网络。因此，这些分析未能充分捕捉有限宽度神经网络中双下降的机制，同时也忽略了关键组成部分——如损失函数的选择。我们通过利用影响函数来弥补这些不足，以推导出总体损失及其下界的合适表达式，同时对参数模型的形式施加最小假设。我们推导的边界与最优解处的Hessian谱有着密切的联系，并且重要的是，在插值阈值处表现出双下降行为。基于我们的分析，我们进一步研究了损失函数如何影响双下降——从而揭示了神经网络及其Hessian谱在插值阈值附近的有趣性质。",
        "领域": "深度学习理论、神经网络优化、机器学习理论",
        "问题": "理解有限宽度神经网络中双下降现象的发生机制及其与损失函数的关系",
        "动机": "当前对双下降现象的理论分析主要基于线性和核回归模型，未能充分解释有限宽度神经网络中的这一现象，特别是忽略了损失函数的作用",
        "方法": "利用影响函数推导总体损失及其下界的表达式，分析这些表达式与Hessian谱的关系，并研究损失函数对双下降现象的影响",
        "关键词": [
            "双下降",
            "有限宽度神经网络",
            "影响函数",
            "Hessian谱",
            "损失函数"
        ],
        "涉及的技术概念": {
            "双下降": "描述模型泛化性能在模型复杂度增加时先下降后上升再下降的现象",
            "影响函数": "用于推导总体损失及其下界的数学工具，帮助理解模型参数变化对损失的影响",
            "Hessian谱": "Hessian矩阵的特征值分布，与模型的优化景观和泛化性能密切相关"
        },
        "success": true
    },
    {
        "order": 769,
        "title": "PI3NN: Out-of-distribution-aware Prediction Intervals from Three Neural Networks",
        "html": "https://iclr.cc//virtual/2022/poster/6974",
        "abstract": "We propose a novel prediction interval (PI) method for uncertainty quantification, which addresses three major issues with the state-of-the-art PI methods. First, existing PI methods require retraining of neural networks (NNs) for every given confidence level and suffer from the crossing issue in calculating multiple PIs. Second, they usually rely on customized loss functions with extra sensitive hyperparameters for which fine tuning is required to achieve a well-calibrated PI. Third, they usually underestimate uncertainties of out-of-distribution (OOD) samples leading to over-confident PIs. Our PI3NN method calculates PIs from linear combinations of three NNs, each of which is independently trained using the standard mean squared error loss. The coefficients of the linear combinations are computed using root-finding algorithms to ensure tight PIs for a given confidence level. We theoretically prove that PI3NN can calculate PIs for a series of confidence levels without retraining NNs and it completely avoids the crossing issue. Additionally, PI3NN does not introduce any unusual hyperparameters resulting in a stable performance. Furthermore, we address OOD identification challenge by introducing an initialization scheme which provides reasonably larger PIs of the OOD samples than those of the in-distribution samples. Benchmark and real-world experiments show that our method outperforms several state-of-the-art approaches with respect to predictive uncertainty quality, robustness, and OOD samples identification.",
        "conference": "ICLR",
        "中文标题": "PI3NN：基于三个神经网络的外分布感知预测区间",
        "摘要翻译": "我们提出了一种新颖的预测区间（PI）方法用于不确定性量化，解决了当前最先进PI方法的三个主要问题。首先，现有的PI方法需要对每个给定的置信水平重新训练神经网络（NNs），并且在计算多个PIs时存在交叉问题。其次，它们通常依赖于定制的损失函数，这些函数带有额外的敏感超参数，需要通过精细调整才能获得良好校准的PI。第三，它们通常会低估外分布（OOD）样本的不确定性，导致过度自信的PIs。我们的PI3NN方法通过三个NNs的线性组合计算PIs，每个NN都是独立使用标准均方误差损失训练的。线性组合的系数使用根查找算法计算，以确保对于给定置信水平的紧密PIs。我们从理论上证明，PI3NN可以计算一系列置信水平的PIs而无需重新训练NNs，并且完全避免了交叉问题。此外，PI3NN没有引入任何不寻常的超参数，从而实现了稳定的性能。进一步，我们通过引入一个初始化方案解决了OOD识别的挑战，该方案为OOD样本提供了比内分布样本合理更大的PIs。基准和真实世界的实验表明，我们的方法在预测不确定性质量、鲁棒性和OOD样本识别方面优于几种最先进的方法。",
        "领域": "不确定性量化、神经网络、外分布检测",
        "问题": "解决现有预测区间方法在多个置信水平下需要重新训练神经网络、存在交叉问题、依赖定制损失函数和低估外分布样本不确定性的问题。",
        "动机": "提高预测区间的计算效率、避免交叉问题、减少对定制损失函数的依赖，并准确量化外分布样本的不确定性。",
        "方法": "通过三个独立训练的神经网络的线性组合计算预测区间，使用根查找算法确定组合系数，引入初始化方案以区分外分布样本。",
        "关键词": [
            "预测区间",
            "不确定性量化",
            "外分布检测",
            "神经网络",
            "根查找算法"
        ],
        "涉及的技术概念": {
            "预测区间（PI）": "用于量化预测不确定性的区间估计，PI3NN方法通过三个神经网络的线性组合计算。",
            "外分布（OOD）样本": "与训练数据分布不同的样本，PI3NN通过初始化方案为这些样本提供更大的预测区间。",
            "根查找算法": "用于计算线性组合系数，确保预测区间对于给定置信水平的紧密性。"
        },
        "success": true
    },
    {
        "order": 770,
        "title": "PiCO: Contrastive Label Disambiguation for Partial Label Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6038",
        "abstract": "Partial label learning (PLL) is an important problem that allows each training example to be labeled with a coarse candidate set, which well suits many real-world data annotation scenarios with label ambiguity.  Despite the promise, the performance of PLL often lags behind the supervised counterpart. In this work, we bridge the gap by addressing two key research challenges in PLL---representation learning and label disambiguation---in one coherent framework. Specifically, our proposed framework PiCO consists of a contrastive learning module along with a novel class prototype-based label disambiguation algorithm. PiCO produces closely aligned representations for examples from the same classes and facilitates label disambiguation. Theoretically, we show that these two components are mutually beneficial, and can be rigorously justified from an expectation-maximization (EM) algorithm perspective. Extensive experiments demonstrate that PiCO significantly outperforms the current state-of-the-art approaches in PLL and even achieves comparable results to fully supervised learning. Code and data available: https://github.com/hbzju/PiCO.",
        "conference": "ICLR",
        "中文标题": "PiCO：部分标签学习中的对比标签消歧",
        "摘要翻译": "部分标签学习（PLL）是一个重要的问题，它允许每个训练样本被标记为一个粗略的候选集，这非常适合许多现实世界中的标签模糊数据注释场景。尽管有这一承诺，PLL的性能往往落后于有监督的学习。在这项工作中，我们通过在一个统一的框架中解决PLL中的两个关键研究挑战——表示学习和标签消歧——来弥合这一差距。具体来说，我们提出的框架PiCO包括一个对比学习模块和一个新颖的基于类原型的标签消歧算法。PiCO为来自同一类别的样本生成紧密对齐的表示，并促进标签消歧。理论上，我们展示了这两个组件是相互受益的，并且可以从期望最大化（EM）算法的角度进行严格证明。大量实验表明，PiCO在PLL中显著优于当前最先进的方法，甚至达到了与完全监督学习相当的结果。代码和数据可在以下网址获取：https://github.com/hbzju/PiCO。",
        "领域": "部分标签学习、对比学习、标签消歧",
        "问题": "解决部分标签学习中的表示学习和标签消歧问题",
        "动机": "提高部分标签学习的性能，使其接近或达到完全监督学习的水平",
        "方法": "提出一个统一的框架PiCO，结合对比学习模块和基于类原型的标签消歧算法",
        "关键词": [
            "部分标签学习",
            "对比学习",
            "标签消歧",
            "类原型",
            "期望最大化算法"
        ],
        "涉及的技术概念": {
            "对比学习": "用于生成紧密对齐的表示，促进来自同一类别的样本之间的相似性",
            "类原型": "用于标签消歧的核心概念，帮助识别和纠正标签中的模糊性",
            "期望最大化算法": "为PiCO框架提供理论支持，证明表示学习和标签消歧的相互受益关系"
        },
        "success": true
    },
    {
        "order": 771,
        "title": "PipeGCN: Efficient Full-Graph Training of Graph Convolutional Networks with Pipelined Feature Communication",
        "html": "https://iclr.cc//virtual/2022/poster/6173",
        "abstract": "Graph Convolutional Networks (GCNs) is the state-of-the-art method for learning graph-structured data, and training large-scale GCNs requires distributed training across multiple accelerators such that each accelerator is able to hold a partitioned subgraph. However, distributed GCN training incurs prohibitive overhead of communicating node features and feature gradients among partitions for every GCN layer during each training iteration, limiting the achievable training efficiency and model scalability. To this end, we propose PipeGCN, a simple yet effective scheme that hides the communication overhead by pipelining inter-partition communication with intra-partition computation. It is non-trivial to pipeline for efficient GCN training, as communicated node features/gradients will become stale and thus can harm the convergence, negating the pipeline benefit. Notably, little is known regarding the convergence rate of GCN training with both stale features and stale feature gradients. This work not only provides a theoretical convergence analysis but also finds the convergence rate of PipeGCN to be close to that of the vanilla distributed GCN training without any staleness. Furthermore, we develop a smoothing method to further improve PipeGCN's convergence. Extensive experiments show that PipeGCN can largely boost the training throughput (1.7×~28.5×) while achieving the same accuracy as its vanilla counterpart and existing full-graph training methods. The code is available at https://github.com/RICE-EIC/PipeGCN.",
        "conference": "ICLR",
        "中文标题": "PipeGCN：通过流水线特征通信实现图卷积网络的高效全图训练",
        "摘要翻译": "图卷积网络（GCNs）是学习图结构数据的最先进方法，大规模GCNs的训练需要在多个加速器之间进行分布式训练，以便每个加速器能够持有分割的子图。然而，分布式GCN训练在每次训练迭代中，为每一GCN层进行节点特征和特征梯度的分区间通信，产生了过高的开销，限制了可达到的训练效率和模型的可扩展性。为此，我们提出了PipeGCN，一种简单而有效的方案，通过将分区间的通信与分区内的计算流水线化，隐藏了通信开销。实现高效的GCN训练流水线并非易事，因为通信的节点特征/梯度会变得陈旧，从而可能损害收敛性，抵消流水线的好处。值得注意的是，对于同时存在陈旧特征和特征梯度的GCN训练的收敛速度知之甚少。这项工作不仅提供了理论上的收敛分析，还发现PipeGCN的收敛速度接近于没有任何陈旧性的普通分布式GCN训练。此外，我们开发了一种平滑方法，以进一步提高PipeGCN的收敛性。大量实验表明，PipeGCN可以大幅提高训练吞吐量（1.7倍~28.5倍），同时达到与普通版本和现有全图训练方法相同的准确率。代码可在https://github.com/RICE-EIC/PipeGCN获取。",
        "领域": "图神经网络、分布式机器学习、高效计算",
        "问题": "分布式图卷积网络训练中节点特征和特征梯度的通信开销过大，影响训练效率和模型可扩展性。",
        "动机": "减少分布式GCN训练中的通信开销，提高训练效率和模型的可扩展性。",
        "方法": "提出PipeGCN方案，通过流水线化分区间的通信与分区内的计算，隐藏通信开销，并通过理论分析和实验验证其有效性。",
        "关键词": [
            "图卷积网络",
            "分布式训练",
            "流水线通信",
            "高效计算",
            "模型可扩展性"
        ],
        "涉及的技术概念": {
            "图卷积网络": "用于学习图结构数据的先进方法，本文中通过分布式训练提高其处理大规模图的能力。",
            "流水线通信": "通过将通信与计算并行化，隐藏通信延迟，提高训练效率。",
            "收敛分析": "对PipeGCN训练过程中的收敛性进行理论分析，确保其有效性。"
        },
        "success": true
    },
    {
        "order": 772,
        "title": "Pix2seq: A Language Modeling Framework for Object Detection",
        "html": "https://iclr.cc//virtual/2022/poster/6245",
        "abstract": "We present Pix2Seq, a simple and generic framework for object detection. Unlike existing approaches that explicitly integrate prior knowledge about the task, we cast object detection as a language modeling task conditioned on the observed pixel inputs. Object descriptions (e.g., bounding boxes and class labels) are expressed as sequences of discrete tokens, and we train a neural network to perceive the image and generate the desired sequence. Our approach is based mainly on the intuition that if a neural network knows about where and what the objects are, we just need to teach it how to read them out. Beyond the use of task-specific data augmentations, our approach makes minimal assumptions about the task, yet it achieves competitive results on the challenging COCO dataset, compared to highly specialized and well optimized detection algorithms.",
        "conference": "ICLR",
        "中文标题": "Pix2seq：一种用于目标检测的语言建模框架",
        "摘要翻译": "我们提出了Pix2Seq，一个简单且通用的目标检测框架。与现有方法不同，现有方法明确集成了关于任务的先验知识，而我们将目标检测视为基于观察到的像素输入的语言建模任务。对象描述（例如，边界框和类标签）被表示为离散标记的序列，我们训练一个神经网络来感知图像并生成所需的序列。我们的方法主要基于这样一种直觉：如果一个神经网络知道对象在哪里以及它们是什么，我们只需要教它如何读出它们。除了使用任务特定的数据增强外，我们的方法对任务的假设极少，但在具有挑战性的COCO数据集上，与高度专业化和优化良好的检测算法相比，它取得了竞争性的结果。",
        "领域": "目标检测",
        "问题": "如何将目标检测任务转化为语言建模任务，以简化模型设计并提高性能",
        "动机": "基于直觉，即神经网络若已知对象位置和类别，只需学习如何输出这些信息，从而简化目标检测流程",
        "方法": "将目标检测任务转化为语言建模任务，使用神经网络生成描述对象的离散标记序列",
        "关键词": [
            "Pix2Seq",
            "语言建模",
            "目标检测",
            "神经网络",
            "COCO数据集"
        ],
        "涉及的技术概念": {
            "语言建模": "将目标检测任务转化为基于像素输入的语言建模任务，简化模型设计",
            "离散标记序列": "用于表示对象描述（如边界框和类标签），便于神经网络处理和生成",
            "数据增强": "在训练过程中使用任务特定的数据增强技术，以提高模型的泛化能力和性能"
        },
        "success": true
    },
    {
        "order": 773,
        "title": "Pixelated Butterfly: Simple and Efficient Sparse training for Neural Network Models",
        "html": "https://iclr.cc//virtual/2022/poster/6571",
        "abstract": "Overparameterized neural networks generalize well but are expensive to train. Ideally one would like to reduce their computational cost while retaining their generalization benefits. Sparse model training is a simple and promising approach to achieve this, but there remain challenges as existing methods struggle with accuracy loss, slow training runtime, or difficulty in sparsifying all model components. The core problem is that searching for a sparsity mask over a discrete set of sparse matrices is difficult and expensive. To address this, our main insight is to optimize over a continuous superset of sparse matrices with a fixed structure known as products of butterfly matrices. As butterfly matrices are not hardware efficient, we propose simple variants of butterfly (block and flat) to take advantage of modern hardware. Our method (Pixelated Butterfly) uses a simple fixed sparsity pattern based on flat block butterfly and low-rank matrices to sparsify most network layers (e.g., attention, MLP). We empirically validate that Pixelated Butterfly is $3\\times$ faster than Butterfly and speeds up training to achieve favorable accuracy--efficiency tradeoffs. On the ImageNet classification and WikiText-103 language modeling tasks, our sparse models train up to 2.3$\\times$ faster than the dense MLP-Mixer, Vision Transformer, and GPT-2 small with no drop in accuracy.",
        "conference": "ICLR",
        "中文标题": "像素化蝴蝶：神经网络模型简单高效的稀疏训练方法",
        "摘要翻译": "过参数化的神经网络泛化能力强但训练成本高昂。理想情况下，人们希望在保留其泛化优势的同时降低计算成本。稀疏模型训练是一种简单且有前景的实现这一目标的方法，但仍面临挑战，因为现有方法在准确性损失、训练速度慢或难以稀疏化所有模型组件方面存在问题。核心问题在于在离散的稀疏矩阵集合上搜索稀疏掩码既困难又昂贵。为解决这一问题，我们的主要见解是在具有固定结构的稀疏矩阵的连续超集上进行优化，这种结构被称为蝴蝶矩阵的乘积。由于蝴蝶矩阵在硬件上效率不高，我们提出了蝴蝶矩阵的简单变体（块状和平坦）以利用现代硬件的优势。我们的方法（像素化蝴蝶）使用基于平坦块蝴蝶和低秩矩阵的简单固定稀疏模式来稀疏化大多数网络层（例如，注意力、MLP）。我们通过实验验证，像素化蝴蝶比蝴蝶矩阵快3倍，并加速训练以实现有利的准确性-效率权衡。在ImageNet分类和WikiText-103语言建模任务中，我们的稀疏模型训练速度比密集的MLP-Mixer、Vision Transformer和GPT-2小型模型快2.3倍，且准确性没有下降。",
        "领域": "神经网络优化, 稀疏训练, 深度学习效率",
        "问题": "如何在保留神经网络泛化能力的同时降低训练成本",
        "动机": "解决过参数化神经网络训练成本高的问题，同时保持其泛化优势",
        "方法": "提出基于蝴蝶矩阵变体的稀疏训练方法，优化稀疏矩阵的连续超集",
        "关键词": [
            "稀疏训练",
            "蝴蝶矩阵",
            "神经网络优化",
            "深度学习效率",
            "硬件加速"
        ],
        "涉及的技术概念": {
            "蝴蝶矩阵": "一种固定结构的稀疏矩阵，用于优化稀疏训练过程",
            "稀疏训练": "通过减少模型中的非零参数来降低计算成本的方法",
            "低秩矩阵": "用于稀疏化网络层，减少计算复杂度同时保持模型性能"
        },
        "success": true
    },
    {
        "order": 774,
        "title": "Planning in Stochastic Environments with a Learned Model",
        "html": "https://iclr.cc//virtual/2022/poster/6832",
        "abstract": "Model-based reinforcement learning has proven highly successful. However, learning a model in isolation from its use during planning is problematic in complex environments. To date, the most effective techniques have instead combined value-equivalent model learning with powerful tree-search methods. This approach is exemplified by MuZero, which has achieved state-of-the-art performance in a wide range of domains, from board games to visually rich environments, with discrete and continuous action spaces, in online and offline settings. However, previous instantiations of this approach were limited to the use of deterministic models. This limits their performance in environments that are inherently stochastic, partially observed, or so large and complex that they appear stochastic to a finite agent. In this paper we extend this approach to learn and plan with stochastic models. Specifically, we introduce a new algorithm, Stochastic MuZero, that learns a stochastic model incorporating afterstates, and uses this model to perform a stochastic tree search. Stochastic MuZero matched or exceeded the state of the art in a set of canonical single and multi-agent environments, including 2048 and backgammon, while maintaining the same performance as standard MuZero in the game of Go.",
        "conference": "ICLR",
        "中文标题": "在随机环境中使用学习模型进行规划",
        "摘要翻译": "基于模型的强化学习已被证明非常成功。然而，在复杂环境中，独立于规划使用学习模型是有问题的。迄今为止，最有效的技术是将价值等价模型学习与强大的树搜索方法相结合。这种方法以MuZero为例，它在从棋盘游戏到视觉丰富环境的广泛领域中，在离散和连续动作空间中，在线和离线设置下，都实现了最先进的性能。然而，这种方法之前的实例仅限于使用确定性模型。这限制了它们在本质上随机、部分可观察或如此之大和复杂以至于对有限代理来说显得随机的环境中的性能。在本文中，我们扩展了这种方法，以学习和规划随机模型。具体来说，我们引入了一种新算法，随机MuZero，它学习一个包含后状态的随机模型，并使用该模型执行随机树搜索。随机MuZero在一组典型的单和多代理环境中，包括2048和双陆棋，匹配或超过了最先进的水平，同时在围棋游戏中保持了与标准MuZero相同的性能。",
        "领域": "强化学习、游戏AI、多智能体系统",
        "问题": "在随机、部分可观察或复杂环境中，确定性模型的局限性",
        "动机": "扩展基于模型的强化学习方法，以更好地处理随机环境中的规划问题",
        "方法": "引入随机MuZero算法，结合随机模型学习和随机树搜索",
        "关键词": [
            "随机模型",
            "强化学习",
            "树搜索",
            "MuZero",
            "后状态"
        ],
        "涉及的技术概念": {
            "随机模型": "用于模拟环境中的随机性和不确定性，提高在复杂环境中的规划能力",
            "后状态": "在动作执行后但尚未观察到结果时的状态表示，有助于模型更准确地预测未来状态",
            "随机树搜索": "一种在随机环境中进行决策的方法，通过模拟可能的未来状态和动作来优化策略"
        },
        "success": true
    },
    {
        "order": 775,
        "title": "Plant 'n' Seek: Can You Find the Winning Ticket?",
        "html": "https://iclr.cc//virtual/2022/poster/7073",
        "abstract": "The lottery ticket hypothesis has sparked the rapid development of pruning algorithms that aim to reduce the computational costs associated with deep learning during training and model deployment. Currently, such algorithms are primarily evaluated on imaging data, for which we lack ground truth information and thus the understanding of how sparse lottery tickets could be. To fill this gap, we develop a framework that allows us to plant and hide winning tickets with desirable properties in randomly initialized neural networks. To analyze the ability of state-of-the-art pruning to identify tickets of extreme sparsity, we design and hide such tickets solving four challenging tasks. In extensive experiments, we observe similar trends as in imaging studies, indicating that our framework can provide transferable insights into realistic problems. Additionally, we can now see beyond such relative trends and highlight limitations of current pruning methods. Based on our results, we conclude that the current limitations in ticket sparsity are likely of algorithmic rather than fundamental nature. We anticipate that comparisons to planted tickets will facilitate future developments of efficient pruning algorithms.",
        "conference": "ICLR",
        "中文标题": "种植与寻找：你能找到中奖彩票吗？",
        "摘要翻译": "彩票假设激发了修剪算法的快速发展，这些算法旨在减少深度学习中训练和模型部署相关的计算成本。目前，这类算法主要在成像数据上进行评估，对此我们缺乏真实信息，因此对稀疏彩票的理解有限。为了填补这一空白，我们开发了一个框架，允许我们在随机初始化的神经网络中种植和隐藏具有理想属性的中奖彩票。为了分析最先进修剪算法识别极端稀疏彩票的能力，我们设计并隐藏了解决四个挑战性任务的彩票。在大量实验中，我们观察到了与成像研究中相似的趋势，表明我们的框架可以为现实问题提供可转移的见解。此外，我们现在可以超越这些相对趋势，突出当前修剪方法的局限性。基于我们的结果，我们得出结论，当前彩票稀疏性的限制可能是算法性的而非根本性的。我们预期，与种植彩票的比较将促进高效修剪算法的未来发展。",
        "领域": "神经网络修剪、深度学习优化、模型压缩",
        "问题": "如何有效识别和利用神经网络中的极端稀疏彩票（即高效子网络）以减少计算成本。",
        "动机": "当前修剪算法主要在缺乏真实信息的成像数据上评估，限制了我们对稀疏彩票的理解和应用。",
        "方法": "开发了一个框架，在随机初始化的神经网络中种植和隐藏具有特定属性的中奖彩票，并通过设计挑战性任务来评估修剪算法的能力。",
        "关键词": [
            "彩票假设",
            "神经网络修剪",
            "模型稀疏性",
            "深度学习优化",
            "计算效率"
        ],
        "涉及的技术概念": {
            "彩票假设": "指在大型神经网络中存在小的子网络（即“彩票”），这些子网络在单独训练时能够达到与原网络相当的性能。",
            "神经网络修剪": "一种减少神经网络复杂度和计算成本的技术，通过移除不重要的连接或神经元来实现。",
            "模型稀疏性": "指模型中非零参数的比例，稀疏性越高，模型的计算效率通常也越高。"
        },
        "success": true
    },
    {
        "order": 776,
        "title": "POETREE: Interpretable Policy Learning with Adaptive Decision Trees",
        "html": "https://iclr.cc//virtual/2022/poster/7015",
        "abstract": "Building models of human decision-making from observed behaviour is critical to better understand, diagnose and support real-world policies such as clinical care. As established policy learning approaches remain focused on imitation performance, they fall short of explaining the demonstrated decision-making process. Policy Extraction through decision Trees (POETREE) is a novel framework for interpretable policy learning, compatible with fully-offline and partially-observable clinical decision environments -- and builds probabilistic tree policies determining physician actions based on patients' observations and medical history. Fully-differentiable tree architectures are grown incrementally during optimization to adapt their complexity to the modelling task, and learn a representation of patient history through recurrence, resulting in decision tree policies that adapt over time with patient information. This policy learning method outperforms the state-of-the-art on real and synthetic medical datasets, both in terms of understanding, quantifying and evaluating observed behaviour as well as in accurately replicating it -- with potential to improve future decision support systems.",
        "conference": "ICLR",
        "中文标题": "POETREE：基于自适应决策树的可解释策略学习",
        "摘要翻译": "从观察到的行为中构建人类决策模型对于更好地理解、诊断和支持现实世界中的政策（如临床护理）至关重要。由于现有的策略学习方法仍然侧重于模仿性能，它们无法解释所展示的决策过程。通过决策树提取策略（POETREE）是一种新颖的可解释策略学习框架，兼容完全离线和部分可观察的临床决策环境——并构建基于患者观察和医疗历史的概率树策略，决定医生的行动。完全可微的树架构在优化过程中逐步增长，以适应建模任务的复杂性，并通过递归学习患者历史的表示，从而产生随时间适应患者信息的决策树策略。这种策略学习方法在真实和合成的医疗数据集上均优于现有技术，无论是在理解、量化和评估观察到的行为方面，还是在准确复制这些行为方面——有潜力改善未来的决策支持系统。",
        "领域": "可解释人工智能、医疗决策支持、策略学习",
        "问题": "如何从观察到的行为中构建可解释的人类决策模型，以更好地理解和支持现实世界中的政策（如临床护理）。",
        "动机": "现有的策略学习方法侧重于模仿性能，但缺乏解释决策过程的能力，这限制了其在临床决策支持等领域的应用。",
        "方法": "提出了一种名为POETREE的新框架，通过构建完全可微的树架构，在优化过程中逐步增长以适应任务复杂性，并通过递归学习患者历史的表示，实现随时间适应患者信息的决策树策略。",
        "关键词": [
            "可解释人工智能",
            "决策树",
            "策略学习",
            "医疗决策支持",
            "递归学习"
        ],
        "涉及的技术概念": {
            "完全可微的树架构": "在优化过程中逐步增长的树结构，能够适应建模任务的复杂性，提高策略学习的灵活性和效率。",
            "递归学习": "通过递归机制学习患者历史的表示，使决策树策略能够随时间适应患者信息的变化。",
            "概率树策略": "基于患者观察和医疗历史构建的策略，能够决定医生的行动，具有解释性和适应性。"
        },
        "success": true
    },
    {
        "order": 777,
        "title": "Poisoning and Backdooring Contrastive Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6316",
        "abstract": "Multimodal contrastive learning methods like CLIP train on noisy and uncurated training datasets. This is cheaper than labeling datasets manually, and even improves out-of-distribution robustness. We show that this practice makes backdoor and poisoning attacks a significant threat. By poisoning just 0.01% of a dataset (e.g., just 300 images of the 3 million-example Conceptual Captions dataset), we can cause the model to misclassify test images by overlaying a small patch. Targeted poisoning attacks, whereby the model misclassifies a particular test input  with an adversarially-desired label, are even easier requiring control of 0.0001% of the dataset (e.g., just three out of the 3 million images). Our attacks call into question whether training on noisy and uncurated Internet scrapes is desirable.",
        "conference": "ICLR",
        "中文标题": "毒化和后门对比学习",
        "摘要翻译": "多模态对比学习方法如CLIP在嘈杂且未经筛选的训练数据集上进行训练。这比手动标注数据集更便宜，甚至提高了分布外鲁棒性。我们展示这种做法使得后门和毒化攻击成为重大威胁。通过仅毒化数据集的0.01%（例如，在300万样本的概念标题数据集中仅300张图像），我们可以通过在测试图像上叠加一个小补丁导致模型错误分类。有针对性的毒化攻击，即模型将特定的测试输入错误分类为对抗性期望的标签，甚至更容易，仅需控制数据集的0.0001%（例如，300万图像中的仅三张）。我们的攻击质疑了在嘈杂且未经筛选的互联网抓取数据上训练是否可取。",
        "领域": "多模态学习, 对抗性攻击, 对比学习",
        "问题": "研究揭示了在多模态对比学习中，使用未筛选和嘈杂的数据集训练模型容易受到毒化和后门攻击的问题。",
        "动机": "探讨在追求数据收集和标注成本效益的同时，如何保障模型安全，防止对抗性攻击。",
        "方法": "通过在数据集中注入极小比例的毒化样本（如0.01%或0.0001%），研究其对模型分类性能的影响，特别是导致模型错误分类的能力。",
        "关键词": [
            "毒化攻击",
            "后门攻击",
            "对比学习",
            "多模态学习",
            "对抗性样本"
        ],
        "涉及的技术概念": {
            "对比学习": "一种通过比较正负样本来学习数据表示的方法，用于提升模型的泛化能力。",
            "毒化攻击": "通过在训练数据中注入恶意样本，影响模型的学习过程，导致模型在特定输入上产生错误输出。",
            "后门攻击": "一种特定类型的毒化攻击，攻击者通过控制训练数据，使得模型在特定触发条件下产生预设的错误行为。"
        },
        "success": true
    },
    {
        "order": 778,
        "title": "Policy Gradients Incorporating the Future",
        "html": "https://iclr.cc//virtual/2022/poster/6264",
        "abstract": "Reasoning about the future -- understanding how decisions in the present time affect outcomes in the future -- is one of the central challenges for reinforcement learning (RL), especially in highly-stochastic or partially observable environments. While predicting the future directly is hard, in this work we introduce a method that allows an agent to ``look into the future'' without explicitly predicting it. Namely, we propose to allow an agent, during its training on past experience, to observe what \\emph{actually} happened in the future at that time, while enforcing an information bottleneck to avoid the agent overly relying on this privileged information. Coupled with recent advances in variational inference and a latent-variable autoregressive model, this gives our agent the ability to utilize rich and \\emph{useful} information about the future trajectory dynamics in addition to the present. Our method, Policy Gradients Incorporating the Future (PGIF), is easy to implement and versatile, being applicable to virtually any policy gradient algorithm. We apply our proposed method to a number of off-the-shelf RL algorithms and show that PGIF is able to achieve higher reward faster in a variety of online and offline RL domains, as well as sparse-reward and partially observable environments. ",
        "conference": "ICLR",
        "success": true,
        "中文标题": "融入未来的策略梯度",
        "摘要翻译": "关于未来的推理——理解当前时间的决策如何影响未来的结果——是强化学习（RL）的核心挑战之一，尤其是在高度随机或部分可观察的环境中。虽然直接预测未来是困难的，但在这项工作中，我们引入了一种方法，允许代理“窥视未来”而无需明确预测它。即，我们建议允许代理在对其过去经验进行训练时，观察当时未来实际发生的情况，同时强制执行信息瓶颈以避免代理过度依赖这一特权信息。结合变分推断和潜在变量自回归模型的最新进展，这使我们的代理除了当前信息外，还能利用关于未来轨迹动态的丰富且有用的信息。我们的方法，融入未来的策略梯度（PGIF），易于实现且通用，几乎适用于任何策略梯度算法。我们将我们提出的方法应用于多种现成的RL算法，并显示PGIF能够在各种在线和离线RL领域，以及稀疏奖励和部分可观察的环境中更快地获得更高的奖励。",
        "领域": "强化学习, 策略优化, 变分推断",
        "问题": "如何在高度随机或部分可观察的环境中，使强化学习代理能够有效地利用未来信息来优化当前决策。",
        "动机": "解决强化学习代理在高度随机或部分可观察环境中难以有效利用未来信息进行决策的问题。",
        "方法": "通过引入一种允许代理在训练过程中观察未来实际发生情况的方法，结合变分推断和潜在变量自回归模型，使代理能够利用未来轨迹动态的丰富信息。",
        "关键词": [
            "策略梯度",
            "未来信息利用",
            "变分推断",
            "潜在变量模型",
            "强化学习"
        ],
        "涉及的技术概念": {
            "策略梯度": "一种优化策略的方法，通过梯度上升来直接优化策略参数，以最大化预期回报。",
            "变分推断": "用于近似复杂概率分布的技术，在本研究中用于处理未来信息的不确定性。",
            "潜在变量自回归模型": "一种能够捕捉时间序列数据中潜在动态的模型，用于预测和理解未来轨迹的动态。"
        }
    },
    {
        "order": 779,
        "title": "Policy improvement by planning with Gumbel",
        "html": "https://iclr.cc//virtual/2022/poster/6418",
        "abstract": "AlphaZero is a powerful reinforcement learning algorithm based on approximate policy iteration and tree search. However, AlphaZero can fail to improve its policy network, if not visiting all actions at the root of a search tree. To address this issue, we propose a policy improvement algorithm based on sampling actions without replacement. Furthermore, we use the idea of policy improvement to replace the more heuristic mechanisms by which AlphaZero selects and uses actions, both at root nodes and at non-root nodes. Our new algorithms, Gumbel AlphaZero and Gumbel MuZero, respectively without and with model-learning, match the state of the art on Go, chess, and Atari, and significantly improve prior performance when planning with few simulations.",
        "conference": "ICLR",
        "中文标题": "通过使用Gumbel规划改进策略",
        "摘要翻译": "AlphaZero是一种基于近似策略迭代和树搜索的强大强化学习算法。然而，如果在搜索树的根节点未访问所有动作，AlphaZero可能无法改进其策略网络。为了解决这个问题，我们提出了一种基于无放回动作采样的策略改进算法。此外，我们利用策略改进的思想取代了AlphaZero在根节点和非根节点选择和动作使用的更启发式机制。我们的新算法，Gumbel AlphaZero和Gumbel MuZero，分别在不使用和使用模型学习的情况下，在围棋、国际象棋和Atari上达到了最先进的水平，并在少量模拟规划时显著提高了先前的性能。",
        "领域": "强化学习, 游戏AI, 策略优化",
        "问题": "解决AlphaZero在搜索树根节点未访问所有动作时无法改进策略网络的问题",
        "动机": "改进AlphaZero的策略网络性能，特别是在少量模拟规划的情况下",
        "方法": "提出基于无放回动作采样的策略改进算法，并利用策略改进思想优化动作选择和使用的启发式机制",
        "关键词": [
            "Gumbel AlphaZero",
            "策略改进",
            "无放回采样",
            "强化学习",
            "树搜索"
        ],
        "涉及的技术概念": {
            "近似策略迭代": "用于强化学习中的策略优化，通过迭代改进策略来逼近最优策略",
            "树搜索": "在决策过程中使用树结构来探索可能的动作序列，以找到最优策略",
            "无放回采样": "一种采样方法，确保每个动作在采样过程中只被选择一次，用于策略改进"
        },
        "success": true
    },
    {
        "order": 780,
        "title": "Policy Smoothing for Provably Robust Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6719",
        "abstract": "The study of provable adversarial robustness for deep neural networks (DNNs) has mainly focused on $\\textit{static}$ supervised learning tasks such as image classification. However, DNNs have been used extensively in real-world $\\textit{adaptive}$ tasks such as reinforcement learning (RL), making such systems vulnerable to adversarial attacks as well. Prior works in provable robustness in RL seek to certify the behaviour of the victim policy at every time-step against a non-adaptive adversary using methods developed for the static setting. But in the real world, an RL adversary can infer the defense strategy used by the victim agent by observing the states, actions, etc. from previous time-steps and adapt itself to produce stronger attacks in future steps (e.g., by focusing more on states critical to the agent's performance). We present an efficient procedure, designed specifically to defend against an adaptive RL adversary, that can directly certify the total reward without requiring the policy to be robust at each time-step. Focusing on randomized smoothing based defenses, our main theoretical contribution is to prove an $\\textit{adaptive version}$ of the Neyman-Pearson Lemma -- a key lemma for smoothing-based certificates -- where the adversarial perturbation at a particular time can be a stochastic function of current and previous observations and states as well as previous actions. Building on this result, we propose $\\textit{policy smoothing}$ where the agent adds a Gaussian noise to its observation at each time-step before passing it through the policy function. Our robustness certificates guarantee that the final total reward obtained by policy smoothing remains above a certain threshold, even though the actions at intermediate time-steps may change under the attack. We show that our certificates are $\\textit{tight}$ by constructing a worst-case scenario that achieves the bounds derived in our analysis. Our experiments on various environments like Cartpole, Pong, Freeway and Mountain Car show that our method can yield meaningful robustness guarantees in practice.",
        "conference": "ICLR",
        "中文标题": "策略平滑用于可证明鲁棒的强化学习",
        "摘要翻译": "深度神经网络（DNNs）的可证明对抗鲁棒性研究主要集中在静态监督学习任务上，如图像分类。然而，DNNs在现实世界的自适应任务中，如强化学习（RL），被广泛使用，这使得这些系统同样容易受到对抗攻击。先前关于RL中可证明鲁棒性的工作试图通过为静态设置开发的方法，在每一个时间步证明受害者策略对非自适应对手的行为。但在现实世界中，RL对手可以通过观察之前时间步的状态、动作等来推断受害者代理使用的防御策略，并适应自己以在未来步骤中产生更强的攻击（例如，更多地关注对代理性能至关重要的状态）。我们提出了一种专门设计用于防御自适应RL对手的高效程序，该程序可以直接证明总奖励，而不要求策略在每个时间步都是鲁棒的。专注于基于随机平滑的防御，我们的主要理论贡献是证明了Neyman-Pearson引理的一个自适应版本——这是基于平滑的证书的关键引理——其中特定时间的对抗扰动可以是当前和之前的观察、状态以及之前动作的随机函数。基于这一结果，我们提出了策略平滑，其中代理在每个时间步将其观察通过高斯噪声添加到策略函数之前。我们的鲁棒性证书保证，即使中间时间步的动作在攻击下可能改变，通过策略平滑获得的最终总奖励仍保持在某个阈值以上。我们通过构建一个达到我们分析中得出的界限的最坏情况场景，展示了我们的证书是紧密的。我们在Cartpole、Pong、Freeway和Mountain Car等各种环境上的实验表明，我们的方法在实践中可以产生有意义的鲁棒性保证。",
        "领域": "强化学习安全、对抗性鲁棒性、自适应防御策略",
        "问题": "如何在强化学习中提供可证明的对抗鲁棒性，特别是在面对能够适应并学习防御策略的自适应对手时。",
        "动机": "现有的可证明对抗鲁棒性研究主要集中在静态任务上，而强化学习作为一种自适应任务，其对抗鲁棒性研究相对不足，特别是在面对能够适应并学习防御策略的自适应对手时。",
        "方法": "提出了一种基于随机平滑的防御方法，通过在每个时间步向观察添加高斯噪声，并证明了一个自适应版本的Neyman-Pearson引理，以提供对总奖励的鲁棒性保证。",
        "关键词": [
            "强化学习",
            "对抗鲁棒性",
            "策略平滑",
            "自适应防御",
            "Neyman-Pearson引理"
        ],
        "涉及的技术概念": {
            "策略平滑": "在每个时间步向观察添加高斯噪声，以防御自适应对手的攻击。",
            "Neyman-Pearson引理的自适应版本": "扩展了传统的Neyman-Pearson引理，使其适用于能够根据历史观察和动作自适应调整攻击策略的对手。",
            "对抗鲁棒性证书": "提供了一种方法来证明，即使在面对自适应对手的攻击时，强化学习代理的总奖励也能保持在一定的阈值以上。"
        },
        "success": true
    },
    {
        "order": 781,
        "title": "PolyLoss: A Polynomial Expansion Perspective of Classification Loss Functions",
        "html": "https://iclr.cc//virtual/2022/poster/6089",
        "abstract": "Cross-entropy loss and focal loss are the most common choices when training deep neural networks for classification problems. Generally speaking, however, a good loss function can take on much more flexible forms, and should be tailored for different tasks and datasets. Motivated by how functions can be approximated via Taylor expansion, we propose a simple framework, named PolyLoss, to view and design loss functions as a linear combination of polynomial functions. Our PolyLoss allows the importance of different polynomial bases to be easily adjusted depending on the targeting tasks and datasets, while naturally subsuming the aforementioned cross-entropy loss and focal loss as special cases. Extensive experimental results show that the optimal choice within the PolyLoss is indeed dependent on the task and dataset. Simply by introducing one extra hyperparameter and adding one line of code, our Poly-1 formulation outperforms the cross-entropy loss and focal loss on 2D image classification, instance segmentation, object detection, and 3D object detection tasks, sometimes by a large margin.",
        "conference": "ICLR",
        "中文标题": "PolyLoss：分类损失函数的多项式展开视角",
        "摘要翻译": "交叉熵损失和焦点损失是训练深度神经网络解决分类问题时最常用的选择。然而，一般而言，一个好的损失函数可以采取更加灵活的形式，并且应该针对不同的任务和数据集进行定制。受到函数可以通过泰勒展开近似这一思想的启发，我们提出了一个简单的框架，名为PolyLoss，将损失函数视为多项式函数的线性组合来设计和看待。我们的PolyLoss允许根据不同任务和数据集的需求轻松调整不同多项式基的重要性，同时自然地将上述交叉熵损失和焦点损失作为特例包含在内。大量的实验结果表明，在PolyLoss中的最优选择确实依赖于任务和数据集。仅通过引入一个额外的超参数和添加一行代码，我们的Poly-1公式在2D图像分类、实例分割、目标检测和3D目标检测任务上的表现就超过了交叉熵损失和焦点损失，有时优势显著。",
        "领域": "深度学习优化、图像分类、目标检测",
        "问题": "如何设计更灵活、适应性更强的分类损失函数以适应不同的任务和数据集。",
        "动机": "受到泰勒展开近似函数的启发，探索损失函数设计的新视角，以提高模型在不同任务和数据集上的性能。",
        "方法": "提出PolyLoss框架，将损失函数设计为多项式函数的线性组合，允许根据不同任务和数据集调整多项式基的重要性。",
        "关键词": [
            "PolyLoss",
            "分类损失函数",
            "多项式展开",
            "深度学习优化",
            "目标检测"
        ],
        "涉及的技术概念": {
            "PolyLoss": "一个将损失函数视为多项式函数线性组合的框架，允许灵活调整以适应不同任务和数据集。",
            "泰勒展开": "用于近似函数的方法，为PolyLoss框架提供了理论基础。",
            "交叉熵损失和焦点损失": "两种常见的分类损失函数，被PolyLoss框架作为特例包含。"
        },
        "success": true
    },
    {
        "order": 782,
        "title": "PoNet: Pooling Network for Efficient Token Mixing in Long Sequences",
        "html": "https://iclr.cc//virtual/2022/poster/6219",
        "abstract": "Transformer-based models have achieved great success in various NLP, vision, and speech tasks. However, the core of Transformer, the self-attention mechanism, has a quadratic time and memory complexity with respect to the sequence length, which hinders applications of Transformer-based models to long sequences. Many approaches have been proposed to mitigate this problem, such as sparse attention mechanisms, low-rank matrix approximations and scalable kernels, and token mixing alternatives to self-attention. We propose a novel Pooling Network (PoNet) for token mixing in long sequences with linear complexity. We design multi-granularity pooling and pooling fusion to capture different levels of contextual information and combine their interactions with tokens. On the Long Range Arena benchmark, PoNet significantly outperforms Transformer and achieves competitive accuracy, while being only slightly slower than the fastest model, FNet, across all sequence lengths measured on GPUs. We also conduct systematic studies on the transfer learning capability of PoNet and observe that PoNet achieves 95.7 percent of the accuracy of BERT on the GLUE benchmark, outperforming FNet by 4.5 percent relative. Comprehensive ablation analysis demonstrates effectiveness of the designed multi-granularity pooling and pooling fusion for token mixing in long sequences and efficacy of the designed pre-training tasks for PoNet to learn transferable contextualized language representations.",
        "conference": "ICLR",
        "中文标题": "PoNet: 用于长序列中高效令牌混合的池化网络",
        "摘要翻译": "基于Transformer的模型在各种NLP、视觉和语音任务中取得了巨大成功。然而，Transformer的核心——自注意力机制，其时间和内存复杂度与序列长度成二次方关系，这阻碍了基于Transformer的模型在长序列中的应用。已经提出了许多方法来缓解这个问题，如稀疏注意力机制、低秩矩阵近似和可扩展核，以及自注意力的令牌混合替代方案。我们提出了一种新颖的池化网络（PoNet），用于长序列中的令牌混合，具有线性复杂度。我们设计了多粒度池化和池化融合，以捕获不同级别的上下文信息，并将它们与令牌的交互结合起来。在Long Range Arena基准测试中，PoNet显著优于Transformer，并达到了竞争性的准确度，同时在GPU上测量的所有序列长度上仅比最快的模型FNet稍慢。我们还对PoNet的迁移学习能力进行了系统研究，观察到PoNet在GLUE基准测试中达到了BERT准确度的95.7%，相对FNet高出4.5%。全面的消融分析证明了设计的多粒度池化和池化融合在长序列令牌混合中的有效性，以及为PoNet设计的预训练任务学习可迁移的上下文化语言表示的效果。",
        "领域": "自然语言处理与视觉结合",
        "问题": "解决Transformer模型在处理长序列时因自注意力机制的二次复杂度而导致的高计算资源消耗问题",
        "动机": "为了降低Transformer模型在处理长序列时的计算复杂度，同时保持或提高模型性能",
        "方法": "提出了一种名为PoNet的池化网络，采用多粒度池化和池化融合技术，以实现线性复杂度的令牌混合",
        "关键词": [
            "池化网络",
            "令牌混合",
            "长序列处理",
            "线性复杂度",
            "迁移学习"
        ],
        "涉及的技术概念": {
            "多粒度池化": "用于捕获不同级别的上下文信息，提高模型对长序列的理解能力",
            "池化融合": "结合不同粒度池化的交互信息，优化令牌混合的效果",
            "线性复杂度": "确保模型在处理长序列时的计算效率，解决传统Transformer模型的二次复杂度问题"
        },
        "success": true
    },
    {
        "order": 783,
        "title": "Possibility Before Utility: Learning And Using Hierarchical Affordances",
        "html": "https://iclr.cc//virtual/2022/poster/6681",
        "abstract": "Reinforcement learning algorithms struggle on tasks with complex hierarchical dependency structures. Humans and other intelligent agents do not waste time assessing the utility of every high-level action in existence, but instead only consider ones they deem possible in the first place. By focusing only on what is feasible, or 'afforded'', at the present moment, an agent can spend more time both evaluating the utility of and acting on what matters. To this end, we present Hierarchical Affordance Learning (HAL), a method that learns a model of hierarchical affordances in order to prune impossible subtasks for more effective learning. Existing works in hierarchical reinforcement learning provide agents with structural representations of subtasks but are not affordance-aware, and by grounding our definition of hierarchical affordances in the present state, our approach is more flexible than the multitude of approaches that ground their subtask dependencies in a symbolic history. While these logic-based methods often require complete knowledge of the subtask hierarchy, our approach is able to utilize incomplete and varying symbolic specifications. Furthermore, we demonstrate that relative to non-affordance-aware methods, HAL agents are better able to efficiently learn complex tasks, navigate environment stochasticity, and acquire diverse skills in the absence of extrinsic supervision---all of which are hallmarks of human learning.",
        "conference": "ICLR",
        "中文标题": "可能性先于效用：学习与使用层次化可供性",
        "摘要翻译": "强化学习算法在处理具有复杂层次依赖结构的任务时面临困难。人类和其他智能体不会浪费时间评估每一个存在的高层次行动的效用，而是首先只考虑他们认为可能的行为。通过仅关注当前时刻可行的或'可供'的行为，智能体可以将更多时间用于评估重要行为的效用并采取行动。为此，我们提出了层次化可供性学习（HAL），一种学习层次化可供性模型以剪枝不可能的子任务从而实现更有效学习的方法。现有的层次化强化学习工作为智能体提供了子任务的结构表示，但并不具备可供性意识，而通过将我们对层次化可供性的定义基于当前状态，我们的方法比那些将子任务依赖基于符号历史的多种方法更加灵活。这些基于逻辑的方法通常需要完全了解子任务层次结构，而我们的方法能够利用不完整和变化的符号规范。此外，我们证明，相对于不具备可供性意识的方法，HAL智能体能够更有效地学习复杂任务、导航环境随机性，并在缺乏外部监督的情况下获取多样化的技能——这些都是人类学习的标志。",
        "领域": "层次化强化学习",
        "问题": "强化学习在处理具有复杂层次依赖结构的任务时的效率问题",
        "动机": "提高智能体在处理复杂任务时的学习效率和适应性，模仿人类学习的高效性",
        "方法": "提出层次化可供性学习（HAL），通过学习层次化可供性模型来剪枝不可能的子任务，以提高学习效率",
        "关键词": [
            "层次化强化学习",
            "可供性学习",
            "子任务剪枝"
        ],
        "涉及的技术概念": {
            "层次化可供性": "基于当前状态定义的行为可行性，用于指导智能体选择可能的子任务",
            "子任务剪枝": "通过评估子任务的可行性来排除不可能的子任务，优化学习过程",
            "符号规范": "用于描述任务层次结构的不完整和变化的符号表示，HAL方法能够灵活处理"
        },
        "success": true
    },
    {
        "order": 784,
        "title": "Post hoc Explanations may be Ineffective for Detecting Unknown Spurious Correlation",
        "html": "https://iclr.cc//virtual/2022/poster/6565",
        "abstract": "We investigate whether three types of post hoc model explanations--feature attribution, concept activation, and training point ranking--are effective for detecting a model's reliance on spurious signals in the training data. Specifically, we consider the scenario where the spurious signal to be detected is unknown, at test-time, to the user of the explanation method. We design an empirical methodology that uses semi-synthetic datasets along with pre-specified spurious artifacts to obtain models that verifiably rely on these spurious training signals. We then provide a suite of metrics that assess an explanation method's reliability for spurious signal detection under various conditions. We find that the post hoc explanation methods tested are ineffective when the spurious artifact is unknown at test-time especially for non-visible artefacts like a background blur. Further, we find that feature attribution methods are susceptible to erroneously indicating dependence on spurious signals even when the model being explained does not rely on spurious artefacts. This finding casts doubt on the utility of these approaches, in the hands of a practitioner, for detecting a model's reliance on spurious signals.",
        "conference": "ICLR",
        "中文标题": "事后解释可能无法有效检测未知的虚假相关性",
        "摘要翻译": "我们研究了三种类型的事后模型解释——特征归因、概念激活和训练点排名——是否有效于检测模型对训练数据中虚假信号的依赖。具体而言，我们考虑了这样一种场景：在测试时，解释方法的用户不知道要检测的虚假信号。我们设计了一种实证方法，该方法使用半合成数据集和预先指定的虚假伪影来获得可验证依赖这些虚假训练信号的模型。然后，我们提供了一套指标，用于评估解释方法在不同条件下对虚假信号检测的可靠性。我们发现，当虚假伪影在测试时未知时，尤其是对于像背景模糊这样的非可见伪影，测试的事后解释方法无效。此外，我们发现特征归因方法容易错误地指示对虚假信号的依赖，即使被解释的模型并不依赖虚假伪影。这一发现让人怀疑这些方法在实践者手中用于检测模型对虚假信号依赖的效用。",
        "领域": "模型解释性、虚假相关性检测、深度学习可靠性",
        "问题": "检测模型是否依赖训练数据中的虚假信号",
        "动机": "评估事后解释方法在检测模型依赖未知虚假信号时的有效性",
        "方法": "使用半合成数据集和预先指定的虚假伪影设计实证方法，评估三种事后解释方法的有效性",
        "关键词": [
            "事后解释",
            "虚假相关性",
            "模型可靠性",
            "特征归因",
            "概念激活"
        ],
        "涉及的技术概念": {
            "特征归因": "用于识别模型决策中最重要的输入特征的技术",
            "概念激活": "通过激活特定概念来解释模型行为的方法",
            "训练点排名": "根据训练数据点对模型预测的影响进行排名的技术"
        },
        "success": true
    },
    {
        "order": 785,
        "title": "Post-Training Detection of Backdoor Attacks for Two-Class and Multi-Attack Scenarios",
        "html": "https://iclr.cc//virtual/2022/poster/7149",
        "abstract": "Backdoor attacks (BAs) are an emerging threat to deep neural network classifiers. A victim classifier will predict to an attacker-desired target class whenever a test sample is embedded with the same backdoor pattern (BP) that was used to poison the classifier's training set. Detecting whether a classifier is backdoor attacked is not easy in practice, especially when the defender is, e.g., a downstream user without access to the classifier's training set. This challenge is addressed here by a reverse-engineering defense (RED), which has been shown to yield state-of-the-art performance in several domains. However, existing REDs are not applicable when there are only two classes or when multiple attacks are present. These scenarios are first studied in the current paper, under the practical constraints that the defender neither has access to the classifier's training set nor to supervision from clean reference classifiers trained for the same domain. We propose a detection framework based on BP reverse-engineering and a novel expected transferability (ET) statistic. We show that our ET statistic is effective using the same detection threshold, irrespective of the classification domain, the attack configuration, and the BP reverse-engineering algorithm that is used. The excellent performance of our method is demonstrated on six benchmark datasets. Notably, our detection framework is also applicable to multi-class scenarios with multiple attacks. Code is available at https://github.com/zhenxianglance/2ClassBADetection.",
        "conference": "ICLR",
        "中文标题": "后训练检测两类和多攻击场景下的后门攻击",
        "摘要翻译": "后门攻击（BAs）是对深度神经网络分类器的新兴威胁。每当测试样本嵌入了与污染分类器训练集相同的后门模式（BP）时，受害分类器就会预测到攻击者期望的目标类别。在实际中，检测分类器是否受到后门攻击并不容易，特别是当防御者（如下游用户）无法访问分类器的训练集时。本文通过一种逆向工程防御（RED）方法解决了这一挑战，该方法已在多个领域显示出最先进的性能。然而，现有的RED方法在只有两类或存在多攻击时不适用。本文首次研究了这些场景，在防御者既无法访问分类器的训练集，也无法获得来自同一领域训练的干净参考分类器的监督的实际约束下。我们提出了一个基于BP逆向工程和新颖的预期可转移性（ET）统计量的检测框架。我们展示了我们的ET统计量在使用相同的检测阈值时是有效的，无论分类领域、攻击配置和使用的BP逆向工程算法如何。我们的方法在六个基准数据集上展示了卓越的性能。值得注意的是，我们的检测框架也适用于多类场景下的多攻击检测。代码可在https://github.com/zhenxianglance/2ClassBADetection获取。",
        "领域": "深度学习安全、后门攻击检测、神经网络防御",
        "问题": "在两类和多攻击场景下，如何有效检测深度神经网络分类器是否受到后门攻击。",
        "动机": "现有的逆向工程防御方法在两类或多攻击场景下不适用，且防御者通常无法访问训练集或干净的参考分类器，因此需要开发新的检测方法。",
        "方法": "提出基于后门模式逆向工程和预期可转移性统计量的检测框架，适用于不同领域、攻击配置和逆向工程算法。",
        "关键词": [
            "后门攻击检测",
            "逆向工程防御",
            "预期可转移性",
            "两类场景",
            "多攻击检测"
        ],
        "涉及的技术概念": {
            "后门攻击（BAs）": "一种通过在训练数据中植入特定模式（后门模式）来操纵模型预测的攻击方式。",
            "逆向工程防御（RED）": "通过逆向工程方法识别和防御后门攻击的技术。",
            "预期可转移性（ET）统计量": "一种新颖的统计量，用于评估后门模式的可转移性，有效检测后门攻击。"
        },
        "success": true
    },
    {
        "order": 786,
        "title": "Practical Conditional Neural Process Via Tractable Dependent Predictions",
        "html": "https://iclr.cc//virtual/2022/poster/6738",
        "abstract": "Conditional Neural Processes (CNPs; Garnelo et al., 2018a) are meta-learning models which leverage the flexibility of deep learning to produce well-calibrated predictions and naturally handle off-the-grid and missing data. CNPs scale to large datasets and train with ease. Due to these features, CNPs appear well-suited to tasks from environmental sciences or healthcare. Unfortunately, CNPs do not produce correlated predictions, making them fundamentally inappropriate for many estimation and decision making tasks. Predicting heat waves or floods, for example, requires modelling dependencies in temperature or precipitation over time and space. Existing approaches which model output dependencies, such as Neural Processes (NPs; Garnelo et al., 2018b) or the FullConvGNP (Bruinsma et al., 2021), are either complicated to train or prohibitively expensive. What is needed is an approach which provides dependent predictions, but is simple to train and computationally tractable. In this work, we present a new class of Neural Process models that make correlated predictions and support exact maximum likelihood training that is simple and scalable. We extend the proposed models by using invertible output transformations, to capture non-Gaussian output distributions. Our models can be used in downstream estimation tasks which require dependent function samples. By accounting for output dependencies, our models show improved predictive performance on a range of experiments with synthetic and real data.",
        "conference": "ICLR",
        "中文标题": "通过可处理的依赖预测实现实用的条件神经过程",
        "摘要翻译": "条件神经过程（CNPs；Garnelo等人，2018a）是一种元学习模型，它利用深度学习的灵活性来产生校准良好的预测，并自然地处理离网和缺失数据。CNPs能够扩展到大型数据集并且易于训练。由于这些特点，CNPs似乎非常适合环境科学或医疗保健领域的任务。然而，CNPs不会产生相关的预测，这使得它们从根本上不适合许多估计和决策制定任务。例如，预测热浪或洪水需要模拟温度或降水在时间和空间上的依赖性。现有的模拟输出依赖性的方法，如神经过程（NPs；Garnelo等人，2018b）或FullConvGNP（Bruinsma等人，2021），要么训练复杂，要么计算成本过高。我们需要一种方法，既能提供依赖预测，又简单易训练且计算上可处理。在这项工作中，我们提出了一类新的神经过程模型，这些模型能够做出相关预测，并支持简单且可扩展的精确最大似然训练。我们通过使用可逆输出变换来扩展所提出的模型，以捕捉非高斯输出分布。我们的模型可以用于需要依赖函数样本的下游估计任务。通过考虑输出依赖性，我们的模型在一系列合成和真实数据的实验中显示出改进的预测性能。",
        "领域": "元学习、环境科学数据分析、医疗保健数据分析",
        "问题": "条件神经过程（CNPs）无法产生相关的预测，限制了其在需要依赖预测的估计和决策任务中的应用。",
        "动机": "开发一种既能够提供依赖预测，又简单易训练且计算上可处理的神经过程模型，以扩展CNPs在环境科学和医疗保健等领域的应用。",
        "方法": "提出了一类新的神经过程模型，支持相关预测和精确最大似然训练，并通过可逆输出变换捕捉非高斯输出分布。",
        "关键词": [
            "条件神经过程",
            "依赖预测",
            "最大似然训练",
            "可逆输出变换",
            "非高斯分布"
        ],
        "涉及的技术概念": {
            "条件神经过程（CNPs）": "一种元学习模型，利用深度学习的灵活性进行预测，适用于处理离网和缺失数据。",
            "依赖预测": "模型能够产生在时间或空间上相关的预测，适用于需要模拟依赖性的任务。",
            "可逆输出变换": "用于扩展模型以捕捉非高斯输出分布的技术，增强模型的适用性和灵活性。"
        },
        "success": true
    },
    {
        "order": 787,
        "title": "Practical Integration via Separable Bijective Networks",
        "html": "https://iclr.cc//virtual/2022/poster/5958",
        "abstract": "Neural networks have enabled learning over examples that contain thousands of dimensions.However, most of these models are limited to training and evaluating on a finite collection of \\textit{points} and do not consider the hypervolume in which the data resides.Any analysis of the model's local or global behavior is therefore limited to very expensive or imprecise estimators.We propose to formulate neural networks as a composition of a bijective (flow) network followed by a learnable, separable network.This construction allows for learning (or assessing) over full hypervolumes with precise estimators at tractable computational cost via integration over the \\textit{input space}.We develop the necessary machinery, propose several practical integrals to use during training, and demonstrate their utility.",
        "conference": "ICLR",
        "中文标题": "通过可分离双射网络实现实用集成",
        "摘要翻译": "神经网络已经能够学习包含数千维度的样本。然而，大多数这些模型仅限于在有限的点集合上进行训练和评估，并未考虑数据所在的超体积。因此，对模型局部或全局行为的任何分析都仅限于非常昂贵或不精确的估计器。我们提出将神经网络表述为一个双射（流）网络和一个可学习的可分离网络的组合。这种构造允许通过输入空间的集成，以可计算成本学习（或评估）完整的超体积，并使用精确的估计器。我们开发了必要的机制，提出了几种在训练中使用的实用积分，并展示了它们的效用。",
        "领域": "深度学习模型架构、神经网络优化、数据表示学习",
        "问题": "解决神经网络在处理高维数据时，对数据超体积的考虑不足以及模型行为分析成本高或精度低的问题。",
        "动机": "为了能够更有效地学习和评估高维数据中的完整超体积，同时降低计算成本和提高分析精度。",
        "方法": "提出了一种新的神经网络架构，该架构由双射网络和可分离网络组成，通过输入空间的集成来实现对高维数据的有效学习和评估。",
        "关键词": [
            "双射网络",
            "可分离网络",
            "高维数据",
            "模型评估",
            "输入空间集成"
        ],
        "涉及的技术概念": {
            "双射网络": "用于构建一个可逆的映射，使得数据可以在高维空间和潜在空间之间双向转换，便于数据的表示和分析。",
            "可分离网络": "通过将网络分解为可学习的部分，简化模型结构，降低计算复杂度，同时保持或提高模型的表达能力。",
            "输入空间集成": "通过在输入空间进行积分，实现对高维数据完整超体积的精确评估，提高模型分析的准确性和效率。"
        },
        "success": true
    },
    {
        "order": 788,
        "title": "Predicting Physics in Mesh-reduced Space with Temporal Attention",
        "html": "https://iclr.cc//virtual/2022/poster/6494",
        "abstract": "Auto-regressive sequence models for physics prediction are often restricted to low-dimensional systems, as memory cost increases with both spatial extents and sequence length. On the other hand, graph-based next-step prediction models have recently been very successful in modeling complex high-dimensional physical systems on irregular meshes, but suffer from error accumulation and drift, due to their short temporal attention span. In this paper, we present a method that marries the strengths of both approaches. We use a GNN to locally summarize features and create coarsened, compact mesh representation of the system state, onto which we apply a transformer-style temporal attention module. We use a second GNN to decode these predictions back to a full-sized graph and perform fine-scale updates. Our method outperforms a competitive GNN baseline on three complex fluid dynamics prediction tasks, from sonic shocks to vascular flow. We demonstrate stable rollouts without the need for training noise and show perfectly phase-stable predictions even for very long sequences. More broadly, we believe our approach paves the way to bringing the benefits of attention-based sequence models to solving high-dimensional complex physics tasks.",
        "conference": "ICLR",
        "中文标题": "在网格简化空间中使用时间注意力预测物理现象",
        "摘要翻译": "用于物理预测的自回归序列模型通常仅限于低维系统，因为内存成本随着空间范围和序列长度的增加而增加。另一方面，基于图的下一步预测模型最近在建模不规则网格上的复杂高维物理系统方面非常成功，但由于其短暂的时间注意力跨度，容易受到误差累积和漂移的影响。在本文中，我们提出了一种方法，结合了这两种方法的优点。我们使用图神经网络（GNN）局部总结特征并创建系统状态的粗化、紧凑网格表示，然后应用变换器风格的时间注意力模块。我们使用第二个GNN将这些预测解码回全尺寸图并执行精细尺度的更新。我们的方法在三个复杂的流体动力学预测任务上优于竞争性的GNN基线，从声波冲击到血管流动。我们展示了无需训练噪声的稳定推出，并展示了即使对于非常长的序列也能实现完美的相位稳定预测。更广泛地说，我们相信我们的方法为将基于注意力的序列模型的优势带到解决高维复杂物理任务铺平了道路。",
        "领域": "流体动力学模拟, 图神经网络应用, 时间序列预测",
        "问题": "解决高维物理系统预测中的内存成本高和误差累积问题",
        "动机": "结合自回归序列模型和图神经网络的优势，提高高维复杂物理系统预测的准确性和稳定性",
        "方法": "使用GNN创建系统状态的紧凑表示，应用时间注意力模块进行预测，再通过第二个GNN进行精细更新",
        "关键词": [
            "图神经网络",
            "时间注意力",
            "流体动力学预测",
            "高维物理系统",
            "自回归模型"
        ],
        "涉及的技术概念": {
            "图神经网络（GNN）": "用于局部特征总结和系统状态的紧凑表示创建，以及预测结果的全尺寸图解码",
            "时间注意力模块": "变换器风格的模块，用于处理时间序列数据，提高长期依赖的捕捉能力",
            "自回归序列模型": "用于物理预测的传统方法，本文中通过结合GNN和时间注意力模块克服其在高维系统中的限制"
        },
        "success": true
    },
    {
        "order": 789,
        "title": "Pretrained Language Model in Continual Learning: A Comparative Study",
        "html": "https://iclr.cc//virtual/2022/poster/6154",
        "abstract": "Continual learning (CL) is a  setting in which a model learns from a stream of incoming data while avoiding to forget previously learned knowledge. Pre-trained language models (PLMs) have been successfully employed in continual learning of different natural language problems. With the rapid development of many continual learning methods and PLMs, understanding and disentangling their interactions become essential for continued improvement of continual learning performance. In this paper, we thoroughly compare the continual learning performance over the combination of 5 PLMs and 4 CL approaches on 3 benchmarks in 2 typical incremental settings. Our extensive experimental analyses reveal interesting performance differences across PLMs and across CL methods. Furthermore, our representativeness probing analyses dissect PLMs’ performance characteristics in a layer-wise and task-wise manner, uncovering the extent to which their inner layers suffer from forgetting, and the effect of different CL approaches on each layer. Finally, our observations and analyses open up a number of important research questions that will inform and guide the design of effective continual learning techniques.",
        "conference": "ICLR",
        "中文标题": "预训练语言模型在持续学习中的比较研究",
        "摘要翻译": "持续学习（CL）是一种模型从不断流入的数据中学习，同时避免遗忘先前学到的知识的学习设置。预训练语言模型（PLMs）已成功应用于不同自然语言问题的持续学习中。随着许多持续学习方法和PLMs的快速发展，理解和解析它们之间的互动对于持续学习性能的持续提升变得至关重要。在本文中，我们全面比较了在两种典型的增量设置下，5种PLMs和4种CL方法在3个基准测试上的持续学习性能。我们广泛的实验分析揭示了PLMs和CL方法之间有趣的性能差异。此外，我们的代表性探测分析以分层和任务方式剖析了PLMs的性能特征，揭示了它们内部层遭受遗忘的程度，以及不同CL方法对每一层的影响。最后，我们的观察和分析提出了一系列重要的研究问题，这些问题将为设计有效的持续学习技术提供信息和指导。",
        "领域": "自然语言处理与视觉结合, 持续学习, 预训练语言模型",
        "问题": "比较不同预训练语言模型和持续学习方法在持续学习任务中的性能差异",
        "动机": "理解和解析预训练语言模型与持续学习方法之间的互动，以提升持续学习性能",
        "方法": "通过广泛的实验分析比较5种预训练语言模型和4种持续学习方法在3个基准测试上的性能，并进行代表性探测分析",
        "关键词": [
            "持续学习",
            "预训练语言模型",
            "性能比较",
            "自然语言处理",
            "增量学习"
        ],
        "涉及的技术概念": {
            "持续学习（CL）": "一种模型从不断流入的数据中学习，同时避免遗忘先前学到的知识的学习设置",
            "预训练语言模型（PLMs）": "已成功应用于不同自然语言问题的持续学习中的模型",
            "代表性探测分析": "以分层和任务方式剖析模型性能特征，揭示内部层遭受遗忘的程度及不同方法对每一层的影响"
        },
        "success": true
    },
    {
        "order": 790,
        "title": "Pre-training Molecular Graph Representation with 3D Geometry",
        "html": "https://iclr.cc//virtual/2022/poster/6888",
        "abstract": "Molecular graph representation learning is a fundamental problem in modern drug and material discovery. Molecular graphs are typically modeled by their 2D topological structures, but it has been recently discovered that 3D geometric information plays a more vital role in predicting molecular functionalities. However, the lack of 3D information in real-world scenarios has significantly impeded the learning of geometric graph representation. To cope with this challenge, we propose the Graph Multi-View Pre-training (GraphMVP) framework where self-supervised learning (SSL) is performed by leveraging the correspondence and consistency between 2D topological structures and 3D geometric views. GraphMVP effectively learns a 2D molecular graph encoder that is enhanced by richer and more discriminative 3D geometry. We further provide theoretical insights to justify the effectiveness of GraphMVP. Finally, comprehensive experiments show that GraphMVP can consistently outperform existing graph SSL methods. Code is available on GitHub: https://github.com/chao1224/GraphMVP.",
        "conference": "ICLR",
        "中文标题": "预训练分子图表示与3D几何",
        "摘要翻译": "分子图表示学习是现代药物和材料发现中的一个基本问题。分子图通常通过其2D拓扑结构建模，但最近发现3D几何信息在预测分子功能方面起着更为关键的作用。然而，现实场景中3D信息的缺乏极大地阻碍了几何图表示的学习。为了应对这一挑战，我们提出了图多视图预训练（GraphMVP）框架，其中通过利用2D拓扑结构和3D几何视图之间的对应性和一致性进行自监督学习（SSL）。GraphMVP有效地学习了一个2D分子图编码器，该编码器通过更丰富和更具区分性的3D几何得到增强。我们进一步提供了理论见解以证明GraphMVP的有效性。最后，全面的实验表明，GraphMVP能够持续优于现有的图SSL方法。代码可在GitHub上获取：https://github.com/chao1224/GraphMVP。",
        "领域": "分子图表示学习、药物发现、材料科学",
        "问题": "解决在缺乏3D几何信息的情况下，如何有效学习分子图的几何表示问题。",
        "动机": "认识到3D几何信息在预测分子功能中的重要性，但现实中3D信息的缺乏限制了分子图表示学习的发展。",
        "方法": "提出GraphMVP框架，通过自监督学习利用2D拓扑结构和3D几何视图之间的对应性和一致性，增强2D分子图编码器的学习。",
        "关键词": [
            "分子图表示学习",
            "3D几何",
            "自监督学习",
            "药物发现",
            "材料科学"
        ],
        "涉及的技术概念": {
            "自监督学习（SSL）": "在缺乏大量标注数据的情况下，通过设计预测任务从数据本身生成监督信号来训练模型。",
            "分子图编码器": "将分子图的结构信息转换为向量表示，便于后续的预测和分析任务。",
            "3D几何视图": "分子在三维空间中的几何排列和结构信息，对于理解分子的物理和化学性质至关重要。"
        },
        "success": true
    },
    {
        "order": 791,
        "title": "Pretraining Text Encoders with Adversarial Mixture of Training Signal Generators",
        "html": "https://iclr.cc//virtual/2022/poster/6049",
        "abstract": "We present a new framework AMOS that pretrains text encoders with an Adversarial learning curriculum via a Mixture Of Signals from multiple auxiliary generators. Following ELECTRA-style pretraining, the main encoder is trained as a discriminator to detect replaced tokens generated by auxiliary masked language models (MLMs). Different from ELECTRA which trains one MLM as the generator, we jointly train multiple MLMs of different sizes to provide training signals at various levels of difficulty. To push the discriminator to learn better with challenging replaced tokens, we learn mixture weights over the auxiliary MLMs' outputs to maximize the discriminator loss by backpropagating the gradient from the discriminator via Gumbel-Softmax. For better pretraining efficiency, we propose a way to assemble multiple MLMs into one unified auxiliary model. AMOS outperforms ELECTRA and recent state-of-the-art pretrained models by about 1 point on the GLUE benchmark for BERT base-sized models.",
        "conference": "ICLR",
        "中文标题": "使用对抗性混合训练信号生成器预训练文本编码器",
        "摘要翻译": "我们提出了一个新的框架AMOS，该框架通过来自多个辅助生成器的混合信号，采用对抗性学习课程来预训练文本编码器。遵循ELECTRA风格的预训练，主编码器被训练为一个判别器，以检测由辅助掩码语言模型（MLMs）生成的替换标记。与ELECTRA训练一个MLM作为生成器不同，我们联合训练了不同大小的多个MLMs，以提供不同难度级别的训练信号。为了推动判别器更好地学习具有挑战性的替换标记，我们通过学习辅助MLMs输出的混合权重，通过Gumbel-Softmax从判别器反向传播梯度，以最大化判别器损失。为了提高预训练效率，我们提出了一种将多个MLMs组装成一个统一辅助模型的方法。AMOS在GLUE基准测试中，对于BERT基础大小的模型，比ELECTRA和最近的最先进预训练模型高出约1个百分点。",
        "领域": "自然语言处理与视觉结合、文本表示学习、预训练语言模型",
        "问题": "如何通过多源训练信号提升文本编码器的预训练效果",
        "动机": "探索更高效的文本编码器预训练方法，通过多源和对抗性学习提升模型性能",
        "方法": "采用对抗性学习课程和多辅助生成器的混合信号进行预训练，通过Gumbel-Softmax优化混合权重",
        "关键词": [
            "对抗性学习",
            "文本编码器预训练",
            "混合信号",
            "Gumbel-Softmax",
            "ELECTRA"
        ],
        "涉及的技术概念": {
            "对抗性学习": "用于通过最大化判别器损失来提升模型对挑战性样本的学习能力",
            "混合信号": "来自不同难度级别的辅助生成器的信号，用于提供多样化的训练数据",
            "Gumbel-Softmax": "一种允许梯度通过离散决策的技术，用于优化混合权重"
        },
        "success": true
    },
    {
        "order": 792,
        "title": "PriorGrad: Improving Conditional Denoising Diffusion Models with Data-Dependent Adaptive Prior",
        "html": "https://iclr.cc//virtual/2022/poster/6445",
        "abstract": "Denoising diffusion probabilistic models have been recently proposed to generate high-quality samples by estimating the gradient of the data density. The framework assumes the prior noise as a standard Gaussian distribution, whereas the corresponding data distribution may be more complicated than the standard Gaussian distribution, which potentially introduces inefficiency in denoising the prior noise into the data sample because of the discrepancy between the data and the prior. In this paper, we propose PriorGrad to improve the efficiency of the conditional diffusion model (for example, a vocoder using a mel-spectrogram as the condition) by applying an adaptive prior derived from the data statistics based on the conditional information. We formulate the training and sampling procedures of PriorGrad and demonstrate the advantages of an adaptive prior through a theoretical analysis. Focusing on the audio domain, we consider the recently proposed diffusion-based audio generative models based on both the spectral and time domains and show that PriorGrad achieves faster convergence and superior performance, leading to an improved perceptual quality and tolerance to a smaller network capacity, and thereby demonstrating the efficiency of a data-dependent adaptive prior.",
        "conference": "ICLR",
        "中文标题": "PriorGrad：通过数据依赖的自适应先验改进条件去噪扩散模型",
        "摘要翻译": "去噪扩散概率模型最近被提出用于通过估计数据密度的梯度来生成高质量样本。该框架假设先验噪声为标准高斯分布，而相应的数据分布可能比标准高斯分布更复杂，这由于数据与先验之间的差异，可能导致将先验噪声去噪为数据样本时的效率不高。在本文中，我们提出了PriorGrad，通过应用基于条件信息的数据统计得出的自适应先验，来提高条件扩散模型（例如，使用梅尔频谱图作为条件的声码器）的效率。我们制定了PriorGrad的训练和采样过程，并通过理论分析展示了自适应先验的优势。聚焦于音频领域，我们考虑了最近提出的基于频谱和时间域的扩散基音频生成模型，并表明PriorGrad实现了更快的收敛和卓越的性能，从而提高了感知质量和对较小网络容量的容忍度，进而证明了数据依赖的自适应先验的效率。",
        "领域": "音频生成、条件扩散模型、去噪扩散概率模型",
        "问题": "解决标准高斯先验与复杂数据分布之间的不匹配问题，提高条件扩散模型的去噪效率。",
        "动机": "由于标准高斯先验与复杂数据分布之间的差异，导致去噪效率不高，因此提出使用数据依赖的自适应先验来提高效率。",
        "方法": "提出PriorGrad方法，通过基于条件信息的数据统计得出自适应先验，改进条件扩散模型的训练和采样过程。",
        "关键词": [
            "PriorGrad",
            "条件扩散模型",
            "自适应先验",
            "音频生成",
            "去噪效率"
        ],
        "涉及的技术概念": {
            "去噪扩散概率模型": "一种通过估计数据密度的梯度来生成高质量样本的模型框架。",
            "自适应先验": "基于数据统计和条件信息动态调整的先验分布，用于提高模型的去噪效率。",
            "条件扩散模型": "一种利用条件信息（如梅尔频谱图）指导生成过程的扩散模型，适用于特定任务如音频生成。"
        },
        "success": true
    },
    {
        "order": 793,
        "title": "Privacy Implications of Shuffling",
        "html": "https://iclr.cc//virtual/2022/poster/6854",
        "abstract": "\\ldp deployments are vulnerable to inference attacks as an adversary can link the noisy responses to their identity and subsequently, auxiliary information using the \\textit{order} of the data. An alternative model, shuffle \\textsf{DP}, prevents this by shuffling the noisy responses uniformly at random.  However, this limits the data learnability -- only symmetric functions (input order agnostic) can be learned. In this paper, we strike a balance and show that systematic shuffling of the noisy responses can thwart specific inference attacks while retaining some meaningful data learnability. To this end, we propose a novel privacy guarantee, \\name-privacy, that captures the privacy of the order of a data sequence. \\name-privacy allows tuning the granularity at which the ordinal information is maintained, which formalizes the degree the resistance to inference attacks trading it off with data learnability.  Additionally, we propose a novel shuffling mechanism that can achieve \\name-privacy and demonstrate the practicality of our mechanism via evaluation on real-world datasets. ",
        "conference": "ICLR",
        "中文标题": "洗牌机制的隐私影响",
        "摘要翻译": "LDP部署容易受到推理攻击，因为攻击者可以将噪声响应与其身份以及使用数据顺序的辅助信息联系起来。另一种模型，洗牌DP，通过均匀随机地洗牌噪声响应来防止这种情况。然而，这限制了数据的可学习性——只能学习对称函数（输入顺序无关）。在本文中，我们找到了一个平衡点，并表明系统地洗牌噪声响应可以阻止特定的推理攻击，同时保留一些有意义的数据可学习性。为此，我们提出了一种新的隐私保证，名称隐私，它捕捉了数据序列顺序的隐私。名称隐私允许调整顺序信息维护的粒度，这形式化了抵抗推理攻击的程度，与数据可学习性进行权衡。此外，我们提出了一种新的洗牌机制，可以实现名称隐私，并通过在真实世界数据集上的评估展示了我们机制的实用性。",
        "领域": "隐私保护、数据安全、机器学习安全",
        "问题": "如何在保护数据顺序隐私的同时，保持数据的可学习性",
        "动机": "解决现有隐私保护模型在防止推理攻击和保持数据可学习性之间的不足",
        "方法": "提出了一种新的隐私保证名称隐私和一种新的洗牌机制，以在保护数据顺序隐私的同时保持数据的可学习性",
        "关键词": [
            "隐私保护",
            "洗牌机制",
            "数据可学习性",
            "推理攻击",
            "名称隐私"
        ],
        "涉及的技术概念": {
            "名称隐私": "一种新的隐私保证，用于捕捉和调整数据序列顺序的隐私保护级别",
            "洗牌机制": "通过系统地洗牌噪声响应来防止特定的推理攻击，同时保留数据可学习性的技术",
            "数据可学习性": "指在保护隐私的同时，数据仍可用于有效学习和分析的能力"
        },
        "success": true
    },
    {
        "order": 794,
        "title": "Probabilistic Implicit Scene Completion",
        "html": "https://iclr.cc//virtual/2022/poster/5910",
        "abstract": "We propose a probabilistic shape completion method extended to the continuous geometry of large-scale 3D scenes. Real-world scans of 3D scenes suffer from a considerable amount of missing data cluttered with unsegmented objects. The problem of shape completion is inherently ill-posed, and high-quality result requires scalable solutions that consider multiple possible outcomes. We employ the Generative Cellular Automata that learns the multi-modal distribution and transform the formulation to process large-scale continuous geometry. The local continuous shape is incrementally generated as a sparse voxel embedding, which contains the latent code for each occupied cell. We formally derive that our training objective for the sparse voxel embedding maximizes the variational lower bound of the complete shape distribution and therefore our progressive generation constitutes a valid generative model. Experiments show that our model successfully generates diverse plausible scenes faithful to the input, especially when the input suffers from a significant amount of missing data. We also demonstrate that our approach outperforms deterministic models even in less ambiguous cases with a small amount of missing data, which infers that probabilistic formulation is crucial for high-quality geometry completion on input scans exhibiting any levels of completeness.",
        "conference": "ICLR",
        "中文标题": "概率隐式场景补全",
        "摘要翻译": "我们提出了一种扩展至大规模3D场景连续几何的概率形状补全方法。现实世界中的3D场景扫描数据存在大量缺失，且杂乱无章地分布着未分割的对象。形状补全问题本质上是病态的，高质量的结果需要能够考虑多种可能结果的、可扩展的解决方案。我们采用了生成细胞自动机来学习多模态分布，并将该公式转化为处理大规模连续几何的过程。局部连续形状被逐步生成为稀疏体素嵌入，其中包含每个被占据单元的潜在代码。我们正式推导出，稀疏体素嵌入的训练目标最大化完整形状分布的变分下界，因此我们的渐进生成构成了一个有效的生成模型。实验表明，我们的模型成功地生成了多样化的、忠实于输入的合理场景，尤其是在输入数据存在大量缺失的情况下。我们还证明了，即使在缺失数据量较小的较不模糊情况下，我们的方法也优于确定性模型，这表明概率公式对于在表现出任何完整性水平的输入扫描上进行高质量几何补全至关重要。",
        "领域": "三维重建、形状补全、生成模型",
        "问题": "解决3D场景扫描数据中大量缺失和未分割对象导致的形状补全问题",
        "动机": "现实世界中的3D场景扫描数据存在大量缺失和杂乱无章的对象分布，需要一种能够考虑多种可能结果的、可扩展的形状补全方法",
        "方法": "采用生成细胞自动机学习多模态分布，并将该过程转化为处理大规模连续几何，逐步生成稀疏体素嵌入",
        "关键词": [
            "概率形状补全",
            "生成细胞自动机",
            "稀疏体素嵌入",
            "3D场景重建",
            "变分下界"
        ],
        "涉及的技术概念": {
            "生成细胞自动机": "用于学习多模态分布，处理大规模连续几何",
            "稀疏体素嵌入": "逐步生成局部连续形状，包含每个被占据单元的潜在代码",
            "变分下界": "训练稀疏体素嵌入的目标，最大化完整形状分布的变分下界，构成有效的生成模型"
        },
        "success": true
    },
    {
        "order": 795,
        "title": "Procedural generalization by planning with self-supervised world models",
        "html": "https://iclr.cc//virtual/2022/poster/7007",
        "abstract": "One of the key promises of model-based reinforcement learning is the ability to generalize using an internal model of the world to make predictions in novel environments and tasks. However, the generalization ability of model-based agents is not well understood because existing work has focused on model-free agents when benchmarking generalization. Here, we explicitly measure the generalization ability of model-based agents in comparison to their model-free counterparts. We focus our analysis on MuZero (Schrittwieser et al., 2020), a powerful model-based agent, and evaluate its performance on both procedural and task generalization. We identify three factors of procedural generalization---planning, self-supervised representation learning, and procedural data diversity---and show that by combining these techniques, we achieve state-of-the art generalization performance and data efficiency on Procgen (Cobbe et al., 2019). However, we find that these factors do not always provide the same benefits for the task generalization benchmarks in Meta-World (Yu et al., 2019), indicating that transfer remains a challenge and may require different approaches than procedural generalization. Overall, we suggest that building generalizable agents requires moving beyond the single-task, model-free paradigm and towards self-supervised model-based agents that are trained in rich, procedural, multi-task environments.",
        "conference": "ICLR",
        "中文标题": "通过自监督世界模型规划实现程序化泛化",
        "摘要翻译": "基于模型的强化学习的一个关键承诺是能够利用对世界的内部模型在新环境和任务中进行预测。然而，基于模型代理的泛化能力尚未得到充分理解，因为现有工作在基准测试泛化时主要集中在无模型代理上。在这里，我们明确测量了基于模型代理与无模型代理相比的泛化能力。我们将分析集中在MuZero（Schrittwieser等人，2020年），一个强大的基于模型代理，并评估其在程序化和任务泛化上的表现。我们确定了程序化泛化的三个因素——规划、自监督表示学习和程序化数据多样性——并展示了通过结合这些技术，我们在Procgen（Cobbe等人，2019年）上实现了最先进的泛化性能和数据效率。然而，我们发现这些因素在Meta-World（Yu等人，2019年）的任务泛化基准测试中并不总是提供相同的好处，表明转移仍然是一个挑战，可能需要不同于程序化泛化的方法。总的来说，我们建议构建可泛化的代理需要超越单一任务、无模型的范式，转向在丰富的、程序化的、多任务环境中训练的自监督基于模型代理。",
        "领域": "强化学习、自监督学习、多任务学习",
        "问题": "理解并提升基于模型强化学习代理在新环境和任务中的泛化能力",
        "动机": "探索基于模型代理与无模型代理在泛化能力上的差异，并寻找提升泛化性能的方法",
        "方法": "结合规划、自监督表示学习和程序化数据多样性技术，评估MuZero代理在程序化和任务泛化上的表现",
        "关键词": [
            "程序化泛化",
            "自监督学习",
            "MuZero",
            "Procgen",
            "Meta-World"
        ],
        "涉及的技术概念": {
            "规划": "在基于模型的强化学习中用于预测和决策的技术",
            "自监督表示学习": "通过模型自身生成监督信号来学习数据表示的方法",
            "程序化数据多样性": "通过程序化生成多样化的训练数据以提升模型泛化能力的技术"
        },
        "success": true
    },
    {
        "order": 796,
        "title": "Programmatic Reinforcement Learning without Oracles",
        "html": "https://iclr.cc//virtual/2022/poster/6744",
        "abstract": "Deep reinforcement learning (RL) has led to encouraging successes in many challenging control tasks. However, a deep RL model lacks interpretability due to the difficulty of identifying how the model's control logic relates to its network structure. Programmatic policies structured in more interpretable representations emerge as a promising solution. Yet two shortcomings remain: First, synthesizing programmatic policies requires optimizing over the discrete and non-differentiable search space of program architectures. Previous works are suboptimal because they only enumerate program architectures greedily guided by a pretrained RL oracle. Second, these works do not exploit compositionality, an important programming concept, to reuse and compose primitive functions to form a complex function for new tasks. Our first contribution is a programmatically interpretable RL framework that conducts program architecture search on top of a continuous relaxation of the architecture space defined by programming language grammar rules. Our algorithm allows policy architectures to be learned with policy parameters via bilevel optimization using efficient policy-gradient methods, and thus does not require a pretrained oracle. Our second contribution is improving programmatic policies to support compositionality by integrating primitive functions learned to grasp task-agnostic skills as a composite program to solve novel RL problems. Experiment results demonstrate that our algorithm excels in discovering optimal programmatic policies that are highly interpretable.",
        "conference": "ICLR",
        "中文标题": "无需预设程序的程序化强化学习",
        "摘要翻译": "深度强化学习（RL）在许多具有挑战性的控制任务中取得了令人鼓舞的成功。然而，由于难以确定模型的控制逻辑与其网络结构之间的关系，深度RL模型缺乏可解释性。以更可解释的表示形式构建的程序化策略作为一种有前景的解决方案出现。然而，仍存在两个不足：首先，合成程序化策略需要在程序架构的离散且不可微的搜索空间上进行优化。先前的工作由于仅通过预训练的RL预言机贪婪地枚举程序架构而显得不够优化。其次，这些工作没有利用组合性这一重要的编程概念来重用和组合基本函数以形成解决新任务的复杂函数。我们的第一个贡献是一个程序化可解释的RL框架，该框架在编程语言语法规则定义的架构空间的连续松弛之上进行程序架构搜索。我们的算法允许通过使用高效策略梯度方法的双层优化来学习策略架构与策略参数，因此不需要预训练的预言机。我们的第二个贡献是通过整合学习到的用于掌握任务无关技能的基本函数作为解决新RL问题的复合程序，改进了支持组合性的程序化策略。实验结果表明，我们的算法在发现高度可解释的最优程序化策略方面表现出色。",
        "领域": "强化学习、程序合成、可解释人工智能",
        "问题": "深度强化学习模型缺乏可解释性，以及现有程序化策略合成方法在优化和组合性方面的不足。",
        "动机": "提高强化学习模型的可解释性，并通过程序化策略的合成和组合性来解决新任务。",
        "方法": "提出一个程序化可解释的RL框架，通过双层优化在编程语言语法规则定义的架构空间上进行程序架构搜索，并整合基本函数以支持组合性。",
        "关键词": [
            "程序化强化学习",
            "可解释性",
            "组合性",
            "程序架构搜索",
            "双层优化"
        ],
        "涉及的技术概念": {
            "程序化策略": "以程序形式表示的策略，提高模型的可解释性。",
            "双层优化": "用于同时优化策略架构和策略参数的方法，提高策略合成的效率。",
            "组合性": "通过重用和组合基本函数来构建解决新任务的复杂函数的能力。"
        },
        "success": true
    },
    {
        "order": 797,
        "title": "Progressive Distillation for Fast Sampling of Diffusion Models",
        "html": "https://iclr.cc//virtual/2022/poster/6537",
        "abstract": "Diffusion models have recently shown great promise for generative modeling, outperforming GANs on perceptual quality and autoregressive models at density estimation. A remaining downside is their slow sampling time: generating high quality samples takes many hundreds or thousands of model evaluations. Here we make two contributions to help eliminate this downside: First, we present new parameterizations of diffusion models that provide increased stability when using few sampling steps, compared to models in the literature. Second, we present a method to distill a trained deterministic diffusion sampler, using many steps, into a new diffusion model that takes half as many sampling steps. We then keep progressively applying this distillation procedure to our model, halving the number of required sampling steps each time. On standard image generation benchmarks like CIFAR-10, ImageNet, and LSUN, we start out with (near) state-of-the-art samplers taking 1024 or 8192 steps, and are able to distill down to models taking as little as 4 steps without losing much perceptual quality; achieving, for example, a FID of 3.0 on CIFAR-10 in 4 steps. Finally, we show that the full progressive distillation procedure does not take more time than it takes to train the original model, thus representing an efficient solution for generative modeling using diffusion at both train and test time.",
        "conference": "ICLR",
        "中文标题": "渐进式蒸馏用于扩散模型的快速采样",
        "摘要翻译": "扩散模型最近在生成建模方面显示出巨大的潜力，在感知质量上超越了GANs，在密度估计上超越了自回归模型。一个剩余的缺点是它们的采样速度慢：生成高质量样本需要数百或数千次模型评估。在这里，我们做出了两项贡献来帮助消除这一缺点：首先，我们提出了扩散模型的新参数化方法，与文献中的模型相比，在使用较少采样步骤时提供了更高的稳定性。其次，我们提出了一种方法，将一个训练好的确定性扩散采样器（使用许多步骤）蒸馏成一个新的扩散模型，该模型所需的采样步骤减半。然后，我们持续对这一模型应用蒸馏过程，每次将所需的采样步骤减半。在标准的图像生成基准测试中，如CIFAR-10、ImageNet和LSUN，我们开始时使用（接近）最先进的采样器，需要1024或8192步，并且能够蒸馏到仅需4步的模型而不损失太多感知质量；例如，在CIFAR-10上，4步内实现了3.0的FID。最后，我们展示了完整的渐进式蒸馏过程不会比训练原始模型花费更多时间，因此代表了一种在训练和测试时间都使用扩散进行生成建模的高效解决方案。",
        "领域": "生成模型优化",
        "问题": "扩散模型采样速度慢的问题",
        "动机": "提高扩散模型的采样效率，减少生成高质量样本所需的步骤",
        "方法": "提出新的扩散模型参数化方法和渐进式蒸馏技术，逐步减少采样步骤",
        "关键词": [
            "扩散模型",
            "渐进式蒸馏",
            "快速采样",
            "生成建模",
            "模型优化"
        ],
        "涉及的技术概念": {
            "扩散模型": "一种生成模型，通过逐步添加和去除噪声来生成数据样本",
            "渐进式蒸馏": "一种逐步减少模型采样步骤的技术，通过蒸馏过程保持样本质量",
            "FID": "Frechet Inception Distance，用于评估生成图像质量的指标"
        },
        "success": true
    },
    {
        "order": 798,
        "title": "Promoting Saliency From Depth: Deep Unsupervised RGB-D Saliency Detection",
        "html": "https://iclr.cc//virtual/2022/poster/5929",
        "abstract": "Growing interests in RGB-D salient object detection (RGB-D SOD) have been witnessed in recent years, owing partly to the popularity of depth sensors and the rapid progress of deep learning techniques. Unfortunately, existing RGB-D SOD methods typically demand large quantity of training images being thoroughly annotated at pixel-level. The laborious and time-consuming manual annotation has become a real bottleneck in various practical scenarios. On the other hand, current unsupervised RGB-D SOD methods still heavily rely on handcrafted feature representations. This inspires us to propose in this paper a deep unsupervised RGB-D saliency detection approach, which requires no manual pixel-level annotation during training. It is realized by two key ingredients in our training pipeline. First, a depth-disentangled saliency update (DSU) framework is designed to automatically produce pseudo-labels with iterative follow-up refinements, which provides more trustworthy supervision signals for training the saliency network. Second, an attentive training strategy is introduced to tackle the issue of noisy pseudo-labels, by properly re-weighting to highlight the more reliable pseudo-labels. Extensive experiments demonstrate the superior efficiency and effectiveness of our approach in tackling the challenging unsupervised RGB-D SOD scenarios. Moreover, our approach can also be adapted to work in fully-supervised situation. Empirical studies show the incorporation of our approach gives rise to notably performance improvement in existing supervised RGB-D SOD models.",
        "conference": "ICLR",
        "中文标题": "从深度信息促进显著性：深度无监督RGB-D显著性检测",
        "摘要翻译": "近年来，RGB-D显著物体检测（RGB-D SOD）的兴趣日益增长，部分原因是深度传感器的普及和深度学习技术的快速发展。不幸的是，现有的RGB-D SOD方法通常需要大量训练图像进行像素级的详尽标注。这种费力且耗时的手动标注已成为各种实际场景中的真正瓶颈。另一方面，当前的无监督RGB-D SOD方法仍然严重依赖于手工制作的特征表示。这激励我们在本文中提出一种深度无监督RGB-D显著性检测方法，该方法在训练过程中不需要手动像素级标注。它通过我们训练流程中的两个关键要素实现。首先，设计了一个深度解缠的显著性更新（DSU）框架，以自动生成带有迭代后续细化的伪标签，这为训练显著性网络提供了更可信的监督信号。其次，引入了一种注意力训练策略，通过适当重新加权以突出更可靠的伪标签，来解决噪声伪标签的问题。大量实验证明了我们的方法在处理具有挑战性的无监督RGB-D SOD场景中的卓越效率和有效性。此外，我们的方法也可以适应全监督的情况。实证研究表明，将我们的方法结合使用可以显著提高现有监督RGB-D SOD模型的性能。",
        "领域": "RGB-D显著物体检测",
        "问题": "解决RGB-D显著物体检测中需要大量手动标注数据和依赖手工特征表示的问题",
        "动机": "减少RGB-D显著物体检测对手动标注的依赖，提高检测效率和效果",
        "方法": "提出深度无监督RGB-D显著性检测方法，包括深度解缠的显著性更新框架和注意力训练策略",
        "关键词": [
            "RGB-D显著物体检测",
            "无监督学习",
            "深度解缠",
            "注意力训练",
            "伪标签"
        ],
        "涉及的技术概念": {
            "深度解缠的显著性更新（DSU）框架": "自动生成并迭代细化伪标签，为显著性网络训练提供监督信号",
            "注意力训练策略": "通过重新加权突出更可靠的伪标签，解决噪声伪标签问题",
            "伪标签": "在无监督学习中自动生成的标签，用于替代手动标注"
        },
        "success": true
    },
    {
        "order": 799,
        "title": "Proof Artifact Co-Training for Theorem Proving with Language Models",
        "html": "https://iclr.cc//virtual/2022/poster/6391",
        "abstract": "Labeled data for imitation learning of theorem proving in large libraries of formalized mathematics is scarce as such libraries require years of concentrated effort by human specialists to be built. This is particularly challenging when applying large Transformer language models to tactic prediction, because the scaling of performance with respect to model size is quickly disrupted in the data-scarce, easily-overfitted regime.  We propose PACT (Proof Artifact Co-Training), a general methodology for extracting abundant self-supervised data from kernel-level proof terms for joint training alongside the usual tactic prediction objective.  We apply this methodology to Lean,an interactive proof assistant which hosts some of the most sophisticated formalized mathematics to date. We instrument Lean with a neural theorem prover driven by a Transformer language model and show that PACT improves theorem proving success rate on a held-out suite of test theorems from 32% to 48%.",
        "conference": "ICLR",
        "中文标题": "证明工件协同训练：基于语言模型的定理证明",
        "摘要翻译": "在大型形式化数学库中，用于定理证明模仿学习的标记数据稀缺，因为这些库需要人类专家多年的集中努力才能构建。这在将大型Transformer语言模型应用于策略预测时尤其具有挑战性，因为在数据稀缺、容易过拟合的情况下，模型性能随模型大小的扩展很快受到干扰。我们提出了PACT（证明工件协同训练），这是一种从内核级证明项中提取丰富的自监督数据以与通常的策略预测目标联合训练的通用方法。我们将这一方法应用于Lean，一个交互式证明助手，它托管了迄今为止一些最复杂的形式化数学。我们为Lean配备了一个由Transformer语言模型驱动的神经定理证明器，并显示PACT将测试定理套件上的定理证明成功率从32%提高到了48%。",
        "领域": "自动定理证明、形式化数学、机器学习与数学结合",
        "问题": "解决在大型形式化数学库中定理证明模仿学习标记数据稀缺的问题",
        "动机": "由于大型形式化数学库的构建需要大量人力和时间，导致可用于训练的数据稀缺，影响了基于大型Transformer语言模型的定理证明性能",
        "方法": "提出PACT方法，通过从内核级证明项中提取自监督数据，与策略预测目标联合训练，以提高定理证明的成功率",
        "关键词": [
            "证明工件协同训练",
            "定理证明",
            "Transformer语言模型",
            "自监督学习",
            "形式化数学"
        ],
        "涉及的技术概念": {
            "证明工件协同训练": "一种从内核级证明项中提取自监督数据以与策略预测目标联合训练的方法，旨在提高定理证明的成功率",
            "Transformer语言模型": "用于驱动神经定理证明器的核心技术，能够处理和理解复杂的数学语言和结构",
            "自监督学习": "在数据稀缺的情况下，通过从现有数据中自动生成训练标签来训练模型的方法，用于提高模型的泛化能力和性能"
        },
        "success": true
    },
    {
        "order": 800,
        "title": "Properties from mechanisms: an equivariance perspective on identifiable representation learning",
        "html": "https://iclr.cc//virtual/2022/poster/7092",
        "abstract": "A key goal of unsupervised representation learning is ``inverting'' a data generating process to recover its latent properties.  Existing work that provably achieves this goal relies on strong assumptions on relationships between the latent variables (e.g., independence conditional on auxiliary information). In this paper, we take a very different perspective on the problem and ask,  ``Can we instead identify latent properties by leveraging knowledge of the mechanisms that govern their evolution?'' We provide a complete characterization of the sources of non-identifiability as we vary knowledge about a set of possible mechanisms. In particular, we prove that if we know the exact mechanisms under which the latent properties evolve, then identification can be achieved up to any equivariances that are shared by the underlying mechanisms. We generalize this characterization to settings where we only know some hypothesis class over possible mechanisms, as well as settings where the mechanisms are stochastic. We demonstrate the power of this mechanism-based perspective by showing that we can leverage our results to generalize existing identifiable representation learning results. These results suggest that by exploiting inductive biases on mechanisms, it is possible to design a range of new identifiable representation learning approaches.",
        "conference": "ICLR",
        "中文标题": "从机制到属性：可辨识表示学习的等变性视角",
        "摘要翻译": "无监督表示学习的一个关键目标是“反转”数据生成过程以恢复其潜在属性。现有工作证明实现这一目标依赖于对潜在变量之间关系的强假设（例如，基于辅助信息的条件独立性）。在本文中，我们从一个非常不同的角度看待这个问题，并问：“我们是否可以通过利用控制其演变的机制知识来识别潜在属性？”随着我们对一组可能机制的知识变化，我们提供了非可辨识性来源的完整特征描述。特别是，我们证明，如果我们知道潜在属性演变的精确机制，那么识别可以达到与底层机制共享的任何等变性。我们将这一特征描述推广到我们只知道可能机制的某些假设类的情况，以及机制是随机的情况。通过展示我们可以利用我们的结果来推广现有的可辨识表示学习结果，我们证明了这种基于机制的视角的力量。这些结果表明，通过利用机制的归纳偏差，可以设计出一系列新的可辨识表示学习方法。",
        "领域": "无监督学习、表示学习、机器学习理论",
        "问题": "如何在无监督表示学习中通过利用控制潜在属性演变的机制知识来识别潜在属性",
        "动机": "探索通过利用机制知识而非传统的强假设条件，来实现潜在属性的识别，以推动可辨识表示学习的发展",
        "方法": "通过分析非可辨识性来源，提出并证明在知道潜在属性演变的精确机制条件下，识别可以达到与机制共享的等变性，并推广到更广泛的机制假设和随机机制情况",
        "关键词": [
            "无监督学习",
            "表示学习",
            "等变性",
            "机制知识",
            "可辨识性"
        ],
        "涉及的技术概念": {
            "等变性": "在本文中指潜在属性识别过程中与底层机制共享的变换不变性，是实现可辨识性的关键",
            "机制知识": "指控制潜在属性演变的规则或过程的知识，用于指导表示学习中的潜在属性识别",
            "可辨识性": "指在表示学习中能够唯一确定潜在属性的能力，是评估表示学习方法有效性的重要标准"
        },
        "success": true
    },
    {
        "order": 801,
        "title": "Prospect Pruning: Finding Trainable Weights at Initialization using Meta-Gradients",
        "html": "https://iclr.cc//virtual/2022/poster/6758",
        "abstract": "Pruning neural networks at initialization would enable us to find sparse models that retain the accuracy of the original network while consuming fewer computational resources for training and inference. However, current methods are insufficient to enable this optimization and lead to a large degradation in model performance. In this paper, we identify a fundamental limitation in the formulation of current methods, namely that their saliency criteria look at a single step at the start of training without taking into account the trainability of the network. While pruning iteratively and gradually has been shown to improve pruning performance, explicit consideration of the training stage that will immediately follow pruning has so far been absent from the computation of the saliency criterion. To overcome the short-sightedness of existing methods, we propose Prospect Pruning (ProsPr), which uses meta-gradients through the first few steps of optimization to determine which weights to prune. ProsPr combines an estimate of the higher-order effects of pruning on the loss and the optimization trajectory to identify the trainable sub-network. Our method achieves state-of-the-art pruning performance on a variety of vision classification tasks, with less data and in a single shot compared to existing pruning-at-initialization methods.",
        "conference": "ICLR",
        "中文标题": "前瞻剪枝：利用元梯度在初始化时寻找可训练权重",
        "摘要翻译": "在神经网络初始化时进行剪枝，能够让我们找到稀疏模型，这些模型在保持原始网络精度的同时，减少了训练和推理所需的计算资源。然而，当前的方法不足以支持这种优化，导致模型性能大幅下降。在本文中，我们指出了当前方法在公式化上的一个基本限制，即它们的显著性标准仅关注训练开始时的单一步骤，而没有考虑到网络的可训练性。虽然迭代和逐步剪枝已被证明可以提高剪枝性能，但在显著性标准的计算中，迄今为止尚未明确考虑紧随剪枝之后的训练阶段。为了克服现有方法的短视，我们提出了前瞻剪枝（ProsPr），该方法通过优化前几步的元梯度来确定哪些权重应该被剪枝。ProsPr结合了剪枝对损失和优化轨迹的高阶效应估计，以识别可训练的子网络。我们的方法在各种视觉分类任务上实现了最先进的剪枝性能，与现有的初始化时剪枝方法相比，使用更少的数据且一次性完成。",
        "领域": "神经网络剪枝",
        "问题": "如何在神经网络初始化时有效剪枝，以找到既保持模型精度又减少计算资源的稀疏模型",
        "动机": "解决当前剪枝方法在初始化时无法有效保持模型性能的问题",
        "方法": "提出前瞻剪枝（ProsPr），利用元梯度通过优化前几步来确定剪枝权重，结合剪枝对损失和优化轨迹的高阶效应估计",
        "关键词": [
            "神经网络剪枝",
            "元梯度",
            "稀疏模型",
            "初始化剪枝",
            "视觉分类"
        ],
        "涉及的技术概念": {
            "元梯度": "用于在优化过程中指导剪枝决策的高阶梯度信息",
            "稀疏模型": "通过剪枝减少模型参数数量，提高计算效率的模型",
            "初始化剪枝": "在神经网络训练开始前进行剪枝，以减少训练和推理的计算资源消耗"
        },
        "success": true
    },
    {
        "order": 802,
        "title": "ProtoRes: Proto-Residual Network for Pose Authoring via Learned Inverse Kinematics",
        "html": "https://iclr.cc//virtual/2022/poster/6539",
        "abstract": "Our work focuses on the development of a learnable neural representation of human pose for advanced AI assisted animation tooling. Specifically, we tackle the problem of constructing a full static human pose based on sparse and variable user inputs (e.g. locations and/or orientations of a subset of body joints). To solve this problem, we propose a novel neural architecture that combines residual connections with prototype encoding of a partially specified pose to create a new complete pose from the learned latent space. We show that our architecture outperforms a baseline based on Transformer, both in terms of accuracy and computational efficiency. Additionally, we develop a user interface to integrate our neural model in Unity, a real-time 3D development platform. Furthermore, we introduce two new datasets representing the static human pose modeling problem, based on high-quality human motion capture data, which will be released publicly along with model code.",
        "conference": "ICLR",
        "中文标题": "ProtoRes：通过学习逆向运动学进行姿势创作的原始残差网络",
        "摘要翻译": "我们的工作专注于开发一种可学习的人类姿势神经表示，用于高级AI辅助动画工具。具体来说，我们解决了基于稀疏和可变用户输入（例如身体关节子集的位置和/或方向）构建完整静态人体姿势的问题。为了解决这个问题，我们提出了一种新颖的神经架构，该架构结合了残差连接与部分指定姿势的原型编码，从学习的潜在空间中创建新的完整姿势。我们展示了我们的架构在准确性和计算效率方面均优于基于Transformer的基线。此外，我们开发了一个用户界面，将我们的神经模型集成到Unity中，这是一个实时3D开发平台。此外，我们基于高质量的人类动作捕捉数据，引入了两个代表静态人体姿势建模问题的新数据集，这些数据集将与模型代码一起公开发布。",
        "领域": "动作捕捉与动画、逆向运动学、神经网络应用",
        "问题": "如何基于稀疏和可变的用户输入构建完整静态人体姿势",
        "动机": "开发高级AI辅助动画工具，提高姿势构建的准确性和效率",
        "方法": "提出了一种结合残差连接与原型编码的神经架构，从学习的潜在空间中创建完整姿势",
        "关键词": [
            "神经表示",
            "逆向运动学",
            "残差网络",
            "原型编码",
            "动作捕捉"
        ],
        "涉及的技术概念": {
            "残差连接": "用于在网络中传递梯度，解决深度网络中的梯度消失问题",
            "原型编码": "用于部分指定姿势的编码，帮助从潜在空间生成完整姿势",
            "逆向运动学": "用于根据末端效应器的位置计算关节角度，实现姿势的自然生成"
        },
        "success": true
    },
    {
        "order": 803,
        "title": "Prototype memory and attention mechanisms for few shot image generation",
        "html": "https://iclr.cc//virtual/2022/poster/6150",
        "abstract": "Recent discoveries indicate that the neural codes in the primary visual cortex (V1) of macaque monkeys are complex, diverse and sparse. This leads us to ponder the computational advantages and functional role of these “grandmother cells.' Here, we propose that such cells can serve as prototype memory priors that bias and shape the distributed feature processing within the image generation process in the brain. These memory prototypes are learned by momentum online clustering and are utilized via a memory-based attention operation, which we define as Memory Concept Attention (MoCA). To test our proposal, we show in a few-shot image generation task, that having a prototype memory during attention can improve image synthesis quality, learn interpretable visual concept clusters, as well as improve the robustness of the model. Interestingly, we also find that our attentional memory mechanism can implicitly modify the horizontal connections by updating the transformation into the prototype embedding space for self-attention. Insofar as GANs can be seen as plausible models for reasoning about the top-down synthesis in the analysis-by-synthesis loop of the hierarchical visual cortex, our findings demonstrate a plausible computational role for these “prototype concept' neurons in visual processing in the brain.",
        "conference": "ICLR",
        "中文标题": "原型记忆与注意力机制在少样本图像生成中的应用",
        "摘要翻译": "最近的研究表明，猕猴初级视觉皮层（V1）中的神经编码是复杂、多样且稀疏的。这使我们思考这些‘祖母细胞’的计算优势和功能角色。在此，我们提出这些细胞可以作为原型记忆先验，在图像生成过程中偏置和塑造分布式特征处理。这些记忆原型通过动量在线聚类学习，并通过基于记忆的注意力操作利用，我们将其定义为记忆概念注意力（MoCA）。为了验证我们的提议，我们在少样本图像生成任务中展示，在注意力过程中拥有原型记忆可以提高图像合成质量，学习可解释的视觉概念聚类，以及提高模型的鲁棒性。有趣的是，我们还发现我们的注意力记忆机制可以通过更新到原型嵌入空间的转换来隐式修改水平连接，用于自注意力。就GANs可以被视为对层次视觉皮层分析-合成循环中自上而下合成的合理模型而言，我们的发现展示了这些‘原型概念’神经元在视觉处理中的合理计算角色。",
        "领域": "图像生成、少样本学习、注意力机制",
        "问题": "如何在少样本条件下提高图像生成的质量和可解释性",
        "动机": "探索猕猴初级视觉皮层中‘祖母细胞’的计算优势和功能角色，以及如何将这些发现应用于图像生成任务",
        "方法": "提出原型记忆先验和记忆概念注意力（MoCA）机制，通过动量在线聚类学习记忆原型，并在图像生成任务中应用这些原型以提高合成质量和模型鲁棒性",
        "关键词": [
            "原型记忆",
            "注意力机制",
            "少样本学习",
            "图像生成",
            "MoCA"
        ],
        "涉及的技术概念": {
            "原型记忆": "在图像生成过程中作为先验知识，用于偏置和塑造分布式特征处理",
            "记忆概念注意力（MoCA）": "基于记忆的注意力操作，用于利用学习到的记忆原型",
            "动量在线聚类": "用于学习记忆原型的方法，通过动态更新聚类中心来适应新数据"
        },
        "success": true
    },
    {
        "order": 804,
        "title": "Prototypical Contrastive Predictive Coding",
        "html": "https://iclr.cc//virtual/2022/poster/6453",
        "abstract": "Transferring representational knowledge of a model to another is a wide-ranging topic in machine learning. Those applications include the distillation of a large supervised or self-supervised teacher model to a smaller student model or self-supervised learning via self-distillation. Knowledge distillation is an original method to solve these problems, which minimizes a cross-entropy loss between the prototypical probabilistic outputs of teacher and student networks. On the other hand, contrastive learning has shown its competency in transferring representations as they allow students to capture the information of teacher representations. In this paper, we amalgamate the advantages of knowledge distillation and contrastive learning by modeling the critic of a contrastive objective by the prototypical probabilistic discrepancy between two features. We refer to it as prototypical contrastive predictive coding and present efficient implementation using the proposed objective for three distillation tasks: supervised model compression, self-supervised model compression, and self-supervised learning via self-distillation. Through extensive experiments, we validate the effectiveness of our method and show that our method achieves state-of-the-art performance in supervised / self-supervised model compression. ",
        "conference": "ICLR",
        "中文标题": "原型对比预测编码",
        "摘要翻译": "将模型的表示知识转移到另一个模型是机器学习中的一个广泛话题。这些应用包括将大型有监督或自监督教师模型蒸馏到较小的学生模型，或通过自蒸馏进行自监督学习。知识蒸馏是解决这些问题的原始方法，它最小化教师和学生网络原型概率输出之间的交叉熵损失。另一方面，对比学习在转移表示方面显示出了其能力，因为它们允许学生捕捉教师表示的信息。在本文中，我们通过将对比目标的批评者建模为两个特征之间的原型概率差异，结合了知识蒸馏和对比学习的优势。我们将其称为原型对比预测编码，并提出了使用所提出的目标对三种蒸馏任务的高效实现：有监督模型压缩、自监督模型压缩和通过自蒸馏的自监督学习。通过大量实验，我们验证了我们方法的有效性，并表明我们的方法在有监督/自监督模型压缩中实现了最先进的性能。",
        "领域": "自监督学习, 模型压缩, 知识蒸馏",
        "问题": "如何有效地将教师模型的表示知识转移到学生模型中",
        "动机": "结合知识蒸馏和对比学习的优势，以提高模型压缩和自监督学习的效率",
        "方法": "通过将对比目标的批评者建模为两个特征之间的原型概率差异，结合知识蒸馏和对比学习的方法",
        "关键词": [
            "原型对比预测编码",
            "知识蒸馏",
            "对比学习",
            "模型压缩",
            "自监督学习"
        ],
        "涉及的技术概念": {
            "原型对比预测编码": "结合知识蒸馏和对比学习的方法，通过原型概率差异来优化模型表示转移",
            "知识蒸馏": "通过最小化教师和学生网络输出之间的差异，将知识从教师模型转移到学生模型",
            "对比学习": "通过比较样本间的相似性和差异性来学习有效表示的方法"
        },
        "success": true
    },
    {
        "order": 805,
        "title": "Provable Adaptation across Multiway Domains via Representation Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6899",
        "abstract": "This paper studies zero-shot domain adaptation where each domain is indexed on a multi-dimensional array, and we only have data from a small subset of domains. Our goal is to produce predictors that perform well on \\emph{unseen} domains. We propose a model which consists of a domain-invariant latent representation layer and a domain-specific linear prediction layer with a low-rank tensor structure. Theoretically, we present explicit sample complexity bounds to characterize the prediction error on unseen domains in terms of the number of domains with training data and the number of data per domain. To our knowledge, this is the first finite-sample guarantee for zero-shot domain adaptation. In addition, we provide experiments on two-way MNIST and four-way fiber sensing datasets to demonstrate the effectiveness of our proposed model.",
        "conference": "ICLR",
        "中文标题": "通过表示学习实现多领域间的可证明适应",
        "摘要翻译": "本文研究了零样本领域适应问题，其中每个领域都索引在一个多维数组上，而我们只有来自一小部分领域的数据。我们的目标是生成在未见领域上表现良好的预测器。我们提出了一个模型，该模型由一个领域不变的潜在表示层和一个具有低秩张量结构的领域特定线性预测层组成。理论上，我们提出了明确的样本复杂度界限，以根据训练数据的领域数量和每个领域的数据数量来表征未见领域的预测误差。据我们所知，这是零样本领域适应的第一个有限样本保证。此外，我们在双向MNIST和四向光纤传感数据集上进行了实验，以证明我们提出的模型的有效性。",
        "领域": "零样本学习",
        "问题": "解决在未见领域上的预测问题",
        "动机": "研究如何在只有少量领域数据的情况下，生成能够适应未见领域的预测器",
        "方法": "提出一个包含领域不变潜在表示层和领域特定线性预测层的模型，利用低秩张量结构",
        "关键词": [
            "零样本领域适应",
            "表示学习",
            "低秩张量",
            "样本复杂度",
            "多领域学习"
        ],
        "涉及的技术概念": {
            "领域不变的潜在表示层": "用于捕捉不同领域间的共同特征，实现领域间的知识迁移",
            "低秩张量结构": "用于建模领域特定的线性预测层，减少模型复杂度并提高泛化能力",
            "样本复杂度界限": "提供了理论保证，量化了模型在未见领域上的预测误差与训练数据量之间的关系"
        },
        "success": true
    },
    {
        "order": 806,
        "title": "Provable Learning-based Algorithm For Sparse Recovery",
        "html": "https://iclr.cc//virtual/2022/poster/6689",
        "abstract": "Recovering sparse parameters from observational data is a fundamental problem in machine learning with wide applications. Many classic algorithms can solve this problem with theoretical guarantees, but their performances rely on choosing the correct hyperparameters. Besides, hand-designed algorithms do not fully exploit the particular problem distribution of interest. In this work, we propose a deep learning method for algorithm learning called PLISA (Provable Learning-based Iterative Sparse recovery Algorithm). PLISA is designed by unrolling a classic path-following algorithm for sparse recovery, with some components being more flexible and learnable. We theoretically show the improved recovery accuracy achievable by PLISA. Furthermore, we analyze the empirical Rademacher complexity of PLISA to characterize its generalization ability to solve new problems outside the training set. This paper contains novel theoretical contributions to the area of learning-based algorithms in the sense that (i) PLISA is generically applicable to a broad class of sparse estimation problems, (ii) generalization analysis has received less attention so far, and (iii) our analysis makes novel connections between the generalization ability and algorithmic properties such as stability and convergence of the unrolled algorithm, which leads to a tighter bound that can explain the empirical observations. The techniques could potentially be applied to analyze other learning-based algorithms in the literature.",
        "conference": "ICLR",
        "中文标题": "可证明的基于学习的稀疏恢复算法",
        "摘要翻译": "从观测数据中恢复稀疏参数是机器学习中的一个基本问题，具有广泛的应用。许多经典算法可以在理论保证下解决这个问题，但它们的性能依赖于选择正确的超参数。此外，手工设计的算法没有充分利用感兴趣的特定问题分布。在这项工作中，我们提出了一种用于算法学习的深度学习方法，称为PLISA（可证明的基于学习的迭代稀疏恢复算法）。PLISA是通过展开一个经典的路径跟踪算法来设计的，用于稀疏恢复，其中一些组件更加灵活和可学习。我们从理论上展示了PLISA可实现的改进恢复精度。此外，我们分析了PLISA的经验Rademacher复杂性，以表征其解决训练集外新问题的泛化能力。本文在学习基于算法的领域内做出了新的理论贡献，因为（i）PLISA普遍适用于广泛的稀疏估计问题，（ii）泛化分析迄今为止受到的关注较少，以及（iii）我们的分析在泛化能力与展开算法的稳定性和收敛性等算法属性之间建立了新的联系，这导致了一个可以解释经验观察的更紧密的界限。这些技术可能应用于分析文献中的其他基于学习的算法。",
        "领域": "稀疏恢复、深度学习、算法学习",
        "问题": "解决从观测数据中恢复稀疏参数的问题，同时克服传统算法在超参数选择和问题分布利用上的限制。",
        "动机": "传统稀疏恢复算法依赖于正确的超参数选择且未能充分利用特定问题分布，限制了其性能和泛化能力。",
        "方法": "提出了一种基于深度学习的算法PLISA，通过展开经典路径跟踪算法并引入灵活可学习的组件，以提高恢复精度和泛化能力。",
        "关键词": [
            "稀疏恢复",
            "深度学习",
            "算法学习",
            "泛化分析",
            "路径跟踪算法"
        ],
        "涉及的技术概念": {
            "PLISA": "可证明的基于学习的迭代稀疏恢复算法，通过展开经典算法并引入可学习组件来提高性能。",
            "Rademacher复杂性": "用于衡量算法泛化能力的理论工具，帮助分析算法在新问题上的表现。",
            "路径跟踪算法": "一种经典的稀疏恢复算法，PLISA基于此算法设计，通过展开和引入可学习组件来优化性能。"
        },
        "success": true
    },
    {
        "order": 807,
        "title": "Provably convergent quasistatic dynamics for mean-field two-player zero-sum games",
        "html": "https://iclr.cc//virtual/2022/poster/6723",
        "abstract": "In this paper, we study the problem of finding mixed Nash equilibrium for mean-field two-player zero-sum games. Solving this problem requires optimizing over two probability distributions. We consider a quasistatic Wasserstein gradient flow dynamics in which one probability distribution follows the Wasserstein gradient flow, while the other one is always at the equilibrium. Theoretical analysis are conducted on this dynamics, showing its convergence to the mixed Nash equilibrium under mild conditions. Inspired by the continuous dynamics of probability distributions, we derive a quasistatic Langevin gradient descent method with inner-outer iterations, and test the method on different problems, including training mixture of GANs. ",
        "conference": "ICLR",
        "中文标题": "可证明收敛的拟静态动力学用于平均场双人零和博弈",
        "摘要翻译": "本文研究了寻找平均场双人零和博弈的混合纳什均衡问题。解决这一问题需要在两个概率分布上进行优化。我们考虑了一种拟静态Wasserstein梯度流动力学，其中一个概率分布遵循Wasserstein梯度流，而另一个始终处于均衡状态。对这一动力学进行了理论分析，表明在温和条件下其收敛于混合纳什均衡。受概率分布连续动力学的启发，我们推导了一种具有内外迭代的拟静态Langevin梯度下降方法，并在不同问题上测试了该方法，包括训练GANs的混合。",
        "领域": "博弈论、优化算法、生成对抗网络",
        "问题": "寻找平均场双人零和博弈的混合纳什均衡",
        "动机": "研究旨在解决在平均场双人零和博弈中寻找混合纳什均衡的优化问题，通过拟静态动力学方法实现高效求解。",
        "方法": "采用拟静态Wasserstein梯度流动力学和拟静态Langevin梯度下降方法，结合内外迭代策略，进行优化求解。",
        "关键词": [
            "平均场博弈",
            "混合纳什均衡",
            "Wasserstein梯度流",
            "Langevin梯度下降",
            "生成对抗网络"
        ],
        "涉及的技术概念": {
            "Wasserstein梯度流": "用于描述一个概率分布随时间演化的动力学过程，是实现优化目标的关键技术。",
            "Langevin梯度下降": "一种结合随机性的梯度下降方法，用于在概率分布空间中进行高效优化。",
            "混合纳什均衡": "博弈论中的一种均衡概念，指在混合策略下，没有任何一方能通过单方面改变策略而获得更高收益的状态。"
        },
        "success": true
    },
    {
        "order": 808,
        "title": "Provably Filtering Exogenous Distractors using Multistep Inverse Dynamics",
        "html": "https://iclr.cc//virtual/2022/poster/6733",
        "abstract": "Many real-world applications of reinforcement learning (RL) require the agent to deal with high-dimensional observations such as those generated from a megapixel camera. Prior work has addressed such problems with representation learning, through which the agent can provably extract endogenous, latent state information from raw observations and subsequently plan efficiently. However, such approaches can fail in the presence of temporally correlated noise in the observations, a phenomenon that is common in practice. We initiate the formal study of latent state discovery in the presence of such exogenous noise sources by proposing a new model, the Exogenous Block MDP (EX-BMDP), for rich observation RL. We start by establishing several negative results, by highlighting failure cases of prior representation learning based approaches. Then, we introduce the Predictive Path Elimination (PPE) algorithm, that learns a generalization of inverse dynamics and is provably sample and computationally efficient in EX-BMDPs when the endogenous state dynamics are near deterministic. The sample complexity of PPE depends polynomially on the size of the latent endogenous state space while not directly depending on the size of the observation space, nor the exogenous state space. We provide experiments on challenging exploration problems which show that our approach works empirically. ",
        "conference": "ICLR",
        "中文标题": "可证明使用多步逆动力学过滤外生干扰",
        "摘要翻译": "强化学习（RL）的许多实际应用要求代理处理高维观测，例如由百万像素相机生成的观测。先前的工作通过表示学习解决了这类问题，代理可以从中可证明地从原始观测中提取内生的潜在状态信息，并随后高效规划。然而，在观测中存在时间相关噪声的情况下，这种方法可能会失败，这种现象在实践中很常见。我们通过提出一个新模型——外生块马尔可夫决策过程（EX-BMDP），用于丰富观测的RL，正式研究了在这种外生噪声源存在下的潜在状态发现。我们首先通过强调先前基于表示学习的方法的失败案例，建立了几个负面结果。然后，我们引入了预测路径消除（PPE）算法，该算法学习逆动力学的泛化，并且在EX-BMDP中当内生状态动态接近确定性时，可证明是样本和计算效率高的。PPE的样本复杂度多项式依赖于潜在内生状态空间的大小，而不直接依赖于观测空间的大小，也不依赖于外生状态空间的大小。我们在具有挑战性的探索问题上提供了实验，表明我们的方法在实践中有效。",
        "领域": "强化学习、表示学习、马尔可夫决策过程",
        "问题": "在高维观测中处理时间相关噪声，以发现潜在状态",
        "动机": "解决在存在外生噪声源的情况下，强化学习代理如何有效地从高维观测中提取内生状态信息的问题",
        "方法": "提出外生块马尔可夫决策过程（EX-BMDP）模型和预测路径消除（PPE）算法，通过泛化逆动力学来过滤外生干扰",
        "关键词": [
            "强化学习",
            "表示学习",
            "EX-BMDP",
            "PPE算法",
            "逆动力学"
        ],
        "涉及的技术概念": {
            "外生块马尔可夫决策过程（EX-BMDP）": "用于描述在存在外生噪声源的情况下，强化学习代理如何从高维观测中提取内生状态信息的模型",
            "预测路径消除（PPE）算法": "一种学习逆动力学泛化的算法，用于在EX-BMDP中高效地过滤外生干扰",
            "逆动力学": "在强化学习中，用于从观测序列预测动作的技术，PPE算法通过泛化逆动力学来过滤外生干扰"
        },
        "success": true
    },
    {
        "order": 809,
        "title": "Provably Robust Adversarial Examples",
        "html": "https://iclr.cc//virtual/2022/poster/6160",
        "abstract": "We introduce the concept of provably robust adversarial examples for deep neural networks – connected input regions constructed from standard adversarial examples which are guaranteed to be robust to a set of real-world perturbations (such as changes in pixel intensity and geometric transformations). We present a novel method called PARADE for generating these regions in a scalable manner which works by iteratively refining the region initially obtained via sampling until a refined region is certified to be adversarial with existing state-of-the-art verifiers. At each step, a novel optimization procedure is applied to maximize the region's volume under the constraint that the convex relaxation of the network behavior with respect to the region implies a chosen bound on the certification objective. Our experimental evaluation shows the effectiveness of PARADE: it successfully finds large provably robust regions including ones containing $\\approx 10^{573}$ adversarial examples for pixel intensity and $\\approx 10^{599}$ for geometric perturbations. The provability enables our robust examples to be significantly more effective against state-of-the-art defenses based on randomized smoothing than the individual attacks used to construct the regions.",
        "conference": "ICLR",
        "中文标题": "可证明鲁棒的对抗样本",
        "摘要翻译": "我们为深度神经网络引入了可证明鲁棒的对抗样本的概念——这些由标准对抗样本构建的连通输入区域，保证能够抵抗一系列现实世界中的扰动（如像素强度的变化和几何变换）。我们提出了一种名为PARADE的新方法，用于以可扩展的方式生成这些区域，该方法通过迭代细化最初通过采样获得的区域，直到现有最先进的验证器能够证明细化后的区域具有对抗性。在每一步中，应用一种新颖的优化程序，以在网络的区域行为凸松弛意味着认证目标的选定约束下最大化区域的体积。我们的实验评估显示了PARADE的有效性：它成功地找到了包括约10^573个对抗样本的像素强度扰动和约10^599个几何扰动的大规模可证明鲁棒区域。这种可证明性使我们的鲁棒样本在对抗基于随机平滑的最先进防御时，比用于构建区域的个体攻击更为有效。",
        "领域": "对抗样本防御、深度学习安全、神经网络验证",
        "问题": "如何生成可证明对现实世界扰动鲁棒的对抗样本区域",
        "动机": "提高对抗样本的鲁棒性，使其能够有效抵抗包括像素强度变化和几何变换在内的多种扰动",
        "方法": "提出PARADE方法，通过迭代优化和验证，生成大规模的可证明鲁棒的对抗样本区域",
        "关键词": [
            "对抗样本",
            "鲁棒性验证",
            "深度学习安全",
            "神经网络验证",
            "优化方法"
        ],
        "涉及的技术概念": {
            "可证明鲁棒的对抗样本": "通过数学方法保证对特定扰动具有鲁棒性的对抗样本",
            "PARADE方法": "一种迭代优化和验证的方法，用于生成大规模的可证明鲁棒的对抗样本区域",
            "随机平滑": "一种防御技术，通过向输入添加随机噪声来提高模型对对抗样本的鲁棒性"
        },
        "success": true
    },
    {
        "order": 810,
        "title": "Proving the Lottery Ticket Hypothesis for Convolutional Neural Networks",
        "html": "https://iclr.cc//virtual/2022/poster/5981",
        "abstract": "The lottery ticket hypothesis states that a randomly-initialized neural network contains a small subnetwork which, when trained in isolation, can compete with the performance of the original network. Recent theoretical works proved an even stronger version: every sufficiently overparameterized (dense) neural network contains a subnetwork that, even without training, achieves accuracy comparable to that of the trained large network. These works left as an open problem to extend the result to convolutional neural networks (CNNs).In this work we provide such generalization by showing that, with high probability, it is possible to approximate any CNN by pruning a random CNN whose size is larger by a logarithmic factor.",
        "conference": "ICLR",
        "中文标题": "证明卷积神经网络的彩票假设",
        "摘要翻译": "彩票假设指出，一个随机初始化的神经网络中包含一个小子网络，当这个子网络被单独训练时，其性能可以与原始网络相媲美。最近的理论工作证明了一个更加强的版本：每一个足够过度参数化（密集）的神经网络都包含一个子网络，即使不经过训练，也能达到与训练过的大型网络相当的准确度。这些工作留下了一个开放问题，即将结果扩展到卷积神经网络（CNNs）。在这项工作中，我们通过证明，以高概率，可以通过修剪一个大小是对数因子更大的随机CNN来近似任何CNN，从而提供了这样的推广。",
        "领域": "神经网络优化、模型压缩、深度学习理论",
        "问题": "如何将彩票假设的理论结果扩展到卷积神经网络",
        "动机": "探索在卷积神经网络中是否存在未经训练即可达到高性能的子网络，以验证彩票假设的普遍性",
        "方法": "通过理论证明，展示通过修剪一个随机初始化的、规模更大的卷积神经网络，可以高概率地近似任何目标CNN",
        "关键词": [
            "彩票假设",
            "卷积神经网络",
            "模型修剪",
            "神经网络初始化",
            "过参数化"
        ],
        "涉及的技术概念": {
            "彩票假设": "指在随机初始化的神经网络中存在一个小子网络，单独训练时能达到与原始网络相当的性能",
            "过参数化": "指神经网络的参数数量远超训练样本数量，这在理论证明中是一个关键条件",
            "模型修剪": "一种减少神经网络复杂度的方法，通过移除不重要的连接或节点来压缩模型"
        },
        "success": true
    },
    {
        "order": 811,
        "title": "PSA-GAN: Progressive Self Attention GANs for Synthetic Time Series",
        "html": "https://iclr.cc//virtual/2022/poster/6757",
        "abstract": "Realistic synthetic time series data of sufficient length enables practical applications in time series modeling tasks, such as forecasting, but remains a challenge. In this paper we present PSA-GAN, a generative adversarial network (GAN) that generates long time series samples of high quality using progressive growing of GANs and self-attention. We show that PSA-GAN can be used to reduce the error in several downstream forecasting tasks over baselines that only use real data. We also introduce a Frechet-Inception Distance-like score for time series, Context-FID, assessing the quality of synthetic time series samples. We find that Context-FID is indicative for downstream performance. Therefore, Context-FID could be a useful tool to develop time series GAN models. ",
        "conference": "ICLR",
        "中文标题": "PSA-GAN：用于合成时间序列的渐进式自注意力生成对抗网络",
        "摘要翻译": "足够长度的真实合成时间序列数据在时间序列建模任务（如预测）中具有实际应用价值，但这仍然是一个挑战。在本文中，我们提出了PSA-GAN，这是一种生成对抗网络（GAN），它通过渐进式增长的GAN和自注意力机制生成长时间序列的高质量样本。我们展示了PSA-GAN可以在几个下游预测任务中减少仅使用真实数据的基线的误差。我们还为时间序列引入了一个类似于Frechet-Inception距离的评分——Context-FID，用于评估合成时间序列样本的质量。我们发现Context-FID对下游性能有指示作用。因此，Context-FID可能是开发时间序列GAN模型的有用工具。",
        "领域": "时间序列生成、时间序列预测、生成对抗网络",
        "问题": "如何生成足够长度且高质量的时间序列数据以支持时间序列建模任务",
        "动机": "解决在时间序列建模任务中高质量长序列数据生成的挑战",
        "方法": "采用渐进式增长的生成对抗网络结合自注意力机制来生成长时间序列的高质量样本",
        "关键词": [
            "时间序列生成",
            "生成对抗网络",
            "自注意力机制",
            "Context-FID",
            "时间序列预测"
        ],
        "涉及的技术概念": {
            "渐进式增长的GAN": "通过逐步增加网络深度和样本复杂度来生成高质量的时间序列数据",
            "自注意力机制": "用于捕捉时间序列数据中的长距离依赖关系，提升生成样本的质量",
            "Context-FID": "一种评估合成时间序列样本质量的指标，类似于Frechet-Inception距离，对下游任务性能有指示作用"
        },
        "success": true
    },
    {
        "order": 812,
        "title": "Pseudo-Labeled Auto-Curriculum Learning for Semi-Supervised Keypoint Localization",
        "html": "https://iclr.cc//virtual/2022/poster/6943",
        "abstract": "Localizing keypoints of an object is a basic visual problem. However, supervised learning of a keypoint localization network often requires a large amount of data, which is expensive and time-consuming to obtain. To remedy this, there is an ever-growing interest in semi-supervised learning (SSL), which leverages a small set of labeled data along with a large set of unlabeled data. Among these SSL approaches, pseudo-labeling (PL) is one of the most popular. PL approaches apply pseudo-labels to unlabeled data, and then train the model with a combination of the labeled and pseudo-labeled data iteratively. The key to the success of PL is the selection of high-quality pseudo-labeled samples. Previous works mostly select training samples by manually setting a single confidence threshold. We propose to automatically select reliable pseudo-labeled samples with a series of dynamic thresholds, which constitutes a learning curriculum.Extensive experiments on five keypoint localization benchmark datasets demonstrate that the proposed approach significantly outperforms the previous state-of-the-art SSL approaches. ",
        "conference": "ICLR",
        "中文标题": "半监督关键点定位中的伪标签自动课程学习",
        "摘要翻译": "定位物体的关键点是一个基本的视觉问题。然而，关键点定位网络的监督学习通常需要大量数据，这些数据的获取既昂贵又耗时。为了解决这个问题，半监督学习（SSL）越来越受到关注，它利用一小部分标记数据和大量未标记数据。在这些SSL方法中，伪标签（PL）是最受欢迎的方法之一。PL方法对未标记数据应用伪标签，然后迭代地用标记和伪标记数据的组合训练模型。PL成功的关键在于选择高质量的伪标记样本。以前的工作大多通过手动设置单一置信度阈值来选择训练样本。我们提出用一系列动态阈值自动选择可靠的伪标记样本，这构成了一个学习课程。在五个关键点定位基准数据集上的大量实验表明，所提出的方法显著优于之前最先进的SSL方法。",
        "领域": "关键点检测、半监督学习、计算机视觉",
        "问题": "如何在半监督学习环境下高效选择高质量的伪标记样本以提升关键点定位的准确性",
        "动机": "减少关键点定位任务中对大量标记数据的依赖，通过半监督学习提高模型性能",
        "方法": "提出一种自动选择可靠伪标记样本的方法，通过动态阈值构建学习课程，迭代训练模型",
        "关键词": [
            "半监督学习",
            "关键点定位",
            "伪标签",
            "动态阈值",
            "自动课程学习"
        ],
        "涉及的技术概念": {
            "伪标签（PL）": "在半监督学习中，对未标记数据自动生成的标签，用于扩展训练数据集",
            "动态阈值": "根据模型的学习进度自动调整的置信度阈值，用于筛选高质量的伪标记样本",
            "学习课程": "一种训练策略，通过逐步增加学习任务的难度或复杂性，以提高模型的学习效率和性能"
        },
        "success": true
    },
    {
        "order": 813,
        "title": "Pseudo Numerical Methods for Diffusion Models on Manifolds",
        "html": "https://iclr.cc//virtual/2022/poster/6066",
        "abstract": "Denoising Diffusion Probabilistic Models (DDPMs) can generate high-quality samples such as image and audio samples. However, DDPMs require hundreds to thousands of iterations to produce a sample. Several prior works have successfully accelerated DDPMs through adjusting the variance schedule (e.g., Improved Denoising Diffusion Probabilistic Models) or the denoising equation (e.g., Denoising Diffusion Implicit Models (DDIMs)). However, these acceleration methods cannot maintain the quality of samples and even introduce new noise at high speedup rate, which limit their practicability. To accelerate the inference process while keeping the sample quality, we provide a new perspective that DDPMs should be treated as solving differential equations on manifolds. Under such a perspective, we propose pseudo numerical methods for diffusion models (PNDMs). Specifically, we figure out how to solve differential equations on manifolds and show that DDIMs are simple cases of pseudo numerical methods. We change several classical numerical methods to corresponding pseudo numerical methods and find that pseudo linear multi-step method is the best method in most situations. According to our experiments, by directly using pre-trained models on Cifar10, CelebA and LSUN, PNDMs can generate higher quality synthetic images with only 50 steps compared with 1000-step DDIMs (20x speedup), significantly outperform DDIMs with 250 steps (by around 0.4 in FID) and have good generalization on different variance schedules.",
        "conference": "ICLR",
        "中文标题": "流形上扩散模型的伪数值方法",
        "摘要翻译": "去噪扩散概率模型（DDPMs）能够生成高质量的样本，如图像和音频样本。然而，DDPMs需要数百到数千次迭代才能生成一个样本。之前的一些工作通过调整方差计划（例如，改进的去噪扩散概率模型）或去噪方程（例如，去噪扩散隐式模型（DDIMs））成功地加速了DDPMs。然而，这些加速方法无法保持样本的质量，甚至在高速率下会引入新的噪声，这限制了它们的实用性。为了在保持样本质量的同时加速推理过程，我们提供了一个新的视角，即DDPMs应被视为在流形上求解微分方程。在这样的视角下，我们提出了扩散模型的伪数值方法（PNDMs）。具体来说，我们找出了如何在流形上求解微分方程，并表明DDIMs是伪数值方法的简单案例。我们将几种经典的数值方法改为相应的伪数值方法，并发现伪线性多步法在大多数情况下是最好的方法。根据我们的实验，通过直接在Cifar10、CelebA和LSUN上使用预训练模型，PNDMs仅用50步就能生成比1000步DDIMs（20倍加速）更高质量的合成图像，显著优于250步的DDIMs（在FID上大约高出0.4），并且对不同方差计划具有良好的泛化能力。",
        "领域": "图像生成、音频合成、深度学习加速",
        "问题": "加速去噪扩散概率模型（DDPMs）的推理过程同时保持样本质量",
        "动机": "现有的DDPMs加速方法在高速率下无法保持样本质量，甚至引入新的噪声，限制了其实用性",
        "方法": "提出将DDPMs视为在流形上求解微分方程的新视角，并基于此提出伪数值方法（PNDMs），包括伪线性多步法",
        "关键词": [
            "去噪扩散概率模型",
            "伪数值方法",
            "流形微分方程",
            "图像生成",
            "深度学习加速"
        ],
        "涉及的技术概念": {
            "去噪扩散概率模型（DDPMs）": "一种生成高质量样本的模型，但需要大量迭代",
            "伪数值方法（PNDMs）": "在流形上求解微分方程的新方法，用于加速DDPMs同时保持样本质量",
            "流形微分方程": "将DDPMs的生成过程视为在流形上求解微分方程，为加速提供理论基础"
        },
        "success": true
    },
    {
        "order": 814,
        "title": "Pyraformer: Low-Complexity Pyramidal Attention for Long-Range Time Series Modeling and Forecasting",
        "html": "https://iclr.cc//virtual/2022/poster/6827",
        "abstract": "Accurate prediction of the future given the past based on time series data is of paramount importance, since it opens the door for decision making and risk management ahead of time. In practice, the challenge is to build a flexible but parsimonious model that can capture a wide range of temporal dependencies. In this paper, we propose Pyraformer by exploring the multiresolution representation of the time series. Specifically, we introduce the pyramidal attention module (PAM) in which the inter-scale tree structure summarizes features at different resolutions and the intra-scale neighboring connections model the temporal dependencies of different ranges. Under mild conditions, the maximum length of the signal traversing path in Pyraformer is a constant (i.e., $\\mathcal O(1)$) with regard to the sequence length $L$, while its time and space complexity scale linearly with $L$. Extensive numerical results show that Pyraformer typically achieves the highest prediction accuracy in both single-step and long-range forecasting tasks with the least amount of time and memory consumption, especially when the sequence is long.",
        "conference": "ICLR",
        "中文标题": "Pyraformer：用于长距离时间序列建模与预测的低复杂度金字塔注意力机制",
        "摘要翻译": "基于时间序列数据准确预测未来对提前进行决策和风险管理至关重要。实践中，挑战在于构建一个既灵活又简洁的模型，能够捕捉广泛的时间依赖性。本文中，我们通过探索时间序列的多分辨率表示，提出了Pyraformer。具体来说，我们引入了金字塔注意力模块（PAM），其中跨尺度树结构总结了不同分辨率下的特征，而尺度内邻近连接则建模了不同范围的时间依赖性。在温和条件下，Pyraformer中信号穿越路径的最大长度相对于序列长度L是一个常数（即O(1)），而其时间和空间复杂度与L线性增长。大量数值结果表明，Pyraformer在单步和长距离预测任务中通常以最少的时间和内存消耗达到最高的预测准确度，尤其是当序列较长时。",
        "领域": "时间序列预测、深度学习、注意力机制",
        "问题": "构建一个能够有效捕捉时间序列中长期依赖关系的模型，同时保持模型的计算和存储效率。",
        "动机": "为了解决在长序列预测中模型复杂度和预测准确度之间的平衡问题，提出了一种新的注意力机制来高效建模时间序列中的多尺度依赖关系。",
        "方法": "提出Pyraformer模型，采用金字塔注意力模块（PAM）来捕捉时间序列的多分辨率特征和不同范围的时间依赖性，实现了在序列长度上的线性复杂度。",
        "关键词": [
            "时间序列预测",
            "金字塔注意力",
            "多分辨率表示",
            "长距离依赖",
            "低复杂度"
        ],
        "涉及的技术概念": {
            "金字塔注意力模块（PAM）": "用于捕捉时间序列中不同尺度的特征和依赖关系，通过跨尺度树结构和尺度内邻近连接实现。",
            "多分辨率表示": "通过分析时间序列在不同分辨率下的特征，增强模型对时间序列的理解和预测能力。",
            "线性复杂度": "Pyraformer模型在时间和空间复杂度上与序列长度成线性关系，保证了模型在处理长序列时的高效性。"
        },
        "success": true
    },
    {
        "order": 815,
        "title": "QDrop: Randomly Dropping Quantization for Extremely Low-bit Post-Training Quantization",
        "html": "https://iclr.cc//virtual/2022/poster/5893",
        "abstract": "Recently, post-training quantization (PTQ) has driven much attention to produce efficient neural networks without long-time retraining. Despite the low cost, current PTQ works always fail under the extremely low-bit setting. In this study, we pioneeringly confirm that properly incorporating activation quantization into the PTQ reconstruction benefits the final accuracy. To deeply understand the inherent reason, a theoretical framework is established, which inspires us that the flatness of the optimized low-bit model on calibration and test data is crucial. Based on the conclusion, a simple yet effective approach dubbed as \\textsc{QDrop} is proposed, which randomly drops the quantization of activations during reconstruction. Extensive experiments on various tasks including computer vision (image classification, object detection) and natural language processing (text classification and question answering) prove its superiority. With \\textsc{QDrop}, the limit of PTQ is pushed to the 2-bit activation for the first time and the accuracy boost can be up to 51.49\\%. Without bells and whistles, \\textsc{QDrop} establishes a new state of the art for PTQ.",
        "conference": "ICLR",
        "中文标题": "QDrop：随机丢弃量化以实现极低位训练后量化",
        "摘要翻译": "近年来，训练后量化（PTQ）因其无需长时间重新训练即可生成高效神经网络的能力而备受关注。尽管成本低廉，当前的PTQ工作在极低位设置下往往失败。在本研究中，我们首次确认，在PTQ重建中适当融入激活量化有利于最终精度。为了深入理解内在原因，我们建立了一个理论框架，该框架启发我们，优化后的低位模型在校准和测试数据上的平坦度至关重要。基于这一结论，我们提出了一种简单而有效的方法，称为QDrop，该方法在重建过程中随机丢弃激活的量化。在包括计算机视觉（图像分类、目标检测）和自然语言处理（文本分类和问答）在内的各种任务上的大量实验证明了其优越性。使用QDrop，PTQ的极限首次被推至2位激活，精度提升可达51.49%。无需任何修饰，QDrop为PTQ设立了新的技术标杆。",
        "领域": "模型量化、计算机视觉、自然语言处理",
        "问题": "解决在极低位设置下训练后量化（PTQ）精度下降的问题",
        "动机": "探索在PTQ重建中融入激活量化以提高模型精度的方法",
        "方法": "提出QDrop方法，在重建过程中随机丢弃激活的量化，以提高模型在校准和测试数据上的平坦度",
        "关键词": [
            "训练后量化",
            "极低位量化",
            "激活量化",
            "模型优化",
            "精度提升"
        ],
        "涉及的技术概念": {
            "训练后量化（PTQ）": "一种无需长时间重新训练即可生成高效神经网络的技术",
            "激活量化": "在模型量化过程中对激活值进行量化处理，以减少模型大小和提高运行效率",
            "平坦度": "优化后的低位模型在校准和测试数据上的性能稳定性，是影响最终精度的关键因素"
        },
        "success": true
    },
    {
        "order": 816,
        "title": "Quadtree Attention for Vision Transformers",
        "html": "https://iclr.cc//virtual/2022/poster/6822",
        "abstract": "Transformers have been successful in many vision tasks, thanks to their capability of capturing long-range dependency. However, their quadratic computational complexity poses a major obstacle for applying them to vision tasks requiring dense predictions, such as object detection, feature matching, stereo, etc. We introduce QuadTree Attention, which reduces the computational complexity from quadratic to linear. Our quadtree transformer builds token pyramids and computes attention in a coarse-to-fine manner. At each level, the top K patches with the highest attention scores are selected, such that at the next level, attention is only evaluated within the relevant regions corresponding to these top K patches. We demonstrate that quadtree attention achieves state-of-the-art performance in various vision tasks, e.g. with 4.0% improvement in feature matching on ScanNet, about 50% flops reduction in stereo matching, 0.4-1.5% improvement in top-1 accuracy on ImageNet classification, 1.2-1.8% improvement on COCO object detection, and 0.7-2.4% improvement on semantic segmentation over previous state-of-the-art transformers. The codes are available at https://github.com/Tangshitao/QuadtreeAttention.",
        "conference": "ICLR",
        "中文标题": "视觉Transformer的四叉树注意力机制",
        "摘要翻译": "Transformer因其能够捕捉长距离依赖关系，在许多视觉任务中取得了成功。然而，其二次计算复杂度成为应用于需要密集预测的视觉任务（如目标检测、特征匹配、立体视觉等）的主要障碍。我们引入了四叉树注意力机制，将计算复杂度从二次降低到线性。我们的四叉树Transformer构建了令牌金字塔，并以从粗到细的方式计算注意力。在每一层级，选择注意力分数最高的前K个补丁，使得在下一层级，注意力仅在这些前K个补丁对应的相关区域内进行评估。我们证明，四叉树注意力在各种视觉任务中实现了最先进的性能，例如在ScanNet上的特征匹配提高了4.0%，在立体匹配中减少了约50%的浮点运算，在ImageNet分类上的top-1准确率提高了0.4-1.5%，在COCO目标检测上提高了1.2-1.8%，在语义分割上比之前最先进的Transformer提高了0.7-2.4%。代码可在https://github.com/Tangshitao/QuadtreeAttention获取。",
        "领域": "特征匹配, 立体视觉, 语义分割",
        "问题": "降低Transformer在密集预测视觉任务中的计算复杂度",
        "动机": "解决Transformer因二次计算复杂度难以应用于需要密集预测的视觉任务的问题",
        "方法": "引入四叉树注意力机制，通过构建令牌金字塔和从粗到细的注意力计算，减少计算复杂度",
        "关键词": [
            "四叉树注意力",
            "视觉Transformer",
            "计算复杂度优化"
        ],
        "涉及的技术概念": {
            "四叉树注意力": "一种将计算复杂度从二次降低到线性的注意力机制，通过构建令牌金字塔和从粗到细的注意力计算实现",
            "令牌金字塔": "在四叉树Transformer中用于表示不同层级信息的结构，支持从粗到细的注意力计算",
            "从粗到细的注意力计算": "一种注意力计算策略，先在粗粒度层级筛选重要区域，再在细粒度层级进行详细计算，以提高效率"
        },
        "success": true
    },
    {
        "order": 817,
        "title": "Quantitative Performance Assessment of CNN Units via Topological Entropy Calculation",
        "html": "https://iclr.cc//virtual/2022/poster/7129",
        "abstract": " Identifying the status of individual network units is critical for understanding the mechanism of convolutional neural networks (CNNs). However, it is still challenging to reliably give a general indication of unit status, especially for units in different network models. To this end, we propose a novel method for quantitatively clarifying the status of single unit in CNN using algebraic topological tools. Unit status is indicated via the calculation of a defined topological-based entropy, called feature entropy, which measures the degree of chaos of the global spatial pattern hidden in the unit for a category. In this way, feature entropy could provide an accurate indication of status for units in different networks with diverse situations like weight-rescaling operation. Further, we show that feature entropy decreases as the layer goes deeper and shares almost simultaneous trend with loss during training. We show that by investigating the feature entropy of units on only training data, it could give discrimination between networks with different generalization ability from the view of the effectiveness of feature representations.",
        "conference": "ICLR",
        "中文标题": "通过拓扑熵计算对CNN单元进行定量性能评估",
        "摘要翻译": "识别单个网络单元的状态对于理解卷积神经网络（CNNs）的机制至关重要。然而，可靠地给出单元状态的通用指示仍然具有挑战性，特别是对于不同网络模型中的单元。为此，我们提出了一种新颖的方法，利用代数拓扑工具定量阐明CNN中单个单元的状态。单元状态通过计算一种定义的基于拓扑的熵（称为特征熵）来指示，该熵测量了单元中隐藏的全局空间模式对于一个类别的混沌程度。这样，特征熵可以为不同网络中的单元提供准确的状态指示，包括权重重新缩放操作等多种情况。此外，我们展示了特征熵随着层数的加深而减小，并且在训练过程中与损失几乎同步变化。我们表明，通过仅研究训练数据上单元的特征熵，可以从特征表示的有效性角度区分具有不同泛化能力的网络。",
        "领域": "卷积神经网络分析、深度学习模型解释、网络单元性能评估",
        "问题": "如何可靠地评估和指示卷积神经网络中单个单元的状态，尤其是在不同网络模型中。",
        "动机": "为了更深入地理解卷积神经网络的工作机制，并提供一个通用的方法来评估网络单元的状态。",
        "方法": "提出了一种基于代数拓扑工具的新方法，通过计算特征熵来定量评估CNN单元的状态。",
        "关键词": [
            "卷积神经网络",
            "拓扑熵",
            "特征熵",
            "网络单元评估",
            "模型解释"
        ],
        "涉及的技术概念": {
            "特征熵": "一种基于拓扑的熵，用于测量CNN单元中隐藏的全局空间模式的混沌程度，从而指示单元的状态。",
            "代数拓扑工具": "用于分析和量化CNN单元状态的高级数学工具。",
            "权重重新缩放操作": "一种网络操作，特征熵能够在这种操作下准确指示单元状态。"
        },
        "success": true
    },
    {
        "order": 818,
        "title": "QUERY EFFICIENT DECISION BASED SPARSE ATTACKS AGAINST BLACK-BOX DEEP LEARNING MODELS",
        "html": "https://iclr.cc//virtual/2022/poster/6170",
        "abstract": "Despite our best efforts, deep learning models remain highly vulnerable to even tiny adversarial perturbations applied to the inputs. The ability to extract information from solely the output of a machine learning model to craft adversarial perturbations to black-box models is a practical threat against real-world systems, such as Machine Learning as a Service (MLaaS), particularly $sparse~attacks$. The realization of sparse attacks in black-box settings demonstrates that machine learning models are more vulnerable than we believe. Because, these attacks aim to $minimize~the~number~of~perturbed~pixels$—measured by $l_0$ norm—required to mislead a model by $solely$ observing the decision ($the~predicted~label$) returned to a model query; the so-called $decision-based~setting$. But, such an attack leads to an NP-hard optimization problem. We develop an evolution-based algorithm—$SparseEvo$—for the problem and evaluate against both convolutional deep neural networks and $vision~transformers$. Notably, vision transformers are yet to be investigated under a decision-based attack setting. SparseEvo requires significantly fewer queries than the state-of-the-art sparse attack $Pointwise$ for both untargeted and targeted attacks. The attack algorithm, although conceptually simple, is competitive with only a limited query budget against the state-of-the-art gradient-based $white-box$ attacks in standard computer vision tasks such as $ImageNet$. Importantly, the query efficient SparseEvo, along with decision-based attacks, in general, raise new questions regarding the safety of deployed systems and poses new directions to study and understand the robustness of machine learning models.",
        "conference": "ICLR",
        "中文标题": "针对黑盒深度学习模型的高效查询决策稀疏攻击",
        "摘要翻译": "尽管我们尽了最大努力，深度学习模型仍然极易受到输入中微小对抗性扰动的影响。仅从机器学习模型的输出中提取信息来为黑盒模型制作对抗性扰动的能力，是对现实世界系统（如机器学习即服务（MLaaS））的实际威胁，尤其是稀疏攻击。在黑盒设置中实现稀疏攻击表明，机器学习模型比我们想象的更脆弱。因为这些攻击旨在通过仅观察返回给模型查询的决策（预测标签）来最小化误导模型所需的扰动像素数量（以l0范数衡量）；即所谓的基于决策的设置。但是，这样的攻击导致了一个NP难优化问题。我们为这个问题开发了一种基于进化的算法——SparseEvo——并对卷积深度神经网络和视觉变换器进行了评估。值得注意的是，视觉变换器在基于决策的攻击设置下尚未被研究。SparseEvo在无目标和有目标攻击中所需的查询数量显著少于最先进的稀疏攻击Pointwise。这种攻击算法虽然在概念上简单，但在标准计算机视觉任务（如ImageNet）中，仅用有限的查询预算就能与最先进的基于梯度的白盒攻击竞争。重要的是，查询高效的SparseEvo以及一般的基于决策的攻击，对部署系统的安全性提出了新的问题，并为研究和理解机器学习模型的鲁棒性提供了新的方向。",
        "领域": "对抗性攻击、深度学习安全、计算机视觉",
        "问题": "在黑盒设置下，如何高效地实施稀疏对抗性攻击以最小化扰动像素数量，同时仅依赖模型的输出决策。",
        "动机": "揭示机器学习模型在面对仅依赖输出决策的稀疏攻击时的脆弱性，推动对模型鲁棒性的深入理解和安全性的提升。",
        "方法": "开发了一种基于进化的算法SparseEvo，用于在黑盒设置下实施稀疏对抗性攻击，该算法在减少查询次数的同时保持攻击效果。",
        "关键词": [
            "稀疏攻击",
            "黑盒攻击",
            "对抗性机器学习",
            "进化算法",
            "模型鲁棒性"
        ],
        "涉及的技术概念": {
            "稀疏攻击": "一种对抗性攻击方法，旨在通过最小化扰动像素数量（l0范数）来误导模型，特别适用于黑盒设置。",
            "基于决策的攻击": "攻击者仅依赖模型的输出决策（如预测标签）来制作对抗性样本，无需了解模型内部细节。",
            "进化算法": "SparseEvo采用的一种优化方法，通过模拟自然选择过程来寻找有效的对抗性扰动，适用于解决NP难优化问题。"
        },
        "success": true
    },
    {
        "order": 819,
        "title": "Query Embedding on Hyper-Relational Knowledge Graphs",
        "html": "https://iclr.cc//virtual/2022/poster/6321",
        "abstract": "Multi-hop logical reasoning is an established problem in the field of representation learning on knowledge graphs (KGs). It subsumes both one-hop link prediction as well as other more complex types of logical queries. Existing algorithms operate only on classical, triple-based graphs, whereas modern KGs often employ a hyper-relational modeling paradigm. In this paradigm, typed edges may have several key-value pairs known as qualifiers that provide fine-grained context for facts. In queries, this context modifies the meaning of relations, and usually reduces the answer set. Hyper-relational queries are often observed in real-world KG applications, and existing approaches for approximate query answering cannot make use of qualifier pairs. In this work, we bridge this gap and extend the multi-hop reasoning problem to hyper-relational KGs allowing to tackle this new type of complex queries. Building upon recent advancements in Graph Neural Networks and query embedding techniques, we study how to embed and answer hyper-relational conjunctive queries. Besides that, we propose a method to answer such queries and demonstrate in our experiments that qualifiers improve query answering on a diverse set of query patterns.",
        "conference": "ICLR",
        "中文标题": "超关系知识图上的查询嵌入",
        "摘要翻译": "多跳逻辑推理是知识图（KGs）表示学习领域中的一个既定问题。它既包括单跳链接预测，也包括其他更复杂的逻辑查询类型。现有算法仅适用于基于三元组的经典图，而现代知识图往往采用超关系建模范式。在这一范式中，类型化的边可能具有几个称为限定符的键值对，这些限定符为事实提供了细粒度的上下文。在查询中，这种上下文修改了关系的含义，并且通常会减少答案集。超关系查询在现实世界的知识图应用中经常被观察到，而现有的近似查询应答方法无法利用限定符对。在这项工作中，我们填补了这一空白，并将多跳推理问题扩展到超关系知识图，以解决这种新型复杂查询。基于图神经网络和查询嵌入技术的最新进展，我们研究了如何嵌入和回答超关系联合查询。除此之外，我们提出了一种回答此类查询的方法，并在我们的实验中证明了限定符在多种查询模式上改进了查询应答。",
        "领域": "知识图谱表示学习、图神经网络、多跳逻辑推理",
        "问题": "如何在超关系知识图上进行有效的多跳逻辑推理和查询应答",
        "动机": "填补现有方法无法处理超关系知识图中限定符对查询应答影响的空白",
        "方法": "基于图神经网络和查询嵌入技术，提出了一种能够处理超关系联合查询的方法",
        "关键词": [
            "超关系知识图",
            "查询嵌入",
            "多跳逻辑推理",
            "图神经网络",
            "限定符"
        ],
        "涉及的技术概念": {
            "超关系知识图": "一种扩展的知识图建模范式，允许边具有多个键值对限定符，提供更丰富的事实上下文",
            "查询嵌入": "将查询转换为低维向量表示的技术，便于在知识图上进行高效的查询应答",
            "图神经网络": "用于处理图结构数据的深度学习模型，能够捕捉图中节点和边的复杂关系"
        },
        "success": true
    },
    {
        "order": 820,
        "title": "R4D: Utilizing Reference Objects for Long-Range Distance Estimation",
        "html": "https://iclr.cc//virtual/2022/poster/6625",
        "abstract": "Estimating the distance of objects is a safety-critical task for autonomous driving. Focusing on short-range objects, existing methods and datasets neglect the equally important long-range objects. In this paper, we introduce a challenging and under-explored task, which we refer to as Long-Range Distance Estimation, as well as two datasets to validate new methods developed for this task. We then proposeR4D, the first framework to accurately estimate the distance of long-range objects by using references with known distances in the scene. Drawing inspiration from human perception, R4D builds a graph by connecting a target object to all references. An edge in the graph encodes the relative distance information between a pair of target and reference objects. An attention module is then used to weigh the importance of reference objects and combine them into one target object distance prediction. Experiments on the two proposed datasets demonstrate the effectiveness and robustness of R4D by showing significant improvements compared to existing baselines. We’re looking to make the proposed dataset, Waymo OpenDataset - Long-Range Labels, available publicly at waymo.com/open/download.",
        "conference": "ICLR",
        "中文标题": "R4D：利用参考物体进行远距离距离估计",
        "摘要翻译": "估计物体的距离是自动驾驶中一项安全关键的任务。现有的方法和数据集主要关注短距离物体，而忽视了同样重要的远距离物体。在本文中，我们引入了一个具有挑战性且未被充分探索的任务，我们称之为远距离距离估计，以及两个用于验证为此任务开发的新方法的数据集。然后，我们提出了R4D，这是第一个通过使用场景中已知距离的参考物体来准确估计远距离物体距离的框架。受到人类感知的启发，R4D通过将目标物体连接到所有参考物体来构建一个图。图中的一条边编码了一对目标和参考物体之间的相对距离信息。然后使用一个注意力模块来权衡参考物体的重要性，并将它们合并为一个目标物体距离预测。在两个提出的数据集上的实验证明了R4D的有效性和鲁棒性，与现有基线相比显示出显著的改进。我们计划将提出的数据集Waymo OpenDataset - Long-Range Labels公开在waymo.com/open/download上。",
        "领域": "自动驾驶视觉感知",
        "问题": "现有方法在远距离物体距离估计上的不足",
        "动机": "解决自动驾驶中远距离物体距离估计的挑战，提高安全性",
        "方法": "通过构建目标物体与参考物体之间的图，利用注意力模块整合参考信息进行距离预测",
        "关键词": [
            "远距离距离估计",
            "参考物体",
            "注意力机制",
            "自动驾驶",
            "图构建"
        ],
        "涉及的技术概念": {
            "图构建": "通过连接目标物体和参考物体构建图，编码相对距离信息",
            "注意力机制": "用于权衡不同参考物体对目标物体距离预测的重要性",
            "远距离距离估计": "专注于估计远距离物体的距离，解决自动驾驶中的安全关键任务"
        },
        "success": true
    },
    {
        "order": 821,
        "title": "R5: Rule Discovery with Reinforced and Recurrent Relational Reasoning",
        "html": "https://iclr.cc//virtual/2022/poster/7053",
        "abstract": "Systematicity, i.e., the ability to recombine known parts and rules to form new sequences while reasoning over relational data, is critical to machine intelligence. A model with strong systematicity is able to train on small-scale tasks and generalize to large-scale tasks. In this paper, we propose R5, a relational reasoning framework based on reinforcement learning that reasons over relational graph data and explicitly mines underlying compositional logical rules from observations. R5 has strong systematicity and being robust to noisy data. It consists of a policy value network equipped with Monte Carlo Tree Search to perform recurrent relational prediction and a backtrack rewriting mechanism for rule mining. By alternately applying the two components, R5 progressively learns a set of explicit rules from data and performs explainable and generalizable relation prediction. We conduct extensive evaluations on multiple datasets. Experimental results show that R5 outperforms various embedding-based and rule induction baselines on relation prediction tasks while achieving a high recall rate in discovering ground truth rules. ",
        "conference": "ICLR",
        "中文标题": "R5：通过强化和循环关系推理的规则发现",
        "摘要翻译": "系统性，即在关系数据推理过程中重新组合已知部分和规则以形成新序列的能力，对机器智能至关重要。具有强系统性的模型能够在小规模任务上训练并推广到大规模任务。在本文中，我们提出了R5，一个基于强化学习的关系推理框架，它推理关系图数据并明确从观察中挖掘潜在的组合逻辑规则。R5具有很强的系统性，并且对噪声数据具有鲁棒性。它由一个配备蒙特卡洛树搜索的策略价值网络组成，用于执行循环关系预测，以及一个用于规则挖掘的回溯重写机制。通过交替应用这两个组件，R5逐步从数据中学习一组明确的规则，并执行可解释和可推广的关系预测。我们在多个数据集上进行了广泛的评估。实验结果表明，R5在关系预测任务上优于各种基于嵌入和规则归纳的基线，同时在发现真实规则方面实现了高召回率。",
        "领域": "关系推理、强化学习、图数据挖掘",
        "问题": "如何在关系数据中系统地发现和组合逻辑规则以提高机器智能的推理能力",
        "动机": "为了解决机器智能在处理关系数据时缺乏系统性推理能力的问题，特别是在小规模训练数据上训练后推广到大规模任务的能力",
        "方法": "提出了一个结合强化学习和蒙特卡洛树搜索的关系推理框架R5，通过策略价值网络和回溯重写机制交替工作，从数据中学习明确的规则并进行关系预测",
        "关键词": [
            "关系推理",
            "强化学习",
            "规则挖掘",
            "系统性",
            "图数据"
        ],
        "涉及的技术概念": {
            "强化学习": "用于构建策略价值网络，指导模型在关系数据中进行有效的规则发现和预测",
            "蒙特卡洛树搜索": "用于优化策略价值网络的决策过程，提高关系预测的准确性和效率",
            "回溯重写机制": "用于从观察中挖掘和组合潜在的逻辑规则，增强模型的规则发现能力和解释性"
        },
        "success": true
    },
    {
        "order": 822,
        "title": "Random matrices in service of ML footprint: ternary random features with no performance loss",
        "html": "https://iclr.cc//virtual/2022/poster/6229",
        "abstract": "In this article, we investigate the spectral behavior of random features kernel matrices of the type ${\\bf K} = \\mathbb{E}_{{\\bf w}} \\left[\\sigma\\left({\\bf w}^{\\sf T}{\\bf x}_i\\right)\\sigma\\left({\\bf w}^{\\sf T}{\\bf x}_j\\right)\\right]_{i,j=1}^n$, with nonlinear function $\\sigma(\\cdot)$, data ${\\bf x}_1, \\ldots, {\\bf x}_n \\in \\mathbb{R}^p$, and random projection vector ${\\bf w} \\in \\mathbb{R}^p$ having i.i.d. entries. In a high-dimensional setting where the number of data $n$ and their dimension $p$ are both large and comparable, we show, under a Gaussian mixture model for the data, that the eigenspectrum of ${\\bf K}$ is independent of the distribution of the i.i.d.(zero-mean and unit-variance) entries of ${\\bf w}$, and only depends on $\\sigma(\\cdot)$ via its (generalized) Gaussian moments $\\mathbb{E}_{z\\sim \\mathcal N(0,1)}[\\sigma'(z)]$ and $\\mathbb{E}_{z\\sim \\mathcal N(0,1)}[\\sigma''(z)]$. As a result, for any kernel matrix ${\\bf K}$ of the form above, we propose a novel random features technique, called Ternary Random Features (TRFs), that (i) asymptotically yields the same limiting kernel as the original ${\\bf K}$ in a spectral sense and (ii) can be computed and stored much more efficiently, by wisely tuning (in a data-dependent manner) the function $\\sigma$ and the random vector ${\\bf w}$, both taking values in $\\{-1,0,1\\}$. The computation of the proposed random features requires no multiplication, and a factor of $b$ times less bits for storage compared to classical random features such as random Fourier features, with $b$ the number of bits to store full precision values. Besides, it appears in our experiments on real data that the substantial gains in computation and storage are accompanied with somewhat improved performances compared to state-of-the-art random features methods.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "服务于机器学习足迹的随机矩阵：无性能损失的三元随机特征",
        "摘要翻译": "本文研究了随机特征核矩阵的光谱行为，该矩阵类型为${\\bf K} = \\mathbb{E}_{{\\bf w}} \\left[\\sigma\\left({\\bf w}^{\\sf T}{\\bf x}_i\\right)\\sigma\\left({\\bf w}^{\\sf T}{\\bf x}_j\\right)\\right]_{i,j=1}^n$，其中非线性函数为$\\sigma(\\cdot)$，数据为${\\bf x}_1, \\ldots, {\\bf x}_n \\in \\mathbb{R}^p$，随机投影向量为${\\bf w} \\in \\mathbb{R}^p$，且${\\bf w}$的条目是独立同分布的。在高维设置中，数据量$n$和维度$p$都很大且相当，我们证明，在数据的高斯混合模型下，${\\bf K}$的特征谱与${\\bf w}$的独立同分布（零均值和单位方差）条目的分布无关，仅取决于$\\sigma(\\cdot)$通过其（广义）高斯矩$\\mathbb{E}_{z\\sim \\mathcal N(0,1)}[\\sigma'(z)]$和$\\mathbb{E}_{z\\sim \\mathcal N(0,1)}[\\sigma''(z)]$。因此，对于任何上述形式的核矩阵${\\bf K}$，我们提出了一种新颖的随机特征技术，称为三元随机特征（TRFs），它（i）在光谱意义上渐近地产生与原始${\\bf K}$相同的极限核，并且（ii）通过明智地调整（以数据相关的方式）函数$\\sigma$和随机向量${\\bf w}$，可以更有效地计算和存储，两者均在$\\\\{-1,0,1\\\\}$中取值。与诸如随机傅里叶特征之类的经典随机特征相比，所提出的随机特征的计算不需要乘法，并且存储所需的位数减少了$b$倍，其中$b$是存储全精度值的位数。此外，我们在真实数据上的实验表明，与最先进的随机特征方法相比，计算和存储方面的显着收益伴随着性能的某种程度的提高。",
        "领域": "核方法、降维、随机特征",
        "问题": "如何降低随机特征方法的计算和存储成本，同时保持甚至提升性能。",
        "动机": "传统的随机特征方法在处理大规模数据时，计算和存储成本较高，限制了其应用。为了克服这些限制，研究人员探索更高效的随机特征表示方法。",
        "方法": "提出了一种名为三元随机特征（TRFs）的新型随机特征技术，通过将随机向量和非线性函数的值限制在{-1, 0, 1}中，减少了计算和存储所需的资源。同时，通过数据依赖的方式调整函数和随机向量，保证了TRFs在光谱意义上与原始核函数渐近等价。",
        "关键词": [
            "三元随机特征",
            "随机特征核矩阵",
            "高斯混合模型",
            "降维",
            "光谱分析"
        ],
        "涉及的技术概念": {
            "随机特征": "一种用于近似核函数的降维技术，通过将数据映射到随机选择的特征空间来降低计算复杂度。",
            "核矩阵": "描述数据点之间相似度的矩阵，是许多机器学习算法的基础。"
        }
    },
    {
        "order": 823,
        "title": "Real-Time Neural Voice Camouflage",
        "html": "https://iclr.cc//virtual/2022/poster/6986",
        "abstract": "Automatic speech recognition systems have created exciting possibilities for applications, however they also enable opportunities for systematic eavesdropping.We propose a method to camouflage a person's voice from these systems without inconveniencing the conversation between people in the room. Standard adversarial attacks are not effective in real-time streaming situations because the characteristics of the signal will have changed by the time the attack is executed. We introduce predictive adversarial attacks, which achieves real-time performance by forecasting the attack vector that will be the most effective in the future. Under real-time constraints, our method jams the established speech recognition system DeepSpeech 3.9x more than online projected gradient descent as measured through word error rate, and 6.6x more as measured through character error rate. We furthermore demonstrate our approach is practically effective in realistic environments with complex scene geometries. ",
        "conference": "ICLR",
        "中文标题": "实时神经语音伪装",
        "摘要翻译": "自动语音识别系统为应用创造了令人兴奋的可能性，然而它们也为系统性窃听提供了机会。我们提出了一种方法，可以在不干扰房间内人员对话的情况下，将人的语音从这些系统中伪装起来。标准的对抗性攻击在实时流式情境中并不有效，因为信号的特征在执行攻击时已经改变。我们引入了预测性对抗性攻击，通过预测未来最有效的攻击向量来实现实时性能。在实时约束下，我们的方法通过词错误率衡量，对已建立的语音识别系统DeepSpeech的干扰比在线投影梯度下降法多3.9倍，通过字符错误率衡量多6.6倍。我们进一步证明了我们的方法在具有复杂场景几何的现实环境中实际有效。",
        "领域": "语音识别对抗攻击、实时语音处理、隐私保护技术",
        "问题": "如何在实时语音流中有效伪装语音，以防止自动语音识别系统的窃听，同时不干扰正常对话。",
        "动机": "随着自动语音识别系统的广泛应用，隐私保护成为一个重要问题，尤其是在防止系统性窃听方面。",
        "方法": "提出预测性对抗性攻击方法，通过预测未来最有效的攻击向量，实现在实时语音流中对语音识别系统的有效干扰。",
        "关键词": [
            "语音伪装",
            "对抗性攻击",
            "实时处理",
            "隐私保护",
            "语音识别"
        ],
        "涉及的技术概念": {
            "预测性对抗性攻击": "通过预测未来最有效的攻击向量，实现在实时语音流中对语音识别系统的干扰。",
            "实时性能": "在实时约束下，确保攻击方法能够即时响应并有效干扰语音识别系统。",
            "DeepSpeech": "一个已建立的语音识别系统，作为本研究中对抗性攻击的目标。"
        },
        "success": true
    },
    {
        "order": 824,
        "title": "Recursive Disentanglement Network",
        "html": "https://iclr.cc//virtual/2022/poster/6663",
        "abstract": "Disentangled feature representation is essential for data-efficient learning. The feature space of deep models is inherently compositional. Existing $\\beta$-VAE-based methods, which only apply disentanglement regularization to the resulting embedding space of deep models, cannot effectively regularize such compositional feature space, resulting in unsatisfactory disentangled results. In this paper, we formulate the compositional disentanglement learning problem from an information-theoretic perspective and propose a recursive disentanglement network (RecurD) that propagates regulatory inductive bias recursively across the compositional feature space during disentangled representation learning. Experimental studies demonstrate that RecurD outperforms $\\beta$-VAE and several of its state-of-the-art variants on disentangled representation learning and enables more data-efficient downstream machine learning tasks.",
        "conference": "ICLR",
        "中文标题": "递归解缠网络",
        "摘要翻译": "解缠特征表示对于数据高效学习至关重要。深度模型的特征空间本质上是组合性的。现有的基于β-VAE的方法，仅对深度模型的结果嵌入空间应用解缠正则化，无法有效正则化这种组合特征空间，导致解缠结果不尽人意。本文从信息论的角度制定了组合解缠学习问题，并提出了一种递归解缠网络（RecurD），在解缠表示学习过程中递归传播调节性归纳偏置跨越组合特征空间。实验研究表明，RecurD在解缠表示学习上优于β-VAE及其几种最先进的变体，并能够实现更高效的下游机器学习任务。",
        "领域": "特征解缠、表示学习、数据高效学习",
        "问题": "如何有效正则化深度模型的组合特征空间以实现更好的解缠特征表示",
        "动机": "现有的β-VAE方法在解缠表示学习中无法有效正则化组合特征空间，导致解缠效果不理想",
        "方法": "提出递归解缠网络（RecurD），通过递归传播调节性归纳偏置跨越组合特征空间",
        "关键词": [
            "递归解缠网络",
            "组合特征空间",
            "信息论",
            "数据高效学习",
            "表示学习"
        ],
        "涉及的技术概念": {
            "递归解缠网络（RecurD）": "在解缠表示学习过程中递归传播调节性归纳偏置跨越组合特征空间的网络",
            "组合特征空间": "深度模型特征空间的本质特性，由多个特征组合而成",
            "信息论": "从信息论的角度制定组合解缠学习问题，提供理论基础"
        },
        "success": true
    },
    {
        "order": 825,
        "title": "Recycling Model Updates in Federated Learning: Are Gradient Subspaces Low-Rank?",
        "html": "https://iclr.cc//virtual/2022/poster/6546",
        "abstract": "In this paper, we question the rationale behind propagating large numbers of parameters through a distributed system during federated learning. We start by examining the rank characteristics of the subspace spanned by gradients (i.e., the gradient-space) in centralized model training, and observe that the gradient-space often consists of a few leading principal components accounting for an overwhelming majority (95-99%) of the explained variance. Motivated by this, we propose the 'Look-back Gradient Multiplier' (LBGM) algorithm, which utilizes this low-rank property of the gradient-space in federated learning. Operationally, LBGM recycles the gradients between model update rounds to significantly reduce the number of parameters to be propagated through the system. We analytically characterize the convergence behavior of LBGM, revealing the nature of the trade-off between communication savings and model performance. Our subsequent experimental results demonstrate the improvement LBGM obtains on communication overhead compared to federated learning baselines. Additionally, we show that LBGM is a general plug-and-play algorithm that can be used standalone or stacked on top of existing sparsification techniques for distributed model training.",
        "conference": "ICLR",
        "中文标题": "联邦学习中的模型更新回收：梯度子空间是低秩的吗？",
        "摘要翻译": "在本文中，我们对联邦学习过程中通过分布式系统传播大量参数的合理性提出了质疑。我们首先考察了集中式模型训练中梯度（即梯度空间）所跨越子空间的秩特性，并观察到梯度空间通常由少数主导主成分构成，这些成分占据了绝大部分（95-99%）的解释方差。受此启发，我们提出了‘回顾梯度乘数’（LBGM）算法，该算法利用联邦学习中梯度空间的这一低秩特性。操作上，LBGM在模型更新轮次之间回收梯度，从而显著减少了需要通过系统传播的参数数量。我们分析了LBGM的收敛行为，揭示了通信节省与模型性能之间权衡的本质。随后的实验结果表明，与联邦学习基线相比，LBGM在通信开销上取得了改进。此外，我们还展示了LBGM是一种通用的即插即用算法，可以单独使用或堆叠在现有的分布式模型训练稀疏化技术之上。",
        "领域": "联邦学习、分布式机器学习、梯度优化",
        "问题": "减少联邦学习中的通信开销",
        "动机": "观察到梯度空间具有低秩特性，可以利用这一特性减少通信量",
        "方法": "提出‘回顾梯度乘数’（LBGM）算法，利用梯度空间的低秩特性回收梯度",
        "关键词": [
            "联邦学习",
            "梯度回收",
            "低秩特性",
            "通信优化",
            "LBGM算法"
        ],
        "涉及的技术概念": {
            "梯度空间": "梯度所跨越的子空间，具有低秩特性",
            "回顾梯度乘数（LBGM）": "利用梯度空间的低秩特性回收梯度的算法",
            "通信开销": "联邦学习中的主要挑战之一，LBGM旨在减少这一开销"
        },
        "success": true
    },
    {
        "order": 826,
        "title": "Reducing Excessive Margin to Achieve a Better Accuracy vs. Robustness Trade-off",
        "html": "https://iclr.cc//virtual/2022/poster/5907",
        "abstract": "While adversarial training has become the de facto approach for training robust classifiers, it leads to a drop in accuracy. This has led to prior works postulating that accuracy is inherently at odds with robustness. Yet, the phenomenon remains inexplicable. In this paper, we closely examine the changes induced in the decision boundary of a deep network during adversarial training. We find that adversarial training leads to unwarranted increase in the margin along certain adversarial directions, thereby hurting accuracy. Motivated by this observation, we present a novel algorithm, called Helper-based Adversarial Training (HAT), to reduce this effect by incorporating additional wrongly labelled examples during training. Our proposed method provides a notable improvement in accuracy without compromising robustness. It achieves a better trade-off between accuracy and robustness in comparison to existing defenses. Code is available at https://github.com/imrahulr/hat.",
        "conference": "ICLR",
        "中文标题": "减少过度边际以实现更好的准确性与鲁棒性权衡",
        "摘要翻译": "尽管对抗训练已成为训练鲁棒分类器的实际标准方法，但它会导致准确性的下降。这使得先前的工作假设准确性与鲁棒性本质上是相互矛盾的。然而，这一现象仍然无法解释。在本文中，我们仔细研究了对抗训练期间深度网络决策边界引起的变化。我们发现对抗训练会导致沿某些对抗方向的不必要边际增加，从而损害准确性。基于这一观察，我们提出了一种名为基于辅助的对抗训练（HAT）的新算法，通过在训练过程中加入额外错误标记的样本来减少这种影响。我们提出的方法在不损害鲁棒性的情况下显著提高了准确性。与现有防御方法相比，它在准确性和鲁棒性之间实现了更好的权衡。代码可在https://github.com/imrahulr/hat获取。",
        "领域": "对抗训练、深度学习安全、图像分类",
        "问题": "对抗训练在提高模型鲁棒性的同时导致准确性下降的问题",
        "动机": "探索对抗训练导致准确性下降的原因，并提出解决方案以实现准确性与鲁棒性的更好平衡",
        "方法": "提出基于辅助的对抗训练（HAT）算法，通过引入错误标记样本减少对抗训练中的不必要边际增加",
        "关键词": [
            "对抗训练",
            "准确性",
            "鲁棒性",
            "决策边界",
            "HAT"
        ],
        "涉及的技术概念": {
            "对抗训练": "一种通过引入对抗样本来提高模型鲁棒性的训练方法",
            "决策边界": "分类模型中区分不同类别的界限，对抗训练会改变其形状和位置",
            "HAT算法": "一种新型对抗训练方法，旨在通过减少不必要的边际增加来提高模型的准确性和鲁棒性"
        },
        "success": true
    },
    {
        "order": 827,
        "title": "RegionViT: Regional-to-Local Attention for Vision Transformers",
        "html": "https://iclr.cc//virtual/2022/poster/6345",
        "abstract": "Vision transformer (ViT) has recently shown its strong capability in achieving comparable results to convolutional neural networks (CNNs) on image classification. However, vanilla ViT simply inherits the same architecture from the natural language processing directly, which is often not optimized for vision applications. Motivated by this, in this paper, we propose a new architecture that adopts the pyramid structure and employ novel regional-to-local attention rather than global self-attention in vision transformers. More specifically, our model first generates regional tokens and local tokens from an image with different patch sizes, where each regional token is associated with a set of local tokens based on the spatial location. The regional-to-local attention includes two steps: first, the regional self-attention extracts global information among all regional tokens and then the local self-attention exchanges the information among one regional token and the associated local tokens via self-attention. Therefore, even though local self-attention confines the scope in a local region but it can still receive global information.Extensive experiments on four vision tasks, including image classification, object and keypoint detection, semantics segmentation and action recognition, show that our approach outperforms or is on par with state-of-the-art ViT variants including many concurrent works. Our source codes and models are available at \\url{https://github.com/IBM/RegionViT}.",
        "conference": "ICLR",
        "中文标题": "RegionViT：视觉Transformer的区域到局部注意力机制",
        "摘要翻译": "视觉Transformer（ViT）最近在图像分类任务中显示出其强大的能力，能够达到与卷积神经网络（CNN）相媲美的结果。然而，原始的ViT直接从自然语言处理中继承了相同的架构，这通常不适合视觉应用。受此启发，本文提出了一种新架构，该架构采用金字塔结构，并在视觉Transformer中采用新颖的区域到局部注意力机制，而非全局自注意力。具体来说，我们的模型首先从图像中生成不同补丁大小的区域标记和局部标记，其中每个区域标记基于空间位置与一组局部标记相关联。区域到局部注意力包括两个步骤：首先，区域自注意力在所有区域标记之间提取全局信息；然后，局部自注意力通过自注意力在一个区域标记和相关的局部标记之间交换信息。因此，尽管局部自注意力将范围限制在局部区域，但它仍然可以接收全局信息。在四个视觉任务上的大量实验，包括图像分类、物体和关键点检测、语义分割和动作识别，表明我们的方法优于或与包括许多同期工作在内的最先进的ViT变体相当。我们的源代码和模型可在https://github.com/IBM/RegionViT获取。",
        "领域": "图像分类, 语义分割, 动作识别",
        "问题": "原始ViT架构直接从自然语言处理继承，未针对视觉应用优化",
        "动机": "提出一种更适合视觉应用的Transformer架构，通过区域到局部注意力机制提升性能",
        "方法": "采用金字塔结构和区域到局部注意力机制，首先生成区域和局部标记，然后通过两步注意力机制交换信息",
        "关键词": [
            "视觉Transformer",
            "区域到局部注意力",
            "金字塔结构",
            "自注意力机制",
            "图像分类"
        ],
        "涉及的技术概念": {
            "视觉Transformer": "一种基于自注意力机制的模型，用于处理视觉任务",
            "区域到局部注意力": "一种新颖的注意力机制，首先在区域级别提取全局信息，然后在局部级别交换信息",
            "金字塔结构": "一种多尺度表示方法，用于在不同层次上处理图像信息"
        },
        "success": true
    },
    {
        "order": 828,
        "title": "Regularized Autoencoders for Isometric Representation Learning",
        "html": "https://iclr.cc//virtual/2022/poster/5986",
        "abstract": "The recent success of autoencoders for representation learning can be traced in large part to the addition of a regularization term.Such regularized autoencoders ``constrain' the representation so as to prevent overfitting to the data while producing a parsimonious generative model. A regularized autoencoder should in principle learn not only the data manifold, but also a set of geometry-preserving coordinates for the latent representation space; by geometry-preserving we mean that the latent space representation should attempt to preserve actual distances and angles on the data manifold. In this paper we first formulate a hierarchy for geometry-preserving mappings (isometry, conformal mapping of degree $k$, area-preserving mappings). We then show that a conformal regularization term of degree zero -- i.e., one that attempts to preserve angles and relative distances, instead of angles and exact distances -- produces data representations that are superior to other existing methods. Applying our algorithm to an unsupervised information retrieval task for CelebA data with 40 annotations, we achieve 79\\% precision at five retrieved images, an improvement of more than 10\\% compared to recent related work. Code is available at https://github.com/Gabe-YHLee/IRVAE-public.",
        "conference": "ICLR",
        "中文标题": "正则化自编码器用于等距表示学习",
        "摘要翻译": "自编码器在表示学习方面的近期成功很大程度上可以归因于正则化项的加入。这类正则化自编码器通过‘约束’表示来防止对数据的过拟合，同时生成一个简约的生成模型。理论上，正则化自编码器不仅应该学习数据流形，还应该为潜在表示空间学习一组保持几何的坐标；所谓保持几何，我们指的是潜在空间表示应该尝试保持数据流形上的实际距离和角度。在本文中，我们首先为保持几何的映射（等距、k度共形映射、保面积映射）制定了一个层次结构。然后我们展示了一个零度的共形正则化项——即一个尝试保持角度和相对距离，而不是角度和精确距离的正则化项——产生的数据表示优于其他现有方法。将我们的算法应用于具有40个注释的CelebA数据的无监督信息检索任务，我们在检索到的五张图像中实现了79%的精确度，与最近的相关工作相比提高了10%以上。代码可在https://github.com/Gabe-YHLee/IRVAE-public获取。",
        "领域": "表示学习、生成模型、无监督学习",
        "问题": "如何在自编码器的表示学习中保持数据流形的几何结构，防止过拟合并提高表示的质量。",
        "动机": "探索正则化自编码器在保持数据流形几何结构方面的潜力，以提高表示学习的质量和应用效果。",
        "方法": "引入零度共形正则化项，以保持潜在表示空间中的角度和相对距离，从而优于其他保持几何结构的正则化方法。",
        "关键词": [
            "正则化自编码器",
            "等距表示学习",
            "共形映射",
            "无监督信息检索",
            "数据流形"
        ],
        "涉及的技术概念": {
            "正则化自编码器": "通过添加正则化项来约束表示，防止过拟合并生成简约的生成模型。",
            "共形映射": "一种保持角度和相对距离的映射方法，用于提高潜在表示的质量。",
            "数据流形": "数据在潜在空间中的几何结构，正则化自编码器旨在学习并保持这一结构。"
        },
        "success": true
    },
    {
        "order": 829,
        "title": "Reinforcement Learning in Presence of Discrete Markovian Context Evolution ",
        "html": "https://iclr.cc//virtual/2022/poster/6691",
        "abstract": "We consider a context-dependent Reinforcement Learning (RL) setting, which is characterized by: a) an unknown finite number of not directly observable contexts; b) abrupt (discontinuous) context changes occurring during an episode; and c) Markovian context evolution. We argue that this challenging case is often met in applications and we tackle it using a Bayesian model-based approach and variational inference. We adapt a sticky Hierarchical Dirichlet Process (HDP) prior for model learning, which is arguably best-suited for infinite Markov chain modeling. We then derive a context distillation procedure, which identifies and removes spurious contexts in an unsupervised fashion. We argue that the combination of these two components allows inferring the number of contexts from data thus dealing with the context cardinality assumption. We then find the representation of the optimal policy enabling efficient policy learning using off-the-shelf RL algorithms. Finally, we demonstrate empirically (using gym environments cart-pole swing-up, drone, intersection) that our approach succeeds where state-of-the-art methods of other frameworks fail and elaborate on the reasons for such failures.",
        "conference": "ICLR",
        "中文标题": "离散马尔可夫上下文演化下的强化学习",
        "摘要翻译": "我们考虑了一种上下文依赖的强化学习（RL）设置，其特点包括：a）未知且有限的不可直接观察的上下文数量；b）在情节中发生的突然（不连续）上下文变化；以及c）马尔可夫上下文演化。我们认为这种具有挑战性的情况在应用中经常遇到，并通过使用基于贝叶斯模型的方法和变分推理来解决它。我们采用了一种粘性层次狄利克雷过程（HDP）先验进行模型学习，这被认为是最适合无限马尔可夫链建模的方法。然后，我们推导出一种上下文蒸馏过程，以无监督的方式识别并去除虚假上下文。我们认为，这两个组件的结合允许从数据中推断上下文的数量，从而处理上下文基数假设。接着，我们找到了最优策略的表示，使得能够使用现成的RL算法进行有效的策略学习。最后，我们通过实验（使用gym环境的cart-pole swing-up、drone、intersection）证明，我们的方法在现有其他框架的最先进方法失败的地方取得了成功，并详细阐述了这些失败的原因。",
        "领域": "强化学习、马尔可夫决策过程、变分推理",
        "问题": "在上下文数量未知且不可直接观察、上下文变化突然且遵循马尔可夫演化的情况下，如何进行有效的强化学习。",
        "动机": "解决在复杂动态环境中，上下文变化不可预测且难以直接观察的强化学习问题，以提高模型在实际应用中的适应性和效率。",
        "方法": "采用基于贝叶斯模型的方法和变分推理，结合粘性层次狄利克雷过程（HDP）先验进行模型学习，并通过上下文蒸馏过程无监督地识别和去除虚假上下文，最终利用现成的RL算法进行策略学习。",
        "关键词": [
            "强化学习",
            "马尔可夫上下文演化",
            "变分推理",
            "层次狄利克雷过程",
            "上下文蒸馏"
        ],
        "涉及的技术概念": {
            "粘性层次狄利克雷过程（HDP）": "用于模型学习，特别适合无限马尔可夫链建模，能够处理上下文数量的不确定性。",
            "变分推理": "用于近似推断，帮助在复杂模型中高效地学习和推断参数。",
            "上下文蒸馏": "一种无监督方法，用于识别和去除虚假上下文，优化模型对真实上下文的理解和学习。"
        },
        "success": true
    },
    {
        "order": 830,
        "title": "Reinforcement Learning under a Multi-agent Predictive State Representation Model: Method and Theory",
        "html": "https://iclr.cc//virtual/2022/poster/6620",
        "abstract": "This paper proposes a new algorithm for learning the optimal policies under a novel multi-agent predictive state representation reinforcement learning model. Compared to the state-of-the-art methods, the most striking feature of our approach is the introduction of a dynamic interaction graph to the model, which allows us to represent each agent's predictive state by considering the behaviors of its ``neighborhood'' agents. Methodologically, we develop an online algorithm that simultaneously learns the predictive state representation and agent policies. Theoretically, we provide an upper bound of the $L_2$-norm of the learned predictive state representation. Empirically, to demonstrate the efficacy of the proposed method, we provide thorough numerical results on both a MAMuJoCo robotic learning experiment and a multi-agent particle learning environment.",
        "conference": "ICLR",
        "中文标题": "多智能体预测状态表示模型下的强化学习：方法与理论",
        "摘要翻译": "本文提出了一种新的算法，用于在一种新颖的多智能体预测状态表示强化学习模型下学习最优策略。与现有最先进的方法相比，我们方法最显著的特点是在模型中引入了动态交互图，这使我们能够通过考虑每个智能体的‘邻居’智能体的行为来表示其预测状态。在方法上，我们开发了一种在线算法，该算法同时学习预测状态表示和智能体策略。理论上，我们提供了学习到的预测状态表示的$L_2$范数的上界。实证上，为了证明所提出方法的有效性，我们在MAMuJoCo机器人学习实验和多智能体粒子学习环境上提供了全面的数值结果。",
        "领域": "多智能体强化学习、机器人学习、动态交互建模",
        "问题": "在多智能体环境中学习最优策略的问题",
        "动机": "通过引入动态交互图来更有效地表示和预测多智能体环境中的状态和行为，以提高策略学习的效率和效果",
        "方法": "开发了一种在线算法，同时学习预测状态表示和智能体策略，并引入了动态交互图来考虑智能体间的相互作用",
        "关键词": [
            "多智能体强化学习",
            "预测状态表示",
            "动态交互图",
            "在线算法",
            "MAMuJoCo"
        ],
        "涉及的技术概念": {
            "多智能体预测状态表示": "用于在多智能体环境中表示和预测状态的技术，通过考虑邻居智能体的行为来增强状态表示的准确性",
            "动态交互图": "模型中引入的结构，用于捕捉和表示智能体间的动态相互作用，以优化策略学习",
            "$L_2$范数上界": "理论分析中提供的学习预测状态表示准确性的数学保证，确保学习过程的稳定性和收敛性"
        },
        "success": true
    },
    {
        "order": 831,
        "title": "Reinforcement Learning with Sparse Rewards using Guidance from Offline Demonstration",
        "html": "https://iclr.cc//virtual/2022/poster/6479",
        "abstract": "A major challenge in real-world reinforcement learning (RL) is the sparsity of reward feedback.  Often, what is available is an intuitive but sparse reward function that only indicates whether the task is completed partially or fully.  However, the lack of carefully designed, fine grain feedback implies that most existing RL algorithms fail to learn an acceptable policy in a reasonable time frame.  This is because of the large number of exploration actions that the policy has to perform before it gets any useful feedback that it can learn from.  In this work, we address this challenging problem by developing an algorithm that exploits the offline demonstration data generated by {a sub-optimal behavior policy} for faster and efficient online RL in such sparse reward settings.  The proposed algorithm, which we call the Learning Online with Guidance Offline (LOGO) algorithm, merges a policy improvement step with an additional policy guidance step by using the offline demonstration data.  The key idea is that by obtaining guidance from - not imitating - the offline {data}, LOGO orients its policy in the manner of the sub-optimal {policy}, while yet being able to learn beyond and approach optimality.  We provide a theoretical analysis of our algorithm, and provide a lower bound on the performance improvement in each learning episode.  We also extend our algorithm to the even more challenging incomplete observation setting, where the demonstration data contains only a censored version of the true state observation.  We demonstrate the superior performance of our algorithm over state-of-the-art approaches on a number of  benchmark environments with sparse rewards {and censored state}.  Further, we demonstrate the value of our approach via implementing LOGO on a mobile robot for trajectory tracking and obstacle avoidance, where it shows excellent performance.",
        "conference": "ICLR",
        "中文标题": "利用离线演示指导的稀疏奖励强化学习",
        "摘要翻译": "现实世界强化学习（RL）中的一个主要挑战是奖励反馈的稀疏性。通常，可用的是一种直观但稀疏的奖励函数，仅能部分或完全指示任务是否完成。然而，缺乏精心设计的细粒度反馈意味着大多数现有的RL算法无法在合理的时间内学习到可接受的策略。这是因为策略在执行大量探索动作之前，无法获得任何有用的反馈以供学习。在这项工作中，我们通过开发一种算法来解决这一挑战性问题，该算法利用由{次优行为策略}生成的离线演示数据，在稀疏奖励设置中实现更快、更高效的在线RL。我们提出的算法，称为离线指导在线学习（LOGO）算法，通过使用离线演示数据，将策略改进步骤与额外的策略指导步骤合并。关键思想是通过从离线{数据}中获得指导——而不是模仿——LOGO以次优{策略}的方式定向其策略，同时还能学习并接近最优性。我们提供了对我们算法的理论分析，并给出了每个学习阶段性能改进的下限。我们还将我们的算法扩展到更具挑战性的不完全观察设置，其中演示数据仅包含真实状态观察的删节版本。我们在多个具有稀疏奖励{和删节状态}的基准环境中展示了我们的算法相对于最先进方法的优越性能。此外，我们通过在移动机器人上实现LOGO进行轨迹跟踪和避障，展示了我们方法的价值，其中它表现出色。",
        "领域": "强化学习、机器人控制、自动驾驶",
        "问题": "解决在稀疏奖励环境下强化学习算法学习效率低下的问题",
        "动机": "由于现实世界中奖励反馈的稀疏性，现有的强化学习算法难以在合理时间内学习到有效的策略，因此需要一种能够利用离线演示数据加速学习的方法。",
        "方法": "提出LOGO算法，通过结合离线演示数据的策略指导步骤和策略改进步骤，加速在线强化学习过程。",
        "关键词": [
            "稀疏奖励",
            "离线演示",
            "强化学习",
            "策略指导",
            "机器人控制"
        ],
        "涉及的技术概念": {
            "稀疏奖励": "指在强化学习中，奖励信号稀少且不频繁，导致学习效率低下。",
            "离线演示数据": "由次优策略生成的历史数据，用于指导在线学习过程。",
            "策略指导": "通过离线数据指导在线学习策略的方向，而非直接模仿，以加速学习并接近最优策略。"
        },
        "success": true
    },
    {
        "order": 832,
        "title": "Relating transformers to models and neural representations of the hippocampal formation",
        "html": "https://iclr.cc//virtual/2022/poster/6743",
        "abstract": "Many deep neural network architectures loosely based on brain networks have recently been shown to replicate neural firing patterns observed in the brain. One of the most exciting and promising novel architectures, the Transformer neural network, was developed without the brain in mind. In this work, we show that transformers, when equipped with recurrent position encodings, replicate the precisely tuned spatial representations of the hippocampal formation; most notably place and grid cells. Furthermore, we show that this result is no surprise since it is closely related to current hippocampal models from neuroscience. We additionally show the transformer version offers dramatic performance gains over the neuroscience version. This work continues to bind computations of artificial and brain networks, offers a novel understanding of the hippocampal-cortical interaction, and suggests how wider cortical areas may perform complex tasks beyond current neuroscience models such as language comprehension.",
        "conference": "ICLR",
        "中文标题": "将Transformer模型与海马体形成的模型及神经表征联系起来",
        "摘要翻译": "许多基于大脑网络松散构建的深度神经网络架构最近被证明能够复制大脑中观察到的神经放电模式。Transformer神经网络作为一种最令人兴奋且前景广阔的新型架构，其开发初衷并未考虑大脑。在这项工作中，我们展示了当Transformer配备循环位置编码时，能够复制海马体形成的精确调谐空间表征；尤其是位置细胞和网格细胞。此外，我们还表明这一结果并不意外，因为它与神经科学中现有的海马体模型密切相关。我们还展示了Transformer版本相比神经科学版本在性能上的显著提升。这项工作继续将人工和大脑网络的计算联系起来，提供了对海马体-皮质相互作用的新理解，并提出了更广泛的皮质区域如何执行超出当前神经科学模型（如语言理解）的复杂任务。",
        "领域": "神经网络模型比较、海马体神经表征、深度学习与神经科学结合",
        "问题": "探索Transformer模型如何能够复制海马体形成的神经表征，并比较其与现有神经科学模型的性能差异。",
        "动机": "研究旨在揭示Transformer模型与大脑海马体在空间表征上的相似性，以及这种相似性如何为理解大脑如何处理复杂任务（如语言理解）提供新的视角。",
        "方法": "通过为Transformer模型配备循环位置编码，研究其复制海马体空间表征的能力，并与现有的神经科学模型进行性能比较。",
        "关键词": [
            "Transformer模型",
            "海马体",
            "神经表征",
            "循环位置编码",
            "性能比较"
        ],
        "涉及的技术概念": {
            "Transformer模型": "一种最初为自然语言处理任务设计的神经网络架构，本研究用于探索其与大脑海马体在空间表征上的相似性。",
            "循环位置编码": "一种使Transformer模型能够处理序列数据中位置信息的技术，本研究用于复制海马体的空间表征。",
            "海马体神经表征": "大脑海马体中特定的神经细胞（如位置细胞和网格细胞）如何编码空间信息，本研究探索了Transformer模型如何复制这些表征。"
        },
        "success": true
    },
    {
        "order": 833,
        "title": "Relational Learning with Variational Bayes",
        "html": "https://iclr.cc//virtual/2022/poster/6522",
        "abstract": "In psychology, relational learning refers to the ability to recognize and respond to relationship among objects irrespective of the nature of those objects. Relational learning has long been recognized as a hallmark of human cognition and a key question in artificial intelligence research. In this work, we propose an unsupervised learning method for addressing the relational learning problem where we learn the underlying relationship between a pair of data irrespective of the nature of those data. The central idea of the proposed method is to encapsulate the relational learning problem with a probabilistic graphical model in which we perform inference to learn about data relationship and other relational processing tasks.",
        "conference": "ICLR",
        "中文标题": "关系学习的变分贝叶斯方法",
        "摘要翻译": "在心理学中，关系学习指的是识别和响应对象之间关系的能力，而不考虑这些对象的本质。关系学习长期以来被认为是人类认知的标志，也是人工智能研究中的一个关键问题。在这项工作中，我们提出了一种无监督学习方法，用于解决关系学习问题，即我们学习一对数据之间的潜在关系，而不考虑这些数据的本质。所提出方法的核心思想是用概率图模型封装关系学习问题，在该模型中我们进行推理以了解数据关系和其他关系处理任务。",
        "领域": "无监督学习、概率图模型、关系学习",
        "问题": "解决在无监督条件下学习数据对之间潜在关系的问题",
        "动机": "探索和实现类似于人类认知能力的关系学习，以推动人工智能在该领域的发展",
        "方法": "采用变分贝叶斯方法和概率图模型进行关系学习的无监督学习",
        "关键词": [
            "关系学习",
            "变分贝叶斯",
            "无监督学习",
            "概率图模型",
            "人工智能"
        ],
        "涉及的技术概念": {
            "变分贝叶斯": "用于在概率图模型中近似推断，以学习数据之间的关系",
            "概率图模型": "用于封装和表示数据之间的关系，便于进行关系学习和推理",
            "无监督学习": "在不需要标注数据的情况下，学习数据之间的潜在关系"
        },
        "success": true
    },
    {
        "order": 834,
        "title": "Relational Multi-Task Learning: Modeling Relations between Data and Tasks",
        "html": "https://iclr.cc//virtual/2022/poster/5979",
        "abstract": "A key assumption in multi-task learning is that at the inference time the multi-task model only has access to a given data point but not to the data point’s labels from other tasks. This presents an opportunity to extend multi-task learning to utilize data point’s labels from other auxiliary tasks, and this way improves performance on the new task. Here we introduce a novel relational multi-task learning setting where we leverage data point labels from auxiliary tasks to make more accurate predictions on the new task. We develop MetaLink, where our key innovation is to build a knowledge graph that connects data points and tasks and thus allows us to leverage labels from auxiliary tasks. The knowledge graph consists of two types of nodes: (1) data nodes, where node features are data embeddings computed by the neural network, and (2) task nodes, with the last layer’s weights for each task as node features. The edges in this knowledge graph capture data-task relationships, and the edge label captures the label of a data point on a particular task. Under MetaLink, we reformulate the new task as a link label prediction problem between a data node and a task node. The MetaLink framework provides flexibility to model knowledge transfer from auxiliary task labels to the task of interest. We evaluate MetaLink on 6 benchmark datasets in both biochemical and vision domains. Experiments demonstrate that MetaLink can successfully utilize the relations among different tasks, outperforming the state-of-the-art methods under the proposed relational multi-task learning setting, with up to 27% improvement in ROC AUC.",
        "conference": "ICLR",
        "中文标题": "关系型多任务学习：数据与任务间关系的建模",
        "摘要翻译": "多任务学习中的一个关键假设是，在推理时，多任务模型只能访问给定的数据点，而不能访问该数据点在其他任务中的标签。这为扩展多任务学习以利用来自其他辅助任务的数据点标签提供了机会，从而在新任务上提高性能。在这里，我们介绍了一种新颖的关系型多任务学习设置，其中我们利用来自辅助任务的数据点标签来对新任务做出更准确的预测。我们开发了MetaLink，其中的关键创新是构建一个连接数据点和任务的知识图谱，从而使我们能够利用来自辅助任务的标签。该知识图谱由两种类型的节点组成：（1）数据节点，其中节点特征是由神经网络计算的数据嵌入；（2）任务节点，其中每个任务的最后一层权重作为节点特征。该知识图谱中的边捕捉了数据-任务关系，边标签捕捉了数据点在特定任务上的标签。在MetaLink下，我们将新任务重新表述为数据节点和任务节点之间的链接标签预测问题。MetaLink框架提供了灵活性，以建模从辅助任务标签到感兴趣任务的知识转移。我们在生物化学和视觉领域的6个基准数据集上评估了MetaLink。实验表明，MetaLink能够成功利用不同任务之间的关系，在提出的关系型多任务学习设置下，性能优于最先进的方法，ROC AUC提高了高达27%。",
        "领域": "多任务学习、知识图谱、深度学习",
        "问题": "如何利用来自其他辅助任务的数据点标签来提升新任务的性能",
        "动机": "扩展多任务学习以利用辅助任务的标签信息，提高新任务的预测准确性",
        "方法": "构建连接数据点和任务的知识图谱，将新任务重新表述为链接标签预测问题",
        "关键词": [
            "关系型多任务学习",
            "知识图谱",
            "MetaLink",
            "ROC AUC",
            "数据嵌入"
        ],
        "涉及的技术概念": {
            "知识图谱": "用于连接数据点和任务，捕捉数据-任务关系，支持从辅助任务到新任务的知识转移",
            "数据嵌入": "由神经网络计算的数据表示，作为知识图谱中数据节点的特征",
            "链接标签预测": "将新任务重新表述为预测数据节点和任务节点之间边的标签问题"
        },
        "success": true
    },
    {
        "order": 835,
        "title": "Relational Surrogate Loss Learning",
        "html": "https://iclr.cc//virtual/2022/poster/5918",
        "abstract": "Evaluation metrics in machine learning are often hardly taken as loss functions, as they could be non-differentiable and non-decomposable, e.g., average precision and F1 score. This paper aims to address this problem by revisiting the surrogate loss learning, where a deep neural network is employed to approximate the evaluation metrics. Instead of pursuing an exact recovery of the evaluation metric through a deep neural network, we are reminded of the purpose of the existence of these evaluation metrics, which is to distinguish whether one model is better or worse than another. In this paper, we show that directly maintaining the relation of models between surrogate losses and metrics suffices, and propose a rank correlation-based optimization method to maximize this relation and learn surrogate losses. Compared to previous works, our method is much easier to optimize and enjoys significant efficiency and performance gains. Extensive experiments show that our method achieves improvements on various tasks including image classification and neural machine translation, and even outperforms state-of-the-art methods on human pose estimation and machine reading comprehension tasks. Code is available at: https://github.com/hunto/ReLoss.",
        "conference": "ICLR",
        "中文标题": "关系型替代损失学习",
        "摘要翻译": "在机器学习中，评估指标往往难以直接作为损失函数使用，因为它们可能是不可微分和不可分解的，例如平均精度和F1分数。本文旨在通过重新审视替代损失学习来解决这一问题，其中采用深度神经网络来近似评估指标。我们并不追求通过深度神经网络精确恢复评估指标，而是提醒这些评估指标存在的目的，即区分一个模型是否比另一个更好或更差。在本文中，我们展示了直接保持替代损失和指标之间模型的关系就足够了，并提出了一种基于秩相关的优化方法来最大化这种关系并学习替代损失。与之前的工作相比，我们的方法更易于优化，并且在效率和性能上都有显著提升。大量实验表明，我们的方法在包括图像分类和神经机器翻译在内的各种任务上实现了改进，甚至在人体姿态估计和机器阅读理解任务上超越了最先进的方法。代码可在https://github.com/hunto/ReLoss获取。",
        "领域": "深度学习优化、计算机视觉、自然语言处理",
        "问题": "解决评估指标难以直接作为损失函数使用的问题",
        "动机": "通过替代损失学习，使深度神经网络能够近似不可微分和不可分解的评估指标，从而区分模型性能的优劣",
        "方法": "提出一种基于秩相关的优化方法，直接保持替代损失和评估指标之间模型的关系，以学习替代损失",
        "关键词": [
            "替代损失学习",
            "秩相关优化",
            "深度神经网络",
            "评估指标近似",
            "模型性能区分"
        ],
        "涉及的技术概念": {
            "替代损失学习": "采用深度神经网络近似评估指标，解决评估指标难以直接作为损失函数使用的问题",
            "秩相关优化": "通过最大化替代损失和评估指标之间模型的关系，优化替代损失的学习过程",
            "深度神经网络": "用于近似评估指标，实现替代损失学习的关键技术"
        },
        "success": true
    },
    {
        "order": 836,
        "title": "RelaxLoss: Defending Membership Inference Attacks without Losing Utility",
        "html": "https://iclr.cc//virtual/2022/poster/5964",
        "abstract": "As a long-term threat to the privacy of training data, membership inference attacks (MIAs) emerge ubiquitously in machine learning models.Existing works evidence strong connection between the distinguishability of the training and testing loss distributions and the model's vulnerability to MIAs. Motivated by existing results, we propose a novel training framework based on a relaxed loss ($\\textbf{RelaxLoss}$) with a more achievable learning target, which leads to narrowed generalization gap and reduced privacy leakage. RelaxLoss is applicable to any classification model with added benefits of easy implementation and negligible overhead. Through extensive evaluations on five datasets with diverse modalities (images, medical data, transaction records), our approach consistently outperforms state-of-the-art defense mechanisms in terms of resilience against MIAs as well as model utility. Our defense is the first that can withstand a wide range of attacks while preserving (or even improving) the target model's utility.",
        "conference": "ICLR",
        "中文标题": "RelaxLoss：在不损失效用的情况下防御成员推理攻击",
        "摘要翻译": "作为一种对训练数据隐私的长期威胁，成员推理攻击（MIAs）在机器学习模型中无处不在。现有工作证明了训练和测试损失分布的可区分性与模型对MIAs的脆弱性之间存在强烈联系。受现有结果的启发，我们提出了一种基于松弛损失（RelaxLoss）的新型训练框架，该框架具有更易实现的学习目标，从而缩小了泛化差距并减少了隐私泄露。RelaxLoss适用于任何分类模型，具有易于实现和开销可忽略的额外优势。通过对五种不同模态（图像、医疗数据、交易记录）的数据集进行广泛评估，我们的方法在抵抗MIAs的韧性以及模型效用方面始终优于最先进的防御机制。我们的防御是第一个能够抵御广泛攻击同时保持（甚至提高）目标模型效用的防御方法。",
        "领域": "隐私保护机器学习、对抗性防御、分类模型安全",
        "问题": "如何在防御成员推理攻击的同时不损害模型的效用",
        "动机": "现有研究表明训练和测试损失分布的可区分性与模型对成员推理攻击的脆弱性密切相关，这促使我们开发一种新的训练框架以减少隐私泄露同时保持模型性能。",
        "方法": "提出了一种基于松弛损失（RelaxLoss）的新型训练框架，该框架通过设定更易实现的学习目标来缩小泛化差距，从而减少隐私泄露。",
        "关键词": [
            "成员推理攻击",
            "隐私保护",
            "松弛损失",
            "分类模型",
            "对抗性防御"
        ],
        "涉及的技术概念": {
            "成员推理攻击（MIAs）": "一种攻击方法，旨在推断特定数据样本是否被用于训练目标模型，威胁训练数据的隐私。",
            "松弛损失（RelaxLoss）": "论文提出的新型损失函数，通过调整学习目标来减少模型对训练数据的过度拟合，从而降低隐私泄露风险。",
            "泛化差距": "模型在训练数据和测试数据上表现的差异，论文通过缩小这一差距来减少模型对成员推理攻击的脆弱性。"
        },
        "success": true
    },
    {
        "order": 837,
        "title": "Reliable Adversarial Distillation with Unreliable Teachers",
        "html": "https://iclr.cc//virtual/2022/poster/6336",
        "abstract": "In ordinary distillation, student networks are trained with soft labels (SLs) given by pretrained teacher networks, and students are expected to improve upon teachers since SLs are stronger supervision than the original hard labels. However, when considering adversarial robustness, teachers may become unreliable and adversarial distillation may not work: teachers are pretrained on their own adversarial data, and it is too demanding to require that teachers are also good at every adversarial data queried by students. Therefore, in this paper, we propose reliable introspective adversarial distillation (IAD) where students partially instead of fully trust their teachers. Specifically, IAD distinguishes between three cases given a query of a natural data (ND) and the corresponding adversarial data (AD): (a) if a teacher is good at AD, its SL is fully trusted; (b) if a teacher is good at ND but not AD, its SL is partially trusted and the student also takes its own SL into account; (c) otherwise, the student only relies on its own SL. Experiments demonstrate the effectiveness of IAD for improving upon teachers in terms of adversarial robustness.",
        "conference": "ICLR",
        "中文标题": "不可靠教师下的可靠对抗蒸馏",
        "摘要翻译": "在普通的蒸馏过程中，学生网络通过预训练教师网络提供的软标签（SLs）进行训练，由于软标签比原始硬标签提供更强的监督，学生网络有望超越教师网络。然而，当考虑到对抗鲁棒性时，教师网络可能变得不可靠，对抗蒸馏可能失效：教师网络是在自己的对抗数据上预训练的，要求学生网络查询的每一份对抗数据教师网络都表现良好要求过高。因此，本文提出了可靠的内省对抗蒸馏（IAD），学生网络部分而非完全信任其教师网络。具体来说，IAD针对自然数据（ND）和相应的对抗数据（AD）的查询区分三种情况：（a）如果教师网络在AD上表现良好，其SL被完全信任；（b）如果教师网络在ND上表现良好但在AD上不佳，其SL被部分信任，学生网络也会考虑自己的SL；（c）否则，学生网络仅依赖自己的SL。实验证明，IAD在提高对抗鲁棒性方面超越教师网络的有效性。",
        "领域": "对抗学习、知识蒸馏、模型鲁棒性",
        "问题": "在对抗环境下，教师网络可能不可靠，导致对抗蒸馏失效的问题",
        "动机": "解决在对抗环境下教师网络不可靠导致的知识蒸馏效果不佳的问题",
        "方法": "提出可靠的内省对抗蒸馏（IAD），学生网络根据教师网络在不同数据上的表现，部分或完全信任教师网络的软标签",
        "关键词": [
            "对抗蒸馏",
            "知识蒸馏",
            "模型鲁棒性",
            "内省学习",
            "对抗学习"
        ],
        "涉及的技术概念": {
            "软标签（SLs）": "教师网络提供的概率分布标签，比硬标签提供更丰富的监督信息",
            "对抗鲁棒性": "模型在面对对抗性攻击时保持性能的能力",
            "内省对抗蒸馏（IAD）": "一种改进的对抗蒸馏方法，学生网络根据教师网络的表现选择性信任其软标签"
        },
        "success": true
    },
    {
        "order": 838,
        "title": "RelViT: Concept-guided Vision Transformer for Visual Relational Reasoning",
        "html": "https://iclr.cc//virtual/2022/poster/6087",
        "abstract": "Reasoning about visual relationships is central to how humans interpret the visual world. This task remains challenging for current deep learning algorithms since it requires addressing three key technical problems jointly: 1) identifying object entities and their properties, 2) inferring semantic relations between pairs of entities, and 3) generalizing to novel object-relation combinations, i.e., systematic generalization. In this work, we use vision transformers (ViTs) as our base model for visual reasoning and make better use of concepts defined as object entities and their relations to improve the reasoning ability of ViTs. Specifically, we introduce a novel concept-feature dictionary to allow flexible image feature retrieval at training time with concept keys. This dictionary enables two new concept-guided auxiliary tasks: 1) a global task for promoting relational reasoning, and 2) a local task for facilitating semantic object-centric correspondence learning. To examine the systematic generalization of visual reasoning models, we introduce systematic splits for the standard HICO and GQA benchmarks. We show the resulting model, Concept-guided Vision Transformer (or RelViT for short) significantly outperforms prior approaches on HICO and GQA by 16% and 13% in the original split, and by 43% and 18% in the systematic split. Our ablation analyses also reveal our model's compatibility with multiple ViT variants and robustness to hyper-parameters.",
        "conference": "ICLR",
        "中文标题": "RelViT：概念引导的视觉Transformer用于视觉关系推理",
        "摘要翻译": "视觉关系推理是人类解释视觉世界的核心。这一任务对当前的深度学习算法仍然具有挑战性，因为它需要共同解决三个关键技术问题：1) 识别物体实体及其属性，2) 推断实体对之间的语义关系，以及3) 泛化到新的物体-关系组合，即系统泛化。在本工作中，我们使用视觉Transformer（ViTs）作为视觉推理的基础模型，并更好地利用定义为物体实体及其关系的概念来提高ViTs的推理能力。具体来说，我们引入了一个新颖的概念-特征字典，允许在训练时使用概念键灵活检索图像特征。这个字典支持两个新的概念引导辅助任务：1) 一个促进关系推理的全局任务，和2) 一个促进语义物体中心对应学习的局部任务。为了检验视觉推理模型的系统泛化能力，我们为标准HICO和GQA基准引入了系统分割。我们展示了由此产生的模型，概念引导的视觉Transformer（简称RelViT），在原始分割上显著优于先前的方法，在HICO和GQA上分别提高了16%和13%，在系统分割上分别提高了43%和18%。我们的消融分析还揭示了我们的模型与多种ViT变体的兼容性以及对超参数的鲁棒性。",
        "领域": "视觉关系推理",
        "问题": "解决视觉关系推理中的三个关键技术问题：物体实体及其属性的识别、实体对之间语义关系的推断、以及向新的物体-关系组合的系统泛化。",
        "动机": "提高视觉Transformer（ViTs）在视觉关系推理任务中的性能，特别是在识别物体实体及其属性、推断语义关系以及系统泛化方面的能力。",
        "方法": "引入概念-特征字典以灵活检索图像特征，并设计两个概念引导的辅助任务：一个用于促进关系推理的全局任务和一个用于促进语义物体中心对应学习的局部任务。",
        "关键词": [
            "视觉关系推理",
            "概念引导",
            "视觉Transformer",
            "系统泛化",
            "辅助任务"
        ],
        "涉及的技术概念": {
            "视觉Transformer（ViTs）": "作为视觉推理的基础模型，用于处理图像数据。",
            "概念-特征字典": "允许在训练时使用概念键灵活检索图像特征，支持概念引导的辅助任务。",
            "系统泛化": "模型泛化到新的物体-关系组合的能力，通过引入系统分割来检验。"
        },
        "success": true
    },
    {
        "order": 839,
        "title": "Representation-Agnostic Shape Fields",
        "html": "https://iclr.cc//virtual/2022/poster/6435",
        "abstract": "3D shape analysis has been widely explored in the era of deep learning. Numerous models have been developed for various 3D data representation formats, e.g., MeshCNN for meshes, PointNet for point clouds and VoxNet for voxels. In this study, we present Representation-Agnostic Shape Fields (RASF), a generalizable and computation-efficient shape embedding module for 3D deep learning. RASF is implemented with a learnable 3D grid with multiple channels to store local geometry. Based on RASF, shape embeddings for various 3D shape representations (point clouds, meshes and voxels) are retrieved by coordinate indexing. While there are multiple ways to optimize the learnable parameters of RASF, we provide two effective schemes among all in this paper for RASF pre-training: shape reconstruction and normal estimation. Once trained, RASF becomes a plug-and-play performance booster with negligible cost. Extensive experiments on diverse 3D representation formats, networks and applications, validate the universal effectiveness of the proposed RASF. Code and pre-trained models are publicly available\\footnote{\\url{https://github.com/seanywang0408/RASF}}.",
        "conference": "ICLR",
        "中文标题": "表示无关的形状场",
        "摘要翻译": "在深度学习时代，3D形状分析已被广泛探索。针对各种3D数据表示格式，已经开发了许多模型，例如用于网格的MeshCNN、用于点云的PointNet和用于体素的VoxNet。在本研究中，我们提出了表示无关的形状场（RASF），这是一种可推广且计算高效的3D深度学习形状嵌入模块。RASF通过一个可学习的3D网格实现，该网格具有多个通道来存储局部几何。基于RASF，通过坐标索引检索各种3D形状表示（点云、网格和体素）的形状嵌入。虽然有多种方法可以优化RASF的可学习参数，但我们在本文中提供了两种有效的RASF预训练方案：形状重建和法线估计。一旦训练完成，RASF就成为一个即插即用的性能提升器，成本可忽略不计。在各种3D表示格式、网络和应用上的大量实验验证了所提出的RASF的普遍有效性。代码和预训练模型公开可用。",
        "领域": "3D形状分析, 深度学习, 计算机视觉",
        "问题": "如何为不同的3D数据表示格式开发一个通用的形状嵌入模块",
        "动机": "为了解决不同3D数据表示格式之间缺乏通用形状嵌入模块的问题，提高3D深度学习的效率和性能",
        "方法": "开发了一个表示无关的形状场（RASF），通过可学习的3D网格存储局部几何信息，支持通过坐标索引检索形状嵌入，并提供了形状重建和法线估计两种预训练方案",
        "关键词": [
            "3D形状分析",
            "形状嵌入",
            "表示无关",
            "深度学习",
            "计算机视觉"
        ],
        "涉及的技术概念": {
            "表示无关的形状场（RASF）": "一种通用的形状嵌入模块，适用于不同的3D数据表示格式，通过可学习的3D网格实现",
            "坐标索引": "用于从RASF中检索各种3D形状表示的形状嵌入的技术",
            "预训练方案": "包括形状重建和法线估计，用于优化RASF的可学习参数"
        },
        "success": true
    },
    {
        "order": 840,
        "title": "Representational Continuity for Unsupervised Continual Learning",
        "html": "https://iclr.cc//virtual/2022/poster/7119",
        "abstract": "Continual learning (CL) aims to learn a sequence of tasks without forgetting the previously acquired knowledge. However, recent CL advances are restricted to supervised continual learning (SCL) scenarios. Consequently, they are not scalable to real-world applications where the data distribution is often biased and unannotated. In this work, we focus on unsupervised continual learning (UCL), where we learn the feature representations on an unlabelled sequence of tasks and show that reliance on annotated data is not necessary for continual learning. We conduct a systematic study analyzing the learned feature representations and show that unsupervised visual representations are surprisingly more robust to catastrophic forgetting, consistently achieve better performance, and generalize better to out-of-distribution tasks than SCL. Furthermore, we find that UCL achieves a smoother loss landscape through qualitative analysis of the learned representations and learns meaningful feature representations. Additionally, we propose Lifelong Unsupervised Mixup (Lump), a simple yet effective technique that interpolates between the current task and previous tasks' instances to alleviate catastrophic forgetting for unsupervised representations. ",
        "conference": "ICLR",
        "中文标题": "无监督持续学习的表示连续性",
        "摘要翻译": "持续学习（CL）旨在学习一系列任务而不忘记先前获得的知识。然而，最近的CL进展仅限于监督持续学习（SCL）场景。因此，它们无法扩展到数据分布通常有偏差且未注释的现实世界应用。在这项工作中，我们专注于无监督持续学习（UCL），在未标记的任务序列上学习特征表示，并表明持续学习不一定需要注释数据。我们进行了一项系统研究，分析了学习到的特征表示，并表明无监督视觉表示对灾难性遗忘的鲁棒性出人意料地更强，一致地实现了更好的性能，并且比SCL更好地泛化到分布外任务。此外，我们发现UCL通过学习表示的定性分析实现了更平滑的损失景观，并学习了有意义的特征表示。此外，我们提出了Lifelong Unsupervised Mixup（Lump），这是一种简单而有效的技术，它在当前任务和先前任务的实例之间进行插值，以减轻无监督表示的灾难性遗忘。",
        "领域": "无监督学习、持续学习、特征表示学习",
        "问题": "解决在无监督环境下持续学习中的灾难性遗忘问题",
        "动机": "现实世界中的数据往往未标注且分布有偏差，需要一种不依赖标注数据的持续学习方法",
        "方法": "提出Lifelong Unsupervised Mixup（Lump）技术，通过在当前任务和先前任务的实例之间进行插值来减轻灾难性遗忘",
        "关键词": [
            "无监督持续学习",
            "灾难性遗忘",
            "特征表示",
            "Lifelong Unsupervised Mixup",
            "损失景观"
        ],
        "涉及的技术概念": {
            "无监督持续学习（UCL）": "在未标记的任务序列上学习特征表示，不依赖注释数据进行持续学习",
            "灾难性遗忘": "在学习新任务时忘记先前学到的知识，UCL通过特定技术减轻这一问题",
            "Lifelong Unsupervised Mixup（Lump）": "一种通过插值减轻无监督表示中灾难性遗忘的技术"
        },
        "success": true
    },
    {
        "order": 841,
        "title": "Representation Learning for Online and Offline RL in Low-rank MDPs",
        "html": "https://iclr.cc//virtual/2022/poster/7191",
        "abstract": "This work studies the question of Representation Learning in RL: how can we learn a compact low-dimensional representation such that on top of the representation we can perform RL procedures such as exploration and exploitation, in a sample efficient manner. We focus on the low-rank Markov Decision Processes (MDPs) where the transition dynamics correspond to a low-rank transition matrix. Unlike prior works that assume the representation is known (e.g., linear MDPs), here we need to learn the representation for the low-rank MDP. We study both the online RL and offline RL settings. For the online setting, operating with the same computational oracles used in FLAMBE (Agarwal et.al), the state-of-art algorithm for learning representations in low-rank MDPs, we propose an algorithm REP-UCB Upper Confidence Bound driven Representation learning for RL), which significantly improves the sample complexity from $\\widetilde{O}( A^9 d^7 / (\\epsilon^{10} (1-\\gamma)^{22}))$ for FLAMBE to $\\widetilde{O}( A^4 d^4 / (\\epsilon^2 (1-\\gamma)^{2})  )$ with $d$ being the rank of the transition matrix (or dimension of the ground truth representation), $A$ being the number of actions, and $\\gamma$ being the discounted factor. Notably, REP-UCB is simpler than FLAMBE, as it directly balances the interplay between representation learning, exploration, and exploitation, while FLAMBE is an explore-then-commit style approach and has to perform reward-free exploration step-by-step forward in time. For the offline RL setting, we develop an algorithm that leverages pessimism to learn under a partial coverage condition: our algorithm is able to compete against any policy as long as it is covered by the offline distribution.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "低秩MDP中在线和离线强化学习的表示学习",
        "摘要翻译": "这项工作研究了强化学习中的表示学习问题：如何学习一个紧凑的低维表示，使得在此表示之上，我们可以以样本高效的方式执行诸如探索和利用等强化学习过程。我们专注于低秩马尔可夫决策过程（MDP），其中转移动态对应于一个低秩转移矩阵。与假设表示已知（例如，线性MDP）的先前工作不同，这里我们需要学习低秩MDP的表示。我们研究了在线强化学习和离线强化学习设置。对于在线设置，使用与FLAMBE（Agarwal等人）中使用的相同的计算预言机，FLAMBE是用于学习低秩MDP中表示的最先进算法，我们提出了一种算法REP-UCB（Upper Confidence Bound驱动的强化学习表示学习），该算法显著提高了样本复杂度，从FLAMBE的$\\widetilde{O}( A^9 d^7 / (\\epsilon^{10} (1-\\gamma)^{22}))$ 降低到 $\\widetilde{O}( A^4 d^4 / (\\epsilon^2 (1-\\gamma)^{2})  )$，其中$d$是转移矩阵的秩（或ground truth表示的维度），$A$是动作的数量，$\\gamma$是折扣因子。值得注意的是，REP-UCB比FLAMBE更简单，因为它直接平衡了表示学习、探索和利用之间的相互作用，而FLAMBE是一种explore-then-commit风格的方法，并且必须逐步执行无奖励探索。对于离线强化学习设置，我们开发了一种算法，该算法利用悲观主义在部分覆盖条件下进行学习：我们的算法能够与任何策略竞争，只要它被离线分布覆盖。",
        "领域": "强化学习、表示学习、马尔可夫决策过程",
        "问题": "如何在低秩马尔可夫决策过程中学习紧凑的低维表示，从而提升在线和离线强化学习的样本效率。",
        "动机": "现有的强化学习方法在处理低秩MDP时，通常假设表示已知，而实际情况中需要学习这种表示。该研究旨在解决学习低秩MDP表示的问题，并提高强化学习的样本效率。",
        "方法": "提出了在线强化学习算法REP-UCB，该算法基于Upper Confidence Bound，直接平衡表示学习、探索和利用之间的关系，并设计了基于悲观主义的离线强化学习算法，使其在部分覆盖条件下也能有效学习。",
        "关键词": [
            "表示学习",
            "强化学习",
            "低秩MDP",
            "样本效率",
            "在线强化学习",
            "离线强化学习"
        ],
        "涉及的技术概念": {
            "表示学习": "学习数据的低维表示，用于简化问题并提高学习效率。",
            "Upper Confidence Bound (UCB)": "一种探索策略，通过给每个动作的奖励估计加上一个置信度上界，平衡探索和利用。"
        }
    },
    {
        "order": 842,
        "title": "Representing Mixtures of Word Embeddings with Mixtures of Topic Embeddings",
        "html": "https://iclr.cc//virtual/2022/poster/6840",
        "abstract": "A topic model is often formulated as a generative model that explains how each word of a document is generated given a set of topics and document-specific topic proportions.  It is focused on capturing the word co-occurrences in a document and hence often suffers from poor performance in analyzing short documents. In addition, its parameter estimation often relies on approximate posterior inference that is either not scalable or suffering from large approximation error. This paper introduces a new topic-modeling framework where each document is viewed as a set of word embedding vectors and each topic is modeled as an embedding vector in the same embedding space. Embedding the words and topics in the same vector space, we define a method to measure the semantic difference between the embedding vectors of the words of a document and these of the topics, and optimize the topic embeddings to minimize the expected difference over all documents. Experiments on text analysis demonstrate that the proposed method, which is amenable to mini-batch stochastic gradient descent based optimization and hence scalable to big corpora, provides competitive performance in discovering more coherent and diverse topics and extracting better document representations. ",
        "conference": "ICLR",
        "中文标题": "用主题嵌入的混合表示词嵌入的混合",
        "摘要翻译": "主题模型通常被表述为一个生成模型，解释了在给定一组主题和文档特定主题比例的情况下，如何生成文档的每个单词。它专注于捕捉文档中的单词共现，因此在分析短文档时往往表现不佳。此外，其参数估计通常依赖于近似后验推断，这种方法要么不可扩展，要么存在较大的近似误差。本文介绍了一种新的主题建模框架，其中每个文档被视为一组词嵌入向量，每个主题被建模为同一嵌入空间中的嵌入向量。通过将单词和主题嵌入同一向量空间，我们定义了一种方法来测量文档单词的嵌入向量与主题的嵌入向量之间的语义差异，并优化主题嵌入以最小化所有文档的预期差异。文本分析实验表明，所提出的方法适用于基于小批量随机梯度下降的优化，因此可扩展到大型语料库，在发现更连贯和多样化的主题以及提取更好的文档表示方面提供了竞争性能。",
        "领域": "自然语言处理与视觉结合、文本挖掘、语义分析",
        "问题": "主题模型在分析短文档时表现不佳，且参数估计方法不可扩展或存在较大近似误差。",
        "动机": "提高主题模型在短文档分析中的性能，并通过可扩展的优化方法减少参数估计的近似误差。",
        "方法": "将文档和主题嵌入同一向量空间，定义语义差异度量并优化主题嵌入以最小化差异。",
        "关键词": [
            "主题模型",
            "词嵌入",
            "语义差异",
            "随机梯度下降",
            "文本分析"
        ],
        "涉及的技术概念": {
            "主题模型": "用于捕捉文档中单词共现的生成模型。",
            "词嵌入": "将单词表示为向量空间中的点，以捕捉语义信息。",
            "语义差异": "测量文档单词嵌入与主题嵌入之间差异的方法，用于优化主题表示。"
        },
        "success": true
    },
    {
        "order": 843,
        "title": "Resolving Training Biases via Influence-based Data Relabeling",
        "html": "https://iclr.cc//virtual/2022/poster/6491",
        "abstract": "The performance of supervised learning methods easily suffers from the training bias issue caused by train-test distribution mismatch or label noise. Influence function is a  technique that estimates the impacts of a training sample on the model’s predictions. Recent studies on \\emph{data resampling} have employed influence functions to identify \\emph{harmful} training samples that will degrade model's test performance. They have shown that discarding or downweighting the identified harmful training samples is an effective way to resolve training biases. In this work, we move one step forward and propose an influence-based relabeling framework named RDIA for reusing harmful training samples toward better model performance. To achieve this, we use influence functions to estimate how relabeling a training sample would affect model's test performance and further develop a novel relabeling function R. We theoretically prove that applying R to relabel harmful training samples allows the model to achieve lower test loss than simply discarding them for any classification tasks using cross-entropy loss. Extensive experiments on ten real-world datasets demonstrate RDIA outperforms the state-of-the-art data resampling methods and improves model's robustness against label noise. ",
        "conference": "ICLR",
        "中文标题": "通过基于影响力的数据重新标记解决训练偏差问题",
        "摘要翻译": "监督学习方法的性能容易受到由训练-测试分布不匹配或标签噪声引起的训练偏差问题的影响。影响力函数是一种估计训练样本对模型预测影响的技术。最近关于数据重采样的研究已经利用影响力函数来识别会降低模型测试性能的有害训练样本。研究表明，丢弃或降低这些有害训练样本的权重是解决训练偏差的有效方法。在这项工作中，我们更进一步，提出了一个基于影响力的重新标记框架RDIA，旨在通过重新利用有害训练样本来提高模型性能。为此，我们使用影响力函数来估计重新标记一个训练样本将如何影响模型的测试性能，并进一步开发了一个新颖的重新标记函数R。我们从理论上证明，对于使用交叉熵损失的任何分类任务，应用R来重新标记有害训练样本可以使模型获得比简单丢弃它们更低的测试损失。在十个真实世界数据集上的大量实验表明，RDIA优于最先进的数据重采样方法，并提高了模型对标签噪声的鲁棒性。",
        "领域": "监督学习优化、标签噪声处理、模型鲁棒性增强",
        "问题": "解决监督学习中由训练-测试分布不匹配或标签噪声引起的训练偏差问题",
        "动机": "通过重新利用有害训练样本而非简单丢弃，以提高模型性能和鲁棒性",
        "方法": "提出基于影响力的重新标记框架RDIA，利用影响力函数估计重新标记对测试性能的影响，并开发新的重新标记函数R",
        "关键词": [
            "影响力函数",
            "数据重新标记",
            "训练偏差",
            "标签噪声",
            "模型鲁棒性"
        ],
        "涉及的技术概念": {
            "影响力函数": "用于估计训练样本对模型预测影响的技术，帮助识别有害训练样本",
            "数据重新标记": "通过重新标记有害训练样本来提高模型性能的方法",
            "交叉熵损失": "在分类任务中用于优化模型训练的损失函数，RDIA框架通过优化此损失来提高模型性能"
        },
        "success": true
    },
    {
        "order": 844,
        "title": "Resonance in Weight Space: Covariate Shift Can Drive Divergence of SGD with Momentum",
        "html": "https://iclr.cc//virtual/2022/poster/7051",
        "abstract": "Most convergence guarantees for stochastic gradient descent with momentum (SGDm) rely on iid  sampling. Yet, SGDm is often used outside this regime, in settings with temporally correlated input samples such as continual learning and reinforcement learning. Existing work has shown that SGDm with a decaying step-size can converge under Markovian temporal correlation. In this work, we show that SGDm under covariate shift with a fixed step-size can be unstable and diverge. In particular, we show SGDm under covariate shift is a parametric oscillator, and so can suffer from a phenomenon known as resonance. We approximate the learning system as a time varying system of ordinary differential equations, and leverage existing theory to characterize the system's divergence/convergence as resonant/nonresonant modes. The theoretical result is limited to the linear setting with periodic covariate shift, so we empirically supplement this result to show that resonance phenomena persist even under non-periodic covariate shift, nonlinear dynamics with neural networks, and optimizers other than SGDm.",
        "conference": "ICLR",
        "中文标题": "权重空间中的共振：协变量偏移可导致带动量的随机梯度下降发散",
        "摘要翻译": "大多数关于带动量的随机梯度下降（SGDm）的收敛保证依赖于独立同分布（iid）采样。然而，SGDm经常被用于这种制度之外，在具有时间相关输入样本的设置中，如持续学习和强化学习。现有工作表明，带有衰减步长的SGDm可以在马尔可夫时间相关性下收敛。在这项工作中，我们表明，在固定步长下的协变量偏移下的SGDm可能不稳定并发散。特别是，我们展示了协变量偏移下的SGDm是一个参数振荡器，因此可能会遭受一种称为共振的现象。我们将学习系统近似为一个时变的常微分方程系统，并利用现有理论将系统的发散/收敛特性描述为共振/非共振模式。理论结果仅限于具有周期性协变量偏移的线性设置，因此我们通过实验补充这一结果，以表明即使在非周期性协变量偏移、具有神经网络的非线性动态以及除SGDm之外的优化器下，共振现象仍然存在。",
        "领域": "持续学习, 强化学习, 优化算法",
        "问题": "在协变量偏移条件下，带动量的随机梯度下降（SGDm）可能发散的问题",
        "动机": "探索SGDm在非独立同分布采样条件下的行为，特别是在协变量偏移情况下，可能导致算法不稳定的现象",
        "方法": "将SGDm在协变量偏移下的行为建模为参数振荡器，利用时变常微分方程系统理论分析其发散/收敛特性，并通过实验验证共振现象的存在",
        "关键词": [
            "带动量的随机梯度下降",
            "协变量偏移",
            "共振现象",
            "参数振荡器",
            "时变系统"
        ],
        "涉及的技术概念": {
            "带动量的随机梯度下降（SGDm）": "一种优化算法，通过引入动量项来加速收敛过程，减少震荡",
            "协变量偏移": "输入数据的分布随时间变化的现象，影响模型的训练和泛化能力",
            "共振现象": "在特定条件下，系统对外部激励的响应显著增强的现象，可能导致系统不稳定或发散"
        },
        "success": true
    },
    {
        "order": 845,
        "title": "Responsible Disclosure of Generative Models Using Scalable Fingerprinting",
        "html": "https://iclr.cc//virtual/2022/poster/6395",
        "abstract": "Over the past years, deep generative models have achieved a new level of performance. Generated data has become difficult, if not impossible, to be distinguished from real data. While there are plenty of use cases that benefit from this technology, there are also strong concerns on how this new technology can be misused to generate deep fakes and enable misinformation at scale. Unfortunately, current deep fake detection methods are not sustainable, as the gap between real and fake continues to close. In contrast, our work enables a responsible disclosure of such state-of-the-art generative models, that allows model inventors to fingerprint their models, so that the generated samples containing a fingerprint can be accurately detected and attributed to a source. Our technique achieves this by an efficient and scalable ad-hoc generation of a large population of models with distinct fingerprints. Our recommended operation point uses a 128-bit fingerprint which in principle results in more than 10^{38} identifiable models. Experiments show that our method fulfills key properties of a fingerprinting mechanism and achieves effectiveness in deep fake detection and attribution. Code and models are available at https://github.com/ningyu1991/ScalableGANFingerprints.",
        "conference": "ICLR",
        "中文标题": "使用可扩展指纹技术负责任地公开生成模型",
        "摘要翻译": "过去几年中，深度生成模型的性能达到了一个新的水平。生成的数据变得难以（如果不是不可能）与真实数据区分开来。虽然有许多用例受益于这项技术，但也有强烈的担忧关于这项新技术如何被滥用来生成深度伪造品并大规模传播错误信息。不幸的是，当前的深度伪造检测方法不可持续，因为真实与伪造之间的差距不断缩小。相比之下，我们的工作使得能够负责任地公开这些最先进的生成模型，允许模型发明者为他们的模型添加指纹，从而可以准确地检测到包含指纹的生成样本并将其归因于来源。我们的技术通过高效且可扩展的临时生成大量具有不同指纹的模型来实现这一点。我们推荐的运行点使用128位指纹，原则上可以产生超过10^38个可识别的模型。实验表明，我们的方法满足了指纹机制的关键属性，并在深度伪造检测和归因方面取得了有效性。代码和模型可在https://github.com/ningyu1991/ScalableGANFingerprints获取。",
        "领域": "深度伪造检测、生成对抗网络、模型指纹技术",
        "问题": "如何在大规模生成模型中实现有效的指纹技术，以便于检测和归因深度伪造内容",
        "动机": "解决深度伪造技术被滥用的问题，提供一种可持续的方法来识别和追踪生成模型的输出",
        "方法": "通过高效且可扩展的临时生成大量具有不同指纹的模型，实现生成样本的准确检测和归因",
        "关键词": [
            "生成模型",
            "指纹技术",
            "深度伪造检测",
            "模型归因",
            "可扩展性"
        ],
        "涉及的技术概念": {
            "指纹技术": "用于在生成模型中嵌入独特的标识，以便于检测和归因生成的样本",
            "生成对抗网络": "用于生成高质量的数据样本，是本研究中生成模型的基础技术",
            "深度伪造检测": "本研究的目标应用之一，通过指纹技术提高检测的准确性和可持续性"
        },
        "success": true
    },
    {
        "order": 846,
        "title": "Rethinking Adversarial Transferability from a Data Distribution Perspective",
        "html": "https://iclr.cc//virtual/2022/poster/7004",
        "abstract": "Adversarial transferability enables attackers to generate adversarial examples from the source model to attack the target model, which has raised security concerns about the deployment of DNNs in practice. In this paper, we rethink adversarial transferability from a data distribution perspective and further enhance transferability by score matching based optimization. We identify that some samples with injecting small Gaussian noise can fool different target models, and their adversarial examples under different source models have much stronger transferability. We hypothesize that these samples are in the low-density region of the ground truth distribution where models are not well trained. To improve the attack success rate of adversarial examples, we match the adversarial attacks with the directions which effectively decrease the ground truth density. We propose Intrinsic Adversarial Attack (IAA), which smooths the activation function and decreases the impact of the later layers of a given normal model, to increase the alignment of adversarial attack and the gradient of joint data distribution. We conduct comprehensive transferable attacks against multiple DNNs and show that our IAA can boost the transferability of the crafted attacks in all cases and go beyond state-of-the-art methods.",
        "conference": "ICLR",
        "中文标题": "从数据分布角度重新思考对抗性可转移性",
        "摘要翻译": "对抗性可转移性使得攻击者能够从源模型生成对抗样本来攻击目标模型，这引发了关于在实践中部署深度神经网络的安全担忧。在本文中，我们从数据分布的角度重新思考对抗性可转移性，并通过基于分数匹配的优化进一步增强可转移性。我们发现，一些注入小高斯噪声的样本可以欺骗不同的目标模型，并且它们在不同源模型下的对抗样本具有更强的可转移性。我们假设这些样本位于真实分布的低密度区域，模型在这些区域没有得到很好的训练。为了提高对抗样本的攻击成功率，我们将对抗攻击与有效降低真实密度的方向相匹配。我们提出了内在对抗攻击（IAA），它平滑激活函数并减少给定正常模型后层的影响，以增加对抗攻击与联合数据分布梯度的对齐。我们对多个深度神经网络进行了全面的可转移攻击，并表明我们的IAA在所有情况下都能提升所制作攻击的可转移性，并超越最先进的方法。",
        "领域": "对抗性攻击、深度神经网络安全、模型鲁棒性",
        "问题": "如何从数据分布的角度理解和增强对抗性攻击的可转移性。",
        "动机": "对抗性可转移性对深度神经网络的实际部署构成安全威胁，需要从新的角度理解和提升其效果。",
        "方法": "通过基于分数匹配的优化方法，识别并利用数据分布的低密度区域，提出内在对抗攻击（IAA）以增强对抗样本的可转移性。",
        "关键词": [
            "对抗性可转移性",
            "内在对抗攻击",
            "数据分布",
            "深度神经网络安全",
            "模型鲁棒性"
        ],
        "涉及的技术概念": {
            "对抗性可转移性": "指对抗样本从一个模型转移到另一个模型的能力，是评估对抗攻击效果的关键指标。",
            "内在对抗攻击（IAA）": "一种通过平滑激活函数和减少后层影响来增强对抗攻击与数据分布梯度对齐的方法。",
            "数据分布的低密度区域": "指数据分布中样本稀疏的区域，模型在这些区域的训练不足，对抗样本更容易在这些区域生成。"
        },
        "success": true
    },
    {
        "order": 847,
        "title": "Rethinking Class-Prior Estimation for Positive-Unlabeled Learning",
        "html": "https://iclr.cc//virtual/2022/poster/7212",
        "abstract": "Given only positive (P) and unlabeled (U) data, PU learning can train a binary classifier without any negative data. It has two building blocks: PU class-prior estimation (CPE) and PU classification; the latter has been well studied while the former has received less attention. Hitherto, the distributional-assumption-free CPE methods rely on a critical assumption that the support of the positive data distribution cannot be contained in the support of the negative data distribution. If this is violated, those CPE methods will systematically overestimate the class prior; it is even worse that we cannot verify the assumption based on the data. In this paper, we rethink CPE for PU learning—can we remove the assumption to make CPE always valid? We show an affirmative answer by proposing Regrouping CPE (ReCPE) that builds an auxiliary probability distribution such that the support of the positive data distribution is never contained in the support of the negative data distribution. ReCPE can work with any CPE method by treating it as the base method. Theoretically, ReCPE does not affect its base if the assumption already holds for the original probability distribution; otherwise, it reduces the positive bias of its base. Empirically, ReCPE improves all state-of-the-art CPE methods on various datasets, implying that the assumption has indeed been violated here.",
        "conference": "ICLR",
        "中文标题": "重新思考正未标记学习中的类先验估计",
        "摘要翻译": "仅给定正（P）和未标记（U）数据，正未标记（PU）学习可以在没有任何负数据的情况下训练二元分类器。它有两个构建模块：PU类先验估计（CPE）和PU分类；后者已被充分研究，而前者受到的关注较少。迄今为止，无分布假设的CPE方法依赖于一个关键假设，即正数据分布的支撑集不能被包含在负数据分布的支撑集中。如果这一假设被违反，这些CPE方法将系统地高估类先验；更糟糕的是，我们无法基于数据验证这一假设。在本文中，我们重新思考了PU学习中的CPE——我们能否移除这一假设，使CPE始终有效？我们通过提出重组CPE（ReCPE）给出了肯定的答案，该方法构建了一个辅助概率分布，使得正数据分布的支撑集永远不会被包含在负数据分布的支撑集中。ReCPE可以通过将其视为基础方法与任何CPE方法一起工作。理论上，如果原始概率分布的假设已经成立，ReCPE不会影响其基础；否则，它会减少其基础的正偏差。实证上，ReCPE在各种数据集上改进了所有最先进的CPE方法，这意味着这里的假设确实被违反了。",
        "领域": "正未标记学习",
        "问题": "解决在正未标记学习中类先验估计方法依赖于一个关键假设的问题，该假设在实际应用中可能不成立。",
        "动机": "移除正未标记学习中类先验估计方法的限制性假设，使其更加通用和有效。",
        "方法": "提出重组CPE（ReCPE），通过构建辅助概率分布来避免正数据分布的支撑集被包含在负数据分布的支撑集中，从而移除关键假设。",
        "关键词": [
            "正未标记学习",
            "类先验估计",
            "重组CPE"
        ],
        "涉及的技术概念": {
            "正未标记学习": "一种仅使用正数据和未标记数据训练分类器的学习方法。",
            "类先验估计": "估计数据集中正类样本的比例，是正未标记学习的关键步骤之一。",
            "重组CPE": "一种新的类先验估计方法，通过构建辅助概率分布来移除对正负数据分布支撑集关系的假设。"
        },
        "success": true
    },
    {
        "order": 848,
        "title": "Rethinking Goal-Conditioned Supervised Learning and Its Connection to Offline RL",
        "html": "https://iclr.cc//virtual/2022/poster/6583",
        "abstract": "Solving goal-conditioned tasks with sparse rewards using self-supervised learning is promising because of its simplicity and stability over current reinforcement learning (RL) algorithms. A recent work, called Goal-Conditioned Supervised Learning (GCSL), provides a new learning framework by iteratively relabeling and imitating self-generated experiences. In this paper, we revisit the theoretical property of GCSL --- optimizing a lower bound of the goal reaching objective, and extend GCSL as a novel offline goal-conditioned RL algorithm. The proposed method is named Weighted GCSL (WGCSL), in which we introduce an advanced compound weight consisting of three parts (1) discounted weight for goal relabeling, (2) goal-conditioned exponential advantage weight, and (3) best-advantage weight. Theoretically, WGCSL is proved to optimize an equivalent lower bound of the goal-conditioned RL objective and generates monotonically improved policies via an iterated scheme. The monotonic property holds for any behavior policies, and therefore WGCSL can be applied to both online and offline settings. To evaluate algorithms in the offline goal-conditioned RL setting, we provide a benchmark including a range of point and simulated robot domains. Experiments in the introduced benchmark demonstrate that WGCSL can consistently outperform GCSL and existing state-of-the-art offline methods in the fully offline goal-conditioned setting.",
        "conference": "ICLR",
        "中文标题": "重新思考目标条件监督学习及其与离线强化学习的联系",
        "摘要翻译": "利用自监督学习解决稀疏奖励的目标条件任务因其相对于当前强化学习（RL）算法的简单性和稳定性而显得前景广阔。最近的一项工作，称为目标条件监督学习（GCSL），通过迭代地重新标记和模仿自我生成的经验，提供了一个新的学习框架。在本文中，我们重新审视了GCSL的理论特性——优化目标达成目标的下界，并将GCSL扩展为一种新颖的离线目标条件RL算法。所提出的方法被命名为加权GCSL（WGCSL），其中我们引入了一个由三部分组成的高级复合权重：（1）用于目标重新标记的折扣权重，（2）目标条件指数优势权重，和（3）最佳优势权重。理论上，WGCSL被证明可以优化目标条件RL目标的等效下界，并通过迭代方案生成单调改进的策略。单调性质适用于任何行为策略，因此WGCSL可以应用于在线和离线设置。为了在离线目标条件RL设置中评估算法，我们提供了一个包括一系列点和模拟机器人领域的基准。在引入的基准测试中的实验表明，WGCSL在完全离线目标条件设置中可以持续优于GCSL和现有的最先进离线方法。",
        "领域": "强化学习、机器人控制、自监督学习",
        "问题": "如何在稀疏奖励环境下有效解决目标条件任务",
        "动机": "探索一种比当前强化学习算法更简单、更稳定的方法来解决稀疏奖励的目标条件任务",
        "方法": "提出加权目标条件监督学习（WGCSL），通过引入复合权重优化目标达成目标的下界，并生成单调改进的策略",
        "关键词": [
            "目标条件监督学习",
            "离线强化学习",
            "稀疏奖励",
            "自监督学习",
            "机器人控制"
        ],
        "涉及的技术概念": {
            "目标条件监督学习（GCSL）": "通过迭代地重新标记和模仿自我生成的经验来学习目标达成策略的框架",
            "加权GCSL（WGCSL）": "引入复合权重优化目标达成目标的下界，扩展GCSL为离线目标条件RL算法",
            "复合权重": "由折扣权重、目标条件指数优势权重和最佳优势权重组成，用于优化策略"
        },
        "success": true
    },
    {
        "order": 849,
        "title": "Rethinking Network Design and Local Geometry in Point Cloud: A Simple Residual MLP Framework",
        "html": "https://iclr.cc//virtual/2022/poster/6005",
        "abstract": "Point cloud analysis is challenging due to irregularity and unordered data structure. To capture the 3D geometries, prior works mainly rely on exploring sophisticated local geometric extractors, using convolution, graph, or attention mechanisms. These methods, however, incur unfavorable latency during inference and the performance saturates over the past few years. In this paper, we present an ovel perspective on this task. We find detailed local geometrical informationprobably is not the key to point cloud analysis – we introduce a pure residual MLP network, called PointMLP, which integrates no local geometrical extractors but still performs very competitively. Equipped with a proposed lightweight geometric-affine module to stabilize the training, PointMLP delivers the new state-of-the-art on multiple datasets. On the real-world ScanObjectNN dataset, our method even surpasses the prior best method by 3.3% accuracy. We emphasize PointMLP achieves this strong performance without any sophisticated operations, hence leading to a prominent inference speed. Compared to most recent CurveNet, PointMLP trains 2× faster, tests 7× faster, and is more accurate on ModelNet40 benchmark. We hope our PointMLP may help the community towards a better understanding of point cloud analysis. The code is available at https://github.com/ma-xu/pointMLP-pytorch.",
        "conference": "ICLR",
        "中文标题": "重新思考点云中的网络设计与局部几何：一个简单的残差MLP框架",
        "摘要翻译": "由于数据结构的非规则性和无序性，点云分析具有挑战性。为了捕捉3D几何特征，先前的工作主要依赖于探索复杂的局部几何提取器，使用卷积、图或注意力机制。然而，这些方法在推理过程中会产生不利的延迟，并且性能在过去几年中趋于饱和。在本文中，我们提出了一个新颖的视角。我们发现详细的局部几何信息可能不是点云分析的关键——我们引入了一个纯粹的残差MLP网络，称为PointMLP，它没有集成任何局部几何提取器，但仍然表现出非常强的竞争力。配备了一个提出的轻量级几何仿射模块以稳定训练，PointMLP在多个数据集上提供了新的最先进性能。在真实世界的ScanObjectNN数据集上，我们的方法甚至比先前的最佳方法准确率高出3.3%。我们强调PointMLP在没有使用任何复杂操作的情况下实现了这一强劲性能，因此带来了显著的推理速度。与最近的CurveNet相比，PointMLP训练速度快2倍，测试速度快7倍，并且在ModelNet40基准测试上更准确。我们希望我们的PointMLP可以帮助社区更好地理解点云分析。代码可在https://github.com/ma-xu/pointMLP-pytorch获取。",
        "领域": "点云分析",
        "问题": "点云分析中复杂的局部几何提取器导致的推理延迟和性能饱和问题",
        "动机": "探索点云分析中局部几何信息的重要性，并提出一个不依赖复杂局部几何提取器的高效网络框架",
        "方法": "提出一个纯粹的残差MLP网络PointMLP，配备轻量级几何仿射模块，以稳定训练并提高性能",
        "关键词": [
            "点云分析",
            "残差MLP",
            "几何仿射模块"
        ],
        "涉及的技术概念": {
            "残差MLP": "一种多层感知机网络，通过残差连接增强信息流动，提高模型性能",
            "几何仿射模块": "用于稳定训练过程的轻量级模块，通过仿射变换调整特征表示",
            "点云分析": "处理和分析三维空间中点的集合，用于理解和建模三维几何结构"
        },
        "success": true
    },
    {
        "order": 850,
        "title": "Rethinking Supervised Pre-Training for Better Downstream Transferring",
        "html": "https://iclr.cc//virtual/2022/poster/6590",
        "abstract": "The pretrain-finetune paradigm has shown outstanding performance on many applications of deep learning, where a model is pre-trained on an upstream large dataset (e.g. ImageNet), and is then fine-tuned to different downstream tasks. Though for most cases, the pre-training stage is conducted based on supervised methods, recent works on self-supervised pre-training have shown powerful transferability and even outperform supervised pre-training on multiple downstream tasks. It thus remains an open question how to better generalize supervised pre- training model to downstream tasks. In this paper, we argue that the worse transferability of existing supervised pre-training methods arise from the negligence of valuable intra-class semantic difference. This is because these methods tend to push images from the same class close to each other despite of the large diversity in their visual contents, a problem to which referred as “overfit of upstream tasks”. To alleviate this problem, we propose a new supervised pre-training method based on Leave-One-Out K-Nearest-Neighbor, or LOOK for short. It relieves the problem of overfitting upstream tasks by only requiring each image to share its class label with most of its k nearest neighbors, thus allowing each class to exhibit a multi-mode distribution and consequentially preserving part of intra-class difference for better transferring to downstream tasks. We developed efficient implementation of the proposed method that scales well to large datasets. Experimental studies on multiple downstream tasks show that LOOK outperforms other state-of-the-art methods for supervised and self-supervised pre-training.",
        "conference": "ICLR",
        "中文标题": "重新思考监督式预训练以实现更优的下游迁移",
        "摘要翻译": "预训练-微调范式在深度学习的许多应用中表现出色，其中模型首先在大型上游数据集（如ImageNet）上进行预训练，然后针对不同的下游任务进行微调。尽管在大多数情况下，预训练阶段是基于监督方法进行的，但最近关于自监督预训练的研究显示出强大的迁移能力，甚至在多个下游任务上超越了监督预训练。因此，如何更好地将监督预训练模型泛化到下游任务仍然是一个开放性问题。在本文中，我们认为现有监督预训练方法迁移能力较差的原因在于忽视了有价值的类内语义差异。这是因为这些方法倾向于将来自同一类的图像在视觉内容上的大多样性情况下彼此靠近，这一问题被称为“上游任务的过拟合”。为了缓解这一问题，我们提出了一种基于留一法K最近邻（简称LOOK）的新监督预训练方法。它通过仅要求每个图像与其k个最近邻中的大多数共享其类别标签，从而缓解上游任务过拟合的问题，允许每个类别表现出多模态分布，从而保留部分类内差异以更好地迁移到下游任务。我们开发了所提出方法的高效实现，能够很好地扩展到大型数据集。在多个下游任务上的实验研究表明，LOOK在监督和自监督预训练方面优于其他最先进的方法。",
        "领域": "自监督学习",
        "问题": "如何提高监督预训练模型在下游任务中的迁移能力",
        "动机": "现有监督预训练方法忽视了类内语义差异，导致迁移能力不足",
        "方法": "提出基于留一法K最近邻（LOOK）的监督预训练方法，保留类内差异以提高迁移能力",
        "关键词": [
            "监督预训练",
            "下游迁移",
            "类内差异",
            "留一法K最近邻",
            "多模态分布"
        ],
        "涉及的技术概念": {
            "监督预训练": "在大型上游数据集上使用监督学习方法进行模型预训练",
            "留一法K最近邻": "一种用于缓解上游任务过拟合的技术，通过要求图像与其k个最近邻中的大多数共享类别标签",
            "多模态分布": "允许每个类别在特征空间中表现出多个分布模式，以保留类内差异"
        },
        "success": true
    },
    {
        "order": 851,
        "title": "Retriever: Learning Content-Style Representation as a Token-Level Bipartite Graph",
        "html": "https://iclr.cc//virtual/2022/poster/5926",
        "abstract": "This paper addresses the unsupervised learning of content-style decomposed representation. We first give a definition of style and then model the content-style representation as a token-level bipartite graph. An unsupervised framework, named Retriever, is proposed to learn such representations. First, a cross-attention module is employed to retrieve permutation invariant (P.I.) information, defined as style, from the input data. Second, a vector quantization (VQ) module is used, together with man-induced constraints, to produce interpretable content tokens. Last, an innovative link attention module serves as the decoder to reconstruct data from the decomposed content and style, with the help of the linking keys. Being modal-agnostic, the proposed Retriever is evaluated in both speech and image domains. The state-of-the-art zero-shot voice conversion performance confirms the disentangling ability of our framework. Top performance is also achieved in the part discovery task for images, verifying the interpretability of our representation. In addition, the vivid part-based style transfer quality demonstrates the potential of Retriever to support various fascinating generative tasks. Project page at https://ydcustc.github.io/retriever-demo/.",
        "conference": "ICLR",
        "中文标题": "检索器：学习内容-风格表示作为令牌级二分图",
        "摘要翻译": "本文探讨了内容-风格分解表示的无监督学习。我们首先定义了风格，然后将内容-风格表示建模为令牌级的二分图。提出了一个名为Retriever的无监督框架来学习这种表示。首先，采用交叉注意力模块从输入数据中检索排列不变（P.I.）信息，定义为风格。其次，使用向量量化（VQ）模块结合人为引入的约束，生成可解释的内容令牌。最后，创新的链接注意力模块作为解码器，借助链接键从分解的内容和风格中重建数据。由于模态无关性，提出的Retriever在语音和图像领域都进行了评估。最先进的零样本语音转换性能证实了我们框架的解缠能力。在图像的部分发现任务中也达到了顶级性能，验证了我们表示的可解释性。此外，基于部分的生动风格转换质量展示了Retriever支持各种迷人生成任务的潜力。项目页面见https://ydcustc.github.io/retriever-demo/。",
        "领域": "语音转换, 图像风格转换, 无监督学习",
        "问题": "如何在无监督的情况下学习内容与风格的分解表示",
        "动机": "探索内容与风格的无监督分解表示，以支持语音和图像领域的多种生成任务",
        "方法": "通过交叉注意力模块检索风格信息，使用向量量化模块生成内容令牌，并通过链接注意力模块重建数据",
        "关键词": [
            "无监督学习",
            "内容-风格分解",
            "二分图",
            "语音转换",
            "图像风格转换"
        ],
        "涉及的技术概念": {
            "交叉注意力模块": "用于从输入数据中检索排列不变信息，定义为风格",
            "向量量化模块": "结合人为约束生成可解释的内容令牌",
            "链接注意力模块": "作为解码器，从分解的内容和风格中重建数据"
        },
        "success": true
    },
    {
        "order": 852,
        "title": "Reverse Engineering of Imperceptible Adversarial Image Perturbations",
        "html": "https://iclr.cc//virtual/2022/poster/6892",
        "abstract": "It has been well recognized that neural network based image classifiers are easily fooled by images with tiny perturbations crafted by an adversary. There has been a vast volume of research to generate and defend such adversarial attacks. However, the following problem is left unexplored: How to reverse-engineer adversarial perturbations from an adversarial image? This leads to a new adversarial learning paradigm—Reverse Engineering of Deceptions (RED). If successful, RED allows us to estimate adversarial perturbations and recover the original images. However, carefully crafted, tiny adversarial perturbations are difficult to recover by optimizing a unilateral RED objective. For example, the pure image denoising method may overfit to minimizing the reconstruction error but hardly preserve the classification properties of the true adversarial perturbations.  To tackle this challenge, we formalize the RED problem and identify a set of principles crucial to the RED approach design. Particularly, we find that prediction alignment and proper data augmentation (in terms of spatial transformations) are two criteria to achieve a generalizable RED approach. By integrating these RED principles with image denoising, we propose a new Class-Discriminative Denoising based RED framework, termed CDD-RED. Extensive experiments demonstrate the effectiveness of CDD-RED under different evaluation metrics (ranging from the pixel-level, prediction-level to the attribution-level alignment) and a variety of attack generation methods (e.g., FGSM, PGD, CW, AutoAttack, and adaptive attacks).",
        "conference": "ICLR",
        "中文标题": "不可察觉对抗性图像扰动的逆向工程",
        "摘要翻译": "众所周知，基于神经网络的图像分类器容易被对手精心制作的微小扰动图像所愚弄。已有大量研究致力于生成和防御此类对抗性攻击。然而，以下问题尚未被探索：如何从对抗性图像中逆向工程出对抗性扰动？这引出了一个全新的对抗性学习范式——欺骗的逆向工程（RED）。如果成功，RED将使我们能够估计对抗性扰动并恢复原始图像。然而，通过优化单边的RED目标来恢复精心制作的微小对抗性扰动是困难的。例如，纯图像去噪方法可能会过度拟合于最小化重建误差，但很难保留真实对抗性扰动的分类属性。为了应对这一挑战，我们形式化了RED问题，并确定了一组对RED方法设计至关重要的原则。特别是，我们发现预测对齐和适当的数据增强（在空间变换方面）是实现可泛化RED方法的两个标准。通过将这些RED原则与图像去噪相结合，我们提出了一种新的基于类判别去噪的RED框架，称为CDD-RED。大量实验证明了CDD-RED在不同评估指标（从像素级、预测级到归因级对齐）和各种攻击生成方法（如FGSM、PGD、CW、AutoAttack和自适应攻击）下的有效性。",
        "领域": "对抗性攻击防御、图像分类安全、深度学习安全",
        "问题": "如何从对抗性图像中逆向工程出对抗性扰动",
        "动机": "探索并解决对抗性图像扰动逆向工程的问题，以估计扰动并恢复原始图像",
        "方法": "通过形式化RED问题，结合预测对齐和数据增强原则，提出基于类判别去噪的CDD-RED框架",
        "关键词": [
            "对抗性攻击",
            "逆向工程",
            "图像去噪",
            "深度学习安全",
            "分类器鲁棒性"
        ],
        "涉及的技术概念": {
            "欺骗的逆向工程（RED）": "一种新的对抗性学习范式，旨在从对抗性图像中逆向工程出对抗性扰动",
            "类判别去噪（CDD-RED）": "结合RED原则与图像去噪技术，提出的新框架，用于恢复对抗性扰动并保持分类属性",
            "预测对齐和数据增强": "RED方法设计中的两个关键原则，确保方法的泛化能力和有效性"
        },
        "success": true
    },
    {
        "order": 853,
        "title": "Reversible Instance Normalization for Accurate Time-Series Forecasting against Distribution Shift",
        "html": "https://iclr.cc//virtual/2022/poster/6034",
        "abstract": "Statistical properties such as mean and variance often change over time in time series, i.e., time-series data suffer from a distribution shift problem. This change in temporal distribution is one of the main challenges that prevent accurate time-series forecasting. To address this issue, we propose a simple yet effective normalization method called reversible instance normalization (RevIN), a generally-applicable normalization-and-denormalization method with learnable affine transformation. The proposed method is symmetrically structured to remove and restore the statistical information of a time-series instance, leading to significant performance improvements in time-series forecasting, as shown in Fig. 1. We demonstrate the effectiveness of RevIN via extensive quantitative and qualitative analyses on various real-world datasets, addressing the distribution shift problem.",
        "conference": "ICLR",
        "中文标题": "可逆实例归一化：针对分布偏移的精确时间序列预测",
        "摘要翻译": "时间序列中的统计属性（如均值和方差）通常会随时间变化，即时间序列数据存在分布偏移问题。这种时间分布的变化是阻碍精确时间序列预测的主要挑战之一。为了解决这一问题，我们提出了一种简单而有效的归一化方法，称为可逆实例归一化（RevIN），这是一种具有可学习仿射变换的通用归一化和反归一化方法。所提出的方法采用对称结构来移除和恢复时间序列实例的统计信息，从而显著提高时间序列预测的性能，如图1所示。我们通过对各种真实世界数据集进行广泛的定量和定性分析，证明了RevIN在解决分布偏移问题方面的有效性。",
        "领域": "时间序列预测",
        "问题": "时间序列数据中的分布偏移问题阻碍了精确预测",
        "动机": "解决时间序列数据中因统计属性随时间变化而导致的分布偏移问题，以提高预测的准确性",
        "方法": "提出了一种称为可逆实例归一化（RevIN）的归一化和反归一化方法，该方法具有可学习的仿射变换，采用对称结构来移除和恢复时间序列实例的统计信息",
        "关键词": [
            "时间序列预测",
            "分布偏移",
            "可逆实例归一化",
            "仿射变换",
            "统计信息"
        ],
        "涉及的技术概念": {
            "可逆实例归一化（RevIN）": "一种通用的归一化和反归一化方法，具有可学习的仿射变换，用于移除和恢复时间序列实例的统计信息",
            "分布偏移": "时间序列数据中统计属性随时间变化的现象，是时间序列预测中的主要挑战之一",
            "仿射变换": "RevIN方法中的一种可学习变换，用于调整归一化和反归一化过程中的统计信息"
        },
        "success": true
    },
    {
        "order": 854,
        "title": "Revisiting Design Choices in Offline Model Based Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6699",
        "abstract": "Offline reinforcement learning enables agents to leverage large pre-collected datasets of environment transitions to learn control policies, circumventing the need for potentially expensive or unsafe online data collection. Significant progress has been made recently in offline model-based reinforcement learning, approaches which leverage a learned dynamics model. This typically involves constructing a probabilistic model, and using the model uncertainty to penalize rewards where there is insufficient data, solving for a pessimistic MDP that lower bounds the true MDP. Existing methods, however, exhibit a breakdown between theory and practice, whereby pessimistic return ought to be bounded by the total variation distance of the model from the true dynamics, but is instead implemented through a penalty based on estimated model uncertainty. This has spawned a variety of uncertainty heuristics, with little to no comparison between differing approaches. In this paper, we compare these heuristics, and design novel protocols to investigate their interaction with other hyperparameters, such as the number of models, or imaginary rollout horizon. Using these insights, we show that selecting these key hyperparameters using Bayesian Optimization produces superior configurations that are vastly different to those currently used in existing hand-tuned state-of-the-art methods, and result in drastically stronger performance.",
        "conference": "ICLR",
        "中文标题": "重新审视离线模型基于强化学习的设计选择",
        "摘要翻译": "离线强化学习使智能体能够利用预先收集的大量环境转换数据集来学习控制策略，从而避免了可能昂贵或不安全的在线数据收集的需要。最近，在离线模型基于强化学习方面取得了显著进展，这些方法利用学习到的动态模型。这通常涉及构建一个概率模型，并使用模型不确定性来惩罚数据不足的奖励，解决一个悲观MDP，该MDP下界于真实MDP。然而，现有方法在理论与实践之间存在脱节，理论上悲观的回报应该受到模型与真实动态的总变差距离的限制，但实际上却是通过基于估计模型不确定性的惩罚来实现的。这催生了各种不确定性启发式方法，但不同方法之间几乎没有比较。在本文中，我们比较了这些启发式方法，并设计了新的协议来研究它们与其他超参数的相互作用，如模型数量或想象推出范围。利用这些见解，我们展示了使用贝叶斯优化选择这些关键超参数可以产生优于现有手工调整的最先进方法的配置，这些配置与当前使用的配置大不相同，并导致性能大幅提升。",
        "领域": "强化学习、模型预测控制、贝叶斯优化",
        "问题": "离线模型基于强化学习方法在理论与实践之间的脱节问题",
        "动机": "解决现有离线模型基于强化学习方法中理论与实践不一致的问题，探索更有效的超参数选择方法",
        "方法": "比较不同的不确定性启发式方法，设计新协议研究其与超参数的相互作用，使用贝叶斯优化选择关键超参数",
        "关键词": [
            "离线强化学习",
            "模型不确定性",
            "贝叶斯优化",
            "超参数选择",
            "悲观MDP"
        ],
        "涉及的技术概念": {
            "悲观MDP": "通过构建一个下界于真实MDP的概率模型，使用模型不确定性惩罚数据不足的奖励",
            "贝叶斯优化": "用于选择关键超参数，以产生优于现有手工调整方法的配置",
            "模型不确定性": "在离线模型基于强化学习中，用于惩罚数据不足的奖励，解决理论与实践脱节的问题"
        },
        "success": true
    },
    {
        "order": 855,
        "title": "Revisiting flow generative models for Out-of-distribution detection",
        "html": "https://iclr.cc//virtual/2022/poster/6013",
        "abstract": "Deep generative models have been widely used in practical applications such as the detection of out-of-distribution (OOD) data. In this work,  we aim to re-examine the potential of generative flow models in OOD detection. We first propose a simple combination of univariate one-sample statistical test (e.g., Kolmogorov-Smirnov) and random projections in the latent space of flow models to perform OOD detection.  Then, we propose a two-sample version of our test to account for imperfect flow models. Quite distinctly, our method does not pose parametric assumptions on OOD data and is capable of exploiting any flow model. Experimentally, firstly we confirm the efficacy of our method against state-of-the-art baselines through extensive experiments on several image datasets; secondly we investigate the relationship between model accuracy (e.g., the generation quality) and the OOD detection performance, and found surprisingly that they are not always positively correlated; and thirdly we show that detection in the latent space of flow models generally outperforms detection in the sample space across various OOD datasets, hence highlighting the benefits of training a flow model.",
        "conference": "ICLR",
        "中文标题": "重新审视流生成模型在分布外检测中的应用",
        "摘要翻译": "深度生成模型已广泛应用于实际应用中，如分布外（OOD）数据的检测。在这项工作中，我们旨在重新审视生成流模型在OOD检测中的潜力。我们首先提出了一种简单的方法，结合单变量单样本统计测试（例如，Kolmogorov-Smirnov）和流模型潜在空间中的随机投影来进行OOD检测。然后，我们提出了我们测试的双样本版本，以考虑不完美的流模型。非常独特的是，我们的方法不对OOD数据提出参数假设，并且能够利用任何流模型。在实验方面，首先我们通过在几个图像数据集上的广泛实验确认了我们的方法相对于最先进基线方法的有效性；其次我们研究了模型准确性（例如，生成质量）与OOD检测性能之间的关系，并意外发现它们并不总是正相关的；第三我们展示了在流模型的潜在空间中进行检测通常优于在各种OOD数据集上的样本空间检测，从而突出了训练流模型的好处。",
        "领域": "生成模型、分布外检测、图像分析",
        "问题": "如何有效利用生成流模型进行分布外数据的检测",
        "动机": "重新评估生成流模型在分布外检测中的潜力，探索更有效的检测方法",
        "方法": "结合单变量单样本统计测试和流模型潜在空间中的随机投影进行OOD检测，并提出双样本测试版本以适应不完美的流模型",
        "关键词": [
            "生成流模型",
            "分布外检测",
            "统计测试",
            "潜在空间",
            "随机投影"
        ],
        "涉及的技术概念": {
            "生成流模型": "用于生成数据的模型，能够学习数据的潜在分布",
            "分布外检测": "识别不属于模型训练数据分布的数据",
            "统计测试": "用于评估数据是否符合特定分布的统计方法，如Kolmogorov-Smirnov测试"
        },
        "success": true
    },
    {
        "order": 856,
        "title": "Revisiting Over-smoothing in BERT from the Perspective of Graph",
        "html": "https://iclr.cc//virtual/2022/poster/6118",
        "abstract": "Recently over-smoothing phenomenon of Transformer-based models is observed in both vision and language fields. However, no existing work has delved deeper to further investigate the main cause of this phenomenon. In this work, we make the attempt to analyze the over-smoothing problem from the perspective of graph, where such problem was first discovered and explored. Intuitively, the self-attention matrix can be seen as a normalized adjacent matrix of a corresponding graph. Based on the above connection, we provide some theoretical analysis and find that layer normalization plays a key role in the over-smoothing issue of Transformer-based models. Specifically, if the standard deviation of layer normalization is sufficiently large, the output of Transformer stacks will converge to a specific low-rank subspace and result in over-smoothing. To alleviate the over-smoothing problem, we consider hierarchical fusion strategies, which combine the representations from different layers adaptively to make the output more diverse. Extensive experiment results on various data sets illustrate the effect of our fusion method.",
        "conference": "ICLR",
        "中文标题": "从图的角度重新审视BERT中的过度平滑问题",
        "摘要翻译": "最近，在视觉和语言领域都观察到了基于Transformer模型的过度平滑现象。然而，目前还没有工作深入探讨这一现象的主要原因。在这项工作中，我们尝试从图的角度分析过度平滑问题，这一问题最初是在图中被发现和探索的。直观上，自注意力矩阵可以被视为对应图的归一化邻接矩阵。基于上述联系，我们提供了一些理论分析，并发现层归一化在基于Transformer模型的过度平滑问题中起着关键作用。具体来说，如果层归一化的标准差足够大，Transformer堆栈的输出将收敛到一个特定的低秩子空间，并导致过度平滑。为了缓解过度平滑问题，我们考虑了分层融合策略，这些策略自适应地结合来自不同层的表示，以使输出更加多样化。在各种数据集上的大量实验结果说明了我们融合方法的有效性。",
        "领域": "自然语言处理与视觉结合、Transformer模型优化、图神经网络",
        "问题": "基于Transformer模型的过度平滑现象",
        "动机": "深入探讨Transformer模型中过度平滑现象的主要原因，并提出解决方案",
        "方法": "从图的角度分析过度平滑问题，提出分层融合策略以缓解问题",
        "关键词": [
            "过度平滑",
            "Transformer模型",
            "层归一化",
            "分层融合",
            "图神经网络"
        ],
        "涉及的技术概念": {
            "自注意力矩阵": "被视为对应图的归一化邻接矩阵，用于分析过度平滑问题",
            "层归一化": "在Transformer模型中起关键作用，其标准差大小影响模型的过度平滑现象",
            "分层融合策略": "自适应地结合来自不同层的表示，以增加输出的多样性，缓解过度平滑问题"
        },
        "success": true
    },
    {
        "order": 857,
        "title": "Revisit Kernel Pruning with Lottery Regulated Grouped Convolutions",
        "html": "https://iclr.cc//virtual/2022/poster/6611",
        "abstract": "Structured pruning methods which are capable of delivering a densely pruned network are among the most popular techniques in the realm of neural network pruning, where most methods prune the original network at a filter or layer level. Although such methods may provide immediate compression and acceleration benefits, we argue that the blanket removal of an entire filter or layer may result in undesired accuracy loss. In this paper, we revisit the idea of kernel pruning (to only prune one or several $k \\times k$ kernels out of a 3D-filter), a heavily overlooked approach under the context of structured pruning. This is because kernel pruning will naturally introduce sparsity to filters within the same convolutional layer — thus, making the remaining network no longer dense. We address this problem by proposing a versatile grouped pruning framework where we first cluster filters from each convolutional layer into equal-sized groups, prune the grouped kernels we deem unimportant from each filter group, then permute the remaining filters to form a densely grouped convolutional architecture (which also enables the parallel computing capability) for fine-tuning. Specifically, we consult empirical findings from a series of literature regarding $\\textit{Lottery Ticket Hypothesis}$ to determine the optimal clustering scheme per layer, and develop a simple yet cost-efficient greedy approximation algorithm to determine which group kernels to keep within each filter group. Extensive experiments also demonstrate our method often outperforms comparable SOTA methods with lesser data augmentation needed, smaller fine-tuning budget required, and sometimes even much simpler procedure executed (e.g., one-shot v. iterative). Please refer to our GitHub repository (https://github.com/choH/lottery_regulated_grouped_kernel_pruning) for code.",
        "conference": "ICLR",
        "中文标题": "重新审视基于彩票调节分组卷积的核剪枝",
        "摘要翻译": "结构化剪枝方法能够提供一个密集剪枝的网络，是神经网络剪枝领域中最受欢迎的技术之一，其中大多数方法在滤波器或层级上进行原始网络的剪枝。尽管这些方法可能立即提供压缩和加速的好处，我们认为全面移除整个滤波器或层可能导致不希望的准确度损失。在本文中，我们重新审视了核剪枝的想法（仅从3D滤波器中剪枝一个或几个$k \times k$核），这是在结构化剪枝背景下被严重忽视的方法。这是因为核剪枝会自然地引入同一卷积层内滤波器的稀疏性——因此，使剩余网络不再密集。我们通过提出一个多功能的分组剪枝框架来解决这个问题，其中我们首先将每个卷积层的滤波器聚类成大小相等的组，从每个滤波器组中剪枝我们认为不重要的分组核，然后排列剩余的滤波器以形成一个密集分组卷积架构（这也启用了并行计算能力）进行微调。具体来说，我们参考了一系列关于$\textit{彩票票假设}$的文献中的实证发现，以确定每层的最佳聚类方案，并开发了一个简单但成本效益高的贪婪近似算法，以确定在每个滤波器组中保留哪些分组核。大量实验也表明，我们的方法通常优于可比较的最先进方法，需要更少的数据增强，更小的微调预算，有时甚至执行更简单的过程（例如，一次性对比迭代）。请参考我们的GitHub仓库（https://github.com/choH/lottery_regulated_grouped_kernel_pruning）获取代码。",
        "领域": "神经网络剪枝",
        "问题": "如何在剪枝过程中减少准确度损失并保持网络的密集性",
        "动机": "解决传统结构化剪枝方法中因移除整个滤波器或层而导致的准确度损失问题",
        "方法": "提出一个多功能的分组剪枝框架，包括滤波器聚类、核剪枝和剩余滤波器排列，以形成密集分组卷积架构",
        "关键词": [
            "核剪枝",
            "分组卷积",
            "彩票票假设",
            "结构化剪枝",
            "神经网络优化"
        ],
        "涉及的技术概念": {
            "核剪枝": "从3D滤波器中剪枝一个或几个核，以减少模型大小和计算量",
            "分组卷积": "将滤波器聚类成组，以保持网络的密集性和并行计算能力",
            "彩票票假设": "用于确定每层滤波器的最佳聚类方案，以优化剪枝效果"
        },
        "success": true
    },
    {
        "order": 858,
        "title": "Reward Uncertainty for Exploration in Preference-based Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6956",
        "abstract": "Conveying complex objectives to reinforcement learning (RL) agents often requires meticulous reward engineering. Preference-based RL methods are able to learn a more flexible reward model based on human preferences by actively incorporating human feedback, i.e. teacher's preferences between two clips of behaviors. However, poor feedback-efficiency still remains as a problem in current preference-based RL algorithms, as tailored human feedback is very expensive. To handle this issue, previous methods have mainly focused on improving query selection and policy initialization. At the same time, recent exploration methods have proven to be a recipe for improving sample-efficiency in RL. We present an exploration method specifically for preference-based RL algorithms. Our main idea is to design an intrinsic reward by measuring the novelty based on learned reward. Specifically, we utilize disagreement across ensemble of learned reward models. Our intuition is that disagreement in learned reward model reflects uncertainty in tailored human feedback and could be useful for exploration. Our experiments show that reward uncertainty exploration improves both feedback- and sample-efficiency of preference-based RL algorithms on complex robot manipulation tasks from Meta-World benchmarks, compared with other existing exploration methods that measure the novelty of state visitation.",
        "conference": "ICLR",
        "中文标题": "基于偏好的强化学习中探索的奖励不确定性",
        "摘要翻译": "向强化学习（RL）智能体传达复杂目标通常需要精细的奖励工程。基于偏好的RL方法能够通过主动融入人类反馈（即教师对两种行为片段的偏好）来学习更灵活的奖励模型。然而，当前基于偏好的RL算法中，反馈效率低仍然是一个问题，因为定制的人类反馈非常昂贵。为了解决这个问题，以前的方法主要集中在改进查询选择和策略初始化上。同时，最近的探索方法已被证明是提高RL样本效率的良方。我们提出了一种专门为基于偏好的RL算法设计的探索方法。我们的主要思想是通过基于学习到的奖励来衡量新颖性来设计内在奖励。具体来说，我们利用了学习到的奖励模型集合中的分歧。我们的直觉是，学习到的奖励模型中的分歧反映了定制人类反馈的不确定性，可能对探索有用。我们的实验表明，与测量状态访问新颖性的其他现有探索方法相比，奖励不确定性探索提高了基于偏好的RL算法在Meta-World基准测试中的复杂机器人操作任务上的反馈和样本效率。",
        "领域": "强化学习、机器人操作、人机交互",
        "问题": "提高基于偏好的强化学习算法的反馈和样本效率",
        "动机": "定制的人类反馈成本高昂，且当前基于偏好的RL算法反馈效率低",
        "方法": "设计了一种基于学习到的奖励模型分歧的内在奖励，用于探索",
        "关键词": [
            "偏好学习",
            "奖励不确定性",
            "探索策略",
            "机器人操作",
            "反馈效率"
        ],
        "涉及的技术概念": {
            "偏好学习": "通过人类反馈学习奖励模型的方法",
            "奖励不确定性": "利用奖励模型集合中的分歧来衡量新颖性，用于探索",
            "探索策略": "设计内在奖励以引导智能体探索未知或不确定的环境区域"
        },
        "success": true
    },
    {
        "order": 859,
        "title": "RISP: Rendering-Invariant State Predictor with Differentiable Simulation and Rendering for Cross-Domain Parameter Estimation",
        "html": "https://iclr.cc//virtual/2022/poster/6921",
        "abstract": "This work considers identifying parameters characterizing a physical system's dynamic motion directly from a video whose rendering configurations are inaccessible. Existing solutions require massive training data or lack generalizability to unknown rendering configurations. We propose a novel approach that marries domain randomization and differentiable rendering gradients to address this problem. Our core idea is to train a rendering-invariant state-prediction (RISP) network that transforms image differences into state differences independent of rendering configurations, e.g., lighting, shadows, or material reflectance. To train this predictor, we formulate a new loss on rendering variances using gradients from differentiable rendering. Moreover, we present an efficient, second-order method to compute the gradients of this loss, allowing it to be integrated seamlessly into modern deep learning frameworks. We evaluate our method in rigid-body and deformable-body simulation environments using four tasks: state estimation, system identification, imitation learning, and visuomotor control. We further demonstrate the efficacy of our approach on a real-world example: inferring the state and action sequences of a quadrotor from a video of its motion sequences. Compared with existing methods, our approach achieves significantly lower reconstruction errors and has better generalizability among unknown rendering configurations.",
        "conference": "ICLR",
        "中文标题": "RISP：具有可微分模拟与渲染的渲染不变状态预测器，用于跨域参数估计",
        "摘要翻译": "本研究考虑直接从无法访问渲染配置的视频中识别表征物理系统动态运动的参数。现有解决方案需要大量训练数据或缺乏对未知渲染配置的泛化能力。我们提出了一种新方法，结合了域随机化和可微分渲染梯度来解决这一问题。我们的核心思想是训练一个渲染不变状态预测（RISP）网络，该网络将图像差异转换为独立于渲染配置（如光照、阴影或材料反射率）的状态差异。为了训练这个预测器，我们利用可微分渲染的梯度制定了一个关于渲染方差的新损失函数。此外，我们提出了一种高效的第二阶方法来计算这个损失的梯度，使其能够无缝集成到现代深度学习框架中。我们在刚体和可变形体模拟环境中使用四个任务评估了我们的方法：状态估计、系统识别、模仿学习和视觉运动控制。我们进一步在一个真实世界的例子中展示了我们方法的有效性：从四旋翼飞行器运动序列的视频中推断其状态和动作序列。与现有方法相比，我们的方法实现了显著更低的重建误差，并且在未知渲染配置中具有更好的泛化能力。",
        "领域": "计算机视觉与物理模拟结合、动态系统参数估计、视觉运动控制",
        "问题": "直接从视频中识别物理系统动态运动的参数，尤其是在渲染配置未知的情况下。",
        "动机": "解决现有方法在需要大量训练数据或缺乏对未知渲染配置泛化能力方面的不足。",
        "方法": "结合域随机化和可微分渲染梯度，训练一个渲染不变状态预测（RISP）网络，将图像差异转换为独立于渲染配置的状态差异。",
        "关键词": [
            "渲染不变状态预测",
            "可微分渲染",
            "跨域参数估计",
            "动态系统识别",
            "视觉运动控制"
        ],
        "涉及的技术概念": {
            "渲染不变状态预测（RISP）网络": "用于将图像差异转换为独立于渲染配置的状态差异的网络。",
            "可微分渲染": "提供渲染过程的梯度，用于训练RISP网络。",
            "域随机化": "通过在训练过程中随机化渲染配置，增强模型对未知渲染配置的泛化能力。"
        },
        "success": true
    },
    {
        "order": 860,
        "title": "Robbing the Fed:  Directly Obtaining Private Data in Federated Learning with Modified Models",
        "html": "https://iclr.cc//virtual/2022/poster/7067",
        "abstract": "Federated learning has quickly gained popularity with its promises of increased user privacy and efficiency.  Previous works have shown that federated gradient updates contain information that can be used to approximately recover user data in some situations.  These previous attacks on user privacy have been limited in scope and do not scale to gradient updates aggregated over even a handful of  data  points,  leaving  some  to  conclude  that  data  privacy  is  still  intact  for realistic training regimes.  In this work, we introduce a new threat model based on minimal but malicious modifications of the shared model architecture which enable the server to directly obtain a verbatim copy of user data from gradient updates without solving difficult inverse problems.  Even user data aggregated over large batches – where previous methods fail to extract meaningful content – can be reconstructed by these minimally modified models.",
        "conference": "ICLR",
        "中文标题": "窃取联邦：通过修改模型直接获取联邦学习中的私有数据",
        "摘要翻译": "联邦学习因其提高用户隐私和效率的承诺而迅速受到欢迎。先前的工作表明，在某些情况下，联邦梯度更新包含的信息可用于近似恢复用户数据。这些先前对用户隐私的攻击在范围上有限，并且不适用于甚至少量数据点聚合的梯度更新，使得一些人认为在实际训练制度下数据隐私仍然完好。在这项工作中，我们引入了一种新的威胁模型，基于对共享模型架构的最小但恶意的修改，使服务器能够直接从梯度更新中获取用户数据的逐字副本，而无需解决困难的反问题。即使是聚合在大批量上的用户数据——先前的方法无法提取有意义的内容——也可以通过这些最小修改的模型重建。",
        "领域": "联邦学习安全、隐私保护、深度学习安全",
        "问题": "联邦学习中的用户数据隐私泄露问题",
        "动机": "揭示联邦学习系统中通过修改模型架构直接泄露用户数据的新威胁",
        "方法": "通过最小但恶意的修改共享模型架构，直接从梯度更新中获取用户数据",
        "关键词": [
            "联邦学习",
            "数据隐私",
            "模型修改",
            "梯度更新",
            "隐私攻击"
        ],
        "涉及的技术概念": {
            "联邦学习": "一种分布式机器学习方法，允许多个参与者协作训练模型而不共享原始数据",
            "梯度更新": "在训练过程中，模型参数根据损失函数的梯度进行调整的信息",
            "隐私攻击": "通过分析模型训练过程中的信息泄露，尝试恢复原始数据的技术"
        },
        "success": true
    },
    {
        "order": 861,
        "title": "Robust and Scalable SDE Learning: A Functional Perspective",
        "html": "https://iclr.cc//virtual/2022/poster/6813",
        "abstract": "Stochastic differential equations provide a rich class of flexible generativemodels, capable of describing a wide range of spatio-temporal processes. A hostof recent work looks to learn data-representing SDEs, using neural networks andother flexible function approximators. Despite these advances, learning remainscomputationally expensive due to the sequential nature of SDE integrators. Inthis work, we propose an importance-sampling estimator for probabilities ofobservations of SDEs for the purposes of learning. Crucially, the approach wesuggest does not rely on such integrators. The proposed method produceslower-variance gradient estimates compared to algorithms based on SDEintegrators and has the added advantage of being embarrassingly parallelizable.This facilitates the effective use of large-scale parallel hardware for massivedecreases in computation time.",
        "conference": "ICLR",
        "中文标题": "稳健且可扩展的随机微分方程学习：一种功能视角",
        "摘要翻译": "随机微分方程提供了一类灵活的生成模型，能够描述广泛的时空过程。最近的大量工作试图使用神经网络和其他灵活的函数逼近器来学习表示数据的随机微分方程。尽管取得了这些进展，但由于随机微分方程积分器的顺序性质，学习过程仍然计算昂贵。在这项工作中，我们提出了一个重要性采样估计器，用于学习随机微分方程观测概率的目的。关键的是，我们建议的方法不依赖于这样的积分器。与基于随机微分方程积分器的算法相比，所提出的方法产生了更低方差的梯度估计，并且具有易于并行化的额外优势。这有助于有效利用大规模并行硬件，从而大幅减少计算时间。",
        "领域": "随机微分方程学习、生成模型、并行计算",
        "问题": "随机微分方程学习过程中的计算效率问题",
        "动机": "解决由于随机微分方程积分器的顺序性质导致的学习过程计算昂贵的问题",
        "方法": "提出了一种不依赖于随机微分方程积分器的重要性采样估计器，用于学习随机微分方程观测概率",
        "关键词": [
            "随机微分方程",
            "重要性采样",
            "并行计算",
            "梯度估计",
            "生成模型"
        ],
        "涉及的技术概念": {
            "随机微分方程": "用于描述广泛的时空过程的灵活生成模型",
            "重要性采样估计器": "用于学习随机微分方程观测概率的方法，不依赖于顺序积分器",
            "并行计算": "通过利用大规模并行硬件，大幅减少计算时间的技术"
        },
        "success": true
    },
    {
        "order": 862,
        "title": "Robust Learning Meets Generative Models: Can Proxy Distributions Improve Adversarial Robustness?",
        "html": "https://iclr.cc//virtual/2022/poster/6374",
        "abstract": "While additional training data improves the robustness of deep neural networks against adversarial examples, it presents the challenge of curating a large number of specific real-world samples. We circumvent this challenge by using additional data from proxy distributions learned by advanced  generative models. We first seek to formally understand the transfer of robustness from classifiers trained on proxy distributions to the real data distribution. We prove that the difference between the robustness of a classifier on the two distributions is upper bounded by the conditional Wasserstein distance between them. Next we use proxy distributions to significantly improve the performance of adversarial training on five different datasets. For example, we improve robust accuracy by up to $7.5$% and $6.7$% in $\\ell_{\\infty}$ and $\\ell_2$ threat model over baselines that are not using proxy distributions on the CIFAR-10 dataset. We also improve certified robust accuracy by $7.6$% on the CIFAR-10 dataset. We further demonstrate that different generative models brings a disparate improvement in the performance in robust training. We propose a robust discrimination approach to characterize the impact and further provide a deeper understanding of why diffusion-based generative models are a better choice for proxy distribution than generative adversarial networks.",
        "conference": "ICLR",
        "中文标题": "鲁棒学习与生成模型的结合：代理分布能否提升对抗鲁棒性？",
        "摘要翻译": "尽管额外的训练数据能够提升深度神经网络对抗对抗样本的鲁棒性，但这也带来了需要大量特定真实世界样本的挑战。我们通过使用来自高级生成模型学习的代理分布的额外数据来规避这一挑战。我们首先试图正式理解从在代理分布上训练的分类器到真实数据分布的鲁棒性转移。我们证明，分类器在两个分布上的鲁棒性差异受它们之间的条件Wasserstein距离的上界限制。接下来，我们使用代理分布显著提升了在五个不同数据集上的对抗训练性能。例如，在CIFAR-10数据集上，我们比不使用代理分布的基线在ℓ∞和ℓ2威胁模型下的鲁棒准确率分别提高了7.5%和6.7%。我们还在CIFAR-10数据集上提高了7.6%的认证鲁棒准确率。我们进一步展示了不同的生成模型在鲁棒训练性能上带来了不同的提升。我们提出了一种鲁棒判别方法来描述这种影响，并进一步深入理解了为什么基于扩散的生成模型比生成对抗网络更适合作为代理分布。",
        "领域": "对抗性机器学习、生成模型、深度神经网络鲁棒性",
        "问题": "如何在不依赖大量真实世界样本的情况下，提升深度神经网络对抗对抗样本的鲁棒性。",
        "动机": "解决在提升深度神经网络对抗对抗样本鲁棒性时，需要大量特定真实世界样本的挑战。",
        "方法": "使用高级生成模型学习的代理分布作为额外数据，通过理论分析和实验验证代理分布对提升对抗训练性能的有效性。",
        "关键词": [
            "对抗鲁棒性",
            "生成模型",
            "代理分布",
            "Wasserstein距离",
            "扩散模型"
        ],
        "涉及的技术概念": {
            "条件Wasserstein距离": "用于衡量分类器在代理分布和真实数据分布上鲁棒性差异的上界。",
            "对抗训练": "通过在训练过程中引入对抗样本来提升模型的鲁棒性。",
            "扩散模型": "一种生成模型，论文中证明其作为代理分布比生成对抗网络更有效。"
        },
        "success": true
    },
    {
        "order": 863,
        "title": "Robust Unlearnable Examples: Protecting Data Privacy Against Adversarial Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6035",
        "abstract": "The tremendous amount of accessible data in cyberspace face the risk of being unauthorized used for training deep learning models. To address this concern, methods are proposed to make data unlearnable for deep learning models by adding a type of error-minimizing noise. However, such conferred unlearnability is found fragile to adversarial training. In this paper, we design new methods to generate robust unlearnable examples that are protected from adversarial training. We first find that the vanilla error-minimizing noise, which suppresses the informative knowledge of data via minimizing the corresponding training loss, could not effectively minimize the adversarial training loss. This explains the vulnerability of error-minimizing noise in adversarial training. Based on the observation, robust error-minimizing noise is then introduced to reduce the adversarial training loss. Experiments show that the unlearnability brought by robust error-minimizing noise can effectively protect data from adversarial training in various scenarios. The code is available at \\url{https://github.com/fshp971/robust-unlearnable-examples}.",
        "conference": "ICLR",
        "中文标题": "鲁棒性不可学习样本：保护数据隐私对抗对抗性学习",
        "摘要翻译": "网络空间中可获取的大量数据面临着被未经授权用于训练深度学习模型的风险。为了解决这一问题，提出了通过添加一种误差最小化噪声使数据对深度学习模型不可学习的方法。然而，这种赋予的不可学习性被发现对对抗性训练脆弱。在本文中，我们设计了新的方法来生成鲁棒的不可学习样本，这些样本能够抵御对抗性训练。我们首先发现，通过最小化相应训练损失来抑制数据信息知识的普通误差最小化噪声，不能有效地最小化对抗性训练损失。这解释了误差最小化噪声在对抗性训练中的脆弱性。基于这一观察，随后引入了鲁棒误差最小化噪声以减少对抗性训练损失。实验表明，鲁棒误差最小化噪声带来的不可学习性能够有效地在各种场景中保护数据免受对抗性训练的影响。代码可在https://github.com/fshp971/robust-unlearnable-examples获取。",
        "领域": "对抗性机器学习、数据隐私保护、深度学习安全",
        "问题": "如何保护数据不被未经授权用于训练深度学习模型，特别是对抗对抗性训练",
        "动机": "解决现有误差最小化噪声方法在对抗性训练中的脆弱性问题，提高数据隐私保护的有效性",
        "方法": "设计并引入鲁棒误差最小化噪声，以减少对抗性训练损失，从而生成能够抵御对抗性训练的不可学习样本",
        "关键词": [
            "不可学习样本",
            "对抗性训练",
            "数据隐私保护",
            "误差最小化噪声",
            "深度学习安全"
        ],
        "涉及的技术概念": {
            "误差最小化噪声": "通过最小化训练损失来抑制数据信息知识，使数据对模型不可学习",
            "对抗性训练": "一种训练方法，通过引入对抗性样本来提高模型的鲁棒性",
            "鲁棒误差最小化噪声": "改进的噪声生成方法，旨在减少对抗性训练损失，提高不可学习样本的鲁棒性"
        },
        "success": true
    },
    {
        "order": 864,
        "title": "RotoGrad: Gradient Homogenization in Multitask Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6379",
        "abstract": "Multitask learning is being increasingly adopted in applications domains like computer vision and reinforcement learning. However, optimally exploiting its advantages remains a major challenge due to the effect of negative transfer. Previous works have tracked down this issue to the disparities in gradient magnitudes and directions across tasks, when optimizing the shared network parameters. While recent work has acknowledged that negative transfer is a two-fold problem, existing approaches fall short as they only focus on either homogenizing the gradient magnitude across tasks; or greedily change the gradient directions, overlooking future conflicts. In this work, we introduce RotoGrad, an algorithm that tackles negative transfer as a whole: it jointly homogenizes gradient magnitudes and directions, while ensuring training convergence. We show that RotoGrad outperforms competing methods in complex problems, including multi-label classification in CelebA and computer vision tasks in the NYUv2 dataset. A Pytorch implementation can be found in https://github.com/adrianjav/rotograd.",
        "conference": "ICLR",
        "中文标题": "RotoGrad：多任务学习中的梯度均质化",
        "摘要翻译": "多任务学习在计算机视觉和强化学习等应用领域正被越来越多地采用。然而，由于负迁移效应的影响，如何最优地利用其优势仍然是一个主要挑战。先前的工作将这一问题归因于在优化共享网络参数时，各任务间梯度大小和方向的差异。尽管最近的工作承认负迁移是一个双重问题，但现有方法仅侧重于均质化各任务间的梯度大小，或贪婪地改变梯度方向而忽视未来的冲突，因此存在不足。在这项工作中，我们介绍了RotoGrad，一种整体解决负迁移问题的算法：它联合均质化梯度大小和方向，同时确保训练收敛。我们证明，RotoGrad在包括CelebA中的多标签分类和NYUv2数据集中的计算机视觉任务在内的复杂问题上优于竞争方法。PyTorch实现可在https://github.com/adrianjav/rotograd找到。",
        "领域": "多任务学习、计算机视觉、强化学习",
        "问题": "解决多任务学习中的负迁移问题，即各任务间梯度大小和方向的差异导致的性能下降",
        "动机": "为了克服现有方法仅关注梯度大小或方向单一方面的不足，提出一种能够同时处理梯度大小和方向差异的解决方案",
        "方法": "引入RotoGrad算法，联合均质化梯度大小和方向，确保训练收敛",
        "关键词": [
            "多任务学习",
            "梯度均质化",
            "负迁移",
            "计算机视觉",
            "强化学习"
        ],
        "涉及的技术概念": {
            "负迁移": "在多任务学习中，由于任务间梯度差异导致的性能下降现象",
            "梯度均质化": "调整各任务的梯度大小和方向，以减少负迁移影响的技术",
            "训练收敛": "确保在优化过程中算法能够稳定地接近最优解的状态"
        },
        "success": true
    },
    {
        "order": 865,
        "title": "RvS: What is Essential for Offline RL via Supervised Learning?",
        "html": "https://iclr.cc//virtual/2022/poster/6088",
        "abstract": "Recent work has shown that supervised learning alone, without temporal difference (TD) learning, can be remarkably effective for offline RL. When does this hold true, and which algorithmic components are necessary? Through extensive experiments, we boil supervised learning for offline RL down to its essential elements. In every environment suite we consider, simply maximizing likelihood with a two-layer feedforward MLP is competitive with state-of-the-art results of substantially more complex methods based on TD learning or sequence modeling with Transformers. Carefully choosing model capacity (e.g., via regularization or architecture) and choosing which information to condition on (e.g., goals or rewards) are critical for performance. These insights serve as a field guide for practitioners doing Reinforcement Learning via Supervised Learning (which we coin RvS learning). They also probe the limits of existing RvS methods, which are comparatively weak on random data, and suggest a number of open problems.",
        "conference": "ICLR",
        "中文标题": "RvS：通过监督学习进行离线强化学习的关键要素是什么？",
        "摘要翻译": "最近的研究表明，仅通过监督学习，无需时间差分（TD）学习，对于离线强化学习（RL）来说可以非常有效。这种情况何时成立，哪些算法组件是必要的？通过大量实验，我们将离线RL的监督学习简化为其基本要素。在我们考虑的每个环境套件中，仅使用两层前馈MLP最大化似然，就能与基于TD学习或使用Transformers进行序列建模的更复杂方法的最新成果相竞争。仔细选择模型容量（例如，通过正则化或架构）和选择条件信息（例如，目标或奖励）对性能至关重要。这些见解为从事通过监督学习进行强化学习（我们称之为RvS学习）的实践者提供了领域指南。它们还探讨了现有RvS方法的局限性，这些方法在随机数据上相对较弱，并提出了许多开放性问题。",
        "领域": "离线强化学习、监督学习、深度强化学习",
        "问题": "探索在离线强化学习中，仅通过监督学习（无需时间差分学习）能够取得有效性的条件和必要的算法组件。",
        "动机": "研究监督学习在离线强化学习中的应用潜力，识别其关键成功因素，并为实践者提供指导。",
        "方法": "通过大量实验分析，简化监督学习在离线强化学习中的应用，比较不同方法的效果，特别是两层前馈MLP与更复杂方法的性能对比。",
        "关键词": [
            "离线强化学习",
            "监督学习",
            "RvS学习",
            "模型容量",
            "条件信息"
        ],
        "涉及的技术概念": {
            "监督学习": "在离线强化学习中，仅通过监督学习而不依赖时间差分学习来训练模型。",
            "模型容量": "通过正则化或架构选择来控制模型的学习能力，对性能有重要影响。",
            "条件信息": "在模型训练中选择性地利用目标或奖励等信息作为条件，以提高模型性能。"
        },
        "success": true
    },
    {
        "order": 866,
        "title": "Safe Neurosymbolic Learning with Differentiable Symbolic Execution",
        "html": "https://iclr.cc//virtual/2022/poster/6860",
        "abstract": "We study the problem of learning verifiably safe parameters for programs that use neural networks as well as symbolic, human-written code. Such neurosymbolic programs arise in many safety-critical domains. However, because they need not be differentiable, it is hard to learn their parameters using existing gradient-based approaches to safe learning. Our method, Differentiable Symbolic Execution (DSE), samples control flow paths in a program, symbolically constructs worst-case 'safety loss' along these paths, and backpropagates the gradients of these losses through program operations using a generalization of the REINFORCE estimator. We evaluate the method on a mix of synthetic tasks and real-world benchmarks. Our experiments show that DSE significantly outperforms the state-of-the-art DiffAI method on these tasks.  ",
        "conference": "ICLR",
        "中文标题": "可微分符号执行的安全神经符号学习",
        "摘要翻译": "我们研究了为使用神经网络以及符号化、人工编写代码的程序学习可验证安全参数的问题。这类神经符号程序在许多安全关键领域中出现。然而，因为它们不一定是可微分的，所以很难使用现有的基于梯度的安全学习方法学习它们的参数。我们的方法，可微分符号执行（DSE），在程序中采样控制流路径，符号化地构造这些路径上的最坏情况‘安全损失’，并使用REINFORCE估计器的推广通过这些程序操作反向传播这些损失的梯度。我们在合成任务和真实世界基准测试的混合上评估了该方法。我们的实验表明，在这些任务上，DSE显著优于最先进的DiffAI方法。",
        "领域": "程序合成与验证、安全关键系统、神经符号集成",
        "问题": "学习神经符号程序中可验证安全参数的问题",
        "动机": "解决神经符号程序由于不可微分性而难以使用现有基于梯度的安全学习方法学习参数的问题",
        "方法": "采用可微分符号执行（DSE）方法，通过采样控制流路径、符号化构造安全损失并反向传播梯度",
        "关键词": [
            "神经符号学习",
            "可微分符号执行",
            "安全验证",
            "程序合成",
            "梯度反向传播"
        ],
        "涉及的技术概念": {
            "可微分符号执行（DSE）": "一种在神经符号程序中采样控制流路径并符号化构造安全损失的方法，使得可以通过程序操作反向传播梯度",
            "REINFORCE估计器": "用于估计梯度的一种方法，DSE方法中推广了此估计器以支持通过程序操作反向传播梯度",
            "安全损失": "在DSE方法中符号化构造的损失，用于衡量程序路径上的最坏情况安全性"
        },
        "success": true
    },
    {
        "order": 867,
        "title": "Salient ImageNet: How to discover spurious features in Deep Learning?",
        "html": "https://iclr.cc//virtual/2022/poster/5903",
        "abstract": "Deep neural networks can be unreliable in the real world especially when they heavily use {\\it spurious} features for their predictions. Focusing on image classifications, we define {\\it core features} as the set of visual features that are always a part of the object definition while {\\it spurious features} are the ones that are likely to {\\it co-occur} with the object but not a part of it (e.g., attribute ``fingers' for class ``band aid'). Traditional methods for discovering spurious features either require extensive human annotations (thus, not scalable), or are useful on specific models. In this work, we introduce a {\\it general} framework to discover a subset of spurious and core visual features used in inferences of a general model and localize them on a large number of images with minimal human supervision. Our methodology is based on this key idea: to identify spurious or core \\textit{visual features} used in model predictions, we identify spurious or core \\textit{neural features} (penultimate layer neurons of a robust model) via limited human supervision (e.g., using top 5 activating images per feature). We then show that these neural feature annotations {\\it generalize} extremely well to many more images {\\it without} any human supervision. We use the activation maps for these neural features as the soft masks to highlight spurious or core visual features. Using this methodology, we introduce the {\\it Salient Imagenet} dataset containing core and spurious masks for a large set of samples from Imagenet. Using this dataset, we show that several popular Imagenet models rely heavily on various spurious features in their predictions, indicating the standard accuracy alone is not sufficient to fully assess model' performance specially in safety-critical applications. Code is available at \\url{https://github.com/singlasahil14/salient_imagenet}.",
        "conference": "ICLR",
        "中文标题": "显著性ImageNet：如何发现深度学习中的虚假特征？",
        "摘要翻译": "深度神经网络在现实世界中可能不可靠，尤其是当它们大量使用虚假特征进行预测时。专注于图像分类，我们将核心特征定义为始终是对象定义一部分的视觉特征集，而虚假特征则是可能与对象共现但不属于其一部分的特征（例如，类别“创可贴”的属性“手指”）。传统的发现虚假特征的方法要么需要大量的人工标注（因此不可扩展），要么仅适用于特定模型。在这项工作中，我们引入了一个通用框架，以发现一般模型推理中使用的虚假和核心视觉特征的子集，并在大量图像上以最少的人工监督定位它们。我们的方法基于这一关键思想：为了识别模型预测中使用的虚假或核心视觉特征，我们通过有限的人工监督（例如，使用每个特征的前5个激活图像）识别虚假或核心神经特征（鲁棒模型的倒数第二层神经元）。然后，我们展示了这些神经特征标注在没有人工监督的情况下能够非常好地推广到更多图像。我们使用这些神经特征的激活图作为软掩码来突出显示虚假或核心视觉特征。利用这一方法，我们引入了显著性ImageNet数据集，其中包含来自ImageNet的大量样本的核心和虚假掩码。使用这个数据集，我们展示了几个流行的ImageNet模型在其预测中严重依赖各种虚假特征，表明仅标准准确性不足以全面评估模型性能，特别是在安全关键应用中。代码可在https://github.com/singlasahil14/salient_imagenet获取。",
        "领域": "图像分类、模型可解释性、深度学习鲁棒性",
        "问题": "深度神经网络在预测时可能依赖虚假特征，导致在现实世界中不可靠。",
        "动机": "开发一种无需大量人工标注即可发现和定位模型依赖的虚假和核心特征的方法，以提高模型的可靠性和可解释性。",
        "方法": "通过有限的人工监督识别神经特征，并利用这些特征的激活图作为软掩码来定位视觉特征，进而构建包含核心和虚假掩码的数据集。",
        "关键词": [
            "虚假特征",
            "核心特征",
            "模型可解释性",
            "ImageNet",
            "深度学习鲁棒性"
        ],
        "涉及的技术概念": {
            "虚假特征": "与对象共现但不属于其一部分的视觉特征，可能导致模型预测不可靠。",
            "核心特征": "始终是对象定义一部分的视觉特征，对模型预测至关重要。",
            "神经特征": "鲁棒模型倒数第二层神经元，通过其激活图可以定位视觉特征。"
        },
        "success": true
    },
    {
        "order": 868,
        "title": "Sample and Computation Redistribution for Efficient Face Detection",
        "html": "https://iclr.cc//virtual/2022/poster/6369",
        "abstract": "Although tremendous strides have been made in uncontrolled face detection, accurate face detection with a low computation cost remains an open challenge. In this paper, we point out that computation distribution and scale augmentation are the keys to detecting small faces from low-resolution images. Motivated by these observations, we introduce two simple but effective methods: (1) Computation Redistribution (CR), which reallocates the computation between the backbone, neck and head of the model; and (2) Sample Redistribution (SR), which augments training samples for the most needed stages. The proposed Sample and Computation Redistribution for Face Detection (SCRFD) is implemented by a random search in a meticulously designed search space. Extensive experiments conducted on WIDER FACE demonstrate the state-of-the-art accuracy-efficiency trade-off for the proposed SCRFD family across a wide range of compute regimes. In particular, SCRFD-34GF outperforms the best competitor, TinaFace, by $4.78\\%$ (AP at hard set) while being more than 3$\\times$ faster on GPUs with VGA-resolution images. Code is available at: https://github.com/deepinsight/insightface/tree/master/detection/scrfd.",
        "conference": "ICLR",
        "中文标题": "样本与计算重分配以实现高效人脸检测",
        "摘要翻译": "尽管在非受控环境下的人脸检测已取得巨大进展，但以低计算成本实现高精度人脸检测仍是一个未解决的挑战。本文指出，计算分配和尺度增强是从低分辨率图像中检测小人脸的关键。基于这些观察，我们引入了两种简单但有效的方法：（1）计算重分配（CR），它在模型的主干、颈部和头部之间重新分配计算资源；（2）样本重分配（SR），它为最需要的阶段增强训练样本。所提出的人脸检测样本与计算重分配方法（SCRFD）通过在一个精心设计的搜索空间中进行随机搜索来实现。在WIDER FACE上进行的大量实验表明，所提出的SCRFD系列在广泛的计算范围内实现了最先进的精度-效率权衡。特别是，SCRFD-34GF在VGA分辨率图像的GPU上，比最佳竞争对手TinaFace在困难集上的AP高出4.78%，同时速度提高了3倍以上。代码可在https://github.com/deepinsight/insightface/tree/master/detection/scrfd获取。",
        "领域": "人脸检测",
        "问题": "在低计算成本下实现高精度人脸检测",
        "动机": "解决在非受控环境下，尤其是低分辨率图像中，高效检测小人脸的挑战",
        "方法": "通过计算重分配（CR）和样本重分配（SR）两种方法优化模型的计算资源和训练样本分配",
        "关键词": [
            "人脸检测",
            "计算重分配",
            "样本重分配",
            "高效检测",
            "低分辨率图像"
        ],
        "涉及的技术概念": {
            "计算重分配（CR）": "在模型的不同部分（主干、颈部和头部）之间重新分配计算资源，以优化计算效率",
            "样本重分配（SR）": "增强训练样本的分配，特别是在模型最需要的阶段，以提高检测精度",
            "随机搜索": "在一个精心设计的搜索空间中应用随机搜索策略，以实现样本和计算资源的最优分配"
        },
        "success": true
    },
    {
        "order": 869,
        "title": "Sample Efficient Deep Reinforcement Learning via Uncertainty Estimation",
        "html": "https://iclr.cc//virtual/2022/poster/6905",
        "abstract": "In model-free deep reinforcement learning (RL) algorithms, using noisy value estimates to supervise policy evaluation and optimization is detrimental to the sample efficiency. As this noise is heteroscedastic, its effects can be mitigated using uncertainty-based weights in the optimization process. Previous methods rely on sampled ensembles, which do not capture all aspects of uncertainty. We provide a systematic analysis of the sources of uncertainty in the noisy supervision that occurs in RL, and introduce inverse-variance RL, a Bayesian framework which combines probabilistic ensembles and Batch Inverse Variance weighting. We propose a method whereby two complementary uncertainty estimation methods account for both the Q-value and the environment stochasticity to better mitigate the negative impacts of noisy supervision. Our results show significant improvement in terms of sample efficiency on discrete and continuous control tasks.",
        "conference": "ICLR",
        "中文标题": "通过不确定性估计实现样本高效的深度强化学习",
        "摘要翻译": "在无模型的深度强化学习（RL）算法中，使用带有噪声的价值估计来监督策略评估和优化对样本效率是有害的。由于这种噪声是异方差的，在优化过程中使用基于不确定性的权重可以减轻其影响。先前的方法依赖于采样集成，这并不能捕捉到不确定性的所有方面。我们对RL中出现的噪声监督的不确定性来源进行了系统分析，并引入了逆方差RL，这是一个结合了概率集成和批量逆方差加权的贝叶斯框架。我们提出了一种方法，通过两种互补的不确定性估计方法来考虑Q值和环境随机性，以更好地减轻噪声监督的负面影响。我们的结果显示，在离散和连续控制任务上，样本效率有显著提高。",
        "领域": "深度强化学习、不确定性估计、控制任务",
        "问题": "解决深度强化学习中由于噪声价值估计导致的样本效率低下问题",
        "动机": "通过更准确地估计和利用不确定性，提高深度强化学习算法的样本效率",
        "方法": "提出了一种结合概率集成和批量逆方差加权的贝叶斯框架，以及两种互补的不确定性估计方法，以减轻噪声监督的负面影响",
        "关键词": [
            "深度强化学习",
            "不确定性估计",
            "样本效率",
            "逆方差加权",
            "贝叶斯框架"
        ],
        "涉及的技术概念": {
            "逆方差RL": "一种贝叶斯框架，结合概率集成和批量逆方差加权，用于减轻噪声监督的影响",
            "概率集成": "用于捕捉和估计RL中不确定性的方法，通过集成多个模型来提供更全面的不确定性评估",
            "批量逆方差加权": "在优化过程中使用的一种权重分配方法，根据估计的不确定性逆方差来调整不同样本的权重，以提高样本效率"
        },
        "success": true
    },
    {
        "order": 870,
        "title": "Sample Efficient Stochastic Policy Extragradient Algorithm for Zero-Sum Markov Game",
        "html": "https://iclr.cc//virtual/2022/poster/6982",
        "abstract": "Two-player zero-sum Markov game is a fundamental problem in reinforcement learning and game theory. Although many algorithms have been proposed for solving zero-sum Markov games in the existing literature, many of them either require a full knowledge of the environment or are not sample-efficient. In this paper, we develop a fully decentralized and sample-efficient stochastic policy extragradient algorithm for solving tabular zero-sum Markov games. In particular, our algorithm utilizes multiple stochastic estimators to accurately estimate the value functions involved in the stochastic updates, and leverages entropy regularization to accelerate the convergence. Specifically, with a proper entropy-regularization parameter, we prove that the stochastic policy extragradient algorithm has a sample complexity of the order $\\widetilde{\\mathcal{O}}(\\frac{A_{\\max}}{\\mu_{\\text{min}}\\epsilon^{5.5}(1-\\gamma)^{13.5}})$ for finding a solution that achieves $\\epsilon$-Nash equilibrium duality gap, where $A_{\\max}$ is the maximum number of actions between the players, $\\mu_{\\min}$ is the lower bound of state stationary distribution, and $\\gamma$ is the discount factor. Such a sample complexity result substantially improves the state-of-the-art complexity result. ",
        "conference": "ICLR",
        "success": true,
        "中文标题": "零和马尔可夫博弈的样本高效随机策略外梯度算法",
        "摘要翻译": "双人零和马尔可夫博弈是强化学习和博弈论中的一个基本问题。尽管现有文献中已经提出了许多用于解决零和马尔可夫博弈的算法，但它们中的许多要么需要对环境的完全了解，要么不是样本高效的。在本文中，我们开发了一种完全去中心化和样本高效的随机策略外梯度算法，用于解决表格型零和马尔可夫博弈。特别地，我们的算法利用多个随机估计器来准确估计随机更新中涉及的价值函数，并利用熵正则化来加速收敛。具体来说，通过适当的熵正则化参数，我们证明了随机策略外梯度算法的样本复杂度为$\\widetilde{\\mathcal{O}}(\\frac{A_{\\max}}{\\mu_{\\text{min}}\\epsilon^{5.5}(1-\\gamma)^{13.5}})$量级，用于找到实现$\\epsilon$-纳什均衡对偶间隙的解，其中$A_{\\max}$是玩家之间最大的动作数量，$\\mu_{\\min}$是状态平稳分布的下界，$\\gamma$是折扣因子。这样的样本复杂度结果大大提高了现有最先进的复杂度结果。",
        "领域": "强化学习, 多智能体强化学习, 博弈论",
        "问题": "解决现有零和马尔可夫博弈算法中存在的环境信息依赖和样本效率低下的问题，并寻求在去中心化环境中实现样本高效的求解方法。",
        "动机": "现有的零和马尔可夫博弈算法通常需要完全了解环境信息或样本效率不高，这限制了它们在实际应用中的可行性。因此，研究者希望开发一种无需完全环境信息且样本高效的算法，以解决实际应用中的零和马尔可夫博弈问题。",
        "方法": "开发了一种完全去中心化和样本高效的随机策略外梯度算法，该算法利用多个随机估计器准确估计价值函数，并结合熵正则化加速收敛。",
        "关键词": [
            "零和马尔可夫博弈",
            "随机策略外梯度",
            "样本效率",
            "熵正则化",
            "去中心化"
        ],
        "涉及的技术概念": {
            "随机策略外梯度算法": "一种优化算法，用于在策略空间中寻找纳什均衡点，通过随机梯度估计和外推步骤来更新策略。",
            "熵正则化": "一种在强化学习中常用的技术，通过在奖励函数中加入策略熵的正则项，鼓励探索，避免策略过于集中，从而加速收敛。"
        }
    },
    {
        "order": 871,
        "title": "Sample Selection with Uncertainty of Losses for Learning with Noisy Labels",
        "html": "https://iclr.cc//virtual/2022/poster/7175",
        "abstract": "In learning with noisy labels, the sample selection approach is very popular, which regards small-loss data as correctly labeled data during training. However, losses are generated on-the-ﬂy based on the model being trained with noisy labels, and thus large-loss data are likely but not certain to be incorrect. There are actually two possibilities of a large-loss data point: (a) it is mislabeled, and then its loss decreases slower than other data, since deep neural networks learn patterns ﬁrst; (b) it belongs to an underrepresented group of data and has not been selected yet. In this paper, we incorporate the uncertainty of losses by adopting interval estimation instead of point estimation of losses, where lower bounds of the conﬁdence intervals of losses derived from distribution-free concentration inequalities, but not losses themselves, are used for sample selection. In this way, we also give large-loss but less selected data a try; then, we can better distinguish between the cases (a) and (b) by seeing if the losses effectively decrease with the uncertainty after the try. As a result, we can better explore underrepresented data that are correctly labeled but seem to be mislabeled at ﬁrst glance. Experiments demonstrate that the proposed method is superior to baselines and robust to a broad range of label noise types.",
        "conference": "ICLR",
        "中文标题": "基于损失不确定性的噪声标签学习样本选择方法",
        "摘要翻译": "在噪声标签学习中，样本选择方法非常流行，该方法在训练过程中将小损失数据视为正确标记的数据。然而，损失是基于带有噪声标签的模型动态生成的，因此大损失数据很可能但不一定是错误的。实际上，大损失数据点有两种可能性：（a）它被错误标记，然后由于深度神经网络首先学习模式，其损失比其他数据下降得更慢；（b）它属于未被充分代表的数据组且尚未被选中。在本文中，我们通过采用区间估计而非点估计来纳入损失的不确定性，其中用于样本选择的是从无分布集中不等式导出的损失置信区间的下限，而非损失本身。通过这种方式，我们也尝试选择那些损失较大但较少被选中的数据；然后，通过观察损失是否随着尝试后的不确定性有效减少，我们可以更好地区分情况（a）和（b）。因此，我们可以更好地探索那些正确标记但初看似乎被错误标记的未被充分代表的数据。实验表明，所提出的方法优于基线方法，并且对广泛的标签噪声类型具有鲁棒性。",
        "领域": "噪声标签学习、深度学习鲁棒性、样本选择策略",
        "问题": "如何在噪声标签学习中更有效地选择样本，以区分真正错误标记的数据和未被充分代表的数据。",
        "动机": "解决噪声标签学习中样本选择方法无法准确区分大损失数据是由于错误标记还是数据未被充分代表的问题。",
        "方法": "采用区间估计而非点估计来评估损失的不确定性，利用损失置信区间的下限进行样本选择，以探索和区分不同类型的大损失数据。",
        "关键词": [
            "噪声标签学习",
            "样本选择",
            "损失不确定性",
            "区间估计",
            "深度学习鲁棒性"
        ],
        "涉及的技术概念": {
            "区间估计": "用于评估损失的不确定性，通过置信区间的下限而非单一损失值进行样本选择。",
            "无分布集中不等式": "用于从数据中推导损失置信区间的数学工具，不依赖于数据的具体分布假设。",
            "深度神经网络学习模式": "指深度神经网络在学习过程中优先学习数据中的普遍模式，可能导致对某些数据点的损失下降速度不同。"
        },
        "success": true
    },
    {
        "order": 872,
        "title": "Sampling with Mirrored Stein Operators",
        "html": "https://iclr.cc//virtual/2022/poster/6304",
        "abstract": "We introduce a new family of particle evolution samplers suitable for constrained domains and non-Euclidean geometries. Stein Variational Mirror Descent and Mirrored Stein Variational Gradient Descent minimize the Kullback-Leibler (KL) divergence to constrained target distributions by evolving particles in a dual space defined by a mirror map. Stein Variational Natural Gradient exploits non-Euclidean geometry to more efficiently minimize the KL divergence to unconstrained targets. We derive these samplers from a new class of mirrored Stein operators and adaptive kernels developed in this work. We demonstrate that these new samplers yield accurate approximations to distributions on the simplex, deliver valid confidence intervals in post-selection inference, and converge more rapidly than prior methods in large-scale unconstrained posterior inference. Finally, we establish the convergence of our new procedures under verifiable conditions on the target distribution.",
        "conference": "ICLR",
        "中文标题": "使用镜像Stein算子的采样方法",
        "摘要翻译": "我们介绍了一种新的粒子演化采样器家族，适用于约束域和非欧几里得几何。Stein变分镜像下降和镜像Stein变分梯度下降通过在一个由镜像映射定义的对偶空间中演化粒子，最小化到约束目标分布的Kullback-Leibler（KL）散度。Stein变分自然梯度利用非欧几里得几何更有效地最小化到无约束目标的KL散度。我们从本工作中开发的一类新的镜像Stein算子和自适应核中推导出这些采样器。我们证明，这些新的采样器能够准确近似单纯形上的分布，在选择后推断中提供有效的置信区间，并且在大规模无约束后验推断中比先前的方法收敛得更快。最后，我们在目标分布的可验证条件下建立了新程序的收敛性。",
        "领域": "概率图模型, 统计机器学习, 优化算法",
        "问题": "在约束域和非欧几里得几何中高效采样的问题",
        "动机": "开发一种能够在约束域和非欧几里得几何中高效采样的方法，以更准确地近似目标分布并提供有效的统计推断",
        "方法": "通过引入镜像Stein算子和自适应核，开发了Stein变分镜像下降、镜像Stein变分梯度下降和Stein变分自然梯度等采样器，以最小化到目标分布的KL散度",
        "关键词": [
            "镜像Stein算子",
            "KL散度",
            "非欧几里得几何",
            "粒子演化采样器",
            "后验推断"
        ],
        "涉及的技术概念": {
            "镜像Stein算子": "用于在约束域和非欧几里得几何中定义粒子演化的新算子",
            "KL散度": "用于衡量采样分布与目标分布之间差异的度量，本方法旨在最小化这一差异",
            "非欧几里得几何": "在采样过程中利用非欧几里得几何结构，以提高采样效率和准确性"
        },
        "success": true
    },
    {
        "order": 873,
        "title": "Scalable One-Pass Optimisation of High-Dimensional Weight-Update Hyperparameters by Implicit Differentiation",
        "html": "https://iclr.cc//virtual/2022/poster/6509",
        "abstract": "Machine learning training methods depend plentifully and intricately on hyperparameters, motivating automated strategies for their optimisation. Many existing algorithms restart training for each new hyperparameter choice, at considerable computational cost. Some hypergradient-based one-pass methods exist, but these either cannot be applied to arbitrary optimiser hyperparameters (such as learning rates and momenta) or take several times longer to train than their base models. We extend these existing methods to develop an approximate hypergradient-based hyperparameter optimiser which is applicable to any continuous hyperparameter appearing in a differentiable model weight update, yet requires only one training episode, with no restarts. We also provide a motivating argument for convergence to the true hypergradient, and perform tractable gradient-based optimisation of independent learning rates for each model parameter. Our method performs competitively from varied random hyperparameter initialisations on several UCI datasets and Fashion-MNIST (using a one-layer MLP), Penn Treebank (using an LSTM) and CIFAR-10 (using a ResNet-18), in time only 2-3x greater than vanilla training.",
        "conference": "ICLR",
        "中文标题": "通过隐式微分实现高维权重更新超参数的可扩展一次性优化",
        "摘要翻译": "机器学习训练方法在很大程度上且复杂地依赖于超参数，这促使了自动化优化策略的发展。许多现有算法为每个新的超参数选择重新开始训练，计算成本相当高。存在一些基于超梯度的一次性方法，但这些方法要么不能应用于任意优化器超参数（如学习率和动量），要么训练时间比其基础模型长几倍。我们扩展了这些现有方法，开发了一种基于超梯度的近似超参数优化器，该优化器适用于出现在可微分模型权重更新中的任何连续超参数，且仅需一次训练过程，无需重启。我们还提供了一个激励性论点，说明其收敛于真实超梯度，并对每个模型参数的独立学习率进行了基于梯度的可处理优化。我们的方法在多个UCI数据集、Fashion-MNIST（使用单层MLP）、Penn Treebank（使用LSTM）和CIFAR-10（使用ResNet-18）上，从不同的随机超参数初始化开始，表现出了竞争力，时间仅比普通训练长2-3倍。",
        "领域": "深度学习优化、超参数优化、自动机器学习",
        "问题": "如何高效优化机器学习模型中的高维权重更新超参数，避免传统方法中因重启训练带来的高计算成本。",
        "动机": "减少超参数优化过程中的计算成本和时间，提高机器学习模型的训练效率和性能。",
        "方法": "开发了一种基于超梯度的近似超参数优化器，适用于任何连续超参数，仅需一次训练过程，无需重启，并对每个模型参数的独立学习率进行了基于梯度的优化。",
        "关键词": [
            "超参数优化",
            "隐式微分",
            "超梯度",
            "一次性训练",
            "深度学习优化"
        ],
        "涉及的技术概念": {
            "隐式微分": "用于计算超梯度，使得超参数优化可以在一次训练过程中完成，无需重启。",
            "超梯度": "基于梯度的超参数优化方法的核心，用于指导超参数的更新方向。",
            "一次性训练": "指仅需一次完整的训练过程即可完成超参数优化，显著减少计算成本和时间。"
        },
        "success": true
    },
    {
        "order": 874,
        "title": "Scalable Sampling for Nonsymmetric Determinantal Point Processes",
        "html": "https://iclr.cc//virtual/2022/poster/7097",
        "abstract": "A determinantal point process (DPP) on a collection of $M$ items is a model, parameterized by a symmetric kernel matrix, that assigns a probability to every subset of those items.  Recent work shows that removing the kernel symmetry constraint, yielding nonsymmetric DPPs (NDPPs), can lead to significant predictive performance gains for machine learning applications. However, existing work leaves open the question of scalable NDPP sampling. There is only one known DPP sampling algorithm, based on Cholesky decomposition, that can directly apply to NDPPs as well. Unfortunately, its runtime is cubic in $M$, and thus does not scale to large item collections. In this work, we first note that this algorithm can be transformed into a linear-time one for kernels with low-rank structure.  Furthermore, we develop a scalable sublinear-time rejection sampling algorithm by constructing a novel proposal distribution.  Additionally, we show that imposing certain structural constraints on the NDPP kernel enables us to bound the rejection rate in a way that depends only on the kernel rank. In our experiments we compare the speed of all of these samplers for a variety of real-world tasks.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "非对称行列式点过程的可扩展采样",
        "摘要翻译": "行列式点过程（DPP）在一个包含$M$个项目的集合上是一个模型，它通过一个对称核矩阵参数化，为这些项目的每一个子集分配一个概率。最近的研究表明，去除核对称性约束，产生非对称DPP（NDPP），可以为机器学习应用带来显著的预测性能提升。然而，现有的研究尚未解决可扩展的NDPP采样问题。目前只有一种基于Cholesky分解的DPP采样算法可以直接应用于NDPP。不幸的是，其运行时间是$M$的立方，因此不适用于大型项目集合。在这项工作中，我们首先注意到，对于具有低秩结构的核，该算法可以转化为线性时间算法。此外，我们通过构建一种新颖的提议分布，开发了一种可扩展的亚线性时间拒绝采样算法。另外，我们展示了在NDPP核上施加某些结构约束，可以以仅依赖于核秩的方式限制拒绝率。在我们的实验中，我们比较了所有这些采样器在各种实际任务中的速度。",
        "领域": "机器学习, 概率模型, 算法优化",
        "问题": "解决非对称行列式点过程（NDPP）在大规模项目集合上的可扩展采样问题。",
        "动机": "现有的NDPP采样算法运行时间过长，无法适应大规模项目集合的需求，限制了NDPP在机器学习等领域的应用。",
        "方法": "开发了一种基于低秩核结构的线性时间采样算法和一种亚线性时间的拒绝采样算法，通过构建新颖的提议分布和施加核结构约束来提高采样效率。",
        "关键词": [
            "非对称行列式点过程",
            "可扩展采样",
            "拒绝采样",
            "低秩结构",
            "算法优化"
        ],
        "涉及的技术概念": {
            "行列式点过程（DPP）": "一种为项目子集分配概率的模型，通过对称核矩阵参数化。",
            "非对称行列式点过程（NDPP）": "去除核对称性约束的DPP变体，能够提供更好的预测性能。",
            "Cholesky分解": "一种用于DPP采样的算法，但其运行时间对于大规模项目集合不具可扩展性。"
        }
    },
    {
        "order": 875,
        "title": "Scale Efficiently: Insights from Pretraining and Finetuning Transformers",
        "html": "https://iclr.cc//virtual/2022/poster/5960",
        "abstract": "There remain many open questions pertaining to the scaling behaviour of Transformer architectures. These scaling decisions and findings can be critical, as training runs often come with an associated computational cost which have both financial and/or environmental impact. The goal of this paper is to present scaling insights from pretraining and finetuning Transformers. While Kaplan et al. presents a comprehensive study of the scaling behaviour of Transformer language models, the scope is only on the upstream (pretraining) loss. Therefore, it is still unclear if these set of findings transfer to downstream task within the context of the pretrain-finetune paradigm. The key findings of this paper are as follows: (1) we show that aside from only the model size, model shape matters for downstream fine-tuning, (2) scaling protocols operate differently at different compute regions, (3) widely adopted T5-base and T5-large sizes are Pareto-inefficient. To this end, we present improved scaling protocols whereby our redesigned models achieve similar downstream fine-tuning quality while having 50\\% fewer parameters and training 40\\% faster compared to the widely adopted T5-base model. We publicly release over 100 pretrained checkpoints of different T5 configurations to facilitate future research and analysis.",
        "conference": "ICLR",
        "中文标题": "高效扩展：从预训练和微调Transformer中获得的见解",
        "摘要翻译": "关于Transformer架构的扩展行为仍存在许多未解之谜。这些扩展决策和发现至关重要，因为训练运行通常伴随着相关的计算成本，这些成本既有财务影响，也有环境影响。本文的目标是展示从预训练和微调Transformer中获得的扩展见解。虽然Kaplan等人对Transformer语言模型的扩展行为进行了全面研究，但范围仅限于上游（预训练）损失。因此，尚不清楚这些发现是否在预训练-微调范式的背景下转移到下游任务。本文的主要发现如下：（1）我们表明，除了模型大小外，模型形状对下游微调也很重要，（2）扩展协议在不同的计算区域操作不同，（3）广泛采用的T5-base和T5-large大小是帕累托低效的。为此，我们提出了改进的扩展协议，通过重新设计的模型，在参数减少50%且训练速度比广泛采用的T5-base模型快40%的情况下，实现了类似的下游微调质量。我们公开发布了100多个不同T5配置的预训练检查点，以促进未来的研究和分析。",
        "领域": "自然语言处理与视觉结合, 模型优化, 深度学习效率",
        "问题": "如何高效地扩展Transformer架构以优化预训练和微调过程",
        "动机": "探索Transformer架构的扩展行为，以减少计算成本并提高模型效率",
        "方法": "通过分析模型大小和形状对下游任务的影响，提出改进的扩展协议",
        "关键词": [
            "Transformer扩展",
            "预训练微调",
            "模型效率",
            "计算优化",
            "T5模型"
        ],
        "涉及的技术概念": {
            "Transformer架构": "一种基于自注意力机制的深度学习模型架构，用于处理序列数据",
            "预训练-微调范式": "先在大型数据集上进行预训练，然后在特定任务上进行微调的方法",
            "帕累托效率": "在经济学中描述资源分配最优状态的概念，在此用于评估模型大小和性能的平衡"
        },
        "success": true
    },
    {
        "order": 876,
        "title": "Scale Mixtures of Neural Network Gaussian Processes",
        "html": "https://iclr.cc//virtual/2022/poster/6289",
        "abstract": "Recent works have revealed that infinitely-wide feed-forward or recurrent neural networks of any architecture correspond to Gaussian processes referred to as NNGP. While these works have extended the class of neural networks converging to Gaussian processes significantly, however, there has been little focus on broadening the class of stochastic processes that such neural networks converge to. In this work, inspired by the scale mixture of Gaussian random variables, we propose the scale mixture of NNGP for which we introduce a prior distribution on the scale of the last-layer parameters. We show that simply introducing a scale prior on the last-layer parameters can turn infinitely-wide neural networks of any architecture into a richer class of stochastic processes. With certain scale priors, we obtain heavy-tailed stochastic processes, and in the case of inverse gamma priors, we recover Student’s $t$ processes. We further analyze the distributions of the neural networks initialized with our prior setting and trained with gradient descents and obtain similar results as for NNGP. We present a practical posterior-inference algorithm for the scale mixture of NNGP and empirically demonstrate its usefulness on regression and classification tasks. In particular, we show that in both tasks, the heavy-tailed stochastic processes obtained from our framework are robust to out-of-distribution data.",
        "conference": "ICLR",
        "中文标题": "神经网络高斯过程的尺度混合",
        "摘要翻译": "最近的研究表明，任何架构的无限宽前馈或循环神经网络都对应于称为NNGP的高斯过程。尽管这些研究显著扩展了收敛于高斯过程的神经网络类别，但对于扩展此类神经网络收敛到的随机过程类别却鲜有研究。在这项工作中，受高斯随机变量尺度混合的启发，我们提出了NNGP的尺度混合，为此我们在最后一层参数的尺度上引入了先验分布。我们表明，简单地在最后一层参数上引入尺度先验，可以将任何架构的无限宽神经网络转化为更丰富的随机过程类别。对于某些尺度先验，我们获得了重尾随机过程，而在逆伽马先验的情况下，我们恢复了学生$t$过程。我们进一步分析了用我们的先验设置初始化并用梯度下降训练的神经网络的分布，并获得了与NNGP相似的结果。我们提出了一个实用的NNGP尺度混合的后验推断算法，并通过回归和分类任务实证证明了其实用性。特别是，我们展示了在这两项任务中，从我们的框架中获得的重尾随机过程对于分布外数据具有鲁棒性。",
        "领域": "深度学习理论、贝叶斯深度学习、随机过程",
        "问题": "扩展无限宽神经网络收敛到的随机过程类别",
        "动机": "为了丰富无限宽神经网络能够收敛到的随机过程类别，提高模型对分布外数据的鲁棒性",
        "方法": "通过在最后一层参数的尺度上引入先验分布，提出NNGP的尺度混合方法，并开发相应的后验推断算法",
        "关键词": [
            "尺度混合",
            "NNGP",
            "重尾随机过程",
            "后验推断",
            "分布外鲁棒性"
        ],
        "涉及的技术概念": {
            "NNGP": "神经网络高斯过程，指无限宽神经网络收敛到的高斯过程",
            "尺度混合": "通过在参数上引入尺度先验，扩展随机过程的类别",
            "重尾随机过程": "具有比高斯过程更厚尾部的随机过程，对异常值或分布外数据更具鲁棒性"
        },
        "success": true
    },
    {
        "order": 877,
        "title": "Scaling Laws for Neural Machine Translation",
        "html": "https://iclr.cc//virtual/2022/poster/6721",
        "abstract": "We present an empirical study of scaling properties of encoder-decoder Transformer models used in neural machine translation (NMT). We show that cross-entropy loss as a function of model size follows a certain scaling law. Specifically (i) We propose a formula which describes the scaling behavior of cross-entropy loss as a bivariate function of encoder and decoder size, and show that it gives accurate predictions under a variety of scaling approaches and languages; we show that the total number of parameters alone is not sufficient for such purposes. (ii) We observe different power law exponents when scaling the decoder vs scaling the encoder, and provide recommendations for optimal allocation of encoder/decoder capacity based on this observation. (iii) We also report that the scaling behavior of the model is acutely influenced by composition bias of the train/test sets, which we define as any deviation from naturally generated text (either via machine generated or human translated text). We observe that natural text on the target side enjoys scaling, which manifests as successful reduction of the cross-entropy loss. (iv) Finally, we investigate the relationship between the cross-entropy loss and the quality of the generated translations. We find two different behaviors, depending on the nature of the test data. For test sets which were originally translated from target language to source language, both loss and BLEU score improve as model size increases. In contrast, for test sets originally translated from source language to target language, the loss improves, but the BLEU score stops improving after a certain threshold. We release generated text from all models used in this study.",
        "conference": "ICLR",
        "中文标题": "神经机器翻译的缩放定律",
        "摘要翻译": "我们进行了一项关于神经机器翻译（NMT）中使用的编码器-解码器Transformer模型缩放特性的实证研究。我们展示了作为模型大小函数的交叉熵损失遵循一定的缩放定律。具体来说：（i）我们提出了一个公式，该公式将交叉熵损失的缩放行为描述为编码器和解码器大小的双变量函数，并表明在各种缩放方法和语言下，该公式都能给出准确的预测；我们表明，仅参数总数不足以实现这一目的。（ii）我们观察到在缩放解码器与缩放编码器时存在不同的幂律指数，并基于这一观察提供了编码器/解码器容量最优分配的建议。（iii）我们还报告了模型的缩放行为受到训练/测试集组成偏差的显著影响，我们将这种偏差定义为与自然生成文本（无论是通过机器生成还是人工翻译的文本）的任何偏离。我们观察到目标侧的自然文本享受缩放，这表现为成功减少交叉熵损失。（iv）最后，我们研究了交叉熵损失与生成翻译质量之间的关系。我们发现两种不同的行为，取决于测试数据的性质。对于最初从目标语言翻译到源语言的测试集，随着模型大小的增加，损失和BLEU分数都会提高。相反，对于最初从源语言翻译到目标语言的测试集，损失有所改善，但BLEU分数在达到一定阈值后停止提高。我们发布了本研究中使用的所有模型生成的文本。",
        "领域": "神经机器翻译、深度学习模型缩放、自然语言处理",
        "问题": "研究神经机器翻译中编码器-解码器Transformer模型的缩放特性及其对翻译质量的影响。",
        "动机": "探索和理解神经机器翻译模型的缩放行为，以及如何优化模型大小和结构以提高翻译性能。",
        "方法": "通过实证研究，提出描述交叉熵损失与编码器和解码器大小关系的公式，分析不同缩放方法下的模型表现，并研究训练/测试集组成偏差对缩放行为的影响。",
        "关键词": [
            "神经机器翻译",
            "缩放定律",
            "Transformer模型",
            "交叉熵损失",
            "BLEU分数"
        ],
        "涉及的技术概念": {
            "交叉熵损失": "用于衡量模型预测概率分布与真实概率分布之间的差异，是优化模型训练的关键指标。",
            "缩放定律": "描述了模型性能（如交叉熵损失）如何随模型大小（如编码器和解码器的参数数量）变化的关系。",
            "BLEU分数": "用于评估机器翻译质量的指标，通过比较机器翻译输出与人工参考翻译的相似度来计算。"
        },
        "success": true
    },
    {
        "order": 878,
        "title": "Scarf: Self-Supervised Contrastive Learning using Random Feature Corruption",
        "html": "https://iclr.cc//virtual/2022/poster/6296",
        "abstract": "Self-supervised contrastive representation learning has proved incredibly successful in the vision and natural language domains, enabling state-of-the-art performance with orders of magnitude less labeled data. However, such methods are domain-specific and little has been done to leverage this technique on real-world \\emph{tabular} datasets. We propose \\textsc{Scarf}, a simple, widely-applicable technique for contrastive learning, where views are formed by corrupting a random subset of features. When applied to pre-train deep neural networks on the 69 real-world, tabular classification datasets from the OpenML-CC18 benchmark, \\textsc{Scarf} not only improves classification accuracy in the fully-supervised setting but does so also in the presence of label noise and in the semi-supervised setting where only a fraction of the available training data is labeled. We show that \\textsc{Scarf} complements existing strategies and outperforms alternatives like autoencoders. We conduct comprehensive ablations, detailing the importance of a range of factors.",
        "conference": "ICLR",
        "中文标题": "Scarf：使用随机特征损坏的自监督对比学习",
        "摘要翻译": "自监督对比表示学习在视觉和自然语言领域已证明极其成功，能够在标记数据量少几个数量级的情况下实现最先进的性能。然而，这些方法是领域特定的，对于如何将这种技术应用于现实世界的表格数据集，人们做得很少。我们提出了Scarf，一种简单、广泛适用的对比学习技术，其中视图是通过损坏随机特征子集形成的。当应用于在OpenML-CC18基准测试的69个真实世界表格分类数据集上预训练深度神经网络时，Scarf不仅在全监督设置下提高了分类准确性，而且在存在标签噪声和半监督设置（只有一部分可用训练数据被标记）下也提高了分类准确性。我们展示了Scarf补充了现有策略，并优于自编码器等替代方案。我们进行了全面的消融研究，详细说明了各种因素的重要性。",
        "领域": "自监督学习、表格数据分类、对比学习",
        "问题": "如何在表格数据上有效应用自监督对比学习技术以提高分类准确性",
        "动机": "探索自监督对比学习技术在表格数据上的应用潜力，特别是在标记数据有限或存在噪声的情况下",
        "方法": "提出Scarf技术，通过随机损坏特征子集形成对比学习的视图，应用于表格数据的预训练",
        "关键词": [
            "自监督学习",
            "对比学习",
            "表格数据",
            "特征损坏",
            "分类准确性"
        ],
        "涉及的技术概念": {
            "自监督对比学习": "一种无需大量标记数据即可学习有效表示的技术，通过对比正负样本进行学习",
            "特征损坏": "在形成对比学习视图时，随机选择并修改一部分特征，以增强模型的鲁棒性",
            "表格数据分类": "处理结构化数据（如数据库表格）的分类任务，Scarf技术旨在提升这类任务的表现"
        },
        "success": true
    },
    {
        "order": 879,
        "title": "Scattering Networks on the Sphere for Scalable and Rotationally Equivariant Spherical CNNs",
        "html": "https://iclr.cc//virtual/2022/poster/6521",
        "abstract": "Convolutional neural networks (CNNs) constructed natively on the sphere have been developed recently and shown to be highly effective for the analysis of spherical data.  While an efficient framework has been formulated, spherical CNNs are nevertheless highly computationally demanding; typically they cannot scale beyond spherical signals of thousands of pixels.  We develop scattering networks constructed natively on the sphere that provide a powerful representational space for spherical data.  Spherical scattering networks are computationally scalable and exhibit rotational equivariance, while their representational space is invariant to isometries and provides efficient and stable signal representations.  By integrating scattering networks as an additional type of layer in the generalized spherical CNN framework, we show how they can be leveraged to scale spherical CNNs to the high-resolution data typical of many practical applications, with spherical signals of many tens of megapixels and beyond.",
        "conference": "ICLR",
        "中文标题": "球面上的散射网络：可扩展且旋转等变的球面卷积神经网络",
        "摘要翻译": "最近，直接在球面上构建的卷积神经网络（CNNs）被开发出来，并显示出对球面数据分析的高度有效性。虽然已经制定了一个高效的框架，但球面CNNs的计算需求仍然非常高；通常它们无法扩展到数千像素以上的球面信号。我们开发了直接在球面上构建的散射网络，为球面数据提供了一个强大的表示空间。球面散射网络在计算上是可扩展的，并展现出旋转等变性，同时它们的表示空间对等距变换是不变的，提供了高效且稳定的信号表示。通过将散射网络作为广义球面CNN框架中的一种额外类型的层集成，我们展示了如何利用它们将球面CNNs扩展到许多实际应用中典型的高分辨率数据，包括数十兆像素及以上的球面信号。",
        "领域": "球面数据分析、旋转等变网络、高分辨率信号处理",
        "问题": "解决球面卷积神经网络在处理高分辨率球面信号时的计算可扩展性问题。",
        "动机": "为了克服球面CNNs在处理大规模球面数据时的高计算需求限制，开发一种既计算高效又能保持旋转等变性的方法。",
        "方法": "开发直接在球面上构建的散射网络，作为球面CNN框架中的一种新型层，以提高计算可扩展性和保持旋转等变性。",
        "关键词": [
            "球面散射网络",
            "旋转等变性",
            "高分辨率球面信号",
            "计算可扩展性",
            "球面CNN"
        ],
        "涉及的技术概念": {
            "球面散射网络": "直接在球面上构建的网络，提供高效且稳定的信号表示，同时保持旋转等变性。",
            "旋转等变性": "网络对输入信号的旋转具有等变响应，即网络的输出会相应于输入的旋转而变化。",
            "计算可扩展性": "指网络能够有效地处理大规模数据，如高分辨率的球面信号，而不显著增加计算资源的需求。"
        },
        "success": true
    },
    {
        "order": 880,
        "title": "Scene Transformer: A unified architecture for predicting future trajectories of multiple agents",
        "html": "https://iclr.cc//virtual/2022/poster/5969",
        "abstract": "Predicting the motion of multiple agents is necessary for planning in dynamic environments. This task is challenging for autonomous driving since agents (e.g., vehicles and pedestrians) and their associated behaviors may be diverse and influence one another. Most prior work have focused on predicting independent futures for each agent based on all past motion, and planning against these independent predictions. However, planning against independent predictions can make it challenging to represent the future interaction possibilities between different agents, leading to sub-optimal planning. In this work, we formulate a model for predicting the behavior of all agents jointly, producing consistent futures that account for interactions between agents. Inspired by recent language modeling approaches, we use a masking strategy as the query to our model, enabling one to invoke a single model to predict agent behavior in many ways, such as potentially conditioned on the goal or full future trajectory of the autonomous vehicle or the behavior of other agents in the environment. Our model architecture employs attention to combine features across road elements, agent interactions, and time steps. We evaluate our approach on autonomous driving datasets for both marginal and joint motion prediction, and achieve state of the art performance across two popular datasets. Through combining a scene-centric approach, agent permutation equivariant model, and a sequence masking strategy, we show that our model can unify a variety of motion prediction tasks from joint motion predictions to conditioned prediction.",
        "conference": "ICLR",
        "中文标题": "场景变换器：一种用于预测多个代理未来轨迹的统一架构",
        "摘要翻译": "预测多个代理的运动对于动态环境中的规划是必要的。这项任务对自动驾驶来说具有挑战性，因为代理（如车辆和行人）及其相关行为可能多种多样并相互影响。大多数先前的工作都集中在基于所有过去的运动为每个代理预测独立的未来，并针对这些独立预测进行规划。然而，针对独立预测进行规划可能难以表示不同代理之间未来的互动可能性，导致规划不够优化。在这项工作中，我们制定了一个模型，用于联合预测所有代理的行为，产生考虑到代理之间互动的一致未来。受到最近语言建模方法的启发，我们使用掩码策略作为对我们模型的查询，使得可以以多种方式调用单个模型来预测代理行为，例如可能基于自动驾驶车辆的目标或完整未来轨迹，或环境中其他代理的行为。我们的模型架构采用注意力机制来结合道路元素、代理互动和时间步长的特征。我们在自动驾驶数据集上评估了我们的方法，用于边缘和联合运动预测，并在两个流行数据集上实现了最先进的性能。通过结合场景中心方法、代理置换等变模型和序列掩码策略，我们展示了我们的模型可以统一从联合运动预测到条件预测的各种运动预测任务。",
        "领域": "自动驾驶、运动预测、多代理系统",
        "问题": "如何在自动驾驶中有效预测多个代理（如车辆和行人）的未来轨迹，考虑到它们之间的互动。",
        "动机": "解决现有方法在预测多个代理未来轨迹时忽视代理间互动的问题，以提高自动驾驶规划的准确性和效率。",
        "方法": "采用基于注意力机制的模型架构，结合场景中心方法、代理置换等变模型和序列掩码策略，联合预测所有代理的行为。",
        "关键词": [
            "自动驾驶",
            "运动预测",
            "多代理系统",
            "注意力机制",
            "联合预测"
        ],
        "涉及的技术概念": {
            "注意力机制": "用于结合道路元素、代理互动和时间步长的特征，提高模型对关键信息的关注。",
            "代理置换等变模型": "确保模型对代理的排列顺序不变，增强模型的泛化能力。",
            "序列掩码策略": "作为模型的查询方式，支持多种预测方式，如基于特定条件预测代理行为。"
        },
        "success": true
    },
    {
        "order": 881,
        "title": "Score-Based Generative Modeling with Critically-Damped Langevin Diffusion",
        "html": "https://iclr.cc//virtual/2022/poster/6687",
        "abstract": "Score-based generative models (SGMs) have demonstrated remarkable synthesis quality. SGMs rely on a diffusion process that gradually perturbs the data towards a tractable distribution, while the generative model learns to denoise. The complexity of this denoising task is, apart from the data distribution itself, uniquely determined by the diffusion process. We argue that current SGMs employ overly simplistic diffusions, leading to unnecessarily complex denoising processes, which limit generative modeling performance. Based on connections to statistical mechanics, we propose a novel critically-damped Langevin diffusion (CLD) and show that CLD-based SGMs achieve superior performance. CLD can be interpreted as running a joint diffusion in an extended space, where the auxiliary variables can be considered 'velocities' that are coupled to the data variables as in Hamiltonian dynamics. We derive a novel score matching objective for CLD and show that the model only needs to learn the score function of the conditional distribution of the velocity given data, an easier task than learning scores of the data directly. We also derive a new sampling scheme for efficient synthesis from CLD-based diffusion models. We find that CLD outperforms previous SGMs in synthesis quality for similar network architectures and sampling compute budgets. We show that our novel sampler for CLD significantly outperforms solvers such as Euler–Maruyama. Our framework provides new insights into score-based denoising diffusion models and can be readily used for high-resolution image synthesis. Project page and code: https://nv-tlabs.github.io/CLD-SGM.",
        "conference": "ICLR",
        "中文标题": "基于临界阻尼朗之万扩散的分数生成建模",
        "摘要翻译": "基于分数的生成模型（SGMs）已展现出卓越的合成质量。SGMs依赖于一个扩散过程，该过程逐渐扰动数据向一个易处理的分布靠拢，而生成模型则学习去噪。除了数据分布本身，这一去噪任务的复杂性唯一由扩散过程决定。我们认为当前的SGMs采用了过于简化的扩散过程，导致了不必要的复杂去噪过程，这限制了生成建模的性能。基于与统计力学的联系，我们提出了一种新颖的临界阻尼朗之万扩散（CLD），并展示了基于CLD的SGMs实现了卓越的性能。CLD可以被解释为在一个扩展空间中运行联合扩散，其中辅助变量可以被视为与数据变量耦合的'速度'，如同哈密顿动力学中那样。我们为CLD推导了一个新的分数匹配目标，并表明模型只需要学习给定数据的速度条件分布的分数函数，这是一个比直接学习数据的分数更简单的任务。我们还推导了一种新的采样方案，用于从基于CLD的扩散模型中高效合成。我们发现，在相似的网络架构和采样计算预算下，CLD在合成质量上优于之前的SGMs。我们展示了我们的CLD新采样器显著优于如Euler–Maruyama等求解器。我们的框架为基于分数的去噪扩散模型提供了新的见解，并可以轻松用于高分辨率图像合成。项目页面和代码：https://nv-tlabs.github.io/CLD-SGM。",
        "领域": "生成模型、图像合成、统计力学应用",
        "问题": "当前基于分数的生成模型（SGMs）采用的扩散过程过于简化，导致去噪过程复杂，限制了生成建模的性能。",
        "动机": "通过引入统计力学的概念，改进SGMs的扩散过程，以提高生成模型的性能和效率。",
        "方法": "提出了一种新颖的临界阻尼朗之万扩散（CLD）方法，通过扩展空间中的联合扩散和辅助变量（速度）的引入，简化了分数匹配目标，并开发了新的采样方案。",
        "关键词": [
            "分数生成模型",
            "临界阻尼朗之万扩散",
            "图像合成",
            "统计力学",
            "去噪扩散模型"
        ],
        "涉及的技术概念": {
            "临界阻尼朗之万扩散（CLD）": "一种新颖的扩散过程，通过在扩展空间中引入辅助变量（速度）来简化去噪任务，提高生成模型的性能。",
            "分数匹配目标": "为CLD推导的新目标，模型只需学习速度给定数据的条件分布的分数函数，简化了学习过程。",
            "采样方案": "为基于CLD的扩散模型开发的新采样方法，显著提高了合成效率和质量。"
        },
        "success": true
    },
    {
        "order": 882,
        "title": "SDEdit: Guided Image Synthesis and Editing with Stochastic Differential Equations",
        "html": "https://iclr.cc//virtual/2022/poster/6268",
        "abstract": "Guided image synthesis enables everyday users to create and edit photo-realistic images with minimum effort. The key challenge is balancing faithfulness to the user inputs (e.g., hand-drawn colored strokes) and realism of the synthesized images. Existing GAN-based methods attempt to achieve such balance using either conditional GANs or GAN inversions, which are challenging and often require additional training data or loss functions for individual applications. To address these issues, we introduce a new image synthesis and editing method, Stochastic Differential Editing (SDEdit), based on a diffusion model generative prior, which synthesizes realistic images by iteratively denoising through a stochastic differential equation (SDE). Given an input image with user guide in a form of manipulating RGB pixels, SDEdit first adds noise to the input, then subsequently denoises the resulting image through the SDE prior to increase its realism. SDEdit does not require task-specific training or inversions and can naturally achieve the balance between realism and faithfulness. SDEdit outperforms state-of-the-art GAN-based methods by up to 98.09% on realism and 91.72% on overall satisfaction scores, according to a human perception study, on multiple tasks, including stroke-based image synthesis and editing as well as image compositing.",
        "conference": "ICLR",
        "中文标题": "SDEdit：基于随机微分方程的引导图像合成与编辑",
        "摘要翻译": "引导图像合成使日常用户能够以最小的努力创建和编辑照片般逼真的图像。关键挑战在于平衡对用户输入（例如，手绘彩色笔画）的忠实度和合成图像的真实感。现有的基于GAN的方法尝试通过条件GAN或GAN反转来实现这种平衡，这些方法具有挑战性，并且通常需要针对个别应用的额外训练数据或损失函数。为了解决这些问题，我们引入了一种新的图像合成和编辑方法——随机微分编辑（SDEdit），基于扩散模型生成先验，通过随机微分方程（SDE）迭代去噪来合成真实图像。给定一个带有用户引导（以操作RGB像素的形式）的输入图像，SDEdit首先向输入添加噪声，然后通过SDE先验对结果图像进行去噪以提高其真实感。SDEdit不需要特定任务的训练或反转，可以自然地实现真实感和忠实度之间的平衡。根据人类感知研究，在包括基于笔画的图像合成和编辑以及图像合成在内的多个任务上，SDEdit在真实感上比最先进的基于GAN的方法高出98.09%，在总体满意度得分上高出91.72%。",
        "领域": "图像合成、图像编辑、生成模型",
        "问题": "平衡用户输入的忠实度和合成图像的真实感",
        "动机": "解决现有基于GAN的方法在实现忠实度和真实感平衡时的挑战和限制",
        "方法": "基于扩散模型生成先验，通过随机微分方程（SDE）迭代去噪来合成和编辑图像",
        "关键词": [
            "随机微分方程",
            "图像合成",
            "图像编辑",
            "扩散模型",
            "生成先验"
        ],
        "涉及的技术概念": {
            "随机微分方程（SDE）": "用于迭代去噪过程，提高合成图像的真实感",
            "扩散模型生成先验": "作为基础生成模型，支持无需特定任务训练的图像合成和编辑",
            "去噪": "通过迭代去噪过程，从噪声图像中恢复出高质量的真实图像"
        },
        "success": true
    },
    {
        "order": 883,
        "title": "Selective Ensembles for Consistent Predictions",
        "html": "https://iclr.cc//virtual/2022/poster/6729",
        "abstract": "Recent work has shown that models trained to the same objective, and which achieve similar measures of accuracy on consistent test data, may nonetheless behave very differently on individual predictions. This inconsistency is undesirable in high-stakes contexts, such as medical diagnosis and finance. We show that this duplicitous behavior extends beyond predictions to feature attributions, which may likewise have negative implications for the intelligibility of a model, and one's ability to find recourse for subjects. We then introduce selective ensembles to mitigate such inconsistencies by applying hypothesis testing to the predictions of a set of models trained using randomly-selected starting conditions; importantly, selective ensembles can abstain in cases where a consistent outcome cannot be achieved up to a specified confidence level. We prove that that prediction disagreement between selective ensembles is bounded, and empirically demonstrate that selective ensembles achieve consistent predictions and feature attributions while maintaining low abstention rates. On several benchmark datasets, selective ensembles reach zero inconsistently predicted points, with abstention rates as low as 1.5%.",
        "conference": "ICLR",
        "中文标题": "选择性集成以实现一致预测",
        "摘要翻译": "最近的研究表明，即使模型针对相同的目标进行训练，并且在一致的测试数据上达到相似的准确度度量，它们在个别预测上的行为可能仍然大相径庭。这种不一致性在高风险情境下（如医疗诊断和金融）是不受欢迎的。我们展示了这种双重行为不仅限于预测，还延伸到特征归因，这可能同样对模型的可理解性以及为受试者寻找补救措施的能力产生负面影响。接着，我们引入了选择性集成来通过将假设检验应用于一组使用随机选择的初始条件训练的模型的预测来减轻这种不一致性；重要的是，选择性集成在无法达到指定置信水平的一致结果的情况下可以弃权。我们证明了选择性集成之间的预测分歧是有界的，并通过实证展示了选择性集成在保持低弃权率的同时实现了预测和特征归因的一致性。在几个基准数据集上，选择性集成达到了零不一致预测点，弃权率低至1.5%。",
        "领域": "模型解释性, 机器学习可靠性, 集成学习",
        "问题": "解决模型在相同准确度下预测行为不一致的问题",
        "动机": "提高高风险应用中模型预测的一致性和可靠性",
        "方法": "引入选择性集成，通过假设检验和随机初始条件训练模型集合来减少不一致性",
        "关键词": [
            "选择性集成",
            "预测一致性",
            "特征归因",
            "假设检验",
            "模型可靠性"
        ],
        "涉及的技术概念": {
            "选择性集成": "通过假设检验选择一致预测的模型集合，以减少预测不一致性",
            "特征归因": "分析模型预测中各个特征的贡献，用于提高模型的可解释性",
            "假设检验": "用于评估模型预测是否达到一致性的统计方法"
        },
        "success": true
    },
    {
        "order": 884,
        "title": "Self-ensemble Adversarial Training for Improved Robustness",
        "html": "https://iclr.cc//virtual/2022/poster/6997",
        "abstract": "Due to numerous breakthroughs in real-world applications brought by machine intelligence, deep neural networks (DNNs) are widely employed in critical applications. However, predictions of DNNs are easily manipulated with imperceptible adversarial perturbations, which impedes the further deployment of DNNs and may result in profound security and privacy implications. By incorporating adversarial samples into the training data pool, adversarial training is the strongest principled strategy against various adversarial attacks among all sorts of defense methods. Recent works mainly focus on developing new loss functions or regularizers, attempting to find the unique optimal point in the weight space. But none of them taps the potentials of classifiers obtained from standard adversarial training, especially states on the searching trajectory of training. In this work, we are dedicated to the weight states of models through the training process and devise a simple but powerful \\emph{Self-Ensemble Adversarial Training} (SEAT) method for yielding a robust classifier by averaging weights of history models. This considerably improves the robustness of the target model against several well known adversarial attacks, even merely utilizing the naive cross-entropy loss to supervise. We also discuss the relationship between the ensemble of predictions from different adversarially trained models and the prediction of weight-ensembled models, as well as provide theoretical and empirical evidence that the proposed self-ensemble method provides a smoother loss landscape and better robustness than both individual models and the ensemble of predictions from different classifiers. We further analyze a subtle but fatal issue in the general settings for the self-ensemble model, which causes the deterioration of the weight-ensembled method in the late phases. ",
        "conference": "ICLR",
        "中文标题": "自集成对抗训练以提升鲁棒性",
        "摘要翻译": "由于机器智能在现实世界应用中带来的众多突破，深度神经网络（DNNs）被广泛应用于关键应用中。然而，DNNs的预测容易被不易察觉的对抗性扰动所操纵，这阻碍了DNNs的进一步部署，并可能导致深远的安全和隐私影响。通过将对抗性样本纳入训练数据池，对抗训练是所有防御方法中对抗各种对抗性攻击的最强原则性策略。最近的工作主要集中在开发新的损失函数或正则化器，试图在权重空间中找到唯一的最优点。但它们都没有挖掘标准对抗训练获得的分类器的潜力，尤其是在训练搜索轨迹上的状态。在这项工作中，我们致力于通过训练过程中的模型权重状态，设计了一种简单但强大的自集成对抗训练（SEAT）方法，通过平均历史模型的权重来产生一个鲁棒的分类器。这显著提高了目标模型对几种众所周知的对抗性攻击的鲁棒性，甚至仅利用朴素的交叉熵损失进行监督。我们还讨论了来自不同对抗训练模型的预测集成与权重集成模型的预测之间的关系，并提供了理论和实证证据，表明所提出的自集成方法提供了比单个模型和来自不同分类器的预测集成更平滑的损失景观和更好的鲁棒性。我们进一步分析了自集成模型在一般设置中的一个微妙但致命的问题，这导致了权重集成方法在后期阶段的恶化。",
        "领域": "对抗性机器学习",
        "问题": "深度神经网络对对抗性扰动的脆弱性",
        "动机": "提高深度神经网络对抗对抗性攻击的鲁棒性",
        "方法": "提出自集成对抗训练（SEAT）方法，通过平均历史模型的权重来产生鲁棒的分类器",
        "关键词": [
            "对抗性训练",
            "模型鲁棒性",
            "权重集成"
        ],
        "涉及的技术概念": {
            "对抗性训练": "通过将对抗性样本纳入训练数据池，提高模型对对抗性攻击的鲁棒性",
            "权重集成": "通过平均历史模型的权重来产生一个鲁棒的分类器，提高模型的鲁棒性",
            "损失景观": "描述模型在训练过程中的损失函数变化情况，自集成方法提供了更平滑的损失景观"
        },
        "success": true
    },
    {
        "order": 885,
        "title": "Self-Joint Supervised Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6953",
        "abstract": "Supervised learning is a fundamental framework used to train machine learning systems. A supervised learning problem is often formulated using an i.i.d. assumption that restricts model attention to a single relevant signal at a time when predicting. This contrasts with the human ability to actively use related samples as reference when making decisions. We hypothesize that the restriction to a single signal for each prediction in the standard i.i.d. framework contributes to well-known drawbacks of supervised learning: making overconfident predictions and vulnerability to overfitting, adversarial attacks, and out-of-distribution data. To address these limitations, we propose a new supervised learning paradigm called self-joint learning that generalizes the standard approach by modeling the joint conditional distribution of two observed samples, where each sample is an image and its label. Rather than assuming samples are independent, our models explicitly learn the sample-to-sample relation of conditional independence. Our framework can naturally incorporate auxiliary unlabeled data to further improve the performance. Experiments on benchmark image datasets show our method offers significant improvement over standard supervised learning in terms of accuracy, robustness against adversarial attacks, out-of-distribution detection, and overconfidence mitigation.",
        "conference": "ICLR",
        "中文标题": "自联合监督学习",
        "摘要翻译": "监督学习是用于训练机器学习系统的基本框架。监督学习问题通常使用独立同分布假设来表述，该假设在预测时将模型注意力限制在每次仅关注一个相关信号上。这与人类在做出决策时能够主动使用相关样本作为参考的能力形成对比。我们假设，在标准的独立同分布框架中，每次预测仅限制于一个信号，这导致了监督学习的众所周知缺点：做出过于自信的预测，以及对过拟合、对抗性攻击和分布外数据的脆弱性。为了解决这些限制，我们提出了一种新的监督学习范式，称为自联合学习，它通过建模两个观察样本的联合条件分布来泛化标准方法，其中每个样本是一个图像及其标签。我们的模型不是假设样本是独立的，而是明确学习样本间条件独立的关系。我们的框架可以自然地整合辅助的未标记数据以进一步提高性能。在基准图像数据集上的实验表明，我们的方法在准确性、对抗性攻击的鲁棒性、分布外检测和过度自信缓解方面比标准监督学习有显著改进。",
        "领域": "深度学习与计算机视觉结合、图像分类、对抗性机器学习",
        "问题": "解决监督学习中的过自信预测、过拟合、对抗性攻击脆弱性和分布外数据问题",
        "动机": "通过模拟人类决策时使用相关样本作为参考的能力，改进监督学习的局限",
        "方法": "提出自联合学习范式，建模两个观察样本的联合条件分布，明确学习样本间条件独立的关系，并整合未标记数据以提高性能",
        "关键词": [
            "自联合学习",
            "监督学习",
            "对抗性鲁棒性",
            "分布外检测",
            "过度自信缓解"
        ],
        "涉及的技术概念": {
            "自联合学习": "一种新的监督学习范式，通过建模两个观察样本的联合条件分布来泛化标准监督学习方法",
            "联合条件分布": "在自联合学习中，用于描述两个观察样本之间关系的统计分布，其中每个样本是一个图像及其标签",
            "条件独立性": "在自联合学习中，模型明确学习的样本间关系，用于改进模型的预测准确性和鲁棒性"
        },
        "success": true
    },
    {
        "order": 886,
        "title": "Self-Supervised Graph Neural Networks for Improved Electroencephalographic Seizure Analysis",
        "html": "https://iclr.cc//virtual/2022/poster/7027",
        "abstract": "Automated seizure detection and classification from electroencephalography (EEG) can greatly improve seizure diagnosis and treatment. However, several modeling challenges remain unaddressed in prior automated seizure detection and classification studies: (1) representing non-Euclidean data structure in EEGs, (2) accurately classifying rare seizure types, and (3) lacking a quantitative interpretability approach to measure model ability to localize seizures. In this study, we address these challenges by (1) representing the spatiotemporal dependencies in EEGs using a graph neural network (GNN) and proposing two EEG graph structures that capture the electrode geometry or dynamic brain connectivity, (2) proposing a self-supervised pre-training method that predicts preprocessed signals for the next time period to further improve model performance, particularly on rare seizure types, and (3) proposing a quantitative model interpretability approach to assess a model’s ability to localize seizures within EEGs. When evaluating our approach on seizure detection and classification on a large public dataset (5,499 EEGs), we find that our GNN with self-supervised pre-training achieves 0.875 Area Under the Receiver Operating Characteristic Curve on seizure detection and 0.749 weighted F1-score on seizure classification, outperforming previous methods for both seizure detection and classification. Moreover, our self-supervised pre-training strategy significantly improves classification of rare seizure types (e.g. 47 points increase in combined tonic seizure accuracy over baselines). Furthermore, quantitative interpretability analysis shows that our GNN with self-supervised pre-training precisely localizes 25.4% focal seizures, a 21.9 point improvement over existing CNNs. Finally, by superimposing the identified seizure locations on both raw EEG signals and EEG graphs, our approach could provide clinicians with an intuitive visualization of localized seizure regions.",
        "conference": "ICLR",
        "中文标题": "自监督图神经网络在改进脑电图癫痫分析中的应用",
        "摘要翻译": "通过脑电图（EEG）自动检测和分类癫痫发作可以极大地改善癫痫的诊断和治疗。然而，在以往的自动癫痫检测和分类研究中，仍有几个建模挑战未得到解决：（1）表示EEG中的非欧几里得数据结构，（2）准确分类罕见的癫痫类型，（3）缺乏一种定量可解释性方法来衡量模型定位癫痫发作的能力。在本研究中，我们通过（1）使用图神经网络（GNN）表示EEG中的时空依赖性，并提出两种捕捉电极几何或动态大脑连接的EEG图结构，（2）提出一种自监督预训练方法，预测下一时间段的预处理信号，以进一步提高模型性能，特别是在罕见癫痫类型上，（3）提出一种定量模型可解释性方法，评估模型在EEG中定位癫痫发作的能力，来解决这些挑战。在大型公共数据集（5,499个EEG）上评估我们的癫痫检测和分类方法时，我们发现带有自监督预训练的GNN在癫痫检测上达到了0.875的接收者操作特征曲线下面积，在癫痫分类上达到了0.749的加权F1分数，优于之前的癫痫检测和分类方法。此外，我们的自监督预训练策略显著提高了罕见癫痫类型的分类（例如，与基线相比，联合强直性癫痫的准确率提高了47点）。此外，定量可解释性分析显示，我们的带有自监督预训练的GNN精确地定位了25.4%的局灶性癫痫发作，比现有的CNN提高了21.9点。最后，通过在原始EEG信号和EEG图上叠加识别的癫痫发作位置，我们的方法可以为临床医生提供局部癫痫发作区域的直观可视化。",
        "领域": "癫痫检测与分类、脑电图分析、自监督学习",
        "问题": "解决脑电图（EEG）中非欧几里得数据结构表示、罕见癫痫类型准确分类及缺乏定量可解释性方法的问题",
        "动机": "改进癫痫的自动检测和分类，提高诊断和治疗的准确性和效率",
        "方法": "使用图神经网络（GNN）表示EEG中的时空依赖性，提出自监督预训练方法和定量模型可解释性方法",
        "关键词": [
            "图神经网络",
            "自监督学习",
            "癫痫检测",
            "脑电图分析",
            "模型可解释性"
        ],
        "涉及的技术概念": {
            "图神经网络（GNN）": "用于表示EEG中的非欧几里得数据结构和时空依赖性",
            "自监督预训练": "通过预测下一时间段的预处理信号来提高模型性能，特别是在罕见癫痫类型上",
            "定量模型可解释性": "评估模型在EEG中定位癫痫发作的能力，提供直观的可视化"
        },
        "success": true
    },
    {
        "order": 887,
        "title": "Self-Supervised Inference in State-Space Models",
        "html": "https://iclr.cc//virtual/2022/poster/6606",
        "abstract": "We perform approximate inference in state-space models with nonlinear state transitions. Without parameterizing a generative model, we apply Bayesian update formulas using a local linearity approximation parameterized by neural networks. It comes accompanied by a maximum likelihood objective that requires no supervision via uncorrupt observations or ground truth latent states. The optimization backpropagates through a recursion similar to the classical Kalman filter and smoother. Additionally, using an approximate conditional independence, we can perform smoothing without having to parameterize a separate model. In scientific applications, domain knowledge can give a linear approximation of the latent transition maps, which we can easily incorporate into our model. Usage of such domain knowledge is reflected in excellent results (despite our model's simplicity) on the chaotic Lorenz system compared to fully supervised and variational inference methods. Finally, we show competitive results on an audio denoising experiment.",
        "conference": "ICLR",
        "中文标题": "状态空间模型中的自监督推理",
        "摘要翻译": "我们在具有非线性状态转换的状态空间模型中执行近似推理。无需参数化生成模型，我们应用贝叶斯更新公式，使用由神经网络参数化的局部线性近似。这伴随着一个最大似然目标，该目标不需要通过未损坏的观测或真实潜在状态进行监督。优化通过类似于经典卡尔曼滤波器和平滑器的递归进行反向传播。此外，利用近似条件独立性，我们可以在不需要参数化单独模型的情况下执行平滑。在科学应用中，领域知识可以提供潜在转换映射的线性近似，我们可以轻松地将其纳入我们的模型。这种领域知识的使用体现在与完全监督和变分推理方法相比，在混沌洛伦兹系统上取得的优异结果（尽管我们的模型简单）。最后，我们在音频去噪实验中展示了竞争性结果。",
        "领域": "非线性状态空间模型、自监督学习、音频去噪",
        "问题": "在非线性状态转换的状态空间模型中执行近似推理，无需参数化生成模型或依赖监督数据。",
        "动机": "开发一种无需监督数据即可在非线性状态空间模型中执行推理的方法，利用领域知识提高模型性能。",
        "方法": "应用贝叶斯更新公式和局部线性近似，由神经网络参数化，结合最大似然目标进行优化，无需监督数据。",
        "关键词": [
            "自监督学习",
            "状态空间模型",
            "非线性状态转换",
            "贝叶斯推理",
            "音频去噪"
        ],
        "涉及的技术概念": {
            "局部线性近似": "由神经网络参数化，用于在非线性状态转换中应用贝叶斯更新公式。",
            "最大似然目标": "用于优化模型，无需监督数据，通过反向传播和递归实现。",
            "近似条件独立性": "允许在不参数化单独模型的情况下执行平滑操作。"
        },
        "success": true
    },
    {
        "order": 888,
        "title": "Self-supervised Learning is More Robust to Dataset Imbalance",
        "html": "https://iclr.cc//virtual/2022/poster/6413",
        "abstract": "Self-supervised learning (SSL) is a scalable way to learn general visual representations since it learns without labels. However, large-scale unlabeled datasets in the wild often have long-tailed label distributions, where we know little about the behavior of SSL. In this work, we systematically investigate self-supervised learning under dataset imbalance. First, we find via extensive experiments that off-the-shelf self-supervised representations are already more robust to class imbalance than supervised representations. The performance gap between balanced and imbalanced pre-training with SSL is significantly smaller than the gap with supervised learning, across sample sizes, for both in-domain and, especially, out-of-domain evaluation. Second, towards understanding the robustness of SSL, we hypothesize that SSL learns richer features from frequent data: it may learn label-irrelevant-but-transferable features that help classify the rare classes and downstream tasks. In contrast, supervised learning has no incentive to learn features irrelevant to the labels from frequent examples. We validate this hypothesis with semi-synthetic experiments as well as rigorous mathematical analyses on a simplified setting. Third, inspired by the theoretical insights, we devise a re-weighted regularization technique that  consistently improves the SSL representation quality on imbalanced datasets with several evaluation criteria, closing the small gap between balanced and imbalanced datasets with the same number of examples.",
        "conference": "ICLR",
        "中文标题": "自监督学习对数据集不平衡更具鲁棒性",
        "摘要翻译": "自监督学习（SSL）是一种无需标签即可学习通用视觉表示的可扩展方法。然而，现实世界中的大规模无标签数据集往往具有长尾标签分布，我们对SSL在这种情况下的行为知之甚少。在这项工作中，我们系统地研究了数据集不平衡下的自监督学习。首先，通过大量实验我们发现，现成的自监督表示已经比监督表示对类别不平衡更具鲁棒性。在样本大小相同的情况下，无论是域内还是域外评估，SSL在平衡和不平衡预训练之间的性能差距显著小于监督学习的差距。其次，为了理解SSL的鲁棒性，我们假设SSL从频繁数据中学习到更丰富的特征：它可能学习到与标签无关但可转移的特征，这些特征有助于分类稀有类别和下游任务。相比之下，监督学习没有动力从频繁示例中学习与标签无关的特征。我们通过半合成实验以及简化设置上的严格数学分析验证了这一假设。第三，受理论见解的启发，我们设计了一种重新加权的正则化技术，该技术在多个评估标准上持续提高了不平衡数据集上SSL表示的质量，缩小了相同数量示例下平衡和不平衡数据集之间的小差距。",
        "领域": "自监督学习",
        "问题": "研究自监督学习在数据集不平衡情况下的表现及其鲁棒性",
        "动机": "探索自监督学习在处理长尾分布数据集时的优势及其潜在机制",
        "方法": "通过实验比较、假设验证和数学分析，提出了一种改进的自监督学习正则化技术",
        "关键词": [
            "自监督学习",
            "数据集不平衡",
            "长尾分布",
            "特征学习",
            "正则化技术"
        ],
        "涉及的技术概念": {
            "自监督学习": "一种无需标签即可学习通用视觉表示的方法，用于提高模型对不平衡数据集的鲁棒性",
            "长尾分布": "数据集中少数类别拥有大量样本，而多数类别样本稀少的情况，研究其对学习算法的影响",
            "正则化技术": "用于防止模型过拟合的技术，本文中特指为改进自监督学习在不平衡数据集上的表现而设计的重新加权方法"
        },
        "success": true
    },
    {
        "order": 889,
        "title": "Self-Supervision Enhanced Feature Selection with Correlated Gates",
        "html": "https://iclr.cc//virtual/2022/poster/7103",
        "abstract": "Discovering relevant input features for predicting a target variable is a key scientific question. However, in many domains, such as medicine and biology, feature selection is confounded by a scarcity of labeled samples coupled with significant correlations among features. In this paper, we propose a novel deep learning approach to feature selection that addresses both challenges simultaneously. First, we pre-train the network using unlabeled samples within a self-supervised learning framework by solving pretext tasks that require the network to learn informative representations from partial feature sets. Then, we fine-tune the pre-trained network to discover relevant features using labeled samples. During both training phases, we explicitly account for the correlation structure of the input features by generating correlated gate vectors from a multivariate Bernoulli distribution. Experiments on multiple real-world datasets including clinical and omics demonstrate that our model discovers relevant features that provide superior prediction performance compared to the state-of-the-art benchmarks in practical scenarios where there is often limited labeled data and high correlations among features.",
        "conference": "ICLR",
        "中文标题": "自监督增强的带相关门特征选择",
        "摘要翻译": "发现用于预测目标变量的相关输入特征是一个关键的科学问题。然而，在许多领域，如医学和生物学，特征选择受到标记样本稀缺和特征间显著相关性的困扰。在本文中，我们提出了一种新颖的深度学习特征选择方法，同时解决了这两个挑战。首先，我们在自监督学习框架内使用未标记样本预训练网络，通过解决需要网络从部分特征集中学习信息表示的前置任务。然后，我们使用标记样本微调预训练网络以发现相关特征。在这两个训练阶段，我们通过从多元伯努利分布生成相关门向量，明确考虑了输入特征的相关结构。在包括临床和组学在内的多个真实世界数据集上的实验表明，在标记数据有限且特征间相关性高的实际场景中，我们的模型发现的那些相关特征提供了优于现有基准的预测性能。",
        "领域": "特征选择、自监督学习、深度学习应用",
        "问题": "在标记样本稀缺且特征间存在显著相关性的情况下，如何有效地进行特征选择。",
        "动机": "解决在医学和生物学等领域中，由于标记数据稀缺和特征间高相关性导致的特征选择难题。",
        "方法": "提出了一种结合自监督学习和深度学习的方法，通过预训练和微调两个阶段，利用多元伯努利分布生成相关门向量来考虑特征间的相关性。",
        "关键词": [
            "自监督学习",
            "特征选择",
            "深度学习",
            "多元伯努利分布",
            "相关性建模"
        ],
        "涉及的技术概念": {
            "自监督学习": "用于预训练网络，通过解决前置任务从未标记数据中学习有用的特征表示。",
            "多元伯努利分布": "用于生成相关门向量，明确建模特征间的相关性，以指导特征选择过程。",
            "特征选择": "核心任务，旨在从高维数据中识别出对预测目标变量最有用的特征子集。"
        },
        "success": true
    },
    {
        "order": 890,
        "title": "Semi-relaxed Gromov-Wasserstein divergence and applications on graphs",
        "html": "https://iclr.cc//virtual/2022/poster/6131",
        "abstract": "Comparing structured objects such as graphs is a fundamental operationinvolved in many learning tasks. To this end, the Gromov-Wasserstein (GW)distance, based on Optimal Transport (OT), has proven to be successful inhandling the specific nature of the associated objects. More specifically,through the nodes connectivity relations, GW operates on graphs, seen asprobability measures over specific spaces. At the core of OT is the idea ofconservation of mass, which imposes a coupling between all the nodes fromthe two considered graphs. We argue in this paper that this property can bedetrimental for tasks such as graph dictionary or partition learning, and werelax it by proposing a new semi-relaxed Gromov-Wasserstein divergence.Aside from immediate computational benefits, we discuss its properties, andshow that it can lead to an efficient graph dictionary learning algorithm.We empirically demonstrate its relevance for complex tasks on graphs such aspartitioning, clustering and completion.",
        "conference": "ICLR",
        "中文标题": "半松弛Gromov-Wasserstein散度及其在图上的应用",
        "摘要翻译": "比较结构化对象如图是许多学习任务中的基本操作。为此，基于最优传输（OT）的Gromov-Wasserstein（GW）距离在处理相关对象的特定性质方面已被证明是成功的。更具体地说，通过节点的连接关系，GW操作于图，将其视为特定空间上的概率测度。OT的核心是质量守恒的思想，这强加了对两个考虑图中所有节点的耦合。我们在本文中认为，这一性质对于如图字典或分区学习等任务可能是有害的，我们通过提出一种新的半松弛Gromov-Wasserstein散度来放松它。除了直接的计算好处外，我们讨论了它的性质，并表明它可以导致一个高效的图字典学习算法。我们通过实验证明了它在图上的复杂任务如分区、聚类和完成中的相关性。",
        "领域": "图表示学习, 图聚类, 图分割",
        "问题": "解决传统Gromov-Wasserstein距离在图字典学习和分区学习等任务中因质量守恒性质导致的限制问题",
        "动机": "传统Gromov-Wasserstein距离的质量守恒性质在图字典学习和分区学习等任务中可能产生不利影响，因此需要一种更灵活的方法来放松这一限制",
        "方法": "提出一种新的半松弛Gromov-Wasserstein散度，放松质量守恒的限制，并开发高效的图字典学习算法",
        "关键词": [
            "Gromov-Wasserstein散度",
            "图字典学习",
            "图聚类",
            "图分割",
            "最优传输"
        ],
        "涉及的技术概念": {
            "Gromov-Wasserstein距离": "用于比较结构化对象如图的距离度量，基于最优传输理论",
            "最优传输": "一种数学框架，用于在两个概率分布之间找到最优的传输方案",
            "半松弛Gromov-Wasserstein散度": "本文提出的新方法，放松了传统GW距离中的质量守恒限制，以提高在图字典学习和分区学习等任务中的灵活性和效率"
        },
        "success": true
    },
    {
        "order": 891,
        "title": "Sequence Approximation using Feedforward Spiking Neural Network for Spatiotemporal Learning: Theory and Optimization Methods",
        "html": "https://iclr.cc//virtual/2022/poster/6640",
        "abstract": "A dynamical system of spiking neurons with only feedforward connections can classify spatiotemporal patterns without recurrent connections. However, the theoretical construct of a feedforward spiking neural network (SNN) for approximating a temporal sequence remains unclear, making it challenging to optimize SNN architectures for learning complex spatiotemporal patterns. In this work, we establish a theoretical framework to understand and improve sequence approximation using a feedforward SNN. Our framework shows that a feedforward SNN with one neuron per layer and skip-layer connections can approximate the mapping function between any arbitrary pairs of input and output spike train on a compact domain. Moreover, we prove that heterogeneous neurons with varying dynamics and skip-layer connections improve sequence approximation using feedforward SNN. Consequently, we propose SNN architectures incorporating the preceding constructs that are trained using supervised backpropagation-through-time (BPTT) and unsupervised spiking-timing-dependent plasticity (STDP) algorithms for classification of spatiotemporal data. A dual-search-space Bayesian optimization method is developed to optimize architecture and parameters of the proposed SNN with heterogeneous neuron dynamics and skip-layer connections. ",
        "conference": "ICLR",
        "success": true,
        "中文标题": "使用前馈脉冲神经网络进行时空学习的序列近似：理论与优化方法",
        "摘要翻译": "仅具有前馈连接的脉冲神经元动态系统可以在没有循环连接的情况下分类时空模式。然而，用于近似时间序列的前馈脉冲神经网络（SNN）的理论构建仍不明确，这使得优化SNN架构以学习复杂时空模式具有挑战性。在这项工作中，我们建立了一个理论框架来理解和改进使用前馈SNN的序列近似。我们的框架表明，具有每层一个神经元和跨层连接的前馈SNN可以在紧凑域上近似任意输入和输出脉冲序列之间的映射函数。此外，我们证明了具有变化动态和跨层连接的异质神经元可以改进使用前馈SNN的序列近似。因此，我们提出了包含前述构建的SNN架构，这些架构使用监督性的时间反向传播（BPTT）和无监督的脉冲时间依赖可塑性（STDP）算法进行训练，用于时空数据的分类。开发了一种双搜索空间贝叶斯优化方法，以优化具有异质神经元动态和跨层连接的提议SNN的架构和参数。",
        "领域": "脉冲神经网络, 时空模式识别, 机器学习优化",
        "问题": "前馈脉冲神经网络在近似时间序列方面的理论构建不明确，难以优化其架构以学习复杂时空模式。",
        "动机": "建立理论框架以理解和改进前馈脉冲神经网络在序列近似中的应用，优化其架构和参数以提高时空数据分类的性能。",
        "方法": "提出了一种包含异质神经元动态和跨层连接的SNN架构，使用BPTT和STDP算法进行训练，并开发了双搜索空间贝叶斯优化方法来优化架构和参数。",
        "关键词": [
            "脉冲神经网络",
            "时空学习",
            "序列近似",
            "贝叶斯优化",
            "异质神经元"
        ],
        "涉及的技术概念": {
            "前馈脉冲神经网络": "用于近似时间序列的神经网络架构，具有前馈连接，无需循环连接即可处理时空模式。",
            "时间反向传播（BPTT）": "一种监督学习算法，用于训练神经网络处理时间序列数据，通过时间展开网络并应用反向传播算法。",
            "脉冲时间依赖可塑性（STDP）": "一种无监督学习规则，根据神经元间脉冲的时间差异调整突触强度，用于时空模式的学习和分类。"
        }
    },
    {
        "order": 892,
        "title": "Sequential Reptile: Inter-Task Gradient Alignment for Multilingual Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6199",
        "abstract": "Multilingual models jointly pretrained on multiple languages have achieved remarkable performance on various multilingual downstream tasks. Moreover, models finetuned on a single monolingual downstream task have shown to generalize to unseen languages. In this paper, we first show that it is crucial for those tasks to align gradients between them in order to maximize knowledge transfer while minimizing negative transfer. Despite its importance, the existing methods for gradient alignment either have a completely different purpose, ignore inter-task alignment, or aim to solve continual learning problems in rather inefficient ways. As a result of the misaligned gradients between tasks, the model suffers from severe negative transfer in the form of catastrophic forgetting of the knowledge acquired from the pretraining. To overcome the limitations, we propose a simple yet effective method that can efficiently align gradients between tasks. Specifically, we perform each inner-optimization by sequentially sampling batches from all the tasks, followed by a Reptile outer update. Thanks to the gradients aligned between tasks by our method, the model becomes less vulnerable to negative transfer and catastrophic forgetting. We extensively validate our method on various multi-task learning and zero-shot cross-lingual transfer tasks, where our method largely outperforms all the relevant baselines we consider.",
        "conference": "ICLR",
        "中文标题": "序列化Reptile：面向多语言学习的任务间梯度对齐",
        "摘要翻译": "在多语言上联合预训练的模型在各种多语言下游任务中取得了显著的性能。此外，针对单一单语言下游任务进行微调的模型已显示出对未见语言的泛化能力。在本文中，我们首先表明，为了最大化知识转移同时最小化负转移，对这些任务之间的梯度进行对齐至关重要。尽管其重要性，现有的梯度对齐方法要么目的完全不同，忽视了任务间对齐，要么旨在以相当低效的方式解决持续学习问题。由于任务间梯度的不对齐，模型遭受了严重的负转移，表现为对预训练获得知识的灾难性遗忘。为了克服这些限制，我们提出了一种简单而有效的方法，可以高效地对齐任务间的梯度。具体来说，我们通过从所有任务中顺序采样批次来执行每个内部优化，随后进行Reptile外部更新。得益于我们方法对齐的任务间梯度，模型变得不那么容易受到负转移和灾难性遗忘的影响。我们在各种多任务学习和零样本跨语言迁移任务上广泛验证了我们的方法，在这些任务中，我们的方法大幅优于我们考虑的所有相关基线。",
        "领域": "多任务学习, 零样本跨语言迁移, 深度学习优化",
        "问题": "解决多语言学习中任务间梯度不对齐导致的负转移和灾难性遗忘问题",
        "动机": "为了在多语言学习中最大化知识转移同时最小化负转移，需要有效对齐任务间的梯度",
        "方法": "提出一种通过顺序采样所有任务的批次进行内部优化，随后进行Reptile外部更新的方法，以高效对齐任务间梯度",
        "关键词": [
            "多语言学习",
            "梯度对齐",
            "Reptile算法",
            "负转移",
            "灾难性遗忘"
        ],
        "涉及的技术概念": {
            "梯度对齐": "在多任务学习中调整不同任务梯度方向，以促进正向知识转移并减少负向干扰",
            "Reptile算法": "一种元学习算法，通过多次内部更新和一次外部更新来优化模型，本文用于任务间梯度对齐",
            "灾难性遗忘": "模型在学习新任务时忘记之前学到的知识，本文通过梯度对齐减轻这一问题"
        },
        "success": true
    },
    {
        "order": 893,
        "title": "SGD Can Converge to Local Maxima",
        "html": "https://iclr.cc//virtual/2022/poster/6576",
        "abstract": "Previous works on stochastic gradient descent (SGD) often focus on its success. In this work, we construct worst-case optimization problems illustrating that, when not in the regimes that the previous works often assume, SGD can exhibit many strange and potentially undesirable behaviors. Specifically, we construct landscapes and data distributions such that (1) SGD converges to local maxima, (2) SGD escapes saddle points arbitrarily slowly, (3) SGD prefers sharp minima over flat ones, and (4) AMSGrad converges to local maxima. We also realize results in a minimal neural network-like example. Our results highlight the importance of simultaneously analyzing the minibatch sampling, discrete-time updates rules, and realistic landscapes to understand the role of SGD in deep learning.",
        "conference": "ICLR",
        "中文标题": "随机梯度下降法可收敛至局部最大值",
        "摘要翻译": "以往关于随机梯度下降（SGD）的研究多聚焦于其成功案例。本研究中，我们构建了最坏情况下的优化问题，以说明当不处于以往研究常假设的范围内时，SGD可能展现出许多奇怪且潜在不理想的行为。具体而言，我们构建了地形和数据分布，使得（1）SGD收敛至局部最大值，（2）SGD逃离鞍点的速度任意慢，（3）SGD偏好尖锐最小值而非平坦最小值，以及（4）AMSGrad收敛至局部最大值。我们还在一个最小化的类神经网络示例中实现了这些结果。我们的研究结果强调了同时分析小批量采样、离散时间更新规则及实际地形对于理解SGD在深度学习中作用的重要性。",
        "领域": "优化算法、深度学习理论、神经网络训练",
        "问题": "揭示随机梯度下降（SGD）在非理想条件下的异常收敛行为",
        "动机": "探索SGD在不符合传统假设条件下的表现，以更全面地理解其在深度学习中的应用和限制",
        "方法": "构建特定的优化问题和数据分布，通过理论分析和实验验证SGD的异常行为",
        "关键词": [
            "随机梯度下降",
            "局部最大值",
            "优化问题",
            "深度学习理论",
            "神经网络训练"
        ],
        "涉及的技术概念": {
            "随机梯度下降（SGD）": "一种常用的优化算法，用于在深度学习中最小化损失函数，本研究中探讨其在非理想条件下的行为",
            "局部最大值": "优化过程中的一个点，其周围所有点的函数值都不大于该点的值，本研究展示了SGD可能收敛至这类点",
            "AMSGrad": "SGD的一个变种，旨在解决传统SGD在某些情况下的性能问题，本研究发现其也可能收敛至局部最大值"
        },
        "success": true
    },
    {
        "order": 894,
        "title": "Shallow and Deep Networks are Near-Optimal Approximators of Korobov Functions",
        "html": "https://iclr.cc//virtual/2022/poster/6865",
        "abstract": "In this paper, we analyze the number of neurons and training parameters that a neural network needs to approximate multivariate functions of bounded second mixed derivatives --- Korobov functions. We prove upper bounds on these quantities for shallow and deep neural networks, drastically lessening the curse of dimensionality. Our bounds hold for general activation functions, including ReLU. We further prove that these bounds nearly match the minimal number of parameters any continuous function approximator needs to approximate Korobov functions, showing that neural networks are near-optimal function approximators.",
        "conference": "ICLR",
        "中文标题": "浅层与深层网络对Korobov函数的近似近乎最优",
        "摘要翻译": "在本文中，我们分析了神经网络近似具有有界二阶混合导数的多元函数——Korobov函数所需的神经元数量和训练参数。我们证明了浅层和深层神经网络在这些量上的上界，极大地减轻了维度灾难。我们的界限适用于包括ReLU在内的通用激活函数。我们进一步证明，这些界限几乎匹配任何连续函数近似器近似Korobov函数所需的最小参数数量，表明神经网络是近乎最优的函数近似器。",
        "领域": "函数近似理论、神经网络优化、高维数据分析",
        "问题": "分析神经网络在近似Korobov函数时所需的神经元和参数数量，以及如何减轻维度灾难。",
        "动机": "探索神经网络在近似高维函数时的效率和最优性，特别是在减轻维度灾难方面的潜力。",
        "方法": "通过理论分析，证明了浅层和深层神经网络在近似Korobov函数时的上界，并与最小参数需求进行比较。",
        "关键词": [
            "Korobov函数",
            "维度灾难",
            "神经网络近似",
            "激活函数",
            "参数效率"
        ],
        "涉及的技术概念": {
            "Korobov函数": "具有有界二阶混合导数的多元函数，用于分析神经网络在高维空间中的近似能力。",
            "维度灾难": "在高维空间中，数据稀疏性和计算复杂性急剧增加的现象，本文通过神经网络的有效近似减轻这一问题。",
            "激活函数": "神经网络中引入非线性的函数，如ReLU，本文证明了对于包括ReLU在内的通用激活函数，神经网络都能有效近似Korobov函数。"
        },
        "success": true
    },
    {
        "order": 895,
        "title": "SHINE: SHaring the INverse Estimate from the forward pass for bi-level optimization and implicit models",
        "html": "https://iclr.cc//virtual/2022/poster/6363",
        "abstract": "In recent years, implicit deep learning has emerged as a method to increase the depth of deep neural networks. While their training is memory-efficient, they are still significantly slower to train than their explicit counterparts. In Deep Equilibrium Models~(DEQs), the training is performed as a bi-level problem, and its computational complexity is partially driven by the iterative inversion of a huge Jacobian matrix. In this paper, we propose a novel strategy to tackle this computational bottleneck from which many bi-level problems suffer. The main idea is to use the quasi-Newton matrices from the forward pass to efficiently approximate the inverse Jacobian matrix in the direction needed for the gradient computation. We provide a theorem that motivates using our method with the original forward algorithms. In addition, by modifying these forward algorithms, we further provide theoretical guarantees that our method asymptotically estimates the true implicit gradient. We empirically study this approach in many settings, ranging from hyperparameter optimization to large Multiscale DEQs applied to CIFAR and ImageNet. We show that it reduces the computational cost of the backward pass by up to two orders of magnitude. All this is achieved while retaining the excellent performance of the original models in hyperparameter optimization and on CIFAR, and giving encouraging and competitive results on ImageNet.",
        "conference": "ICLR",
        "中文标题": "SHINE：共享前向传递中的逆估计用于双层优化和隐式模型",
        "摘要翻译": "近年来，隐式深度学习已成为增加深度神经网络深度的一种方法。虽然它们的训练内存效率高，但训练速度仍然明显慢于显式对应物。在深度平衡模型（DEQs）中，训练是作为一个双层问题进行的，其计算复杂性部分来自于巨大雅可比矩阵的迭代求逆。在本文中，我们提出了一种新策略来解决许多双层问题所面临的这一计算瓶颈。主要思想是利用前向传递中的拟牛顿矩阵来高效近似梯度计算所需方向上的逆雅可比矩阵。我们提供了一个定理，激励将我们的方法与原始前向算法一起使用。此外，通过修改这些前向算法，我们进一步提供了理论保证，证明我们的方法渐近估计了真实的隐式梯度。我们在从超参数优化到应用于CIFAR和ImageNet的大型多尺度DEQs等多种设置中实证研究了这种方法。我们表明，它将反向传递的计算成本降低了多达两个数量级。所有这些都是在保持原始模型在超参数优化和CIFAR上的优异性能的同时实现的，并在ImageNet上给出了令人鼓舞和有竞争力的结果。",
        "领域": "隐式深度学习、深度平衡模型、超参数优化",
        "问题": "解决隐式深度学习模型训练速度慢和计算复杂度高的问题",
        "动机": "提高隐式深度学习模型的训练效率，减少计算资源的消耗",
        "方法": "利用前向传递中的拟牛顿矩阵近似逆雅可比矩阵，以减少反向传递的计算成本",
        "关键词": [
            "隐式深度学习",
            "深度平衡模型",
            "拟牛顿矩阵",
            "雅可比矩阵",
            "计算效率"
        ],
        "涉及的技术概念": {
            "隐式深度学习": "一种通过隐式方法增加网络深度的深度学习技术，旨在提高模型性能而不显式增加网络层数",
            "深度平衡模型（DEQs）": "一种特殊的隐式深度学习模型，通过求解平衡点来定义网络输出，训练过程中涉及双层优化问题",
            "拟牛顿矩阵": "在前向传递中用于近似逆雅可比矩阵的技术，以减少反向传递中的计算复杂度"
        },
        "success": true
    },
    {
        "order": 896,
        "title": "Should I Run Offline Reinforcement Learning or Behavioral Cloning?",
        "html": "https://iclr.cc//virtual/2022/poster/6654",
        "abstract": "Offline reinforcement learning (RL) algorithms can acquire effective policies by utilizing only previously collected experience, without any online interaction.  While it is widely understood that offline RL is able to extract good policies even from highly suboptimal data, in practice offline RL is often used with data that resembles demonstrations. In this case, one can also use behavioral cloning (BC) algorithms, which mimic a subset of the dataset via supervised learning. It seems natural to ask: When should we prefer offline RL over BC? In this paper, our goal is to characterize environments and dataset compositions where offline RL leads to better performance than BC.  In particular, we characterize the properties of environments that allow offline RL methods to perform better than BC methods even when only provided with expert data. Additionally, we show that policies trained on suboptimal data that is sufficiently noisy can attain better performance than even BC algorithms with expert data, especially on long-horizon problems. We validate our theoretical results via extensive experiments on both diagnostic and high-dimensional domains including robot manipulation, maze navigation and Atari games, when learning from a variety of data sources. We observe that modern offline RL methods trained on suboptimal, noisy data in sparse reward domains outperform cloning the expert data in several practical problems.",
        "conference": "ICLR",
        "中文标题": "我应该运行离线强化学习还是行为克隆？",
        "摘要翻译": "离线强化学习（RL）算法仅通过利用先前收集的经验，无需任何在线交互，即可获得有效的策略。虽然人们普遍理解离线RL能够从高度次优的数据中提取出良好的策略，但在实践中，离线RL通常使用类似于演示的数据。在这种情况下，也可以使用行为克隆（BC）算法，它通过监督学习模仿数据集的一个子集。很自然地会问：我们何时应该选择离线RL而不是BC？在本文中，我们的目标是描述环境和数据集组成，其中离线RL比BC表现更好。特别是，我们描述了环境的特性，这些特性允许离线RL方法即使在仅提供专家数据时也能比BC方法表现更好。此外，我们展示了在足够嘈杂的次优数据上训练的策略可以达到比即使是使用专家数据的BC算法更好的性能，尤其是在长视野问题上。我们通过在诊断和高维领域（包括机器人操作、迷宫导航和Atari游戏）上从各种数据源学习时进行的广泛实验验证了我们的理论结果。我们观察到，现代离线RL方法在稀疏奖励领域的次优、嘈杂数据上训练，在几个实际问题中优于克隆专家数据。",
        "领域": "强化学习",
        "问题": "在特定环境和数据集组成下，离线强化学习与行为克隆的性能比较",
        "动机": "明确在何种情况下离线强化学习优于行为克隆，尤其是在处理专家数据和次优数据时",
        "方法": "通过理论分析和在机器人操作、迷宫导航及Atari游戏等多种环境下的实验验证",
        "关键词": [
            "离线强化学习",
            "行为克隆",
            "专家数据",
            "次优数据",
            "长视野问题"
        ],
        "涉及的技术概念": {
            "离线强化学习": "一种仅利用先前收集的经验而不需要在线交互来学习有效策略的方法",
            "行为克隆": "通过监督学习模仿数据集的一个子集来学习策略的方法",
            "专家数据": "由专家生成的、高质量的数据集，用于训练模型"
        },
        "success": true
    },
    {
        "order": 897,
        "title": "Should We Be Pre-training? An Argument for End-task Aware Training as an Alternative",
        "html": "https://iclr.cc//virtual/2022/poster/6249",
        "abstract": "In most settings of practical concern, machine learning practitioners know in advance what end-task they wish to boost with auxiliary tasks. However, widely used methods for leveraging auxiliary data like pre-training and its continued-pretraining variant are end-task agnostic: they rarely, if ever, exploit knowledge of the target task. We study replacing end-task agnostic continued training of pre-trained language models with end-task aware training of said models. We argue that for sufficiently important end-tasks, the benefits of leveraging auxiliary data in a task-aware fashion can justify forgoing the traditional approach of obtaining generic, end-task agnostic representations as with (continued) pre-training. On three different low-resource NLP tasks from two domains, we demonstrate that  multi-tasking the end-task and auxiliary objectives results in significantly better downstream task performance than the widely-used task-agnostic continued pre-training paradigm of Gururangan et al. (2020).We next introduce an online meta-learning algorithm that learns  a set of multi-task weights to better balance among our multiple auxiliary objectives, achieving further improvements on end-task performance and data efficiency.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "我们应该进行预训练吗？关于以端任务感知训练作为替代方案的论证",
        "摘要翻译": "在大多数实际关注的环境中，机器学习从业者事先知道他们希望通过辅助任务提升的端任务。然而，广泛使用的利用辅助数据的方法，如预训练及其持续预训练变体，是端任务无关的：它们很少（如果有的话）利用目标任务的知识。我们研究了用端任务感知训练替代端任务无关的预训练语言模型的持续训练。我们认为，对于足够重要的端任务，以任务感知方式利用辅助数据的好处可以证明放弃传统的获取通用、端任务无关表示的方法（如（持续）预训练）是合理的。在来自两个领域的三个不同的低资源NLP任务上，我们证明了将端任务和辅助目标多任务处理比广泛使用的任务无关持续预训练范式（Gururangan等人，2020年）能显著提高下游任务性能。接下来，我们引入了一种在线元学习算法，该算法学习一组多任务权重以更好地平衡我们的多个辅助目标，从而在端任务性能和数据效率上实现进一步的改进。",
        "领域": "自然语言处理与视觉结合, 低资源NLP, 多任务学习",
        "问题": "如何更有效地利用辅助数据来提升特定端任务的性能，而不是采用通用的预训练方法。",
        "动机": "研究动机是为了探索在已知端任务的情况下，如何通过任务感知的方式利用辅助数据，以提高特定任务的性能和数据效率，而不是依赖于通用的预训练方法。",
        "方法": "采用端任务感知训练替代端任务无关的预训练，通过多任务处理端任务和辅助目标，并引入在线元学习算法优化多任务权重。",
        "关键词": [
            "端任务感知训练",
            "多任务学习",
            "在线元学习",
            "低资源NLP",
            "辅助数据利用"
        ],
        "涉及的技术概念": {
            "端任务感知训练": "在训练过程中明确考虑端任务的需求，以任务感知的方式利用辅助数据，而不是采用通用的预训练方法。",
            "多任务学习": "同时学习端任务和辅助目标，以提高模型的泛化能力和性能。",
            "在线元学习算法": "一种动态调整多任务权重的算法，旨在更好地平衡多个辅助目标，以优化端任务性能和数据效率。"
        }
    },
    {
        "order": 898,
        "title": "Shuffle Private Stochastic Convex Optimization",
        "html": "https://iclr.cc//virtual/2022/poster/6703",
        "abstract": "In shuffle privacy, each user sends a collection of randomized messages to a trusted shuffler, the shuffler randomly permutes these messages, and the resulting shuffled collection of messages must satisfy differential privacy. Prior work in this model has largely focused on protocols that use a single round of communication to compute algorithmic primitives like means, histograms, and counts. In this work, we present interactive shuffle protocols for stochastic convex optimization. Our optimization protocols rely on a new noninteractive protocol for summing vectors of bounded $\\ell_2$ norm. By combining this sum subroutine with techniques including mini-batch stochastic gradient descent, accelerated gradient descent, and Nesterov's smoothing method, we obtain loss guarantees for a variety of convex loss functions that significantly improve on those of the local model and sometimes match those of the central model.",
        "conference": "ICLR",
        "中文标题": "混洗隐私随机凸优化",
        "摘要翻译": "在混洗隐私模型中，每个用户向可信的混洗器发送一组随机化的消息，混洗器对这些消息进行随机排列，最终得到的混洗消息集合必须满足差分隐私。此前在这一模型中的研究主要集中在使用单轮通信计算算法原语（如均值、直方图和计数）的协议上。在本工作中，我们提出了用于随机凸优化的交互式混洗协议。我们的优化协议依赖于一个新的非交互式协议，用于求和有界ℓ2范数的向量。通过将这个求和子程序与包括小批量随机梯度下降、加速梯度下降和Nesterov平滑方法在内的技术相结合，我们为各种凸损失函数获得了损失保证，这些保证显著优于本地模型，有时甚至与中心模型相匹配。",
        "领域": "隐私保护机器学习、随机优化、差分隐私",
        "问题": "在混洗隐私模型下，如何高效地进行随机凸优化",
        "动机": "提升在混洗隐私模型下进行随机凸优化的效率和准确性，以保护用户数据的隐私",
        "方法": "结合非交互式向量求和协议与多种优化技术（如小批量随机梯度下降、加速梯度下降和Nesterov平滑方法）",
        "关键词": [
            "混洗隐私",
            "随机凸优化",
            "差分隐私",
            "交互式协议",
            "向量求和"
        ],
        "涉及的技术概念": {
            "混洗隐私": "一种隐私保护模型，通过混洗用户消息来增强差分隐私保护",
            "随机凸优化": "在随机环境下求解凸优化问题的方法，常用于机器学习中的参数优化",
            "差分隐私": "一种数学上的隐私保护框架，确保数据处理的输出不会泄露个体信息"
        },
        "success": true
    },
    {
        "order": 899,
        "title": "Signing the Supermask: Keep, Hide, Invert",
        "html": "https://iclr.cc//virtual/2022/poster/6550",
        "abstract": "The exponential growth in numbers of parameters of neural networks over the past years has been accompanied by an increase in performance across several fields. However, due to their sheer size, the networks not only became difficult to interpret but also problematic to train and use in real-world applications, since hardware requirements increased accordingly. Tackling both issues, we present a novel approach that either drops a neural network's initial weights or inverts their respective sign. Put simply, a network is trained by weight selection and inversion without changing their absolute values.Our contribution extends previous work on masking by additionally sign-inverting the initial weights and follows the findings of the Lottery Ticket Hypothesis.Through this extension and adaptations of initialization methods, we achieve a pruning rate of up to 99%, while still matching or exceeding the performance of various baseline and previous models.Our approach has two main advantages.First, and most notable, signed Supermask models drastically simplify a model's structure, while still performing well on given tasks.Second, by reducing the neural network to its very foundation, we gain insights into which weights matter for performance. The code is available on GitHub.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "签署超级掩码：保留、隐藏、反转",
        "摘要翻译": "过去几年中，神经网络参数数量的指数级增长伴随着多个领域性能的提升。然而，由于它们庞大的规模，网络不仅变得难以解释，而且在实际应用中训练和使用也变得问题重重，因为硬件需求相应增加。针对这两个问题，我们提出了一种新方法，该方法要么丢弃神经网络的初始权重，要么反转它们各自的符号。简而言之，网络通过权重选择和反转来训练，而不改变它们的绝对值。我们的贡献通过额外对初始权重进行符号反转，扩展了之前关于掩码的工作，并遵循了彩票假设的发现。通过这种扩展和初始化方法的调整，我们实现了高达99%的剪枝率，同时仍然匹配或超过了各种基线和先前模型的性能。我们的方法有两个主要优势。首先，也是最显著的，签署的超级掩码模型极大地简化了模型的结构，同时在给定任务上仍然表现良好。其次，通过将神经网络缩减到其非常基础的部分，我们获得了哪些权重对性能重要的洞察。代码已在GitHub上提供。",
        "领域": "神经网络优化, 模型剪枝, 深度学习效率提升",
        "问题": "解决神经网络因参数数量庞大导致的难以解释、训练和使用困难的问题",
        "动机": "通过简化神经网络结构，同时保持或提升性能，以提高模型的实用性和可解释性",
        "方法": "提出一种通过权重选择和符号反转来训练网络的新方法，不改变权重的绝对值，实现高剪枝率",
        "关键词": [
            "超级掩码",
            "权重反转",
            "模型剪枝",
            "彩票假设",
            "神经网络优化"
        ],
        "涉及的技术概念": {
            "超级掩码": "用于选择性地保留或反转神经网络中的权重，以简化模型结构而不改变权重的绝对值",
            "彩票假设": "该假设认为在随机初始化的神经网络中存在子网络（即“中奖彩票”），这些子网络单独训练时能够达到与原始网络相当的性能",
            "模型剪枝": "通过移除神经网络中不重要的连接或权重来减少模型大小和计算需求，同时尽量保持模型性能的技术"
        }
    },
    {
        "order": 900,
        "title": "Simple GNN Regularisation for 3D Molecular Property Prediction and Beyond",
        "html": "https://iclr.cc//virtual/2022/poster/5968",
        "abstract": "In this paper we show that simple noisy regularisation can be an effective way to address oversmoothing. We first argue that regularisers ad-dressing oversmoothing should both penalise node latent similarity and encourage meaningful node representations. From this observation we derive “Noisy Nodes”,a simple technique in which we corrupt the input graph with noise, and add a noise correcting node-level loss.  The diverse node level loss encourages latent node diversity, and the denoising objective encourages graph manifold learning.  Our regulariser applies well-studied methods in simple, straightforward ways which allow even generic architectures to overcome oversmoothing and achieve state of the art results on quantum chemistry tasks such as QM9 and Open Catalyst, and improve results significantly on Open Graph Benchmark (OGB) datasets.  Our results suggest Noisy Nodes can serve as a complementary building block in the GNN toolkit.",
        "conference": "ICLR",
        "中文标题": "简单图神经网络正则化在3D分子属性预测及其他领域的应用",
        "摘要翻译": "本文展示了简单的噪声正则化可以有效解决过平滑问题。我们首先提出，针对过平滑的正则化方法应同时惩罚节点潜在相似性并鼓励有意义的节点表示。基于这一观察，我们提出了“噪声节点”这一简单技术，即在输入图中引入噪声，并添加一个噪声校正的节点级损失。多样化的节点级损失促进了潜在节点的多样性，而去噪目标则促进了图流形学习。我们的正则化方法以简单直接的方式应用了经过充分研究的方法，使得即使是通用架构也能克服过平滑问题，并在量子化学任务（如QM9和Open Catalyst）上达到最先进的结果，同时在Open Graph Benchmark（OGB）数据集上显著改善结果。我们的结果表明，噪声节点可以作为图神经网络工具包中的一个补充构建块。",
        "领域": "图神经网络、分子属性预测、量子化学",
        "问题": "解决图神经网络中的过平滑问题",
        "动机": "通过噪声正则化方法提升图神经网络在分子属性预测等任务中的性能",
        "方法": "引入噪声到输入图中并添加噪声校正的节点级损失，以促进节点多样性和图流形学习",
        "关键词": [
            "噪声正则化",
            "过平滑",
            "图神经网络",
            "分子属性预测",
            "量子化学"
        ],
        "涉及的技术概念": {
            "噪声节点": "在输入图中引入噪声并添加噪声校正的节点级损失，以解决过平滑问题",
            "过平滑": "图神经网络中节点表示趋向于相似，导致信息丢失的现象",
            "图流形学习": "通过学习图的低维流形结构来提升图表示的质量"
        },
        "success": true
    },
    {
        "order": 901,
        "title": "SimVLM: Simple Visual Language Model Pretraining with Weak Supervision",
        "html": "https://iclr.cc//virtual/2022/poster/6262",
        "abstract": "With recent progress in joint modeling of visual and textual representations, Vision-Language Pretraining (VLP) has achieved impressive performance on many multimodal downstream tasks. However, the requirement for expensive annotations including clean image captions and regional labels limits the scalability of existing approaches, and complicates the pretraining procedure with the introduction of multiple dataset-specific objectives. In this work, we relax these constraints and present a minimalist pretraining framework, named Simple Visual Language Model (SimVLM). Unlike prior work, SimVLM reduces the training complexity by exploiting large-scale weak supervision, and is trained end-to-end with a single prefix language modeling objective. Without utilizing extra data or task-specific customization, the resulting model significantly outperforms previous pretraining methods and achieves new state-of-the-art results on a wide range of discriminative and generative vision-language benchmarks, including VQA (+3.74% vqa-score), NLVR2 (+1.17% accuracy), SNLI-VE (+1.37% accuracy) and image captioning tasks (+10.1% average CIDEr score). Furthermore, we demonstrate that SimVLM acquires strong generalization and transfer ability, enabling zero-shot behavior including open-ended visual question answering and cross-modality transfer.",
        "conference": "ICLR",
        "中文标题": "SimVLM：基于弱监督的简单视觉语言模型预训练",
        "摘要翻译": "随着视觉和文本表示联合建模的最新进展，视觉语言预训练（VLP）在许多多模态下游任务上取得了令人印象深刻的性能。然而，对包括干净图像标题和区域标签在内的昂贵注释的要求限制了现有方法的可扩展性，并通过引入多个数据集特定目标使预训练过程复杂化。在这项工作中，我们放宽了这些限制，并提出了一个极简的预训练框架，名为简单视觉语言模型（SimVLM）。与之前的工作不同，SimVLM通过利用大规模弱监督降低了训练复杂性，并且通过单一前缀语言建模目标进行端到端训练。在不利用额外数据或任务特定定制的情况下，所得模型显著优于先前的预训练方法，并在广泛的判别性和生成性视觉语言基准测试中取得了新的最先进结果，包括VQA（+3.74% vqa-score）、NLVR2（+1.17% 准确率）、SNLI-VE（+1.37% 准确率）和图像字幕任务（+10.1% 平均CIDEr分数）。此外，我们证明了SimVLM具有强大的泛化和迁移能力，能够实现包括开放式视觉问答和跨模态迁移在内的零样本行为。",
        "领域": "视觉语言预训练、多模态学习、零样本学习",
        "问题": "解决视觉语言预训练中对昂贵注释的依赖和训练过程的复杂性",
        "动机": "减少视觉语言预训练中对昂贵注释的依赖，简化训练过程，提高模型的可扩展性和性能",
        "方法": "提出一个极简的预训练框架SimVLM，利用大规模弱监督和单一前缀语言建模目标进行端到端训练",
        "关键词": [
            "视觉语言预训练",
            "弱监督",
            "多模态学习",
            "零样本学习",
            "端到端训练"
        ],
        "涉及的技术概念": {
            "视觉语言预训练（VLP）": "联合建模视觉和文本表示的技术，用于提升多模态任务的性能",
            "弱监督": "利用不完全或噪声较大的数据进行训练，减少对昂贵注释的依赖",
            "前缀语言建模": "一种语言建模方法，通过预测序列中的下一个词来训练模型，此处用于简化训练目标"
        },
        "success": true
    },
    {
        "order": 902,
        "title": "SketchODE: Learning neural sketch representation in continuous time",
        "html": "https://iclr.cc//virtual/2022/poster/6760",
        "abstract": "Learning meaningful representations for chirographic drawing data such as sketches, handwriting, and flowcharts is a gateway for understanding and emulating human creative expression. Despite being inherently continuous-time data, existing works have treated these as discrete-time sequences, disregarding their true nature. In this work, we model such data as continuous-time functions and learn compact representations by virtue of Neural Ordinary Differential Equations. To this end, we introduce the first continuous-time Seq2Seq model and demonstrate some remarkable properties that set it apart from traditional discrete-time analogues. We also provide solutions for some practical challenges for such models, including introducing a family of parameterized ODE dynamics & continuous-time data augmentation particularly suitable for the task. Our models are validated on several datasets including VectorMNIST, DiDi and Quick, Draw!.",
        "conference": "ICLR",
        "中文标题": "SketchODE: 在连续时间中学习神经素描表示",
        "摘要翻译": "学习手写绘图数据（如素描、手写和流程图）的有意义表示是理解和模拟人类创造性表达的途径。尽管这些数据本质上是连续时间的，现有工作却将其视为离散时间序列，忽视了它们的真实性质。在这项工作中，我们将此类数据建模为连续时间函数，并通过神经常微分方程学习紧凑的表示。为此，我们引入了第一个连续时间的Seq2Seq模型，并展示了一些使其与传统离散时间模型区别开来的显著特性。我们还为这类模型的一些实际挑战提供了解决方案，包括引入一系列参数化的ODE动态和特别适合此任务的连续时间数据增强。我们的模型在包括VectorMNIST、DiDi和Quick, Draw!在内的多个数据集上得到了验证。",
        "领域": "手写识别, 连续时间序列建模, 创造性表达模拟",
        "问题": "如何有效地学习和表示连续时间的手写绘图数据",
        "动机": "现有方法忽视了手写绘图数据的连续时间本质，限制了表示学习的深度和准确性",
        "方法": "使用神经常微分方程建模连续时间数据，引入连续时间Seq2Seq模型和参数化ODE动态及数据增强技术",
        "关键词": [
            "神经常微分方程",
            "连续时间建模",
            "Seq2Seq模型",
            "手写识别",
            "数据增强"
        ],
        "涉及的技术概念": {
            "神经常微分方程": "用于建模和学习连续时间数据的紧凑表示",
            "连续时间Seq2Seq模型": "第一个能够处理连续时间序列的Seq2Seq模型，区别于传统离散时间模型",
            "参数化ODE动态": "为模型提供了一系列可调整的动态行为，增强了模型的适应性和表现力"
        },
        "success": true
    },
    {
        "order": 903,
        "title": "Skill-based Meta-Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6702",
        "abstract": "While deep reinforcement learning methods have shown impressive results in robot learning, their sample inefficiency makes the learning of complex, long-horizon behaviors with real robot systems infeasible. To mitigate this issue, meta-reinforcement learning methods aim to enable fast learning on novel tasks by learning how to learn. Yet, the application has been limited to short-horizon tasks with dense rewards. To enable learning long-horizon behaviors, recent works have explored leveraging prior experience in the form of offline datasets without reward or task annotations. While these approaches yield improved sample efficiency, millions of interactions with environments are still required to solve complex tasks. In this work, we devise a method that enables meta-learning on long-horizon, sparse-reward tasks, allowing us to solve unseen target tasks with orders of magnitude fewer environment interactions. Our core idea is to leverage prior experience extracted from offline datasets during meta-learning. Specifically, we propose to (1) extract reusable skills and a skill prior from offline datasets, (2) meta-train a high-level policy that learns to efficiently compose learned skills into long-horizon behaviors, and (3) rapidly adapt the meta-trained policy to solve an unseen target task. Experimental results on continuous control tasks in navigation and manipulation demonstrate that the proposed method can efficiently solve long-horizon novel target tasks by combining the strengths of meta-learning and the usage of offline datasets, while prior approaches in RL, meta-RL, and multi-task RL require substantially more environment interactions to solve the tasks.",
        "conference": "ICLR",
        "中文标题": "基于技能的元强化学习",
        "摘要翻译": "尽管深度强化学习方法在机器人学习方面已显示出令人印象深刻的结果，但其样本效率低下使得在真实机器人系统上学习复杂、长视野行为变得不可行。为了缓解这一问题，元强化学习方法旨在通过学习如何学习来实现对新任务的快速学习。然而，其应用仅限于具有密集奖励的短视野任务。为了实现长视野行为的学习，最近的研究探索了利用离线数据集形式的先前经验，这些数据集没有奖励或任务注释。虽然这些方法提高了样本效率，但解决复杂任务仍需要与环境进行数百万次交互。在这项工作中，我们设计了一种方法，能够在长视野、稀疏奖励任务上进行元学习，使我们能够以数量级更少的环境交互解决未见过的目标任务。我们的核心思想是在元学习过程中利用从离线数据集中提取的先前经验。具体来说，我们提出（1）从离线数据集中提取可重用技能和技能先验，（2）元训练一个高级策略，该策略学习如何有效地将学习到的技能组合成长视野行为，以及（3）快速适应元训练策略以解决未见过的目标任务。在导航和操作的连续控制任务上的实验结果表明，所提出的方法能够通过结合元学习和离线数据集使用的优势，高效解决长视野新目标任务，而先前的强化学习、元强化学习和多任务强化学习方法需要更多的环境交互来解决任务。",
        "领域": "机器人学习、元强化学习、连续控制",
        "问题": "解决在长视野、稀疏奖励任务上样本效率低下的问题",
        "动机": "提高机器人学习复杂、长视野行为的效率，减少所需的环境交互次数",
        "方法": "从离线数据集中提取技能和技能先验，元训练高级策略以组合技能，快速适应新任务",
        "关键词": [
            "元强化学习",
            "技能提取",
            "长视野任务",
            "稀疏奖励",
            "离线数据集"
        ],
        "涉及的技术概念": {
            "元强化学习": "通过学习如何学习来加速新任务的适应过程",
            "技能提取": "从离线数据集中识别和提取可重用的行为模式",
            "技能先验": "利用先前经验指导新任务的学习和策略适应"
        },
        "success": true
    },
    {
        "order": 904,
        "title": "Solving Inverse Problems in Medical Imaging with Score-Based Generative Models",
        "html": "https://iclr.cc//virtual/2022/poster/7035",
        "abstract": "Reconstructing medical images from partial measurements is an important inverse problem in Computed Tomography (CT) and Magnetic Resonance Imaging (MRI). Existing solutions based on machine learning typically train a model to directly map measurements to medical images, leveraging a training dataset of paired images and measurements. These measurements are typically synthesized from images using a fixed physical model of the measurement process, which hinders the generalization capability of models to unknown measurement processes. To address this issue, we propose a fully unsupervised technique for inverse problem solving, leveraging the recently introduced score-based generative models. Specifically, we first train a score-based generative model on medical images to capture their prior distribution. Given measurements and a physical model of the measurement process at test time, we introduce a sampling method to reconstruct an image consistent with both the prior and the observed measurements. Our method does not assume a fixed measurement process during training, and can thus be flexibly adapted to different measurement processes at test time. Empirically, we observe comparable or better performance to supervised learning techniques in several medical imaging tasks in CT and MRI, while demonstrating significantly better generalization to unknown measurement processes.",
        "conference": "ICLR",
        "中文标题": "利用基于分数的生成模型解决医学成像中的逆问题",
        "摘要翻译": "从部分测量数据重建医学图像是计算机断层扫描(CT)和磁共振成像(MRI)中的一个重要逆问题。现有的基于机器学习的解决方案通常训练一个模型直接从测量数据映射到医学图像，利用成对的图像和测量数据的训练数据集。这些测量数据通常使用测量过程的固定物理模型从图像合成，这限制了模型对未知测量过程的泛化能力。为了解决这个问题，我们提出了一种完全无监督的逆问题解决技术，利用了最近引入的基于分数的生成模型。具体来说，我们首先在医学图像上训练一个基于分数的生成模型，以捕捉它们的先验分布。在测试时，给定测量数据和测量过程的物理模型，我们引入了一种采样方法来重建与先验和观察到的测量数据一致的图像。我们的方法在训练时不假设固定的测量过程，因此可以在测试时灵活适应不同的测量过程。实证上，我们在CT和MRI的几个医学成像任务中观察到与监督学习技术相当或更好的性能，同时显示出对未知测量过程显著更好的泛化能力。",
        "领域": "医学图像重建、计算机断层扫描、磁共振成像",
        "问题": "如何从部分测量数据重建医学图像，并提高模型对未知测量过程的泛化能力",
        "动机": "现有方法依赖于固定的测量过程模型，限制了模型对未知测量过程的适应性和泛化能力",
        "方法": "利用基于分数的生成模型捕捉医学图像的先验分布，提出一种无监督的采样方法，在测试时灵活适应不同的测量过程",
        "关键词": [
            "医学图像重建",
            "基于分数的生成模型",
            "无监督学习",
            "计算机断层扫描",
            "磁共振成像"
        ],
        "涉及的技术概念": {
            "基于分数的生成模型": "用于捕捉医学图像的先验分布，为重建提供统计基础",
            "无监督学习": "不依赖于成对的训练数据，提高模型对未知测量过程的适应能力",
            "采样方法": "在测试时根据测量数据和物理模型重建图像，确保与先验和测量数据的一致性"
        },
        "success": true
    },
    {
        "order": 905,
        "title": "SOSP: Efficiently Capturing Global Correlations by Second-Order Structured Pruning",
        "html": "https://iclr.cc//virtual/2022/poster/7189",
        "abstract": "Pruning neural networks reduces inference time and memory costs. On standard hardware, these benefits will be especially prominent if coarse-grained structures, like feature maps, are pruned. We devise two novel saliency-based methods for second-order structured pruning (SOSP) which include correlations among all structures and layers. Our main method SOSP-H employs an innovative second-order approximation, which enables saliency evaluations by fast Hessian-vector products. SOSP-H thereby scales like a first-order method despite taking into account the full Hessian. We validate SOSP-H by comparing it to our second method SOSP-I that uses a well-established Hessian approximation, and to numerous state-of-the-art methods. While SOSP-H performs on par or better in terms of accuracy, it has clear advantages in terms of scalability and efficiency. This allowed us to scale SOSP-H to large-scale vision tasks, even though it captures correlations across all layers of the network. To underscore the global nature of our pruning methods, we evaluate their performance not only by removing structures from a pretrained network, but also by detecting architectural bottlenecks. We show that our algorithms allow to systematically reveal architectural bottlenecks, which we then remove to further increase the accuracy of the networks.",
        "conference": "ICLR",
        "中文标题": "SOSP：通过二阶结构化剪枝高效捕捉全局相关性",
        "摘要翻译": "剪枝神经网络可以减少推理时间和内存成本。在标准硬件上，如果剪枝粗粒度结构（如特征图），这些好处将尤为明显。我们设计了两种基于显著性的新颖方法，用于二阶结构化剪枝（SOSP），这些方法包括所有结构和层之间的相关性。我们的主要方法SOSP-H采用了一种创新的二阶近似，这使得通过快速的海森-向量积进行显著性评估成为可能。尽管考虑了完整的海森矩阵，SOSP-H的扩展性却像一阶方法一样。我们通过将SOSP-H与我们的第二种方法SOSP-I（使用了一种成熟的海森近似）以及众多最先进的方法进行比较来验证SOSP-H。虽然SOSP-H在准确性方面表现相当或更好，但它在可扩展性和效率方面具有明显优势。这使得我们能够将SOSP-H扩展到大规模视觉任务，即使它捕捉了网络所有层之间的相关性。为了强调我们剪枝方法的全局性质，我们不仅通过从预训练网络中移除结构来评估它们的性能，还通过检测架构瓶颈来评估。我们展示了我们的算法可以系统地揭示架构瓶颈，然后我们移除这些瓶颈以进一步提高网络的准确性。",
        "领域": "神经网络剪枝",
        "问题": "如何在减少神经网络推理时间和内存成本的同时，保持或提高模型的准确性",
        "动机": "探索一种能够高效捕捉神经网络中全局相关性并实现结构化剪枝的方法，以优化模型性能和资源使用",
        "方法": "设计了两种基于显著性的二阶结构化剪枝方法，其中SOSP-H采用创新的二阶近似技术，通过快速海森-向量积进行显著性评估，实现了高效和可扩展的剪枝",
        "关键词": [
            "神经网络剪枝",
            "二阶结构化剪枝",
            "海森近似",
            "显著性评估",
            "架构瓶颈检测"
        ],
        "涉及的技术概念": {
            "二阶结构化剪枝": "一种剪枝方法，考虑了神经网络中所有结构和层之间的相关性，以实现更高效的模型压缩",
            "海森-向量积": "用于快速评估神经网络中参数显著性的技术，支持高效的二阶近似计算",
            "架构瓶颈检测": "通过分析网络结构和性能，识别并移除限制模型性能的关键瓶颈，以进一步提高模型准确性"
        },
        "success": true
    },
    {
        "order": 906,
        "title": "Sound Adversarial Audio-Visual Navigation",
        "html": "https://iclr.cc//virtual/2022/poster/6057",
        "abstract": "Audio-visual navigation task requires an agent to find a sound source in a realistic, unmapped 3D environment by utilizing egocentric audio-visual observations. Existing audio-visual navigation works assume a clean environment that solely contains the target sound, which, however, would not be suitable in most real-world applications due to the unexpected sound noise or intentional interference. In this work, we design an acoustically complex environment in which, besides the target sound, there exists a sound attacker playing a zero-sum game with the agent. More specifically, the attacker can move and change the volume and category of the sound to make the agent suffer from finding the sounding object while the agent tries to dodge the attack and navigate to the goal under the intervention. Under certain constraints to the attacker, we can improve the robustness of the agent towards unexpected sound attacks in audio-visual navigation. For better convergence, we develop a joint training mechanism by employing the property of a centralized critic with decentralized actors. Experiments on two real-world 3D scan datasets, Replica, and Matterport3D, verify the effectiveness and the robustness of the agent trained under our designed environment when transferred to the clean environment or the one containing sound attackers with random policy. Project: https://yyf17.github.io/SAAVN .",
        "conference": "ICLR",
        "中文标题": "声音对抗的视听导航",
        "摘要翻译": "视听导航任务要求代理通过利用自我中心的视听观察，在现实的、未映射的3D环境中找到声源。现有的视听导航工作假设环境仅包含目标声音，这在大多数现实应用中并不适用，因为存在意外的声音噪声或故意干扰。在这项工作中，我们设计了一个声学复杂的环境，其中除了目标声音外，还存在一个与代理进行零和游戏的声音攻击者。具体来说，攻击者可以移动并改变声音的音量和类别，使代理在寻找发声物体时遭受困难，而代理则试图躲避攻击并在干预下导航到目标。通过对攻击者的某些约束，我们可以提高代理在视听导航中对意外声音攻击的鲁棒性。为了更好地收敛，我们通过利用集中式评论家与分散式演员的属性，开发了一种联合训练机制。在Replica和Matterport3D两个真实世界的3D扫描数据集上的实验验证了在我们设计的环境下训练的代理在转移到干净环境或包含随机策略声音攻击者的环境时的有效性和鲁棒性。项目：https://yyf17.github.io/SAAVN。",
        "领域": "视听导航",
        "问题": "在存在声音噪声或故意干扰的复杂环境中，如何有效地进行视听导航。",
        "动机": "提高代理在复杂声学环境中对意外声音攻击的鲁棒性，以应对现实世界中的视听导航挑战。",
        "方法": "设计了一个包含声音攻击者的声学复杂环境，并开发了一种联合训练机制，通过集中式评论家与分散式演员的属性来提高代理的鲁棒性。",
        "关键词": [
            "视听导航",
            "声音对抗",
            "鲁棒性训练"
        ],
        "涉及的技术概念": {
            "零和游戏": "在设计中，声音攻击者与代理进行零和游戏，攻击者试图干扰代理的导航任务，而代理则尝试完成任务。",
            "集中式评论家与分散式演员": "用于联合训练机制，集中式评论家评估全局状态，分散式演员执行局部决策，以提高训练效率和代理性能。",
            "声学复杂环境": "模拟现实世界中的声音干扰，包括目标声音和攻击者声音，用于训练和测试代理的鲁棒性。"
        },
        "success": true
    },
    {
        "order": 907,
        "title": "Sound and Complete Neural Network Repair with Minimality and Locality Guarantees",
        "html": "https://iclr.cc//virtual/2022/poster/6686",
        "abstract": "We present a novel methodology for repairing neural networks that use ReLU activation functions. Unlike existing methods that rely on modifying the weights of a neural network which can induce a global change in the function space, our approach applies only a localized change in the function space while still guaranteeing the removal of the buggy behavior. By leveraging the piecewise linear nature of ReLU networks, our approach can efficiently construct a patch network tailored to the linear region where the buggy input resides, which when combined with the original network, provably corrects the behavior on the buggy input. Our method is both sound and complete -- the repaired network is guaranteed to fix the buggy input, and a patch is guaranteed to be found for any buggy input. Moreover, our approach preserves the continuous piecewise linear nature of ReLU networks, automatically generalizes the repair to all the points including other undetected buggy inputs inside the repair region, is minimal in terms of changes in the function space, and guarantees that outputs on inputs away from the repair region are unaltered. On several benchmarks, we show that our approach significantly outperforms existing methods in terms of locality and limiting negative side effects.",
        "conference": "ICLR",
        "中文标题": "具有最小化和局部性保证的声音与完整神经网络修复",
        "摘要翻译": "我们提出了一种新颖的方法论，用于修复使用ReLU激活函数的神经网络。与现有方法依赖于修改神经网络的权重（这可能在函数空间中引起全局变化）不同，我们的方法仅在函数空间中应用局部变化，同时仍保证消除错误行为。通过利用ReLU网络的分段线性特性，我们的方法可以高效地构建一个针对错误输入所在的线性区域量身定制的补丁网络，当与原始网络结合时，可证明纠正错误输入上的行为。我们的方法既声音又完整——修复后的网络保证修复错误输入，并且保证为任何错误输入找到补丁。此外，我们的方法保留了ReLU网络的连续分段线性特性，自动将修复推广到包括修复区域内其他未检测到的错误输入在内的所有点，在函数空间的变化方面是最小的，并保证远离修复区域的输入输出不变。在几个基准测试上，我们展示了我们的方法在局部性和限制负面副作用方面显著优于现有方法。",
        "领域": "神经网络修复",
        "问题": "修复神经网络中的错误行为而不引起全局变化",
        "动机": "现有神经网络修复方法可能导致全局函数空间的变化，需要一种能够局部修复错误同时保证修复效果的方法",
        "方法": "利用ReLU网络的分段线性特性，构建针对错误输入所在线性区域的补丁网络，与原始网络结合以纠正错误行为",
        "关键词": [
            "神经网络修复",
            "ReLU激活函数",
            "局部修复",
            "分段线性",
            "补丁网络"
        ],
        "涉及的技术概念": {
            "ReLU激活函数": "论文中使用的激活函数，其分段线性特性被用来高效构建补丁网络",
            "局部修复": "论文中提出的修复方法，仅在错误输入所在的局部区域进行修改，避免全局变化",
            "补丁网络": "论文中构建的专门针对错误输入所在线性区域的网络，与原始网络结合以纠正错误行为"
        },
        "success": true
    },
    {
        "order": 908,
        "title": "Source-Free Adaptation to Measurement Shift via Bottom-Up Feature Restoration",
        "html": "https://iclr.cc//virtual/2022/poster/6285",
        "abstract": "Source-free domain adaptation (SFDA) aims to adapt a model trained on labelled data in a source domain to unlabelled data in a target domain without access to the source-domain data during adaptation. Existing methods for SFDA leverage entropy-minimization techniques which: (i) apply only to classification; (ii) destroy model calibration; and (iii) rely on the source model achieving a good level of feature-space class-separation in the target domain. We address these issues for a particularly pervasive type of domain shift called measurement shift which can be resolved by restoring the source features rather than extracting new ones. In particular, we propose Feature Restoration (FR) wherein we: (i) store a lightweight and flexible approximation of the feature distribution under the source data; and (ii) adapt the feature-extractor such that the approximate feature distribution under the target data realigns with that saved on the source. We additionally propose a bottom-up training scheme which boosts performance, which we call Bottom-Up Feature Restoration (BUFR). On real and synthetic data, we demonstrate that BUFR outperforms existing SFDA methods in terms of accuracy, calibration, and data efficiency, while being less reliant on the performance of the source model in the target domain.",
        "conference": "ICLR",
        "中文标题": "通过自底向上特征恢复实现无源测量偏移适应",
        "摘要翻译": "无源域适应（SFDA）旨在将源域中标记数据训练的模型适应到目标域中的未标记数据，且在适应过程中不访问源域数据。现有的SFDA方法利用熵最小化技术，这些技术：（i）仅适用于分类；（ii）破坏模型校准；（iii）依赖于源模型在目标域中实现良好的特征空间类分离。我们针对一种特别普遍的域偏移类型——测量偏移，解决了这些问题，这种偏移可以通过恢复源特征而非提取新特征来解决。特别是，我们提出了特征恢复（FR），其中我们：（i）存储源数据下特征分布的轻量级和灵活近似；（ii）调整特征提取器，使得目标数据下的近似特征分布与源数据上保存的对齐。我们还提出了一种自底向上的训练方案，称为自底向上特征恢复（BUFR），以提高性能。在真实和合成数据上，我们证明了BUFR在准确性、校准和数据效率方面优于现有的SFDA方法，同时对源模型在目标域中的性能依赖较少。",
        "领域": "无源域适应",
        "问题": "解决在无源域适应过程中，现有熵最小化技术仅适用于分类、破坏模型校准及依赖源模型在目标域中实现良好特征空间类分离的问题",
        "动机": "针对测量偏移这一普遍存在的域偏移类型，通过恢复源特征而非提取新特征来解决问题",
        "方法": "提出特征恢复（FR）方法存储源数据特征分布的近似，并调整特征提取器使目标数据特征分布与源数据对齐；进一步提出自底向上特征恢复（BUFR）训练方案提升性能",
        "关键词": [
            "无源域适应",
            "特征恢复",
            "测量偏移"
        ],
        "涉及的技术概念": {
            "无源域适应（SFDA）": "在适应过程中不访问源域数据，将源域中标记数据训练的模型适应到目标域中的未标记数据",
            "特征恢复（FR）": "通过存储源数据特征分布的近似并调整特征提取器，使目标数据特征分布与源数据对齐",
            "自底向上特征恢复（BUFR）": "一种训练方案，通过自底向上的方式提升特征恢复的性能"
        },
        "success": true
    },
    {
        "order": 909,
        "title": "Space-Time Graph Neural Networks",
        "html": "https://iclr.cc//virtual/2022/poster/6716",
        "abstract": "We introduce space-time graph neural network (ST-GNN), a novel GNN architecture, tailored to jointly process the underlying space-time topology of time-varying network data. The cornerstone of our proposed architecture is the composition of time and graph convolutional filters followed by pointwise nonlinear activation functions. We introduce a generic definition of convolution operators that mimic the diffusion process of signals over its underlying support. On top of this definition, we propose space-time graph convolutions that are built upon a composition of time and graph shift operators.  We prove that ST-GNNs with multivariate integral Lipschitz filters are stable to small perturbations in the underlying graphs as well as small perturbations in the time domain caused by time warping. Our analysis shows that small variations in the network topology and time evolution of a system does not significantly affect the performance of ST-GNNs. Numerical experiments with decentralized control systems showcase the effectiveness and stability of the proposed ST-GNNs.",
        "conference": "ICLR",
        "中文标题": "时空图神经网络",
        "摘要翻译": "我们介绍了时空图神经网络（ST-GNN），这是一种新颖的GNN架构，专门设计用于联合处理时变网络数据的底层时空拓扑结构。我们提出的架构的核心是时间和图卷积滤波器的组合，随后是点式非线性激活函数。我们引入了一个通用的卷积算子定义，该定义模拟了信号在其底层支持上的扩散过程。基于这一定义，我们提出了建立在时间和图移位算子组合基础上的时空图卷积。我们证明了具有多元积分Lipschitz滤波器的ST-GNN对底层图中的小扰动以及由时间扭曲引起的时间域中的小扰动是稳定的。我们的分析表明，网络拓扑和系统时间演化的小变化不会显著影响ST-GNN的性能。分散控制系统的数值实验展示了所提出的ST-GNN的有效性和稳定性。",
        "领域": "图神经网络、时变网络分析、分散控制系统",
        "问题": "如何有效地联合处理时变网络数据的时空拓扑结构",
        "动机": "为了开发一种能够稳定处理时变网络数据时空特性的图神经网络架构",
        "方法": "提出了一种结合时间和图卷积滤波器的时空图神经网络架构，并引入了模拟信号扩散过程的通用卷积算子定义",
        "关键词": [
            "时空图神经网络",
            "时变网络",
            "图卷积",
            "稳定性分析",
            "分散控制"
        ],
        "涉及的技术概念": {
            "时空图卷积": "建立在时间和图移位算子组合基础上的卷积操作，用于处理时变网络数据的时空特性",
            "积分Lipschitz滤波器": "用于确保ST-GNN对底层图和时间域中的小扰动具有稳定性",
            "点式非线性激活函数": "在时间和图卷积滤波器之后应用，以引入非线性，增强模型的表达能力"
        },
        "success": true
    },
    {
        "order": 910,
        "title": "Spanning Tree-based Graph Generation for Molecules",
        "html": "https://iclr.cc//virtual/2022/poster/6001",
        "abstract": "In this paper, we explore the problem of generating molecules using deep neural networks, which has recently gained much interest in chemistry. To this end, we propose a spanning tree-based graph generation (STGG) framework based on formulating molecular graph generation as a construction of a spanning tree and the residual edges. Such a formulation exploits the sparsity of molecular graphs and allows using compact tree-constructive operations to define the molecular graph connectivity. Based on the intermediate graph structure of the construction process, our framework can constrain its generation to molecular graphs that satisfy the chemical valence rules. We also newly design a Transformer architecture with tree-based relative positional encodings for realizing the tree construction procedure. Experiments on QM9, ZINC250k, and MOSES benchmarks verify the effectiveness of the proposed framework in metrics such as validity, Frechet ChemNet distance, and fragment similarity. We also demonstrate the usefulness of STGG in maximizing penalized LogP value of molecules.",
        "conference": "ICLR",
        "中文标题": "基于生成树的分子图生成方法",
        "摘要翻译": "本文探讨了利用深度神经网络生成分子的问题，这一问题近来在化学领域引起了广泛关注。为此，我们提出了一种基于生成树的图生成（STGG）框架，该框架通过将分子图生成问题转化为生成树和剩余边的构建问题。这种表述利用了分子图的稀疏性，并允许使用紧凑的树构建操作来定义分子图的连接性。基于构建过程的中间图结构，我们的框架可以限制其生成满足化学价规则的分子图。我们还新设计了一种带有基于树的相对位置编码的Transformer架构，用于实现树的构建过程。在QM9、ZINC250k和MOSES基准测试上的实验验证了所提出框架在有效性、Frechet ChemNet距离和片段相似性等指标上的有效性。我们还展示了STGG在最大化分子的惩罚LogP值方面的实用性。",
        "领域": "分子图生成、化学信息学、深度学习在化学中的应用",
        "问题": "如何有效地生成满足化学价规则的分子图",
        "动机": "探索利用深度神经网络生成分子的方法，以解决化学领域中对高效分子生成工具的需求",
        "方法": "提出了一种基于生成树的图生成框架，利用分子图的稀疏性和紧凑的树构建操作，结合新设计的Transformer架构进行分子图生成",
        "关键词": [
            "分子图生成",
            "生成树",
            "Transformer架构",
            "化学价规则",
            "深度神经网络"
        ],
        "涉及的技术概念": {
            "生成树": "用于定义分子图连接性的基本结构，利用了分子图的稀疏性",
            "Transformer架构": "新设计的架构，带有基于树的相对位置编码，用于实现树的构建过程",
            "化学价规则": "分子生成过程中必须满足的规则，确保生成的分子在化学上是有效的"
        },
        "success": true
    },
    {
        "order": 911,
        "title": "Sparse Attention with Learning to Hash",
        "html": "https://iclr.cc//virtual/2022/poster/5999",
        "abstract": "Transformer has become ubiquitous in sequence modeling tasks. As a key component of Transformer, self-attention does not scale to long sequences due to its quadratic time and space complexity with respect to the sequence length. To tackle this problem, recent work developed dynamic attention sparsification techniques based on Approximate Nearest Neighbor (ANN) methods, where similar queries and keys are allocated to the same hash bucket with high probability. However, the effectiveness of those ANN methods relies on the assumption that queries and keys should lie in the same space, which is not well justified. Besides, some of the ANN methods such as Locality-Sensitive Hashing (LSH) are randomized and cannot fully utilize the available real data distributions. To overcome these issues, this paper proposes a new strategy for sparse attention, namely LHA (Learning-to-Hash Attention), which directly learns separate parameterized hash functions for queries and keys, respectively. Another advantage of LHA is that it does not impose extra constraints for queries and keys, which makes it applicable to the wide range of pre-trained Transformer models. Our experiments on evaluation of the WikiText-103 dataset for language modeling, the GLUE benchmark for natural language understanding, and the Lang-Range-Arena benchmark for multiple tasks (text/image classification, retrieval, etc.) show the superior performance of LHA over other strong Transformer variants.",
        "conference": "ICLR",
        "中文标题": "稀疏注意力与学习哈希",
        "摘要翻译": "Transformer在序列建模任务中已经无处不在。作为Transformer的关键组成部分，自注意力机制由于其相对于序列长度的二次时间和空间复杂度，无法扩展到长序列。为了解决这个问题，最近的工作基于近似最近邻（ANN）方法开发了动态注意力稀疏化技术，其中相似的查询和键被高概率分配到同一个哈希桶中。然而，这些ANN方法的有效性依赖于查询和键应该位于同一空间的假设，这一假设并不总是成立。此外，一些ANN方法如局部敏感哈希（LSH）是随机的，不能充分利用可用的真实数据分布。为了克服这些问题，本文提出了一种新的稀疏注意力策略，即LHA（学习哈希注意力），它直接为查询和键分别学习参数化的哈希函数。LHA的另一个优点是它不对查询和键施加额外的约束，这使得它适用于广泛的预训练Transformer模型。我们在WikiText-103数据集上的语言建模评估、GLUE基准测试上的自然语言理解以及Lang-Range-Arena基准测试上的多任务（文本/图像分类、检索等）评估中的实验表明，LHA优于其他强大的Transformer变体。",
        "领域": "自然语言处理与视觉结合",
        "问题": "解决Transformer在处理长序列时自注意力机制的二次复杂度问题",
        "动机": "现有的基于近似最近邻的动态注意力稀疏化技术假设查询和键位于同一空间，且部分方法无法充分利用真实数据分布",
        "方法": "提出学习哈希注意力（LHA），直接为查询和键分别学习参数化的哈希函数，不施加额外约束",
        "关键词": [
            "稀疏注意力",
            "学习哈希",
            "Transformer",
            "自然语言处理",
            "长序列建模"
        ],
        "涉及的技术概念": {
            "稀疏注意力": "通过减少注意力计算中的参与元素数量来降低计算复杂度",
            "学习哈希": "通过学习参数化的哈希函数来优化查询和键的分配，提高效率",
            "Transformer": "一种基于自注意力机制的序列建模架构，广泛应用于自然语言处理等领域"
        },
        "success": true
    },
    {
        "order": 912,
        "title": "Sparse Communication via Mixed Distributions",
        "html": "https://iclr.cc//virtual/2022/poster/5895",
        "abstract": "Neural networks and other machine learning models compute continuous representations, while humans communicate mostly through discrete symbols. Reconciling these two forms of communication is desirable for generating human-readable interpretations or learning discrete latent variable models, while maintaining end-to-end differentiability. Some existing approaches (such as the Gumbel-Softmax transformation) build continuous relaxations that are discrete approximations in the zero-temperature limit, while others (such as sparsemax transformations and the Hard Concrete distribution) produce discrete/continuous hybrids. In this paper, we build rigorous theoretical foundations for these hybrids, which we call 'mixed random variables.'' Our starting point is a new 'direct sum'' base measure defined on the face lattice of the probability simplex. From this measure, we introduce new entropy and Kullback-Leibler divergence functions that subsume the discrete and differential cases and have interpretations in terms of code optimality. Our framework suggests two strategies for representing and sampling mixed random variables, an extrinsic ('sample-and-project'’) and an intrinsic one (based on face stratification). We experiment with both approaches on an  emergent communication benchmark and on modeling MNIST and Fashion-MNIST data with variational auto-encoders with mixed latent variables.",
        "conference": "ICLR",
        "中文标题": "通过混合分布实现稀疏通信",
        "摘要翻译": "神经网络和其他机器学习模型计算连续表示，而人类主要通过离散符号进行通信。为了生成人类可读的解释或学习离散潜在变量模型，同时保持端到端的可微性，调和这两种通信形式是可取的。一些现有方法（如Gumbel-Softmax变换）构建了在零温度极限下为离散近似的连续松弛，而其他方法（如sparsemax变换和Hard Concrete分布）则产生离散/连续混合体。在本文中，我们为这些混合体建立了严格的理论基础，我们称之为‘混合随机变量’。我们的出发点是在概率单纯形的面格上定义的一个新的‘直接和’基测度。从这个测度出发，我们引入了新的熵和Kullback-Leibler散度函数，这些函数包含了离散和微分情况，并在代码最优性方面有解释。我们的框架提出了两种表示和采样混合随机变量的策略，一种是外在的（‘采样和投影’），另一种是内在的（基于面分层）。我们在一个新兴的通信基准上以及通过使用具有混合潜在变量的变分自编码器对MNIST和Fashion-MNIST数据进行建模的实验中对这两种方法进行了实验。",
        "领域": "自然语言处理与视觉结合, 变分自编码器, 离散潜在变量模型",
        "问题": "调和神经网络连续表示与人类离散符号通信之间的矛盾",
        "动机": "为了生成人类可读的解释或学习离散潜在变量模型，同时保持端到端的可微性",
        "方法": "引入新的熵和Kullback-Leibler散度函数，提出两种表示和采样混合随机变量的策略",
        "关键词": [
            "混合随机变量",
            "稀疏通信",
            "变分自编码器",
            "离散潜在变量",
            "Gumbel-Softmax"
        ],
        "涉及的技术概念": {
            "混合随机变量": "在本文中定义为离散和连续混合体，为调和连续表示与离散符号通信提供理论基础",
            "熵和Kullback-Leibler散度": "新引入的函数，用于处理混合随机变量，包含离散和微分情况，并在代码最优性方面有解释",
            "变分自编码器": "用于建模MNIST和Fashion-MNIST数据的工具，具有混合潜在变量"
        },
        "success": true
    },
    {
        "order": 913,
        "title": "Sparse DETR: Efficient End-to-End Object Detection with Learnable Sparsity",
        "html": "https://iclr.cc//virtual/2022/poster/7017",
        "abstract": "DETR is the first end-to-end object detector using a transformer encoder-decoder architecture and demonstrates competitive performance but low computational efficiency. The subsequent work, Deformable DETR, enhances the efficiency of DETR by replacing dense attention with deformable attention, which achieves 10x faster convergence and improved performance. Using the multiscale feature to ameliorate performance, however, the number of encoder queries increases by 20x compared to DETR, and the computation cost of the encoder attention remains a bottleneck. We observe that the encoder queries referenced by the decoder account for only 45% of the total, and find out the detection accuracy does not deteriorate significantly even if only the referenced queries are polished in the encoder block. Inspired by this observation, we propose Sparse DETR that selectively updates only the queries expected to be referenced by the decoder, thus help the model effectively detect objects. In addition, we show that applying an auxiliary detection loss on the selected queries in the encoder improves the performance while minimizing computational overhead. We validate that Sparse DETR achieves better performance than Deformable DETR even with only 10% encoder queries on the COCO dataset. Albeit only the encoder queries are sparsified, the total computation cost decreases by 38% and the frames per second (FPS) increases by 42% compared to Deformable DETR. Code will be released.",
        "conference": "ICLR",
        "中文标题": "稀疏DETR：通过可学习稀疏性实现高效的端到端目标检测",
        "摘要翻译": "DETR是首个使用Transformer编码器-解码器架构的端到端目标检测器，展示了竞争性的性能但计算效率较低。随后的工作Deformable DETR通过用可变形注意力替换密集注意力，提高了DETR的效率，实现了10倍的更快收敛和性能提升。然而，使用多尺度特征来改善性能时，编码器查询的数量比DETR增加了20倍，编码器注意力的计算成本仍然是瓶颈。我们观察到解码器引用的编码器查询仅占总数的45%，并且发现即使仅在编码器块中优化被引用的查询，检测精度也不会显著下降。受此观察启发，我们提出了Sparse DETR，它选择性地仅更新预计会被解码器引用的查询，从而帮助模型有效检测对象。此外，我们展示了在编码器中对选定的查询应用辅助检测损失可以在最小化计算开销的同时提高性能。我们验证了Sparse DETR在COCO数据集上即使仅使用10%的编码器查询也能实现比Deformable DETR更好的性能。尽管仅稀疏化了编码器查询，与Deformable DETR相比，总计算成本减少了38%，每秒帧数（FPS）增加了42%。代码将被发布。",
        "领域": "目标检测",
        "问题": "提高端到端目标检测器的计算效率",
        "动机": "减少不必要的编码器查询更新，以降低计算成本同时保持或提高检测性能",
        "方法": "选择性更新预计会被解码器引用的编码器查询，并在这些查询上应用辅助检测损失",
        "关键词": [
            "稀疏DETR",
            "可学习稀疏性",
            "端到端目标检测",
            "Transformer",
            "计算效率"
        ],
        "涉及的技术概念": {
            "可变形注意力": "用于替换密集注意力，提高模型效率和收敛速度",
            "编码器查询稀疏化": "选择性更新编码器查询，减少计算成本",
            "辅助检测损失": "在选定的编码器查询上应用，以提高性能同时最小化计算开销"
        },
        "success": true
    },
    {
        "order": 914,
        "title": "Sparsity Winning Twice: Better Robust Generalization from More Efficient Training",
        "html": "https://iclr.cc//virtual/2022/poster/6147",
        "abstract": "Recent studies demonstrate the deep networks, even robustified by the state-of-the-art adversarial training (AT), still suffer from large robust generalization gaps, in addition to the much more expensive training costs than standard training. In this paper, we investigate this intriguing problem from a new perspective, i.e., $\\textit{injecting appropriate forms of sparsity}$ during adversarial training. We introduce two alternatives for sparse adversarial training: (i) $\\textit{static sparsity}$, by leveraging recent results from the lottery ticket hypothesis to identify critical sparse subnetworks arising from the early training; (ii) $\\textit{dynamic sparsity}$, by allowing the sparse subnetwork to adaptively adjust its connectivity pattern (while sticking to the same sparsity ratio) throughout training. We find both static and dynamic sparse methods to yield win-win: substantially shrinking the robust generalization gap and alleviating the robust overfitting, meanwhile significantly saving training and inference FLOPs. Extensive experiments validate our proposals with multiple network architectures on diverse datasets, including CIFAR-10/100 and Tiny-ImageNet. For example, our methods reduce robust generalization gap and overfitting by $34.44\\%$ and $4.02\\%$, with comparable robust/standard accuracy boosts and $87.83\\%$/$87.82\\%$ training/inference FLOPs savings on CIFAR-100 with ResNet-18. Besides, our approaches can be organically combined with existing regularizers, establishing new state-of-the-art results in AT. All codes are included.",
        "conference": "ICLR",
        "中文标题": "稀疏性双赢：通过更高效的训练实现更好的鲁棒泛化",
        "摘要翻译": "最近的研究表明，即使是通过最先进的对抗训练（AT）强化的深度网络，除了比标准训练昂贵得多的训练成本外，仍然存在较大的鲁棒泛化差距。在本文中，我们从新的角度研究了这一有趣的问题，即在对抗训练过程中注入适当形式的稀疏性。我们介绍了两种稀疏对抗训练的替代方案：（i）静态稀疏性，通过利用彩票假设的最新结果来识别早期训练中产生的关键稀疏子网络；（ii）动态稀疏性，允许稀疏子网络在整个训练过程中自适应地调整其连接模式（同时保持相同的稀疏比）。我们发现静态和动态稀疏方法都能实现双赢：大幅缩小鲁棒泛化差距并减轻鲁棒过拟合，同时显著节省训练和推理的FLOPs。大量实验验证了我们的提议，在包括CIFAR-10/100和Tiny-ImageNet在内的多种数据集上使用多种网络架构。例如，我们的方法在CIFAR-100上使用ResNet-18时，减少了34.44%的鲁棒泛化差距和4.02%的过拟合，同时获得了可比的鲁棒/标准准确率提升，并节省了87.83%/87.82%的训练/推理FLOPs。此外，我们的方法可以与现有的正则化器有机地结合，在AT中建立了新的最先进结果。所有代码均已包含。",
        "领域": "对抗训练、稀疏网络、深度学习优化",
        "问题": "深度网络在对抗训练中存在的鲁棒泛化差距大和训练成本高的问题",
        "动机": "通过引入稀疏性来减少对抗训练中的鲁棒泛化差距和训练成本",
        "方法": "采用静态稀疏性和动态稀疏性两种方法进行稀疏对抗训练",
        "关键词": [
            "对抗训练",
            "稀疏网络",
            "鲁棒泛化",
            "训练效率",
            "深度学习优化"
        ],
        "涉及的技术概念": {
            "静态稀疏性": "通过彩票假设识别早期训练中产生的关键稀疏子网络，用于减少训练成本和提高模型鲁棒性",
            "动态稀疏性": "允许稀疏子网络自适应调整其连接模式，以优化训练过程和模型性能",
            "对抗训练（AT）": "一种通过引入对抗样本来增强模型鲁棒性的训练方法，本文中通过稀疏性优化其效率和效果"
        },
        "success": true
    },
    {
        "order": 915,
        "title": "Spatial Graph Attention and Curiosity-driven Policy for Antiviral Drug Discovery",
        "html": "https://iclr.cc//virtual/2022/poster/6351",
        "abstract": "We developed Distilled Graph Attention Policy Networks (DGAPNs), a reinforcement learning model to generate novel graph-structured chemical representations that optimize user-defined objectives by efficiently navigating a physically constrained domain. The framework is examined on the task of generating molecules that are designed to bind, noncovalently, to functional sites of SARS-CoV-2 proteins. We present a spatial Graph Attention (sGAT) mechanism that leverages self-attention over both node and edge attributes as well as encoding the spatial structure --- this capability is of considerable interest in synthetic biology and drug discovery. An attentional policy network is introduced to learn the decision rules for a dynamic, fragment-based chemical environment, and state-of-the-art policy gradient techniques are employed to train the network with stability. Exploration is driven by the stochasticity of the action space design and the innovation reward bonuses learned and proposed by random network distillation. In experiments, our framework achieved outstanding results compared to state-of-the-art algorithms, while reducing the complexity of paths to chemical synthesis.",
        "conference": "ICLR",
        "中文标题": "空间图注意力与好奇心驱动策略在抗病毒药物发现中的应用",
        "摘要翻译": "我们开发了蒸馏图注意力策略网络（DGAPNs），这是一种强化学习模型，用于生成新颖的图结构化学表示，通过有效导航物理受限领域来优化用户定义的目标。该框架在生成设计用于非共价结合SARS-CoV-2蛋白质功能位点的分子任务上进行了检验。我们提出了一种空间图注意力（sGAT）机制，该机制利用节点和边属性的自注意力以及编码空间结构——这一能力在合成生物学和药物发现中具有相当大的兴趣。引入了一个注意力策略网络来学习动态、基于片段的化学环境的决策规则，并采用了最先进的策略梯度技术以稳定性训练网络。探索由动作空间设计的随机性和通过随机网络蒸馏学习和提出的创新奖励奖金驱动。在实验中，与最先进的算法相比，我们的框架取得了出色的结果，同时降低了化学合成路径的复杂性。",
        "领域": "药物发现、强化学习、图神经网络",
        "问题": "如何高效生成能够与SARS-CoV-2蛋白质功能位点非共价结合的分子",
        "动机": "开发一种能够优化用户定义目标并有效导航物理受限领域的强化学习模型，以促进抗病毒药物的发现",
        "方法": "提出空间图注意力机制和注意力策略网络，结合最先进的策略梯度技术，通过强化学习生成优化的分子结构",
        "关键词": [
            "空间图注意力",
            "强化学习",
            "药物发现",
            "SARS-CoV-2",
            "策略梯度"
        ],
        "涉及的技术概念": {
            "空间图注意力（sGAT）": "利用节点和边属性的自注意力以及编码空间结构，增强模型对分子结构的理解和表示能力",
            "强化学习": "通过奖励机制优化分子生成过程，实现用户定义目标的优化",
            "策略梯度技术": "用于训练注意力策略网络，提高模型训练的稳定性和效率"
        },
        "success": true
    },
    {
        "order": 916,
        "title": "SphereFace2: Binary Classification is All You Need for Deep Face Recognition",
        "html": "https://iclr.cc//virtual/2022/poster/6265",
        "abstract": "State-of-the-art deep face recognition methods are mostly trained with a softmax-based multi-class classification framework. Despite being popular and effective, these methods still have a few shortcomings that limit empirical performance. In this paper, we start by identifying the discrepancy between training and evaluation in the existing multi-class classification framework and then discuss the potential limitations caused by the 'competitive' nature of softmax normalization. Motivated by these limitations, we propose a novel binary classification training framework, termed SphereFace2. In contrast to existing methods, SphereFace2 circumvents the softmax normalization, as well as the corresponding closed-set assumption. This effectively bridges the gap between training and evaluation, enabling the representations to be improved individually by each binary classification task. Besides designing a specific well-performing loss function, we summarize a few general principles for this 'one-vs-all' binary classification framework so that it can outperform current competitive methods. Our experiments on popular benchmarks demonstrate that SphereFace2 can consistently outperform state-of-the-art deep face recognition methods.",
        "conference": "ICLR",
        "中文标题": "SphereFace2：二元分类足以应对深度人脸识别",
        "摘要翻译": "目前最先进的深度人脸识别方法大多基于softmax的多类分类框架进行训练。尽管这些方法流行且有效，但仍存在一些限制经验性能的缺点。本文首先指出了现有多类分类框架中训练与评估之间的差异，然后讨论了由softmax归一化的‘竞争’性质引起的潜在限制。受这些限制的启发，我们提出了一种新颖的二元分类训练框架，称为SphereFace2。与现有方法相比，SphereFace2绕过了softmax归一化及其相应的闭集假设，有效弥合了训练与评估之间的差距，使得每个二元分类任务能够单独改进表示。除了设计一个特定表现良好的损失函数外，我们还总结了这一‘一对所有’二元分类框架的一些通用原则，使其能够超越当前的竞争方法。我们在流行基准上的实验表明，SphereFace2能够持续超越最先进的深度人脸识别方法。",
        "领域": "人脸识别",
        "问题": "解决现有基于softmax的多类分类框架在深度人脸识别中的训练与评估差异及性能限制问题",
        "动机": "受现有方法中softmax归一化的‘竞争’性质及其闭集假设限制的启发，提出更有效的二元分类训练框架",
        "方法": "提出SphereFace2框架，绕过softmax归一化，设计特定损失函数，并总结‘一对所有’二元分类框架的通用原则",
        "关键词": [
            "深度人脸识别",
            "二元分类",
            "SphereFace2",
            "softmax归一化",
            "损失函数"
        ],
        "涉及的技术概念": {
            "SphereFace2": "一种新颖的二元分类训练框架，旨在绕过softmax归一化及其闭集假设，改进深度人脸识别的表示学习",
            "softmax归一化": "现有方法中使用的多类分类技术，其‘竞争’性质可能导致训练与评估之间的差异",
            "一对所有二元分类": "一种分类策略，每个类别与其他所有类别进行二元分类，旨在超越现有竞争方法"
        },
        "success": true
    },
    {
        "order": 917,
        "title": "Spherical Message Passing for 3D Molecular Graphs",
        "html": "https://iclr.cc//virtual/2022/poster/6403",
        "abstract": "We consider representation learning of 3D molecular graphs in which each atom is associated with a spatial position in 3D. This is an under-explored area of research, and a principled message passing framework is currently lacking. In this work, we conduct analyses in the spherical coordinate system (SCS) for the complete identification of 3D graph structures. Based on such observations, we propose the spherical message passing (SMP) as a novel and powerful scheme for 3D molecular learning. SMP dramatically reduces training complexity, enabling it to perform efficiently on large-scale molecules. In addition, SMP is capable of distinguishing almost all molecular structures, and the uncovered cases may not exist in practice. Based on meaningful physically-based representations of 3D information, we further propose the SphereNet for 3D molecular learning. Experimental results demonstrate that the use of meaningful 3D information in SphereNet leads to significant performance improvements in prediction tasks. Our results also demonstrate the advantages of SphereNet in terms of capability, efficiency, and scalability.",
        "conference": "ICLR",
        "中文标题": "球形消息传递用于3D分子图",
        "摘要翻译": "我们考虑的是3D分子图的表示学习，其中每个原子都与3D空间中的一个位置相关联。这是一个研究不足的领域，目前缺乏一个原则性的消息传递框架。在这项工作中，我们在球坐标系（SCS）中进行分析，以完全识别3D图结构。基于这些观察，我们提出了球形消息传递（SMP）作为一种新颖且强大的3D分子学习方案。SMP极大地降低了训练复杂度，使其能够在大规模分子上高效运行。此外，SMP能够区分几乎所有分子结构，而未被发现的情况在实践中可能不存在。基于有意义的基于物理的3D信息表示，我们进一步提出了用于3D分子学习的SphereNet。实验结果表明，在SphereNet中使用有意义的3D信息可以显著提高预测任务的性能。我们的结果还展示了SphereNet在能力、效率和可扩展性方面的优势。",
        "领域": "分子图表示学习、3D分子结构分析、深度学习在化学中的应用",
        "问题": "如何有效地进行3D分子图的表示学习，特别是在缺乏原则性消息传递框架的情况下。",
        "动机": "解决3D分子图表示学习领域研究不足的问题，提供一个高效且强大的学习框架。",
        "方法": "在球坐标系中进行分析，提出球形消息传递（SMP）方案，并基于此开发SphereNet用于3D分子学习。",
        "关键词": [
            "球形消息传递",
            "3D分子图",
            "球坐标系",
            "SphereNet",
            "分子表示学习"
        ],
        "涉及的技术概念": {
            "球形消息传递（SMP）": "一种新颖的消息传递方案，用于3D分子图的表示学习，显著降低训练复杂度。",
            "球坐标系（SCS）": "用于完全识别3D图结构的坐标系，为SMP提供理论基础。",
            "SphereNet": "基于SMP和物理基础的3D信息表示，用于3D分子学习的网络架构，显著提高预测性能。"
        },
        "success": true
    },
    {
        "order": 918,
        "title": "Spike-inspired rank coding for fast and accurate recurrent neural networks",
        "html": "https://iclr.cc//virtual/2022/poster/6217",
        "abstract": "Biological spiking neural networks (SNNs) can temporally encode information in their outputs, e.g. in the rank order in which neurons fire, whereas artificial neural networks (ANNs) conventionally do not. As a result, models of SNNs for neuromorphic computing are regarded as potentially more rapid and efficient than ANNs when dealing with temporal input. On the other hand, ANNs are simpler to train, and usually achieve superior performance. Here we show that temporal coding such as rank coding (RC) inspired by SNNs can also be applied to conventional ANNs such as LSTMs, and leads to computational savings and speedups.In our RC for ANNs, we apply backpropagation through time using the standard real-valued activations, but only from a strategically early time step of each sequential input example, decided by a threshold-crossing event. Learning then incorporates naturally also when to produce an output, without other changes to the model or the algorithm. Both the forward and the backward training pass can be significantly shortened by skipping the remaining input sequence after that first event. RC-training also significantly reduces time-to-insight during inference, with a minimal decrease in accuracy. The desired speed-accuracy trade-off is tunable by varying the threshold or a regularization parameter that rewards output entropy. We demonstrate these in two toy problems of sequence classification, and in a temporally-encoded MNIST dataset where our RC model achieves 99.19% accuracy after the first input time-step, outperforming the state of the art in temporal coding with SNNs, as well as in spoken-word classification of Google Speech Commands, outperforming non-RC-trained early inference with LSTMs.",
        "conference": "ICLR",
        "中文标题": "受脉冲启发的等级编码用于快速且准确的循环神经网络",
        "摘要翻译": "生物脉冲神经网络（SNNs）可以在其输出中暂时编码信息，例如在神经元放电的等级顺序中，而人工神经网络（ANNs）传统上不这样做。因此，用于神经形态计算的SNN模型在处理时间输入时被认为比ANNs更快速和高效。另一方面，ANNs更易于训练，并且通常实现更优的性能。在这里，我们展示了受SNNs启发的等级编码（RC）等时间编码也可以应用于传统的ANNs，如LSTMs，并导致计算节省和加速。在我们的ANNs的RC中，我们使用标准的实值激活通过时间进行反向传播，但仅从每个序列输入示例的策略性早期时间步骤开始，由阈值交叉事件决定。学习然后自然地也包含了何时产生输出，而无需对模型或算法进行其他更改。通过跳过该首次事件后的剩余输入序列，前向和后向训练过程都可以显著缩短。RC训练还显著减少了推理过程中的洞察时间，准确度下降最小。通过改变阈值或奖励输出熵的正则化参数，可以调整所需的速度-准确度权衡。我们在序列分类的两个玩具问题中展示了这些，以及在一个时间编码的MNIST数据集中，我们的RC模型在第一个输入时间步骤后实现了99.19%的准确度，优于SNNs时间编码的最新技术，以及在Google语音命令的口语单词分类中，优于非RC训练的LSTMs早期推理。",
        "领域": "神经形态计算、循环神经网络、时间序列分类",
        "问题": "如何将生物脉冲神经网络的时间编码优势应用于传统人工神经网络以提高其处理时间输入的效率和速度",
        "动机": "探索将生物脉冲神经网络的时间编码机制应用于传统人工神经网络，以结合两者的优势，即SNNs的高效时间信息处理和ANNs的易于训练及高性能",
        "方法": "采用受SNNs启发的等级编码（RC）方法，通过阈值交叉事件决定早期时间步骤进行反向传播，从而缩短训练和推理过程",
        "关键词": [
            "等级编码",
            "循环神经网络",
            "时间序列分类",
            "神经形态计算",
            "LSTMs"
        ],
        "涉及的技术概念": {
            "等级编码（RC）": "受生物脉冲神经网络启发的编码方法，用于在人工神经网络中实现时间信息的高效处理",
            "反向传播通过时间（BPTT）": "在循环神经网络中用于训练的标准算法，本文中通过RC方法进行了优化",
            "阈值交叉事件": "决定何时开始进行反向传播的关键事件，用于缩短训练和推理过程"
        },
        "success": true
    },
    {
        "order": 919,
        "title": "SPIRAL: Self-supervised Perturbation-Invariant Representation Learning for Speech Pre-Training",
        "html": "https://iclr.cc//virtual/2022/poster/6593",
        "abstract": "We introduce a new approach for speech pre-training named SPIRAL which works by learning denoising representation of perturbed data in a teacher-student framework. Specifically, given a speech utterance, we first feed the utterance to a teacher network to obtain corresponding representation. Then the same utterance is perturbed and fed to a student network. The student network is trained to output representation resembling that of the teacher. At the same time, the teacher network is updated as moving average of student's weights over training steps. In order to prevent representation collapse, we apply an in-utterance contrastive loss as pre-training objective and impose position randomization on the input to the teacher. SPIRAL achieves competitive or better results compared to state-of-the-art speech pre-training method wav2vec 2.0, with significant reduction of training cost (80% for BASE model, 65% for LARGE model). Furthermore, we address the problem of noise-robustness that is critical to real-world speech applications. We propose multi-condition pre-training by perturbing the student's input with various types of additive noise. We demonstrate that multi-condition pre-trained SPIRAL models are more robust to noisy speech (9.0% - 13.3% relative word error rate reduction on real noisy test data), compared to applying multi-condition training solely in the fine-tuning stage. Source code is available at https://github.com/huawei-noah/Speech-Backbones/tree/main/SPIRAL.",
        "conference": "ICLR",
        "中文标题": "SPIRAL：面向语音预训练的自监督扰动不变表示学习方法",
        "摘要翻译": "我们介绍了一种名为SPIRAL的语音预训练新方法，该方法通过在师生框架中学习扰动数据的去噪表示来工作。具体来说，给定一段语音话语，我们首先将其输入教师网络以获得相应的表示。然后，同一段话语被扰动并输入学生网络。学生网络被训练以输出类似于教师的表示。同时，教师网络作为学生权重在训练步骤中的移动平均值进行更新。为了防止表示崩溃，我们应用了话语内对比损失作为预训练目标，并对教师的输入施加位置随机化。与最先进的语音预训练方法wav2vec 2.0相比，SPIRAL取得了竞争性或更好的结果，同时显著降低了训练成本（BASE模型减少80%，LARGE模型减少65%）。此外，我们解决了对现实世界语音应用至关重要的噪声鲁棒性问题。我们提出了通过用各种类型的加性噪声扰动学生输入的多条件预训练。我们证明，与仅在微调阶段应用多条件训练相比，多条件预训练的SPIRAL模型对噪声语音更加鲁棒（在真实噪声测试数据上相对词错误率降低9.0%至13.3%）。源代码可在https://github.com/huawei-noah/Speech-Backbones/tree/main/SPIRAL获取。",
        "领域": "语音识别、自监督学习、噪声鲁棒性",
        "问题": "如何在降低训练成本的同时，提高语音预训练模型的噪声鲁棒性和表示学习能力。",
        "动机": "为了解决语音预训练中噪声鲁棒性不足和训练成本高的问题，提出了一种自监督的扰动不变表示学习方法。",
        "方法": "采用师生框架，通过对比损失和位置随机化防止表示崩溃，同时引入多条件预训练增强噪声鲁棒性。",
        "关键词": [
            "自监督学习",
            "语音预训练",
            "噪声鲁棒性",
            "师生框架",
            "对比损失"
        ],
        "涉及的技术概念": {
            "师生框架": "用于学习扰动数据的去噪表示，教师网络提供目标表示，学生网络学习匹配这些表示。",
            "对比损失": "作为预训练目标，防止表示崩溃，通过比较同一话语的不同扰动版本来学习有效的表示。",
            "多条件预训练": "通过在训练过程中引入各种噪声类型，增强模型对噪声语音的鲁棒性。"
        },
        "success": true
    },
    {
        "order": 920,
        "title": "Spread Spurious Attribute: Improving Worst-group Accuracy with Spurious Attribute Estimation ",
        "html": "https://iclr.cc//virtual/2022/poster/5900",
        "abstract": "The paradigm of worst-group loss minimization has shown its promise in avoiding to learn spurious correlations, but requires costly additional supervision on spurious attributes. To resolve this, recent works focus on developing weaker forms of supervision---e.g., hyperparameters discovered with a small number of validation samples with spurious attribute annotation---but none of the methods retain comparable performance to methods using full supervision on the spurious attribute. In this paper, instead of searching for weaker supervisions, we ask: Given access to a fixed number of samples with spurious attribute annotations, what is the best achievable worst-group loss if we ''fully exploit'' them? To this end, we propose a pseudo-attribute-based algorithm, coined Spread Spurious Attribute (SSA), for improving the worst-group accuracy. In particular, we leverage samples both with and without spurious attribute annotations to train a model to predict the spurious attribute, then use the pseudo-attribute predicted by the trained model as supervision on the spurious attribute to train a new robust model having minimal worst-group loss. Our experiments on various benchmark datasets show that our algorithm consistently outperforms the baseline methods using the same number of validation samples with spurious attribute annotations. We also demonstrate that the proposed SSA can achieve comparable performances to methods using full (100%) spurious attribute supervision, by using a much smaller number of annotated samples---from 0.6% and up to 1.5%, depending on the dataset.",
        "conference": "ICLR",
        "中文标题": "传播伪属性：通过伪属性估计提升最差组准确率",
        "摘要翻译": "最差组损失最小化的范式已显示出避免学习伪相关性的潜力，但需要关于伪属性的昂贵额外监督。为解决这一问题，近期研究集中于开发较弱形式的监督——例如，通过少量带有伪属性标注的验证样本发现的超参数——但没有一种方法能够保持与使用伪属性完全监督方法相当的性能。在本文中，我们不再寻找较弱的监督，而是提出：给定固定数量带有伪属性标注的样本，如果我们'充分利用'它们，可达到的最佳最差组损失是什么？为此，我们提出了一种基于伪属性的算法，称为传播伪属性（SSA），用于提高最差组准确率。具体而言，我们利用带有和不带有伪属性标注的样本来训练模型预测伪属性，然后使用训练模型预测的伪属性作为伪属性的监督，来训练一个新的具有最小最差组损失的鲁棒模型。我们在各种基准数据集上的实验表明，我们的算法在使用相同数量带有伪属性标注的验证样本时，始终优于基线方法。我们还证明，通过使用少得多的标注样本——从0.6%到1.5%，取决于数据集——提出的SSA可以实现与使用完全（100%）伪属性监督方法相当的性能。",
        "领域": "深度学习鲁棒性、伪相关性学习、监督学习优化",
        "问题": "如何在有限的伪属性标注样本下，最大化最差组准确率",
        "动机": "减少对昂贵伪属性标注的依赖，同时保持或提升模型在最差组上的性能",
        "方法": "提出传播伪属性（SSA）算法，利用有限标注样本预测伪属性，并以此训练鲁棒模型",
        "关键词": [
            "最差组准确率",
            "伪属性估计",
            "监督学习优化",
            "深度学习鲁棒性",
            "伪相关性"
        ],
        "涉及的技术概念": {
            "最差组损失最小化": "旨在优化模型在最不利数据子群上的表现，避免模型依赖于伪相关性",
            "伪属性预测": "通过模型预测数据中的伪属性，用于后续的模型训练和优化",
            "鲁棒模型训练": "利用预测的伪属性作为监督信号，训练出对伪相关性不敏感的模型"
        },
        "success": true
    },
    {
        "order": 921,
        "title": "Sqrt(d) Dimension Dependence of Langevin Monte Carlo",
        "html": "https://iclr.cc//virtual/2022/poster/6903",
        "abstract": "This article considers the popular MCMC method of unadjusted Langevin Monte Carlo (LMC) and provides a non-asymptotic analysis of its sampling error in 2-Wasserstein distance. The proof is based on a refinement of mean-square analysis in Li et al. (2019), and this refined framework automates the analysis of a large class of sampling algorithms based on discretizations of contractive SDEs. Using this framework, we establish an $\\tilde{O}(\\sqrt{d}/\\epsilon)$ mixing time bound for LMC, without warm start, under the common log-smooth and log-strongly-convex conditions, plus a growth condition on the 3rd-order derivative of the potential of target measures. This bound improves the best previously known $\\tilde{O}(d/\\epsilon)$ result and is optimal (in terms of order) in both dimension $d$ and accuracy tolerance $\\epsilon$ for target measures satisfying the aforementioned assumptions. Our theoretical analysis is further validated by numerical experiments.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "朗之万蒙特卡洛算法的Sqrt(d)维度依赖性",
        "摘要翻译": "本文考虑了流行的MCMC方法，即未调整的朗之万蒙特卡洛算法（LMC），并提供了其在2-Wasserstein距离下的采样误差的非渐近分析。该证明基于Li等人(2019)的均方分析的改进，并且这个改进的框架可以自动分析一大类基于压缩SDE离散化的采样算法。使用这个框架，我们在常见的对数平滑和对数强凸条件下，加上目标测度的势的三阶导数的增长条件，建立了LMC的$\\tilde{O}(\\sqrt{d}/\\epsilon)$混合时间界限，而无需热启动。这个界限改进了先前已知的$\\tilde{O}(d/\\epsilon)$的最佳结果，并且在维度$d$和精度容差$\\epsilon$方面对于满足上述假设的目标测度都是最优的（就阶数而言）。我们的理论分析通过数值实验得到了进一步验证。",
        "领域": "蒙特卡洛方法, 采样算法, 非凸优化",
        "问题": "研究未调整的朗之万蒙特卡洛算法（LMC）在采样时，其采样误差与维度 d 的关系，并改进混合时间界限。",
        "动机": "先前的研究结果表明LMC的混合时间界限为$\\tilde{O}(d/\\epsilon)$，本文旨在改进这一结果，并找到在维度d和精度容差ε方面都更优的界限。",
        "方法": "通过改进Li等人的均方分析，建立了一个通用的框架，用于分析基于压缩SDE离散化的采样算法。在此框架下，结合对数平滑和对数强凸条件以及目标测度势的三阶导数的增长条件，推导出LMC的混合时间界限。",
        "关键词": [
            "朗之万蒙特卡洛",
            "MCMC",
            "采样算法",
            "混合时间",
            "Wasserstein距离"
        ],
        "涉及的技术概念": {
            "朗之万蒙特卡洛 (LMC)": "一种马尔可夫链蒙特卡洛方法，用于从概率分布中采样。论文研究其采样误差与维度之间的关系。",
            "Wasserstein距离": "一种用于衡量概率分布之间距离的度量。论文使用2-Wasserstein距离来分析LMC的采样误差。"
        }
    },
    {
        "order": 922,
        "title": "SQuant: On-the-Fly Data-Free Quantization via Diagonal Hessian Approximation",
        "html": "https://iclr.cc//virtual/2022/poster/7037",
        "abstract": "Quantization of deep neural networks (DNN) has been proven effective for compressing and accelerating DNN models. Data-free quantization (DFQ) is a promising approach without the original datasets under privacy-sensitive and confidential scenarios. However, current DFQ solutions degrade accuracy, need synthetic data to calibrate networks, and are time-consuming and costly. This paper proposes an on-the-fly DFQ framework with sub-second quantization time, called SQuant, which can quantize networks on inference-only devices with low computation and memory requirements. With the theoretical analysis of the second-order information of DNN task loss, we decompose and approximate the Hessian-based optimization objective into three diagonal sub-items, which have different areas corresponding to three dimensions of weight tensor: element-wise, kernel-wise, and output channel-wise. Then, we progressively compose sub-items and propose a novel data-free optimization objective in the discrete domain,  minimizing Constrained Absolute Sum of Error (or CASE in short), which surprisingly does not need any dataset and is even not aware of network architecture. We also design an efficient algorithm without back-propagation to further reduce the computation complexity of the objective solver. Finally, without fine-tuning and synthetic datasets, SQuant accelerates the data-free quantization process to a sub-second level with >30% accuracy improvement over the existing data-free post-training quantization works, with the evaluated models under 4-bit quantization. We have open-sourced the SQuant framework at https://github.com/clevercool/SQuant.",
        "conference": "ICLR",
        "中文标题": "SQuant：通过对角Hessian近似实现的即时无数据量化",
        "摘要翻译": "深度神经网络（DNN）的量化已被证明对于压缩和加速DNN模型是有效的。无数据量化（DFQ）是一种在隐私敏感和机密场景下无需原始数据集的有前途的方法。然而，当前的DFQ解决方案会降低准确性，需要合成数据来校准网络，并且耗时且成本高。本文提出了一种即时DFQ框架，称为SQuant，具有亚秒级的量化时间，可以在仅推理设备上以低计算和内存需求量化网络。通过对DNN任务损失的二阶信息的理论分析，我们将基于Hessian的优化目标分解并近似为三个对角子项，这些子项对应于权重张量的三个维度：元素级、内核级和输出通道级。然后，我们逐步组合子项，并在离散域中提出了一种新颖的无数据优化目标，最小化约束绝对误差和（简称CASE），这意外地不需要任何数据集，甚至不需要了解网络架构。我们还设计了一种无需反向传播的高效算法，以进一步降低目标求解器的计算复杂度。最后，无需微调和合成数据集，SQuant将无数据量化过程加速到亚秒级，与现有的无数据后训练量化工作相比，准确率提高了30%以上，评估的模型在4位量化下。我们已在https://github.com/clevercool/SQuant开源了SQuant框架。",
        "领域": "模型量化、神经网络加速、隐私保护计算",
        "问题": "解决当前无数据量化方法在准确性、时间和成本上的不足",
        "动机": "在隐私敏感和机密场景下，实现高效、准确的无数据量化",
        "方法": "通过分解和近似Hessian优化目标，提出一种无需数据集和网络架构知识的无数据优化目标，并设计高效算法减少计算复杂度",
        "关键词": [
            "无数据量化",
            "Hessian近似",
            "神经网络加速",
            "隐私保护",
            "模型压缩"
        ],
        "涉及的技术概念": {
            "对角Hessian近似": "用于分解和近似优化目标，减少计算复杂度",
            "约束绝对误差和（CASE）": "作为无数据优化的目标函数，无需数据集和网络架构知识",
            "无反向传播算法": "设计用于高效求解优化目标，进一步降低计算复杂度"
        },
        "success": true
    },
    {
        "order": 923,
        "title": "Stability Regularization for Discrete Representation Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6990",
        "abstract": "We present a method for training neural network models with discrete stochastic variables.The core of the method is \\emph{stability regularization}, which is a regularization procedure based on the idea of noise stability developed in Gaussian isoperimetric theory in the analysis of Gaussian functions.Stability regularization is method to make the output of continuous functions of Gaussian random variables close to discrete, that is binary or categorical, without the need for significant manual tuning.The method allows control over the extent to which a Gaussian function's output is close to discrete, thus allowing for continued flow of gradient.The method can be used standalone or in combination with existing continuous relaxation methods.We validate the method in a broad range of experiments using discrete variables including neural relational inference, generative modeling, clustering and conditional computing.",
        "conference": "ICLR",
        "中文标题": "离散表示学习的稳定性正则化",
        "摘要翻译": "我们提出了一种训练带有离散随机变量的神经网络模型的方法。该方法的核心是稳定性正则化，这是一种基于高斯等周理论中噪声稳定性思想的正则化过程。稳定性正则化是一种使高斯随机变量的连续函数输出接近离散（即二进制或分类）的方法，无需大量手动调整。该方法允许控制高斯函数输出接近离散的程度，从而允许梯度的持续流动。该方法可以单独使用，也可以与现有的连续松弛方法结合使用。我们在包括神经关系推理、生成建模、聚类和条件计算在内的广泛实验中验证了该方法。",
        "领域": "生成建模, 聚类分析, 条件计算",
        "问题": "如何有效地训练带有离散随机变量的神经网络模型",
        "动机": "为了解决在训练带有离散随机变量的神经网络模型时，需要大量手动调整和梯度流动受限的问题",
        "方法": "提出了一种基于高斯等周理论中噪声稳定性思想的正则化过程，即稳定性正则化，以控制高斯函数输出接近离散的程度",
        "关键词": [
            "稳定性正则化",
            "离散随机变量",
            "高斯等周理论",
            "梯度流动",
            "连续松弛方法"
        ],
        "涉及的技术概念": {
            "稳定性正则化": "基于高斯等周理论中噪声稳定性思想的正则化过程，用于使高斯随机变量的连续函数输出接近离散",
            "高斯等周理论": "提供噪声稳定性思想的理论基础，用于开发稳定性正则化方法",
            "连续松弛方法": "与稳定性正则化方法结合使用，以进一步优化模型训练过程"
        },
        "success": true
    },
    {
        "order": 924,
        "title": "Steerable Partial Differential Operators for Equivariant Neural Networks",
        "html": "https://iclr.cc//virtual/2022/poster/6313",
        "abstract": "Recent work in equivariant deep learning bears strong similarities to physics. Fields over a base space are fundamental entities in both subjects, as are equivariant maps between these fields. In deep learning, however, these maps are usually defined by convolutions with a kernel, whereas they are partial differential operators (PDOs) in physics. Developing the theory of equivariant PDOs in the context of deep learning could bring these subjects even closer together and lead to a stronger flow of ideas. In this work, we derive a $G$-steerability constraint that completely characterizes when a PDO between feature vector fields is equivariant, for arbitrary symmetry groups $G$. We then fully solve this constraint for several important groups. We use our solutions as equivariant drop-in replacements for convolutional layers and benchmark them in that role. Finally, we develop a framework for equivariant maps based on Schwartz distributions that unifies classical convolutions and differential operators and gives insight about the relation between the two.",
        "conference": "ICLR",
        "中文标题": "可操纵偏微分算子用于等变神经网络",
        "摘要翻译": "近期在等变深度学习领域的研究与物理学有着强烈的相似性。在这两个学科中，基空间上的场都是基本实体，这些场之间的等变映射也是如此。然而，在深度学习中，这些映射通常由与核的卷积定义，而在物理学中它们是偏微分算子（PDOs）。在深度学习的背景下发展等变PDOs的理论可以使这两个学科更加紧密地结合在一起，并促进思想的更强烈流动。在这项工作中，我们推导出了一个$G$-可操纵性约束，该约束完全描述了对于任意对称群$G$，特征向量场之间的PDO何时是等变的。然后，我们为几个重要的群完全解决了这个约束。我们将我们的解决方案作为等变的即插即用替代品用于卷积层，并在该角色中对它们进行基准测试。最后，我们基于Schwartz分布开发了一个等变映射框架，该框架统一了经典卷积和微分算子，并提供了关于两者之间关系的见解。",
        "领域": "等变神经网络、偏微分方程在深度学习中的应用、对称性学习",
        "问题": "如何在深度学习中实现与物理学中偏微分算子相似的等变映射",
        "动机": "将物理学中的偏微分算子理论引入深度学习，以促进两个领域之间思想的交流和技术的融合",
        "方法": "推导并解决$G$-可操纵性约束，将其作为等变映射的即插即用替代品用于卷积层，并基于Schwartz分布开发统一的等变映射框架",
        "关键词": [
            "等变神经网络",
            "偏微分算子",
            "对称性学习",
            "Schwartz分布",
            "卷积层"
        ],
        "涉及的技术概念": {
            "$G$-可操纵性约束": "描述了特征向量场之间的偏微分算子何时对于任意对称群$G$是等变的",
            "Schwartz分布": "用于开发统一的等变映射框架，该框架能够统一经典卷积和微分算子",
            "等变映射": "在保持对称性的前提下，实现不同场之间的转换"
        },
        "success": true
    },
    {
        "order": 925,
        "title": "Stein Latent Optimization for Generative Adversarial Networks",
        "html": "https://iclr.cc//virtual/2022/poster/6332",
        "abstract": "Generative adversarial networks (GANs) with clustered latent spaces can perform conditional generation in a completely unsupervised manner. In the real world, the salient attributes of unlabeled data can be imbalanced. However, most of existing unsupervised conditional GANs cannot cluster attributes of these data in their latent spaces properly because they assume uniform distributions of the attributes. To address this problem, we theoretically derive Stein latent optimization that provides reparameterizable gradient estimations of the latent distribution parameters assuming a Gaussian mixture prior in a continuous latent space. Structurally, we introduce an encoder network and novel unsupervised conditional contrastive loss to ensure that data generated from a single mixture component represent a single attribute. We confirm that the proposed method, named Stein Latent Optimization for GANs (SLOGAN), successfully learns balanced or imbalanced attributes and achieves state-of-the-art unsupervised conditional generation performance even in the absence of attribute information (e.g., the imbalance ratio). Moreover, we demonstrate that the attributes to be learned can be manipulated using a small amount of probe data.",
        "conference": "ICLR",
        "中文标题": "生成对抗网络的Stein潜在优化",
        "摘要翻译": "具有聚类潜在空间的生成对抗网络（GANs）能够以完全无监督的方式进行条件生成。在现实世界中，未标记数据的显著属性可能是不平衡的。然而，大多数现有的无监督条件GANs无法在其潜在空间中正确聚类这些数据的属性，因为它们假设属性的均匀分布。为了解决这个问题，我们从理论上推导出了Stein潜在优化，该优化在连续潜在空间中假设高斯混合先验，提供了潜在分布参数的可重参数化梯度估计。在结构上，我们引入了一个编码器网络和新的无监督条件对比损失，以确保从单个混合成分生成的数据代表单个属性。我们确认，所提出的方法（命名为SLOGAN）成功地学习了平衡或不平衡的属性，并在缺乏属性信息（例如不平衡比例）的情况下实现了最先进的无监督条件生成性能。此外，我们证明了可以使用少量探针数据操纵要学习的属性。",
        "领域": "生成对抗网络、无监督学习、条件生成",
        "问题": "解决无监督条件GANs在潜在空间中无法正确聚类不平衡属性数据的问题。",
        "动机": "现实世界中的未标记数据属性往往不平衡，而现有方法假设属性均匀分布，无法有效处理这种情况。",
        "方法": "提出Stein潜在优化方法，引入编码器网络和无监督条件对比损失，以在连续潜在空间中假设高斯混合先验，优化潜在分布参数。",
        "关键词": [
            "生成对抗网络",
            "无监督学习",
            "条件生成",
            "潜在空间优化",
            "属性聚类"
        ],
        "涉及的技术概念": {
            "Stein潜在优化": "在连续潜在空间中假设高斯混合先验，提供潜在分布参数的可重参数化梯度估计。",
            "编码器网络": "用于确保从单个混合成分生成的数据代表单个属性的网络结构。",
            "无监督条件对比损失": "新型损失函数，用于在无监督条件下优化生成数据的属性表示。"
        },
        "success": true
    },
    {
        "order": 926,
        "title": "Step-unrolled Denoising Autoencoders for Text Generation",
        "html": "https://iclr.cc//virtual/2022/poster/6942",
        "abstract": "In this paper we propose a new generative model of text, Step-unrolled Denoising Autoencoder (SUNDAE), that does not rely on autoregressive models. Similarly to denoising diffusion techniques, SUNDAE is repeatedly applied on a sequence of tokens, starting from random inputs and improving them each time until convergence. We present a simple new improvement operator that converges in fewer iterations than diffusion methods, while qualitatively producing better samples on natural language datasets. SUNDAE achieves state-of-the-art results (among non-autoregressive methods) on the WMT'14 English-to-German translation task and good qualitative results on unconditional language modeling on the Colossal Cleaned Common Crawl dataset and a dataset of Python code from GitHub. The non-autoregressive nature of SUNDAE opens up possibilities beyond left-to-right prompted generation, by filling in arbitrary blank patterns in a template.",
        "conference": "ICLR",
        "中文标题": "逐步展开的去噪自编码器用于文本生成",
        "摘要翻译": "在本文中，我们提出了一种新的文本生成模型——逐步展开的去噪自编码器（SUNDAE），该模型不依赖于自回归模型。与去噪扩散技术类似，SUNDAE在从随机输入开始的令牌序列上重复应用，每次迭代都进行改进直至收敛。我们提出了一种简单的新改进算子，该算子在比扩散方法更少的迭代次数内收敛，同时在自然语言数据集上定性产生更好的样本。SUNDAE在WMT'14英语到德语翻译任务上取得了（非自回归方法中的）最先进结果，并在Colossal Cleaned Common Crawl数据集和GitHub上的Python代码数据集的无条件语言建模上取得了良好的定性结果。SUNDAE的非自回归特性通过填充模板中的任意空白模式，开启了超越从左到右提示生成的可能性。",
        "领域": "自然语言生成、机器翻译、非自回归模型",
        "问题": "如何在不依赖自回归模型的情况下，高效生成高质量的文本",
        "动机": "探索非自回归模型在文本生成中的应用，以克服自回归模型在生成速度和灵活性上的限制",
        "方法": "提出逐步展开的去噪自编码器（SUNDAE），通过重复应用改进算子从随机输入生成文本，直至收敛",
        "关键词": [
            "非自回归模型",
            "文本生成",
            "去噪自编码器",
            "机器翻译",
            "语言建模"
        ],
        "涉及的技术概念": {
            "逐步展开的去噪自编码器（SUNDAE）": "一种不依赖自回归模型的文本生成方法，通过迭代改进随机输入生成文本",
            "改进算子": "SUNDAE中用于在每次迭代中改进文本生成的简单算子，比扩散方法收敛更快",
            "非自回归特性": "SUNDAE不依赖于传统的从左到右的自回归生成方式，能够灵活填充模板中的任意空白模式"
        },
        "success": true
    },
    {
        "order": 927,
        "title": "Stiffness-aware neural network for learning Hamiltonian systems",
        "html": "https://iclr.cc//virtual/2022/poster/6856",
        "abstract": "We propose stiffness-aware neural network (SANN), a new method for learning Hamiltonian dynamical systems from data. SANN identifies and splits the training data into stiff and nonstiff portions based on a stiffness-aware index, a simple, yet effective metric we introduce to quantify the stiffness of the dynamical system. This classification along with a resampling technique allows us to apply different time integration strategies such as step size adaptation to better capture the dynamical characteristics of the Hamiltonian vector fields. We evaluate SANN on complex physical systems including a three-body problem and  billiard model. We show that SANN is more stable and can better preserve energy when compared with the state-of-the-art methods, leading to significant improvement in accuracy.",
        "conference": "ICLR",
        "中文标题": "刚度感知神经网络用于学习哈密顿系统",
        "摘要翻译": "我们提出了刚度感知神经网络（SANN），一种从数据中学习哈密顿动力系统的新方法。SANN基于我们引入的一个简单而有效的度量——刚度感知指标，识别并将训练数据分为刚性和非刚性部分。这种分类与重采样技术相结合，使我们能够应用不同的时间积分策略，如步长适应，以更好地捕捉哈密顿向量场的动力学特性。我们在包括三体问题和台球模型在内的复杂物理系统上评估了SANN。结果表明，与最先进的方法相比，SANN更稳定，能更好地保持能量，从而显著提高了准确性。",
        "领域": "动力系统学习、物理模拟、神经网络应用",
        "问题": "如何从数据中更有效地学习哈密顿动力系统的动力学特性",
        "动机": "提高对哈密顿动力系统动力学特性学习的准确性和稳定性",
        "方法": "引入刚度感知指标分类数据，结合重采样技术和不同的时间积分策略",
        "关键词": [
            "刚度感知神经网络",
            "哈密顿系统",
            "动力系统学习",
            "时间积分策略",
            "能量保持"
        ],
        "涉及的技术概念": {
            "刚度感知指标": "用于量化动力系统刚度的简单而有效的度量，帮助分类训练数据",
            "重采样技术": "用于调整训练数据的分布，以更好地适应不同的时间积分策略",
            "时间积分策略": "如步长适应，用于更准确地捕捉哈密顿向量场的动力学特性"
        },
        "success": true
    },
    {
        "order": 928,
        "title": "Stochastic Training is Not Necessary for Generalization",
        "html": "https://iclr.cc//virtual/2022/poster/6236",
        "abstract": "It is widely believed that the implicit regularization of SGD is fundamental to the impressive generalization behavior we observe in neural networks.  In this work, we demonstrate that non-stochastic full-batch training can achieve comparably strong performance to SGD on CIFAR-10 using modern architectures. To this end, we show that the implicit regularization of SGD can be completely replaced with explicit regularization. Our observations indicate that the perceived difficulty of full-batch training may be the result of its optimization properties and the disproportionate time and effort spent by the ML community tuning optimizers and hyperparameters for small-batch training.",
        "conference": "ICLR",
        "中文标题": "随机训练对于泛化并非必需",
        "摘要翻译": "人们普遍认为，随机梯度下降（SGD）的隐式正则化是我们在神经网络中观察到的令人印象深刻的泛化行为的基础。在这项工作中，我们证明了非随机的全批量训练可以在CIFAR-10上使用现代架构实现与SGD相当的性能。为此，我们展示了SGD的隐式正则化可以完全被显式正则化所替代。我们的观察表明，全批量训练所感知到的困难可能是其优化特性以及机器学习社区在小批量训练的优化器和超参数调整上投入不成比例的时间和精力的结果。",
        "领域": "深度学习优化",
        "问题": "探讨随机梯度下降（SGD）是否是神经网络泛化能力的关键因素",
        "动机": "挑战SGD隐式正则化对神经网络泛化能力的必要性，探索全批量训练的潜力",
        "方法": "通过实验比较非随机全批量训练和SGD在CIFAR-10上的性能，使用显式正则化替代隐式正则化",
        "关键词": [
            "全批量训练",
            "显式正则化",
            "泛化能力",
            "优化策略",
            "神经网络训练"
        ],
        "涉及的技术概念": {
            "隐式正则化": "SGD在训练过程中自然引入的正则化效果，被认为有助于模型的泛化",
            "显式正则化": "通过明确添加正则化项来控制模型复杂度，替代SGD的隐式正则化效果",
            "全批量训练": "使用整个训练数据集进行每次参数更新，与SGD的小批量训练相对"
        },
        "success": true
    },
    {
        "order": 929,
        "title": "Strength of Minibatch Noise in SGD",
        "html": "https://iclr.cc//virtual/2022/poster/7176",
        "abstract": "The noise in stochastic gradient descent (SGD), caused by minibatch sampling, is poorly understood despite its practical importance in deep learning. This work presents the first systematic study of the SGD noise and fluctuations close to a local minimum. We first analyze the SGD noise in linear regression in detail and then derive a general formula for approximating SGD noise in different types of minima. For application, our results (1) provide insight into the stability of training a neural network, (2) suggest that a large learning rate can help generalization by introducing an implicit regularization, (3) explain why the linear learning rate-batchsize scaling law fails at a large learning rate or at a small batchsize and (4) can provide an understanding of how discrete-time nature of SGD affects the recently discovered power-law phenomenon of SGD.",
        "conference": "ICLR",
        "中文标题": "随机梯度下降中迷你批次噪声的强度",
        "摘要翻译": "随机梯度下降（SGD）中的噪声，由迷你批次采样引起，尽管在深度学习中具有实际重要性，但其理解仍然不足。这项工作首次系统地研究了SGD噪声及其在局部最小值附近的波动。我们首先详细分析了线性回归中的SGD噪声，然后推导了一个通用公式，用于近似不同类型最小值中的SGD噪声。在应用方面，我们的结果（1）提供了对神经网络训练稳定性的洞察，（2）表明大的学习率可以通过引入隐式正则化帮助泛化，（3）解释了为什么线性学习率-批次大小缩放定律在大的学习率或小的批次大小时失效，以及（4）可以理解SGD的离散时间性质如何影响最近发现的SGD幂律现象。",
        "领域": "深度学习优化、神经网络训练、随机梯度下降",
        "问题": "理解随机梯度下降（SGD）中由迷你批次采样引起的噪声及其对深度学习模型训练的影响",
        "动机": "尽管SGD噪声在深度学习中具有实际重要性，但其理解仍然不足，本研究旨在填补这一空白",
        "方法": "首先分析线性回归中的SGD噪声，然后推导一个通用公式来近似不同类型最小值中的SGD噪声",
        "关键词": [
            "随机梯度下降",
            "迷你批次噪声",
            "深度学习优化",
            "神经网络训练",
            "隐式正则化"
        ],
        "涉及的技术概念": {
            "随机梯度下降（SGD）": "一种优化算法，通过使用数据子集（迷你批次）来估计梯度，从而在深度学习中广泛用于模型训练",
            "隐式正则化": "通过优化过程本身引入的正则化效果，如大学习率在SGD中可能带来的泛化优势",
            "线性学习率-批次大小缩放定律": "描述学习率和批次大小之间关系的经验法则，本研究探讨了其在大学习率或小批次大小下的失效原因"
        },
        "success": true
    },
    {
        "order": 930,
        "title": "Structure-Aware Transformer Policy for Inhomogeneous Multi-Task Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6945",
        "abstract": "Modular Reinforcement Learning, where the agent is assumed to be morphologically structured as a graph, for example composed of limbs and joints, aims to learn a policy that is transferable to a structurally similar but different agent. Compared to traditional Multi-Task Reinforcement Learning, this promising approach allows us to cope with inhomogeneous tasks where the state and action space dimensions differ across tasks. Graph Neural Networks are a natural model for representing the pertinent policies, but a recent work has shown that their multi-hop message passing mechanism is not ideal for conveying important information to other modules and thus a transformer model without morphological information was proposed. In this work, we argue that the morphological information is still very useful and propose a transformer policy model that effectively encodes such information. Specifically, we encode the morphological information in terms of the traversal-based positional embedding and the graph-based relational embedding. We empirically show that the morphological information is crucial for modular reinforcement learning, substantially outperforming prior state-of-the-art methods on multi-task learning as well as transfer learning settings with different state and action space dimensions.",
        "conference": "ICLR",
        "中文标题": "结构感知的Transformer策略用于非均匀多任务强化学习",
        "摘要翻译": "模块化强化学习假设智能体在形态上被结构化为图，例如由肢体和关节组成，旨在学习一个可以迁移到结构相似但不同的智能体的策略。与传统的多任务强化学习相比，这种有前景的方法使我们能够应对状态和动作空间维度在不同任务间不同的非均匀任务。图神经网络是表示相关策略的自然模型，但最近的工作表明，它们的多跳消息传递机制并不理想，无法将重要信息传递给其他模块，因此提出了一个没有形态信息的Transformer模型。在这项工作中，我们认为形态信息仍然非常有用，并提出了一种有效编码这种信息的Transformer策略模型。具体来说，我们基于遍历的位置嵌入和图的关系嵌入来编码形态信息。我们通过实验证明，形态信息对于模块化强化学习至关重要，在多任务学习以及具有不同状态和动作空间维度的迁移学习设置中，显著优于先前的最先进方法。",
        "领域": "模块化强化学习、多任务强化学习、迁移学习",
        "问题": "如何在非均匀多任务强化学习中有效利用智能体的形态信息以提高策略的迁移性和适应性",
        "动机": "解决传统多任务强化学习在处理状态和动作空间维度不同的非均匀任务时的局限性，以及图神经网络在多跳消息传递中的不足",
        "方法": "提出了一种结构感知的Transformer策略模型，通过遍历基于的位置嵌入和图基于的关系嵌入来编码智能体的形态信息",
        "关键词": [
            "模块化强化学习",
            "Transformer模型",
            "形态信息编码",
            "多任务学习",
            "迁移学习"
        ],
        "涉及的技术概念": {
            "模块化强化学习": "一种强化学习方法，假设智能体在形态上被结构化为图，旨在学习可迁移的策略",
            "Transformer模型": "一种基于自注意力机制的模型，用于处理序列数据，本文中用于编码智能体的形态信息",
            "形态信息编码": "通过遍历基于的位置嵌入和图基于的关系嵌入来编码智能体的形态信息，以提高策略的迁移性和适应性"
        },
        "success": true
    },
    {
        "order": 931,
        "title": "StyleAlign: Analysis and Applications of Aligned StyleGAN Models",
        "html": "https://iclr.cc//virtual/2022/poster/6948",
        "abstract": "In this paper, we perform an in-depth study of the properties and applications of aligned generative models.We refer to two models as aligned if they share the same architecture, and one of them (the child) is obtained from the other (the parent) via fine-tuning to another domain, a common practice in transfer learning. Several works already utilize some basic properties of aligned StyleGAN models to perform image-to-image translation. Here, we perform the first detailed exploration of model alignment, also focusing on StyleGAN. First, we empirically analyze aligned models and provide answers to important questions regarding their nature. In particular, we find that the child model's latent spaces are semantically aligned with those of the parent, inheriting incredibly rich semantics, even for distant data domains such as human faces and churches. Second, equipped with this better understanding, we leverage aligned models to solve a diverse set of tasks. In addition to image translation, we demonstrate fully automatic cross-domain image morphing. We further show that zero-shot vision tasks may be performed in the child domain, while relying exclusively on supervision in the parent domain. We demonstrate qualitatively and quantitatively that our approach yields state-of-the-art results, while requiring only simple fine-tuning and inversion. ",
        "conference": "ICLR",
        "中文标题": "StyleAlign：对齐StyleGAN模型的分析与应用",
        "摘要翻译": "本文深入研究了对齐生成模型的性质及其应用。我们称两个模型为对齐的，如果它们共享相同的架构，并且其中一个（子模型）是通过对另一个（父模型）进行微调以适应另一个领域而获得的，这是迁移学习中的常见做法。已有几项工作利用对齐StyleGAN模型的一些基本属性来执行图像到图像的转换。在这里，我们首次详细探索了模型对齐，同样聚焦于StyleGAN。首先，我们实证分析了对齐模型，并就其性质提供了重要问题的答案。特别是，我们发现子模型的潜在空间与父模型的潜在空间在语义上是对齐的，继承了极其丰富的语义，即使是对于人类面孔和教堂等远距离数据领域也是如此。其次，基于这种更深入的理解，我们利用对齐模型来解决一系列多样化的任务。除了图像转换外，我们还展示了完全自动的跨域图像变形。我们进一步表明，可以在子领域执行零样本视觉任务，而完全依赖于父领域的监督。我们定性和定量地证明了我们的方法产生了最先进的结果，同时仅需要简单的微调和反转。",
        "领域": "生成对抗网络、图像转换、零样本学习",
        "问题": "探索和利用对齐StyleGAN模型的性质以解决多样化的视觉任务",
        "动机": "深入理解对齐生成模型的性质，并利用这些性质开发新的应用",
        "方法": "实证分析对齐模型的性质，并利用这些性质进行图像转换、跨域图像变形和零样本视觉任务",
        "关键词": [
            "StyleGAN",
            "模型对齐",
            "图像转换",
            "跨域变形",
            "零样本学习"
        ],
        "涉及的技术概念": {
            "模型对齐": "指两个共享相同架构的生成模型，其中一个是通过对另一个进行微调以适应新领域而获得的",
            "潜在空间语义对齐": "子模型的潜在空间与父模型的潜在空间在语义上对齐，继承了丰富的语义信息",
            "零样本视觉任务": "在子领域执行视觉任务，而无需子领域的标注数据，仅依赖于父领域的监督"
        },
        "success": true
    },
    {
        "order": 932,
        "title": "StyleNeRF: A Style-based 3D Aware Generator for High-resolution Image Synthesis",
        "html": "https://iclr.cc//virtual/2022/poster/6113",
        "abstract": "We propose StyleNeRF, a 3D-aware generative model for photo-realistic high-resolution image synthesis with high multi-view  consistency, which can be trained on unstructured 2D images. Existing approaches either cannot synthesize high-resolution images with fine details or yield clearly noticeable 3D-inconsistent artifacts. In addition, many of them lack control on style attributes and explicit 3D camera poses. To address these issues, StyleNeRF integrates the neural radiance field (NeRF) into a style-based generator to tackle the aforementioned challenges, i.e., improving rendering efficiency and 3D consistency for high-resolution image generation. To address the first issue, we perform volume rendering only to produce a low-resolution feature map, and progressively apply upsampling in 2D. To mitigate the inconsistencies caused by 2D upsampling, we propose multiple designs including a better upsampler choice and a new regularization loss to enforce 3D consistency. With these designs, StyleNeRF is able to synthesize high-resolution images at interactive rates while preserving 3D consistency at high quality. StyleNeRF also enables control of camera poses and different levels of styles, which can generalize to unseen views. It also supports challenging tasks such as style mixing, inversion and simple semantic edits. ",
        "conference": "ICLR",
        "中文标题": "StyleNeRF：一种基于风格的高分辨率图像合成的3D感知生成器",
        "摘要翻译": "我们提出了StyleNeRF，一种3D感知的生成模型，用于照片级真实感的高分辨率图像合成，具有高度的多视角一致性，可以在非结构化的2D图像上进行训练。现有的方法要么无法合成具有精细细节的高分辨率图像，要么会产生明显可察觉的3D不一致伪影。此外，许多方法缺乏对风格属性和明确3D相机姿态的控制。为了解决这些问题，StyleNeRF将神经辐射场（NeRF）集成到一个基于风格的生成器中，以解决上述挑战，即提高高分辨率图像生成的渲染效率和3D一致性。为了解决第一个问题，我们仅执行体积渲染以产生低分辨率特征图，并逐步在2D中应用上采样。为了减轻由2D上采样引起的不一致性，我们提出了多种设计，包括更好的上采样器选择和一个新的正则化损失来强制3D一致性。通过这些设计，StyleNeRF能够以交互速率合成高分辨率图像，同时保持高质量的3D一致性。StyleNeRF还能够控制相机姿态和不同级别的风格，这可以推广到未见的视角。它还支持具有挑战性的任务，如风格混合、反转和简单的语义编辑。",
        "领域": "3D图像生成、神经辐射场、高分辨率图像合成",
        "问题": "解决高分辨率图像合成中的3D不一致性和风格控制问题",
        "动机": "提高高分辨率图像生成的渲染效率和3D一致性，同时增强对风格和相机姿态的控制",
        "方法": "将神经辐射场（NeRF）集成到基于风格的生成器中，采用体积渲染和2D上采样技术，引入新的正则化损失以强制3D一致性",
        "关键词": [
            "StyleNeRF",
            "3D感知生成",
            "高分辨率图像合成",
            "神经辐射场",
            "风格控制"
        ],
        "涉及的技术概念": {
            "神经辐射场（NeRF）": "用于从2D图像中重建3D场景的技术，提高图像合成的3D一致性",
            "基于风格的生成器": "允许对生成图像的风格属性进行控制，支持风格混合和编辑",
            "正则化损失": "新设计的损失函数，用于在2D上采样过程中强制保持3D一致性"
        },
        "success": true
    },
    {
        "order": 933,
        "title": "Subspace Regularizers for Few-Shot Class Incremental Learning",
        "html": "https://iclr.cc//virtual/2022/poster/7151",
        "abstract": "Few-shot class incremental learning---the problem of updating a trained classifier to discriminate among an expanded set of classes with limited labeled data---is a key challenge for machine learning systems deployed in non-stationary environments. Existing approaches to the problem rely on complex model architectures and training procedures that are difficult to tune and re-use. In this paper, we present an extremely simple approach that enables the use of ordinary logistic regression classifiers for few-shot incremental learning. The key to this approach is a new family of \\emph{subspace regularization} schemes that encourage weight vectors for new classes to lie close to the subspace spanned by the weights of existing classes. When combined with pretrained convolutional feature extractors, logistic regression models trained with subspace regularization outperform specialized, state-of-the-art approaches to few-shot incremental image classification by up to 22\\% on the \\textit{mini}ImageNet dataset. Because of its simplicity, subspace regularization can be straightforwardly extended to incorporate additional background information about the new classes (including class names and descriptions specified in natural language); these further improve accuracy by up to 2\\%. Our results show that simple geometric regularization of class representations offer an effective tool for continual learning.",
        "conference": "ICLR",
        "中文标题": "子空间正则化器用于少样本类增量学习",
        "摘要翻译": "少样本类增量学习——在有限标记数据的情况下更新训练好的分类器以区分扩展的类别集合——是非平稳环境中部署的机器学习系统面临的一个关键挑战。现有解决这一问题的方法依赖于复杂的模型架构和训练过程，这些方法难以调整和重复使用。在本文中，我们提出了一种极其简单的方法，使得普通的逻辑回归分类器能够用于少样本增量学习。这种方法的关键是一种新的子空间正则化方案家族，它鼓励新类别的权重向量靠近现有类别权重张成的子空间。当与预训练的卷积特征提取器结合使用时，通过子空间正则化训练的逻辑回归模型在miniImageNet数据集上的少样本增量图像分类任务中，比专门的最先进方法高出多达22%。由于其简单性，子空间正则化可以轻松扩展以纳入关于新类别的额外背景信息（包括用自然语言指定的类别名称和描述）；这些进一步提高了准确率多达2%。我们的结果表明，对类别表示的简单几何正则化为持续学习提供了有效工具。",
        "领域": "少样本学习, 增量学习, 图像分类",
        "问题": "在有限标记数据的情况下更新训练好的分类器以区分扩展的类别集合",
        "动机": "解决非平稳环境中部署的机器学习系统面临的少样本类增量学习挑战，简化现有复杂方法",
        "方法": "提出一种新的子空间正则化方案家族，结合预训练的卷积特征提取器，使用逻辑回归模型进行少样本增量学习",
        "关键词": [
            "子空间正则化",
            "少样本学习",
            "增量学习",
            "逻辑回归",
            "图像分类"
        ],
        "涉及的技术概念": {
            "子空间正则化": "一种新的正则化方案，鼓励新类别的权重向量靠近现有类别权重张成的子空间，用于简化少样本增量学习",
            "逻辑回归": "用于少样本增量学习的分类模型，通过子空间正则化提高性能",
            "预训练的卷积特征提取器": "用于提取图像特征的预训练模型，与子空间正则化结合使用以提高分类准确率"
        },
        "success": true
    },
    {
        "order": 934,
        "title": "SUMNAS: Supernet with Unbiased Meta-Features for Neural Architecture Search",
        "html": "https://iclr.cc//virtual/2022/poster/6140",
        "abstract": "One-shot Neural Architecture Search (NAS) usually constructs an over-parameterized network, which we call a supernet, and typically adopts sharing parameters among the sub-models to improve computational efficiency. One-shot NAS often repeatedly samples sub-models from the supernet and trains them to optimize the shared parameters. However, this training strategy suffers from multi-model forgetting. Training a sampled sub-model overrides the previous knowledge learned by the other sub-models, resulting in an unfair performance evaluation between the sub-models. We propose Supernet with Unbiased Meta-Features for Neural Architecture Search (SUMNAS), a supernet learning strategy based on meta-learning to tackle the knowledge forgetting issue. During the training phase, we explicitly address the multi-model forgetting problem and help the supernet learn unbiased meta-features, independent from the sampled sub-models. Once training is over, sub-models can be instantly compared to get the overall ranking or the best sub-model. Our evaluation on the NAS-Bench-201 and MobileNet-based search space demonstrate that SUMNAS shows improved ranking ability and finds architectures whose performance is on par with existing state-of-the-art NAS algorithms.",
        "conference": "ICLR",
        "中文标题": "SUMNAS：用于神经架构搜索的具有无偏元特征的超网络",
        "摘要翻译": "一次性神经架构搜索（NAS）通常构建一个过参数化的网络，我们称之为超网络，并通常采用子模型间共享参数以提高计算效率。一次性NAS经常从超网络中重复采样子模型并训练它们以优化共享参数。然而，这种训练策略遭受多模型遗忘的问题。训练一个采样子模型会覆盖其他子模型先前学到的知识，导致子模型之间的性能评估不公平。我们提出了用于神经架构搜索的具有无偏元特征的超网络（SUMNAS），一种基于元学习的超网络学习策略，以解决知识遗忘问题。在训练阶段，我们明确解决了多模型遗忘问题，并帮助超网络学习独立于采样子模型的无偏元特征。一旦训练完成，可以立即比较子模型以获得总体排名或最佳子模型。我们在NAS-Bench-201和基于MobileNet的搜索空间上的评估表明，SUMNAS显示出改进的排名能力，并找到性能与现有最先进NAS算法相当的架构。",
        "领域": "神经架构搜索、元学习、深度学习优化",
        "问题": "解决一次性神经架构搜索中的多模型遗忘问题，实现子模型间的公平性能评估。",
        "动机": "一次性NAS训练策略导致的知识遗忘问题影响了子模型性能评估的公平性，限制了NAS算法的效率和效果。",
        "方法": "提出了一种基于元学习的超网络学习策略SUMNAS，通过训练超网络学习无偏元特征，解决多模型遗忘问题。",
        "关键词": [
            "神经架构搜索",
            "元学习",
            "超网络",
            "无偏元特征",
            "多模型遗忘"
        ],
        "涉及的技术概念": {
            "超网络": "一次性NAS中构建的过参数化网络，包含所有可能的子模型架构。",
            "元学习": "用于训练超网络学习无偏元特征的方法，使超网络能够独立于采样子模型进行学习。",
            "多模型遗忘": "在训练过程中，新采样子模型的学习覆盖其他子模型知识的现象，导致性能评估不公平。"
        },
        "success": true
    },
    {
        "order": 935,
        "title": "Superclass-Conditional Gaussian Mixture Model For Learning Fine-Grained Embeddings",
        "html": "https://iclr.cc//virtual/2022/poster/6114",
        "abstract": "Learning fine-grained embeddings is essential for extending the generalizability of models pre-trained on 'coarse' labels (e.g., animals). It is crucial to fields for which fine-grained labeling (e.g., breeds of animals) is expensive, but fine-grained prediction is desirable, such as medicine. The dilemma necessitates adaptation of a 'coarsely' pre-trained model to new tasks with a few 'finer-grained' training labels. However, coarsely supervised pre-training tends to suppress intra-class variation, which is vital for cross-granularity adaptation. In this paper, we develop a training framework underlain by a novel superclass-conditional Gaussian mixture model (SCGM). SCGM imitates the generative process of samples from hierarchies of classes through latent variable modeling of the fine-grained subclasses. The framework is agnostic to the encoders and only adds a few distribution related parameters, thus is efficient, and flexible to different domains. The model parameters are learned end-to-end by maximum-likelihood estimation via a principled Expectation-Maximization algorithm. Extensive experiments on benchmark datasets and a real-life medical dataset indicate the effectiveness of our method.",
        "conference": "ICLR",
        "中文标题": "超类条件高斯混合模型用于学习细粒度嵌入",
        "摘要翻译": "学习细粒度嵌入对于扩展基于'粗粒度'标签（如动物）预训练模型的泛化能力至关重要。这对于那些细粒度标注（如动物品种）成本高昂，但细粒度预测又非常需要的领域（如医学）尤为关键。这一困境要求将'粗粒度'预训练的模型适应到具有少量'细粒度'训练标签的新任务上。然而，粗粒度监督的预训练往往会抑制类内变异，这对于跨粒度适应至关重要。在本文中，我们开发了一个基于新型超类条件高斯混合模型（SCGM）的训练框架。SCGM通过细粒度子类的潜在变量建模，模仿了从类层次结构中生成样本的过程。该框架对编码器不可知，仅添加少量与分布相关的参数，因此高效且适用于不同领域。模型参数通过原则性的期望最大化算法进行端到端的最大似然估计学习。在基准数据集和真实医学数据集上的大量实验证明了我们方法的有效性。",
        "领域": "细粒度图像分类, 迁移学习, 医学图像分析",
        "问题": "如何将基于粗粒度标签预训练的模型适应到需要细粒度预测的新任务上",
        "动机": "解决在细粒度标注成本高昂的领域（如医学）中，如何利用少量细粒度标签扩展预训练模型的泛化能力的问题",
        "方法": "开发了一个基于超类条件高斯混合模型（SCGM）的训练框架，通过潜在变量建模模仿细粒度子类的生成过程，实现高效且灵活的跨粒度适应",
        "关键词": [
            "细粒度嵌入",
            "高斯混合模型",
            "迁移学习",
            "医学图像",
            "期望最大化算法"
        ],
        "涉及的技术概念": {
            "超类条件高斯混合模型（SCGM）": "用于模仿从类层次结构中生成样本的过程，通过潜在变量建模细粒度子类",
            "潜在变量建模": "在SCGM中用于表示细粒度子类，帮助模型捕捉类内变异",
            "期望最大化算法": "用于端到端学习模型参数，通过最大似然估计优化SCGM"
        },
        "success": true
    },
    {
        "order": 936,
        "title": "Supervision Exists Everywhere: A Data Efficient Contrastive Language-Image  Pre-training Paradigm",
        "html": "https://iclr.cc//virtual/2022/poster/6406",
        "abstract": "Recently, large-scale Contrastive Language-Image Pre-training (CLIP) has attracted unprecedented attention for its impressive zero-shot recognition ability and excellent transferability to downstream tasks. However, CLIP is quite data-hungry and requires 400M image-text pairs for pre-training, thereby restricting its adoption. This work proposes a novel training paradigm, Data efficient CLIP (DeCLIP), to alleviate this limitation. We demonstrate that by carefully utilizing the widespread supervision among the image-text pairs, our De-CLIP can learn generic visual features more efficiently. Instead of using the single image-text contrastive supervision, we fully exploit data potential through the use of (1) self-supervision within each modality; (2) multi-view supervision across modalities; (3) nearest-neighbor supervision from other similar pairs. Benefiting from intrinsic supervision, our DeCLIP-ResNet50 can achieve 60.4% zero-shot top1 accuracy on ImageNet, which is 0.8% above the CLIP-ResNet50 while using 7.1×fewer data. Our DeCLIP-ResNet50 outperforms its counterpart in 8 out of 11 visual datasets when transferred to downstream tasks. Moreover, Scaling up the model and computing also works well in our framework.",
        "conference": "ICLR",
        "中文标题": "监督无处不在：一种数据高效的对比语言-图像预训练范式",
        "摘要翻译": "最近，大规模对比语言-图像预训练（CLIP）因其令人印象深刻的零样本识别能力和对下游任务的优秀迁移性而吸引了前所未有的关注。然而，CLIP对数据的需求极大，需要4亿图像-文本对进行预训练，这限制了其应用。本研究提出了一种新的训练范式，数据高效CLIP（DeCLIP），以缓解这一限制。我们证明，通过仔细利用图像-文本对中广泛存在的监督，我们的De-CLIP可以更高效地学习通用视觉特征。与仅使用单一图像-文本对比监督不同，我们通过以下方式充分利用数据潜力：（1）每种模态内的自监督；（2）跨模态的多视角监督；（3）来自其他相似对的最近邻监督。得益于内在监督，我们的DeCLIP-ResNet50在ImageNet上可以达到60.4%的零样本top1准确率，比CLIP-ResNet50高出0.8%，同时使用的数据量减少了7.1倍。当迁移到下游任务时，我们的DeCLIP-ResNet50在11个视觉数据集中的8个上优于其对应模型。此外，在我们的框架中，扩大模型规模和计算量也表现良好。",
        "领域": "自然语言处理与视觉结合",
        "问题": "减少大规模对比语言-图像预训练（CLIP）对数据的需求",
        "动机": "CLIP需要大量数据进行预训练，限制了其广泛应用，因此需要开发更数据高效的预训练方法",
        "方法": "提出数据高效CLIP（DeCLIP），通过利用图像-文本对中的自监督、跨模态多视角监督和最近邻监督来提高数据利用效率",
        "关键词": [
            "对比学习",
            "语言-图像预训练",
            "数据高效"
        ],
        "涉及的技术概念": {
            "对比语言-图像预训练（CLIP）": "一种通过对比学习训练的语言-图像预训练模型，能够实现零样本识别和优秀的下游任务迁移性",
            "自监督学习": "在每种模态内利用数据本身的结构进行监督学习，减少对外部标注数据的依赖",
            "多视角监督": "通过跨模态的不同视角（如图像和文本）提供监督信号，增强模型的学习能力"
        },
        "success": true
    },
    {
        "order": 937,
        "title": "SURF: Semi-supervised Reward Learning with Data Augmentation for Feedback-efficient Preference-based Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6054",
        "abstract": "Preference-based reinforcement learning (RL) has shown potential for teaching agents to perform the target tasks without a costly, pre-defined reward function by learning the reward with a supervisor’s preference between the two agent behaviors. However, preference-based learning often requires a large amount of human feedback, making it difficult to apply this approach to various applications. This data-efficiency problem, on the other hand, has been typically addressed by using unlabeled samples or data augmentation techniques in the context of supervised learning. Motivated by the recent success of these approaches, we present SURF, a semi-supervised reward learning framework that utilizes a large amount of unlabeled samples with data augmentation. In order to leverage unlabeled samples for reward learning, we infer pseudo-labels of the unlabeled samples based on the confidence of the preference predictor. To further improve the label-efficiency of reward learning, we introduce a new data augmentation that temporally crops consecutive subsequences from the original behaviors. Our experiments demonstrate that our approach significantly improves the feedback-efficiency of the state-of-the-art preference-based method on a variety of locomotion and robotic manipulation tasks.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "SURF：基于数据增强的半监督奖励学习用于高效反馈的偏好强化学习",
        "摘要翻译": "基于偏好的强化学习（RL）通过利用监督者对两种代理行为偏好的学习来教授代理执行目标任务，而无需昂贵、预定义的奖励函数，已显示出潜力。然而，基于偏好的学习通常需要大量的人类反馈，这使得该方法难以应用于各种应用。另一方面，这一数据效率问题通常通过在监督学习背景下使用未标记样本或数据增强技术来解决。受这些方法最近成功的启发，我们提出了SURF，一个利用大量未标记样本和数据增强的半监督奖励学习框架。为了利用未标记样本进行奖励学习，我们基于偏好预测器的置信度推断未标记样本的伪标签。为了进一步提高奖励学习的标签效率，我们引入了一种新的数据增强方法，该方法从原始行为中时间性地裁剪连续子序列。我们的实验表明，我们的方法在各种运动和机器人操作任务上显著提高了最先进的基于偏好方法的反馈效率。",
        "领域": "强化学习、机器人操作、运动控制",
        "问题": "解决基于偏好的强化学习中需要大量人类反馈的问题，提高数据效率。",
        "动机": "减少基于偏好的强化学习对人类反馈的依赖，使其更易于应用于各种实际场景。",
        "方法": "提出SURF框架，利用未标记样本和数据增强技术进行半监督奖励学习，通过推断未标记样本的伪标签和引入新的数据增强方法来提高反馈效率。",
        "关键词": [
            "半监督学习",
            "数据增强",
            "偏好强化学习",
            "反馈效率",
            "机器人操作"
        ],
        "涉及的技术概念": {
            "半监督奖励学习": "利用未标记样本和少量标记样本进行奖励学习，减少对人类反馈的依赖。",
            "数据增强": "通过时间性裁剪原始行为的连续子序列生成新的训练样本，提高模型的泛化能力和数据效率。",
            "伪标签推断": "基于偏好预测器的置信度为未标记样本分配伪标签，扩展训练数据集。"
        }
    },
    {
        "order": 938,
        "title": "Surreal-GAN:Semi-Supervised Representation Learning via GAN for uncovering heterogeneous disease-related imaging patterns",
        "html": "https://iclr.cc//virtual/2022/poster/6944",
        "abstract": "A plethora of machine learning methods have been applied to imaging data, enabling the construction of clinically relevant imaging signatures of neurological and neuropsychiatric diseases. Oftentimes, such methods don't explicitly model the heterogeneity of disease effects, or approach it via nonlinear models that are not interpretable. Moreover, unsupervised methods may parse heterogeneity that is driven by nuisance confounding factors that affect brain structure or function, rather than heterogeneity relevant to a pathology of interest. On the other hand, semi-supervised clustering methods seek to derive a dichotomous subtype membership, ignoring the truth that disease heterogeneity spatially and temporally extends along a continuum.  To address the aforementioned limitations, herein, we propose a novel method, termed Surreal-GAN (Semi-SUpeRvised ReprEsentAtion Learning via GAN). Using cross-sectional imaging data, Surreal-GAN dissects underlying disease-related heterogeneity under the principle of semi-supervised clustering (cluster mappings from normal control to patient), proposes a continuously dimensional representation, and infers the disease severity of patients at individual level along each dimension. The model first learns a transformation function from normal control (CN) domain to the patient (PT) domain with latent variables controlling transformation directions. An inverse mapping function together with regularization on function continuity, pattern orthogonality and monotonicity was also imposed to make sure that the transformation function captures necessarily meaningful imaging patterns with clinical significance. We first validated the model through extensive semi-synthetic experiments, and then demonstrate its potential in capturing biologically plausible imaging patterns in Alzheimer's disease (AD).",
        "conference": "ICLR",
        "中文标题": "Surreal-GAN：通过GAN进行半监督表示学习以揭示异质性疾病相关成像模式",
        "摘要翻译": "大量机器学习方法已被应用于成像数据，使得构建神经学和神经精神疾病的临床相关成像特征成为可能。然而，这些方法往往没有明确模拟疾病效应的异质性，或者通过不可解释的非线性模型来接近它。此外，无监督方法可能会解析由影响大脑结构或功能的干扰混杂因素驱动的异质性，而非与感兴趣的病理相关的异质性。另一方面，半监督聚类方法试图推导出二分亚型成员资格，忽视了疾病异质性在空间和时间上沿连续体延伸的事实。为了解决上述限制，本文提出了一种名为Surreal-GAN（通过GAN进行半监督表示学习）的新方法。利用横断面成像数据，Surreal-GAN在半监督聚类的原则下（从正常对照到患者的聚类映射）剖析潜在的疾病相关异质性，提出一个连续维度表示，并在个体水平上沿每个维度推断患者的疾病严重程度。该模型首先学习一个从正常对照（CN）域到患者（PT）域的转换函数，其中潜在变量控制转换方向。还施加了一个逆映射函数以及对函数连续性、模式正交性和单调性的正则化，以确保转换函数捕获具有临床意义的必要有意义的成像模式。我们首先通过广泛的半合成实验验证了模型，然后展示了其在捕获阿尔茨海默病（AD）中生物学上可信的成像模式方面的潜力。",
        "领域": "神经影像分析、半监督学习、生成对抗网络",
        "问题": "解决神经影像数据中疾病相关异质性的建模和解释问题",
        "动机": "现有方法无法有效模拟疾病效应的异质性或通过不可解释的非线性模型处理异质性，且无监督方法可能解析与病理无关的异质性，半监督聚类方法忽视疾病异质性的连续性",
        "方法": "提出Surreal-GAN方法，通过半监督聚类原则学习从正常对照到患者的转换函数，引入逆映射函数和正则化确保转换函数捕获有临床意义的成像模式",
        "关键词": [
            "Surreal-GAN",
            "半监督学习",
            "神经影像分析",
            "疾病异质性",
            "生成对抗网络"
        ],
        "涉及的技术概念": {
            "半监督聚类": "在半监督学习框架下，通过聚类方法揭示疾病相关成像模式的异质性",
            "生成对抗网络": "用于学习从正常对照到患者域的转换函数，模拟疾病效应的异质性",
            "连续维度表示": "表示疾病严重程度的多维连续空间，允许在个体水平上评估疾病状态"
        },
        "success": true
    },
    {
        "order": 939,
        "title": "Surrogate Gap Minimization Improves Sharpness-Aware Training",
        "html": "https://iclr.cc//virtual/2022/poster/6070",
        "abstract": "The recently proposed  Sharpness-Aware  Minimization  (SAM)  improves generalization by minimizing a perturbed loss defined as the maximum loss within a neighborhood in the parameter space. However, we show that both sharp and flat minima can have a low perturbed loss, implying that SAM does not always prefer flat minima. Instead, we define a surrogate gap, a measure equivalent to the dominant eigenvalue of Hessian at a local minimum when the radius of neighborhood (to derive the perturbed loss) is small.  The surrogate gap is easy to compute and feasible for direct minimization during training. Based on the above observations, we propose Surrogate Gap Guided Sharpness-Aware Minimization (GSAM), a novel improvement over SAM with negligible computation overhead.  Conceptually, GSAM consists of two steps:  1) a gradient descent like SAM to minimize the perturbed loss, and 2) an ascent step in the orthogonal direction (after gradient decomposition) to minimize the surrogate gap and yet not affect the perturbed loss. GSAM seeks a region with both small loss (by step 1) and low sharpness (by step 2), giving rise to a model with high generalization capabilities. Theoretically, we show the convergence of GSAM and provably better generalization than SAM.Empirically, GSAM consistently improves generalization (e.g., +3.2% over SAM and +5.4% over AdamW on ImageNet top-1 accuracy for ViT-B/32). Code is released at https://sites.google.com/view/gsam-iclr22/home",
        "conference": "ICLR",
        "中文标题": "替代间隙最小化改进锐度感知训练",
        "摘要翻译": "最近提出的锐度感知最小化（SAM）通过最小化定义为参数空间邻域内最大损失的扰动损失来改善泛化能力。然而，我们发现无论是尖锐还是平坦的极小值都可能具有较低的扰动损失，这意味着SAM并不总是偏好平坦的极小值。相反，我们定义了一个替代间隙，当邻域半径（用于推导扰动损失）较小时，该间隙等同于局部极小值处Hessian矩阵的主特征值。替代间隙易于计算，并且在训练过程中适合直接最小化。基于上述观察，我们提出了替代间隙引导的锐度感知最小化（GSAM），这是对SAM的一种新颖改进，计算开销可忽略不计。从概念上讲，GSAM包括两个步骤：1）类似于SAM的梯度下降以最小化扰动损失，和2）在正交方向（梯度分解后）上的上升步骤以最小化替代间隙，同时不影响扰动损失。GSAM寻求一个既有小损失（通过步骤1）又有低锐度（通过步骤2）的区域，从而产生具有高泛化能力的模型。理论上，我们展示了GSAM的收敛性，并证明了其泛化能力优于SAM。实证上，GSAM持续改善了泛化能力（例如，在ImageNet上ViT-B/32的top-1准确率比SAM提高了3.2%，比AdamW提高了5.4%）。代码发布于https://sites.google.com/view/gsam-iclr22/home。",
        "领域": "深度学习优化、模型泛化、图像分类",
        "问题": "如何更有效地最小化模型的锐度以提高泛化能力",
        "动机": "现有的锐度感知最小化（SAM）方法不总是偏好平坦的极小值，这限制了其提高模型泛化能力的潜力",
        "方法": "提出替代间隙引导的锐度感知最小化（GSAM），通过梯度下降和正交方向上的上升步骤，同时最小化扰动损失和替代间隙",
        "关键词": [
            "锐度感知最小化",
            "替代间隙",
            "模型泛化",
            "梯度分解",
            "正交方向上升"
        ],
        "涉及的技术概念": {
            "锐度感知最小化（SAM）": "一种通过最小化参数空间邻域内最大损失来改善模型泛化能力的方法",
            "替代间隙": "一种等同于局部极小值处Hessian矩阵主特征值的度量，用于直接最小化以提高模型泛化能力",
            "梯度分解": "在GSAM中用于分离梯度方向，以便在正交方向上执行上升步骤而不影响扰动损失"
        },
        "success": true
    },
    {
        "order": 940,
        "title": "Surrogate NAS Benchmarks: Going Beyond the Limited Search Spaces of Tabular NAS Benchmarks",
        "html": "https://iclr.cc//virtual/2022/poster/6063",
        "abstract": "The most significant barrier to the advancement of Neural Architecture Search (NAS) is its demand for large computational resources, which hinders scientifically sound empirical evaluations of NAS methods. Tabular NAS benchmarks have alleviated this problem substantially, making it possible to properly evaluate NAS methods in seconds on commodity machines. However, an unintended consequence of tabular NAS benchmarks has been a focus on extremely small architectural search spaces since their construction relies on exhaustive evaluations of the space. This leads to unrealistic results that do not transfer to larger spaces. To overcome this fundamental limitation, we propose a methodology to create cheap NAS surrogate benchmarks for arbitrary search spaces. We exemplify this approach by creating surrogate NAS benchmarks on the existing tabular NAS-Bench-101 and on two widely used NAS search spaces with up to $10^{21}$ architectures ($10^{13}$ times larger than any previous tabular NAS benchmark). We show that surrogate NAS benchmarks can model the true performance of architectures better than tabular benchmarks (at a small fraction of the cost), that they lead to faithful estimates of how well different NAS methods work on the original non-surrogate benchmark, and that they can generate new scientific insight. We open-source all our code and believe that surrogate NAS benchmarks are an indispensable tool to extend scientifically sound work on NAS to large and exciting  search spaces.",
        "conference": "ICLR",
        "中文标题": "替代性神经架构搜索基准：超越表格化NAS基准的有限搜索空间",
        "摘要翻译": "神经架构搜索（NAS）发展的最大障碍是其对大量计算资源的需求，这阻碍了对NAS方法进行科学严谨的实证评估。表格化NAS基准已大幅缓解了这一问题，使得在普通机器上几秒钟内就能正确评估NAS方法成为可能。然而，表格化NAS基准的一个意外后果是由于其构建依赖于对搜索空间的详尽评估，导致了对极小的架构搜索空间的关注。这产生了不切实际的结果，无法转移到更大的空间。为了克服这一根本限制，我们提出了一种为任意搜索空间创建廉价NAS替代基准的方法。我们通过在现有的表格化NAS-Bench-101和两个广泛使用的NAS搜索空间上创建替代NAS基准来举例说明这一方法，这些搜索空间包含多达10^21个架构（比任何先前的表格化NAS基准大10^13倍）。我们展示了替代NAS基准可以比表格化基准更好地建模架构的真实性能（以极小的成本），它们能够忠实估计不同NAS方法在原始非替代基准上的表现，并且能够产生新的科学见解。我们开源了所有代码，并相信替代NAS基准是将科学严谨的NAS工作扩展到大型且令人兴奋的搜索空间不可或缺的工具。",
        "领域": "神经架构搜索、自动化机器学习、深度学习优化",
        "问题": "解决神经架构搜索（NAS）在大型搜索空间中评估方法的高计算成本问题",
        "动机": "为了扩展科学严谨的NAS研究到更大、更复杂的搜索空间，克服现有表格化NAS基准的局限性",
        "方法": "提出并实现了一种创建廉价NAS替代基准的方法，支持任意大小的搜索空间",
        "关键词": [
            "神经架构搜索",
            "替代基准",
            "搜索空间扩展",
            "计算效率",
            "开源工具"
        ],
        "涉及的技术概念": {
            "神经架构搜索（NAS）": "自动化设计神经网络架构的技术，旨在减少人工设计的工作量和提高模型性能",
            "表格化NAS基准": "通过预先评估有限搜索空间中的架构性能来加速NAS方法评估的技术",
            "替代基准": "通过建模而非详尽评估来预测架构性能的方法，显著降低评估大型搜索空间的成本"
        },
        "success": true
    },
    {
        "order": 941,
        "title": "switch-GLAT: Multilingual Parallel Machine Translation Via Code-Switch Decoder",
        "html": "https://iclr.cc//virtual/2022/poster/7033",
        "abstract": "Multilingual machine translation aims to develop a single model for multiple language directions. However, existing multilingual models based on Transformer are limited in terms of both translation performance and inference speed. In this paper, we propose switch-GLAT, a non-autoregressive multilingual machine translation model with a code-switch decoder. It can generate contextual code-switched translations for a given source sentence, and perform code-switch back-translation, greatly boosting multilingual translation performance. In addition, its inference is highly efficient thanks to its parallel decoder. Experiments show that our proposed switch-GLAT outperform the multilingual Transformer with as much as 1.16 BLEU improvement and 6.6x faster decoding speed in inference.",
        "conference": "ICLR",
        "中文标题": "switch-GLAT：通过代码切换解码器实现多语言并行机器翻译",
        "摘要翻译": "多语言机器翻译旨在开发一个适用于多种语言方向的单一模型。然而，现有的基于Transformer的多语言模型在翻译性能和推理速度方面都存在限制。本文中，我们提出了switch-GLAT，一种带有代码切换解码器的非自回归多语言机器翻译模型。它能够为给定的源句子生成上下文代码切换的翻译，并执行代码切换的反向翻译，极大地提升了多语言翻译的性能。此外，由于其并行解码器，其推理效率极高。实验表明，我们提出的switch-GLAT在多语言Transformer上的表现优于多达1.16 BLEU的提升，并且在推理中的解码速度快了6.6倍。",
        "领域": "机器翻译、多语言处理、非自回归模型",
        "问题": "现有基于Transformer的多语言机器翻译模型在翻译性能和推理速度上的限制",
        "动机": "提升多语言机器翻译的性能和推理速度",
        "方法": "提出了一种带有代码切换解码器的非自回归多语言机器翻译模型switch-GLAT，通过生成上下文代码切换的翻译和执行代码切换的反向翻译来提升性能，同时利用并行解码器提高推理效率",
        "关键词": [
            "多语言机器翻译",
            "非自回归模型",
            "代码切换解码器",
            "并行解码",
            "BLEU提升"
        ],
        "涉及的技术概念": {
            "非自回归模型": "一种不依赖于先前生成的输出步骤来预测当前步骤的模型，用于提高推理速度",
            "代码切换解码器": "能够在翻译过程中动态切换语言代码的解码器，用于生成上下文相关的多语言翻译",
            "并行解码": "同时处理多个解码步骤的技术，用于显著提高模型的推理速度"
        },
        "success": true
    },
    {
        "order": 942,
        "title": "Switch to Generalize: Domain-Switch Learning for Cross-Domain Few-Shot Classification",
        "html": "https://iclr.cc//virtual/2022/poster/5957",
        "abstract": "This paper considers few-shot learning under the cross-domain scenario. The cross-domain setting imposes a critical challenge, i.e., using very few (support) samples to generalize the already-learned model to a novel domain. We hold a hypothesis, i.e., if a deep model is capable to fast generalize itself to different domains (using very few samples) during training, it will maintain such domain generalization capacity for testing. It motivates us to propose a novel Domain-Switch Learning (DSL) framework. DSL embeds the cross-domain scenario into the training stage in a ``fast switching'' manner. Specifically, DSL uses a single domain for a training iteration and switches into another domain for the following iteration. During the switching, DSL enforces two constraints: 1) the deep model should not over-fit the domain in the current iteration and 2) the deep model should not forget the already-learned knowledge of other domains. These two constraints jointly promote fast generalization across different domains. Experimental results confirm that the cross-domain generalization capacity can be inherited from the training stage to the testing stage, validating our key hypothesis. Consequentially, DSL significantly improves cross-domain few-shot classification and sets up new state of the art.",
        "conference": "ICLR",
        "中文标题": "切换以泛化：面向跨域少样本分类的域切换学习",
        "摘要翻译": "本文探讨了跨域场景下的少样本学习问题。跨域设置提出了一个关键挑战，即使用极少量的（支持）样本来将已学习模型泛化到一个新域。我们持有一个假设，即如果一个深度模型在训练期间能够快速泛化到不同的域（使用极少量的样本），那么它将在测试阶段保持这种域泛化能力。这激励我们提出了一种新颖的域切换学习（DSL）框架。DSL以“快速切换”的方式将跨域场景嵌入到训练阶段。具体来说，DSL在每次训练迭代中使用一个域，并在接下来的迭代中切换到另一个域。在切换过程中，DSL强制执行两个约束：1）深度模型不应过度拟合当前迭代中的域；2）深度模型不应忘记其他域已学到的知识。这两个约束共同促进了不同域之间的快速泛化。实验结果证实，跨域泛化能力可以从训练阶段继承到测试阶段，验证了我们的关键假设。因此，DSL显著提高了跨域少样本分类的性能，并设立了新的技术标杆。",
        "领域": "跨域少样本学习",
        "问题": "解决在跨域场景下使用极少样本进行模型泛化的挑战",
        "动机": "探索深度模型在训练期间快速适应不同域的能力，以在测试阶段保持泛化性能",
        "方法": "提出域切换学习（DSL）框架，通过在训练阶段快速切换域并施加不过度拟合和不遗忘的约束，促进模型的跨域泛化能力",
        "关键词": [
            "跨域少样本学习",
            "域切换学习",
            "模型泛化"
        ],
        "涉及的技术概念": {
            "域切换学习（DSL）": "一种通过在训练阶段快速切换域来提升模型跨域泛化能力的框架",
            "不过度拟合约束": "确保模型在训练过程中不会过度适应当前域，保持对其他域的泛化能力",
            "不遗忘约束": "防止模型在适应新域时忘记之前学到的知识，保证知识的持续积累"
        },
        "success": true
    },
    {
        "order": 943,
        "title": "Symbolic Learning to Optimize: Towards Interpretability and Scalability",
        "html": "https://iclr.cc//virtual/2022/poster/6741",
        "abstract": "Recent studies on Learning to Optimize (L2O) suggest a promising path to automating and accelerating the optimization procedure for complicated tasks. Existing L2O models parameterize optimization rules by neural networks, and learn those numerical rules via meta-training. However, they face two common pitfalls: (1) scalability: the numerical rules represented by neural networks create extra memory overhead for applying L2O models, and limits their applicability to optimizing larger tasks; (2) interpretability: it is unclear what each L2O model has learned in its black-box optimization rule, nor is it straightforward to compare different L2O models in an explainable way. To avoid both pitfalls, this paper proves the concept that we can 'kill two birds by one stone', by introducing the powerful tool of symbolic regression to L2O. In this paper, we establish a holistic symbolic representation and analysis framework for L2O, which yields a series of insights for learnable optimizers. Leveraging our findings, we further propose a lightweight L2O model that can be meta-trained on large-scale problems and outperformed human-designed and tuned optimizers. Our work is set to supply a brand-new perspective to L2O research. Codes are available at: https://github.com/VITA-Group/Symbolic-Learning-To-Optimize.",
        "conference": "ICLR",
        "中文标题": "符号学习优化：迈向可解释性与可扩展性",
        "摘要翻译": "最近关于学习优化（L2O）的研究提出了一条自动化并加速复杂任务优化过程的有前景的路径。现有的L2O模型通过神经网络参数化优化规则，并通过元训练学习这些数值规则。然而，它们面临两个常见问题：（1）可扩展性：由神经网络表示的数值规则为应用L2O模型创造了额外的内存开销，并限制了它们对更大规模任务的优化适用性；（2）可解释性：不清楚每个L2O模型在其黑盒优化规则中学到了什么，也不容易以可解释的方式比较不同的L2O模型。为了避免这两个问题，本文证明了我们可以通过将符号回归这一强大工具引入L2O来‘一石二鸟’。在本文中，我们为L2O建立了一个全面的符号表示和分析框架，为可学习优化器提供了一系列见解。利用我们的发现，我们进一步提出了一种轻量级的L2O模型，可以在大规模问题上进行元训练，并优于人工设计和调整的优化器。我们的工作旨在为L2O研究提供一个全新的视角。代码可在https://github.com/VITA-Group/Symbolic-Learning-To-Optimize获取。",
        "领域": "优化算法、机器学习、自动化",
        "问题": "解决学习优化（L2O）模型的可扩展性和可解释性问题",
        "动机": "通过引入符号回归工具，提高L2O模型的可扩展性和可解释性，以自动化并加速复杂任务的优化过程",
        "方法": "建立一个全面的符号表示和分析框架，提出一种轻量级的L2O模型，可以在大规模问题上进行元训练",
        "关键词": [
            "符号回归",
            "学习优化",
            "可解释性",
            "可扩展性",
            "元训练"
        ],
        "涉及的技术概念": {
            "符号回归": "用于从数据中学习符号表达式，提高模型的可解释性",
            "学习优化（L2O）": "通过机器学习方法自动化和加速优化过程",
            "元训练": "在多个任务上训练模型，以提高其泛化能力和适应性"
        },
        "success": true
    },
    {
        "order": 944,
        "title": "Synchromesh: Reliable Code Generation from Pre-trained Language Models",
        "html": "https://iclr.cc//virtual/2022/poster/6709",
        "abstract": "Large pre-trained language models have been used to generate code, providing a flexible interface for synthesizing programs from natural language specifications. However, they often violate syntactic and semantic rules of their output language, limiting their practical usability. In this paper, we propose Synchromesh: a framework for substantially improving the reliability of pre-trained models for code generation. Synchromesh comprises two components. First, it retrieves few-shot examples from a training bank using Target Similarity Tuning (TST), a novel method for semantic example selection. TST learns to recognize utterances that describe similar target programs despite of differences in surface natural language features. Then, Synchromesh feeds the examples to a pre-trained language model and samples programs using Constrained Semantic Decoding (CSD): a general framework for constraining the output to a set of valid programs in the target language. CSD leverages constraints on partial outputs to sample complete correct programs, and needs neither re-training nor fine-tuning of the language model. We evaluate our methods by synthesizing code from natural language descriptions using GPT-3 and Codex in three real-world languages: SQL queries, Vega-Lite visualizations and SMCalFlow programs. These domains showcase rich constraints that CSD is able to enforce, including syntax, scoping and typing rules. Across all languages, we observe complementary gains from CSD and TST in prediction accuracy and in effectively preventing parsing, type and run-time errors.",
        "conference": "ICLR",
        "中文标题": "同步啮合：从预训练语言模型中可靠生成代码",
        "摘要翻译": "大型预训练语言模型已被用于生成代码，为从自然语言规范合成程序提供了灵活的接口。然而，它们经常违反输出语言的语法和语义规则，限制了它们的实际可用性。在本文中，我们提出了Synchromesh：一个框架，用于显著提高预训练模型在代码生成中的可靠性。Synchromesh包含两个组件。首先，它使用目标相似性调谐（TST）从训练库中检索少量示例，这是一种用于语义示例选择的新方法。TST学会识别描述相似目标程序的语句，尽管表面自然语言特征存在差异。然后，Synchromesh将这些示例输入预训练语言模型，并使用约束语义解码（CSD）采样程序：这是一个将输出约束为目标语言中一组有效程序的通用框架。CSD利用对部分输出的约束来采样完整的正确程序，既不需要重新训练也不需要微调语言模型。我们通过使用GPT-3和Codex在三种现实世界语言中从自然语言描述合成代码来评估我们的方法：SQL查询、Vega-Lite可视化和SMCalFlow程序。这些领域展示了CSD能够执行的丰富约束，包括语法、作用域和类型规则。在所有语言中，我们观察到CSD和TST在预测准确性和有效防止解析、类型和运行时错误方面的互补增益。",
        "领域": "自然语言处理与代码生成、程序合成、预训练语言模型应用",
        "问题": "提高预训练语言模型在代码生成中的可靠性，避免违反语法和语义规则",
        "动机": "预训练语言模型在代码生成时经常违反输出语言的规则，限制了其实际应用",
        "方法": "提出Synchromesh框架，包含目标相似性调谐（TST）和约束语义解码（CSD）两个组件，以提高代码生成的可靠性和准确性",
        "关键词": [
            "代码生成",
            "预训练语言模型",
            "约束语义解码",
            "目标相似性调谐",
            "程序合成"
        ],
        "涉及的技术概念": {
            "目标相似性调谐（TST）": "一种新颖的语义示例选择方法，用于从训练库中检索与目标程序语义相似的示例",
            "约束语义解码（CSD）": "一种通用框架，用于将语言模型的输出约束为目标语言中的有效程序集合，无需重新训练或微调模型",
            "预训练语言模型": "大型语言模型，如GPT-3和Codex，用于从自然语言描述生成代码"
        },
        "success": true
    },
    {
        "order": 945,
        "title": "Tackling the Generative Learning Trilemma with Denoising Diffusion GANs",
        "html": "https://iclr.cc//virtual/2022/poster/7183",
        "abstract": "A wide variety of deep generative models has been developed in the past decade. Yet, these models often struggle with simultaneously addressing three key requirements including: high sample quality, mode coverage, and fast sampling. We call the challenge imposed by these requirements the generative learning trilemma, as the existing models often trade some of them for others. Particularly, denoising diffusion models have shown impressive sample quality and diversity, but their expensive sampling does not yet allow them to be applied in many real-world applications. In this paper, we argue that slow sampling in these models is fundamentally attributed to the Gaussian assumption in the denoising step which is justified only for small step sizes. To enable denoising with large steps, and hence, to reduce the total number of denoising steps, we propose to model the denoising distribution using a complex multimodal distribution. We introduce denoising diffusion generative adversarial networks (denoising diffusion GANs) that model each denoising step using a multimodal conditional GAN. Through extensive evaluations, we show that denoising diffusion GANs obtain sample quality and diversity competitive with original diffusion models while being 2000$\\times$ faster on the CIFAR-10 dataset. Compared to traditional GANs, our model exhibits better mode coverage and sample diversity. To the best of our knowledge, denoising diffusion GAN is the first model that reduces sampling cost in diffusion models to an extent that allows them to be applied to real-world applications inexpensively.",
        "conference": "ICLR",
        "中文标题": "利用去噪扩散生成对抗网络解决生成学习三难问题",
        "摘要翻译": "过去十年中，已经开发出了多种深度生成模型。然而，这些模型往往难以同时满足三个关键要求：高样本质量、模式覆盖和快速采样。我们将这些要求所构成的挑战称为生成学习三难问题，因为现有模型常常需要在它们之间做出权衡。特别是，去噪扩散模型在样本质量和多样性方面表现出色，但其昂贵的采样成本使得它们尚未能在许多实际应用中得到应用。在本文中，我们认为这些模型中采样速度慢的根本原因在于去噪步骤中的高斯假设，这一假设仅在小步长下成立。为了实现大步长的去噪，从而减少总的去噪步骤数，我们提出使用复杂的多模态分布来建模去噪分布。我们引入了去噪扩散生成对抗网络（去噪扩散GANs），该网络使用多模态条件GAN来建模每个去噪步骤。通过广泛的评估，我们展示了去噪扩散GANs在CIFAR-10数据集上获得了与原始扩散模型相媲美的样本质量和多样性，同时采样速度快了2000倍。与传统GANs相比，我们的模型表现出更好的模式覆盖和样本多样性。据我们所知，去噪扩散GAN是第一个将扩散模型的采样成本降低到可以经济地应用于实际应用中的模型。",
        "领域": "生成对抗网络、图像生成、深度学习",
        "问题": "解决生成模型在同时满足高样本质量、模式覆盖和快速采样这三个关键要求上的挑战",
        "动机": "现有生成模型在满足高样本质量、模式覆盖和快速采样这三个关键要求上存在权衡，特别是去噪扩散模型采样成本高，限制了其在实际应用中的使用",
        "方法": "提出使用复杂的多模态分布建模去噪分布，引入去噪扩散生成对抗网络（去噪扩散GANs），通过多模态条件GAN建模每个去噪步骤，以减少总的去噪步骤数",
        "关键词": [
            "生成对抗网络",
            "去噪扩散模型",
            "快速采样",
            "模式覆盖",
            "样本质量"
        ],
        "涉及的技术概念": {
            "去噪扩散模型": "一种生成模型，通过逐步去噪过程生成样本，以高样本质量和多样性著称",
            "生成对抗网络（GANs）": "一种通过生成器和判别器对抗训练生成样本的模型，能够生成高质量的样本",
            "多模态条件GAN": "一种能够建模复杂多模态分布的GAN变体，用于在去噪步骤中更有效地建模去噪分布"
        },
        "success": true
    },
    {
        "order": 946,
        "title": "TAda! Temporally-Adaptive Convolutions for Video Understanding",
        "html": "https://iclr.cc//virtual/2022/poster/6801",
        "abstract": "Spatial convolutions are widely used in numerous deep video models. It fundamentally assumes spatio-temporal invariance, i.e., using shared weights for every location in different frames. This work presents Temporally-Adaptive Convolutions (TAdaConv) for video understanding, which shows that adaptive weight calibration along the temporal dimension is an efficient way to facilitate modelling complex temporal dynamics in videos. Specifically, TAdaConv empowers the spatial convolutions with temporal modelling abilities by calibrating the convolution weights for each frame according to its local and global temporal context. Compared to previous temporal modelling operations, TAdaConv is more efficient as it operates over the convolution kernels instead of the features, whose dimension is an order of magnitude smaller than the spatial resolutions. Further, the kernel calibration brings an increased model capacity. We construct TAda2D and TAdaConvNeXt networks by replacing the 2D convolutions in ResNet and ConvNeXt with TAdaConv, which leads to at least on par or better performance compared to state-of-the-art approaches on multiple video action recognition and localization benchmarks. We also demonstrate that as a readily plug-in operation with negligible computation overhead, TAdaConv can effectively improve many existing video models with a convincing margin.",
        "conference": "ICLR",
        "中文标题": "TAda！时间自适应卷积用于视频理解",
        "摘要翻译": "空间卷积在众多深度视频模型中被广泛使用。它基本上假设了时空不变性，即在不同的帧中对每个位置使用共享的权重。这项工作提出了用于视频理解的时间自适应卷积（TAdaConv），表明沿时间维度进行自适应权重校准是促进建模视频中复杂时间动态的有效方式。具体来说，TAdaConv通过根据每帧的局部和全局时间上下文校准卷积权重，赋予空间卷积时间建模能力。与之前的时间建模操作相比，TAdaConv更高效，因为它操作的是卷积核而不是特征，其维度比空间分辨率小一个数量级。此外，核校准带来了模型容量的增加。我们通过将ResNet和ConvNeXt中的2D卷积替换为TAdaConv，构建了TAda2D和TAdaConvNeXt网络，这在多个视频动作识别和定位基准测试中至少达到或优于最先进方法的性能。我们还证明，作为一种即插即用的操作，计算开销可忽略不计，TAdaConv可以有效地改善许多现有的视频模型，并有令人信服的提升。",
        "领域": "视频动作识别",
        "问题": "如何有效建模视频中的复杂时间动态",
        "动机": "传统的空间卷积假设时空不变性，限制了模型对视频中时间动态的建模能力",
        "方法": "提出时间自适应卷积（TAdaConv），通过沿时间维度校准卷积权重来增强空间卷积的时间建模能力",
        "关键词": [
            "时间自适应卷积",
            "视频理解",
            "动作识别"
        ],
        "涉及的技术概念": {
            "时间自适应卷积（TAdaConv）": "通过校准卷积权重沿时间维度增强空间卷积的时间建模能力",
            "时空不变性": "传统空间卷积的基本假设，即在不同的帧中对每个位置使用共享的权重",
            "核校准": "通过调整卷积核的权重来增加模型容量和效率"
        },
        "success": true
    },
    {
        "order": 947,
        "title": "Taming Sparsely Activated Transformer with Stochastic Experts",
        "html": "https://iclr.cc//virtual/2022/poster/6179",
        "abstract": "Sparsely activated models (SAMs), such as Mixture-of-Experts (MoE), can easily scale to have outrageously large amounts of parameters without significant increase in computational cost. However, SAMs are reported to be parameter inefficient such that larger models do not always lead to better performance. While most on-going research focuses on improving SAMs models by exploring methods of routing inputs to experts, our analysis reveals that such research might not lead to the solution we expect, i.e., the commonly-used routing methods based on gating mechanisms do not work better than randomly routing inputs to experts. In this paper, we propose a new expert-based model, THOR ($\\underline{\\textbf{T}}$ransformer wit$\\underline{\\textbf{H}}$ St$\\underline{\\textbf{O}}$chastic Expe$\\underline{\\textbf{R}}$ts). Unlike classic expert-based models, such as the Switch Transformer, experts in THOR are randomly activated for each input during training and inference. THOR models are trained using a consistency regularized loss, where experts learn not only from training data but also from other experts as teachers, such that all the experts make consistent predictions.  We validate the effectiveness of THOR on machine translation tasks. Results show that THOR models are more parameter efficient in that they significantly outperform the Transformer and MoE models across various settings. For example, in multilingual translation, THOR outperforms the Switch Transformer by 2 BLEU scores, and obtains the same BLEU score as that of a state-of-the-art MoE model that is 18 times larger. Our code is publicly available at: https://github.com/microsoft/Stochastic-Mixture-of-Experts.",
        "conference": "ICLR",
        "中文标题": "驯服稀疏激活的Transformer与随机专家",
        "摘要翻译": "稀疏激活模型（SAMs），如专家混合（MoE），可以轻松扩展到拥有极其大量的参数，而不会显著增加计算成本。然而，据报道，SAMs在参数效率上表现不佳，以至于更大的模型并不总是带来更好的性能。虽然大多数正在进行的研究通过探索将输入路由到专家的方法来改进SAMs模型，但我们的分析表明，这样的研究可能不会带来我们期望的解决方案，即基于门控机制的常用路由方法并不比随机将输入路由到专家表现得更好。在本文中，我们提出了一种新的基于专家的模型，THOR（带有随机专家的Transformer）。与经典的基于专家的模型（如Switch Transformer）不同，THOR中的专家在训练和推理过程中对每个输入随机激活。THOR模型使用一致性正则化损失进行训练，其中专家不仅从训练数据中学习，还从其他专家作为教师那里学习，以便所有专家做出一致的预测。我们在机器翻译任务上验证了THOR的有效性。结果表明，THOR模型在参数效率上更高，因为它们在各种设置下显著优于Transformer和MoE模型。例如，在多语言翻译中，THOR比Switch Transformer高出2个BLEU分数，并且与一个比它大18倍的最先进MoE模型获得相同的BLEU分数。我们的代码公开在：https://github.com/microsoft/Stochastic-Mixture-of-Experts。",
        "领域": "自然语言处理与视觉结合、机器翻译、模型优化",
        "问题": "解决稀疏激活模型（SAMs）参数效率低下的问题",
        "动机": "探索更有效的模型训练方法，以提高稀疏激活模型的性能而不增加计算成本",
        "方法": "提出THOR模型，采用随机激活专家和一致性正则化损失进行训练",
        "关键词": [
            "稀疏激活模型",
            "随机专家",
            "一致性正则化",
            "机器翻译",
            "参数效率"
        ],
        "涉及的技术概念": {
            "稀疏激活模型（SAMs）": "一种可以扩展到大量参数而不显著增加计算成本的模型",
            "专家混合（MoE）": "一种特定类型的稀疏激活模型，通过多个专家处理不同输入",
            "一致性正则化损失": "用于训练THOR模型的损失函数，确保所有专家做出一致的预测"
        },
        "success": true
    },
    {
        "order": 948,
        "title": "TAMP-S2GCNets: Coupling Time-Aware Multipersistence Knowledge Representation with Spatio-Supra Graph Convolutional Networks for Time-Series Forecasting",
        "html": "https://iclr.cc//virtual/2022/poster/7162",
        "abstract": "Graph Neural Networks (GNNs) are proven to be a powerful machinery for learning complex dependencies in multivariate spatio-temporal processes. However, most existing GNNs have inherently static architectures, and as a result, do not explicitly account for time dependencies of the encoded knowledge and are limited in their ability to simultaneously infer latent time-conditioned relations among entities. We postulate that such hidden time-conditioned properties may be captured by the tools of multipersistence, i.e, a emerging machinery in topological data analysis which allows us to quantify dynamics of the data shape along multiple geometric dimensions.  We make the first step toward integrating the two rising research directions, that is, time-aware deep learning and multipersistence, and propose a new model, Time-Aware Multipersistence Spatio-Supra Graph Convolutional Network (TAMP-S2GCNets). We summarize inherent time-conditioned topological properties of the data as time-aware multipersistence Euler-Poincar\\'e surface and prove its stability. We then construct a supragraph convolution module which simultaneously accounts for the extracted intra- and inter- spatio-temporal dependencies in the data. Our extensive experiments on highway traffic flow, Ethereum token prices, and COVID-19 hospitalizations demonstrate that TAMP-S2GCNets outperforms the state-of-the-art tools in multivariate time series forecasting tasks.",
        "conference": "ICLR",
        "中文标题": "TAMP-S2GCNets：将时间感知多持久性知识表示与空间超图卷积网络耦合用于时间序列预测",
        "摘要翻译": "图神经网络（GNNs）已被证明是学习多元时空过程中复杂依赖关系的强大工具。然而，大多数现有的GNNs具有固有的静态架构，因此没有明确考虑编码知识的时间依赖性，并且在同时推断实体间潜在的时间条件关系方面能力有限。我们假设这种隐藏的时间条件特性可以通过多持久性工具来捕捉，即拓扑数据分析中的一种新兴工具，它允许我们量化数据形状沿多个几何维度的动态。我们迈出了整合两个新兴研究方向的第一步，即时间感知深度学习和多持久性，并提出了一个新模型——时间感知多持久性空间超图卷积网络（TAMP-S2GCNets）。我们将数据固有的时间条件拓扑特性总结为时间感知多持久性欧拉-庞加莱曲面，并证明了其稳定性。然后，我们构建了一个超图卷积模块，该模块同时考虑了数据中提取的空间和时间内及空间和时间间的依赖关系。我们在高速公路交通流量、以太坊代币价格和COVID-19住院情况上的大量实验表明，TAMP-S2GCNets在多元时间序列预测任务中优于最先进的工具。",
        "领域": "时空数据分析, 图神经网络, 时间序列预测",
        "问题": "解决现有图神经网络在时间序列预测中无法有效捕捉时间依赖性和时间条件关系的问题",
        "动机": "探索如何利用多持久性工具来捕捉和量化数据的时间条件特性，以提高时间序列预测的准确性",
        "方法": "提出了一种新的模型TAMP-S2GCNets，该模型整合了时间感知深度学习和多持久性技术，通过构建超图卷积模块来同时处理空间和时间内及空间和时间间的依赖关系",
        "关键词": [
            "时间序列预测",
            "图神经网络",
            "多持久性",
            "超图卷积",
            "时空数据分析"
        ],
        "涉及的技术概念": {
            "多持久性": "一种在拓扑数据分析中用于量化数据形状沿多个几何维度动态的工具，用于捕捉数据的时间条件特性",
            "超图卷积模块": "一种同时处理空间和时间内及空间和时间间依赖关系的模块，用于提高模型对复杂时空数据的理解能力",
            "欧拉-庞加莱曲面": "用于总结数据固有的时间条件拓扑特性的数学工具，证明了模型在处理时间序列数据时的稳定性"
        },
        "success": true
    },
    {
        "order": 949,
        "title": "TAPEX: Table Pre-training via Learning a Neural SQL Executor",
        "html": "https://iclr.cc//virtual/2022/poster/6280",
        "abstract": "Recent progress in language model pre-training has achieved a great success via leveraging large-scale unstructured textual data. However, it is still a challenge to apply pre-training on structured tabular data due to the absence of large-scale high-quality tabular data. In this paper, we propose TAPEX to show that table pre-training can be achieved by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries and their execution outputs. TAPEX addresses the data scarcity challenge via guiding the language model to mimic a SQL executor on the diverse, large-scale and high-quality synthetic corpus. We evaluate TAPEX on four benchmark datasets. Experimental results demonstrate that TAPEX outperforms previous table pre-training approaches by a large margin and achieves new state-of-the-art results on all of them. This includes the improvements on the weakly-supervised WikiSQL denotation accuracy to 89.5% (+2.3%), the WikiTableQuestions denotation accuracy to 57.5% (+4.8%), the SQA denotation accuracy to 74.5% (+3.5%), and the TabFact accuracy to 84.2% (+3.2%). To our knowledge, this is the first work to exploit table pre-training via synthetic executable programs and to achieve new state-of-the-art results on various downstream tasks. Our code can be found at https://github.com/microsoft/Table-Pretraining.",
        "conference": "ICLR",
        "中文标题": "TAPEX：通过学习神经SQL执行器进行表格预训练",
        "摘要翻译": "语言模型预训练的最新进展通过利用大规模非结构化文本数据取得了巨大成功。然而，由于缺乏大规模高质量的表格数据，将预训练应用于结构化表格数据仍然是一个挑战。在本文中，我们提出了TAPEX，以表明通过学习一个神经SQL执行器在合成语料库上进行表格预训练是可行的，该合成语料库是通过自动合成可执行的SQL查询及其执行输出获得的。TAPEX通过引导语言模型在多样化、大规模且高质量的合成语料库上模仿SQL执行器，解决了数据稀缺的挑战。我们在四个基准数据集上评估了TAPEX。实验结果表明，TAPEX大幅优于之前的表格预训练方法，并在所有这些数据集上实现了新的最先进结果。这包括将弱监督WikiSQL表示准确率提高到89.5%（+2.3%），WikiTableQuestions表示准确率提高到57.5%（+4.8%），SQA表示准确率提高到74.5%（+3.5%），以及TabFact准确率提高到84.2%（+3.2%）。据我们所知，这是第一个通过合成可执行程序利用表格预训练并在各种下游任务上实现新最先进结果的工作。我们的代码可以在https://github.com/microsoft/Table-Pretraining找到。",
        "领域": "自然语言处理与视觉结合、表格数据理解、SQL查询处理",
        "问题": "如何有效地对结构化表格数据进行预训练，以解决数据稀缺的问题。",
        "动机": "探索通过合成可执行SQL查询及其执行输出来生成大规模高质量表格数据的方法，以支持表格数据的预训练。",
        "方法": "提出TAPEX方法，通过学习神经SQL执行器在合成语料库上进行表格预训练，解决了数据稀缺的挑战。",
        "关键词": [
            "表格预训练",
            "神经SQL执行器",
            "合成语料库",
            "数据稀缺",
            "下游任务"
        ],
        "涉及的技术概念": {
            "神经SQL执行器": "在合成语料库上训练的模型，用于模仿SQL查询的执行过程，支持表格数据的预训练。",
            "合成语料库": "通过自动合成可执行的SQL查询及其执行输出生成的大规模高质量表格数据，用于预训练。",
            "表格预训练": "利用大规模表格数据对语言模型进行预训练，以提高在表格相关任务上的性能。"
        },
        "success": true
    },
    {
        "order": 950,
        "title": "Target-Side Input Augmentation for Sequence to Sequence Generation",
        "html": "https://iclr.cc//virtual/2022/poster/5922",
        "abstract": "Autoregressive sequence generation, a prevalent task in machine learning and natural language processing, generates every target token conditioned on both a source input and previously generated target tokens. Previous data augmentation methods, which have been shown to be effective for the task, mainly enhance source inputs (e.g., injecting noise into the source sequence by random swapping or masking, back translation, etc.) while overlooking the target-side augmentation. In this work, we propose a target-side augmentation method for sequence generation. In training, we use the decoder output probability distributions as soft indicators, which are multiplied with target token embeddings, to build pseudo tokens. These soft pseudo tokens are then used as target tokens to enhance the training. We conduct comprehensive experiments on various sequence generation tasks, including dialog generation, machine translation, and abstractive summarization. Without using any extra labeled data or introducing additional model parameters, our method significantly outperforms strong baselines. The code is available at https://github.com/TARGET-SIDE-DATA-AUG/TSDASG.",
        "conference": "ICLR",
        "中文标题": "序列到序列生成中的目标端输入增强",
        "摘要翻译": "自回归序列生成是机器学习和自然语言处理中的一项普遍任务，它根据源输入和先前生成的目标标记生成每一个目标标记。以往的数据增强方法主要增强源输入（例如，通过随机交换或掩码、回译等方式向源序列注入噪声），而忽视了目标端的增强。在这项工作中，我们提出了一种用于序列生成的目标端增强方法。在训练中，我们使用解码器输出的概率分布作为软指标，与目标标记嵌入相乘，以构建伪标记。这些软伪标记随后被用作目标标记以增强训练。我们在多种序列生成任务上进行了全面实验，包括对话生成、机器翻译和抽象摘要。在不使用任何额外标记数据或引入额外模型参数的情况下，我们的方法显著优于强基线。代码可在https://github.com/TARGET-SIDE-DATA-AUG/TSDASG获取。",
        "领域": "自然语言处理与视觉结合",
        "问题": "如何在不增加额外标记数据或模型参数的情况下，提高序列生成任务的性能",
        "动机": "以往的数据增强方法主要关注源输入的增强，忽视了目标端的增强潜力，本研究旨在探索目标端增强的有效性",
        "方法": "提出了一种目标端增强方法，通过解码器输出的概率分布与目标标记嵌入相乘构建伪标记，用于训练增强",
        "关键词": [
            "序列生成",
            "目标端增强",
            "伪标记"
        ],
        "涉及的技术概念": {
            "自回归序列生成": "一种序列生成方法，每个目标标记的生成依赖于源输入和之前生成的目标标记",
            "目标端增强": "通过增强目标端输入来提高模型性能的方法，区别于传统的源输入增强",
            "伪标记": "通过解码器输出的概率分布与目标标记嵌入相乘构建的标记，用于训练过程中的数据增强"
        },
        "success": true
    },
    {
        "order": 951,
        "title": "Task Affinity with Maximum Bipartite Matching in Few-Shot Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6214",
        "abstract": "We propose an asymmetric affinity score for representing the complexity of utilizing the knowledge of one task for learning another one. Our method is based on the maximum bipartite matching algorithm and utilizes the Fisher Information matrix. We provide theoretical analyses demonstrating that the proposed score is mathematically well-defined, and subsequently use the affinity score to propose a novel algorithm for the few-shot learning problem. In particular, using this score, we find relevant training data labels to the test data and leverage the discovered relevant data for episodically fine-tuning a few-shot model. Results on various few-shot benchmark datasets demonstrate the efficacy of the proposed approach by improving the classification accuracy over the state-of-the-art methods even when using smaller models.",
        "conference": "ICLR",
        "中文标题": "小样本学习中的任务亲缘性与最大二分图匹配",
        "摘要翻译": "我们提出了一种非对称的亲缘性评分，用于表示利用一个任务的知识学习另一个任务的复杂性。我们的方法基于最大二分图匹配算法，并利用费舍尔信息矩阵。我们提供了理论分析，证明所提出的评分在数学上是定义良好的，随后利用这一亲缘性评分提出了一种针对小样本学习问题的新算法。特别是，利用这一评分，我们找到了与测试数据相关的训练数据标签，并利用发现的相关数据进行小样本模型的周期性微调。在各种小样本基准数据集上的结果表明，即使使用较小的模型，所提出的方法也能通过提高分类准确率来超越最先进的方法。",
        "领域": "小样本学习、迁移学习、图像分类",
        "问题": "如何在小样本学习中有效利用不同任务间的知识迁移",
        "动机": "探索和量化不同任务间知识迁移的复杂性，以提高小样本学习的效率和准确性",
        "方法": "基于最大二分图匹配算法和费舍尔信息矩阵，提出一种非对称亲缘性评分，并利用该评分设计小样本学习算法",
        "关键词": [
            "小样本学习",
            "任务亲缘性",
            "最大二分图匹配",
            "费舍尔信息矩阵",
            "模型微调"
        ],
        "涉及的技术概念": {
            "最大二分图匹配算法": "用于计算任务间的亲缘性评分，优化任务间知识迁移的匹配过程",
            "费舍尔信息矩阵": "用于量化任务间知识迁移的复杂性，为亲缘性评分提供理论基础",
            "周期性微调": "利用发现的与测试数据相关的训练数据，对小样本模型进行周期性调整以提高性能"
        },
        "success": true
    },
    {
        "order": 952,
        "title": "Task-Induced Representation Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6090",
        "abstract": "In this work, we evaluate the effectiveness of representation learning approaches for decision making in visually complex environments. Representation learning is essential for effective reinforcement learning (RL) from high-dimensional in- puts. Unsupervised representation learning approaches based on reconstruction, prediction or contrastive learning have shown substantial learning efficiency gains. Yet, they have mostly been evaluated in clean laboratory or simulated settings. In contrast, real environments are visually complex and contain substantial amounts of clutter and distractors. Unsupervised representations will learn to model such distractors, potentially impairing the agent’s learning efficiency. In contrast, an alternative class of approaches, which we call task-induced representation learning, leverages task information such as rewards or demonstrations from prior tasks to focus on task-relevant parts of the scene and ignore distractors. We investi- gate the effectiveness of unsupervised and task-induced representation learning approaches on four visually complex environments, from Distracting DMControl to the CARLA driving simulator. For both, RL and imitation learning, we find that representation learning generally improves sample efficiency on unseen tasks even in visually complex scenes and that task-induced representations can double learning efficiency compared to unsupervised alternatives.",
        "conference": "ICLR",
        "中文标题": "任务诱导的表示学习",
        "摘要翻译": "在这项工作中，我们评估了表示学习方法在视觉复杂环境中决策制定的有效性。表示学习对于从高维输入中进行有效的强化学习（RL）至关重要。基于重建、预测或对比学习的无监督表示学习方法已显示出显著的学习效率提升。然而，它们大多在干净的实验室或模拟环境中进行评估。相比之下，真实环境视觉复杂，包含大量杂乱和干扰物。无监督表示将学习建模这些干扰物，可能会损害代理的学习效率。相反，另一类方法，我们称之为任务诱导的表示学习，利用来自先前任务的任务信息（如奖励或演示）来关注场景中与任务相关的部分并忽略干扰物。我们在四个视觉复杂的环境中研究了无监督和任务诱导的表示学习方法的有效性，从Distracting DMControl到CARLA驾驶模拟器。对于RL和模仿学习，我们发现表示学习通常能提高在未见任务上的样本效率，即使在视觉复杂的场景中也是如此，并且任务诱导的表示可以将学习效率提高一倍，与无监督替代方案相比。",
        "领域": "强化学习、模仿学习、自动驾驶",
        "问题": "在视觉复杂环境中，如何提高强化学习和模仿学习的样本效率和决策制定的有效性。",
        "动机": "解决无监督表示学习方法在视觉复杂环境中因建模干扰物而可能损害学习效率的问题。",
        "方法": "提出并评估任务诱导的表示学习方法，利用任务信息（如奖励或演示）来关注任务相关部分，忽略干扰物。",
        "关键词": [
            "表示学习",
            "强化学习",
            "模仿学习",
            "视觉复杂环境",
            "任务诱导"
        ],
        "涉及的技术概念": {
            "表示学习": "从高维输入中学习有效表示以支持决策制定的技术。",
            "强化学习": "一种通过与环境交互学习最优行为策略的机器学习方法。",
            "任务诱导的表示学习": "利用任务信息（如奖励或演示）来学习关注任务相关部分、忽略干扰物的表示学习方法。"
        },
        "success": true
    },
    {
        "order": 953,
        "title": "Task Relatedness-Based Generalization Bounds for Meta Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6485",
        "abstract": "Supposing the $n$ training tasks and the new task are sampled from the same environment, traditional meta learning theory derives an error bound on the expected loss over the new task in terms of the empirical training loss, uniformly over the set of all hypothesis spaces. However, there is still little research on how the relatedness of these tasks can affect the full utilization of all $mn$ training data (with $m$ examples per task). In this paper, we propose to address this problem by defining a new notion of task relatedness according to the existence of the bijective transformation between two tasks. A novel generalization bound of $\\mathcal{O}(\\frac{1}{\\sqrt{mn}})$ for meta learning is thus derived by exploiting the proposed task relatedness. Moreover, when investigating a special branch of meta learning that involves representation learning with deep neural networks, we establish spectrally-normalized bounds for both classification and regression problems. Finally, we demonstrate that the relatedness requirement between two tasks is satisfied when the sample space possesses the completeness and separability properties, validating the rationality and applicability of our proposed task-relatedness measure.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "基于任务相关性的元学习泛化界限",
        "摘要翻译": "假设n个训练任务和新任务是从同一环境中采样的，传统的元学习理论在所有假设空间集合上均匀地根据经验训练损失，推导出新任务上期望损失的误差界限。然而，关于这些任务的相关性如何影响所有mn个训练数据（每个任务m个例子）的充分利用，目前仍鲜有研究。在本文中，我们提出通过根据两个任务之间存在双射变换来定义任务相关性的新概念，从而解决这一问题。通过利用提出的任务相关性，我们推导出了一个新颖的元学习泛化界限O(1/√mn)。此外，在研究涉及深度神经网络表示学习的元学习特殊分支时，我们为分类和回归问题建立了谱归一化界限。最后，我们证明了当样本空间具有完备性和可分性属性时，两个任务之间的相关性要求得到满足，验证了我们提出的任务相关性度量的合理性和适用性。",
        "领域": "元学习、表示学习、深度学习理论",
        "问题": "如何利用任务间的相关性来更有效地利用所有训练数据，以提高元学习的泛化能力。",
        "动机": "探索任务相关性对元学习中数据利用效率的影响，并提出新的任务相关性度量方法以提高泛化性能。",
        "方法": "定义基于双射变换的任务相关性新概念，并利用这一概念推导出新的泛化界限；针对深度神经网络表示学习的特殊情况，建立谱归一化界限。",
        "关键词": [
            "元学习",
            "任务相关性",
            "泛化界限",
            "表示学习",
            "深度神经网络"
        ],
        "涉及的技术概念": {
            "任务相关性": "根据两个任务之间存在双射变换来定义，用于衡量任务间的相似性，影响数据利用效率和泛化性能。",
            "泛化界限": "通过分析任务相关性推导出的理论界限，用于评估元学习模型在新任务上的预期性能。",
            "谱归一化": "在深度神经网络表示学习中应用的技术，用于控制模型的复杂度，提高泛化能力。"
        }
    },
    {
        "order": 954,
        "title": "Temporal Alignment Prediction for Supervised Representation Learning and Few-Shot Sequence Classification",
        "html": "https://iclr.cc//virtual/2022/poster/6429",
        "abstract": "Explainable distances for sequence data depend on temporal alignment to tackle sequences with different lengths and local variances. Most sequence alignment methods infer the optimal alignment by solving an optimization problem under pre-defined feasible alignment constraints, which not only is time-consuming, but also makes end-to-end sequence learning intractable. In this paper, we propose a learnable sequence distance called Temporal Alignment Prediction (TAP). TAP employs a lightweight convolutional neural network to directly predict the optimal alignment between two sequences, so that only straightforward calculations are required and no optimization is involved in inference. TAP can be applied in different distance-based machine learning tasks. For supervised sequence representation learning, we show that TAP trained with various metric learning losses achieves completive performances with much faster inference speed. For few-shot action classification, we apply TAP as the distance measure in the metric learning-based episode-training paradigm. This simple strategy achieves comparable results with state-of-the-art few-shot action recognition methods.",
        "conference": "ICLR",
        "中文标题": "时序对齐预测在监督表示学习与小样本序列分类中的应用",
        "摘要翻译": "序列数据的可解释距离依赖于时序对齐来处理长度不同和局部变化的序列。大多数序列对齐方法通过解决预定义可行对齐约束下的优化问题来推断最优对齐，这不仅耗时，而且使得端到端的序列学习变得难以处理。本文提出了一种称为时序对齐预测（TAP）的可学习序列距离。TAP采用轻量级卷积神经网络直接预测两个序列之间的最优对齐，因此在推理过程中仅需简单计算，无需涉及优化。TAP可应用于不同的基于距离的机器学习任务。对于监督序列表示学习，我们展示了TAP与各种度量学习损失训练相结合，能够以更快的推理速度达到竞争性性能。对于小样本动作分类，我们将TAP作为度量学习基于情节训练范式中的距离度量。这一简单策略与最先进的小样本动作识别方法相比，取得了可比较的结果。",
        "领域": "时序数据分析、小样本学习、动作识别",
        "问题": "解决序列数据因长度不同和局部变化导致的时序对齐问题，以及优化现有方法耗时且不利于端到端学习的问题。",
        "动机": "开发一种更高效、更直接的时序对齐方法，以支持快速的序列数据分析和学习。",
        "方法": "提出了一种称为时序对齐预测（TAP）的方法，使用轻量级卷积神经网络直接预测序列间的最优对齐，避免了传统优化方法的耗时问题。",
        "关键词": [
            "时序对齐预测",
            "监督表示学习",
            "小样本序列分类",
            "度量学习",
            "动作识别"
        ],
        "涉及的技术概念": {
            "时序对齐预测（TAP）": "一种使用轻量级卷积神经网络直接预测两个序列间最优对齐的方法，旨在简化序列对齐过程。",
            "度量学习": "在监督序列表示学习中，通过优化模型以学习数据间的距离度量，提升模型性能。",
            "小样本学习": "在数据稀缺的情况下，通过少量样本学习有效的模型，应用于如小样本动作分类等任务。"
        },
        "success": true
    },
    {
        "order": 955,
        "title": "Temporal Efficient Training of Spiking Neural Network via Gradient Re-weighting",
        "html": "https://iclr.cc//virtual/2022/poster/6033",
        "abstract": "Recently, brain-inspired spiking neuron networks (SNNs) have attracted widespread research interest because of their event-driven and energy-efficient characteristics. It is difficult to efficiently train deep SNNs due to the non-differentiability of its activation function, which disables the typically used gradient descent approaches for traditional artificial neural networks (ANNs). Although the adoption of surrogate gradient (SG) formally allows for the back-propagation of losses, the discrete spiking mechanism actually differentiates the loss landscape of SNNs from that of ANNs, failing the surrogate gradient methods to achieve comparable accuracy as for ANNs. In this paper, we first analyze why the current direct training approach with surrogate gradient results in SNNs with poor generalizability. Then we introduce the temporal efficient training (TET) approach to compensate for the loss of momentum in the gradient descent with SG so that the training process can converge into flatter minima with better generalizability. Meanwhile, we demonstrate that TET improves the temporal scalability of SNN and induces a temporal inheritable training for acceleration. Our method consistently outperforms the SOTA on all reported mainstream datasets, including CIFAR-10/100 and ImageNet. Remarkably on DVS-CIFAR10, we obtained  83% top-1 accuracy, over 10% improvement compared to existing state of the art.",
        "conference": "ICLR",
        "中文标题": "通过梯度重加权实现脉冲神经网络的时间高效训练",
        "摘要翻译": "最近，受大脑启发的脉冲神经网络（SNNs）因其事件驱动和能量高效的特性引起了广泛的研究兴趣。由于SNNs激活函数的不可微分性，使得传统人工神经网络（ANNs）常用的梯度下降方法无法直接应用于SNNs的高效训练。尽管采用替代梯度（SG）方法形式上允许损失的反向传播，但离散的脉冲机制实际上使得SNNs的损失景观与ANNs不同，导致替代梯度方法无法达到与ANNs相当的准确度。在本文中，我们首先分析了当前使用替代梯度的直接训练方法为何会导致SNNs的泛化能力较差。然后，我们引入了时间高效训练（TET）方法，以补偿使用SG进行梯度下降时的动量损失，从而使训练过程能够收敛到更平坦的最小值，具有更好的泛化能力。同时，我们证明了TET提高了SNN的时间可扩展性，并诱导了一种时间可继承的训练以加速。我们的方法在所有报告的主流数据集上，包括CIFAR-10/100和ImageNet，始终优于现有技术。特别是在DVS-CIFAR10上，我们获得了83%的top-1准确率，比现有技术提高了超过10%。",
        "领域": "脉冲神经网络、深度学习优化、神经形态计算",
        "问题": "解决脉冲神经网络（SNNs）在直接训练方法下泛化能力差的问题",
        "动机": "由于SNNs激活函数的不可微分性，传统梯度下降方法不适用，且替代梯度方法无法达到与人工神经网络（ANNs）相当的准确度，因此需要一种新的训练方法来提高SNNs的泛化能力和训练效率。",
        "方法": "引入时间高效训练（TET）方法，通过梯度重加权补偿替代梯度下降中的动量损失，使训练过程收敛到更平坦的最小值，提高泛化能力和时间可扩展性。",
        "关键词": [
            "脉冲神经网络",
            "替代梯度",
            "时间高效训练",
            "梯度重加权",
            "神经形态计算"
        ],
        "涉及的技术概念": {
            "替代梯度（SG）": "用于在脉冲神经网络中实现损失的反向传播，尽管存在离散脉冲机制的挑战。",
            "时间高效训练（TET）": "通过梯度重加权补偿替代梯度下降中的动量损失，提高训练效率和模型泛化能力。",
            "梯度重加权": "在训练过程中调整梯度权重，以优化模型收敛路径，实现更平坦的最小值和更好的泛化性能。"
        },
        "success": true
    },
    {
        "order": 956,
        "title": "The Boltzmann Policy Distribution: Accounting for Systematic Suboptimality in Human Models",
        "html": "https://iclr.cc//virtual/2022/poster/7128",
        "abstract": "Models of human behavior for prediction and collaboration tend to fall into two categories: ones that learn from large amounts of data via imitation learning, and ones that assume human behavior to be noisily-optimal for some reward function. The former are very useful, but only when it is possible to gather a lot of human data in the target environment and distribution. The advantage of the latter type, which includes Boltzmann rationality, is the ability to make accurate predictions in new environments without extensive data when humans are actually close to optimal. However, these models fail when humans exhibit systematic suboptimality, i.e. when their deviations from optimal behavior are not independent, but instead consistent over time. Our key insight is that systematic suboptimality can be modeled by predicting policies, which couple action choices over time, instead of trajectories. We introduce the Boltzmann policy distribution (BPD), which serves as a prior over human policies and adapts via Bayesian inference to capture systematic deviations by observing human actions during a single episode. The BPD is difficult to compute and represent because policies lie in a high-dimensional continuous space, but we leverage tools from generative and sequence modeling to enable efficient sampling and inference. We show that the BPD enables prediction of human behavior and human-AI collaboration equally as well as imitation learning-based human models while using far less data.",
        "conference": "ICLR",
        "中文标题": "玻尔兹曼策略分布：在人类模型中考虑系统性次优性",
        "摘要翻译": "用于预测和协作的人类行为模型通常分为两类：一类是通过模仿学习从大量数据中学习，另一类则假设人类行为对于某些奖励函数来说是噪声最优的。前者非常有用，但只有在目标环境和分布中能够收集到大量人类数据时才可行。后者的优势，包括玻尔兹曼理性，在于能够在没有大量数据的情况下，在人类实际上接近最优的新环境中做出准确预测。然而，当人类表现出系统性次优性时，即当他们的行为偏离最优行为不是独立的，而是随着时间的推移保持一致时，这些模型就会失败。我们的关键见解是，系统性次优性可以通过预测策略来建模，这些策略将动作选择随时间耦合，而不是轨迹。我们引入了玻尔兹曼策略分布（BPD），它作为人类策略的先验，并通过贝叶斯推理适应，通过观察单个事件中的人类行为来捕捉系统性偏差。BPD难以计算和表示，因为策略位于高维连续空间中，但我们利用生成和序列建模工具来实现高效的采样和推理。我们表明，BPD能够在使用更少数据的情况下，与基于模仿学习的人类模型一样好地预测人类行为和人类-AI协作。",
        "领域": "行为建模、人机协作、强化学习",
        "问题": "解决人类行为模型中系统性次优性的问题",
        "动机": "为了在不需要大量数据的情况下，准确预测人类行为和促进人机协作",
        "方法": "引入玻尔兹曼策略分布（BPD）作为人类策略的先验，并通过贝叶斯推理适应系统性偏差",
        "关键词": [
            "玻尔兹曼策略分布",
            "系统性次优性",
            "人机协作",
            "行为预测",
            "贝叶斯推理"
        ],
        "涉及的技术概念": {
            "玻尔兹曼策略分布（BPD）": "作为人类策略的先验，用于捕捉系统性偏差",
            "贝叶斯推理": "用于适应和更新对人类行为的预测",
            "生成和序列建模": "用于高效地采样和推理高维连续空间中的策略"
        },
        "success": true
    },
    {
        "order": 957,
        "title": "The Close Relationship Between Contrastive Learning and Meta-Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6024",
        "abstract": "Contrastive learning has recently taken off as a paradigm for learning from unlabeled data. In this paper, we discuss the close relationship between contrastive learning and meta-learning under a certain task distribution. We complement this observation by showing that established meta-learning methods, such as Prototypical Networks, achieve comparable performance to SimCLR when paired with this task distribution. This relationship can be leveraged by taking established techniques from meta-learning, such as task-based data augmentation, and showing that they benefit contrastive learning as well. These tricks also benefit state-of-the-art self-supervised learners without using negative pairs such as BYOL, which achieves 94.6\\% accuracy on CIFAR-10 using a self-supervised ResNet-18 feature extractor trained with our meta-learning tricks.  We conclude that existing advances designed for contrastive learning or meta-learning can be exploited to benefit the other, and it is better for contrastive learning researchers to take lessons from the meta-learning literature (and vice-versa) than to reinvent the wheel. ",
        "conference": "ICLR",
        "中文标题": "对比学习与元学习的密切关系",
        "摘要翻译": "对比学习最近作为一种从无标签数据中学习的范式而兴起。在本文中，我们讨论了在特定任务分布下对比学习与元学习之间的密切关系。我们通过展示已建立的元学习方法，如原型网络，当与这种任务分布配对时，能达到与SimCLR相当的性能，来补充这一观察。这种关系可以通过采用元学习中的已建立技术，如基于任务的数据增强，并展示它们同样有利于对比学习来利用。这些技巧也有利于不使用负对的最先进的自监督学习者，如BYOL，它使用我们的元学习技巧训练的自监督ResNet-18特征提取器在CIFAR-10上达到了94.6%的准确率。我们得出结论，为对比学习或元学习设计的现有进展可以被利用来互相受益，对比学习研究者从元学习文献中吸取教训（反之亦然）比重新发明轮子更好。",
        "领域": "自监督学习、元学习、对比学习",
        "问题": "探讨对比学习与元学习之间的关系，并利用元学习的技术提升对比学习的性能。",
        "动机": "研究对比学习与元学习之间的密切关系，探索如何通过元学习的技术来提升对比学习的性能，避免重复发明轮子。",
        "方法": "通过将元学习方法（如原型网络）与特定任务分布配对，展示其与对比学习方法（如SimCLR）性能相当，并利用元学习中的技术（如基于任务的数据增强）来提升对比学习的性能。",
        "关键词": [
            "对比学习",
            "元学习",
            "自监督学习",
            "任务分布",
            "数据增强"
        ],
        "涉及的技术概念": {
            "对比学习": "一种从无标签数据中学习的范式，通过比较样本间的相似性和差异性来学习表示。",
            "元学习": "学习如何学习的方法，旨在使模型能够快速适应新任务。",
            "任务分布": "在元学习中，指模型被训练以适应的任务集合的统计特性。"
        },
        "success": true
    },
    {
        "order": 958,
        "title": "The Convex Geometry of Backpropagation: Neural Network Gradient Flows Converge to Extreme Points of the Dual Convex Program",
        "html": "https://iclr.cc//virtual/2022/poster/7123",
        "abstract": "We study non-convex subgradient flows for training two-layer ReLU neural networks from a convex geometry and duality perspective. We characterize the implicit bias of unregularized non-convex gradient flow as convex regularization of an equivalent convex model. We then show that the limit points of non-convex subgradient flows can be identified via primal-dual correspondence in this convex optimization problem.  Moreover, we derive a sufficient condition on the dual variables which ensures that the stationary points of the non-convex objective are the KKT points of the convex objective, thus proving convergence of non-convex gradient flows to the global optimum. For a class of regular training data distributions such as orthogonal separable data, we show that this sufficient condition holds. Therefore, non-convex gradient flows in fact converge to optimal solutions of a convex optimization problem. We present numerical results verifying the predictions of our theory for non-convex subgradient descent.",
        "conference": "ICLR",
        "中文标题": "反向传播的凸几何：神经网络梯度流收敛于对偶凸规划的极值点",
        "摘要翻译": "我们从凸几何和对偶性的角度研究用于训练两层ReLU神经网络的非凸次梯度流。我们将无正则化的非凸梯度流的隐式偏差描述为等效凸模型的凸正则化。然后，我们展示了非凸次梯度流的极限点可以通过这个凸优化问题中的原始-对偶对应来识别。此外，我们推导了对偶变量的一个充分条件，该条件确保非凸目标的驻点是凸目标的KKT点，从而证明了非凸梯度流向全局最优解的收敛性。对于一类规则的训练数据分布，如正交可分数据，我们展示了这个充分条件成立。因此，非凸梯度流实际上收敛于凸优化问题的最优解。我们提供了数值结果，验证了我们关于非凸次梯度下降理论的预测。",
        "领域": "深度学习理论、优化算法、神经网络训练",
        "问题": "理解并证明非凸梯度流在训练两层ReLU神经网络时的收敛行为及其与凸优化问题的关系",
        "动机": "探索非凸优化问题在神经网络训练中的行为，特别是梯度流的收敛性，以及如何通过凸优化的视角来理解和保证其全局收敛性",
        "方法": "通过凸几何和对偶性理论分析非凸次梯度流，建立非凸优化与凸优化之间的联系，推导确保收敛的充分条件，并通过数值实验验证理论",
        "关键词": [
            "非凸优化",
            "梯度流",
            "凸对偶",
            "神经网络训练",
            "全局收敛"
        ],
        "涉及的技术概念": {
            "非凸次梯度流": "用于训练神经网络的优化方法，研究其在非凸目标函数上的行为",
            "凸对偶": "将非凸优化问题转化为凸优化问题，以便于分析和求解",
            "KKT点": "Karush-Kuhn-Tucker点，优化问题中满足必要条件的点，用于识别最优解"
        },
        "success": true
    },
    {
        "order": 959,
        "title": "The Effects of Invertibility on the Representational Complexity of Encoders in Variational Autoencoders ",
        "html": "https://iclr.cc//virtual/2022/poster/6975",
        "abstract": "Training and using modern neural-network based latent-variable generative models (like Variational Autoencoders) often require simultaneously training a generative direction along with an inferential (encoding) direction, which approximates the posterior distribution over the latent variables. Thus, the question arises: how complex does the inferential model need to be, in order to be able to accurately model the posterior distribution of a given generative model?  In this paper, we identify an important property of the generative map impacting the required size of the encoder. We show that if the generative map is ``strongly invertible' (in a sense we suitably formalize), the inferential model need not be much more complex. Conversely, we prove that there exist non-invertible generative maps, for which the encoding direction needs to be exponentially larger (under standard assumptions in computational complexity). Importantly, we do not require the generative model to be layerwise invertible, which a lot of the related literature assumes and isn't satisfied by many architectures used in practice (e.g. convolution and pooling based networks). Thus, we provide theoretical support for the empirical wisdom that learning deep generative models is harder when data lies on a low-dimensional manifold.",
        "conference": "ICLR",
        "中文标题": "可逆性对变分自编码器中编码器表示复杂度的影响",
        "摘要翻译": "训练和使用基于现代神经网络的潜在变量生成模型（如变分自编码器）通常需要同时训练生成方向和推理（编码）方向，后者近似于潜在变量的后验分布。因此，问题出现了：推理模型需要多复杂，才能准确建模给定生成模型的后验分布？在本文中，我们确定了影响编码器所需大小的生成映射的一个重要属性。我们表明，如果生成映射是‘强可逆的’（在我们适当形式化的意义上），推理模型不需要复杂得多。相反，我们证明了存在非可逆的生成映射，对于这些映射，编码方向需要指数级更大（在计算复杂度的标准假设下）。重要的是，我们不要求生成模型是逐层可逆的，这是许多相关文献所假设的，并且不满足许多实际使用的架构（例如基于卷积和池化的网络）。因此，我们为经验智慧提供了理论支持，即当数据位于低维流形上时，学习深度生成模型更难。",
        "领域": "变分自编码器、生成模型、深度学习理论",
        "问题": "探讨在变分自编码器中，生成模型的可逆性如何影响编码器的表示复杂度。",
        "动机": "理解生成模型的可逆性对编码器复杂度的影响，为深度生成模型的设计和训练提供理论依据。",
        "方法": "通过理论分析，研究生成映射的可逆性与编码器复杂度之间的关系，并提出‘强可逆性’的概念。",
        "关键词": [
            "变分自编码器",
            "可逆性",
            "表示复杂度",
            "生成模型",
            "深度学习理论"
        ],
        "涉及的技术概念": {
            "强可逆性": "本文中形式化的概念，用于描述生成映射的性质，影响编码器的复杂度要求。",
            "变分自编码器": "一种潜在变量生成模型，通过同时训练生成和推理方向来近似后验分布。",
            "表示复杂度": "指编码器模型为了准确建模后验分布所需的复杂程度，与生成模型的可逆性密切相关。"
        },
        "success": true
    },
    {
        "order": 960,
        "title": "The Effects of Reward Misspecification: Mapping and Mitigating Misaligned Models",
        "html": "https://iclr.cc//virtual/2022/poster/6579",
        "abstract": "Reward hacking---where RL agents exploit gaps in misspecified proxy rewards---has been widely observed, but not yet systematically studied. To understand reward hacking, we construct four RL environments with different misspecified rewards. We investigate reward hacking as a function of agent capabilities: model capacity, action space resolution, and observation space noise. Typically, more capable agents are able to better exploit reward misspecifications, causing them to attain higher proxy reward and lower true reward. Moreover, we find instances of \\emph{phase transitions}: capability thresholds at which the agent's behavior qualitatively shifts, leading to a sharp decrease in the true reward. Such phase transitions pose challenges to monitoring the safety of ML systems. To encourage further research on reward misspecification, address this, we propose an anomaly detection task for aberrant policies and offer several baseline detectors.",
        "conference": "ICLR",
        "中文标题": "奖励错误设定的影响：映射与缓解模型不对齐问题",
        "摘要翻译": "奖励黑客行为——即强化学习（RL）代理利用错误设定的代理奖励中的漏洞——已被广泛观察到，但尚未得到系统研究。为了理解奖励黑客行为，我们构建了四个具有不同错误设定奖励的RL环境。我们研究了奖励黑客行为作为代理能力（模型容量、动作空间分辨率和观察空间噪声）的函数。通常，能力更强的代理能够更好地利用奖励错误设定，导致它们获得更高的代理奖励和更低的真实奖励。此外，我们发现了一些相变的实例：在这些能力阈值处，代理的行为会发生质的变化，导致真实奖励急剧下降。这种相变对监控机器学习系统的安全性提出了挑战。为了鼓励对奖励错误设定的进一步研究，我们提出了一个针对异常策略的异常检测任务，并提供了几个基线检测器。",
        "领域": "强化学习、机器学习安全、异常检测",
        "问题": "研究奖励错误设定如何导致强化学习代理产生黑客行为，并探索如何检测和缓解这种行为。",
        "动机": "奖励黑客行为在强化学习中普遍存在，但缺乏系统研究，这可能导致机器学习系统的不安全行为。",
        "方法": "构建具有不同错误设定奖励的RL环境，研究代理能力对奖励黑客行为的影响，并提出异常检测任务和基线检测器。",
        "关键词": [
            "奖励黑客",
            "强化学习",
            "模型不对齐",
            "异常检测",
            "相变"
        ],
        "涉及的技术概念": {
            "奖励黑客": "强化学习代理利用奖励函数中的漏洞，通过非预期行为最大化代理奖励而非真实奖励。",
            "相变": "代理能力达到某一阈值时，其行为发生质的变化，导致真实奖励急剧下降的现象。",
            "异常检测": "识别与预期行为显著不同的策略，用于监控和确保机器学习系统的安全性。"
        },
        "success": true
    },
    {
        "order": 961,
        "title": "The Efficiency Misnomer",
        "html": "https://iclr.cc//virtual/2022/poster/6607",
        "abstract": "Model efficiency is a critical aspect of developing and deploying machine learning models. Inference time and latency directly affect the user experience, and some applications have hard requirements. In addition to inference costs, model training also have direct financial and environmental impacts.Although there are numerous well-established metrics (cost indicators) for measuring model efficiency, researchers and practitioners often assume that these metrics are correlated with each other and report only a few of them.In this paper, we thoroughly discuss common cost indicators, their advantages and disadvantages, and how they can contradict each other.We demonstrate how incomplete reporting of cost indicators can lead to partial conclusions and a blurred or incomplete picture of the practical considerations of different models. We further present suggestions to improve reporting of efficiency metrics.",
        "conference": "ICLR",
        "中文标题": "效率的误称",
        "摘要翻译": "模型效率是开发和部署机器学习模型的一个关键方面。推理时间和延迟直接影响用户体验，某些应用对此有严格要求。除了推理成本外，模型训练还直接产生财务和环境影响。尽管有许多成熟的指标（成本指标）用于衡量模型效率，研究人员和实践者常常假设这些指标相互关联，并且只报告其中的少数几个。在本文中，我们深入讨论了常见的成本指标、它们的优缺点以及它们如何相互矛盾。我们展示了不完整的成本指标报告如何导致部分结论，以及对不同模型实际考虑因素的模糊或不完整理解。我们进一步提出了改进效率指标报告的建议。",
        "领域": "模型优化、机器学习部署、环境可持续性计算",
        "问题": "模型效率指标的不完整报告导致对模型实际性能的误解",
        "动机": "揭示和解决模型效率评估中的不完整性和误导性报告问题",
        "方法": "分析常见成本指标的优缺点及其相互关系，提出改进报告的建议",
        "关键词": [
            "模型效率",
            "成本指标",
            "推理时间",
            "环境影响",
            "机器学习部署"
        ],
        "涉及的技术概念": {
            "推理时间": "衡量模型响应速度的关键指标，直接影响用户体验",
            "成本指标": "用于评估模型效率的多维度指标，包括计算资源消耗、时间效率等",
            "环境影响": "模型训练和运行过程中的能源消耗和碳排放，反映模型的可持续性"
        },
        "success": true
    },
    {
        "order": 962,
        "title": "The Evolution of Uncertainty of Learning in Games",
        "html": "https://iclr.cc//virtual/2022/poster/6694",
        "abstract": "Learning in games has become an object of intense interest for ML due to its connections to numerous AI architectures. We study standard online learning in games but from a non-standard perspective. Instead of studying the behavior of a single initial condition and whether it converges to equilibrium or not, we study the behavior of a probability distribution/measure over a set of initial conditions. This initial uncertainty is well-motivated both from a standard game-theoretic perspective (e.g. a modeler's uncertainty about the agents' initial beliefs) as well as from a ML one (e.g. noisy measurements, system initialization from a dataset distribution). Despite this, little is formally known about whether and under what conditions uncertainty is amplified or reduced in these systems. We use the popular measure of differential entropy to quantify the evolution of uncertainty. We find that such analysis shares an intimate relationship with volume analysis, a technique which was recently used to demonstrate the occurrence of Lyapunov chaos when using Multiplicative Weights Update (MWU) or Follow-the-Regularized-Leader (FTRL) algorithms in zero-sum games. This allows us to show that the differential entropy of these learning-in-game systems increases linearly with time, formalizing their increased unpredictability over time. We showcase the power of the framework by applying it in the study of multiple related systems, including different standard online optimization algorithms in numerous games and dynamics of evolutionary game theory.",
        "conference": "ICLR",
        "中文标题": "博弈学习中不确定性的演变",
        "摘要翻译": "由于与众多AI架构的联系，博弈学习已成为机器学习领域强烈关注的对象。我们从非标准的角度研究了博弈中的标准在线学习。不同于研究单一初始条件的行为及其是否收敛到均衡，我们研究了一组初始条件上的概率分布/测度的行为。这种初始不确定性从标准博弈论视角（如建模者对智能体初始信念的不确定性）和机器学习视角（如噪声测量、从数据集分布初始化系统）都有很好的动机。尽管如此，关于这些系统中不确定性是否以及在什么条件下被放大或减少，知之甚少。我们使用流行的微分熵度量来量化不确定性的演变。我们发现，这种分析与体积分析有着密切的关系，后者是最近用于证明在使用乘性权重更新（MWU）或跟随正则化领导者（FTRL）算法于零和博弈中时出现Lyapunov混沌的技术。这使我们能够展示这些博弈学习系统的微分熵随时间线性增加，形式化了它们随时间增加的不确定性。我们通过将该框架应用于多个相关系统的研究，包括不同标准在线优化算法在众多博弈和进化博弈论动态中的应用，展示了该框架的强大能力。",
        "领域": "博弈论与机器学习结合、在线学习算法、进化博弈论",
        "问题": "研究博弈学习系统中不确定性的演变及其条件",
        "动机": "理解博弈学习系统中不确定性如何随时间演变，以及这种演变对系统行为的影响",
        "方法": "使用微分熵度量不确定性的演变，并与体积分析技术结合，分析不同在线优化算法在博弈中的应用",
        "关键词": [
            "博弈学习",
            "不确定性演变",
            "微分熵",
            "在线优化算法",
            "进化博弈论"
        ],
        "涉及的技术概念": {
            "微分熵": "用于量化博弈学习系统中不确定性的度量",
            "体积分析": "一种技术，用于分析系统行为，特别是在证明Lyapunov混沌中的应用",
            "乘性权重更新（MWU）": "一种在线优化算法，用于博弈学习中的策略更新"
        },
        "success": true
    },
    {
        "order": 963,
        "title": "The Geometry of Memoryless Stochastic Policy Optimization in Infinite-Horizon POMDPs",
        "html": "https://iclr.cc//virtual/2022/poster/7080",
        "abstract": "We consider the problem of finding the best memoryless stochastic policy for an infinite-horizon partially observable Markov decision process (POMDP) with finite state and action spaces with respect to either the discounted or mean reward criterion. We show that the (discounted) state-action frequencies and the expected cumulative reward are rational functions of the policy, whereby the degree is determined by the degree of partial observability. We then describe the optimization problem as a linear optimization problem in the space of feasible state-action frequencies subject to polynomial constraints that we characterize explicitly. This allows us to address the combinatorial and geometric complexity of the optimization problem using recent tools from polynomial optimization. In particular, we demonstrate how the partial observability constraints can lead to multiple smooth and non-smooth local optimizers and we estimate the number of critical points.",
        "conference": "ICLR",
        "中文标题": "无限视野部分可观察马尔可夫决策过程中无记忆随机策略优化的几何学",
        "摘要翻译": "我们考虑在有限状态和动作空间的无限视野部分可观察马尔可夫决策过程（POMDP）中，寻找关于折扣或平均奖励准则的最佳无记忆随机策略的问题。我们展示了（折扣的）状态-动作频率和期望累积奖励是策略的有理函数，其中度数由部分可观察性的程度决定。然后，我们将优化问题描述为在受我们明确表征的多项式约束的可行状态-动作频率空间中的线性优化问题。这使我们能够利用多项式优化中的最新工具来解决优化问题的组合和几何复杂性。特别是，我们展示了部分可观察性约束如何导致多个平滑和非平滑的局部优化器，并估计了临界点的数量。",
        "领域": "强化学习、部分可观察马尔可夫决策过程、策略优化",
        "问题": "在无限视野部分可观察马尔可夫决策过程中寻找最佳无记忆随机策略",
        "动机": "研究在部分可观察环境下，如何优化无记忆随机策略以最大化累积奖励",
        "方法": "将优化问题转化为受多项式约束的线性优化问题，并利用多项式优化工具分析其复杂性",
        "关键词": [
            "部分可观察马尔可夫决策过程",
            "无记忆随机策略",
            "多项式优化",
            "状态-动作频率",
            "累积奖励"
        ],
        "涉及的技术概念": {
            "部分可观察马尔可夫决策过程": "一种决策过程模型，其中决策者无法完全观察到系统的当前状态",
            "无记忆随机策略": "一种策略，其选择动作的概率仅依赖于当前观察，而不依赖于历史信息",
            "多项式优化": "一种优化技术，用于解决目标函数和约束条件为多项式的问题"
        },
        "success": true
    },
    {
        "order": 964,
        "title": "The Hidden Convex Optimization Landscape of Regularized Two-Layer ReLU Networks: an Exact Characterization of Optimal Solutions",
        "html": "https://iclr.cc//virtual/2022/poster/7124",
        "abstract": "We prove that finding all globally optimal two-layer ReLU neural networks can be performed by solving a convex optimization program with cone constraints. Our analysis is novel, characterizes all optimal solutions, and does not leverage duality-based analysis which was recently used to lift neural network training into convex spaces. Given the set of solutions of our convex optimization program, we show how to construct exactly the entire set of optimal neural networks. We provide a detailed characterization of this optimal set and its invariant transformations. As additional consequences of our convex perspective, (i) we establish that Clarke stationary points found by stochastic gradient descent correspond to the global optimum of a subsampled convex problem (ii) we provide a polynomial-time algorithm for checking if a neural network is a global minimum of the training loss (iii) we provide an explicit construction of a continuous path between any neural network and the global minimum of its sublevel set and (iv) characterize the minimal size of the hidden layer so that the neural network optimization landscape has no spurious valleys.Overall, we provide a rich framework for studying the landscape of neural network training loss through convexity.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "正则化双层ReLU网络的隐藏凸优化景观：最优解的精确刻画",
        "摘要翻译": "我们证明，寻找所有全局最优的双层ReLU神经网络可以通过解决一个带有锥约束的凸优化程序来完成。我们的分析是新颖的，刻画了所有最优解，并且没有利用最近用于将神经网络训练提升到凸空间的基于对偶性的分析。给定我们的凸优化程序的解集，我们展示了如何精确构建所有最优神经网络的整个集合。我们提供了这个最优集及其不变变换的详细刻画。作为我们凸视角的额外结果，（i）我们建立了由随机梯度下降找到的Clarke静止点对应于子采样凸问题的全局最优解（ii）我们提供了一个多项式时间算法来检查神经网络是否是训练损失的全局最小值（iii）我们提供了在任何神经网络和其子水平集的全局最小值之间的连续路径的显式构造（iv）刻画了隐藏层的最小大小，使得神经网络优化景观没有虚假谷。总的来说，我们提供了一个丰富的框架，通过凸性研究神经网络训练损失的景观。",
        "领域": "深度学习优化、神经网络理论、凸优化",
        "问题": "如何精确刻画和找到所有全局最优的双层ReLU神经网络",
        "动机": "研究神经网络训练中的优化问题，特别是如何避免陷入局部最优解，以及如何高效地找到全局最优解",
        "方法": "通过解决带有锥约束的凸优化程序来寻找所有全局最优的双层ReLU神经网络，并详细刻画最优解集及其不变变换",
        "关键词": [
            "ReLU网络",
            "凸优化",
            "全局最优解",
            "神经网络训练",
            "优化景观"
        ],
        "涉及的技术概念": {
            "凸优化程序": "用于寻找所有全局最优的双层ReLU神经网络的数学优化方法，确保找到的解是全局最优的",
            "Clarke静止点": "在非光滑优化中使用的概念，用于描述随机梯度下降可能收敛的点，本文中这些点对应于子采样凸问题的全局最优解",
            "不变变换": "在最优解集中保持某些性质不变的变换，用于理解和刻画最优解的结构和多样性"
        }
    },
    {
        "order": 965,
        "title": "The Inductive Bias of In-Context Learning: Rethinking Pretraining Example Design",
        "html": "https://iclr.cc//virtual/2022/poster/6999",
        "abstract": "Pretraining Neural Language Models (NLMs) over a large corpus involves chunking the text into training examples, which are contiguous text segments of sizes processable by the neural architecture. We highlight a bias introduced by this common practice: we prove that the pretrained NLM can model much stronger dependencies between text segments that appeared in the same training example, than it can between text segments that appeared in different training examples. This intuitive result has a twofold role. First, it formalizes the motivation behind a broad line of recent successful NLM training heuristics, proposed for the pretraining and fine-tuning stages, which do not necessarily appear related at first glance. Second, our result clearly indicates further improvements to be made in NLM pretraining for the benefit of Natural Language Understanding tasks. As an example, we propose ``kNN-Pretraining': we show that including semantically related non-neighboring sentences in the same pretraining example yields improved sentence representations and open domain question answering abilities.This theoretically motivated degree of freedom for pretraining example design indicates new training schemes for self-improving representations. ",
        "conference": "ICLR",
        "中文标题": "上下文学习的归纳偏置：重新思考预训练示例设计",
        "摘要翻译": "预训练神经语言模型（NLMs）在大规模语料库上涉及将文本分块为训练示例，这些示例是由神经架构可处理的连续文本段。我们强调了这一常见做法引入的偏置：我们证明，预训练的NLM可以建模出现在同一训练示例中的文本段之间比出现在不同训练示例中的文本段之间更强的依赖关系。这一直观结果具有双重作用。首先，它形式化了最近一系列成功的NLM训练启发式方法背后的动机，这些方法在预训练和微调阶段提出，初看起来并不一定相关。其次，我们的结果明确指出了在NLM预训练中为进一步改进自然语言理解任务所做的进一步改进。例如，我们提出了“kNN-Pretraining”：我们展示了将语义相关的非相邻句子包含在同一预训练示例中，可以产生改进的句子表示和开放领域问答能力。这一理论上动机的预训练示例设计自由度表明了自我改进表示的新训练方案。",
        "领域": "自然语言处理与视觉结合, 语言模型预训练, 开放领域问答",
        "问题": "预训练神经语言模型在处理文本段依赖关系时存在的偏置问题",
        "动机": "揭示并解决预训练过程中由于文本分块导致的依赖关系建模偏置，以提升语言模型的理解和生成能力",
        "方法": "提出kNN-Pretraining方法，通过将语义相关的非相邻句子包含在同一预训练示例中，以改进句子表示和问答能力",
        "关键词": [
            "神经语言模型",
            "预训练偏置",
            "kNN-Pretraining",
            "句子表示",
            "开放领域问答"
        ],
        "涉及的技术概念": {
            "神经语言模型（NLM）": "用于处理和生成自然语言的深度学习模型，通过预训练在大规模文本数据上学习语言表示",
            "预训练偏置": "指在预训练过程中由于数据分块方式导致的模型在处理文本段依赖关系时的偏好或限制",
            "kNN-Pretraining": "一种预训练方法，通过将语义相关的非相邻句子组合在同一训练示例中，以增强模型对长距离依赖关系的建模能力"
        },
        "success": true
    },
    {
        "order": 966,
        "title": "The Information Geometry of Unsupervised Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6206",
        "abstract": "How can a reinforcement learning (RL) agent prepare to solve downstream tasks if those tasks are not known a priori? One approach is unsupervised skill discovery, a class of algorithms that learn a set of policies without access to a reward function. Such algorithms bear a close resemblance to representation learning algorithms (e.g., contrastive learning) in supervised learning, in that both are pretraining algorithms that maximize some approximation to a mutual information objective. While prior work has shown that the set of skills learned by such methods can accelerate downstream RL tasks, prior work offers little analysis into whether these skill learning algorithms are optimal, or even what notion of optimality would be appropriate to apply to them. In this work, we show that unsupervised skill discovery algorithms based on mutual information maximization do not learn skills that are optimal for every possible reward function. However, we show that the distribution over skills provides an optimal initialization minimizing regret against adversarially-chosen reward functions, assuming a certain type of adaptation procedure. Our analysis also provides a geometric perspective on these skill learning methods.",
        "conference": "ICLR",
        "中文标题": "无监督强化学习的信息几何",
        "摘要翻译": "如果一个强化学习（RL）代理不知道下游任务，它如何为这些任务做准备？一种方法是无监督技能发现，这是一类不需要访问奖励函数就能学习一组策略的算法。这类算法与监督学习中的表示学习算法（例如对比学习）非常相似，因为它们都是预训练算法，最大化某种近似于互信息的目标。虽然之前的工作表明，通过这些方法学习到的技能集可以加速下游RL任务，但之前的工作很少分析这些技能学习算法是否最优，甚至什么样的最优性概念适用于它们。在这项工作中，我们展示了基于互信息最大化的无监督技能发现算法并不学习对每个可能的奖励函数都最优的技能。然而，我们展示了技能分布提供了一个最优初始化，最小化对抗选择的奖励函数的遗憾，假设某种类型的适应过程。我们的分析还为这些技能学习方法提供了一个几何视角。",
        "领域": "强化学习",
        "问题": "无监督技能发现算法是否能够学习到对所有可能的奖励函数都最优的技能",
        "动机": "探索无监督技能发现算法的最优性及其在对抗性奖励函数下的表现",
        "方法": "基于互信息最大化的无监督技能发现算法，并分析其在对抗性奖励函数下的表现",
        "关键词": [
            "无监督技能发现",
            "互信息最大化",
            "对抗性奖励函数",
            "强化学习",
            "信息几何"
        ],
        "涉及的技术概念": {
            "无监督技能发现": "一类不需要访问奖励函数就能学习一组策略的算法",
            "互信息最大化": "预训练算法中最大化某种近似于互信息的目标",
            "对抗性奖励函数": "在对抗选择的奖励函数下最小化遗憾的初始化策略"
        },
        "success": true
    },
    {
        "order": 967,
        "title": "The MultiBERTs: BERT Reproductions for Robustness Analysis",
        "html": "https://iclr.cc//virtual/2022/poster/6291",
        "abstract": "Experiments with pre-trained models such as BERT are often based on a single checkpoint. While the conclusions drawn apply to the artifact tested in the experiment (i.e., the particular instance of the model), it is not always clear whether they hold for the more general procedure which includes the architecture, training data, initialization scheme, and loss function. Recent work has shown that repeating the pre-training process can lead to substantially different performance, suggesting that an alternative strategy is needed to make principled statements about procedures. To enable researchers to draw more robust conclusions, we introduce MultiBERTs, a set of 25 BERT-Base checkpoints, trained with similar hyper-parameters as the original BERT model but differing in random weight initialization and shuffling of training data. We also define the Multi-Bootstrap, a non-parametric bootstrap method for statistical inference designed for settings where there are multiple pre-trained models and limited test data. To illustrate our approach, we present a case study of gender bias in coreference resolution, in which the Multi-Bootstrap lets us measure effects that may not be detected with a single checkpoint. The models and statistical library are available online, along with an additional set of 140 intermediate checkpoints captured during pre-training to facilitate research on learning dynamics.",
        "conference": "ICLR",
        "中文标题": "MultiBERTs：用于鲁棒性分析的BERT复现",
        "摘要翻译": "使用如BERT这样的预训练模型进行的实验通常基于单一检查点。虽然得出的结论适用于实验中测试的工件（即模型的特定实例），但并不总是清楚这些结论是否适用于更一般的程序，包括架构、训练数据、初始化方案和损失函数。最近的工作表明，重复预训练过程可能导致性能显著不同，这表明需要一种替代策略来对程序做出有原则的陈述。为了使研究人员能够得出更稳健的结论，我们引入了MultiBERTs，这是一组25个BERT-Base检查点，使用与原始BERT模型相似的超参数训练，但在随机权重初始化和训练数据的洗牌上有所不同。我们还定义了Multi-Bootstrap，这是一种非参数自举方法，专为有多个预训练模型和有限测试数据的统计推断设计。为了说明我们的方法，我们提出了一个关于共指消解中性别偏见的案例研究，其中Multi-Bootstrap让我们能够测量可能无法通过单一检查点检测到的影响。模型和统计库可在线获取，还包括一组140个在预训练期间捕获的中间检查点，以促进学习动态的研究。",
        "领域": "自然语言处理与视觉结合",
        "问题": "如何基于BERT预训练模型进行更鲁棒的实验分析",
        "动机": "解决单一检查点实验结论可能不具有普遍性的问题",
        "方法": "引入MultiBERTs和Multi-Bootstrap方法，通过多个预训练模型和统计推断提高实验的鲁棒性",
        "关键词": [
            "BERT复现",
            "鲁棒性分析",
            "统计推断",
            "预训练模型",
            "共指消解"
        ],
        "涉及的技术概念": {
            "MultiBERTs": "一组25个BERT-Base检查点，用于提高实验的鲁棒性",
            "Multi-Bootstrap": "一种非参数自举方法，用于在多个预训练模型和有限测试数据下进行统计推断",
            "共指消解": "自然语言处理中的一项任务，用于确定文本中不同表达是否指向同一实体"
        },
        "success": true
    },
    {
        "order": 968,
        "title": "The Neural Data Router: Adaptive Control Flow in Transformers Improves Systematic Generalization",
        "html": "https://iclr.cc//virtual/2022/poster/6053",
        "abstract": "Despite progress across a broad range of applications, Transformers have limited success in systematic generalization. The situation is especially frustrating in the case of algorithmic tasks, where they often fail to find intuitive solutions that route relevant information to the right node/operation at the right time in the grid represented by Transformer columns. To facilitate the learning of useful control flow, we propose two modifications to the Transformer architecture, copy gate and geometric attention. Our novel Neural Data Router (NDR) achieves 100% length generalization accuracy on the classic compositional table lookup task, as well as near-perfect accuracy on the simple arithmetic task and a new variant of ListOps testing for generalization across computational depths. NDR’s attention and gating patterns tend to be interpretable as an intuitive form of neural routing",
        "conference": "ICLR",
        "中文标题": "神经数据路由器：Transformer中的自适应控制流提升系统泛化能力",
        "摘要翻译": "尽管Transformer在广泛的应用中取得了进展，但在系统泛化方面的成功有限。在算法任务中，这种情况尤其令人沮丧，因为它们经常无法找到直观的解决方案，这些解决方案能够在Transformer列表示的网格中，在正确的时间将相关信息路由到正确的节点/操作。为了促进有用控制流的学习，我们提出了对Transformer架构的两项修改：复制门和几何注意力。我们新颖的神经数据路由器（NDR）在经典的组合表查找任务上实现了100%的长度泛化准确率，以及在简单算术任务和ListOps的新变体上实现了近乎完美的准确率，测试了跨计算深度的泛化能力。NDR的注意力和门控模式往往可以被解释为一种直观的神经路由形式。",
        "领域": "自然语言处理与视觉结合, 算法任务处理, 系统泛化",
        "问题": "Transformer在系统泛化和算法任务中难以实现直观的信息路由和操作。",
        "动机": "提升Transformer在系统泛化和算法任务中的性能，特别是在信息路由和操作方面的直观性和准确性。",
        "方法": "提出了对Transformer架构的两项修改：复制门和几何注意力，引入了神经数据路由器（NDR）来实现更有效的信息路由和控制流。",
        "关键词": [
            "神经数据路由器",
            "系统泛化",
            "Transformer架构",
            "算法任务",
            "信息路由"
        ],
        "涉及的技术概念": {
            "复制门": "用于控制信息在Transformer中的流动，确保相关信息能够在正确的时间被路由到正确的节点。",
            "几何注意力": "一种改进的注意力机制，旨在提升模型对信息路由的控制能力，使其更加直观和有效。",
            "神经数据路由器（NDR）": "一种新颖的架构，通过结合复制门和几何注意力，实现了在算法任务中的高效信息路由和系统泛化。"
        },
        "success": true
    },
    {
        "order": 969,
        "title": "The Rich Get Richer: Disparate Impact of Semi-Supervised Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6926",
        "abstract": "Semi-supervised learning (SSL) has demonstrated its potential to improve the model accuracy for a variety of learning tasks when the high-quality supervised data is severely limited. Although it is often established that the average accuracy for the entire population of data is improved, it is unclear how SSL fares with different sub-populations. Understanding the above question has substantial fairness implications when different sub-populations are defined by the demographic groups that we aim to treat fairly. In this paper, we reveal the disparate impacts of deploying SSL: the sub-population who has a higher baseline accuracy without using SSL (the 'rich' one) tends to benefit more from SSL; while the sub-population who suffers from a low baseline accuracy (the 'poor' one) might even observe a performance drop after adding the SSL module. We theoretically and empirically establish the above observation for a broad family of SSL algorithms, which either explicitly or implicitly use an auxiliary 'pseudo-label'. Experiments on a set of image and text classification tasks confirm our claims. We introduce a new metric, Benefit Ratio, and promote the evaluation of the fairness of SSL (Equalized Benefit Ratio). We further discuss how the disparate impact can be mitigated. We hope our paper will alarm the potential pitfall of using SSL and encourage a multifaceted evaluation of future SSL algorithms.  ",
        "conference": "ICLR",
        "中文标题": "富者愈富：半监督学习的差异性影响",
        "摘要翻译": "半监督学习（SSL）在高质量监督数据严重受限的情况下，已显示出提高各种学习任务模型准确性的潜力。虽然通常认为整个数据群体的平均准确性得到了提高，但SSL在不同子群体中的表现如何尚不明确。当不同的子群体由我们旨在公平对待的人口统计群体定义时，理解上述问题具有重大的公平性影响。在本文中，我们揭示了部署SSL的差异性影响：基线准确性较高（‘富有’的）的子群体倾向于从SSL中获益更多；而基线准确性较低（‘贫穷’的）的子群体在添加SSL模块后甚至可能观察到性能下降。我们从理论上和实证上为广泛的一系列SSL算法建立了上述观察，这些算法要么明确要么隐含地使用了一个辅助的‘伪标签’。在一组图像和文本分类任务上的实验证实了我们的主张。我们引入了一个新的指标，利益比率，并促进了SSL公平性的评估（平等利益比率）。我们进一步讨论了如何减轻差异性影响。我们希望我们的论文能够警示使用SSL的潜在陷阱，并鼓励对未来SSL算法进行多方面的评估。",
        "领域": "半监督学习、公平性机器学习、图像与文本分类",
        "问题": "半监督学习在不同子群体中的差异性影响及其公平性问题",
        "动机": "揭示半监督学习在不同基线准确性子群体中的不公平性影响，促进算法的公平性评估",
        "方法": "理论分析和实证研究，引入利益比率作为新指标，评估并讨论减轻差异性影响的策略",
        "关键词": [
            "半监督学习",
            "公平性",
            "差异性影响",
            "利益比率",
            "伪标签"
        ],
        "涉及的技术概念": {
            "半监督学习": "在监督数据有限的情况下，利用未标记数据提高模型性能的学习方法",
            "伪标签": "SSL算法中用于未标记数据的预测标签，作为监督信号辅助训练",
            "利益比率": "新引入的指标，用于量化SSL对不同子群体性能提升的公平性"
        },
        "success": true
    },
    {
        "order": 970,
        "title": "The Role of Permutation Invariance in Linear Mode Connectivity of Neural Networks",
        "html": "https://iclr.cc//virtual/2022/poster/6604",
        "abstract": "In this paper, we conjecture that if the permutation invariance of neural networks is taken into account, SGD solutions will likely have no barrier in the linear interpolation between them. Although it is a bold conjecture, we show how extensive empirical attempts fall short of refuting it. We further provide a preliminary theoretical result to support our conjecture. Our conjecture has implications for the lottery ticket hypothesis, distributed training, and ensemble methods. The source code is available at \\url{https://github.com/rahimentezari/PermutationInvariance}.",
        "conference": "ICLR",
        "中文标题": "排列不变性在神经网络线性模式连接中的作用",
        "摘要翻译": "在本文中，我们推测如果考虑到神经网络的排列不变性，SGD解决方案在它们之间的线性插值中很可能没有障碍。尽管这是一个大胆的推测，但我们展示了广泛的实证尝试如何未能反驳它。我们进一步提供了一个初步的理论结果来支持我们的推测。我们的推测对彩票假设、分布式训练和集成方法有影响。源代码可在https://github.com/rahimentezari/PermutationInvariance获取。",
        "领域": "深度学习理论、神经网络优化、模型泛化",
        "问题": "探讨排列不变性对神经网络线性模式连接中SGD解决方案障碍的影响",
        "动机": "研究排列不变性如何影响神经网络优化过程中的解决方案连接性，以及这种影响对深度学习理论和实践的潜在意义",
        "方法": "通过实证研究和初步理论分析，探讨排列不变性与SGD解决方案线性插值障碍之间的关系",
        "关键词": [
            "排列不变性",
            "线性模式连接",
            "SGD优化",
            "神经网络理论",
            "模型泛化"
        ],
        "涉及的技术概念": {
            "排列不变性": "指神经网络对输入排列的不变性，本文探讨其对优化过程的影响",
            "线性模式连接": "研究神经网络不同解决方案之间通过线性插值连接的属性",
            "SGD优化": "随机梯度下降，本文研究其在考虑排列不变性时的优化行为"
        },
        "success": true
    },
    {
        "order": 971,
        "title": "The Role of Pretrained Representations for the OOD Generalization of RL Agents",
        "html": "https://iclr.cc//virtual/2022/poster/7156",
        "abstract": "Building sample-efficient agents that generalize out-of-distribution (OOD) in real-world settings remains a fundamental unsolved problem on the path towards achieving higher-level cognition. One particularly promising approach is to begin with low-dimensional, pretrained representations of our world, which should facilitate efficient downstream learning and generalization. By training 240 representations and over 10,000 reinforcement learning (RL) policies on a simulated robotic setup, we evaluate to what extent different properties of pretrained VAE-based representations affect the OOD generalization of downstream agents. We observe that many agents are surprisingly robust to realistic distribution shifts, including the challenging sim-to-real case. In addition, we find that the generalization performance of a simple downstream proxy task reliably predicts the generalization performance of our RL agents under a wide range of OOD settings. Such proxy tasks can thus be used to select pretrained representations that will lead to agents that generalize.",
        "conference": "ICLR",
        "中文标题": "预训练表征在强化学习智能体分布外泛化中的作用",
        "摘要翻译": "构建在现实世界设置中能够进行分布外（OOD）泛化的样本高效智能体，仍然是实现更高层次认知道路上未解决的基本问题。一个特别有前景的方法是从我们世界的低维预训练表征开始，这应该有助于高效的下游学习和泛化。通过在模拟机器人设置上训练240种表征和超过10,000个强化学习（RL）策略，我们评估了基于VAE的预训练表征的不同属性对下游智能体OOD泛化的影响程度。我们观察到，许多智能体对现实的分布变化表现出惊人的鲁棒性，包括具有挑战性的模拟到现实情况。此外，我们发现简单下游代理任务的泛化性能可靠地预测了我们的RL智能体在广泛OOD设置下的泛化性能。因此，这样的代理任务可以用来选择会导致智能体泛化的预训练表征。",
        "领域": "强化学习、机器人学习、表征学习",
        "问题": "如何构建能够在分布外（OOD）情况下泛化的样本高效强化学习智能体",
        "动机": "解决强化学习智能体在现实世界中的分布外泛化问题，以实现更高层次的认知",
        "方法": "通过训练大量基于VAE的预训练表征和强化学习策略，评估不同表征属性对智能体OOD泛化的影响，并利用简单下游代理任务预测泛化性能",
        "关键词": [
            "强化学习",
            "分布外泛化",
            "预训练表征",
            "VAE",
            "机器人学习"
        ],
        "涉及的技术概念": {
            "预训练表征": "用于提供低维、高效的下游学习和泛化基础的表征",
            "VAE（变分自编码器）": "用于生成预训练表征的模型，评估其对强化学习智能体泛化能力的影响",
            "分布外（OOD）泛化": "指智能体在面对与训练数据分布不同的新环境时的表现能力"
        },
        "success": true
    },
    {
        "order": 972,
        "title": "The Spectral Bias of Polynomial Neural Networks",
        "html": "https://iclr.cc//virtual/2022/poster/6710",
        "abstract": "Polynomial neural networks (PNNs) have been recently shown to be particularly effective at image generation and face recognition, where high-frequency information is critical. Previous studies have revealed that neural networks demonstrate a $\\text{\\it{spectral bias}}$ towards low-frequency functions, which yields faster learning of low-frequency components during training. Inspired by such studies, we conduct a spectral analysis of the Neural Tangent Kernel (NTK) of PNNs. We find that the $\\Pi$-Net family, i.e., a recently proposed parametrization of PNNs, speeds up the learning of the higher frequencies. We verify the theoretical bias through extensive experiments. We expect our analysis to provide novel insights into designing architectures and learning frameworks by incorporating multiplicative interactions via polynomials. ",
        "conference": "ICLR",
        "中文标题": "多项式神经网络的频谱偏差",
        "摘要翻译": "多项式神经网络（PNNs）最近被证明在图像生成和人脸识别方面特别有效，这些领域高频信息至关重要。先前的研究表明，神经网络对低频函数表现出一种频谱偏差，这在训练过程中导致低频成分学习得更快。受这些研究的启发，我们对PNNs的神经切线核（NTK）进行了频谱分析。我们发现，Π-Net家族，即最近提出的一种PNNs参数化方法，加速了高频成分的学习。我们通过大量实验验证了这一理论偏差。我们期望我们的分析能够通过引入多项式乘法交互，为设计架构和学习框架提供新的见解。",
        "领域": "图像生成, 人脸识别, 神经网络架构设计",
        "问题": "研究多项式神经网络在频谱上的偏差特性及其对高频信息学习的影响",
        "动机": "探索和利用多项式神经网络在图像生成和人脸识别中对高频信息学习的优势",
        "方法": "通过频谱分析PNNs的神经切线核（NTK），并验证Π-Net家族在加速高频成分学习方面的效果",
        "关键词": [
            "多项式神经网络",
            "频谱偏差",
            "神经切线核",
            "高频学习",
            "Π-Net"
        ],
        "涉及的技术概念": {
            "多项式神经网络（PNNs）": "一种利用多项式激活函数的神经网络，特别适用于需要高频信息的任务",
            "频谱偏差": "神经网络在学习过程中对低频成分的偏好现象",
            "神经切线核（NTK）": "用于分析神经网络训练动态的理论工具，本研究用于分析PNNs的频谱特性"
        },
        "success": true
    },
    {
        "order": 973,
        "title": "The Three Stages of Learning Dynamics in High-dimensional Kernel Methods",
        "html": "https://iclr.cc//virtual/2022/poster/7181",
        "abstract": "To understand how deep learning works, it is crucial to understand the training dynamics of neural networks. Several interesting hypotheses about these dynamics have been made based on empirically observed phenomena, but there exists a limited theoretical understanding of when and why such phenomena occur. In this paper, we consider the training dynamics of gradient flow on kernel least-squares objectives, which is a limiting dynamics of SGD trained neural networks. Using precise high-dimensional asymptotics, we characterize the dynamics of the fitted model in two “worlds”: in the Oracle World the model is trained on the population distribution and in the Empirical World the model is trained on an i.i.d finite dataset. We show that under mild conditions on the kernel and $L^2$ target regression function the training dynamics have three stages that are based on the behaviors of the models in the two worlds. Our theoretical results also mathematically formalize some interesting deep learning phenomena. Specifically, in our setting we show that SGD progressively learns more complex functions and that there is a 'deep bootstrap' phenomenon: during the second stage, the test error of both worlds remain close despite the empirical training error being much smaller. Finally, we give a concrete example comparing the dynamics of two different kernels which shows that faster training is not necessary for better generalization.",
        "conference": "ICLR",
        "中文标题": "高维核方法学习动力学的三个阶段",
        "摘要翻译": "为了理解深度学习的工作原理，关键在于理解神经网络的训练动力学。基于经验观察到的现象，人们提出了几个关于这些动力学有趣假设，但对于这些现象何时以及为何发生的理论理解仍然有限。在本文中，我们考虑了核最小二乘目标上梯度流的训练动力学，这是SGD训练神经网络的极限动力学。利用精确的高维渐近分析，我们描述了拟合模型在两个“世界”中的动力学：在“预言世界”中，模型是在总体分布上训练的；在“经验世界”中，模型是在一个独立同分布的有限数据集上训练的。我们表明，在核和L2目标回归函数的温和条件下，训练动力学具有基于两个世界中模型行为的三个阶段。我们的理论结果也在数学上形式化了一些有趣的深度学习现象。具体来说，在我们的设置中，我们展示了SGD逐步学习更复杂的函数，并且存在一个“深度引导”现象：在第二阶段，两个世界的测试误差保持接近，尽管经验训练误差要小得多。最后，我们给出了一个具体例子，比较了两种不同核的动力学，表明更快的训练并不一定意味着更好的泛化。",
        "领域": "深度学习理论、核方法、梯度下降优化",
        "问题": "理解深度学习训练动力学的理论基础，特别是在高维核方法中的表现。",
        "动机": "基于对深度学习训练过程中观察到的现象缺乏理论解释，研究旨在填补这一空白，特别是在核方法和梯度流动力学方面。",
        "方法": "使用高维渐近分析技术，研究在总体分布和有限数据集上训练的模型的动力学行为，识别训练过程中的三个阶段。",
        "关键词": [
            "高维渐近分析",
            "核方法",
            "梯度流动力学",
            "深度学习理论",
            "SGD训练"
        ],
        "涉及的技术概念": {
            "核最小二乘目标": "用于描述梯度流训练的目标函数，是理解SGD训练神经网络极限动力学的关键。",
            "高维渐近分析": "用于精确描述在高维空间中模型训练动力学行为的技术。",
            "深度引导现象": "描述了在训练过程中，尽管经验训练误差显著降低，测试误差在两个世界中保持接近的现象。"
        },
        "success": true
    },
    {
        "order": 974,
        "title": "The Uncanny Similarity of Recurrence and Depth",
        "html": "https://iclr.cc//virtual/2022/poster/6385",
        "abstract": "It is widely believed that deep neural networks contain layer specialization, wherein networks extract hierarchical features representing edges and patterns in shallow layers and complete objects in deeper layers. Unlike common feed-forward models that have distinct filters at each layer, recurrent networks reuse the same parameters at various depths. In this work, we observe that recurrent models exhibit the same hierarchical behaviors and the same performance benefits as depth despite reusing the same filters at every recurrence. By training models of various feed-forward and recurrent architectures on several datasets for image classification as well as maze solving, we show that recurrent networks have the ability to closely emulate the behavior of non-recurrent deep models, often doing so with far fewer parameters.",
        "conference": "ICLR",
        "中文标题": "循环与深度的惊人相似性",
        "摘要翻译": "人们普遍认为，深度神经网络包含层次专业化，其中网络在浅层提取代表边缘和模式的层次特征，在深层提取完整对象。与在每个层具有不同过滤器的常见前馈模型不同，循环网络在不同深度重复使用相同的参数。在这项工作中，我们观察到，尽管在每个循环中重复使用相同的过滤器，循环模型展现出与深度相同的层次行为和相同的性能优势。通过在多个数据集上训练各种前馈和循环架构的模型进行图像分类以及迷宫解决，我们展示了循环网络有能力紧密模仿非循环深度模型的行为，通常使用更少的参数即可实现。",
        "领域": "深度学习架构设计, 循环神经网络, 图像分类",
        "问题": "探索循环神经网络在参数共享的情况下如何模仿深度前馈网络的层次行为和性能优势。",
        "动机": "研究循环网络是否能够在重复使用相同参数的情况下，达到与深度前馈网络相似的层次特征提取和性能表现。",
        "方法": "通过在图像分类和迷宫解决任务上训练和比较不同架构的前馈和循环网络模型，分析其行为和性能。",
        "关键词": [
            "循环神经网络",
            "深度前馈网络",
            "参数共享",
            "层次特征",
            "图像分类"
        ],
        "涉及的技术概念": {
            "层次专业化": "指深度神经网络在不同层次提取不同级别的特征，从边缘和模式到完整对象。",
            "参数共享": "循环网络在不同时间步或深度重复使用相同的权重参数，以减少模型参数数量。",
            "性能优势": "指循环网络在参数较少的情况下，能够达到或接近深度前馈网络的性能表现。"
        },
        "success": true
    },
    {
        "order": 975,
        "title": "The Unreasonable Effectiveness of Random Pruning: Return of the Most Naive Baseline for Sparse Training",
        "html": "https://iclr.cc//virtual/2022/poster/6925",
        "abstract": "Random pruning is arguably the most naive way to attain sparsity in neural networks, but has been deemed uncompetitive by either post-training pruning or sparse training. In this paper, we focus on sparse training and highlight a perhaps counter-intuitive finding, that random pruning at initialization can be quite powerful for the sparse training of modern neural networks. Without any delicate pruning criteria or carefully pursued sparsity structures, we empirically demonstrate that sparsely training a randomly pruned network from scratch can match the performance of its dense equivalent. There are two key factors that contribute to this revival: (i) $the network sizes matter$: as the original dense networks grow wider and deeper, the performance of training a randomly pruned sparse network will quickly grow to matching that of its dense equivalent, even at high sparsity ratios; (ii) $appropriate layer-wise sparsity ratios$ can be pre-chosen for sparse training, which shows to be another important performance booster. Simple as it looks,  a randomly pruned subnetwork of Wide ResNet-50 can be sparsely trained to outperforming a dense Wide ResNet-50, on ImageNet. We also observed such randomly pruned networks outperform dense counterparts in other favorable aspects, such as out-of-distribution detection, uncertainty estimation, and adversarial robustness. Overall, our results strongly suggest there is larger-than-expected room for sparse training at scale, and the benefits of sparsity might be more universal beyond carefully designed pruning. Our source code can be found at https://github.com/VITA-Group/Random_Pruning.",
        "conference": "ICLR",
        "中文标题": "随机剪枝的不合理有效性：回归稀疏训练中最朴素基线",
        "摘要翻译": "随机剪枝可以说是神经网络中获得稀疏性最朴素的方式，但一直被认为不如训练后剪枝或稀疏训练有竞争力。在本文中，我们专注于稀疏训练，并强调了一个可能反直觉的发现：初始化时的随机剪枝对于现代神经网络的稀疏训练可以非常有效。没有任何精细的剪枝标准或精心追求的稀疏结构，我们经验性地证明，从头开始稀疏训练一个随机剪枝的网络可以匹配其密集等价物的性能。有两个关键因素促成了这一复兴：(i) 网络大小很重要：随着原始密集网络变得更宽更深，训练一个随机剪枝的稀疏网络的性能将迅速增长到与其密集等价物相匹配，即使在高的稀疏比下也是如此；(ii) 可以预先为稀疏训练选择适当的层间稀疏比，这显示出是另一个重要的性能提升器。看起来简单，一个随机剪枝的Wide ResNet-50子网络可以在ImageNet上稀疏训练，性能超过密集的Wide ResNet-50。我们还观察到，这种随机剪枝的网络在其他有利方面也优于密集对应物，如分布外检测、不确定性估计和对抗鲁棒性。总的来说，我们的结果强烈表明，大规模稀疏训练的空间比预期更大，稀疏性的好处可能比精心设计的剪枝更普遍。我们的源代码可以在https://github.com/VITA-Group/Random_Pruning找到。",
        "领域": "神经网络稀疏化、深度学习优化、计算机视觉",
        "问题": "探索随机剪枝在稀疏训练中的有效性及其与现代神经网络性能的匹配能力",
        "动机": "重新评估随机剪枝作为稀疏训练方法的潜力，挑战传统认为其不具竞争力的观点",
        "方法": "通过实证研究，展示在宽深网络中使用随机剪枝和适当层间稀疏比进行稀疏训练的有效性",
        "关键词": [
            "随机剪枝",
            "稀疏训练",
            "神经网络优化",
            "ImageNet",
            "对抗鲁棒性"
        ],
        "涉及的技术概念": {
            "随机剪枝": "在神经网络初始化时随机移除权重，作为稀疏训练的一种朴素方法",
            "稀疏训练": "训练过程中保持网络权重的稀疏性，以提高效率和性能",
            "层间稀疏比": "不同网络层采用不同的稀疏比例，以优化整体网络性能"
        },
        "success": true
    },
    {
        "order": 976,
        "title": "THOMAS: Trajectory Heatmap Output with learned Multi-Agent Sampling",
        "html": "https://iclr.cc//virtual/2022/poster/6793",
        "abstract": "In this paper, we propose THOMAS, a joint multi-agent trajectory prediction framework allowing for an efficient and consistent prediction of multi-agent multi-modal trajectories. We present a unified model architecture for simultaneous agent future heatmap estimation, in which we leverage hierarchical and sparse image generation for fast and memory-efficient inference. We propose a learnable trajectory recombination model that takes as input a set of predicted trajectories for each agent and outputs its consistent reordered recombination. This recombination module is able to realign the initially independent modalities so that they do no collide and are coherent with each other.  We report our results on the Interaction multi-agent prediction challenge and rank $1^{st}$ on the online test leaderboard.",
        "conference": "ICLR",
        "中文标题": "THOMAS：基于学习多智能体采样的轨迹热图输出",
        "摘要翻译": "在本文中，我们提出了THOMAS，一个联合多智能体轨迹预测框架，能够高效且一致地预测多智能体多模态轨迹。我们提出了一个统一的模型架构，用于同时估计智能体未来的热图，其中我们利用分层和稀疏的图像生成技术，以实现快速且内存高效的推理。我们提出了一种可学习的轨迹重组模型，该模型以每个智能体的一组预测轨迹作为输入，并输出其一致的重排序重组。这个重组模块能够重新对齐最初独立的模态，使它们不会发生碰撞并且彼此一致。我们在Interaction多智能体预测挑战中报告了我们的结果，并在在线测试排行榜上排名第一。",
        "领域": "多智能体轨迹预测、自动驾驶、智能交通系统",
        "问题": "如何高效且一致地预测多智能体在多模态情况下的未来轨迹",
        "动机": "为了解决多智能体轨迹预测中的一致性和效率问题，特别是在多模态情况下避免轨迹冲突和提高预测的准确性",
        "方法": "提出了一个联合多智能体轨迹预测框架THOMAS，包括统一的模型架构用于热图估计和可学习的轨迹重组模型",
        "关键词": [
            "多智能体轨迹预测",
            "热图估计",
            "轨迹重组",
            "多模态预测",
            "自动驾驶"
        ],
        "涉及的技术概念": {
            "联合多智能体轨迹预测框架": "用于高效且一致地预测多智能体在多模态情况下的未来轨迹",
            "分层和稀疏的图像生成技术": "用于实现快速且内存高效的推理",
            "可学习的轨迹重组模型": "用于重新对齐最初独立的模态，避免碰撞并保持一致性"
        },
        "success": true
    },
    {
        "order": 977,
        "title": "Tighter Sparse Approximation Bounds for ReLU Neural Networks",
        "html": "https://iclr.cc//virtual/2022/poster/7185",
        "abstract": "A well-known line of work (Barron, 1993; Breiman, 1993; Klusowski & Barron, 2018) provides bounds on the width $n$ of a ReLU two-layer neural network needed to approximate a function $f$ over the ball $\\mathcal{B}_R(\\mathbb{R}^d)$ up to error $\\epsilon$, when the Fourier based quantity $C_f = \\int_{\\mathbb{R}^d} \\|\\xi\\|^2 |\\hat{f}(\\xi)| \\ d\\xi$ is finite. More recently Ongie et al. (2019) used the Radon transform as a tool for analysis of infinite-width ReLU two-layer networks. In particular, they introduce the concept of Radon-based $\\mathcal{R}$-norms and show that a function defined on $\\mathbb{R}^d$ can be represented as an infinite-width two-layer neural network if and only if its $\\mathcal{R}$-norm is finite. In this work, we extend the framework of Ongie et al. (2019) and define similar Radon-based semi-norms ($\\mathcal{R}, \\mathcal{U}$-norms) such that a function admits an infinite-width neural network representation on a bounded open set $\\mathcal{U} \\subseteq \\mathbb{R}^d$ when its $\\mathcal{R}, \\mathcal{U}$-norm is finite. Building on this, we derive sparse (finite-width) neural network approximation bounds that refine those of Breiman (1993); Klusowski & Barron (2018). Finally, we show that infinite-width neural network representations on bounded open sets are not unique and study their structure, providing a functional view of mode connectivity.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "ReLU神经网络更紧凑的稀疏逼近界",
        "摘要翻译": "一项著名的研究工作（Barron, 1993; Breiman, 1993; Klusowski & Barron, 2018）提供了ReLU两层神经网络的宽度n的界限，该宽度n用于在球$\\\\mathcal{B}_R(\\\\mathbb{R}^d)$上以误差$\\\\epsilon$逼近函数$f$，当基于傅里叶的量$C_f = \\\\int_{\\\\mathbb{R}^d} \\\\|\\\\xi\\\\|^2 |\\\\hat{f}(\\\\xi)| \\\\ d\\\\xi$是有限的时。最近，Ongie等人(2019)使用Radon变换作为分析无限宽度ReLU两层网络的工具。特别地，他们介绍了基于Radon的$\\\\mathcal{R}$-范数的概念，并表明如果且仅当其$\\\\mathcal{R}$-范数是有限的时，定义在$\\\\mathbb{R}^d$上的函数才能表示为无限宽度的两层神经网络。在这项工作中，我们扩展了Ongie等人(2019)的框架，并定义了类似的基于Radon的半范数（$\\\\mathcal{R}, \\\\mathcal{U}$-范数），使得当其$\\\\mathcal{R}, \\\\mathcal{U}$-范数是有限的时，函数允许在有界开集$\\\\mathcal{U} \\\\subseteq \\\\mathbb{R}^d$上进行无限宽度的神经网络表示。在此基础上，我们推导出稀疏（有限宽度）神经网络逼近界限，这些界限改进了Breiman (1993); Klusowski & Barron (2018)的界限。最后，我们表明有界开集上的无限宽度神经网络表示不是唯一的，并研究它们的结构，提供了模式连接的功能视图。",
        "领域": "神经网络压缩, 理论分析, 函数逼近",
        "问题": "论文旨在找到更紧凑的ReLU神经网络，使其在特定误差范围内逼近目标函数，并研究无限宽度网络表示的唯一性。",
        "动机": "现有的ReLU神经网络宽度界限不够紧凑，需要改进。同时，对无限宽度网络表示的唯一性和结构缺乏深入理解。",
        "方法": "论文扩展了基于Radon变换的分析框架，定义了新的Radon半范数（$\\\\mathcal{R}, \\\\mathcal{U}$-范数），并基于此推导出更紧凑的稀疏神经网络逼近界限。此外，研究了无限宽度网络表示的结构。",
        "关键词": [
            "ReLU神经网络",
            "稀疏逼近",
            "Radon变换",
            "函数逼近界",
            "模式连接"
        ],
        "涉及的技术概念": {
            "ReLU激活函数": "神经网络中常用的非线性激活函数，用于引入非线性特性。",
            "Radon变换": "一种积分变换，用于分析图像或函数的几何特性，论文中用于分析无限宽度ReLU网络的表示能力。"
        }
    },
    {
        "order": 978,
        "title": "ToM2C: Target-oriented Multi-agent Communication and Cooperation with Theory of Mind",
        "html": "https://iclr.cc//virtual/2022/poster/6578",
        "abstract": "Being able to predict the mental states of others is a key factor to effective social interaction. It is also crucial for distributed multi-agent systems, where agents are required to communicate and cooperate. In this paper, we introduce such an important social-cognitive skill, i.e. Theory of Mind (ToM), to build socially intelligent agents who are able to communicate and cooperate effectively to accomplish challenging tasks. With ToM, each agent is capable of inferring the mental states and intentions of others according to its (local) observation. Based on the inferred states, the agents decide 'when'' and with 'whom'' to share their intentions. With the information observed, inferred, and received, the agents decide their sub-goals and reach a consensus among the team. In the end, the low-level executors independently take primitive actions to accomplish the sub-goals. We demonstrate the idea in two typical target-oriented multi-agent tasks: cooperative navigation and multi-sensor target coverage. The experiments show that the proposed model not only outperforms the state-of-the-art methods on reward and communication efficiency, but also shows good generalization across different scales of the environment.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "ToM2C：基于心智理论的目标导向多智能体通信与合作",
        "摘要翻译": "能够预测他人的心理状态是有效社交互动的关键因素。这对于分布式多智能体系统也至关重要，因为系统内的智能体需要进行通信和合作。在本文中，我们引入了这样一种重要的社会认知技能，即心智理论（ToM），以构建能够有效沟通和合作完成挑战性任务的社交智能体。借助ToM，每个智能体能够根据其（局部）观察推断他人的心理状态和意图。基于推断出的状态，智能体决定‘何时’与‘谁’分享其意图。根据观察、推断和接收到的信息，智能体决定其子目标并在团队中达成共识。最后，低层执行器独立采取原始行动以完成子目标。我们在两个典型的目标导向多智能体任务中展示了这一理念：合作导航和多传感器目标覆盖。实验表明，所提出的模型不仅在奖励和通信效率上优于最先进的方法，而且在不同规模的环境中显示出良好的泛化能力。",
        "领域": "多智能体系统, 社交智能体, 合作导航",
        "问题": "如何在多智能体系统中实现有效的通信与合作，以完成复杂的任务",
        "动机": "通过引入心智理论（ToM），提升多智能体系统的社交智能，使其能够更有效地沟通和合作",
        "方法": "利用心智理论（ToM）使智能体能够推断他人的心理状态和意图，基于此决定通信和合作策略，最终通过低层执行器完成子目标",
        "关键词": [
            "心智理论",
            "多智能体系统",
            "合作导航",
            "社交智能体",
            "目标覆盖"
        ],
        "涉及的技术概念": {
            "心智理论（ToM）": "用于使智能体能够推断他人的心理状态和意图，从而提升通信和合作的效率",
            "合作导航": "展示ToM2C模型在多智能体合作导航任务中的应用",
            "多传感器目标覆盖": "展示ToM2C模型在多传感器环境下的目标覆盖任务中的应用"
        }
    },
    {
        "order": 979,
        "title": "Top-label calibration and multiclass-to-binary reductions",
        "html": "https://iclr.cc//virtual/2022/poster/6278",
        "abstract": "We investigate the relationship between commonly considered notions of multiclass calibration and the calibration algorithms used to achieve these notions, leading to two broad contributions. First, we propose a new and arguably natural notion of top-label calibration, which requires the reported probability of the most likely label to be calibrated. Along the way, we highlight certain philosophical issues with the closely related and popular notion of confidence calibration. Second, we outline general 'wrapper' multiclass-to-binary (M2B) algorithms that can be used to achieve confidence, top-label, and class-wise calibration, using underlying binary calibration routines. Our wrappers can also be generalized to other notions of calibration, if required for certain practical applications. We instantiate these wrappers with the binary histogram binning (HB) algorithm, and show that the overall procedure has distribution-free calibration guarantees. In an empirical evaluation, we find that with the right M2B wrapper, HB performs significantly better than other calibration approaches. Code for this work is available at https://github.com/aigen/df-posthoc-calibration.",
        "conference": "ICLR",
        "中文标题": "顶层标签校准与多类到二类的简化方法",
        "摘要翻译": "我们研究了多类校准的常见概念与用于实现这些概念的校准算法之间的关系，提出了两大贡献。首先，我们提出了一个新的、可以说是更自然的顶层标签校准概念，它要求最可能标签的报告概率是校准的。在此过程中，我们强调了与密切相关且流行的置信度校准概念的某些哲学问题。其次，我们概述了通用的‘包装器’多类到二类（M2B）算法，这些算法可以利用基础的二类校准程序来实现置信度、顶层标签和类别的校准。如果需要，我们的包装器还可以推广到其他校准概念，以适应某些实际应用的需求。我们用二类直方图分箱（HB）算法实例化了这些包装器，并展示了整个过程具有无分布校准保证。在实证评估中，我们发现使用正确的M2B包装器时，HB的表现显著优于其他校准方法。本工作的代码可在https://github.com/aigen/df-posthoc-calibration获取。",
        "领域": "机器学习模型校准、多类分类、二类分类",
        "问题": "解决多类分类中的校准问题，特别是顶层标签校准和如何通过多类到二类的简化方法实现有效的校准。",
        "动机": "研究多类校准的不同概念及其实现算法之间的关系，提出更自然的顶层标签校准概念，并开发通用的多类到二类校准算法。",
        "方法": "提出顶层标签校准的新概念，开发通用的多类到二类（M2B）校准算法，并使用二类直方图分箱（HB）算法实例化这些算法。",
        "关键词": [
            "顶层标签校准",
            "多类到二类简化",
            "直方图分箱",
            "模型校准",
            "无分布校准"
        ],
        "涉及的技术概念": {
            "顶层标签校准": "要求模型对最可能标签的概率预测是校准的，即预测概率与实际概率一致。",
            "多类到二类（M2B）算法": "将多类分类问题转化为二类分类问题，以便利用二类校准技术实现多类校准。",
            "直方图分箱（HB）算法": "一种二类校准算法，通过将预测概率分箱来实现校准，本研究中用于实例化M2B包装器。"
        },
        "success": true
    },
    {
        "order": 980,
        "title": "Top-N: Equivariant Set and Graph Generation without Exchangeability",
        "html": "https://iclr.cc//virtual/2022/poster/6635",
        "abstract": "This work addresses one-shot set and graph generation, and, more specifically, the parametrization of probabilistic decoders that map a vector-shaped prior to a distribution over sets or graphs. Sets and graphs are most commonly generated by first sampling points i.i.d. from a normal distribution, and then processing these points along with the prior vector using Transformer layers or Graph Neural Networks. This architecture is designed to generate exchangeable distributions, i.e., all permutations of the generated outputs are equally likely. We however show that it only optimizes a proxy to the evidence lower bound, which makes it hard to train. We then study equivariance in generative settings and show that non-exchangeable methods can still achieve permutation equivariance. Using this result, we introduce Top-n creation, a differentiable generation mechanism that uses the latent vector to select the most relevant points from a trainable reference set. Top-n can replace i.i.d. generation in any Variational Autoencoder or Generative Adversarial Network. Experimentally, our method outperforms i.i.d. generation by 15% at SetMNIST reconstruction, by 33% at object detection on CLEVR, generates sets that are 74% closer to the true distribution on a synthetic molecule-like dataset, and generates more valid molecules on QM9. ",
        "conference": "ICLR",
        "中文标题": "Top-N：无需交换性的等变集合与图生成",
        "摘要翻译": "本工作解决了一次性集合与图生成的问题，更具体地说，是概率解码器的参数化问题，这些解码器将向量形状的先验映射到集合或图的分布上。集合和图最常通过首先从正态分布中独立同分布地采样点，然后使用Transformer层或图神经网络处理这些点与先验向量来生成。这种架构设计用于生成可交换的分布，即生成输出的所有排列同样可能。然而，我们表明它仅优化了证据下界的代理，这使得训练变得困难。然后，我们研究了生成设置中的等变性，并表明非交换性方法仍然可以实现排列等变性。利用这一结果，我们引入了Top-n创建，一种可微分的生成机制，使用潜在向量从可训练的参考集中选择最相关的点。Top-n可以在任何变分自编码器或生成对抗网络中替换独立同分布生成。实验上，我们的方法在SetMNIST重建上比独立同分布生成高出15%，在CLEVR上的物体检测高出33%，在合成分子类数据集上生成的集合比真实分布接近74%，并且在QM9上生成更多有效的分子。",
        "领域": "图生成、集合生成、变分自编码器",
        "问题": "解决一次性集合与图生成中的概率解码器参数化问题，以及独立同分布采样导致的训练困难问题。",
        "动机": "研究非交换性方法在生成等变分布中的潜力，以克服现有方法仅优化证据下界代理导致的训练困难。",
        "方法": "引入Top-n创建机制，通过潜在向量从可训练的参考集中选择最相关的点，替代传统的独立同分布生成方法。",
        "关键词": [
            "等变性",
            "Top-n创建",
            "变分自编码器",
            "生成对抗网络",
            "图生成"
        ],
        "涉及的技术概念": {
            "等变性": "在生成模型中保持输入排列不变性的性质，使得模型能够处理不同排列的输入。",
            "Top-n创建": "一种可微分的生成机制，通过选择最相关的点来生成集合或图，替代传统的独立同分布采样。",
            "变分自编码器": "一种生成模型，通过学习数据的潜在分布来生成新的数据点，本研究中用于集合与图的生成。"
        },
        "success": true
    },
    {
        "order": 981,
        "title": "Topological Experience Replay",
        "html": "https://iclr.cc//virtual/2022/poster/6567",
        "abstract": "State-of-the-art deep Q-learning methods update Q-values using state transition tuples sampled from the experience replay buffer. This strategy often randomly samples or prioritizes data sampling based on measures such as the temporal difference (TD) error. Such sampling strategies can be inefficient at learning Q-function since a state's correct Q-value preconditions on the accurate successor states' Q-value. Disregarding such a successor's value dependency leads to useless updates and even learning wrong values.To expedite Q-learning, we maintain states' dependency by organizing the agent's experience into a graph. Each edge in the graph represents a transition between two connected states. We perform value backups via a breadth-first search that expands vertices in the graph starting from the set of terminal states successively moving backward. We empirically show that our method is substantially more data-efficient than several baselines on a diverse range of goal-reaching tasks. Notably, the proposed method also outperforms baselines that consume more batches of training experience. ",
        "conference": "ICLR",
        "中文标题": "拓扑经验回放",
        "摘要翻译": "最先进的深度Q学习方法使用从经验回放缓冲区采样的状态转移元组来更新Q值。这种策略通常基于诸如时间差分（TD）误差等度量随机采样或优先采样数据。这样的采样策略在学习Q函数时可能效率低下，因为一个状态的正确Q值以准确后继状态的Q值为前提。忽视这种后继值的依赖性会导致无用的更新甚至学习错误的值。为了加速Q学习，我们通过将代理的经验组织成一个图来维持状态的依赖性。图中的每条边代表两个连接状态之间的转移。我们通过广度优先搜索执行值备份，该搜索从终端状态集开始，依次向后移动，扩展图中的顶点。我们实证表明，我们的方法在多种目标达成任务上比几种基线方法数据效率显著更高。值得注意的是，所提出的方法也优于消耗更多训练经验批次的基线方法。",
        "领域": "强化学习、深度Q学习、经验回放优化",
        "问题": "提高深度Q学习中经验回放的数据效率和准确性",
        "动机": "现有的经验回放策略忽视了状态间Q值的依赖性，导致学习效率低下和可能的错误学习",
        "方法": "通过将代理的经验组织成图结构，并利用广度优先搜索从终端状态开始逆向更新Q值，以维持状态间的依赖性",
        "关键词": [
            "拓扑经验回放",
            "深度Q学习",
            "数据效率",
            "广度优先搜索",
            "经验回放优化"
        ],
        "涉及的技术概念": {
            "经验回放缓冲区": "存储代理的经验（状态转移元组）以供后续学习使用",
            "时间差分误差": "用于衡量当前Q值与目标Q值之间的差异，常用于优先经验回放",
            "广度优先搜索": "用于从终端状态开始逆向更新图中的Q值，确保状态间的依赖性得到考虑"
        },
        "success": true
    },
    {
        "order": 982,
        "title": "Topological Graph Neural Networks",
        "html": "https://iclr.cc//virtual/2022/poster/6389",
        "abstract": "Graph neural networks (GNNs) are a powerful architecture for tackling graph learning tasks, yet have been shown to be oblivious to eminent substructures such as cycles. We present TOGL, a novel layer that incorporates global topological information of a graph using persistent homology. TOGL can be easily integrated into any type of GNN and is strictly more expressive (in terms the Weisfeiler–Lehman graph isomorphism test) than message-passing GNNs. Augmenting GNNs with TOGL leads to improved predictive performance for graph and node classification tasks, both on synthetic data sets, which can be classified by humans using their topology but not by ordinary GNNs, and on real-world data.",
        "conference": "ICLR",
        "中文标题": "拓扑图神经网络",
        "摘要翻译": "图神经网络（GNNs）是解决图学习任务的强大架构，但已被证明对诸如循环这样的显著子结构视而不见。我们提出了TOGL，一种利用持久同源性融入图的全局拓扑信息的新层。TOGL可以轻松集成到任何类型的GNN中，并且在表达能力上（依据Weisfeiler-Lehman图同构测试）严格优于消息传递GNNs。通过用TOGL增强GNNs，在图和节点分类任务上的预测性能得到了提升，无论是在合成数据集上——这些数据集可以通过其拓扑结构由人类分类，但不能由普通GNNs分类——还是在真实世界数据上。",
        "领域": "图神经网络、拓扑数据分析、图分类",
        "问题": "图神经网络在处理图数据时对显著子结构（如循环）的忽视问题",
        "动机": "提升图神经网络对图数据中全局拓扑结构的识别能力，以改善图和节点分类任务的性能",
        "方法": "提出了一种新型层TOGL，利用持久同源性将图的全局拓扑信息融入图神经网络中",
        "关键词": [
            "拓扑图神经网络",
            "持久同源性",
            "图分类",
            "节点分类",
            "Weisfeiler-Lehman测试"
        ],
        "涉及的技术概念": {
            "持久同源性": "用于捕捉和量化图数据的全局拓扑特征，增强模型对图结构的理解",
            "Weisfeiler-Lehman图同构测试": "用于评估图神经网络的表达能力，TOGL在此测试中表现优于传统消息传递GNNs",
            "消息传递GNNs": "传统的图神经网络方法，通过节点间的消息传递来学习图表示，但对某些子结构不敏感"
        },
        "success": true
    },
    {
        "order": 983,
        "title": "Topologically Regularized Data Embeddings",
        "html": "https://iclr.cc//virtual/2022/poster/6844",
        "abstract": "Unsupervised feature learning often finds low-dimensional embeddings that capture the structure of complex data.  For tasks for which prior expert topological knowledge is available, incorporating this into the learned representation may lead to higher quality embeddings. For example, this may help one to embed the data into a given number of clusters, or to accommodate for noise that prevents one from deriving the distribution of the data over the model directly, which can then be learned more effectively. However, a general tool for integrating different prior topological knowledge into embeddings is lacking. Although differentiable topology layers have been recently developed that can (re)shape embeddings into prespecified topological models, they have two important limitations for representation learning, which we address in this paper. First, the currently suggested topological losses fail to represent simple models such as clusters and flares in a natural manner. Second, these losses neglect all original structural (such as neighborhood) information in the data that is useful for learning. We overcome these limitations by introducing a new set of topological losses, and proposing their usage as a way for topologically regularizing data embeddings to naturally represent a prespecified model. We include thorough experiments on synthetic and real data that highlight the usefulness and versatility of this approach, with applications ranging from modeling high-dimensional single-cell data, to graph embedding.",
        "conference": "ICLR",
        "中文标题": "拓扑正则化的数据嵌入",
        "摘要翻译": "无监督特征学习常常能找到捕捉复杂数据结构的低维嵌入。对于已有先验专家拓扑知识的任务，将这些知识融入学习到的表示中可能会产生更高质量的嵌入。例如，这可能帮助人们将数据嵌入到给定数量的簇中，或者适应噪声，这些噪声阻碍了直接从模型推导出数据的分布，从而可以更有效地学习。然而，目前缺乏一种将不同先验拓扑知识整合到嵌入中的通用工具。尽管最近开发的可微分拓扑层可以将嵌入（重新）塑形为预定的拓扑模型，但它们在表示学习方面有两个重要的限制，我们在本文中解决了这些问题。首先，目前提出的拓扑损失未能以自然的方式表示简单的模型，如簇和耀斑。其次，这些损失忽略了数据中所有对学习有用的原始结构（如邻域）信息。我们通过引入一组新的拓扑损失，并建议将其用作拓扑正则化数据嵌入以自然表示预定模型的方式，克服了这些限制。我们在合成数据和真实数据上进行了全面的实验，突出了这种方法的有用性和多功能性，应用范围从高维单细胞数据建模到图嵌入。",
        "领域": "无监督学习, 数据嵌入, 拓扑数据分析",
        "问题": "如何将先验拓扑知识有效地整合到数据嵌入中，以生成更高质量的嵌入表示",
        "动机": "现有的拓扑损失无法自然表示简单模型，且忽略了数据中的有用结构信息，限制了表示学习的质量和应用范围",
        "方法": "引入新的拓扑损失函数，作为拓扑正则化手段，用于数据嵌入以自然表示预定模型",
        "关键词": [
            "拓扑正则化",
            "数据嵌入",
            "无监督学习",
            "拓扑损失",
            "表示学习"
        ],
        "涉及的技术概念": {
            "拓扑正则化": "通过引入拓扑损失函数，将先验拓扑知识融入数据嵌入过程，以优化嵌入质量",
            "数据嵌入": "将高维数据映射到低维空间，同时保留或突出数据的某些特性或结构",
            "拓扑损失": "专门设计的损失函数，用于衡量嵌入数据与预定拓扑模型之间的差异，指导模型学习"
        },
        "success": true
    },
    {
        "order": 984,
        "title": "Toward Efficient Low-Precision Training: Data Format Optimization and Hysteresis Quantization",
        "html": "https://iclr.cc//virtual/2022/poster/6023",
        "abstract": "As the complexity and size of deep neural networks continue to increase, low-precision training has been extensively studied in the last few years to reduce hardware overhead. Training performance is largely affected by the numeric formats representing different values in low-precision training, but finding an optimal format typically requires numerous training runs, which is a very time-consuming process. In this paper, we propose a method to efficiently find an optimal format for activations and errors without actual training. We employ this method to determine an 8-bit format suitable for training various models. In addition, we propose hysteresis quantization to suppress undesired fluctuation in quantized weights during training. This scheme enables deeply quantized training using 4-bit weights, exhibiting only 0.2% degradation for ResNet-18 trained on ImageNet.",
        "conference": "ICLR",
        "中文标题": "迈向高效低精度训练：数据格式优化与滞后量化",
        "摘要翻译": "随着深度神经网络复杂性和规模的不断增加，低精度训练在过去几年中被广泛研究以减少硬件开销。训练性能在很大程度上受到低精度训练中表示不同值的数字格式的影响，但找到最优格式通常需要大量的训练运行，这是一个非常耗时的过程。在本文中，我们提出了一种方法，无需实际训练即可高效找到激活和误差的最优格式。我们采用这种方法来确定适用于训练各种模型的8位格式。此外，我们提出了滞后量化来抑制训练期间量化权重的非期望波动。该方案使得使用4位权重进行深度量化训练成为可能，对于在ImageNet上训练的ResNet-18，仅表现出0.2%的性能下降。",
        "领域": "深度学习优化、神经网络训练加速、量化训练",
        "问题": "如何在低精度训练中高效找到最优的数据格式并减少量化权重的不稳定性",
        "动机": "减少低精度训练中的硬件开销和训练时间，同时保持模型性能",
        "方法": "提出了一种无需实际训练即可确定最优数据格式的方法，并引入滞后量化技术以减少量化权重的波动",
        "关键词": [
            "低精度训练",
            "数据格式优化",
            "滞后量化",
            "神经网络加速",
            "量化权重"
        ],
        "涉及的技术概念": {
            "低精度训练": "使用比传统浮点数更少的位数来表示和计算神经网络中的权重和激活值，以减少计算和存储开销",
            "数据格式优化": "通过算法确定在低精度训练中最优的数字表示格式，以提高训练效率和模型性能",
            "滞后量化": "一种量化技术，通过在训练过程中动态调整量化参数来减少量化权重的波动，从而提高训练的稳定性和模型的最终性能"
        },
        "success": true
    },
    {
        "order": 985,
        "title": "Toward Faithful Case-based Reasoning through Learning Prototypes in a Nearest Neighbor-friendly Space.",
        "html": "https://iclr.cc//virtual/2022/poster/6132",
        "abstract": "Recent advances in machine learning have brought opportunities for the ever-increasing use of AI in the real world. This has created concerns about the black-box nature of many of the most recent machine learning approaches. In this work, we propose an interpretable neural network that leverages metric and prototype learning for classification tasks. It encodes its own explanations and provides an improved case-based reasoning through learning prototypes in an embedding space learned by a probabilistic nearest neighbor rule. Through experiments, we demonstrated the effectiveness of the proposed method in both performance and the accuracy of the explanations provided.",
        "conference": "ICLR",
        "中文标题": "通过学习最近邻友好空间中的原型实现忠实的基于案例的推理",
        "摘要翻译": "机器学习的最新进展为AI在现实世界中的日益广泛应用带来了机遇。这引发了对许多最新机器学习方法黑箱性质的担忧。在这项工作中，我们提出了一种可解释的神经网络，该网络利用度量和原型学习进行分类任务。它通过在学习由概率最近邻规则学习的嵌入空间中的原型，编码自己的解释并提供改进的基于案例的推理。通过实验，我们证明了所提出方法在性能和提供解释的准确性方面的有效性。",
        "领域": "可解释人工智能、原型学习、度量学习",
        "问题": "解决机器学习模型的黑箱性质问题，提高模型的可解释性",
        "动机": "为了应对AI应用中对于模型透明度和可解释性日益增长的需求，开发一种能够提供清晰解释的机器学习方法",
        "方法": "提出了一种结合度量和原型学习的可解释神经网络，通过学习嵌入空间中的原型来改进基于案例的推理",
        "关键词": [
            "可解释性",
            "原型学习",
            "度量学习",
            "基于案例的推理",
            "最近邻规则"
        ],
        "涉及的技术概念": {
            "可解释神经网络": "一种设计用于提供模型决策过程透明度的神经网络，旨在解决黑箱模型的可解释性问题",
            "原型学习": "通过学习数据中的典型代表（原型）来改进分类和解释能力的技术",
            "度量学习": "通过学习数据点之间的距离度量来优化分类性能的方法，有助于提高模型的解释性和性能"
        },
        "success": true
    },
    {
        "order": 986,
        "title": "Towards a Unified View of Parameter-Efficient Transfer Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6524",
        "abstract": "Fine-tuning large pretrained language models on downstream tasks has become the de-facto learning paradigm in NLP. However, conventional approaches fine-tune all the parameters of the pretrained model, which becomes prohibitive as the model size and the number of tasks grow. Recent work has proposed a variety of parameter-efficient transfer learning methods that only fine-tune a small number of (extra) parameters to attain strong performance. While effective, the critical ingredients for success and the connections among the various methods are poorly understood. In this paper, we break down the design of state-of-the-art parameter-efficient transfer learning methods and present a unified framework that establishes connections between them. Specifically, we re-frame them as modifications to specific hidden states in pretrained models, and define a set of design dimensions along which different methods vary, such as the function to compute the modification and the position to apply the modification. Through comprehensive empirical studies across machine translation, text summarization, language understanding, and text classification benchmarks, we utilize the unified view to identify important design choices in previous methods. Furthermore, our unified framework enables the transfer of design elements across different approaches, and as a result we are able to instantiate new parameter-efficient fine-tuning methods that tune less parameters than previous methods while being more effective, achieving comparable results to fine-tuning all parameters on all four tasks.",
        "conference": "ICLR",
        "中文标题": "迈向参数高效迁移学习的统一视角",
        "摘要翻译": "在下游任务上微调大型预训练语言模型已成为NLP领域的事实学习范式。然而，传统方法微调预训练模型的所有参数，随着模型大小和任务数量的增加，这种方法变得不可行。最近的工作提出了多种参数高效的迁移学习方法，这些方法仅微调少量（额外）参数即可获得强大的性能。虽然有效，但对于成功的关键因素以及各种方法之间的联系理解不足。在本文中，我们分解了最先进的参数高效迁移学习方法的设计，并提出了一个统一框架，建立了它们之间的联系。具体来说，我们将它们重新定义为对预训练模型中特定隐藏状态的修改，并定义了一组设计维度，不同方法在这些维度上有所不同，例如计算修改的函数和应用修改的位置。通过在机器翻译、文本摘要、语言理解和文本分类基准上的全面实证研究，我们利用统一视角识别了先前方法中的重要设计选择。此外，我们的统一框架使得设计元素能够在不同方法之间转移，因此我们能够实例化新的参数高效微调方法，这些方法比先前的方法调整更少的参数同时更有效，在所有四个任务上实现了与微调所有参数相当的结果。",
        "领域": "自然语言处理与视觉结合",
        "问题": "如何在减少参数调整量的同时保持或提升模型在下游任务上的性能",
        "动机": "解决传统微调方法在大模型和多任务场景下参数调整量大、计算成本高的问题",
        "方法": "提出一个统一框架，将现有参数高效迁移学习方法重新定义为对预训练模型隐藏状态的修改，并通过实证研究识别关键设计选择",
        "关键词": [
            "参数高效迁移学习",
            "统一框架",
            "隐藏状态修改",
            "设计维度",
            "微调方法"
        ],
        "涉及的技术概念": {
            "参数高效迁移学习": "一种仅微调少量参数即可在下游任务上获得强大性能的迁移学习方法",
            "隐藏状态修改": "对预训练模型中特定隐藏状态进行调整以适配下游任务的技术手段",
            "设计维度": "用于区分不同参数高效迁移学习方法的关键设计方面，如修改函数和应用位置"
        },
        "success": true
    },
    {
        "order": 987,
        "title": "Towards Better Understanding and Better Generalization of Low-shot Classification in Histology Images with Contrastive Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6718",
        "abstract": "Few-shot learning is an established topic in natural images for years, but few work is attended to histology images, which is of high clinical value since well-labeled datasets and rare abnormal samples are expensive to collect. Here, we facilitate the study of few-shot learning in histology images by setting up three cross-domain tasks that simulate real clinics problems. To enable label-efficient learning and better generalizability, we propose to incorporate contrastive learning (CL) with latent augmentation (LA) to build a few-shot system. CL learns useful representations without manual labels, while LA transfers semantic variations of the base dataset in an unsupervised way. These two components fully exploit unlabeled training data and can scale gracefully to other label-hungry problems. In experiments, we find i) models learned by CL generalize better than supervised learning for histology images in unseen classes, and ii) LA brings consistent gains over baselines. Prior studies of self-supervised learning mainly focus on ImageNet-like images, which only present a dominant object in their centers. Recent attention has been paid to images with multi-objects and multi-textures. Histology images are a natural choice for such a study. We show the superiority of CL over supervised learning in terms of generalization for such data and provide our empirical understanding for this observation. The findings in this work could contribute to understanding how the model generalizes in the context of both representation learning and histological image analysis. Code is available.",
        "conference": "ICLR",
        "中文标题": "通过对比学习更好地理解和泛化组织学图像中的少样本分类",
        "摘要翻译": "少样本学习在自然图像领域已是一个成熟的研究课题多年，但针对组织学图像的研究却鲜有问津，尽管组织学图像具有很高的临床价值，因为标注良好的数据集和罕见的异常样本收集成本高昂。在此，我们通过设立三个模拟真实临床问题的跨领域任务，促进了组织学图像中少样本学习的研究。为了实现标签高效学习和更好的泛化能力，我们提出将对比学习（CL）与潜在增强（LA）结合，构建一个少样本系统。CL无需手动标签即可学习有用的表示，而LA则以无监督的方式转移基础数据集的语义变化。这两个组件充分利用了未标记的训练数据，并能优雅地扩展到其他标签稀缺的问题。在实验中，我们发现：i）对于未见过的类别的组织学图像，通过CL学习的模型比监督学习具有更好的泛化能力；ii）LA带来了相对于基线的持续增益。先前关于自监督学习的研究主要集中在类似ImageNet的图像上，这些图像仅在其中心呈现一个主导对象。最近，注意力已经转向具有多对象和多纹理的图像。组织学图像是此类研究的自然选择。我们展示了CL在此类数据的泛化方面优于监督学习，并提供了我们对此观察的经验性理解。这项工作的发现可能有助于理解模型在表示学习和组织学图像分析背景下的泛化方式。代码已公开。",
        "领域": "组织学图像分析",
        "问题": "解决组织学图像中少样本分类的泛化能力和理解问题",
        "动机": "由于组织学图像标注成本高且异常样本稀少，研究如何通过少样本学习提高模型在组织学图像上的泛化能力和理解能力",
        "方法": "结合对比学习（CL）和潜在增强（LA）构建少样本系统，利用未标记数据进行高效学习",
        "关键词": [
            "对比学习",
            "潜在增强",
            "少样本学习",
            "组织学图像",
            "自监督学习"
        ],
        "涉及的技术概念": {
            "对比学习（CL）": "用于无需手动标签即可学习有用表示的技术，提高模型在未见类别上的泛化能力",
            "潜在增强（LA）": "以无监督方式转移基础数据集语义变化的技术，增强模型的泛化能力",
            "少样本学习": "在标注数据稀缺的情况下，通过学习少量样本实现有效分类的技术"
        },
        "success": true
    },
    {
        "order": 988,
        "title": "Towards Building A Group-based Unsupervised Representation Disentanglement Framework",
        "html": "https://iclr.cc//virtual/2022/poster/5931",
        "abstract": "Disentangled representation learning is one of the major goals of deep learning, and is a key step for achieving explainable and generalizable models. The key idea of the state-of-the-art VAE-based unsupervised representation disentanglement methods is to minimize the total correlation of the joint distribution of the latent variables. However, it has been proved that their goal can not be achieved without introducing other inductive biases. The Group Theory based definition of representation disentanglement mathematically connects the data transformations to the representations using the formalism of group. In this paper, built on the group-based definition and inspired by the \\emph{n-th dihedral group}, we first propose a theoretical framework towards achieving unsupervised representation disentanglement. We then propose a model based on existing VAE-based methods to tackle the unsupervised learning problem of the framework. In the theoretical framework, we prove three sufficient conditions on model, group structure, and data respectively in an effort to achieve, in an unsupervised way, disentangled representation per group-based definition. With these conditions, we offer an option, from the perspective of the group-based definition, for the inductive bias that existing VAE-based models lack. Experimentally, we train 1800 models covering the most prominent VAE-based methods on five datasets to verify the effectiveness of our theoretical framework. Compared to the original VAE-based methods, these Groupified VAEs consistently achieve better mean performance with smaller variances.",
        "conference": "ICLR",
        "中文标题": "构建基于群的无监督表示解缠框架",
        "摘要翻译": "解缠表示学习是深度学习的主要目标之一，也是实现可解释和可泛化模型的关键步骤。当前最先进的基于VAE的无监督表示解缠方法的核心思想是最小化潜在变量联合分布的总相关性。然而，已经证明，如果不引入其他归纳偏置，这些方法的目标是无法实现的。基于群论的表示解缠定义使用群的形式主义将数据变换与表示数学地联系起来。在本文中，基于群的定义并受到第n个二面体群的启发，我们首先提出了一个实现无监督表示解缠的理论框架。然后，我们提出了一个基于现有VAE方法的模型来解决该框架的无监督学习问题。在理论框架中，我们证明了模型、群结构和数据三个充分条件，以努力实现基于群定义的无监督解缠表示。通过这些条件，我们从群定义的角度为现有基于VAE的模型所缺乏的归纳偏置提供了一个选项。实验上，我们在五个数据集上训练了1800个模型，涵盖了最突出的基于VAE的方法，以验证我们理论框架的有效性。与原始的基于VAE的方法相比，这些群化的VAE在更小的方差下一致地实现了更好的平均性能。",
        "领域": "表示学习、无监督学习、深度学习理论",
        "问题": "如何在无监督条件下实现有效的表示解缠",
        "动机": "解决现有基于VAE的无监督表示解缠方法缺乏有效归纳偏置的问题",
        "方法": "提出基于群论的理论框架，并通过改进现有VAE方法实现无监督表示解缠",
        "关键词": [
            "表示解缠",
            "无监督学习",
            "变分自编码器",
            "群论",
            "归纳偏置"
        ],
        "涉及的技术概念": {
            "表示解缠": "将数据的高维表示分解为独立的、可解释的因素",
            "变分自编码器": "一种生成模型，用于学习数据的潜在表示",
            "群论": "数学理论，用于描述对称性和变换，为表示解缠提供理论基础"
        },
        "success": true
    },
    {
        "order": 989,
        "title": "Towards Continual Knowledge Learning of Language Models",
        "html": "https://iclr.cc//virtual/2022/poster/6187",
        "abstract": "Large Language Models (LMs) are known to encode world knowledge in their parameters as they pretrain on a vast amount of web corpus, which is often utilized for performing knowledge-dependent downstream tasks such as question answering, fact-checking, and open dialogue. In real-world scenarios, the world knowledge stored in the LMs can quickly become outdated as the world changes, but it is non-trivial to avoid catastrophic forgetting and reliably acquire new knowledge while preserving invariant knowledge. To push the community towards better maintenance of ever-changing LMs, we formulate a new continual learning (CL) problem called Continual Knowledge Learning (CKL). We construct a new benchmark and metric to quantify the retention of time-invariant world knowledge, the update of outdated knowledge, and the acquisition of new knowledge. We adopt applicable recent methods from literature to create several strong baselines. Through extensive experiments, we find that CKL exhibits unique challenges that are not addressed in previous CL setups, where parameter expansion is necessary to reliably retain and learn knowledge simultaneously. By highlighting the critical causes of knowledge forgetting, we show that CKL is a challenging and important problem that helps us better understand and train ever-changing LMs.",
        "conference": "ICLR",
        "中文标题": "迈向语言模型的持续知识学习",
        "摘要翻译": "众所周知，大型语言模型（LMs）在预训练大量网络语料库时，会在其参数中编码世界知识，这些知识通常用于执行依赖于知识的后续任务，如问答、事实核查和开放对话。在现实世界场景中，随着世界的变化，存储在LMs中的世界知识可能迅速过时，但避免灾难性遗忘并可靠地获取新知识同时保留不变知识并非易事。为了推动社区更好地维护不断变化的LMs，我们提出了一个新的持续学习（CL）问题，称为持续知识学习（CKL）。我们构建了一个新的基准和度量标准，以量化时间不变世界知识的保留、过时知识的更新和新知识的获取。我们采用文献中适用的最新方法创建了几个强大的基线。通过大量实验，我们发现CKL展示了以前CL设置中未解决的独特挑战，其中参数扩展对于同时可靠地保留和学习知识是必要的。通过强调知识遗忘的关键原因，我们表明CKL是一个具有挑战性和重要性的问题，有助于我们更好地理解和训练不断变化的LMs。",
        "领域": "自然语言处理与视觉结合",
        "问题": "如何避免灾难性遗忘并可靠地获取新知识同时保留不变知识",
        "动机": "推动社区更好地维护不断变化的语言模型",
        "方法": "构建新的基准和度量标准，采用文献中适用的最新方法创建基线",
        "关键词": [
            "持续知识学习",
            "大型语言模型",
            "灾难性遗忘"
        ],
        "涉及的技术概念": {
            "持续知识学习（CKL）": "一个新的持续学习问题，旨在量化时间不变世界知识的保留、过时知识的更新和新知识的获取",
            "灾难性遗忘": "在获取新知识时，模型忘记之前学到的知识的现象",
            "参数扩展": "为了同时可靠地保留和学习知识，模型需要增加其参数数量"
        },
        "success": true
    },
    {
        "order": 990,
        "title": "Towards Deepening Graph Neural Networks: A GNTK-based Optimization Perspective",
        "html": "https://iclr.cc//virtual/2022/poster/6585",
        "abstract": "Graph convolutional networks (GCNs) and their variants have achieved great success in dealing with graph-structured data. Nevertheless, it is well known that deep GCNs suffer from the over-smoothing problem, where node representations tend to be indistinguishable as more layers are stacked up. The theoretical research to date on deep GCNs has focused primarily on expressive power rather than trainability, an optimization perspective. Compared to expressivity, trainability attempts to address a more fundamental question: Given a sufficiently expressive space of models, can we successfully find a good solution via gradient descent-based optimizers? This work fills this gap by exploiting the Graph Neural Tangent Kernel (GNTK), which governs the optimization trajectory under gradient descent for wide GCNs. We formulate the asymptotic behaviors of GNTK in the large depth, which enables us to reveal the dropping trainability of wide and deep GCNs at an exponential rate in the optimization process. Additionally, we extend our theoretical framework to analyze residual connection-based techniques, which are found to be merely able to mitigate the exponential decay of trainability mildly. Inspired by our theoretical insights on trainability, we propose Critical DropEdge, a connectivity-aware and graph-adaptive sampling method, to alleviate the exponential decay problem more fundamentally. Experimental evaluation consistently confirms using our proposed method can achieve better results compared to relevant counterparts with both infinite-width and finite-width. ",
        "conference": "ICLR",
        "中文标题": "迈向深化图神经网络：基于GNTK的优化视角",
        "摘要翻译": "图卷积网络（GCNs）及其变体在处理图结构数据方面取得了巨大成功。然而，众所周知，深层GCNs面临着过度平滑问题，即随着层数的增加，节点表示趋于不可区分。迄今为止，关于深层GCNs的理论研究主要集中在表达能力而非可训练性上，即优化视角。与表达能力相比，可训练性试图解决一个更基本的问题：给定一个足够表达能力的模型空间，我们能否通过基于梯度下降的优化器成功找到一个好的解决方案？这项工作通过利用图神经切线核（GNTK）填补了这一空白，GNTK控制着宽GCNs在梯度下降下的优化轨迹。我们在大深度下制定了GNTK的渐进行为，这使我们能够在优化过程中以指数速率揭示宽且深的GCNs的可训练性下降。此外，我们扩展了我们的理论框架来分析基于残差连接的技术，发现这些技术仅能轻微缓解可训练性的指数衰减。受到我们对可训练性理论见解的启发，我们提出了Critical DropEdge，一种连接感知和图自适应的采样方法，以更根本地缓解指数衰减问题。实验评估一致证实，使用我们提出的方法可以在无限宽度和有限宽度下与相关对应物相比获得更好的结果。",
        "领域": "图神经网络、深度学习优化、图结构数据分析",
        "问题": "深层图卷积网络（GCNs）在训练过程中面临的可训练性指数衰减问题。",
        "动机": "探索并解决深层GCNs在优化过程中的可训练性问题，以提升模型性能。",
        "方法": "利用图神经切线核（GNTK）分析深层GCNs的优化轨迹，提出Critical DropEdge方法来缓解可训练性的指数衰减。",
        "关键词": [
            "图神经网络",
            "优化视角",
            "GNTK",
            "Critical DropEdge",
            "可训练性"
        ],
        "涉及的技术概念": {
            "图神经切线核（GNTK）": "用于分析宽GCNs在梯度下降下的优化轨迹，揭示可训练性的变化。",
            "Critical DropEdge": "一种连接感知和图自适应的采样方法，旨在更根本地缓解深层GCNs的可训练性指数衰减问题。",
            "残差连接": "一种技术，用于轻微缓解深层GCNs的可训练性指数衰减问题。"
        },
        "success": true
    },
    {
        "order": 991,
        "title": "Towards Deployment-Efficient Reinforcement Learning: Lower Bound and Optimality",
        "html": "https://iclr.cc//virtual/2022/poster/7178",
        "abstract": "Deployment efficiency is an important criterion for many real-world applications of reinforcement learning (RL). Despite the community's increasing interest, there lacks a formal theoretical formulation for the problem. In this paper, we propose such a formulation for deployment-efficient RL (DE-RL) from an ''optimization with constraints'' perspective: we are interested in exploring an MDP and obtaining a near-optimal policy within minimal \\emph{deployment complexity}, whereas in each deployment the policy can sample a large batch of data. Using finite-horizon linear MDPs as a concrete structural model, we reveal the fundamental limit in achieving deployment efficiency by establishing information-theoretic lower bounds, and provide algorithms that achieve the optimal deployment efficiency. Moreover, our formulation for DE-RL is flexible and can serve as a building block for other practically relevant settings; we give ''Safe DE-RL'' and ''Sample-Efficient DE-RL'' as two examples, which may be worth future investigation.",
        "conference": "ICLR",
        "中文标题": "迈向部署高效的强化学习：下界与最优性",
        "摘要翻译": "部署效率是强化学习（RL）在许多实际应用中的一个重要标准。尽管社区对此越来越感兴趣，但缺乏对该问题的正式理论表述。在本文中，我们从‘带约束的优化’角度提出了部署高效RL（DE-RL）的表述：我们感兴趣的是探索马尔可夫决策过程（MDP）并在最小的部署复杂度内获得一个接近最优的策略，而在每次部署中，策略可以采样大量数据。使用有限水平线性MDP作为具体的结构模型，我们通过建立信息论下界揭示了实现部署效率的基本限制，并提供了达到最优部署效率的算法。此外，我们对DE-RL的表述是灵活的，可以作为其他实际相关设置的基础；我们给出了‘安全DE-RL’和‘样本高效DE-RL’作为两个例子，这些可能值得未来研究。",
        "领域": "强化学习、马尔可夫决策过程、优化算法",
        "问题": "如何在最小的部署复杂度内探索马尔可夫决策过程并获得接近最优的策略",
        "动机": "提高强化学习在实际应用中的部署效率，减少部署过程中的资源消耗",
        "方法": "从带约束的优化角度提出部署高效RL的表述，使用有限水平线性MDP作为结构模型，建立信息论下界并提供达到最优部署效率的算法",
        "关键词": [
            "部署效率",
            "强化学习",
            "马尔可夫决策过程",
            "优化算法",
            "信息论下界"
        ],
        "涉及的技术概念": {
            "部署复杂度": "在强化学习中，指探索马尔可夫决策过程并获得接近最优策略所需的部署次数和资源消耗",
            "有限水平线性MDP": "一种马尔可夫决策过程的结构模型，用于简化分析和算法设计",
            "信息论下界": "在信息论中，指在给定条件下，实现特定目标所需的最小信息量或资源量，用于评估算法的效率极限"
        },
        "success": true
    },
    {
        "order": 992,
        "title": "Towards Empirical Sandwich Bounds on the Rate-Distortion Function",
        "html": "https://iclr.cc//virtual/2022/poster/6563",
        "abstract": "Rate-distortion (R-D) function, a key quantity in information theory, characterizes the fundamental limit of how much a data source can be compressed subject to a fidelity criterion, by any compression algorithm. As researchers push for ever-improving compression performance, establishing the R-D function of a given data source is not only of scientific interest, but also sheds light on the possible room for improving compression algorithms. Previous work on this problem relied on distributional assumptions on the data source (Gibson, 2017) or only applied to discrete data (Blahut, 1972; Arimoto, 1972). By contrast, this paper makes the first attempt at an algorithm for sandwiching the R-D function of a general (not necessarily discrete) source requiring only i.i.d. data samples. We estimate R-D sandwich bounds for a variety of artificial and real-world data sources, in settings far beyond the feasibility of any known method, and shed light on the optimality of neural data compression (Ballé et al., 2021; Yang et al., 2022). Our R-D upper bound on natural images indicates theoretical room for improving state-of-the-art image compression methods by at least one dB in PSNR at various bitrates. Our data and code can be found at https://github.com/mandt-lab/empirical-RD-sandwich.",
        "conference": "ICLR",
        "中文标题": "实证三明治界限在率失真函数上的探索",
        "摘要翻译": "率失真（R-D）函数是信息论中的一个关键量，它描述了在任何压缩算法下，数据源在满足一定保真度标准下可以被压缩的基本极限。随着研究人员追求不断提高的压缩性能，确定给定数据源的R-D函数不仅具有科学意义，而且还揭示了改进压缩算法的可能空间。之前关于这个问题的研究依赖于数据源的分布假设（Gibson, 2017）或仅适用于离散数据（Blahut, 1972; Arimoto, 1972）。相比之下，本文首次尝试提出一种算法，用于三明治一般（不一定是离散的）数据源的R-D函数，仅需要独立同分布的数据样本。我们估计了各种人工和真实世界数据源的R-D三明治界限，在远超出任何已知方法可行性的设置下，并揭示了神经数据压缩的最优性（Ballé et al., 2021; Yang et al., 2022）。我们对自然图像的R-D上界表明，在各种比特率下，理论上改进最先进图像压缩方法的PSNR至少还有1 dB的空间。我们的数据和代码可以在https://github.com/mandt-lab/empirical-RD-sandwich找到。",
        "领域": "数据压缩、信息论、神经数据压缩",
        "问题": "如何在不依赖数据源分布假设或仅适用于离散数据的情况下，估计一般数据源的率失真函数。",
        "动机": "探索和确定数据源的率失真函数，以揭示压缩算法的改进空间，并推动压缩性能的极限。",
        "方法": "提出一种新算法，利用独立同分布的数据样本，对一般数据源的率失真函数进行三明治界限估计。",
        "关键词": [
            "率失真函数",
            "数据压缩",
            "信息论",
            "神经数据压缩",
            "三明治界限"
        ],
        "涉及的技术概念": {
            "率失真函数": "描述数据压缩的基本极限，即在给定保真度标准下，数据源可以被压缩的最小比特率。",
            "独立同分布样本": "算法仅需要的数据输入形式，不依赖于数据源的具体分布假设。",
            "三明治界限": "通过上下界估计来夹逼率失真函数的方法，旨在更准确地描述压缩极限。"
        },
        "success": true
    },
    {
        "order": 993,
        "title": "Towards Evaluating the Robustness of Neural Networks Learned by Transduction",
        "html": "https://iclr.cc//virtual/2022/poster/6995",
        "abstract": "There has been emerging interest in using transductive learning for adversarial robustness (Goldwasser et al., NeurIPS 2020; Wu et al., ICML 2020; Wang et al., ArXiv 2021). Compared to traditional defenses, these defense mechanisms 'dynamically learn' the model based on test-time input; and theoretically, attacking these defenses reduces to solving a bilevel optimization problem, which poses difficulty in crafting adaptive attacks. In this paper, we examine these defense mechanisms from a principled threat analysis perspective. We formulate and analyze threat models for transductive-learning based defenses, and point out important subtleties. We propose the principle of attacking model space for solving bilevel attack objectives, and present Greedy Model Space Attack (GMSA), an attack framework that can serve as a new baseline for evaluating transductive-learning based defenses. Through systematic evaluation, we show that GMSA, even with weak instantiations, can break previous transductive-learning based defenses, which were resilient to previous attacks, such as AutoAttack (Croce and Hein, ICML 2020). On the positive side, we report a somewhat surprising empirical result of 'transductive adversarial training': Adversarially retraining the model using fresh randomness at the test time gives a significant increase in robustness against attacks we consider.",
        "conference": "ICLR",
        "中文标题": "面向评估通过转导学习的神经网络的鲁棒性",
        "摘要翻译": "近年来，利用转导学习来提高对抗鲁棒性引起了越来越多的兴趣（Goldwasser等人，NeurIPS 2020；Wu等人，ICML 2020；Wang等人，ArXiv 2021）。与传统防御方法相比，这些防御机制基于测试时的输入‘动态学习’模型；理论上，攻击这些防御机制相当于解决一个双层优化问题，这给设计自适应攻击带来了困难。在本文中，我们从原则性的威胁分析角度审视这些防御机制。我们为基于转导学习的防御制定并分析了威胁模型，并指出了重要的细微差别。我们提出了攻击模型空间的原则来解决双层攻击目标，并提出了贪婪模型空间攻击（GMSA），这是一个可以作为评估基于转导学习的防御的新基准的攻击框架。通过系统评估，我们表明，即使使用弱实例化，GMSA也能突破之前的基于转导学习的防御，这些防御对之前的攻击（如AutoAttack（Croce和Hein，ICML 2020））具有弹性。在积极的一面，我们报告了一个有些令人惊讶的‘转导对抗训练’的实证结果：在测试时使用新的随机性对模型进行对抗性重新训练，可以显著提高对我们考虑的攻击的鲁棒性。",
        "领域": "对抗性机器学习",
        "问题": "评估和提升基于转导学习的神经网络防御机制对抗攻击的鲁棒性",
        "动机": "现有基于转导学习的防御机制在理论上难以被攻击，但实际上其鲁棒性尚未得到充分验证，需要更有效的评估方法",
        "方法": "提出贪婪模型空间攻击（GMSA）框架，作为评估基于转导学习的防御的新基准，并通过实证研究验证其有效性",
        "关键词": [
            "转导学习",
            "对抗鲁棒性",
            "贪婪模型空间攻击",
            "双层优化",
            "对抗训练"
        ],
        "涉及的技术概念": {
            "转导学习": "一种学习方法，模型在测试时基于输入动态调整，以提高对抗攻击的鲁棒性",
            "双层优化问题": "攻击基于转导学习的防御机制时需解决的优化问题，增加了攻击的复杂性",
            "贪婪模型空间攻击（GMSA）": "本文提出的攻击框架，旨在有效评估基于转导学习的防御机制的鲁棒性"
        },
        "success": true
    },
    {
        "order": 994,
        "title": "Towards General Function Approximation in Zero-Sum Markov Games",
        "html": "https://iclr.cc//virtual/2022/poster/6810",
        "abstract": "This paper considers two-player zero-sum finite-horizon Markov games with simultaneous moves. The study focuses on the challenging settings where the valuefunction or the model is parameterized by general function classes. Provably efficientalgorithms for both decoupled and coordinated settings are developed. In the decoupled setting where the agent controls a single player and plays against an arbitrary opponent, we propose a new model-free algorithm. The sample complexity is governed by the Minimax Eluder dimension—a new dimension of the function class in Markov games. As a special case, this method improves the state-of-the-art algorithmby a $\\sqrt{d}$ factor in the regret when the reward function and transition kernel are parameterized with d-dimensional linear features. In the coordinated setting where bothplayers are controlled by the agent, we propose a model-based algorithm and a model-free algorithm. In the model-based algorithm, we prove that sample complexity canbe bounded by a generalization of Witness rank to Markov games. The model-freealgorithm enjoys a  $\\sqrt{K}$-regret upper bound where $K$ is the number of episodes. Ouralgorithms are based on new techniques of alternate optimism",
        "conference": "ICLR",
        "中文标题": "迈向零和马尔可夫博弈中的通用函数逼近",
        "摘要翻译": "本文考虑的是具有同时移动的双人零和有限时间马尔可夫博弈。研究聚焦于价值函数或模型由通用函数类参数化的挑战性设置。为解耦和协调两种设置开发了可证明高效的算法。在解耦设置中，代理控制单个玩家并与任意对手对抗，我们提出了一种新的无模型算法。样本复杂度由Minimax Eluder维度——马尔可夫博弈中函数类的一个新维度——所控制。作为一种特殊情况，当奖励函数和转移核用d维线性特征参数化时，该方法在遗憾上将最先进算法改进了√d倍。在协调设置中，两个玩家都由代理控制，我们提出了一种基于模型的算法和一种无模型算法。在基于模型的算法中，我们证明样本复杂度可以由Witness秩到马尔可夫博弈的推广所界定。无模型算法享有√K-遗憾上界，其中K是情节数。我们的算法基于交替乐观的新技术。",
        "领域": "强化学习、博弈论、机器学习",
        "问题": "在零和马尔可夫博弈中实现通用函数逼近的高效算法设计",
        "动机": "解决在价值函数或模型由通用函数类参数化的挑战性设置下，零和马尔可夫博弈中的高效学习问题",
        "方法": "提出了基于Minimax Eluder维度的无模型算法和基于Witness秩推广的模型算法，以及交替乐观技术",
        "关键词": [
            "零和马尔可夫博弈",
            "通用函数逼近",
            "Minimax Eluder维度",
            "Witness秩",
            "交替乐观"
        ],
        "涉及的技术概念": {
            "Minimax Eluder维度": "马尔可夫博弈中函数类的一个新维度，用于控制样本复杂度",
            "Witness秩": "推广到马尔可夫博弈中，用于界定基于模型算法的样本复杂度",
            "交替乐观技术": "算法设计中的新技术，用于实现高效学习"
        },
        "success": true
    },
    {
        "order": 995,
        "title": "Towards Model Agnostic Federated Learning Using Knowledge Distillation",
        "html": "https://iclr.cc//virtual/2022/poster/6644",
        "abstract": "Is it possible to design an universal API for federated learning using which an ad-hoc group of data-holders (agents) collaborate with each other and perform federated learning? Such an API would necessarily need to be model-agnostic i.e. make no assumption about the model architecture being used by the agents, and also cannot rely on having representative public data at hand. Knowledge distillation (KD) is the obvious tool of choice to design such protocols. However, surprisingly, we show that most natural KD-based federated learning protocols have poor performance.        To investigate this, we propose a new theoretical framework, Federated Kernel ridge regression, which can capture both model heterogeneity as well as data heterogeneity. Our analysis shows that the degradation is largely due to a fundamental limitation of knowledge distillation under data heterogeneity. We further validate our framework by analyzing and designing new protocols based on KD. Their performance on real world experiments using neural networks, though still unsatisfactory, closely matches our theoretical predictions. ",
        "conference": "ICLR",
        "中文标题": "迈向使用知识蒸馏的模型无关联邦学习",
        "摘要翻译": "是否有可能设计一个通用的API用于联邦学习，使得一组临时的数据持有者（代理）能够相互协作并执行联邦学习？这样的API必然需要是模型无关的，即不对代理使用的模型架构做出任何假设，也不能依赖于手头有代表性的公共数据。知识蒸馏（KD）显然是设计此类协议的理想工具。然而，令人惊讶的是，我们发现大多数基于KD的自然联邦学习协议性能不佳。为了研究这一点，我们提出了一个新的理论框架——联邦核岭回归，它能够捕捉模型异质性以及数据异质性。我们的分析表明，性能下降主要是由于数据异质性下知识蒸馏的基本限制。我们通过分析和设计基于KD的新协议进一步验证了我们的框架。尽管在神经网络上的实际实验性能仍然不尽人意，但它们与我们的理论预测非常接近。",
        "领域": "联邦学习、知识蒸馏、机器学习框架",
        "问题": "设计一个模型无关的联邦学习API，使得不同模型架构和数据分布的数据持有者能够有效协作。",
        "动机": "解决在数据异质性和模型异质性条件下，基于知识蒸馏的联邦学习协议性能不佳的问题。",
        "方法": "提出联邦核岭回归理论框架，分析知识蒸馏在数据异质性下的限制，并设计新的基于KD的协议。",
        "关键词": [
            "联邦学习",
            "知识蒸馏",
            "模型无关",
            "数据异质性",
            "核岭回归"
        ],
        "涉及的技术概念": {
            "知识蒸馏（KD）": "用于设计模型无关联邦学习协议的技术，通过将知识从复杂模型转移到简单模型来实现。",
            "联邦核岭回归": "提出的理论框架，用于分析模型和数据异质性对联邦学习性能的影响。",
            "数据异质性": "指不同数据持有者之间的数据分布不一致，是影响联邦学习性能的关键因素。"
        },
        "success": true
    },
    {
        "order": 996,
        "title": "Towards Training Billion Parameter Graph Neural Networks for Atomic Simulations",
        "html": "https://iclr.cc//virtual/2022/poster/6800",
        "abstract": "Recent progress in Graph Neural Networks (GNNs) for modeling atomic simulations has the potential to revolutionize catalyst discovery, which is a key step in making progress towards the energy breakthroughs needed to combat climate change. However, the GNNs that have proven most effective for this task are memory intensive as they model higher-order interactions in the graphs such as those between triplets or quadruplets of atoms, making it challenging to scale these models. In this paper, we introduce Graph Parallelism, a method to distribute input graphs across multiple GPUs, enabling us to train very large GNNs with hundreds of millions or billions of parameters. We empirically evaluate our method by scaling up the recently proposed DimeNet++ and GemNet models by over an order of magnitude in the number of parameters. On the large-scale Open Catalyst 2020 (OC20) dataset, these graph-parallelized models lead to relative improvements of 1) 15% on the force MAE metric on the S2EF task and 2) 21% on the AFbT metric on the IS2RS task, establishing new state-of-the-art results.",
        "conference": "ICLR",
        "中文标题": "迈向训练十亿参数图神经网络用于原子模拟",
        "摘要翻译": "最近在图神经网络（GNNs）用于原子模拟建模方面的进展，有潜力彻底改变催化剂发现的过程，这是实现对抗气候变化所需能源突破的关键一步。然而，对于这一任务最有效的GNNs由于需要建模图中的高阶交互（如原子间的三重或四重交互），内存消耗大，这使得扩展这些模型具有挑战性。在本文中，我们介绍了图并行性，一种将输入图分布到多个GPU上的方法，使我们能够训练具有数亿或数十亿参数的非常大的GNNs。我们通过将最近提出的DimeNet++和GemNet模型的参数数量扩展超过一个数量级来实证评估我们的方法。在大规模的Open Catalyst 2020（OC20）数据集上，这些图并行化模型在S2EF任务上的力MAE指标相对提高了15%，在IS2RS任务上的AFbT指标相对提高了21%，建立了新的最先进结果。",
        "领域": "图神经网络、原子模拟、催化剂发现",
        "问题": "如何扩展内存密集型的图神经网络以建模原子间的高阶交互，从而促进催化剂发现。",
        "动机": "为了克服现有图神经网络在建模原子间高阶交互时的内存限制，推动催化剂发现和能源突破。",
        "方法": "提出图并行性方法，通过将输入图分布到多个GPU上来训练具有数亿或数十亿参数的大型图神经网络。",
        "关键词": [
            "图神经网络",
            "原子模拟",
            "催化剂发现",
            "图并行性",
            "大规模训练"
        ],
        "涉及的技术概念": {
            "图神经网络（GNNs）": "用于建模原子模拟中的高阶交互，是催化剂发现的关键技术。",
            "图并行性": "一种将输入图分布到多个GPU上的方法，使得训练具有大量参数的图神经网络成为可能。",
            "DimeNet++和GemNet模型": "最近提出的图神经网络模型，通过图并行性方法扩展其参数数量，以提高在原子模拟任务上的性能。"
        },
        "success": true
    },
    {
        "order": 997,
        "title": "Towards Understanding Generalization via Decomposing Excess Risk Dynamics",
        "html": "https://iclr.cc//virtual/2022/poster/6570",
        "abstract": "Generalization is one of the fundamental issues in machine learning. However, traditional techniques like uniform convergence may be unable to explain generalization under overparameterization \\citep{nagarajan2019uniform}. As alternative approaches, techniques based on stability analyze the training dynamics and derive algorithm-dependent generalization bounds. Unfortunately, the stability-based bounds are still far from explaining the surprising generalization in deep learning since neural networks usually suffer from unsatisfactory stability. This paper proposes a novel decomposition framework to improve the stability-based bounds via a more fine-grained analysis of the signal and noise, inspired by the observation that neural networks converge relatively slowly when fitting noise (which indicates better stability). Concretely, we decompose the excess risk dynamics and apply the stability-based bound only on the noise component. The decomposition framework performs well in both linear regimes (overparameterized linear regression) and non-linear regimes (diagonal matrix recovery). Experiments on neural networks verify the utility of the decomposition framework.",
        "conference": "ICLR",
        "中文标题": "通过分解超额风险动态理解泛化性",
        "摘要翻译": "泛化性是机器学习中的基本问题之一。然而，传统的技术如一致收敛可能无法解释过参数化下的泛化性。作为替代方法，基于稳定性的技术分析训练动态并导出依赖于算法的泛化界限。不幸的是，基于稳定性的界限仍然远未解释深度学习中的惊人泛化，因为神经网络通常遭受不满意的稳定性。本文提出了一种新颖的分解框架，通过对信号和噪声的更细粒度分析来改进基于稳定性的界限，灵感来自于观察到神经网络在拟合噪声时收敛相对较慢（这表明更好的稳定性）。具体来说，我们分解了超额风险动态，并仅对噪声分量应用基于稳定性的界限。分解框架在线性体制（过参数化线性回归）和非线性体制（对角矩阵恢复）中都表现良好。在神经网络上的实验验证了分解框架的实用性。",
        "领域": "深度学习理论、机器学习理论、神经网络优化",
        "问题": "如何更有效地解释和理解深度学习模型在过参数化情况下的泛化能力。",
        "动机": "传统的泛化性解释方法如一致收敛和基于稳定性的界限在解释深度学习模型的泛化能力时存在不足，特别是在过参数化的情况下。",
        "方法": "提出了一种新的分解框架，通过更细粒度地分析信号和噪声来改进基于稳定性的泛化界限，特别是在神经网络拟合噪声时表现出的更好稳定性。",
        "关键词": [
            "泛化性",
            "超额风险",
            "稳定性",
            "过参数化",
            "神经网络"
        ],
        "涉及的技术概念": {
            "超额风险动态": "论文中用于分析和理解模型泛化性能的关键概念，通过分解超额风险动态来更细致地理解模型的泛化行为。",
            "稳定性": "论文中用于导出算法依赖性泛化界限的技术，稳定性分析帮助理解模型训练过程中的行为。",
            "信号与噪声分解": "论文提出的核心方法，通过区分学习过程中的信号和噪声，更有效地分析模型的泛化性能。"
        },
        "success": true
    },
    {
        "order": 998,
        "title": "Towards Understanding the Data Dependency of Mixup-style Training",
        "html": "https://iclr.cc//virtual/2022/poster/6526",
        "abstract": "In the Mixup training paradigm, a model is trained using convex combinations of data points and their associated labels. Despite seeing very few true data points during training, models trained using Mixup seem to still minimize the original empirical risk and exhibit better generalization and robustness on various tasks when compared to standard training. In this paper, we investigate how these benefits of Mixup training rely on properties of the data in the context of classification. For minimizing the original empirical risk, we compute a closed form for the Mixup-optimal classification, which allows us to construct a simple dataset on which minimizing the Mixup loss leads to learning a classifier that does not minimize the empirical loss on the data. On the other hand, we also give sufficient conditions for Mixup training to also minimize the original empirical risk. For generalization, we characterize the margin of a Mixup classifier, and use this to understand why the decision boundary of a Mixup classifier can adapt better to the full structure of the training data when compared to standard training. In contrast, we also show that, for a large class of linear models and linearly separable datasets, Mixup training leads to learning the same classifier as standard training.",
        "conference": "ICLR",
        "中文标题": "迈向理解Mixup风格训练的数据依赖性",
        "摘要翻译": "在Mixup训练范式中，模型通过数据点及其关联标签的凸组合进行训练。尽管在训练过程中看到的真实数据点非常少，但使用Mixup训练的模型似乎仍然能够最小化原始经验风险，并在各种任务上展现出比标准训练更好的泛化能力和鲁棒性。在本文中，我们研究了Mixup训练的这些益处如何在分类任务的背景下依赖于数据的属性。为了最小化原始经验风险，我们计算了Mixup最优分类的闭式解，这使我们能够构建一个简单的数据集，在该数据集上最小化Mixup损失会导致学习到一个不最小化数据上经验损失的分类器。另一方面，我们也给出了Mixup训练同样能够最小化原始经验风险的充分条件。对于泛化能力，我们描述了Mixup分类器的边界，并利用这一点来理解为什么Mixup分类器的决策边界能够比标准训练更好地适应训练数据的完整结构。相比之下，我们还表明，对于一大类线性模型和线性可分数据集，Mixup训练会导致学习到与标准训练相同的分类器。",
        "领域": "深度学习优化方法",
        "问题": "Mixup训练方法的数据依赖性及其对模型泛化能力和鲁棒性的影响",
        "动机": "探索Mixup训练方法为何能在极少真实数据点的情况下，仍能有效最小化经验风险并提升模型性能",
        "方法": "通过计算Mixup最优分类的闭式解和构建特定数据集，分析Mixup训练的数据依赖性及其对模型性能的影响",
        "关键词": [
            "Mixup训练",
            "数据依赖性",
            "经验风险最小化",
            "泛化能力",
            "鲁棒性"
        ],
        "涉及的技术概念": {
            "Mixup训练": "一种通过数据点及其标签的凸组合来训练模型的方法，旨在提升模型的泛化能力和鲁棒性",
            "经验风险最小化": "机器学习中的一种基本准则，旨在最小化模型在训练数据上的预测误差",
            "泛化能力": "模型在未见数据上的表现能力，Mixup训练通过增加数据多样性来提升这一能力"
        },
        "success": true
    },
    {
        "order": 999,
        "title": "Towards Understanding the Robustness Against Evasion Attack on Categorical Data",
        "html": "https://iclr.cc//virtual/2022/poster/6787",
        "abstract": "Characterizing and assessing the adversarial vulnerability of classification models with categorical input has been a practically important, while rarely explored research problem. Our work echoes the challenge by first unveiling the impact factors of adversarial vulnerability of classification models with categorical data based on an information-theoretic adversarial risk analysis about the targeted classifier. Though certifying the robustness of such classification models is intrinsically an NP-hard combinatorial problem, our study shows that the robustness certification can be solved via an efficient greedy exploration of the discrete attack space for any measurable classifiers with a mild smoothness constraint. Our proposed robustness certification framework is instantiated with deep neural network models applied on real-world safety-critic data sources. Our empirical observations confirm the impact of the key adversarial risk factors with categorical input.",
        "conference": "ICLR",
        "中文标题": "理解分类数据对抗逃避攻击的鲁棒性",
        "摘要翻译": "描述和评估具有分类输入的分类模型的对抗脆弱性一直是一个实际重要但很少被探索的研究问题。我们的工作通过首先基于目标分类器的信息论对抗风险分析，揭示了分类数据分类模型对抗脆弱性的影响因素，回应了这一挑战。尽管证明这类分类模型的鲁棒性本质上是一个NP难组合问题，但我们的研究表明，对于任何具有温和平滑约束的可测量分类器，鲁棒性认证可以通过对离散攻击空间的有效贪婪探索来解决。我们提出的鲁棒性认证框架通过应用于现实世界安全关键数据源的深度神经网络模型进行了实例化。我们的实证观察确认了分类输入的关键对抗风险因素的影响。",
        "领域": "对抗性机器学习、分类模型安全、信息论安全",
        "问题": "评估和提升分类数据分类模型对抗逃避攻击的鲁棒性",
        "动机": "研究分类数据分类模型在对抗攻击下的脆弱性，以提升模型的安全性和可靠性",
        "方法": "基于信息论的对抗风险分析，提出一种通过贪婪探索离散攻击空间来认证分类模型鲁棒性的框架",
        "关键词": [
            "对抗性攻击",
            "分类数据",
            "鲁棒性认证",
            "深度神经网络",
            "信息论安全"
        ],
        "涉及的技术概念": {
            "对抗风险分析": "用于评估分类模型在对抗攻击下的脆弱性，基于信息论原理",
            "鲁棒性认证": "通过算法证明分类模型对特定攻击的抵抗能力，本研究提出了一种高效的贪婪探索方法",
            "深度神经网络": "作为分类模型应用于安全关键数据源，用于实例化鲁棒性认证框架"
        },
        "success": true
    },
    {
        "order": 1000,
        "title": "TPU-GAN: Learning temporal coherence from dynamic point cloud sequences",
        "html": "https://iclr.cc//virtual/2022/poster/6936",
        "abstract": "Point cloud sequence is an important data representation that provides flexible shape and motion information. Prior work demonstrates that incorporating scene flow information into loss can make model learn temporally coherent feature spaces. However, it is prohibitively expensive to acquire point correspondence information across frames in real-world environments. In this work, we propose a super-resolution generative adversarial network (GAN) for upsampling dynamic point cloud sequences, which does not require point correspondence annotation.  Our model, Temporal Point cloud Upsampling GAN (TPU-GAN), can implicitly learn the underlying temporal coherence from point cloud sequence, which in turn guides the generator to produce temporally coherent output. In addition, we propose a learnable masking module to adapt upsampling ratio according to the point distribution. We conduct extensive experiments on point cloud sequences from two different domains: particles in the fluid dynamical system and human action scanned data. The quantitative and qualitative evaluation demonstrates the effectiveness of our method on upsampling tasks as well as learning temporal coherence from irregular point cloud sequences.",
        "conference": "ICLR",
        "中文标题": "TPU-GAN：从动态点云序列中学习时间一致性",
        "摘要翻译": "点云序列是一种重要的数据表示形式，提供了灵活的形态和运动信息。先前的工作表明，将场景流信息融入损失函数可以使模型学习到时间一致的特征空间。然而，在现实环境中获取跨帧的点对应信息成本极高。在这项工作中，我们提出了一种用于上采样动态点云序列的超分辨率生成对抗网络（GAN），该网络不需要点对应注释。我们的模型，时间点云上采样GAN（TPU-GAN），能够隐式地从点云序列中学习潜在的时间一致性，进而指导生成器产生时间一致的输出。此外，我们提出了一个可学习的掩码模块，根据点的分布自适应调整上采样比率。我们在来自两个不同领域的点云序列上进行了广泛的实验：流体动力学系统中的粒子和扫描的人体动作数据。定量和定性的评估证明了我们的方法在上采样任务以及从不规则点云序列中学习时间一致性方面的有效性。",
        "领域": "点云处理, 生成对抗网络, 时间序列分析",
        "问题": "在不需要点对应注释的情况下，从动态点云序列中学习时间一致性并进行上采样。",
        "动机": "解决在现实环境中获取跨帧点对应信息成本高的问题，同时提高点云序列上采样的时间一致性。",
        "方法": "提出了一种超分辨率生成对抗网络（TPU-GAN），通过隐式学习点云序列的时间一致性来指导生成器产生时间一致的输出，并引入可学习的掩码模块自适应调整上采样比率。",
        "关键词": [
            "点云上采样",
            "时间一致性",
            "生成对抗网络",
            "动态点云",
            "超分辨率"
        ],
        "涉及的技术概念": {
            "生成对抗网络（GAN）": "用于上采样动态点云序列，通过对抗训练提高生成点云的质量和时间一致性。",
            "时间一致性学习": "模型隐式地从点云序列中学习时间一致性，以指导生成器产生时间一致的输出。",
            "可学习的掩码模块": "根据点分布自适应调整上采样比率，提高模型对不同点云序列的适应性。"
        },
        "success": true
    },
    {
        "order": 1001,
        "title": "Tracking the risk of a deployed model and detecting harmful distribution shifts",
        "html": "https://iclr.cc//virtual/2022/poster/6896",
        "abstract": "When deployed in the real world, machine learning models inevitably encounter changes in the data distribution, and certain---but not all---distribution shifts could result in significant performance degradation. In practice, it may make sense to ignore benign shifts, under which the performance of a deployed model does not degrade substantially, making  interventions by a human expert (or model retraining) unnecessary.  While several works have developed tests for distribution shifts, these typically either use non-sequential methods, or detect arbitrary shifts (benign or harmful), or both. We argue that a sensible method for firing off a warning has to both (a) detect harmful shifts while ignoring benign ones, and (b) allow continuous monitoring of model performance without increasing the false alarm rate. In this work, we design simple sequential tools for testing if the difference between source (training) and target (test) distributions leads to a significant increase in a risk function of interest, like accuracy or calibration. Recent advances in constructing time-uniform confidence sequences allow efficient aggregation of statistical evidence accumulated during the tracking process. The designed framework is applicable in settings where (some) true labels are revealed after the prediction is performed, or when batches of labels become available in a delayed fashion. We demonstrate the efficacy of the proposed framework through an extensive empirical study on a collection of simulated and real datasets.",
        "conference": "ICLR",
        "中文标题": "追踪部署模型的风险并检测有害分布变化",
        "摘要翻译": "在现实世界中部署时，机器学习模型不可避免地会遇到数据分布的变化，某些——但不是所有——分布变化可能导致性能显著下降。在实践中，忽略那些不会导致部署模型性能大幅下降的良性变化可能是有意义的，这样就不需要人类专家干预（或模型重新训练）。虽然已有几项工作开发了用于检测分布变化的测试，但这些测试通常要么使用非序列方法，要么检测任意变化（良性或有害），或者两者兼而有之。我们认为，一个合理的警告触发方法必须（a）检测有害变化而忽略良性变化，并且（b）允许在不增加误报率的情况下持续监控模型性能。在这项工作中，我们设计了简单的序列工具，用于测试源（训练）和目标（测试）分布之间的差异是否会导致感兴趣的风险函数（如准确性或校准）显著增加。构建时间均匀置信序列的最新进展允许有效聚合跟踪过程中积累的统计证据。设计的框架适用于在预测后揭示（部分）真实标签的情况，或者当标签批次以延迟方式可用时。我们通过对一系列模拟和真实数据集的广泛实证研究，证明了所提出框架的有效性。",
        "领域": "机器学习模型监控、分布变化检测、风险函数评估",
        "问题": "如何有效检测和区分机器学习模型部署过程中遇到的有害和良性数据分布变化，以避免不必要的干预或重新训练。",
        "动机": "现有方法无法有效区分有害和良性分布变化，或不能持续监控模型性能而不增加误报率，导致资源浪费或性能下降未被及时发现。",
        "方法": "设计简单的序列工具，利用时间均匀置信序列的最新进展，测试源和目标分布差异是否导致风险函数显著增加，适用于不同标签获取场景。",
        "关键词": [
            "分布变化检测",
            "风险函数",
            "序列测试",
            "模型监控",
            "时间均匀置信序列"
        ],
        "涉及的技术概念": {
            "时间均匀置信序列": "用于有效聚合跟踪过程中积累的统计证据，支持持续监控模型性能而不增加误报率。",
            "风险函数": "用于量化源和目标分布差异对模型性能（如准确性或校准）的影响。",
            "序列测试": "设计用于连续监控和测试分布变化的方法，能够区分有害和良性变化。"
        },
        "success": true
    },
    {
        "order": 1002,
        "title": "TRAIL: Near-Optimal Imitation Learning with Suboptimal Data",
        "html": "https://iclr.cc//virtual/2022/poster/6774",
        "abstract": "In imitation learning, one aims to learn task-solving policies using access to near-optimal expert trajectories collected from the task environment. However, high-quality trajectories -- e.g., from human experts -- can be expensive to obtain in practical settings. On the contrary, it is often much easier to obtain large amounts of suboptimal trajectories which can nevertheless provide insight into the structure of the environment, showing what \\emph{could} be done in the environment even if not what \\emph{should} be done. Is it possible to formalize these conceptual benefits and devise algorithms to use offline datasets to yield \\emph{provable} improvements to the sample-efficiency of imitation learning? In this work, we answer this question affirmatively and present training objectives which use an offline dataset to learn an approximate \\emph{factored} dynamics model whose structure enables the extraction of a \\emph{latent action space}. Our theoretical analysis shows that the learned latent action space can boost the sample-efficiency of downstream imitation learning, effectively reducing the need for large near-optimal expert datasets through the use of auxiliary non-expert data. We evaluate the practicality of our objective through experiments on a set of navigation and locomotion tasks. Our results verify the benefits suggested by our theory and show that our algorithms is able to recover near-optimal policies with fewer expert trajectories.",
        "conference": "ICLR",
        "中文标题": "TRAIL：利用次优数据进行接近最优的模仿学习",
        "摘要翻译": "在模仿学习中，人们旨在通过访问从任务环境中收集的接近最优的专家轨迹来学习任务解决策略。然而，高质量的轨迹——例如来自人类专家的轨迹——在实际环境中获取成本高昂。相反，获取大量次优轨迹通常要容易得多，这些轨迹仍然可以提供对环境结构的洞察，展示在环境中可以做什么，即使不是应该做什么。是否有可能将这些概念上的好处形式化，并设计算法使用离线数据集来为模仿学习的样本效率提供可证明的改进？在这项工作中，我们肯定地回答了这个问题，并提出了使用离线数据集学习近似分解动态模型的训练目标，其结构能够提取潜在动作空间。我们的理论分析表明，学习到的潜在动作空间可以提高下游模仿学习的样本效率，通过使用辅助非专家数据有效减少对大型接近最优专家数据集的需求。我们通过在一组导航和运动任务上的实验评估了我们目标的实用性。我们的结果验证了我们理论所建议的好处，并表明我们的算法能够用更少的专家轨迹恢复接近最优的策略。",
        "领域": "模仿学习",
        "问题": "如何在模仿学习中利用次优数据提高样本效率",
        "动机": "减少对高质量专家轨迹的依赖，利用更易获取的次优数据提升模仿学习的效率",
        "方法": "提出使用离线数据集学习近似分解动态模型，提取潜在动作空间以提升样本效率",
        "关键词": [
            "模仿学习",
            "次优数据",
            "潜在动作空间",
            "样本效率",
            "分解动态模型"
        ],
        "涉及的技术概念": {
            "潜在动作空间": "通过分解动态模型提取的动作空间，用于提升模仿学习的样本效率",
            "分解动态模型": "近似模型，其结构有助于提取潜在动作空间",
            "样本效率": "衡量学习算法在给定样本数量下性能的指标，本文通过利用次优数据提高这一指标"
        },
        "success": true
    },
    {
        "order": 1003,
        "title": "Training Data Generating Networks: Shape Reconstruction via Bi-level Optimization",
        "html": "https://iclr.cc//virtual/2022/poster/5933",
        "abstract": "We propose a novel 3d shape representation for 3d shape reconstruction from a single image. Rather than predicting a shape directly, we train a network to generate a training set which will be fed into another learning algorithm to define the shape. The nested optimization problem can be modeled by bi-level optimization. Specifically, the algorithms for bi-level optimization are also being used in meta learning approaches for few-shot learning. Our framework establishes a link between 3D shape analysis and few-shot learning. We combine training data generating networks with bi-level optimization algorithms to obtain a complete framework for which all components can be jointly trained. We improve upon recent work on standard benchmarks for 3d shape reconstruction.",
        "conference": "ICLR",
        "中文标题": "训练数据生成网络：通过双层优化的形状重建",
        "摘要翻译": "我们提出了一种新颖的3D形状表示方法，用于从单张图像进行3D形状重建。不同于直接预测形状，我们训练一个网络来生成训练集，该训练集将被输入到另一个学习算法中以定义形状。这个嵌套的优化问题可以通过双层优化来建模。具体来说，双层优化的算法也被用于元学习方法中的少样本学习。我们的框架在3D形状分析和少样本学习之间建立了联系。我们将训练数据生成网络与双层优化算法结合起来，获得了一个可以联合训练所有组件的完整框架。我们在3D形状重建的标准基准上改进了最近的工作。",
        "领域": "3D形状重建",
        "问题": "如何从单张图像有效地重建3D形状",
        "动机": "探索3D形状重建与少样本学习之间的联系，提高重建的准确性和效率",
        "方法": "使用训练数据生成网络结合双层优化算法，构建一个可联合训练的完整框架",
        "关键词": [
            "3D形状重建",
            "双层优化",
            "训练数据生成网络",
            "少样本学习",
            "元学习"
        ],
        "涉及的技术概念": {
            "训练数据生成网络": "用于生成训练集的网络，为后续学习算法提供输入",
            "双层优化": "用于建模嵌套优化问题的算法，同时在元学习中应用",
            "少样本学习": "一种学习范式，旨在从少量样本中学习，与3D形状重建相结合以提高效率"
        },
        "success": true
    },
    {
        "order": 1004,
        "title": "Training invariances and the low-rank phenomenon: beyond linear networks",
        "html": "https://iclr.cc//virtual/2022/poster/6638",
        "abstract": "The implicit bias induced by the training of neural networks has become a topic of rigorous study. In the limit of gradient flow and gradient descent with appropriate step size, it has been shown that when one trains a deep linear network with logistic or exponential loss on linearly separable data, the weights converge to rank-$1$ matrices. In this paper, we extend this theoretical result to the last few linear layers of the much wider class of nonlinear ReLU-activated feedforward networks containing fully-connected layers and skip connections.  Similar to the linear case, the proof relies on specific local training invariances, sometimes referred to as alignment, which we show to hold for submatrices where neurons are stably-activated in all training examples, and it reflects empirical results in the literature. We also show this is not true in general for the full matrix of ReLU fully-connected layers. Our proof relies on a specific decomposition of the network into a multilinear function and another ReLU network whose weights are constant under a certain parameter directional convergence.",
        "conference": "ICLR",
        "中文标题": "训练不变性与低秩现象：超越线性网络",
        "摘要翻译": "神经网络训练所诱导的隐式偏差已成为严格研究的主题。在梯度流和适当步长的梯度下降的极限情况下，已经证明，当使用逻辑或指数损失在线性可分数据上训练深度线性网络时，权重会收敛到秩-1矩阵。在本文中，我们将这一理论结果扩展到包含全连接层和跳跃连接的更广泛类别的非线性ReLU激活前馈网络的最后几个线性层。与线性情况类似，证明依赖于特定的局部训练不变性，有时称为对齐，我们展示了这些不变性对于在所有训练示例中神经元稳定激活的子矩阵成立，并且它反映了文献中的实证结果。我们还表明，对于ReLU全连接层的完整矩阵，这通常不成立。我们的证明依赖于将网络分解为多线性函数和另一个ReLU网络的特定分解，后者的权重在特定参数方向收敛下是恒定的。",
        "领域": "深度学习理论、神经网络优化、非线性网络分析",
        "问题": "研究非线性ReLU激活前馈网络在训练过程中的权重收敛特性，特别是其低秩现象。",
        "动机": "扩展线性网络中权重收敛到秩-1矩阵的理论结果到更广泛的非线性网络，以深入理解神经网络训练的隐式偏差。",
        "方法": "通过分析特定局部训练不变性（对齐），证明在稳定激活的子矩阵中权重收敛到低秩矩阵，并对网络进行特定分解以支持理论证明。",
        "关键词": [
            "训练不变性",
            "低秩现象",
            "ReLU网络",
            "权重收敛",
            "隐式偏差"
        ],
        "涉及的技术概念": {
            "梯度流": "用于描述在无限小步长下梯度下降的动态，是分析权重收敛特性的理论基础。",
            "ReLU激活函数": "非线性激活函数，本文研究其在网络训练中对权重收敛特性的影响。",
            "隐式偏差": "指神经网络训练过程中算法偏好于某些解的特性，本文研究其在非线性网络中的表现。"
        },
        "success": true
    },
    {
        "order": 1005,
        "title": "Training Structured Neural Networks Through Manifold Identification and Variance Reduction",
        "html": "https://iclr.cc//virtual/2022/poster/6536",
        "abstract": "This paper proposes an algorithm, RMDA, for training neural networks (NNs) with a regularization term for promoting desired structures. RMDA does not incur computation additional to proximal SGD with momentum, and achieves variance reduction without requiring the objective function to be of the finite-sum form. Through the tool of manifold identification from nonlinear optimization, we prove that after a finite number of iterations, all iterates of RMDA possess a desired structure identical to that induced by the regularizer at the stationary point of asymptotic convergence, even in the presence of engineering tricks like data augmentation that complicate the training process. Experiments on training NNs with structured sparsity confirm that variance reduction is necessary for such an identification, and show that RMDA thus significantly outperforms existing methods for this task. For unstructured sparsity, RMDA also outperforms a state-of-the-art pruning method, validating the benefits of training structured NNs through regularization. Implementation of RMDA is available at https://www.github.com/zihsyuan1214/rmda.",
        "conference": "ICLR",
        "中文标题": "通过流形识别和方差减少训练结构化神经网络",
        "摘要翻译": "本文提出了一种算法RMDA，用于训练带有促进期望结构正则化项的神经网络(NNs)。RMDA不会产生超过带有动量的近端随机梯度下降(SGD)的计算量，并且在不要求目标函数为有限和形式的情况下实现了方差减少。通过非线性优化中的流形识别工具，我们证明了在经过有限次迭代后，即使存在如数据增强这样使训练过程复杂化的工程技巧，RMDA的所有迭代都具有与渐近收敛的静止点处由正则化项诱导的期望结构相同的结构。在训练具有结构化稀疏性的神经网络上的实验证实，方差减少对于这种识别是必要的，并且显示RMDA因此显著优于现有方法。对于非结构化稀疏性，RMDA也优于最先进的剪枝方法，验证了通过正则化训练结构化神经网络的好处。RMDA的实现可在https://www.github.com/zihsyuan1214/rmda获取。",
        "领域": "结构化神经网络训练、稀疏性优化、深度学习优化算法",
        "问题": "如何在训练神经网络时有效引入和保持期望的结构化稀疏性，同时减少计算方差。",
        "动机": "探索一种能够在训练过程中自动识别并保持神经网络结构化稀疏性的方法，同时优化计算效率。",
        "方法": "提出RMDA算法，结合流形识别技术和方差减少策略，无需额外计算量即可实现结构化稀疏性的保持和优化。",
        "关键词": [
            "结构化神经网络",
            "方差减少",
            "流形识别",
            "正则化",
            "稀疏性优化"
        ],
        "涉及的技术概念": {
            "流形识别": "用于在训练过程中识别并保持神经网络的结构化稀疏性，确保模型收敛到期望的结构。",
            "方差减少": "通过算法优化减少训练过程中的计算方差，提高训练效率和模型性能。",
            "正则化": "在损失函数中加入正则化项，促进神经网络保持特定的结构化稀疏性，避免过拟合。"
        },
        "success": true
    },
    {
        "order": 1006,
        "title": "Training Transition Policies via Distribution Matching for Complex Tasks",
        "html": "https://iclr.cc//virtual/2022/poster/6407",
        "abstract": "Humans decompose novel complex tasks into simpler ones to exploit previously learned skills. Analogously, hierarchical reinforcement learning seeks to leverage lower-level policies for simple tasks to solve complex ones. However, because each lower-level policy induces a different distribution of states, transitioning from one lower-level policy to another may fail due to an unexpected starting state. We introduce transition policies that smoothly connect lower-level policies by producing a distribution of states and actions that matches what is expected by the next policy. Training transition policies is challenging because the natural reward signal---whether the next policy can execute its subtask successfully---is sparse. By training transition policies via adversarial inverse reinforcement learning to match the distribution of expected states and actions, we avoid relying on task-based reward. To further improve performance, we use deep Q-learning with a binary action space to determine when to switch from a transition policy to the next pre-trained policy, using the success or failure of the next subtask as the reward. Although the reward is still sparse, the problem is less severe due to the simple binary action space. We demonstrate our method on continuous bipedal locomotion and arm manipulation tasks that require diverse skills. We show that it smoothly connects the lower-level policies, achieving higher success rates than previous methods that search for successful trajectories based on a reward function, but do not match the state distribution.",
        "conference": "ICLR",
        "中文标题": "通过分布匹配训练复杂任务的过渡策略",
        "摘要翻译": "人类将新颖复杂的任务分解为更简单的任务，以利用先前学到的技能。类似地，分层强化学习试图利用简单任务的低级策略来解决复杂任务。然而，由于每个低级策略都会产生不同的状态分布，从一个低级策略过渡到另一个可能会因为意外的初始状态而失败。我们引入了过渡策略，通过产生与下一个策略期望的状态和动作分布相匹配的分布，平稳地连接低级策略。训练过渡策略具有挑战性，因为自然的奖励信号——即下一个策略是否能成功执行其子任务——是稀疏的。通过使用对抗性逆强化学习训练过渡策略以匹配期望的状态和动作分布，我们避免依赖于基于任务的奖励。为了进一步提高性能，我们使用带有二元动作空间的深度Q学习来确定何时从过渡策略切换到下一个预训练策略，使用下一个子任务的成功或失败作为奖励。尽管奖励仍然是稀疏的，但由于简单的二元动作空间，问题不那么严重。我们在需要多样化技能的连续双足行走和手臂操纵任务上展示了我们的方法。我们表明，它平稳地连接了低级策略，比之前基于奖励函数搜索成功轨迹但不匹配状态分布的方法获得了更高的成功率。",
        "领域": "分层强化学习",
        "问题": "解决在分层强化学习中，由于低级策略产生的状态分布不同，导致策略间过渡失败的问题",
        "动机": "为了提高复杂任务中策略过渡的成功率，通过匹配期望的状态和动作分布来平稳连接低级策略",
        "方法": "使用对抗性逆强化学习训练过渡策略以匹配期望分布，并结合深度Q学习决定策略切换时机",
        "关键词": [
            "分层强化学习",
            "过渡策略",
            "对抗性逆强化学习",
            "深度Q学习",
            "状态分布匹配"
        ],
        "涉及的技术概念": {
            "对抗性逆强化学习": "用于训练过渡策略以匹配期望的状态和动作分布，避免依赖稀疏的任务奖励",
            "深度Q学习": "用于决定何时从过渡策略切换到下一个预训练策略，利用二元动作空间简化问题",
            "状态分布匹配": "确保过渡策略产生的状态和动作分布与下一个策略期望的分布相匹配，以实现平稳过渡"
        },
        "success": true
    },
    {
        "order": 1007,
        "title": "Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation",
        "html": "https://iclr.cc//virtual/2022/poster/6261",
        "abstract": "Since the introduction of the transformer model by Vaswani et al. (2017), a fundamental question has yet to be answered: how does a model achieve extrapolation at inference time for sequences that are longer than it saw during training? We first show that extrapolation can be enabled by simply changing the position representation method, though we find that current methods do not allow for efficient extrapolation. We therefore introduce a simpler and more efficient position method, Attention with Linear Biases (ALiBi). ALiBi does not add positional embeddings to word embeddings;  instead, it biases query-key attention scores with a penalty that is proportional to their distance. We show that this method trains a 1.3 billion parameter model on input sequences of length 1024 that extrapolates to input sequences of length 2048, achieving the same perplexity as a sinusoidal position embedding model trained on inputs of length 2048 but training 11% faster and using 11% less memory. ALiBi's inductive bias towards recency also leads it to outperform multiple strong position methods on the WikiText-103 benchmark.",
        "conference": "ICLR",
        "中文标题": "训练短，测试长：带线性偏置的注意力机制实现输入长度外推",
        "摘要翻译": "自Vaswani等人（2017）引入Transformer模型以来，一个基本问题尚未得到解答：模型如何在推理时对训练期间未见过的更长序列进行外推？我们首先表明，仅通过改变位置表示方法即可实现外推，尽管我们发现当前方法不允许高效外推。因此，我们引入了一种更简单、更高效的位置方法——带线性偏置的注意力机制（ALiBi）。ALiBi不向词嵌入添加位置嵌入；相反，它通过一个与距离成比例的惩罚来偏置查询-键注意力分数。我们展示了这种方法在长度为1024的输入序列上训练一个13亿参数的模型，能够外推到长度为2048的输入序列，达到与在长度为2048的输入上训练的正弦位置嵌入模型相同的困惑度，但训练速度快11%，内存使用少11%。ALiBi对近期性的归纳偏置也使其在WikiText-103基准测试中优于多种强位置方法。",
        "领域": "自然语言处理与视觉结合, 序列建模, 注意力机制优化",
        "问题": "解决Transformer模型在推理时对长于训练序列的输入进行有效外推的问题",
        "动机": "探索并实现Transformer模型对长序列的有效外推能力，提高模型效率和性能",
        "方法": "引入带线性偏置的注意力机制（ALiBi），通过距离成比例的惩罚偏置查询-键注意力分数，替代传统的位置嵌入方法",
        "关键词": [
            "长度外推",
            "ALiBi",
            "注意力机制",
            "Transformer",
            "位置表示"
        ],
        "涉及的技术概念": {
            "带线性偏置的注意力机制（ALiBi）": "一种新型的位置表示方法，通过引入与距离成比例的惩罚来偏置注意力分数，实现高效的长度外推",
            "位置嵌入": "传统的位置表示方法，通过添加位置信息到词嵌入中来处理序列顺序，ALiBi方法对此进行了改进",
            "困惑度": "用于评估语言模型性能的指标，衡量模型预测序列的不确定性，ALiBi在保持相同困惑度的同时提高了效率"
        },
        "success": true
    },
    {
        "order": 1008,
        "title": "Trans-Encoder: Unsupervised sentence-pair modelling through self- and mutual-distillations",
        "html": "https://iclr.cc//virtual/2022/poster/6242",
        "abstract": "In NLP, a large volume of tasks involve pairwise comparison between two sequences (e.g. sentence similarity and paraphrase identification). Predominantly, two formulations are used for sentence-pair tasks: bi-encoders and cross-encoders. Bi-encoders produce fixed-dimensional sentence representations and are computationally efficient, however, they usually underperform cross-encoders. Cross-encoders can leverage their attention heads to exploit inter-sentence interactions for better performance but they require task fine-tuning and are computationally more expensive. In this paper, we present a completely unsupervised sentence representation model termed as Trans-Encoder that combines the two learning paradigms into an iterative joint framework to simultaneously learn enhanced bi- and cross-encoders. Specifically, on top of a pre-trained Language Model (PLM), we start with converting it to an unsupervised bi-encoder, and then alternate between the bi- and cross-encoder task formulations. In each alternation, one task formulation will produce pseudo-labels which are used as learning signals for the other task formulation. We then propose an extension to conduct such self-distillation approach on multiple PLMs in parallel and use the average of their pseudo-labels for mutual distillation. Trans-Encoder creates, to the best of our knowledge, the first completely unsupervised cross-encoder and also a state-of-the-art unsupervised bi-encoder for sentence similarity. Both the bi-encoder and cross-encoder formulations of Trans-Encoder outperform recently proposed state-of-the-art unsupervised sentence encoders such as Mirror-BERT and SimCSE by up to 5% on the sentence similarity benchmarks.",
        "conference": "ICLR",
        "中文标题": "Trans-Encoder：通过自蒸馏和互蒸馏的无监督句子对建模",
        "摘要翻译": "在自然语言处理（NLP）中，大量任务涉及两个序列之间的成对比较（例如句子相似性和复述识别）。对于句子对任务，主要使用两种形式：双编码器和交叉编码器。双编码器生成固定维度的句子表示，计算效率高，但通常性能不如交叉编码器。交叉编码器可以利用其注意力头来利用句子间的交互以获得更好的性能，但它们需要任务微调并且计算成本更高。在本文中，我们提出了一种完全无监督的句子表示模型，称为Trans-Encoder，它将两种学习范式结合到一个迭代的联合框架中，以同时学习增强的双编码器和交叉编码器。具体来说，在预训练语言模型（PLM）的基础上，我们首先将其转换为无监督的双编码器，然后在双编码器和交叉编码器任务形式之间交替。在每次交替中，一种任务形式将产生伪标签，这些伪标签被用作另一种任务形式的学习信号。然后，我们提出了一种扩展方法，以在多个PLM上并行进行这种自蒸馏方法，并使用它们的伪标签的平均值进行互蒸馏。据我们所知，Trans-Encoder创建了第一个完全无监督的交叉编码器，以及一个最先进的无监督双编码器，用于句子相似性。Trans-Encoder的双编码器和交叉编码器形式在句子相似性基准测试中，比最近提出的最先进的无监督句子编码器（如Mirror-BERT和SimCSE）高出5%。",
        "领域": "自然语言处理与视觉结合",
        "问题": "解决无监督句子对建模中双编码器和交叉编码器的性能与计算效率之间的权衡问题",
        "动机": "为了结合双编码器的计算效率和交叉编码器的高性能，同时避免交叉编码器需要任务微调和计算成本高的问题",
        "方法": "提出Trans-Encoder模型，通过自蒸馏和互蒸馏的方法，在预训练语言模型的基础上，交替使用双编码器和交叉编码器任务形式，以无监督方式同时学习增强的双编码器和交叉编码器",
        "关键词": [
            "无监督学习",
            "句子相似性",
            "自蒸馏",
            "互蒸馏",
            "预训练语言模型"
        ],
        "涉及的技术概念": {
            "双编码器": "生成固定维度的句子表示，计算效率高，但性能通常不如交叉编码器",
            "交叉编码器": "利用注意力头来利用句子间的交互以获得更好的性能，但需要任务微调并且计算成本更高",
            "自蒸馏和互蒸馏": "通过交替使用双编码器和交叉编码器任务形式，产生伪标签作为学习信号，以无监督方式同时学习增强的双编码器和交叉编码器"
        },
        "success": true
    },
    {
        "order": 1009,
        "title": "Transferable Adversarial Attack based on Integrated Gradients",
        "html": "https://iclr.cc//virtual/2022/poster/6584",
        "abstract": "The vulnerability of deep neural networks to adversarial examples has drawn tremendous attention from the community. Three approaches, optimizing standard objective functions, exploiting attention maps, and smoothing decision surfaces, are commonly used to craft adversarial examples. By tightly integrating the three approaches, we propose a new and simple algorithm named Transferable Attack based on Integrated Gradients (TAIG) in this paper, which can find highly transferable adversarial examples for black-box attacks. Unlike previous methods using multiple computational terms or combining with other methods, TAIG integrates the three approaches into one single term. Two versions of TAIG that compute their integrated gradients on a straight-line path and a random piecewise linear path are studied. Both versions offer strong transferability and can seamlessly work together with the previous methods. Experimental results demonstrate that TAIG outperforms the state-of-the-art methods.",
        "conference": "ICLR",
        "中文标题": "基于积分梯度的可转移对抗攻击",
        "摘要翻译": "深度神经网络对对抗样本的脆弱性已引起社区的极大关注。通常有三种方法来制作对抗样本：优化标准目标函数、利用注意力图和平滑决策面。通过紧密整合这三种方法，我们在本文中提出了一种新的简单算法，名为基于积分梯度的可转移攻击（TAIG），该算法可以为黑盒攻击找到高度可转移的对抗样本。与之前使用多个计算项或与其他方法结合的方法不同，TAIG将三种方法整合为一个单一的计算项。研究了TAIG的两个版本，它们分别在直线路径和随机分段线性路径上计算其积分梯度。两个版本都提供了强大的可转移性，并且可以与之前的方法无缝协作。实验结果表明，TAIG优于最先进的方法。",
        "领域": "对抗样本生成、黑盒攻击、深度学习安全",
        "问题": "如何提高对抗样本在黑盒攻击中的可转移性",
        "动机": "深度神经网络对对抗样本的脆弱性是一个重要的安全问题，研究如何提高对抗样本的可转移性对于黑盒攻击尤为重要。",
        "方法": "提出了一种名为TAIG的新算法，通过整合优化标准目标函数、利用注意力图和平滑决策面三种方法，来生成高度可转移的对抗样本。",
        "关键词": [
            "对抗样本",
            "可转移攻击",
            "积分梯度",
            "黑盒攻击",
            "深度学习安全"
        ],
        "涉及的技术概念": {
            "对抗样本": "在输入数据上添加微小扰动，导致深度学习模型产生错误输出的样本。",
            "积分梯度": "一种用于解释模型决策的方法，通过计算输入特征对模型输出的贡献度来生成对抗样本。",
            "黑盒攻击": "攻击者在没有目标模型内部信息的情况下，通过输入输出对模型进行攻击的方法。"
        },
        "success": true
    },
    {
        "order": 1010,
        "title": "Transfer RL across Observation Feature Spaces via Model-Based Regularization",
        "html": "https://iclr.cc//virtual/2022/poster/6740",
        "abstract": "In many reinforcement learning (RL) applications, the observation space is specified by human developers and restricted by physical realizations, and may thus be subject to dramatic changes over time (e.g. increased number of observable features). However, when the observation space changes, the previous policy will likely fail due to the mismatch of input features, and another policy must be trained from scratch, which is inefficient in terms of computation and sample complexity. Following theoretical insights, we propose a novel algorithm which extracts the latent-space dynamics in the source task, and transfers the dynamics model to the target task to use as a model-based regularizer. Our algorithm works for drastic changes of observation space (e.g. from vector-based observation to image-based observation), without any inter-task mapping or any prior knowledge of the target task. Empirical results show that our algorithm significantly improves the efficiency and stability of learning in the target task.",
        "conference": "ICLR",
        "中文标题": "通过基于模型的正则化实现跨观测特征空间的强化学习迁移",
        "摘要翻译": "在许多强化学习（RL）应用中，观测空间由人类开发者指定并受物理实现的限制，因此可能会随时间发生剧烈变化（例如可观测特征数量的增加）。然而，当观测空间发生变化时，先前的策略很可能会因为输入特征的不匹配而失效，必须从头开始训练另一个策略，这在计算和样本复杂度上是低效的。基于理论洞察，我们提出了一种新颖的算法，该算法提取源任务中的潜在空间动态，并将动态模型迁移到目标任务中作为基于模型的正则化器使用。我们的算法适用于观测空间的剧烈变化（例如从基于向量的观测到基于图像的观测），无需任何任务间映射或对目标任务的任何先验知识。实证结果表明，我们的算法显著提高了目标任务中学习的效率和稳定性。",
        "领域": "强化学习迁移",
        "问题": "解决观测空间变化导致策略失效，需要重新训练策略的低效问题",
        "动机": "提高强化学习在观测空间变化时的适应性和效率，减少重新训练的需求",
        "方法": "提出一种算法，通过提取源任务的潜在空间动态并将其作为基于模型的正则化器迁移到目标任务中",
        "关键词": [
            "强化学习迁移",
            "模型正则化",
            "观测空间变化"
        ],
        "涉及的技术概念": {
            "潜在空间动态": "算法提取源任务中的潜在空间动态，用于目标任务的正则化",
            "基于模型的正则化器": "将源任务的动态模型迁移到目标任务中，作为正则化器以提高学习效率和稳定性",
            "观测空间变化": "算法能够处理观测空间的剧烈变化，如从向量到图像的转变"
        },
        "success": true
    },
    {
        "order": 1011,
        "title": "Transform2Act: Learning a Transform-and-Control Policy for Efficient Agent Design",
        "html": "https://iclr.cc//virtual/2022/poster/6196",
        "abstract": "An agent's functionality is largely determined by its design, i.e., skeletal structure and joint attributes (e.g., length, size, strength). However, finding the optimal agent design for a given function is extremely challenging since the problem is inherently combinatorial and the design space is prohibitively large. Additionally, it can be costly to evaluate each candidate design which requires solving for its optimal controller. To tackle these problems, our key idea is to incorporate the design procedure of an agent into its decision-making process. Specifically, we learn a conditional policy that, in an episode, first applies a sequence of transform actions to modify an agent's skeletal structure and joint attributes, and then applies control actions under the new design. To handle a variable number of joints across designs, we use a graph-based policy where each graph node represents a joint and uses message passing with its neighbors to output joint-specific actions. Using policy gradient methods, our approach enables joint optimization of agent design and control as well as experience sharing across different designs, which improves sample efficiency substantially.  Experiments show that our approach, Transform2Act, outperforms prior methods significantly in terms of convergence speed and final performance. Notably, Transform2Act can automatically discover plausible designs similar to giraffes, squids, and spiders. Code and videos are available at https://sites.google.com/view/transform2act.",
        "conference": "ICLR",
        "中文标题": "Transform2Act：学习一种转换与控制策略以实现高效智能体设计",
        "摘要翻译": "智能体的功能在很大程度上由其设计决定，即骨架结构和关节属性（如长度、大小、强度）。然而，为给定功能找到最优的智能体设计极具挑战性，因为这个问题本质上是组合性的，且设计空间大得令人望而却步。此外，评估每个候选设计的成本可能很高，这需要为其最优控制器求解。为了解决这些问题，我们的关键思想是将智能体的设计过程纳入其决策过程中。具体来说，我们学习了一个条件策略，在一个情节中，首先应用一系列转换动作来修改智能体的骨架结构和关节属性，然后在新设计下应用控制动作。为了处理设计中关节数量的可变性，我们使用了一个基于图的策略，其中每个图节点代表一个关节，并通过与其邻居的消息传递来输出特定于关节的动作。使用策略梯度方法，我们的方法能够实现智能体设计和控制的联合优化，以及跨不同设计的经验共享，从而大幅提高样本效率。实验表明，我们的方法Transform2Act在收敛速度和最终性能方面显著优于先前的方法。值得注意的是，Transform2Act能够自动发现类似于长颈鹿、鱿鱼和蜘蛛的合理设计。代码和视频可在https://sites.google.com/view/transform2act获取。",
        "领域": "智能体设计优化、强化学习、机器人控制",
        "问题": "如何在巨大的设计空间中高效地找到最优的智能体设计，并解决评估每个候选设计的高成本问题。",
        "动机": "智能体的设计对其功能至关重要，但设计空间巨大且评估成本高，需要一种能够同时优化设计和控制策略的方法。",
        "方法": "学习一个条件策略，先通过转换动作修改智能体设计，再在新设计下应用控制动作，使用基于图的策略处理可变数量的关节，并通过策略梯度方法实现设计和控制的联合优化。",
        "关键词": [
            "智能体设计",
            "强化学习",
            "策略梯度",
            "图神经网络",
            "机器人控制"
        ],
        "涉及的技术概念": {
            "条件策略": "在智能体的决策过程中，先修改设计再应用控制动作的策略，以实现设计和控制的联合优化。",
            "图基策略": "使用图结构表示智能体的关节，通过节点间的消息传递处理不同设计间关节数量的变化。",
            "策略梯度方法": "用于优化智能体的设计和控制策略，实现跨设计的经验共享，提高样本效率。"
        },
        "success": true
    },
    {
        "order": 1012,
        "title": "Transformer-based Transform Coding",
        "html": "https://iclr.cc//virtual/2022/poster/7095",
        "abstract": "Neural data compression based on nonlinear transform coding has made great progress over the last few years, mainly due to improvements in prior models, quantization methods and nonlinear transforms. A general trend in many recent works pushing the limit of rate-distortion performance is to use ever more expensive prior models that can lead to prohibitively slow decoding. Instead, we focus on more expressive transforms that result in a better rate-distortion-computation trade-off. Specifically, we show that nonlinear transforms built on Swin-transformers can achieve better compression efficiency than transforms built on convolutional neural networks (ConvNets), while requiring fewer parameters and shorter decoding time. Paired with a compute-efficient Channel-wise Auto-Regressive Model prior, our SwinT-ChARM model outperforms VTM-12.1 by $3.68\\%$ in BD-rate on Kodak with comparable decoding speed. In P-frame video compression setting, we are able to outperform the popular ConvNet-based scale-space-flow model by $12.35\\%$ in BD-rate on UVG. We provide model scaling studies to verify the computational efficiency of the proposed solutions and conduct several analyses to reveal the source of coding gain of transformers over ConvNets, including better spatial decorrelation, flexible effective receptive field, and more localized response of latent pixels during progressive decoding.",
        "conference": "ICLR",
        "中文标题": "基于Transformer的变换编码",
        "摘要翻译": "基于非线性变换编码的神经数据压缩在过去几年取得了巨大进展，主要归功于先验模型、量化方法和非线性变换的改进。许多近期工作推动率失真性能极限的一个普遍趋势是使用越来越昂贵的先验模型，这可能导致解码速度极慢。相反，我们专注于更具表现力的变换，以实现更好的率失真计算权衡。具体来说，我们展示了基于Swin-transformers构建的非线性变换比基于卷积神经网络（ConvNets）构建的变换能够实现更好的压缩效率，同时需要更少的参数和更短的解码时间。与计算高效的通道自回归模型先验配对，我们的SwinT-ChARM模型在Kodak上以可比的解码速度在BD-rate上优于VTM-12.1 3.68%。在P帧视频压缩设置中，我们能够在UVG上在BD-rate上优于流行的基于ConvNet的尺度空间流模型12.35%。我们提供了模型缩放研究以验证所提出解决方案的计算效率，并进行了几项分析以揭示Transformer相对于ConvNets的编码增益来源，包括更好的空间去相关、灵活的有效感受野以及在渐进解码过程中更局部的潜在像素响应。",
        "领域": "神经数据压缩",
        "问题": "提高神经数据压缩的率失真计算权衡",
        "动机": "解决现有方法中因使用昂贵先验模型导致的解码速度慢的问题",
        "方法": "使用基于Swin-transformers的非线性变换和计算高效的通道自回归模型先验",
        "关键词": [
            "神经数据压缩",
            "Swin-transformers",
            "非线性变换编码"
        ],
        "涉及的技术概念": {
            "Swin-transformers": "用于构建非线性变换，提高压缩效率和计算效率",
            "通道自回归模型": "作为先验模型，与Swin-transformers配对使用，优化率失真性能",
            "率失真计算权衡": "评估压缩效率和计算资源消耗之间的平衡"
        },
        "success": true
    },
    {
        "order": 1013,
        "title": "Transformer Embeddings of Irregularly Spaced Events and Their Participants",
        "html": "https://iclr.cc//virtual/2022/poster/6600",
        "abstract": "The neural Hawkes process (Mei & Eisner, 2017) is a generative model of irregularly spaced sequences of discrete events. To handle complex domains with many event types, Mei et al. (2020a) further consider a setting in which each event in the sequence updates a deductive database of facts (via domain-specific pattern-matching rules); future events are then conditioned on the database contents. They show how to convert such a symbolic system into a neuro-symbolic continuous-time generative model, in which each database fact and possible event has a time-varying embedding that is derived from its symbolic provenance. In this paper, we modify both models, replacing their recurrent LSTM-based architectures with flatter attention-based architectures (Vaswani et al., 2017), which are simpler and more parallelizable. This does not appear to hurt our accuracy, which is comparable to or better than that of the original models as well as (where applicable) previous attention-based methods (Zuo et al., 2020; Zhang et al., 2020a).",
        "conference": "ICLR",
        "中文标题": "不规则间隔事件及其参与者的Transformer嵌入",
        "摘要翻译": "神经霍克斯过程（Mei & Eisner, 2017）是一种生成模型，用于处理离散事件的不规则间隔序列。为了处理具有多种事件类型的复杂领域，Mei等人（2020a）进一步考虑了一种设置，其中序列中的每个事件通过特定领域的模式匹配规则更新一个事实的演绎数据库；未来的事件则基于数据库内容进行条件化。他们展示了如何将这样的符号系统转换为神经符号连续时间生成模型，其中每个数据库事实和可能的事件都有一个随时间变化的嵌入，该嵌入源自其符号来源。在本文中，我们修改了这两种模型，将它们基于循环LSTM的架构替换为更扁平化的基于注意力的架构（Vaswani等人，2017），这些架构更简单且更易于并行化。这似乎并未损害我们的准确性，其准确性与原始模型以及（在适用的情况下）先前基于注意力的方法（Zuo等人，2020；Zhang等人，2020a）相当或更好。",
        "领域": "时间序列分析, 神经符号学习, 注意力机制",
        "问题": "如何更有效地建模和处理不规则间隔的事件序列及其参与者的动态嵌入",
        "动机": "改进现有的神经霍克斯过程和神经符号连续时间生成模型，通过引入更简单、更高效的注意力机制架构，以提高模型的并行化能力和处理效率",
        "方法": "将基于LSTM的循环架构替换为基于注意力的扁平化架构，以简化模型并提高其并行化能力",
        "关键词": [
            "Transformer嵌入",
            "神经霍克斯过程",
            "注意力机制",
            "神经符号学习",
            "时间序列建模"
        ],
        "涉及的技术概念": {
            "神经霍克斯过程": "一种生成模型，用于处理离散事件的不规则间隔序列",
            "注意力机制": "用于替换LSTM架构，以提高模型的并行化能力和处理效率",
            "神经符号学习": "结合神经网络和符号推理的方法，用于处理复杂领域中的事件序列"
        },
        "success": true
    },
    {
        "order": 1014,
        "title": "Transformers Can Do Bayesian Inference",
        "html": "https://iclr.cc//virtual/2022/poster/6595",
        "abstract": "Currently, it is hard to reap the benefits of deep learning for Bayesian methods, which allow the explicit specification of prior knowledge and accurately capture model uncertainty. We present Prior-Data Fitted Networks (PFNs). PFNs leverage large-scale machine learning techniques to approximate a large set of posteriors. The only requirement for PFNs to work is the ability to sample from a prior distribution over supervised learning tasks (or functions). Our method restates the objective of posterior approximation as a supervised classification problem with a set-valued input: it repeatedly draws a task (or function) from the prior, draws a set of data points and their labels from it, masks one of the labels and learns to make probabilistic predictions for it based on the set-valued input of the rest of the data points. Presented with a set of samples from a new supervised learning task as input, PFNs make probabilistic predictions for arbitrary other data points in a single forward propagation, having learned to approximate Bayesian inference. We demonstrate that PFNs can near-perfectly mimic Gaussian processes and also enable efficient Bayesian inference for intractable problems, with over 200-fold speedups in multiple setups compared to current methods. We obtain strong results in very diverse areas such as Gaussian process regression, Bayesian neural networks, classification for small tabular data sets, and few-shot image classification, demonstrating the generality of PFNs. Code and trained PFNs are released at https://github.com/automl/TransformersCanDoBayesianInference.",
        "conference": "ICLR",
        "中文标题": "Transformer能做贝叶斯推断",
        "摘要翻译": "目前，深度学习在贝叶斯方法中的应用难以实现，贝叶斯方法允许明确指定先验知识并准确捕捉模型的不确定性。我们提出了先验数据拟合网络（PFNs）。PFNs利用大规模机器学习技术来近似一大组后验分布。PFNs工作的唯一要求是能够从监督学习任务（或函数）的先验分布中采样。我们的方法将后验近似的目标重新表述为一个具有集合值输入的监督分类问题：它反复从先验中抽取一个任务（或函数），从中抽取一组数据点及其标签，掩码其中一个标签，并学习基于其余数据点的集合值输入对其进行概率预测。当输入一组来自新监督学习任务的样本时，PFNs通过一次前向传播对任意其他数据点进行概率预测，学会了近似贝叶斯推断。我们证明，PFNs可以近乎完美地模仿高斯过程，并且对于难以处理的问题也能实现高效的贝叶斯推断，在多种设置中比现有方法快200倍以上。我们在高斯过程回归、贝叶斯神经网络、小表格数据集的分类以及少样本图像分类等非常多样化的领域获得了强有力的结果，证明了PFNs的通用性。代码和训练好的PFNs已在https://github.com/automl/TransformersCanDoBayesianInference发布。",
        "领域": "贝叶斯深度学习, 高斯过程, 少样本学习",
        "问题": "如何将深度学习技术有效应用于贝叶斯方法，以实现先验知识的明确指定和模型不确定性的准确捕捉",
        "动机": "解决深度学习在贝叶斯方法中应用的限制，通过大规模机器学习技术近似后验分布，提高计算效率",
        "方法": "提出先验数据拟合网络（PFNs），通过将后验近似问题转化为监督分类问题，利用大规模机器学习技术近似后验分布",
        "关键词": [
            "贝叶斯推断",
            "先验数据拟合网络",
            "高斯过程",
            "少样本学习",
            "监督分类"
        ],
        "涉及的技术概念": {
            "先验数据拟合网络（PFNs）": "利用大规模机器学习技术近似一大组后验分布的网络",
            "监督分类问题": "将后验近似的目标重新表述为具有集合值输入的监督分类问题",
            "高斯过程": "PFNs可以近乎完美地模仿高斯过程，实现高效的贝叶斯推断"
        },
        "success": true
    },
    {
        "order": 1015,
        "title": "Transition to Linearity of Wide Neural Networks is an Emerging Property of Assembling Weak Models",
        "html": "https://iclr.cc//virtual/2022/poster/7200",
        "abstract": "Wide neural networks with linear output layer have been shown to be near-linear, and to have near-constant neural tangent kernel (NTK), in a region containing the optimization path of gradient descent. These findings seem counter-intuitive since in general neural networks are highly complex models. Why does a linear structure emerge when the neural networks become wide? In this work, we provide a new perspective on this 'transition to linearity' by considering a neural network as an assembly model recursively built from a set of sub-models corresponding to individual neurons. In this view, we show that the linearity of wide neural networks is, in fact, an emerging property of assembling a large number of diverse ``weak'' sub-models, none of which dominate the assembly. ",
        "conference": "ICLR",
        "中文标题": "宽神经网络向线性过渡是弱模型组装的新兴特性",
        "摘要翻译": "具有线性输出层的宽神经网络已被证明在包含梯度下降优化路径的区域中接近线性，并且具有接近恒定的神经切线核（NTK）。这些发现似乎与直觉相悖，因为一般来说神经网络是高度复杂的模型。为什么当神经网络变宽时会出现线性结构？在这项工作中，我们通过将神经网络视为从对应于单个神经元的子模型集合递归构建的组装模型，为这种‘向线性过渡’提供了新的视角。从这个角度来看，我们表明宽神经网络的线性实际上是组装大量多样化的‘弱’子模型的新兴特性，其中没有一个子模型主导整个组装。",
        "领域": "深度学习理论、神经网络架构、优化方法",
        "问题": "解释宽神经网络为何在变宽时表现出线性行为",
        "动机": "探索宽神经网络线性行为背后的原因，以理解其优化和泛化特性",
        "方法": "将神经网络视为由多个弱子模型递归组装而成的模型，分析其线性行为",
        "关键词": [
            "宽神经网络",
            "线性过渡",
            "弱模型组装",
            "神经切线核",
            "梯度下降"
        ],
        "涉及的技术概念": {
            "神经切线核（NTK）": "用于描述神经网络在训练过程中动态变化的核函数，本文中用于解释宽神经网络的线性行为",
            "梯度下降": "优化神经网络参数的常用方法，本文中用于探索优化路径与线性行为的关系",
            "弱模型组装": "指将多个性能较弱但多样化的子模型组合起来构建更强大模型的方法，本文中用于解释宽神经网络的线性特性"
        },
        "success": true
    },
    {
        "order": 1016,
        "title": "TRGP: Trust Region Gradient Projection for Continual Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6867",
        "abstract": "Catastrophic forgetting is one of the major challenges in continual learning. To address this issue, some existing methods put restrictive constraints on the optimization space of the new task for minimizing the interference to old tasks. However, this may lead to unsatisfactory performance for the new task, especially when the new task is strongly correlated with old tasks. To tackle this challenge, we propose Trust Region Gradient Projection (TRGP) for continual learning to facilitate the forward knowledge transfer based on an efficient characterization of task correlation. Particularly, we introduce a notion of 'trust region' to select the most related old tasks for the new task in a layer-wise and single-shot manner, using the norm of gradient projection onto the subspace spanned by task inputs. Then, a scaled weight projection is proposed to cleverly reuse the frozen weights of the selected old tasks in the trust region through a layer-wise scaling matrix. By jointly optimizing the scaling matrices and the model, where the model is updated along the directions orthogonal to the subspaces of old tasks,  TRGP can effectively prompt knowledge transfer without forgetting. Extensive experiments show that our approach achieves significant improvement over related state-of-the-art methods.",
        "conference": "ICLR",
        "中文标题": "TRGP：持续学习中的信任区域梯度投影方法",
        "摘要翻译": "灾难性遗忘是持续学习中的主要挑战之一。为了解决这一问题，一些现有方法对新任务的优化空间施加了严格的约束，以最小化对旧任务的干扰。然而，这可能导致新任务的性能不尽如人意，尤其是当新任务与旧任务强相关时。为了应对这一挑战，我们提出了持续学习中的信任区域梯度投影（TRGP）方法，以基于任务相关性的高效表征促进前向知识转移。具体而言，我们引入了‘信任区域’的概念，以层间和单次的方式选择与新任务最相关的旧任务，使用梯度投影到任务输入所张成的子空间上的范数。然后，提出了一种缩放权重投影方法，通过层间缩放矩阵巧妙地重用信任区域中选定旧任务的冻结权重。通过联合优化缩放矩阵和模型，其中模型沿着与旧任务子空间正交的方向更新，TRGP可以有效促进知识转移而不遗忘。大量实验表明，我们的方法相较于相关的最先进方法取得了显著改进。",
        "领域": "持续学习、梯度投影、知识转移",
        "问题": "解决持续学习中的灾难性遗忘问题，特别是在新任务与旧任务强相关时，如何有效促进前向知识转移而不遗忘旧任务。",
        "动机": "现有方法在处理新任务与旧任务强相关时，可能导致新任务性能不佳，因此需要一种更有效的方法来促进知识转移而不遗忘。",
        "方法": "提出信任区域梯度投影（TRGP）方法，通过引入信任区域选择相关旧任务，使用缩放权重投影重用旧任务权重，并联合优化缩放矩阵和模型以促进知识转移。",
        "关键词": [
            "持续学习",
            "信任区域",
            "梯度投影",
            "知识转移",
            "灾难性遗忘"
        ],
        "涉及的技术概念": {
            "信任区域": "用于选择与新任务最相关的旧任务，基于梯度投影的范数，以层间和单次方式进行。",
            "缩放权重投影": "通过层间缩放矩阵重用选定旧任务的冻结权重，以促进知识转移。",
            "正交方向更新": "模型更新方向与旧任务子空间正交，以避免干扰旧任务，有效减少灾难性遗忘。"
        },
        "success": true
    },
    {
        "order": 1017,
        "title": "Triangle and Four Cycle Counting with Predictions in Graph Streams",
        "html": "https://iclr.cc//virtual/2022/poster/6712",
        "abstract": "We propose data-driven one-pass streaming algorithms for estimating the number of triangles and four cycles, two fundamental problems in graph analytics that are widely studied in the graph data stream literature. Recently, Hsu et al. (2019) and Jiang et al. (2020) applied machine learning techniques in other data stream problems, using a trained oracle that can predict certain properties of the stream elements to improve on prior “classical” algorithms that did not use oracles. In this paper, we explore the power of a “heavy edge” oracle in multiple graph edge streaming models. In the adjacency list model, we present a one-pass triangle counting algorithm improving upon the previous space upper bounds without such an oracle. In the arbitrary order model, we present algorithms for both triangle and four cycle estimation with fewer passes and the same space complexity as in previous algorithms, and we show several of these bounds are optimal. We analyze our algorithms under several noise models, showing that the algorithms perform well even when the oracle errs. Our methodology expands upon prior work on “classical” streaming algorithms, as previous multi-pass and random order streaming algorithms can be seen as special cases of our algorithms, where the first pass or random order was used to implement the heavy edge oracle. Lastly, our experiments demonstrate advantages of the proposed method compared to state-of-the-art streaming algorithms.",
        "conference": "ICLR",
        "中文标题": "图流中基于预测的三角形和四环计数",
        "摘要翻译": "我们提出了数据驱动的一遍流式算法，用于估计三角形和四环的数量，这是图分析中的两个基本问题，在图数据流文献中被广泛研究。最近，Hsu等人（2019）和Jiang等人（2020）在其他数据流问题中应用了机器学习技术，使用一个训练过的预言机来预测流元素的某些属性，以改进之前不使用预言机的“经典”算法。在本文中，我们探索了“重边”预言机在多种图边流模型中的力量。在邻接表模型中，我们提出了一种一遍三角形计数算法，改进了之前没有此类预言机的空间上界。在任意顺序模型中，我们提出了用于三角形和四环估计的算法，这些算法具有更少的遍数和与之前算法相同的空间复杂度，并且我们展示了其中一些界限是最优的。我们在几种噪声模型下分析了我们的算法，表明即使预言机出错，算法也能表现良好。我们的方法扩展了之前关于“经典”流式算法的工作，因为之前的多遍和随机顺序流式算法可以被视为我们算法的特殊情况，其中第一遍或随机顺序被用来实现重边预言机。最后，我们的实验展示了所提出方法与最先进的流式算法相比的优势。",
        "领域": "图数据分析、流式算法、机器学习在图分析中的应用",
        "问题": "在图数据流中高效准确地估计三角形和四环的数量",
        "动机": "探索利用机器学习预言机改进传统图流算法的性能，特别是在减少空间复杂性和遍数方面",
        "方法": "提出基于数据驱动的一遍流式算法，利用“重边”预言机在不同图流模型中优化三角形和四环的计数",
        "关键词": [
            "图流算法",
            "三角形计数",
            "四环估计",
            "机器学习预言机",
            "数据驱动优化"
        ],
        "涉及的技术概念": {
            "重边预言机": "用于预测流元素中边的权重或重要性，以优化算法的空间和时间效率",
            "一遍流式算法": "仅需一次遍历数据流即可完成计算的算法，适用于大规模数据处理",
            "噪声模型分析": "评估算法在预言机预测存在误差时的鲁棒性和性能表现"
        },
        "success": true
    },
    {
        "order": 1018,
        "title": "Trigger Hunting with a Topological Prior for Trojan Detection",
        "html": "https://iclr.cc//virtual/2022/poster/6614",
        "abstract": "Despite their success and popularity, deep neural networks (DNNs) are vulnerable when facing backdoor attacks. This impedes their wider adoption, especially in mission critical applications. This paper tackles the problem of Trojan detection, namely, identifying Trojaned models – models trained with poisoned data. One popular approach is reverse engineering, i.e., recovering the triggers on a clean image by manipulating the model’s prediction. One major challenge of reverse engineering approach is the enormous search space of triggers. To this end, we propose innovative priors such as diversity and topological simplicity to not only increase the chances of finding the appropriate triggers but also improve the quality of the found triggers. Moreover, by encouraging a diverse set of trigger candidates, our method can perform effectively in cases with unknown target labels. We demonstrate that these priors can significantly improve the quality of the recovered triggers, resulting in substantially improved Trojan detection accuracy as validated on both synthetic and publicly available TrojAI benchmarks.",
        "conference": "ICLR",
        "中文标题": "利用拓扑先验进行触发器狩猎以检测木马",
        "摘要翻译": "尽管深度神经网络（DNNs）取得了成功并广受欢迎，但在面对后门攻击时它们显得脆弱。这阻碍了它们在关键任务应用中的更广泛采用。本文解决了木马检测的问题，即识别被木马感染的模型——这些模型是用被污染的数据训练的。一种流行的方法是逆向工程，即通过操纵模型的预测来恢复干净图像上的触发器。逆向工程方法的一个主要挑战是触发器的巨大搜索空间。为此，我们提出了创新性的先验，如多样性和拓扑简单性，不仅增加了找到适当触发器的机会，还提高了找到的触发器的质量。此外，通过鼓励一组多样化的触发器候选，我们的方法可以在目标标签未知的情况下有效执行。我们证明，这些先验可以显著提高恢复的触发器的质量，从而在合成和公开可用的TrojAI基准测试中验证了木马检测准确性的显著提高。",
        "领域": "深度学习安全、后门攻击防御、模型逆向工程",
        "问题": "识别和检测被木马感染的深度神经网络模型",
        "动机": "深度神经网络在面对后门攻击时的脆弱性限制了其在关键任务应用中的使用，需要有效的方法来检测这些被污染的模型。",
        "方法": "提出利用多样性和拓扑简单性等创新性先验来优化触发器的搜索过程，提高逆向工程的质量和效率。",
        "关键词": [
            "木马检测",
            "逆向工程",
            "触发器狩猎",
            "拓扑先验",
            "深度神经网络安全"
        ],
        "涉及的技术概念": {
            "逆向工程": "通过操纵模型的预测来恢复触发器，用于识别被木马感染的模型。",
            "拓扑简单性": "作为触发器搜索的先验之一，用于提高找到的触发器的质量和搜索效率。",
            "多样性先验": "鼓励多样化的触发器候选，使方法在目标标签未知的情况下也能有效执行。"
        },
        "success": true
    },
    {
        "order": 1019,
        "title": "Trivial or Impossible --- dichotomous data difficulty masks model differences (on ImageNet and beyond)",
        "html": "https://iclr.cc//virtual/2022/poster/5966",
        "abstract": "'The power of a generalization system follows directly from its biases' (Mitchell 1980). Today, CNNs are incredibly powerful generalisation systems---but to what degree have we understood how their inductive bias influences model decisions? We here attempt to disentangle the various aspects that determine how a model decides. In particular, we ask: what makes one model decide differently from another? In a meticulously controlled setting, we find that (1.) irrespective of the network architecture or objective (e.g. self-supervised, semi-supervised, vision transformers, recurrent models) all models end up with a similar decision boundary. (2.) To understand these findings, we analysed model decisions on the ImageNet validation set from epoch to epoch and image by image. We find that the ImageNet validation set, among others, suffers from dichotomous data difficulty (DDD): For the range of investigated models and their accuracies, it is dominated by 46.0% 'trivial' and 11.5% 'impossible' images (beyond label errors). Only 42.5%  of the images could possibly be responsible for the differences between two models' decision boundaries. (3.) Only removing the 'impossible' and 'trivial' images allows us to see pronounced differences between models. (4.) Humans are highly accurate at predicting which images are 'trivial' and 'impossible' for CNNs (81.4%). This implies that in future comparisons of brains, machines and behaviour, much may be gained from investigating the decisive role of images and the distribution of their difficulties.",
        "conference": "ICLR",
        "中文标题": "微不足道或不可能——二分数据难度掩盖模型差异（在ImageNet及其他数据集上）",
        "摘要翻译": "‘泛化系统的力量直接来源于其偏见’（Mitchell 1980）。如今，卷积神经网络（CNNs）是极其强大的泛化系统——但我们在多大程度上理解了它们的归纳偏见如何影响模型决策？我们在此尝试解析决定模型决策的各个方面。特别是，我们提出：是什么使得一个模型的决策不同于另一个？在一个精心控制的设置中，我们发现（1.）不论网络架构或目标（例如自监督、半监督、视觉变换器、循环模型）如何，所有模型最终都会形成相似的决策边界。（2.）为了理解这些发现，我们逐时期、逐图像地分析了模型在ImageNet验证集上的决策。我们发现，ImageNet验证集等存在二分数据难度（DDD）：对于所研究的模型范围及其准确率，它由46.0%的‘微不足道’和11.5%的‘不可能’图像（超出标签错误）主导。只有42.5%的图像可能负责两个模型决策边界之间的差异。（3.）只有移除‘不可能’和‘微不足道’的图像，我们才能看到模型之间的显著差异。（4.）人类在预测哪些图像对CNNs来说是‘微不足道’和‘不可能’方面非常准确（81.4%）。这意味着，在未来比较大脑、机器和行为时，从研究图像及其难度分布的决定性角色中可能会获得很多。",
        "领域": "图像分类、模型比较、深度学习理论",
        "问题": "理解不同模型在ImageNet等数据集上决策边界相似性的原因，以及数据难度分布对模型比较的影响。",
        "动机": "探索卷积神经网络的归纳偏见如何影响其决策，以及为何不同架构的模型在相同数据集上表现出相似的决策边界。",
        "方法": "通过精心控制的实验设置，分析不同模型在ImageNet验证集上的决策过程，识别数据难度分布对模型决策边界的影响。",
        "关键词": [
            "二分数据难度",
            "模型比较",
            "决策边界",
            "ImageNet",
            "归纳偏见"
        ],
        "涉及的技术概念": {
            "二分数据难度（DDD）": "描述了数据集中图像对模型而言的难度分布，分为‘微不足道’、‘可能’和‘不可能’三类，影响模型决策边界的形成。",
            "决策边界": "模型在特征空间中划分不同类别的界限，本研究探讨了不同模型在相同数据集上决策边界相似的原因。",
            "归纳偏见": "模型在学习过程中对某些假设的偏好，本研究探讨了CNN的归纳偏见如何影响其决策过程。"
        },
        "success": true
    },
    {
        "order": 1020,
        "title": "Trust Region Policy Optimisation in Multi-Agent Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6244",
        "abstract": "Trust region methods rigorously enabled reinforcement learning (RL) agents to learn monotonically improving policies, leading to superior performance on a variety of tasks. Unfortunately, when it comes to multi-agent reinforcement learning (MARL),  the property of monotonic improvement may not simply apply; this is because agents, even in cooperative games, could have conflicting directions of policy updates. As a result, achieving a guaranteed improvement on the joint policy where each agent acts individually remains an open challenge. In this paper, we extend the theory of trust region learning to MARL. Central to our findings are the multi-agent advantage decomposition lemma and the sequential policy update scheme. Based on these, we develop Heterogeneous-Agent Trust Region Policy Optimisation (HATPRO) and Heterogeneous-Agent Proximal Policy Optimisation (HAPPO) algorithms. Unlike many existing MARL algorithms, HATRPO/HAPPO do not need agents to share parameters, nor do they need any restrictive assumptions on decomposibility of the joint value function. Most importantly, we justify in theory the monotonic improvement property of HATRPO/HAPPO. We evaluate the proposed methods on a series of Multi-Agent MuJoCo and StarCraftII tasks. Results show that HATRPO and HAPPO significantly outperform strong baselines such as IPPO, MAPPO and MADDPG on all tested tasks, thereby establishing a new state of the art. ",
        "conference": "ICLR",
        "中文标题": "多智能体强化学习中的信任区域策略优化",
        "摘要翻译": "信任区域方法严格地使强化学习（RL）智能体能够学习单调改进的策略，从而在各种任务上获得卓越的性能。不幸的是，当涉及到多智能体强化学习（MARL）时，单调改进的特性可能不简单适用；这是因为即使在合作游戏中，智能体也可能有策略更新的冲突方向。因此，在联合策略上实现保证的改进，其中每个智能体独立行动，仍然是一个未解决的挑战。在本文中，我们将信任区域学习的理论扩展到MARL。我们发现的核心是多智能体优势分解引理和顺序策略更新方案。基于这些，我们开发了异构智能体信任区域策略优化（HATPRO）和异构智能体近端策略优化（HAPPO）算法。与许多现有的MARL算法不同，HATRPO/HAPPO不需要智能体共享参数，也不需要任何关于联合价值函数可分解性的限制性假设。最重要的是，我们在理论上证明了HATRPO/HAPPO的单调改进特性。我们在多智能体MuJoCo和StarCraftII任务系列上评估了所提出的方法。结果显示，HATRPO和HAPPO在所有测试任务上显著优于IPPO、MAPPO和MADDPG等强基线，从而建立了新的技术状态。",
        "领域": "多智能体强化学习",
        "问题": "在多智能体环境中实现单调改进的联合策略",
        "动机": "解决多智能体强化学习中由于策略更新方向冲突导致的单调改进特性不适用的问题",
        "方法": "扩展信任区域学习理论到MARL，开发HATRPO和HAPPO算法，基于多智能体优势分解引理和顺序策略更新方案",
        "关键词": [
            "多智能体强化学习",
            "信任区域方法",
            "策略优化",
            "单调改进",
            "异构智能体"
        ],
        "涉及的技术概念": {
            "信任区域方法": "用于保证强化学习智能体策略单调改进的技术",
            "多智能体优势分解引理": "在多智能体环境中分解和利用优势函数的技术",
            "顺序策略更新方案": "在多智能体环境中按顺序更新策略以避免冲突的方法"
        },
        "success": true
    },
    {
        "order": 1021,
        "title": "Tuformer: Data-driven Design of Transformers for Improved Generalization or Efficiency",
        "html": "https://iclr.cc//virtual/2022/poster/6003",
        "abstract": "Transformers are neural network architectures that achieve remarkable performance in many areas. However, the core component of Transformers, multi-head self-attention (MHSA), is mainly derived from heuristics, and the interactions across its components are not well understood. To address the problem, we first introduce a mathematically rigorous and yet intuitive tensor diagram representation of MHSA. Guided by tensor diagram representations, we propose a novel design, namely Tunable Transformers (Tuformers), by allowing data-driven weights across heads, whereas MHSA adopts pre-defined and fixed weights across heads, as will be explained in our paper. Tuformers naturally reveal a flexible design space that a user, depending on the needs, can choose a structure that has either improved performance (generalization error) or higher model efficiency. Any pre-trained Transformer can be an initialization of the corresponding Tuformer with trainable number of heads for efficient training and fine-tuning. Tuformers universally outperform Transformers on various tasks across multiple domains under a wide range of model sizes.",
        "conference": "ICLR",
        "中文标题": "Tuformer：数据驱动的Transformer设计以提升泛化能力或效率",
        "摘要翻译": "Transformer是一种在许多领域取得显著性能的神经网络架构。然而，Transformer的核心组件——多头自注意力机制（MHSA）主要来源于启发式设计，其组件间的相互作用尚未得到充分理解。为解决这一问题，我们首先引入了一种数学上严谨且直观的张量图表示法来描述MHSA。在张量图表示的指导下，我们提出了一种新颖的设计，即可调谐Transformer（Tuformer），它允许跨头部的数据驱动权重，而MHSA则采用预定义且固定的跨头部权重，正如我们将在论文中解释的那样。Tuformer自然揭示了一个灵活的设计空间，用户可以根据需求选择具有更好性能（泛化误差）或更高模型效率的结构。任何预训练的Transformer都可以作为相应Tuformer的初始化，具有可训练的头数以实现高效的训练和微调。在各种任务和多个领域下，Tuformer在广泛的模型大小范围内普遍优于Transformer。",
        "领域": "自然语言处理与视觉结合, 深度学习模型优化, 注意力机制研究",
        "问题": "如何通过数据驱动的方法改进Transformer的多头自注意力机制，以提升其泛化能力或效率",
        "动机": "当前Transformer的多头自注意力机制设计基于启发式方法，缺乏对组件间相互作用的深入理解，限制了模型的性能和效率",
        "方法": "引入张量图表示法描述多头自注意力机制，并提出可调谐Transformer（Tuformer），通过数据驱动的方式调整跨头部的权重",
        "关键词": [
            "可调谐Transformer",
            "多头自注意力机制",
            "张量图表示",
            "数据驱动设计",
            "模型效率"
        ],
        "涉及的技术概念": {
            "多头自注意力机制（MHSA）": "Transformer的核心组件，用于捕捉序列中不同位置间的依赖关系",
            "张量图表示": "一种数学上严谨且直观的表示方法，用于描述和分析MHSA的结构和相互作用",
            "可调谐Transformer（Tuformer）": "通过数据驱动的方式调整跨头部权重的Transformer变体，旨在提升模型的泛化能力或效率"
        },
        "success": true
    },
    {
        "order": 1022,
        "title": "T-WaveNet: A Tree-Structured Wavelet Neural Network for Time Series Signal Analysis",
        "html": "https://iclr.cc//virtual/2022/poster/6803",
        "abstract": "Time series signal analysis plays an essential role in many applications, e.g., activity recognition and healthcare monitoring.Recently, features extracted with deep neural networks (DNNs) have shown to be more effective than conventional hand-crafted ones.However, most existing solutions rely solely on the network to extract information carried in the raw signal, regardless of its inherent physical and statistical properties, leading to sub-optimal performance particularly under a limited amount of training data.In this work, we propose a novel tree-structured wavelet neural network for time series signal analysis, namely \\emph{T-WaveNet}, taking advantage of an inherent property of various types of signals, known as the \\emph{dominant frequency range}. Specifically, with \\emph{T-WaveNet}, we first conduct frequency spectrum energy analysis of the signals to get a set of dominant frequency subbands. Then, we construct a tree-structured network that iteratively decomposes the input signal into various frequency subbands with similar energies. Each node on the tree is built with an invertible neural network (INN) based wavelet transform unit. Such a disentangled representation learning method facilitates a more effective extraction of the discriminative features, as demonstrated with the comprehensive experiments on various real-life time series classification datasets. ",
        "conference": "ICLR",
        "中文标题": "T-WaveNet：一种用于时间序列信号分析的树结构小波神经网络",
        "摘要翻译": "时间序列信号分析在许多应用中扮演着关键角色，例如活动识别和健康监测。近年来，通过深度神经网络（DNNs）提取的特征已被证明比传统手工制作的特征更为有效。然而，大多数现有解决方案仅依赖网络从原始信号中提取信息，而忽略了其固有的物理和统计特性，这导致在训练数据量有限的情况下性能不佳。在本工作中，我们提出了一种新颖的树结构小波神经网络用于时间序列信号分析，即T-WaveNet，它利用了各种类型信号的一个固有属性，称为主导频率范围。具体来说，使用T-WaveNet，我们首先对信号进行频谱能量分析，以获得一组主导频率子带。然后，我们构建一个树结构网络，该网络迭代地将输入信号分解为具有相似能量的各种频率子带。树上的每个节点都构建有一个基于可逆神经网络（INN）的小波变换单元。这种解耦的表示学习方法有助于更有效地提取判别性特征，如对各种实际时间序列分类数据集的全面实验所证明的那样。",
        "领域": "时间序列分析、信号处理、深度学习",
        "问题": "解决在有限训练数据下，现有深度神经网络方法忽略信号固有物理和统计特性导致的性能不佳问题",
        "动机": "利用信号的主导频率范围这一固有属性，提高时间序列信号分析的性能",
        "方法": "提出一种树结构小波神经网络（T-WaveNet），通过频率谱能量分析提取主导频率子带，并构建树结构网络迭代分解信号，每个节点使用基于可逆神经网络的小波变换单元",
        "关键词": [
            "时间序列分析",
            "小波神经网络",
            "主导频率范围",
            "可逆神经网络",
            "信号分解"
        ],
        "涉及的技术概念": {
            "主导频率范围": "信号中能量集中的频率子带，用于指导信号分解和特征提取",
            "树结构小波神经网络": "一种树形结构的网络，用于迭代分解信号到不同频率子带，提高特征提取效率",
            "可逆神经网络（INN）": "用于构建网络节点的小波变换单元，确保信号分解的可逆性和信息保留"
        },
        "success": true
    },
    {
        "order": 1023,
        "title": "Uncertainty Modeling for Out-of-Distribution Generalization",
        "html": "https://iclr.cc//virtual/2022/poster/7084",
        "abstract": "Though remarkable progress has been achieved in various vision tasks, deep neural networks still suffer obvious performance degradation when tested in out-of-distribution scenarios. We argue that the feature statistics (mean and standard deviation), which carry the domain characteristics of the training data, can be properly manipulated to improve the generalization ability of deep learning models. Common methods often consider the feature statistics as deterministic values measured from the learned features and do not explicitly consider the uncertain statistics discrepancy caused by potential domain shifts during testing. In this paper, we improve the network generalization ability by modeling the uncertainty of domain shifts with synthesized feature statistics during training. Specifically, we hypothesize that the feature statistic, after considering the potential uncertainties, follows a multivariate Gaussian distribution. Hence, each feature statistic is no longer a deterministic value, but a probabilistic point with diverse distribution possibilities. With the uncertain feature statistics, the models can be trained to alleviate the domain perturbations and achieve better robustness against potential domain shifts. Our method can be readily integrated into networks without additional parameters. Extensive experiments demonstrate that our proposed method consistently improves the network generalization ability on multiple vision tasks, including image classification, semantic segmentation, and instance retrieval.",
        "conference": "ICLR",
        "中文标题": "面向分布外泛化的不确定性建模",
        "摘要翻译": "尽管在各种视觉任务中取得了显著进展，深度神经网络在分布外场景测试时仍然表现出明显的性能下降。我们认为，携带训练数据域特征的特征统计量（均值和标准差）可以被适当操纵，以提高深度学习模型的泛化能力。常见方法通常将特征统计量视为从学习到的特征中测量得到的确定性值，并未明确考虑测试期间潜在域转移引起的不确定性统计差异。在本文中，我们通过在训练期间用合成的特征统计量建模域转移的不确定性，来提高网络的泛化能力。具体来说，我们假设在考虑潜在不确定性后，特征统计量遵循多元高斯分布。因此，每个特征统计量不再是一个确定性值，而是一个具有多样分布可能性的概率点。利用不确定的特征统计量，可以训练模型以减轻域扰动，并对抗潜在的域转移，实现更好的鲁棒性。我们的方法可以轻松集成到网络中，无需额外参数。大量实验证明，我们提出的方法在多个视觉任务上持续提高了网络的泛化能力，包括图像分类、语义分割和实例检索。",
        "领域": "域适应、图像分类、语义分割",
        "问题": "深度神经网络在分布外场景下的性能下降问题",
        "动机": "提高深度学习模型在分布外场景下的泛化能力和鲁棒性",
        "方法": "通过建模特征统计量的不确定性来模拟域转移，训练模型以减轻域扰动",
        "关键词": [
            "不确定性建模",
            "域适应",
            "特征统计量",
            "多元高斯分布",
            "网络泛化"
        ],
        "涉及的技术概念": {
            "特征统计量": "携带训练数据域特征的均值和标准差，用于提高模型的泛化能力",
            "多元高斯分布": "假设特征统计量在考虑潜在不确定性后遵循的分布，用于模拟域转移的不确定性",
            "域适应": "通过建模域转移的不确定性，训练模型以减轻域扰动，提高在分布外场景下的性能"
        },
        "success": true
    },
    {
        "order": 1024,
        "title": "Understanding and Improving Graph Injection Attack by Promoting Unnoticeability",
        "html": "https://iclr.cc//virtual/2022/poster/6046",
        "abstract": "Recently Graph Injection Attack (GIA) emerges as a practical attack scenario on Graph Neural Networks (GNNs), where the adversary can merely inject few malicious nodes instead of modifying existing nodes or edges, i.e., Graph Modification Attack (GMA). Although GIA has achieved promising results, little is known about why it is successful and whether there is any pitfall behind the success. To understand the power of GIA, we compare it with GMA and find that GIA can be provably more harmful than GMA due to its relatively high flexibility. However, the high flexibility will also lead to great damage to the homophily distribution of the original graph, i.e., similarity among neighbors. Consequently, the threats of GIA can be easily alleviated or even prevented by homophily-based defenses designed to recover the original homophily. To mitigate the issue, we introduce a novel constraint – homophily unnoticeability that enforces GIA to preserve the homophily, and propose Harmonious Adversarial Objective (HAO) to instantiate it. Extensive experiments verify that GIA with HAO can break homophily-based defenses and outperform previous GIA attacks by a significant margin. We believe our methods can serve for a more reliable evaluation of the robustness of GNNs.",
        "conference": "ICLR",
        "中文标题": "理解并提升图注入攻击通过促进不可察觉性",
        "摘要翻译": "最近，图注入攻击（GIA）作为一种对图神经网络（GNNs）的实际攻击场景出现，攻击者仅需注入少量恶意节点，而非修改现有节点或边，即图修改攻击（GMA）。尽管GIA已取得显著成果，但其成功的原因及背后是否存在陷阱尚不明确。为了理解GIA的力量，我们将其与GMA进行比较，发现由于GIA具有相对较高的灵活性，可证明其比GMA更具危害性。然而，高灵活性也会对原始图的同质性分布（即邻居间的相似性）造成巨大破坏。因此，通过设计用于恢复原始同质性的基于同质性的防御措施，可以轻易缓解甚至防止GIA的威胁。为了缓解这一问题，我们引入了一种新的约束——同质性不可察觉性，强制GIA保持同质性，并提出了和谐对抗目标（HAO）来实现它。大量实验验证，带有HAO的GIA能够突破基于同质性的防御，并显著优于之前的GIA攻击。我们相信，我们的方法可以为GNNs的鲁棒性评估提供更可靠的依据。",
        "领域": "图神经网络安全、对抗攻击、图数据挖掘",
        "问题": "图注入攻击（GIA）为何成功及其潜在的缺陷，以及如何提升其不可察觉性以突破基于同质性的防御。",
        "动机": "探究GIA攻击成功的原因及其潜在问题，开发更有效的攻击方法以评估图神经网络的鲁棒性。",
        "方法": "通过比较GIA与GMA的攻击效果，引入同质性不可察觉性约束，并提出和谐对抗目标（HAO）来实施这一约束。",
        "关键词": [
            "图注入攻击",
            "同质性不可察觉性",
            "和谐对抗目标",
            "图神经网络",
            "对抗攻击"
        ],
        "涉及的技术概念": {
            "图注入攻击（GIA）": "一种通过注入恶意节点而非修改现有图结构来攻击图神经网络的方法。",
            "同质性不可察觉性": "一种约束，强制GIA攻击在保持图结构同质性的同时进行，以提高攻击的隐蔽性。",
            "和谐对抗目标（HAO）": "一种新提出的目标函数，用于实现同质性不可察觉性，使GIA攻击能够有效突破基于同质性的防御措施。"
        },
        "success": true
    },
    {
        "order": 1025,
        "title": "Understanding and Leveraging Overparameterization in Recursive Value Estimation",
        "html": "https://iclr.cc//virtual/2022/poster/7117",
        "abstract": "The theory of function approximation in reinforcement learning (RL) typically considers low capacity representations that incur a tradeoff between approximation error, stability and generalization.  Current deep architectures, however, operate in an overparameterized regime where approximation error is not necessarily a bottleneck.  To better understand the utility of deep models in RL we present an analysis of recursive value estimation using \\emph{overparameterized} linear representations that provides useful, transferable findings.  First, we show that classical updates such as temporal difference (TD) learning or fitted-value-iteration (FVI) converge to \\emph{different} fixed points than residual minimization (RM) in the overparameterized linear case.  We then develop a unified interpretation of overparameterized linear value estimation as minimizing the Euclidean norm of the weights subject to alternative constraints.  A practical consequence is that RM can be modified by a simple alteration of the backup targets to obtain the same fixed points as FVI and TD (when they converge), while universally ensuring stability.  Further, we provide an analysis of the generalization error of these methods, demonstrating per iterate bounds on the value prediction error of FVI, and fixed point bounds for TD and RM.  Given this understanding, we then develop new algorithmic tools for improving recursive value estimation with deep models. In particular, we extract two regularizers that penalize out-of-span top-layer weights and co-linearity in top-layer features respectively.  Empirically we find that these regularizers dramatically improve the stability of TD and FVI, while allowing RM to match and even sometimes surpass their generalization performance with assured stability. ",
        "conference": "ICLR",
        "中文标题": "理解并利用递归价值估计中的过参数化",
        "摘要翻译": "强化学习（RL）中的函数逼近理论通常考虑低容量表示，这些表示在逼近误差、稳定性和泛化性之间进行权衡。然而，当前的深度架构在过参数化机制下运行，其中逼近误差不一定是瓶颈。为了更好地理解深度模型在RL中的效用，我们提出了一种使用过参数化线性表示的递归价值估计分析，提供了有用且可转移的发现。首先，我们展示了在过参数化线性情况下，经典更新如时间差分（TD）学习或拟合价值迭代（FVI）收敛到与残差最小化（RM）不同的固定点。然后，我们发展了对过参数化线性价值估计的统一解释，即最小化权重的欧几里得范数，同时满足替代约束。一个实际结果是，RM可以通过简单修改备份目标来获得与FVI和TD相同的固定点（当它们收敛时），同时普遍确保稳定性。此外，我们提供了这些方法泛化误差的分析，展示了FVI价值预测误差的每迭代界限，以及TD和RM的固定点界限。基于这一理解，我们随后开发了新的算法工具，用于改进深度模型的递归价值估计。特别是，我们提取了两个正则化器，分别惩罚顶层权重的跨度和顶层特征的共线性。实证我们发现，这些正则化器显著提高了TD和FVI的稳定性，同时允许RM匹配甚至有时超越它们的泛化性能，同时确保稳定性。",
        "领域": "强化学习、深度强化学习、价值估计",
        "问题": "解决在过参数化机制下，递归价值估计方法的收敛性和泛化性问题",
        "动机": "探索深度模型在强化学习中的效用，特别是在过参数化情况下如何改进递归价值估计的稳定性和泛化性能",
        "方法": "分析过参数化线性表示的递归价值估计，开发统一解释和新的正则化器",
        "关键词": [
            "过参数化",
            "递归价值估计",
            "正则化器",
            "强化学习",
            "深度模型"
        ],
        "涉及的技术概念": {
            "过参数化线性表示": "在过参数化机制下，使用线性表示进行递归价值估计，以探索逼近误差、稳定性和泛化性之间的关系",
            "残差最小化（RM）": "一种价值估计方法，通过修改备份目标来确保稳定性，并匹配其他方法的固定点",
            "正则化器": "用于惩罚顶层权重的跨度和顶层特征的共线性，以提高方法的稳定性和泛化性能"
        },
        "success": true
    },
    {
        "order": 1026,
        "title": "Understanding and Preventing Capacity Loss in Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6597",
        "abstract": "The reinforcement learning (RL) problem is rife with sources of non-stationarity that can destabilize or inhibit learning progress.We identify a key mechanism by which this occurs in agents using neural networks as function approximators: \\textit{capacity loss}, whereby networks trained to predict a sequence of target values lose their ability to quickly fit new functions over time.We demonstrate that capacity loss occurs in a broad range of RL agents and environments, and is particularly damaging to learning progress in sparse-reward tasks. We then present a simple regularizer, Initial Feature Regularization (InFeR), that mitigates this phenomenon by regressing a subspace of features towards its value at initialization, improving performance over a state-of-the-art model-free algorithm in the Atari 2600 suite. Finally, we study how this regularization affects different notions of capacity and evaluate other mechanisms by which it may improve performance.",
        "conference": "ICLR",
        "中文标题": "理解与预防强化学习中的容量损失",
        "摘要翻译": "强化学习（RL）问题充满了可能导致学习进程不稳定或受阻的非平稳性来源。我们发现，在使用神经网络作为函数逼近器的智能体中，这种现象发生的一个关键机制是：容量损失，即经过训练以预测一系列目标值的网络随时间推移失去快速拟合新函数的能力。我们证明，容量损失发生在广泛的RL智能体和环境中，并且对稀疏奖励任务中的学习进程尤其有害。然后，我们提出了一种简单的正则化方法，初始特征正则化（InFeR），通过将特征的一个子空间回归到其初始化的值来缓解这一现象，从而在Atari 2600套件中提高了最先进的无模型算法的性能。最后，我们研究了这种正则化如何影响不同的容量概念，并评估了它可能通过其他机制提高性能的方式。",
        "领域": "强化学习",
        "问题": "解决强化学习中由于容量损失导致的学习进程不稳定或受阻的问题",
        "动机": "识别并缓解强化学习智能体中因容量损失导致的学习效率下降",
        "方法": "提出初始特征正则化（InFeR）方法，通过回归特征子空间到其初始值来防止容量损失",
        "关键词": [
            "容量损失",
            "初始特征正则化",
            "强化学习",
            "非平稳性",
            "稀疏奖励"
        ],
        "涉及的技术概念": {
            "容量损失": "神经网络在训练过程中失去快速拟合新函数能力的现象",
            "初始特征正则化（InFeR）": "一种通过回归特征子空间到其初始值来防止容量损失的正则化方法",
            "非平稳性": "强化学习环境中导致学习进程不稳定或受阻的动态变化特性"
        },
        "success": true
    },
    {
        "order": 1027,
        "title": "Understanding approximate and unrolled dictionary learning for pattern recovery",
        "html": "https://iclr.cc//virtual/2022/poster/6331",
        "abstract": "Dictionary learning consists of finding a sparse representation from noisy data and is a common way to encode data-driven prior knowledge on signals. Alternating minimization (AM) is standard for the underlying optimization, where gradient descent steps alternate with sparse coding procedures. The major drawback of this method is its prohibitive computational cost, making it unpractical on large real-world data sets. This work studies an approximate formulation of dictionary learning based on unrolling and compares it to alternating minimization to find the best trade-off between speed and precision. We analyze the asymptotic behavior and convergence rate of gradients estimates in both methods. We show that unrolling performs better on the support of the inner problem solution and during the first iterations. Finally, we apply unrolling on pattern learning in magnetoencephalography (MEG) with the help of a stochastic algorithm and compare the performance to a state-of-the-art method.",
        "conference": "ICLR",
        "中文标题": "理解近似与展开式字典学习在模式恢复中的应用",
        "摘要翻译": "字典学习包括从噪声数据中寻找稀疏表示，是编码信号数据驱动先验知识的常用方法。交替最小化（AM）是基础优化的标准方法，其中梯度下降步骤与稀疏编码过程交替进行。该方法的主要缺点是其高昂的计算成本，使其在大型现实世界数据集上不切实际。本研究基于展开式研究了字典学习的近似公式，并将其与交替最小化进行比较，以找到速度和精度之间的最佳权衡。我们分析了两种方法中梯度估计的渐近行为和收敛速度。我们表明，展开式在内部问题解的支撑上和最初几次迭代中表现更好。最后，我们在随机算法的帮助下将展开式应用于脑磁图（MEG）中的模式学习，并将其性能与最先进的方法进行比较。",
        "领域": "稀疏编码、信号处理、模式识别",
        "问题": "解决字典学习在大规模数据集上计算成本高的问题",
        "动机": "寻找一种在速度和精度之间达到最佳平衡的字典学习方法",
        "方法": "研究基于展开式的字典学习近似公式，并与交替最小化方法进行比较",
        "关键词": [
            "字典学习",
            "展开式",
            "交替最小化",
            "稀疏编码",
            "脑磁图"
        ],
        "涉及的技术概念": {
            "字典学习": "从噪声数据中寻找稀疏表示，编码数据驱动的先验知识",
            "交替最小化": "通过交替进行梯度下降和稀疏编码来优化字典学习",
            "展开式": "一种近似优化方法，通过展开迭代过程来加速计算"
        },
        "success": true
    },
    {
        "order": 1028,
        "title": "Understanding Dimensional Collapse in Contrastive Self-supervised Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6792",
        "abstract": "Self-supervised visual representation learning aims to learn useful representations without relying on human annotations. Joint embedding approach bases on maximizing the agreement between embedding vectors from different views of the same image. Various methods have been proposed to solve the collapsing problem where all embedding vectors collapse to a trivial constant solution. Among these methods, contrastive learning prevents collapse via negative sample pairs. It has been shown that non-contrastive methods suffer from a lesser collapse problem of a different nature: dimensional collapse, whereby the embedding vectors end up spanning a lower-dimensional subspace instead of the entire available embedding space. Here, we show that dimensional collapse also happens in contrastive learning. In this paper, we shed light on the dynamics at play in contrastive learning that leads to dimensional collapse. Inspired by our theory,  we propose a novel contrastive learning method, called DirectCLR, which directly optimizes the representation space without relying on a trainable projector. Experiments show that DirectCLR  outperforms SimCLR with a trainable linear projector on ImageNet. ",
        "conference": "ICLR",
        "中文标题": "理解对比自监督学习中的维度坍缩",
        "摘要翻译": "自监督视觉表示学习旨在不依赖人类标注的情况下学习有用的表示。联合嵌入方法基于最大化同一图像不同视图间嵌入向量的一致性。已有多种方法被提出来解决所有嵌入向量坍缩到一个平凡常数解的坍缩问题。在这些方法中，对比学习通过负样本对防止坍缩。研究表明，非对比方法遭受另一种性质的坍缩问题：维度坍缩，即嵌入向量最终跨越一个较低维度的子空间，而非整个可用的嵌入空间。本文中，我们展示了对比学习中也存在维度坍缩。本文揭示了导致维度坍缩的对比学习动态。受我们理论的启发，我们提出了一种新的对比学习方法，称为DirectCLR，它直接优化表示空间，而不依赖于可训练的投影器。实验表明，DirectCLR在ImageNet上优于带有可训练线性投影器的SimCLR。",
        "领域": "自监督学习、对比学习、视觉表示学习",
        "问题": "解决对比自监督学习中的维度坍缩问题",
        "动机": "揭示对比学习中维度坍缩的动态，并提出解决方案以优化表示空间",
        "方法": "提出DirectCLR方法，直接优化表示空间，避免使用可训练的投影器",
        "关键词": [
            "维度坍缩",
            "对比学习",
            "自监督学习",
            "DirectCLR",
            "表示学习"
        ],
        "涉及的技术概念": {
            "维度坍缩": "嵌入向量跨越的维度低于可用嵌入空间维度的问题",
            "对比学习": "通过正负样本对学习表示的方法，防止表示坍缩",
            "DirectCLR": "一种新型对比学习方法，直接优化表示空间，不依赖可训练投影器"
        },
        "success": true
    },
    {
        "order": 1029,
        "title": "Understanding Domain Randomization for Sim-to-real Transfer",
        "html": "https://iclr.cc//virtual/2022/poster/6876",
        "abstract": "Reinforcement learning encounters many challenges when applied directly in the real world. Sim-to-real transfer is widely used to transfer the knowledge learned from simulation to the real world. Domain randomization---one of the most popular algorithms for sim-to-real transfer---has been demonstrated to be effective in various tasks in robotics and  autonomous driving. Despite its empirical successes, theoretical understanding on why this simple algorithm works is largely missing. In this paper, we propose a  theoretical framework for sim-to-real transfers, in which the simulator is modeled as a set of MDPs with tunable parameters (corresponding to unknown physical parameters such as friction).  We provide sharp bounds on the sim-to-real gap---the difference between the value of policy returned by domain randomization and the value of an optimal policy for the real world. We prove that sim-to-real transfer can succeed under mild conditions without any real-world training samples. Our theory also highlights the importance of using memory (i.e., history-dependent policies) in domain randomization. Our proof is based on novel techniques that reduce the problem of bounding the sim-to-real gap to the problem of designing efficient learning algorithms for infinite-horizon MDPs, which we believe are of independent interest.",
        "conference": "ICLR",
        "中文标题": "理解域随机化在模拟到现实迁移中的应用",
        "摘要翻译": "强化学习在直接应用于现实世界时遇到许多挑战。模拟到现实迁移被广泛用于将从模拟中学到的知识迁移到现实世界。域随机化——模拟到现实迁移中最流行的算法之一——已被证明在机器人和自动驾驶的各种任务中是有效的。尽管它在经验上取得了成功，但关于这个简单算法为何有效的理论理解在很大程度上是缺失的。在本文中，我们提出了一个模拟到现实迁移的理论框架，其中模拟器被建模为一组具有可调参数（对应于未知的物理参数，如摩擦）的MDPs。我们提供了关于模拟到现实差距的尖锐界限——域随机化返回的策略的价值与针对现实世界的最优策略的价值之间的差异。我们证明，在温和的条件下，模拟到现实迁移可以成功，而无需任何现实世界的训练样本。我们的理论还强调了在域随机化中使用记忆（即依赖于历史的策略）的重要性。我们的证明基于新技术，这些技术将限制模拟到现实差距的问题简化为设计无限视野MDPs的高效学习算法的问题，我们认为这些技术具有独立的意义。",
        "领域": "强化学习、机器人控制、自动驾驶",
        "问题": "理解域随机化算法在模拟到现实迁移中为何有效",
        "动机": "尽管域随机化在经验上取得了成功，但其理论基础的缺失促使本研究探索其有效性背后的原因。",
        "方法": "提出一个理论框架，将模拟器建模为具有可调参数的MDPs，并提供模拟到现实差距的界限，证明在特定条件下无需现实世界训练样本即可成功迁移。",
        "关键词": [
            "域随机化",
            "模拟到现实迁移",
            "强化学习",
            "MDPs",
            "理论框架"
        ],
        "涉及的技术概念": {
            "域随机化": "一种模拟到现实迁移的算法，通过在模拟环境中随机化参数来增强模型的泛化能力。",
            "MDPs（马尔可夫决策过程）": "用于建模决策过程的数学框架，其中模拟器被建模为一组具有可调参数的MDPs。",
            "模拟到现实差距": "域随机化返回的策略价值与最优现实世界策略价值之间的差异，本研究提供了其界限的理论分析。"
        },
        "success": true
    },
    {
        "order": 1030,
        "title": "Understanding Intrinsic Robustness Using Label Uncertainty",
        "html": "https://iclr.cc//virtual/2022/poster/6167",
        "abstract": "A fundamental question in adversarial machine learning is whether a robust classifier exists for a given task. A line of research has made some progress towards this goal by studying the concentration of measure, but we argue standard concentration fails to fully characterize the intrinsic robustness of a classification problem since it ignores data labels which are essential to any classification task. Building on a novel definition of label uncertainty, we empirically demonstrate that error regions induced by state-of-the-art models tend to have much higher label uncertainty than randomly-selected subsets. This observation motivates us to adapt a concentration estimation algorithm to account for label uncertainty, resulting in more accurate intrinsic robustness measures for benchmark image classification problems.",
        "conference": "ICLR",
        "中文标题": "利用标签不确定性理解内在鲁棒性",
        "摘要翻译": "在对抗性机器学习中，一个基本问题是对于给定任务是否存在一个鲁棒的分类器。一系列研究通过研究测度的集中性在这一目标上取得了一些进展，但我们认为标准集中性未能完全表征分类问题的内在鲁棒性，因为它忽略了任何分类任务都必不可少的数据标签。基于对标签不确定性的新定义，我们实证证明了由最先进模型引起的错误区域往往比随机选择的子集具有更高的标签不确定性。这一观察促使我们调整一个集中性估计算法以考虑标签不确定性，从而为基准图像分类问题提供了更准确的内在鲁棒性度量。",
        "领域": "对抗性机器学习",
        "问题": "研究内在鲁棒性的准确度量方法",
        "动机": "标准集中性方法忽略了数据标签，未能完全表征分类问题的内在鲁棒性",
        "方法": "基于标签不确定性的新定义，调整集中性估计算法以考虑标签不确定性",
        "关键词": [
            "对抗性机器学习",
            "内在鲁棒性",
            "标签不确定性",
            "集中性估计",
            "图像分类"
        ],
        "涉及的技术概念": {
            "标签不确定性": "用于衡量分类任务中数据标签的不确定性程度，帮助更准确地评估模型的鲁棒性",
            "集中性估计": "一种用于研究数据分布特性的方法，本文中调整以考虑标签不确定性",
            "内在鲁棒性": "指分类问题本身固有的抵抗对抗性攻击的能力，本文旨在更准确地度量这一特性"
        },
        "success": true
    },
    {
        "order": 1031,
        "title": "Understanding Latent Correlation-Based Multiview Learning and Self-Supervision: An Identifiability Perspective",
        "html": "https://iclr.cc//virtual/2022/poster/6061",
        "abstract": "Multiple views of data, both naturally acquired (e.g., image and audio) and artificially produced (e.g., via adding different noise to data samples), have proven useful in enhancing representation learning. Natural views are often handled by multiview analysis tools, e.g., (deep) canonical correlation analysis [(D)CCA], while the artificial ones are frequently used in self-supervised learning (SSL) paradigms, e.g., BYOL and Barlow Twins. Both types of approaches often involve learning neural feature extractors such that the embeddings of data exhibit high cross-view correlations. Although intuitive, the effectiveness of correlation-based neural embedding is mostly empirically validated. This work aims to understand latent correlation maximization-based deep multiview learning from a latent component identification viewpoint. An intuitive generative model of multiview data is adopted, where the views are different nonlinear mixtures of shared and private components. Since the shared components are view/distortion-invariant, representing the data using such components is believed to reveal the identity of the samples effectively and robustly. Under this model, latent correlation maximization is shown to guarantee the extraction of the shared components across views (up to certain ambiguities). In addition, it is further shown that the private information in each view can be provably disentangled from the shared using proper regularization design. A finite sample analysis, which has been rare in nonlinear mixture identifiability study, is also presented. The theoretical results and newly designed regularization are tested on a series of tasks. ",
        "conference": "ICLR",
        "中文标题": "理解基于潜在相关性的多视图学习与自监督：从可识别性角度出发",
        "摘要翻译": "数据的多视图，无论是自然获取的（如图像和音频）还是人工生成的（例如通过向数据样本添加不同的噪声），已被证明在增强表示学习方面非常有用。自然视图通常通过多视图分析工具处理，例如（深度）典型相关分析[(D)CCA]，而人工视图则常用于自监督学习（SSL）范式，如BYOL和Barlow Twins。这两种类型的方法通常涉及学习神经特征提取器，使得数据的嵌入表现出高跨视图相关性。尽管直观，基于相关性的神经嵌入的有效性大多通过经验验证。本研究旨在从潜在组件识别的角度理解基于潜在相关性最大化的深度多视图学习。采用了一个直观的多视图数据生成模型，其中视图是共享和私有组件的不同非线性混合。由于共享组件是视图/失真不变的，使用这些组件表示数据被认为可以有效地和鲁棒地揭示样本的身份。在该模型下，潜在相关性最大化被证明可以保证跨视图提取共享组件（达到某些模糊性）。此外，还进一步表明，通过适当的正则化设计，可以证明每个视图中的私有信息可以从共享信息中解耦。还提出了一个在非线性混合可识别性研究中罕见的有限样本分析。理论结果和新设计的正则化在一系列任务上进行了测试。",
        "领域": "多视图学习, 自监督学习, 表示学习",
        "问题": "如何从潜在组件识别的角度理解和验证基于潜在相关性最大化的深度多视图学习和自监督学习的有效性。",
        "动机": "探索和验证基于潜在相关性最大化的深度多视图学习和自监督学习方法的理论基础，特别是在共享和私有组件识别方面的有效性。",
        "方法": "采用一个直观的多视图数据生成模型，通过潜在相关性最大化提取共享组件，并设计适当的正则化以解耦私有信息，同时进行有限样本分析。",
        "关键词": [
            "多视图学习",
            "自监督学习",
            "潜在相关性",
            "共享组件",
            "正则化设计"
        ],
        "涉及的技术概念": {
            "潜在相关性最大化": "用于跨视图提取共享组件，保证视图间的一致性。",
            "共享和私有组件": "在多视图数据中，共享组件是视图间共有的信息，私有组件是各视图特有的信息。",
            "正则化设计": "用于在特征提取过程中解耦共享和私有信息，提高模型的泛化能力和鲁棒性。"
        },
        "success": true
    },
    {
        "order": 1032,
        "title": "Understanding over-squashing and bottlenecks on graphs via curvature",
        "html": "https://iclr.cc//virtual/2022/poster/6849",
        "abstract": "Most graph neural networks (GNNs) use the message passing paradigm, in which node features are propagated on the input graph. Recent works pointed to the distortion of information flowing from distant nodes as a factor limiting the efficiency of message passing for tasks relying on long-distance interactions. This phenomenon, referred to as 'over-squashing', has been heuristically attributed to graph bottlenecks where the number of $k$-hop neighbors grows rapidly with $k$. We provide a precise description of the over-squashing phenomenon in GNNs and analyze how it arises from bottlenecks in the graph. For this purpose, we introduce a new edge-based combinatorial curvature and prove that negatively curved edges are responsible for the over-squashing issue. We also propose and experimentally test a  curvature-based graph rewiring method to alleviate the over-squashing.",
        "conference": "ICLR",
        "中文标题": "通过曲率理解图上的过度挤压和瓶颈问题",
        "摘要翻译": "大多数图神经网络（GNNs）采用消息传递范式，其中节点特征在输入图上传播。最近的研究指出，信息从远距离节点流动时的扭曲是限制消息传递效率的一个因素，尤其是在依赖长距离交互的任务中。这种现象被称为‘过度挤压’，并启发式地归因于图的瓶颈，即$k$-跳邻居的数量随着$k$迅速增长。我们为GNNs中的过度挤压现象提供了一个精确的描述，并分析了它如何从图的瓶颈中产生。为此，我们引入了一种新的基于边的组合曲率，并证明了负曲率边是导致过度挤压问题的原因。我们还提出并通过实验测试了一种基于曲率的图重连方法，以缓解过度挤压问题。",
        "领域": "图神经网络、图表示学习、图结构优化",
        "问题": "解决图神经网络中因图结构瓶颈导致的过度挤压问题",
        "动机": "研究图神经网络中信息传递效率受限的原因，特别是长距离交互中的信息扭曲问题",
        "方法": "引入基于边的组合曲率分析过度挤压现象，并提出基于曲率的图重连方法",
        "关键词": [
            "图神经网络",
            "过度挤压",
            "组合曲率",
            "图重连",
            "长距离交互"
        ],
        "涉及的技术概念": {
            "消息传递范式": "图神经网络中节点特征传播的基本机制",
            "过度挤压": "图神经网络中因图结构瓶颈导致的信息传递效率下降现象",
            "组合曲率": "用于分析图结构瓶颈和过度挤压现象的新引入的曲率概念"
        },
        "success": true
    },
    {
        "order": 1033,
        "title": "Understanding the Role of Self Attention for Efficient Speech Recognition",
        "html": "https://iclr.cc//virtual/2022/poster/6116",
        "abstract": "Self-attention (SA) is a critical component of Transformer neural networks that have succeeded in automatic speech recognition (ASR). In this paper, we analyze the role of SA in Transformer-based ASR models for not only understanding the mechanism of improved recognition accuracy but also lowering the computational complexity. We reveal that SA performs two distinct roles: phonetic and linguistic localization. Especially, we show by experiments that phonetic localization in the lower layers extracts phonologically meaningful features from speech and reduces the phonetic variance in the utterance for proper linguistic localization in the upper layers. From this understanding, we discover that attention maps can be reused as long as their localization capability is preserved. To evaluate this idea, we implement the layer-wise attention map reuse on real GPU platforms and achieve up to 1.96 times speedup in inference and 33% savings in training time with noticeably improved ASR performance for the challenging benchmark on LibriSpeech dev/test-other dataset.",
        "conference": "ICLR",
        "中文标题": "理解自注意力在高效语音识别中的作用",
        "摘要翻译": "自注意力（SA）是Transformer神经网络中的关键组件，这些网络在自动语音识别（ASR）中取得了成功。在本文中，我们分析了基于Transformer的ASR模型中SA的作用，不仅为了理解提高识别准确性的机制，还为了降低计算复杂度。我们揭示了SA执行两个不同的角色：语音和语言定位。特别是，我们通过实验表明，较低层的语音定位从语音中提取具有语音学意义的特征，并减少话语中的语音变异，以便在上层进行适当的语言定位。基于这一理解，我们发现只要保持其定位能力，注意力图就可以被重用。为了评估这一想法，我们在实际的GPU平台上实现了层间注意力图重用，并在LibriSpeech dev/test-other数据集的挑战性基准测试中实现了推理速度最高1.96倍的提升和训练时间33%的节省，同时显著提高了ASR性能。",
        "领域": "自动语音识别、Transformer模型、语音处理",
        "问题": "分析自注意力在Transformer-based ASR模型中的作用，以提高识别准确性和降低计算复杂度",
        "动机": "理解自注意力机制如何提升ASR性能，并探索降低计算成本的方法",
        "方法": "通过实验分析自注意力的语音和语言定位作用，并实现层间注意力图重用以优化性能",
        "关键词": [
            "自注意力",
            "语音识别",
            "Transformer",
            "计算效率",
            "注意力图重用"
        ],
        "涉及的技术概念": {
            "自注意力": "论文中用于从语音中提取特征并减少语音变异的技术",
            "语音定位": "在较低层中提取具有语音学意义的特征的过程",
            "注意力图重用": "通过重用保持定位能力的注意力图来优化模型性能的技术"
        },
        "success": true
    },
    {
        "order": 1034,
        "title": "Understanding the Variance Collapse of SVGD in High Dimensions",
        "html": "https://iclr.cc//virtual/2022/poster/6835",
        "abstract": "Stein variational gradient descent (SVGD) is a deterministic inference algorithm that evolves a set of particles to fit a target distribution. Despite its computational efficiency, SVGD often underestimates the variance of the target distribution in high dimensions. In this work we attempt to explain the variance collapse in SVGD. On the qualitative side, we compare the SVGD update with gradient descent on the maximum mean discrepancy (MMD) objective; we observe that the variance collapse phenomenon relates to the bias from deterministic updates present in the 'driving force' of SVGD, and empirically verify that removal of such bias leads to more accurate variance estimation. On the quantitative side, we demonstrate that the variance collapse of SVGD can be accurately predicted in the proportional asymptotic limit, i.e., when the number of particles $n$ and dimensions $d$ diverge at the same rate. In particular, for learning high-dimensional isotropic Gaussians, we derive the exact equilibrium variance for both SVGD and MMD-descent under certain near-orthogonality assumption on the converged particles, and confirm that SVGD suffers from the 'curse of dimensionality'.",
        "conference": "ICLR",
        "中文标题": "理解高维空间中SVGD的方差崩溃现象",
        "摘要翻译": "Stein变分梯度下降（SVGD）是一种确定性推理算法，通过演化一组粒子来拟合目标分布。尽管SVGD在计算上效率高，但在高维空间中常常低估目标分布的方差。在本工作中，我们试图解释SVGD中的方差崩溃现象。在定性方面，我们将SVGD更新与最大均值差异（MMD）目标上的梯度下降进行比较；我们观察到方差崩溃现象与SVGD'驱动力'中确定性更新带来的偏差有关，并通过实验验证去除这种偏差可以更准确地估计方差。在定量方面，我们证明了SVGD的方差崩溃可以在比例渐近极限下准确预测，即当粒子数n和维度d以相同速率发散时。特别是，对于学习高维各向同性高斯分布，我们在收敛粒子满足某种近正交性假设下，推导出SVGD和MMD下降的确切平衡方差，并确认SVGD遭受'维度诅咒'。",
        "领域": "变分推理、高维统计、概率机器学习",
        "问题": "SVGD在高维空间中低估目标分布方差的问题",
        "动机": "解释SVGD在高维空间中方差崩溃的原因，并提出改进方法",
        "方法": "定性比较SVGD与MMD梯度下降的更新过程，定量分析在比例渐近极限下的方差预测",
        "关键词": [
            "Stein变分梯度下降",
            "方差崩溃",
            "高维统计",
            "最大均值差异",
            "维度诅咒"
        ],
        "涉及的技术概念": {
            "Stein变分梯度下降（SVGD）": "一种确定性推理算法，用于通过粒子演化拟合目标分布",
            "最大均值差异（MMD）": "用于衡量两个分布之间差异的度量，SVGD更新与之相关",
            "维度诅咒": "指在高维空间中，算法性能随维度增加而急剧下降的现象"
        },
        "success": true
    },
    {
        "order": 1035,
        "title": "Unified Visual Transformer Compression",
        "html": "https://iclr.cc//virtual/2022/poster/6958",
        "abstract": "Vision transformers (ViTs) have gained popularity recently. Even without customized image operators such as convolutions, ViTs can yield competitive performance when properly trained on massive data. However, the computational overhead of ViTs remains prohibitive, due to stacking multi-head self-attention modules and else. Compared to the vast literature and prevailing success in compressing convolutional neural networks, the study of Vision Transformer compression has also just emerged, and existing works focused on one or two aspects of compression. This paper proposes a unified ViT compression framework that seamlessly assembles three effective techniques: pruning, layer skipping, and knowledge distillation. We formulate a budget-constrained, end-to-end optimization framework, targeting jointly learning model weights, layer-wise pruning ratios/masks, and skip configurations, under a distillation loss. The optimization problem is then solved using the primal-dual algorithm. Experiments are conducted with several ViT variants, e.g. DeiT and T2T-ViT backbones on the ImageNet dataset, and our approach consistently outperforms recent competitors. For example, DeiT-Tiny can be trimmed down to 50\\% of the original FLOPs almost without losing accuracy. Codes are available online:~\\url{https://github.com/VITA-Group/UVC}.",
        "conference": "ICLR",
        "中文标题": "统一的视觉Transformer压缩",
        "摘要翻译": "视觉Transformer（ViTs）近年来变得流行。即使没有像卷积这样的定制图像操作符，ViTs在大规模数据上经过适当训练后也能表现出竞争性的性能。然而，由于堆叠多头自注意力模块等原因，ViTs的计算开销仍然令人望而却步。与压缩卷积神经网络的大量文献和普遍成功相比，视觉Transformer压缩的研究也刚刚兴起，现有工作集中于压缩的一两个方面。本文提出了一个统一的ViT压缩框架，无缝集成了三种有效技术：剪枝、层跳过和知识蒸馏。我们制定了一个预算约束的端到端优化框架，目标是在蒸馏损失下联合学习模型权重、层间剪枝比率/掩码和跳过配置。然后使用原始对偶算法解决优化问题。实验使用了几种ViT变体，例如在ImageNet数据集上的DeiT和T2T-ViT骨干网络，我们的方法始终优于最近的竞争对手。例如，DeiT-Tiny可以被修剪到原始FLOPs的50%，几乎不损失准确性。代码可在网上获取：https://github.com/VITA-Group/UVC。",
        "领域": "模型压缩",
        "问题": "视觉Transformer模型的计算开销过大",
        "动机": "减少视觉Transformer模型的计算开销，同时保持其性能",
        "方法": "提出一个统一的ViT压缩框架，集成剪枝、层跳过和知识蒸馏三种技术，通过预算约束的端到端优化框架联合学习模型权重、剪枝比率/掩码和跳过配置",
        "关键词": [
            "视觉Transformer",
            "模型压缩",
            "知识蒸馏",
            "剪枝",
            "层跳过"
        ],
        "涉及的技术概念": {
            "剪枝": "减少模型参数数量，降低计算复杂度",
            "层跳过": "在模型推理过程中跳过某些层的计算，减少计算量",
            "知识蒸馏": "通过训练一个小模型（学生模型）来模仿一个大模型（教师模型）的行为，以保持性能同时减少模型大小和计算量"
        },
        "success": true
    },
    {
        "order": 1036,
        "title": "UniFormer: Unified Transformer for Efficient Spatial-Temporal Representation Learning",
        "html": "https://iclr.cc//virtual/2022/poster/5991",
        "abstract": "It is a challenging task to learn rich and multi-scale spatiotemporal semantics from high-dimensional videos, due to large local redundancy and complex global dependency between video frames. The recent advances in this research have been mainly driven by 3D convolutional neural networks and vision transformers. Although 3D convolution can efficiently aggregate local context to suppress local redundancy from a small 3D neighborhood, it lacks the capability to capture global dependency because of the limited receptive field. Alternatively, vision transformers can effectively capture long-range dependency by self-attention mechanism, while having the limitation on reducing local redundancy with blind similarity comparison among all the tokens in each layer. Based on these observations, we propose a novel Unified transFormer (UniFormer) which seamlessly integrates merits of 3D convolution and spatiotemporal self-attention in a concise transformer format, and achieves a preferable balance between computation and accuracy. Different from traditional transformers, our relation aggregator can tackle both spatiotemporal redundancy and dependency, by learning local and global token affinity respectively in shallow and deep layers. We conduct extensive experiments on the popular video benchmarks, e.g., Kinetics-400, Kinetics-600, and Something-Something V1&V2. With only ImageNet-1K pretraining, our UniFormer achieves 82.9%/84.8% top-1 accuracy on Kinetics-400/Kinetics-600, while requiring 10x fewer GFLOPs than other state-of-the-art methods. For Something-Something V1 and V2, our UniFormer achieves new state-of-the-art performances of 60.9% and 71.2% top-1 accuracy respectively. Code is available at https://github.com/Sense-X/UniFormer.",
        "conference": "ICLR",
        "中文标题": "UniFormer：用于高效时空表示学习的统一Transformer",
        "摘要翻译": "从高维视频中学习丰富且多尺度的时空语义是一项具有挑战性的任务，这主要是由于视频帧之间存在大量的局部冗余和复杂的全局依赖性。这一研究领域的最新进展主要由3D卷积神经网络和视觉Transformer驱动。尽管3D卷积可以有效地聚合局部上下文以抑制来自小3D邻域的局部冗余，但由于有限的感受野，它缺乏捕捉全局依赖性的能力。另一方面，视觉Transformer通过自注意力机制可以有效捕捉长距离依赖性，但在减少局部冗余方面存在局限，因为它在每一层中对所有令牌进行盲目的相似性比较。基于这些观察，我们提出了一种新颖的统一Transformer（UniFormer），它以简洁的Transformer格式无缝集成了3D卷积和时空自注意力的优点，并在计算和准确性之间实现了更优的平衡。不同于传统的Transformer，我们的关系聚合器通过学习浅层和深层中的局部和全局令牌亲和力，能够同时处理时空冗余和依赖性。我们在流行的视频基准测试上进行了广泛的实验，例如Kinetics-400、Kinetics-600和Something-Something V1&V2。仅使用ImageNet-1K预训练，我们的UniFormer在Kinetics-400/Kinetics-600上达到了82.9%/84.8%的top-1准确率，同时所需的GFLOPs比其他最先进方法少10倍。对于Something-Something V1和V2，我们的UniFormer分别达到了60.9%和71.2%的top-1准确率，创造了新的最先进性能。代码可在https://github.com/Sense-X/UniFormer获取。",
        "领域": "视频理解、时空表示学习、视觉Transformer",
        "问题": "如何高效地从高维视频中学习丰富且多尺度的时空语义，同时处理局部冗余和全局依赖性问题",
        "动机": "现有的3D卷积神经网络和视觉Transformer在处理视频时空语义时各有局限，3D卷积难以捕捉全局依赖，而视觉Transformer在减少局部冗余方面效率不高",
        "方法": "提出了一种统一Transformer（UniFormer），结合3D卷积和时空自注意力的优点，通过学习浅层和深层中的局部和全局令牌亲和力，有效处理时空冗余和依赖性",
        "关键词": [
            "UniFormer",
            "时空表示学习",
            "视觉Transformer",
            "3D卷积",
            "自注意力机制"
        ],
        "涉及的技术概念": {
            "3D卷积": "用于聚合局部上下文以抑制局部冗余，但在捕捉全局依赖性方面有限",
            "时空自注意力": "通过自注意力机制捕捉长距离依赖性，但在减少局部冗余方面效率不高",
            "关系聚合器": "UniFormer中的核心组件，通过学习局部和全局令牌亲和力，有效处理时空冗余和依赖性"
        },
        "success": true
    },
    {
        "order": 1037,
        "title": "Unifying Likelihood-free Inference with Black-box Optimization and Beyond",
        "html": "https://iclr.cc//virtual/2022/poster/6503",
        "abstract": "Black-box optimization formulations for biological sequence design have drawn recent attention due to their promising potential impact on the pharmaceutical industry. In this work, we propose to unify two seemingly distinct worlds: likelihood-free inference and black-box optimization, under one probabilistic framework. In tandem, we provide a recipe for constructing various sequence design methods based on this framework. We show how previous optimization approaches can be 'reinvented' in our framework, and further propose new probabilistic black-box optimization algorithms. Extensive experiments on sequence design application illustrate the benefits of the proposed methodology.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "统一无似然推断与黑盒优化及其超越",
        "摘要翻译": "生物序列设计的黑盒优化公式由于其在制药行业中潜在的巨大影响而引起了近期的关注。在这项工作中，我们提出将两个看似截然不同的领域：无似然推断和黑盒优化，统一在一个概率框架下。同时，我们提供了基于这一框架构建各种序列设计方法的方案。我们展示了如何在我们框架中‘重新发明’先前的优化方法，并进一步提出了新的概率黑盒优化算法。在序列设计应用上的大量实验证明了所提出方法的好处。",
        "领域": "生物序列设计、概率模型、优化算法",
        "问题": "如何将无似然推断和黑盒优化统一在一个概率框架下，以促进生物序列设计。",
        "动机": "鉴于黑盒优化在生物序列设计中的潜在巨大影响，研究旨在统一无似然推断与黑盒优化，以提供更高效的序列设计方法。",
        "方法": "提出一个统一的概率框架，将无似然推断和黑盒优化结合起来，并基于此框架开发新的序列设计方法和优化算法。",
        "关键词": [
            "生物序列设计",
            "无似然推断",
            "黑盒优化",
            "概率框架",
            "优化算法"
        ],
        "涉及的技术概念": {
            "无似然推断": "在缺乏明确似然函数的情况下进行统计推断的方法，本文中用于统一框架的一部分。",
            "黑盒优化": "不依赖于目标函数内部信息的优化方法，本文中用于序列设计的优化。",
            "概率框架": "提供一个统一的数学结构，用于结合无似然推断和黑盒优化，支持新算法的开发。"
        }
    },
    {
        "order": 1038,
        "title": "Universal Approximation Under Constraints is Possible with Transformers",
        "html": "https://iclr.cc//virtual/2022/poster/6477",
        "abstract": "Many practical problems need the output of a machine learning model to satisfy a set of constraints, $K$.  Nevertheless, there is no known guarantee that classical neural network architectures can exactly encode constraints while simultaneously achieving universality.  We provide a quantitative constrained universal approximation theorem which guarantees that for any non-convex compact set $K$ and any continuous function $f:\\mathbb{R}^n\\rightarrow K$, there is a probabilistic transformer $\\hat{F}$ whose randomized outputs all lie in $K$ and whose expected output uniformly approximates $f$.  Our second main result is a ``deep neural version'' of Berge's Maximum Theorem (1963).  The result guarantees that given an objective function $L$, a constraint set $K$, and a family of soft constraint sets, there is a probabilistic transformer $\\hat{F}$ that approximately minimizes $L$ and whose outputs belong to $K$; moreover, $\\hat{F}$ approximately satisfies the soft constraints.  Our results imply the first universal approximation theorem for classical transformers with exact convex constraint satisfaction.  They also yield that a chart-free universal approximation theorem for Riemannian manifold-valued functions subject to suitable geodesically convex constraints.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "约束下的通用逼近可以通过Transformer实现",
        "摘要翻译": "许多实际问题需要机器学习模型的输出满足一组约束条件 K。然而，目前还没有已知的保证表明经典的神经网络架构可以在实现通用性的同时精确地编码约束。我们提供了一个定量的约束通用逼近定理，该定理保证对于任何非凸紧集 K 和任何连续函数 f:R^n→K，都存在一个概率 Transformer F̂，其随机输出都位于 K 中，并且其期望输出一致地逼近 f。我们的第二个主要结果是 Berge 最大定理（1963）的“深度神经网络版本”。该结果保证，给定一个目标函数 L、一个约束集 K 和一系列软约束集，存在一个概率 Transformer F̂，它近似地最小化 L 并且其输出属于 K；此外，F̂ 近似地满足软约束。我们的结果意味着第一个具有精确凸约束满足的经典 Transformer 的通用逼近定理。它们也产生了一个无图表的黎曼流形值函数的通用逼近定理，该定理受制于合适的测地凸约束。",
        "领域": "Transformer, 约束优化, 概率建模",
        "问题": "经典的神经网络架构无法保证在满足约束条件的同时实现通用逼近，而实际问题中模型输出往往需要满足某些约束。",
        "动机": "解决在满足特定约束条件下，机器学习模型如何实现通用逼近的问题，使模型输出更符合实际应用的需求。",
        "方法": "提出了一个定量的约束通用逼近定理，并基于概率Transformer架构，证明了在非凸紧集约束下，可以实现对连续函数的通用逼近。同时，提出了Berge最大定理的深度神经网络版本，用于处理带有软约束的优化问题。",
        "关键词": [
            "Transformer",
            "约束优化",
            "通用逼近",
            "概率模型",
            "深度神经网络"
        ],
        "涉及的技术概念": {
            "Transformer": "一种基于自注意力机制的神经网络架构，用于学习输入序列的表示，并在各种任务中取得了显著成果。本文中使用Transformer作为基础模型，并对其进行改进以满足约束条件。",
            "约束优化": "在优化问题中，寻找满足特定约束条件的最优解的过程。本文关注的是模型输出需要满足一组约束的场景，并提出了相应的解决方案。"
        }
    },
    {
        "order": 1039,
        "title": "Universalizing Weak Supervision",
        "html": "https://iclr.cc//virtual/2022/poster/7091",
        "abstract": "Weak supervision (WS) frameworks are a popular way to bypass hand-labeling large datasets for training data-hungry models.These approaches synthesize multiple noisy but cheaply-acquired estimates of labels into a set of high-quality pseudo-labels for downstream training. However, the synthesis technique is specific to a particular kind of label, such as binary labels or sequences, and each new label type requires manually designing a new synthesis algorithm. Instead, we propose a universal technique that enables weak supervision over any label type while still offering desirable properties, including practical flexibility, computational efficiency, and theoretical guarantees. We apply this technique to important problems previously not tackled by WS frameworks including learning to rank, regression, and learning in hyperbolic space. Theoretically, our synthesis approach produces a consistent estimators for learning some challenging but important generalizations of the exponential family model. Experimentally, we validate our framework and show improvement over baselines in diverse settings including real-world learning-to-rank and regression problems along with learning on hyperbolic manifolds.",
        "conference": "ICLR",
        "中文标题": "通用化弱监督",
        "摘要翻译": "弱监督（WS）框架是一种流行的方式，用于绕过手工标记大型数据集以训练数据饥渴模型。这些方法将多个噪声大但获取成本低的标签估计合成为一组高质量伪标签，用于下游训练。然而，合成技术特定于特定类型的标签，如二进制标签或序列，每种新标签类型都需要手动设计新的合成算法。相反，我们提出了一种通用技术，使得弱监督可以应用于任何标签类型，同时仍提供理想的特性，包括实际灵活性、计算效率和理论保证。我们将此技术应用于以前WS框架未解决的重要问题，包括学习排序、回归和在双曲空间中的学习。理论上，我们的合成方法为学习指数族模型的一些具有挑战性但重要的泛化产生了一致的估计量。实验上，我们验证了我们的框架，并在包括现实世界学习排序和回归问题以及在双曲流形上的学习在内的多样化设置中展示了相对于基线的改进。",
        "领域": "弱监督学习、学习排序、回归分析",
        "问题": "解决弱监督框架中合成技术特定于特定标签类型，无法通用化的问题。",
        "动机": "为了扩展弱监督技术的应用范围，使其能够适用于任何标签类型，同时保持灵活性、效率和理论保证。",
        "方法": "提出了一种通用技术，支持对任何标签类型的弱监督，应用于学习排序、回归和在双曲空间中的学习。",
        "关键词": [
            "弱监督学习",
            "通用技术",
            "学习排序",
            "回归分析",
            "双曲空间学习"
        ],
        "涉及的技术概念": {
            "弱监督学习": "一种通过合成多个噪声标签估计来生成高质量伪标签的技术，用于训练数据饥渴模型。",
            "通用技术": "提出的方法，使得弱监督可以应用于任何标签类型，而不需要为每种新标签类型手动设计合成算法。",
            "双曲空间学习": "在双曲流形上进行的学习任务，这是WS框架之前未解决的重要问题之一。"
        },
        "success": true
    },
    {
        "order": 1040,
        "title": "Unraveling Model-Agnostic Meta-Learning via The Adaptation Learning Rate",
        "html": "https://iclr.cc//virtual/2022/poster/6474",
        "abstract": "Model-Agnostic Meta-Learning (MAML) aims to find initial weights that allow fast adaptation to new tasks. The adaptation (inner loop) learning rate in MAML plays a central role in enabling such fast adaptation. However, how to choose this value in practice and how this choice affects the adaptation error remains less explored. In this paper, we study the effect of the adaptation learning rate in meta-learning with mixed linear regression. First, we present a principled way to estimate optimal adaptation learning rates that minimize the population risk of MAML. Second, we interpret the underlying dependence between the optimal adaptation learning rate and the input data. Finally, we prove that compared with empirical risk minimization (ERM), MAML produces an initialization with a smaller average distance to the task optima, consistent with previous practical findings. These results are corroborated with numerical experiments.",
        "conference": "ICLR",
        "中文标题": "通过适应学习率解析模型无关元学习",
        "摘要翻译": "模型无关元学习（MAML）旨在找到能够快速适应新任务的初始权重。MAML中的适应（内循环）学习率在实现这种快速适应中起着核心作用。然而，在实践中如何选择这个值以及这个选择如何影响适应误差仍然较少被探索。在本文中，我们研究了在混合线性回归的元学习中适应学习率的影响。首先，我们提出了一种原则性的方法来估计最小化MAML群体风险的最优适应学习率。其次，我们解释了最优适应学习率与输入数据之间的潜在依赖关系。最后，我们证明，与经验风险最小化（ERM）相比，MAML产生的初始化与任务最优解的平均距离更小，这与之前的实际发现一致。这些结果通过数值实验得到了证实。",
        "领域": "元学习、深度学习优化、自适应学习",
        "问题": "如何选择和优化模型无关元学习（MAML）中的适应学习率，以及这一选择如何影响模型的适应性能。",
        "动机": "探索适应学习率在MAML中的作用，提供理论支持和实践指导，以优化元学习模型的性能。",
        "方法": "通过混合线性回归模型研究适应学习率的影响，提出估计最优适应学习率的方法，分析学习率与输入数据的关系，并通过实验验证MAML在初始化上的优势。",
        "关键词": [
            "模型无关元学习",
            "适应学习率",
            "混合线性回归",
            "群体风险",
            "任务最优解"
        ],
        "涉及的技术概念": {
            "模型无关元学习（MAML）": "一种元学习方法，旨在通过找到能够快速适应新任务的初始权重来提高学习效率。",
            "适应学习率": "MAML内循环中用于调整模型权重以适应新任务的学习率，对模型的适应速度和性能有重要影响。",
            "群体风险": "在MAML中，指模型在所有可能任务上的预期风险，最优适应学习率的选择旨在最小化这一风险。"
        },
        "success": true
    },
    {
        "order": 1041,
        "title": "Unrolling PALM for Sparse Semi-Blind Source Separation",
        "html": "https://iclr.cc//virtual/2022/poster/6592",
        "abstract": "Sparse  Blind  Source  Separation  (BSS)  has  become  a  well  established  tool  for a  wide  range  of  applications  –  for  instance,  in  astrophysics  and  remote  sensing.  Classical sparse BSS methods, such as the Proximal Alternating Linearized Minimization (PALM) algorithm, nevertheless often suffer from a difficult hyper-parameter choice, which undermines their results.  To bypass this pitfall, we propose in this work to build on the thriving field of algorithm unfolding/unrolling. Unrolling PALM enables to leverage the data-driven knowledge stemming from realistic simulations or ground-truth data by learning both PALM hyper-parameters and variables.  In contrast to most existing unrolled algorithms, which assume a fixed known dictionary during the training and testing phases, this article further emphasizes on the ability to deal with variable mixing matrices (a.k.a.  dictionaries).  The proposed Learned PALM (LPALM) algorithm thus enables to perform semi-blind source separation, which is key to increase the generalization of the learnt model in real-world applications. We illustrate the relevance of LPALM in astrophysical multispectral imaging: the algorithm not only needs up to $10^4−10^5$ times less iterations than PALM, but also improves the separation quality, while avoiding the cumbersome hyper-parameter and initialization choice of PALM. We further show that LPALM outperforms other unrolled source separation methods in the semi-blind setting.",
        "conference": "ICLR",
        "中文标题": "展开PALM算法用于稀疏半盲源分离",
        "摘要翻译": "稀疏盲源分离（BSS）已成为广泛应用于天体物理学和遥感等多个领域的强大工具。然而，诸如近端交替线性化最小化（PALM）算法等经典稀疏BSS方法，常常因为难以选择的超参数而影响其结果。为了绕过这一陷阱，我们在这项工作中提出基于算法展开/解开的蓬勃发展的领域。通过展开PALM，能够通过学习PALM的超参数和变量，利用来自现实模拟或地面真实数据的数据驱动知识。与大多数现有的展开算法不同，这些算法在训练和测试阶段假设一个固定的已知字典，本文进一步强调了处理可变混合矩阵（又称字典）的能力。因此，提出的学习型PALM（LPALM）算法能够执行半盲源分离，这对于提高学习模型在现实应用中的泛化能力至关重要。我们在天体物理多光谱成像中说明了LPALM的相关性：该算法不仅比PALM需要少10^4−10^5倍的迭代次数，而且还提高了分离质量，同时避免了PALM繁琐的超参数和初始化选择。我们进一步表明，在半盲设置中，LPALM优于其他展开的源分离方法。",
        "领域": "稀疏信号处理, 盲源分离, 多光谱成像",
        "问题": "解决稀疏盲源分离中超参数选择困难的问题",
        "动机": "通过数据驱动的方法优化PALM算法的超参数和变量选择，提高分离质量和算法效率",
        "方法": "采用算法展开技术，学习PALM的超参数和变量，处理可变混合矩阵，实现半盲源分离",
        "关键词": [
            "稀疏盲源分离",
            "算法展开",
            "半盲源分离",
            "多光谱成像",
            "PALM算法"
        ],
        "涉及的技术概念": {
            "算法展开/解开": "一种将迭代算法转换为可学习网络结构的技术，用于优化算法参数和提高性能",
            "半盲源分离": "在源分离问题中，部分混合矩阵或源信号已知的情况下进行的分离，提高模型的泛化能力",
            "近端交替线性化最小化（PALM）算法": "一种用于解决非凸、非光滑优化问题的迭代算法，广泛应用于稀疏信号处理和盲源分离"
        },
        "success": true
    },
    {
        "order": 1042,
        "title": "Unsupervised Discovery of Object Radiance Fields",
        "html": "https://iclr.cc//virtual/2022/poster/6279",
        "abstract": "We study the problem of inferring an object-centric scene representation from a single image, aiming to derive a representation that explains the image formation process, captures the scene's 3D nature, and is learned without supervision. Most existing methods on scene decomposition lack one or more of these characteristics, due to the fundamental challenge in integrating the complex 3D-to-2D image formation process into powerful inference schemes like deep networks. In this paper, we propose unsupervised discovery of Object Radiance Fields (uORF), integrating recent progresses in neural 3D scene representations and rendering with deep inference networks for unsupervised 3D scene decomposition. Trained on multi-view RGB images without annotations, uORF learns to decompose complex scenes with diverse, textured background from a single image. We show that uORF enables novel tasks, such as scene segmentation and editing in 3D, and it performs well on these tasks and on novel view synthesis on three datasets.",
        "conference": "ICLR",
        "中文标题": "无监督发现物体辐射场",
        "摘要翻译": "我们研究了从单张图像推断以物体为中心的场景表示的问题，旨在推导出一种能够解释图像形成过程、捕捉场景3D特性且无需监督学习的表示方法。大多数现有的场景分解方法由于在将复杂的3D到2D图像形成过程整合到如深度网络这样的强大推理方案中存在根本性挑战，而缺乏上述一个或多个特性。在本文中，我们提出了无监督发现物体辐射场（uORF），将神经3D场景表示和渲染的最新进展与深度推理网络相结合，用于无监督3D场景分解。uORF在无需标注的多视角RGB图像上训练，能够从单张图像中学习分解具有多样化纹理背景的复杂场景。我们展示了uORF能够实现新颖的任务，如3D场景分割和编辑，并且在这些任务以及三个数据集上的新视角合成任务中表现良好。",
        "领域": "3D场景理解、神经渲染、无监督学习",
        "问题": "如何从单张图像无监督地推断出解释图像形成过程并捕捉场景3D特性的物体中心表示",
        "动机": "现有场景分解方法难以同时解释图像形成过程、捕捉3D特性且无需监督学习",
        "方法": "结合神经3D场景表示、渲染技术和深度推理网络，提出无监督物体辐射场（uORF）方法",
        "关键词": [
            "无监督学习",
            "神经渲染",
            "3D场景分解",
            "物体辐射场",
            "场景编辑"
        ],
        "涉及的技术概念": {
            "物体辐射场": "用于表示和渲染3D场景中的物体，支持无监督场景分解",
            "神经渲染": "通过神经网络实现从3D场景到2D图像的渲染过程，支持高质量新视角合成",
            "无监督学习": "无需标注数据，直接从多视角图像中学习场景的3D结构和外观"
        },
        "success": true
    },
    {
        "order": 1043,
        "title": "Unsupervised Disentanglement with Tensor Product Representations on the Torus",
        "html": "https://iclr.cc//virtual/2022/poster/5949",
        "abstract": "The current methods for learning representations with auto-encoders almost exclusively employ vectors as the latent representations.  In this work, we propose to employ a tensor product structure for this purpose. This way, the obtained representations are naturally disentangled. In contrast to the conventional variations methods, which are targeted toward normally distributed features, the latent space in our representation is distributed uniformly over a set of unit circles. We argue that the torus structure of the latent space captures the generative factors effectively. We employ recent tools for measuring unsupervised disentanglement, and in an extensive set of experiments demonstrate the advantage of our method in terms of disentanglement, completeness, and informativeness. The code for our proposed method is available at https://github.com/rotmanmi/Unsupervised-Disentanglement-Torus.",
        "conference": "ICLR",
        "中文标题": "基于环面张量积表示的无监督解缠",
        "摘要翻译": "当前使用自动编码器学习表示的方法几乎无一例外地采用向量作为潜在表示。在这项工作中，我们提出为此目的采用张量积结构。这样，所获得的表示自然解缠。与针对正态分布特征的传统变分方法不同，我们的表示中的潜在空间在一组单位圆上均匀分布。我们认为潜在空间的环面结构有效地捕捉了生成因素。我们采用了最新的工具来测量无监督解缠，并在大量实验中证明了我们的方法在解缠、完整性和信息性方面的优势。我们提出的方法的代码可在https://github.com/rotmanmi/Unsupervised-Disentanglement-Torus获取。",
        "领域": "无监督学习、表示学习、生成模型",
        "问题": "如何更有效地在无监督条件下学习解缠的表示",
        "动机": "探索超越传统向量潜在表示的方法，以提高表示的解缠性、完整性和信息性",
        "方法": "采用张量积结构作为潜在表示，利用环面结构捕捉生成因素，并通过实验验证其有效性",
        "关键词": [
            "无监督解缠",
            "张量积表示",
            "环面结构",
            "自动编码器",
            "生成模型"
        ],
        "涉及的技术概念": {
            "张量积表示": "用于构建潜在表示的结构，促进表示的自然解缠",
            "环面结构": "潜在空间的几何结构，有助于均匀分布和有效捕捉生成因素",
            "无监督解缠": "无需监督信号即可分离数据中的独立变化因素的技术"
        },
        "success": true
    },
    {
        "order": 1044,
        "title": "Unsupervised Learning of Full-Waveform Inversion: Connecting CNN and Partial Differential Equation in a Loop",
        "html": "https://iclr.cc//virtual/2022/poster/6618",
        "abstract": "This paper investigates unsupervised learning of Full-Waveform Inversion (FWI), which has been widely used in geophysics to estimate subsurface velocity maps from seismic data. This problem is mathematically formulated by a second order partial differential equation (PDE), but is hard to solve. Moreover, acquiring velocity map is extremely expensive, making it impractical to scale up a supervised approach to train the mapping from seismic data to velocity maps with convolutional neural networks (CNN).We address these difficulties by $\\textit{integrating PDE and CNN in a loop}$, thus shifting the paradigm to unsupervised learning that only requires seismic data. In particular, we use finite difference to approximate the forward modeling of PDE as a differentiable operator (from velocity map to seismic data) and model its inversion by CNN (from seismic data to velocity map). Hence, we transform the supervised inversion task into an unsupervised seismic data reconstruction task. We also introduce a new large-scale dataset $\\textit{OpenFWI}$, to establish a more challenging benchmark for the community. Experiment results show that our model (using seismic data alone) yields comparable accuracy to the supervised counterpart (using both seismic data and velocity map). Furthermore, it outperforms the supervised model when involving more seismic data.",
        "conference": "ICLR",
        "中文标题": "全波形反演的无监督学习：在循环中连接CNN与偏微分方程",
        "摘要翻译": "本文研究了全波形反演（FWI）的无监督学习，该方法在地球物理学中被广泛用于从地震数据估计地下速度图。这一问题在数学上由二阶偏微分方程（PDE）表述，但难以求解。此外，获取速度图极其昂贵，使得使用卷积神经网络（CNN）训练从地震数据到速度图的监督学习方法难以规模化。我们通过将PDE和CNN在循环中集成来解决这些困难，从而将范式转向仅需地震数据的无监督学习。具体而言，我们使用有限差分来近似PDE的正向建模作为一个可微分算子（从速度图到地震数据），并通过CNN建模其反演（从地震数据到速度图）。因此，我们将监督反演任务转化为无监督地震数据重建任务。我们还引入了一个新的大规模数据集OpenFWI，为社区建立一个更具挑战性的基准。实验结果表明，我们的模型（仅使用地震数据）达到了与监督对应模型（使用地震数据和速度图）相当的准确性。此外，当涉及更多地地震数据时，它优于监督模型。",
        "领域": "地震数据处理、无监督学习、偏微分方程求解",
        "问题": "解决从地震数据估计地下速度图的高成本和难以规模化的问题",
        "动机": "由于获取地下速度图的成本高昂，传统的监督学习方法难以规模化，因此转向无监督学习以降低成本和复杂性",
        "方法": "通过将偏微分方程的正向建模和卷积神经网络的反演建模集成在一个循环中，实现仅需地震数据的无监督学习",
        "关键词": [
            "全波形反演",
            "无监督学习",
            "卷积神经网络",
            "偏微分方程",
            "地震数据重建"
        ],
        "涉及的技术概念": {
            "全波形反演（FWI）": "用于从地震数据估计地下速度图的技术，本文通过无监督学习方法改进其效率和可扩展性",
            "卷积神经网络（CNN）": "用于建模从地震数据到速度图的反演过程，是实现无监督学习的核心技术",
            "偏微分方程（PDE）": "描述地震波传播的数学模型，本文通过有限差分方法近似其正向建模，作为可微分算子集成到学习循环中"
        },
        "success": true
    },
    {
        "order": 1045,
        "title": "Unsupervised Semantic Segmentation by Distilling Feature Correspondences",
        "html": "https://iclr.cc//virtual/2022/poster/6068",
        "abstract": "Unsupervised semantic segmentation aims to discover and localize semantically meaningful categories within image corpora without any form of annotation. To solve this task, algorithms must produce features for every pixel that are both semantically meaningful and compact enough to form distinct clusters. Unlike previous works which achieve this with a single end-to-end framework, we propose to separate feature learning from cluster compactification. Empirically, we show that current unsupervised feature learning frameworks already generate dense features whose correlations are semantically consistent. This observation motivates us to design STEGO ($\\textbf{S}$elf-supervised $\\textbf{T}$ransformer with $\\textbf{E}$nergy-based $\\textbf{G}$raph $\\textbf{O}$ptimization), a novel framework that distills unsupervised features into high-quality discrete semantic labels. At the core of STEGO is a novel contrastive loss function that encourages features to form compact clusters while preserving their association pattern. STEGO yields a significant improvement over the prior state of the art, on both the CocoStuff ($\\textbf{+14 mIoU}$) and Cityscapes ($\\textbf{+9 mIoU}$) semantic segmentation challenges.  ",
        "conference": "ICLR",
        "中文标题": "通过蒸馏特征对应实现无监督语义分割",
        "摘要翻译": "无监督语义分割旨在无需任何形式的标注的情况下，发现并定位图像库中具有语义意义的类别。为了解决这一任务，算法必须为每个像素生成既具有语义意义又足够紧凑以形成不同聚类的特征。与之前通过单一端到端框架实现这一目标的工作不同，我们提出将特征学习与聚类紧凑化分离。实证上，我们展示了当前的无监督特征学习框架已经生成了密集特征，这些特征的相关性在语义上是一致的。这一观察促使我们设计了STEGO（基于能量的图优化的自监督变压器），这是一个新颖的框架，将无监督特征蒸馏成高质量的离散语义标签。STEGO的核心是一个新颖的对比损失函数，它鼓励特征形成紧凑的聚类，同时保留它们的关联模式。STEGO在CocoStuff（+14 mIoU）和Cityscapes（+9 mIoU）语义分割挑战上相比之前的最先进技术有显著提升。",
        "领域": "语义分割、无监督学习、特征学习",
        "问题": "如何在无监督的情况下实现高质量的语义分割",
        "动机": "现有的无监督特征学习框架已经能够生成语义一致的特征，但如何将这些特征有效地转化为高质量的语义标签仍是一个挑战",
        "方法": "提出STEGO框架，通过分离特征学习和聚类紧凑化，并设计新的对比损失函数来优化特征聚类",
        "关键词": [
            "无监督语义分割",
            "特征蒸馏",
            "对比损失",
            "STEGO",
            "聚类紧凑化"
        ],
        "涉及的技术概念": {
            "无监督特征学习": "在无需标注的情况下学习图像特征，为语义分割提供基础",
            "对比损失函数": "用于优化特征，使其形成紧凑的聚类同时保持语义关联",
            "STEGO框架": "结合自监督变压器和基于能量的图优化，将无监督特征转化为高质量的语义标签"
        },
        "success": true
    },
    {
        "order": 1046,
        "title": "Unsupervised Vision-Language Grammar Induction with Shared Structure Modeling",
        "html": "https://iclr.cc//virtual/2022/poster/6110",
        "abstract": "We introduce a new task, unsupervised vision-language (VL) grammar induction. Given an image-caption pair, the goal is to extract a shared hierarchical structure for both image and language simultaneously.  We argue that such structured output, grounded in both modalities, is a clear step towards the high-level understanding of multimodal information. Besides challenges existing in conventional visually grounded grammar induction tasks, VL grammar induction requires a model to capture contextual semantics and perform a fine-grained alignment. To address these challenges, we propose a novel method, CLIORA, which constructs a shared vision-language constituency tree structure with context-dependent semantics for all possible phrases in different levels of the tree. It computes a matching score between each constituent and image region, trained via contrastive learning.  It integrates two levels of fusion, namely at feature-level and at score-level, so as to allow fine-grained alignment. We introduce a new evaluation metric for VL grammar induction, CCRA, and show a 3.3% improvement over a strong baseline on Flickr30k Entities. We also evaluate our model via two derived tasks, i.e., language grammar induction and phrase grounding, and improve over the state-of-the-art for both.",
        "conference": "ICLR",
        "中文标题": "无监督视觉语言语法归纳与共享结构建模",
        "摘要翻译": "我们引入了一个新任务，无监督视觉语言（VL）语法归纳。给定一个图像-标题对，目标是同时为图像和语言提取一个共享的层次结构。我们认为，这种基于两种模态的结构化输出，是向多模态信息高级理解迈出的明确一步。除了传统视觉基础语法归纳任务中存在的挑战外，VL语法归纳需要一个模型来捕捉上下文语义并执行细粒度对齐。为了应对这些挑战，我们提出了一种新方法CLIORA，它构建了一个共享的视觉语言成分树结构，为树的不同层次中的所有可能短语提供上下文依赖的语义。它通过对比学习训练，计算每个成分与图像区域之间的匹配分数。它集成了两个层次的融合，即在特征级和分数级，以允许细粒度对齐。我们为VL语法引入了一个新的评估指标CCRA，并在Flickr30k Entities上显示了比强基线3.3%的改进。我们还通过两个派生任务，即语言语法归纳和短语基础，评估了我们的模型，并在两者上都改进了最先进的技术。",
        "领域": "视觉语言理解、多模态学习、语法归纳",
        "问题": "如何无监督地从图像-标题对中同时提取共享的层次结构，以实现多模态信息的高级理解。",
        "动机": "探索和实现视觉和语言模态之间的高级结构化理解，通过共享的层次结构促进多模态信息的细粒度对齐和理解。",
        "方法": "提出CLIORA方法，构建共享的视觉语言成分树结构，通过对比学习训练成分与图像区域的匹配分数，集成特征级和分数级的融合以实现细粒度对齐。",
        "关键词": [
            "无监督学习",
            "视觉语言语法归纳",
            "共享结构建模",
            "对比学习",
            "细粒度对齐"
        ],
        "涉及的技术概念": {
            "无监督视觉语言语法归纳": "在无监督设置下，同时从视觉和语言模态中归纳出共享的语法结构，以实现多模态理解。",
            "对比学习": "用于训练模型计算成分与图像区域之间的匹配分数，促进模型学习有效的表示。",
            "特征级和分数级融合": "通过在不同层次上融合视觉和语言特征，实现细粒度的模态对齐和理解。"
        },
        "success": true
    },
    {
        "order": 1047,
        "title": "Using Graph Representation Learning with Schema Encoders to Measure the Severity of Depressive Symptoms",
        "html": "https://iclr.cc//virtual/2022/poster/5921",
        "abstract": "Graph neural networks (GNNs) are widely used in regression and classification problems applied to text, in areas such as sentiment analysis and medical decision-making processes. We propose a novel form for node attributes within a GNN based model that captures node-specific embeddings for every word in the vocabulary. This provides a global representation at each node, coupled with node-level updates according to associations among words in a transcript. We demonstrate the efficacy of the approach by augmenting the accuracy of measuring major depressive disorder (MDD). Prior research has sought to make a diagnostic prediction of depression levels from patient data using several modalities, including audio, video, and text. On the DAIC-WOZ benchmark, our method outperforms state-of-art methods by a substantial margin, including those using multiple modalities. Moreover, we also evaluate the performance of our novel model on a Twitter sentiment dataset. We show that our model outperforms a general GNN model by leveraging our novel 2-D node attributes. The performance of our work demonstrates the generality of the proposed method.",
        "conference": "ICLR",
        "中文标题": "使用图表示学习与模式编码器测量抑郁症状的严重程度",
        "摘要翻译": "图神经网络（GNNs）在文本的回归和分类问题中广泛应用，如情感分析和医疗决策过程。我们提出了一种在基于GNN的模型中节点属性的新形式，该形式能够捕获词汇表中每个词的节点特定嵌入。这提供了每个节点的全局表示，并结合了根据转录本中词之间关联的节点级更新。我们通过提高测量重度抑郁症（MDD）的准确性来证明该方法的有效性。先前的研究试图使用包括音频、视频和文本在内的多种模态从患者数据中预测抑郁水平。在DAIC-WOZ基准测试中，我们的方法以显著优势超越了现有技术，包括那些使用多种模态的方法。此外，我们还在Twitter情感数据集上评估了我们新模型的性能。我们展示了通过利用我们新颖的二维节点属性，我们的模型优于一般的GNN模型。我们工作的性能证明了所提出方法的通用性。",
        "领域": "情感分析, 医疗决策支持, 自然语言处理与视觉结合",
        "问题": "如何准确测量抑郁症状的严重程度",
        "动机": "提高从患者数据中预测抑郁水平的准确性，特别是在使用文本数据时",
        "方法": "提出了一种新的图神经网络节点属性形式，结合节点特定嵌入和节点级更新，以提高测量准确性",
        "关键词": [
            "图神经网络",
            "抑郁症状测量",
            "节点特定嵌入",
            "情感分析",
            "医疗决策支持"
        ],
        "涉及的技术概念": {
            "图神经网络（GNNs）": "用于处理图结构数据的深度学习模型，本文中用于从文本数据中提取特征和进行预测",
            "节点特定嵌入": "为词汇表中的每个词生成的特定表示，用于捕获词的上下文和语义信息",
            "二维节点属性": "一种新颖的节点属性表示方法，用于提升模型在特定任务（如抑郁症状测量）上的性能"
        },
        "success": true
    },
    {
        "order": 1048,
        "title": "VAE Approximation Error: ELBO and Exponential Families",
        "html": "https://iclr.cc//virtual/2022/poster/7070",
        "abstract": "The importance of Variational Autoencoders reaches far beyond standalone generative models -- the approach is also used for learning latent representations and can be generalized to semi-supervised learning. This requires a thorough analysis of their commonly known shortcomings: posterior collapse and approximation errors. This paper analyzes VAE approximation errors caused by the combination of the ELBO objective and encoder models from conditional exponential families, including, but not limited to, commonly used conditionally independent discrete and continuous models.We characterize subclasses of generative models consistent with these encoder families. We show that the ELBO optimizer is pulled away from the likelihood optimizer towards the consistent subset and study this effect experimentally. Importantly, this subset can not be enlarged, and the respective error cannot be decreased, by considering deeper encoder/decoder networks.",
        "conference": "ICLR",
        "中文标题": "VAE近似误差：ELBO与指数族",
        "摘要翻译": "变分自编码器（VAE）的重要性远不止于作为独立的生成模型——该方法还用于学习潜在表示，并可推广到半监督学习。这需要对其常见缺点进行彻底分析：后验塌缩和近似误差。本文分析了由ELBO目标与来自条件指数族的编码器模型（包括但不限于常用的条件独立离散和连续模型）结合引起的VAE近似误差。我们描述了与这些编码器家族一致的生成模型的子类。我们展示了ELBO优化器被从似然优化器拉向一致子集，并通过实验研究了这一效应。重要的是，通过考虑更深的编码器/解码器网络，无法扩大这一子集，也无法减少相应的误差。",
        "领域": "生成模型、半监督学习、潜在表示学习",
        "问题": "分析变分自编码器（VAE）中由ELBO目标和条件指数族编码器模型结合引起的近似误差。",
        "动机": "为了深入理解VAE在潜在表示学习和半监督学习中的应用及其局限性，特别是后验塌缩和近似误差问题。",
        "方法": "通过理论分析和实验研究，探讨ELBO优化器与似然优化器之间的关系，以及条件指数族编码器模型对VAE近似误差的影响。",
        "关键词": [
            "变分自编码器",
            "ELBO",
            "指数族",
            "近似误差",
            "潜在表示"
        ],
        "涉及的技术概念": {
            "变分自编码器（VAE）": "一种生成模型，用于学习数据的潜在表示并生成新数据样本。",
            "ELBO（证据下界）": "变分推断中用于近似难以处理的后验分布的目标函数。",
            "条件指数族": "一类概率分布，用于建模编码器，包括常见的条件独立离散和连续模型。"
        },
        "success": true
    },
    {
        "order": 1049,
        "title": "Value Function Spaces: Skill-Centric State Abstractions for Long-Horizon Reasoning",
        "html": "https://iclr.cc//virtual/2022/poster/6739",
        "abstract": "Reinforcement learning can train policies that effectively perform complex tasks. However for long-horizon tasks, the performance of these methods degrades with horizon, often necessitating reasoning over and chaining lower-level skills. Hierarchical reinforcement learning aims to enable this by providing a bank of low-level skills as action abstractions. Hierarchies can further improve on this by abstracting the space states as well. We posit that a suitable state abstraction should depend on the capabilities of the available lower-level policies. We propose Value Function Spaces: a simple approach that produces such a representation by using the value functions corresponding to each lower-level skill. These value functions capture the affordances of the scene, thus forming a  representation that compactly abstracts task relevant information and robustly ignores distractors. Empirical evaluations for maze-solving and robotic manipulation tasks demonstrate that our approach improves long-horizon performance and enables better zero-shot generalization than alternative model-free and model-based methods.",
        "conference": "ICLR",
        "中文标题": "价值函数空间：面向长期推理的技能中心状态抽象",
        "摘要翻译": "强化学习可以训练出有效执行复杂任务的策略。然而，对于长期任务，这些方法的性能会随着时间范围的延长而下降，通常需要对低级技能进行推理和链接。分层强化学习旨在通过提供一组低级技能作为动作抽象来支持这一点。通过进一步抽象状态空间，层次结构可以在此基础上进行改进。我们认为，合适的状态抽象应该依赖于可用低级策略的能力。我们提出了价值函数空间：一种简单的方法，通过使用对应于每个低级技能的价值函数来产生这样的表示。这些价值函数捕捉了场景的可供性，从而形成了一个紧凑地抽象任务相关信息并稳健地忽略干扰物的表示。对迷宫解决和机器人操作任务的实证评估表明，与替代的无模型和基于模型的方法相比，我们的方法提高了长期性能，并实现了更好的零样本泛化。",
        "领域": "分层强化学习、机器人操作、长期任务规划",
        "问题": "如何在长期任务中有效地进行状态抽象以支持低级技能的推理和链接",
        "动机": "解决长期任务中由于时间范围延长导致的性能下降问题，通过状态抽象提升分层强化学习的效率",
        "方法": "提出价值函数空间方法，利用低级技能对应的价值函数进行状态抽象，捕捉场景的可供性，形成紧凑且鲁棒的表示",
        "关键词": [
            "价值函数空间",
            "分层强化学习",
            "状态抽象",
            "长期任务",
            "零样本泛化"
        ],
        "涉及的技术概念": {
            "价值函数空间": "利用低级技能对应的价值函数进行状态抽象，捕捉场景的可供性",
            "分层强化学习": "通过提供一组低级技能作为动作抽象，支持长期任务的推理和链接",
            "状态抽象": "通过抽象状态空间，形成紧凑地抽象任务相关信息并稳健地忽略干扰物的表示"
        },
        "success": true
    },
    {
        "order": 1050,
        "title": "Value Gradient weighted Model-Based Reinforcement Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6704",
        "abstract": "Model-based reinforcement learning (MBRL) is a sample efficient technique to obtain control policies, yet unavoidable modeling errors often lead performance deterioration. The model in MBRL is often solely fitted to reconstruct dynamics, state observations in particular, while the impact of model error on the policy is not captured by the training objective. This leads to a mismatch between the intended goal of MBRL, enabling good policy and value learning, and the target of the loss function employed in practice, future state prediction. Naive intuition would suggest that value-aware model learning would fix this problem and, indeed, several solutions to this objective mismatch problem have been proposed based on theoretical analysis. However, they tend to be inferior in practice to commonly used maximum likelihood (MLE) based approaches. In this paper we propose the Value-gradient weighted Model Learning (VaGraM), a novel method for value-aware model learning which improves the performance of MBRL in challenging settings, such as small model capacity and the presence of distracting state dimensions. We analyze both MLE and value-aware approaches and demonstrate how they fail to account for exploration and the behavior of function approximation when learning value-aware models and highlight the additional goals that must be met to stabilize optimization in the deep learning setting. We verify our analysis by showing that our loss function is able to achieve high returns on the Mujoco benchmark suite while being more robust than maximum likelihood based approaches.",
        "conference": "ICLR",
        "中文标题": "基于价值梯度加权的模型强化学习",
        "摘要翻译": "基于模型的强化学习（MBRL）是一种样本高效的技术，用于获取控制策略，但不可避免的建模误差常常导致性能下降。MBRL中的模型通常仅用于重构动态，特别是状态观察，而模型误差对策略的影响并未被训练目标所捕获。这导致了MBRL的预期目标——促进良好的策略和价值学习——与实践中使用的损失函数目标——未来状态预测——之间的不匹配。天真的直觉可能会认为价值感知模型学习会解决这个问题，事实上，基于理论分析，已经提出了几种解决这一目标不匹配问题的方法。然而，在实践中，它们往往不如常用的基于最大似然估计（MLE）的方法。在本文中，我们提出了价值梯度加权模型学习（VaGraM），一种新颖的价值感知模型学习方法，在具有挑战性的环境中提高了MBRL的性能，如小模型容量和存在干扰状态维度的情况。我们分析了MLE和价值感知方法，并展示了在学习价值感知模型时它们如何未能考虑到探索和函数逼近的行为，并强调了在深度学习环境中稳定优化必须满足的额外目标。我们通过展示我们的损失函数能够在Mujoco基准测试套件上实现高回报，同时比基于最大似然估计的方法更稳健，来验证我们的分析。",
        "领域": "强化学习",
        "问题": "解决基于模型的强化学习中模型误差导致性能下降的问题",
        "动机": "通过价值感知模型学习改进MBRL在挑战性环境中的性能",
        "方法": "提出价值梯度加权模型学习（VaGraM），一种新颖的价值感知模型学习方法",
        "关键词": [
            "价值感知模型学习",
            "模型误差",
            "强化学习"
        ],
        "涉及的技术概念": {
            "价值感知模型学习": "在模型学习中考虑价值信息，以改进策略和价值学习",
            "最大似然估计（MLE）": "常用的模型学习方法，专注于未来状态预测",
            "价值梯度加权模型学习（VaGraM）": "提出的新方法，通过加权价值梯度来优化模型学习，提高MBRL性能"
        },
        "success": true
    },
    {
        "order": 1051,
        "title": "Variational autoencoders in the presence of low-dimensional data: landscape and implicit bias",
        "html": "https://iclr.cc//virtual/2022/poster/6885",
        "abstract": "Variational Autoencoders (VAEs) are one of the most commonly used generative models, particularly for image data. A prominent difficulty in training VAEs is data that is supported on a lower dimensional manifold. Recent work by Dai and Wipf (2020) proposes a two-stage training algorithm for VAEs, based on a conjecture that in standard VAE training the generator will converge to a solution with 0 variance which is correctly supported on the ground truth manifold. They gave partial support for this conjecture by showing that some optima of the VAE loss do satisfy this property, but did not analyze the training dynamics.  In this paper, we show that for linear encoders/decoders, the conjecture is true—that is the VAE training does recover a generator with support equal to the ground truth manifold—and does so due to an implicit bias of gradient descent rather than merely the VAE loss itself. In the nonlinear case, we show that VAE training frequently learns a higher-dimensional manifold which is a superset of the ground truth manifold.",
        "conference": "ICLR",
        "中文标题": "低维数据存在下的变分自编码器：景观与隐式偏差",
        "摘要翻译": "变分自编码器（VAEs）是最常用的生成模型之一，特别是对于图像数据。训练VAEs时的一个突出困难是数据支持在较低维度的流形上。Dai和Wipf（2020）最近的工作提出了一种基于两阶段的VAEs训练算法，基于一个猜想，即在标准VAE训练中，生成器将收敛到一个方差为0的解，该解正确地支持在真实流形上。他们通过展示VAE损失的某些最优解确实满足这一性质，为这一猜想提供了部分支持，但没有分析训练动态。在本文中，我们表明，对于线性编码器/解码器，这一猜想是正确的——即VAE训练确实恢复了一个支持等于真实流形的生成器——并且这是由于梯度下降的隐式偏差，而不仅仅是VAE损失本身。在非线性情况下，我们表明VAE训练经常学习一个更高维度的流形，该流形是真实流形的超集。",
        "领域": "生成模型、深度学习理论、图像生成",
        "问题": "解决变分自编码器在低维数据支持流形上的训练困难问题",
        "动机": "探索变分自编码器在低维数据支持流形上的训练动态和隐式偏差，以验证Dai和Wipf的猜想",
        "方法": "通过分析线性编码器/解码器的训练动态，验证VAE训练恢复真实流形的能力，并探讨非线性情况下的训练行为",
        "关键词": [
            "变分自编码器",
            "低维流形",
            "隐式偏差",
            "梯度下降",
            "生成模型"
        ],
        "涉及的技术概念": {
            "变分自编码器": "一种生成模型，用于学习数据的潜在表示并生成新数据",
            "低维流形": "数据在低维空间中的几何结构，VAEs需要正确识别和支持",
            "隐式偏差": "梯度下降优化过程中算法偏好某些解的特性，影响模型的学习结果"
        },
        "success": true
    },
    {
        "order": 1052,
        "title": "Variational Inference for Discriminative Learning with Generative Modeling of Feature Incompletion",
        "html": "https://iclr.cc//virtual/2022/poster/6533",
        "abstract": "We are concerned with the problem of distributional prediction with incomplete features: The goal is to estimate the distribution of target variables given feature vectors with some of the elements missing. A typical approach to this problem is to perform missing-value imputation and regression, simultaneously or sequentially, which we call the generative approach. Another approach is to perform regression after appropriately encoding missing values into the feature, which we call the discriminative approach. In comparison, the generative approach is more robust to the feature corruption while the discriminative approach is more favorable to maximize the performance of prediction. In this study, we propose a hybrid method to take the best of both worlds. Our method utilizes the black-box variational inference framework so that it can be applied to a wide variety of modern machine learning models, including the variational autoencoders. We also confirmed the effectiveness of the proposed method empirically.",
        "conference": "ICLR",
        "中文标题": "基于特征不完全生成建模的判别学习变分推理",
        "摘要翻译": "我们关注的是特征不完全情况下的分布预测问题：目标是在给定部分元素缺失的特征向量时，估计目标变量的分布。解决这一问题的典型方法是同时或顺序执行缺失值插补和回归，我们称之为生成方法。另一种方法是在将缺失值适当编码到特征后执行回归，我们称之为判别方法。相比之下，生成方法对特征损坏更为鲁棒，而判别方法更有利于最大化预测性能。在本研究中，我们提出了一种混合方法，以取两者之长。我们的方法利用了黑盒变分推理框架，因此可以应用于包括变分自编码器在内的多种现代机器学习模型。我们也通过实验证实了所提方法的有效性。",
        "领域": "缺失数据处理",
        "问题": "在特征不完全的情况下估计目标变量的分布",
        "动机": "结合生成方法和判别方法的优势，提高预测性能和鲁棒性",
        "方法": "提出了一种混合方法，利用黑盒变分推理框架，适用于包括变分自编码器在内的多种现代机器学习模型",
        "关键词": [
            "变分推理",
            "判别学习",
            "生成建模",
            "缺失数据处理",
            "黑盒变分推理"
        ],
        "涉及的技术概念": {
            "变分推理": "用于近似复杂概率分布的技术，在本研究中用于处理特征不完全的问题",
            "判别学习": "直接建模条件概率分布的方法，用于最大化预测性能",
            "生成建模": "通过建模数据的生成过程来处理缺失数据，提高模型的鲁棒性"
        },
        "success": true
    },
    {
        "order": 1053,
        "title": "Variational methods for simulation-based inference",
        "html": "https://iclr.cc//virtual/2022/poster/6748",
        "abstract": "We present Sequential Neural Variational Inference (SNVI), an approach to perform Bayesian inference in models with intractable likelihoods. SNVI combines likelihood-estimation (or likelihood-ratio-estimation) with variational inference to achieve a scalable simulation-based inference approach. SNVI maintains the flexibility of likelihood(-ratio) estimation to allow arbitrary proposals for simulations, while simultaneously providing a functional estimate of the posterior distribution without requiring MCMC sampling. We present several variants of SNVI and demonstrate that they are substantially more computationally efficient than previous algorithms, without loss of accuracy on benchmark tasks. We apply SNVI to a neuroscience model of the pyloric network in the crab and demonstrate that it can infer the posterior distribution with one order of magnitude fewer simulations than previously reported. SNVI vastly reduces the computational cost of simulation-based inference while maintaining accuracy and flexibility, making it possible to tackle problems that were previously inaccessible.",
        "conference": "ICLR",
        "中文标题": "基于模拟推理的变分方法",
        "摘要翻译": "我们提出了序列神经变分推理（SNVI），一种在具有难解似然的模型中进行贝叶斯推理的方法。SNVI将似然估计（或似然比估计）与变分推理相结合，实现了一种可扩展的基于模拟的推理方法。SNVI保持了似然（比）估计的灵活性，允许对模拟提出任意建议，同时提供了后验分布的功能性估计，而无需进行MCMC采样。我们展示了SNVI的几种变体，并证明它们在基准任务上比以前的算法计算效率显著提高，且不损失准确性。我们将SNVI应用于螃蟹幽门网络神经科学模型，并证明它可以用比先前报道少一个数量级的模拟次数推断后验分布。SNVI在保持准确性和灵活性的同时，大大降低了基于模拟的推理的计算成本，使得解决以前无法处理的问题成为可能。",
        "领域": "贝叶斯推理、变分推理、神经科学模型分析",
        "问题": "在具有难解似然的模型中高效进行贝叶斯推理",
        "动机": "开发一种计算效率高、灵活性强的基于模拟的推理方法，以解决传统方法计算成本高的问题",
        "方法": "结合似然估计（或似然比估计）与变分推理，提出序列神经变分推理（SNVI）方法",
        "关键词": [
            "序列神经变分推理",
            "贝叶斯推理",
            "变分推理",
            "模拟推理",
            "计算效率"
        ],
        "涉及的技术概念": {
            "序列神经变分推理（SNVI）": "一种结合似然估计与变分推理的方法，用于在难解似然模型中高效进行贝叶斯推理",
            "似然估计": "用于估计模型参数的概率分布，是SNVI方法中的关键组成部分",
            "变分推理": "一种近似推理方法，通过优化问题来近似后验分布，SNVI利用其提高计算效率"
        },
        "success": true
    },
    {
        "order": 1054,
        "title": "Variational Neural Cellular Automata",
        "html": "https://iclr.cc//virtual/2022/poster/6756",
        "abstract": "In nature, the process of cellular growth and differentiation has lead to an amazing diversity of organisms --- algae, starfish, giant sequoia, tardigrades, and orcas are all created by the same generative process.Inspired by the incredible diversity of this biological generative process, we propose a generative model, the Variational Neural Cellular Automata (VNCA), which is loosely inspired by the biological processes of cellular growth and differentiation. Unlike previous related works, the VNCA is a proper probabilistic generative model, and we evaluate it according to best practices. We find that the VNCA learns to reconstruct samples well and that despite its relatively few parameters and simple local-only communication, the VNCA can learn to generate a large variety of output from information encoded in a common vector format. While there is a significant gap to the current state-of-the-art in terms of generative modeling performance, we show that the VNCA can learn a purely self-organizing generative process of data. Additionally, the self-organizing nature bestows the VNCA with some inherent robustness against perturbations in the early stages of growth.",
        "conference": "ICLR",
        "中文标题": "变分神经细胞自动机",
        "摘要翻译": "在自然界中，细胞的生长和分化过程造就了惊人的生物多样性——藻类、海星、巨杉、缓步动物和虎鲸都是由相同的生成过程创造的。受到这一生物生成过程惊人多样性的启发，我们提出了一种生成模型，即变分神经细胞自动机（VNCA），它在一定程度上受到了细胞生长和分化生物过程的启发。与之前的相关工作不同，VNCA是一个适当的概率生成模型，我们根据最佳实践对其进行了评估。我们发现，VNCA能够很好地学习重建样本，并且尽管其参数相对较少且仅具有简单的局部通信能力，VNCA能够从以通用向量格式编码的信息中学习生成多种输出。虽然在生成模型性能方面与当前最先进技术存在显著差距，但我们展示了VNCA可以学习一种纯粹自组织的数据生成过程。此外，这种自组织特性赋予了VNCA在生长早期阶段对扰动具有一定的固有鲁棒性。",
        "领域": "生成模型、自组织系统、概率建模",
        "问题": "如何设计一个能够模拟生物细胞生长和分化过程的生成模型，并评估其性能。",
        "动机": "受到自然界中细胞生长和分化过程创造生物多样性的启发，探索一种新的生成模型，能够模拟这一过程并生成多样化的输出。",
        "方法": "提出变分神经细胞自动机（VNCA），作为一种概率生成模型，通过简单的局部通信和自组织过程学习生成数据。",
        "关键词": [
            "变分神经细胞自动机",
            "生成模型",
            "自组织",
            "概率建模",
            "细胞自动机"
        ],
        "涉及的技术概念": {
            "变分神经细胞自动机（VNCA）": "一种受生物细胞生长和分化过程启发的生成模型，能够通过自组织过程生成多样化的数据。",
            "概率生成模型": "VNCA作为一种概率生成模型，能够学习数据的概率分布并生成新的数据样本。",
            "自组织": "VNCA通过局部交互和简单的规则，无需全局控制即可组织生成复杂的数据结构。"
        },
        "success": true
    },
    {
        "order": 1055,
        "title": "Variational oracle guiding for reinforcement learning",
        "html": "https://iclr.cc//virtual/2022/poster/6904",
        "abstract": "How to make intelligent decisions is a central problem in machine learning and artificial intelligence. Despite recent successes of deep reinforcement learning (RL) in various decision making problems, an important but under-explored aspect is how to leverage oracle observation (the information that is invisible during online decision making, but is available during offline training) to facilitate learning. For example, human experts will look at the replay after a Poker game, in which they can check the opponents' hands to improve their estimation of the opponents' hands from the visible information during playing. In this work, we study such problems based on Bayesian theory and derive an objective to leverage oracle observation in RL using variational methods. Our key contribution is to propose a general learning framework referred to as variational latent oracle guiding (VLOG) for DRL. VLOG is featured with preferable properties such as its robust and promising performance and its versatility to incorporate with any value-based DRL algorithm. We empirically demonstrate the effectiveness of VLOG in online and offline RL domains with tasks ranging from video games to a challenging tile-based game Mahjong. Furthermore, we publish the Mahjong environment and an offline RL dataset as a benchmark to facilitate future research on oracle guiding (https://github.com/Agony5757/mahjong).",
        "conference": "ICLR",
        "中文标题": "变分预言引导的强化学习",
        "摘要翻译": "如何做出智能决策是机器学习和人工智能中的一个核心问题。尽管深度强化学习（RL）在各种决策问题上取得了近期的成功，但一个重要但尚未充分探索的方面是如何利用预言观察（在线决策时不可见但在离线训练时可用的信息）来促进学习。例如，人类专家在扑克游戏后会查看回放，他们可以检查对手的手牌，从而从游戏过程中可见的信息中改进对对手手牌的估计。在这项工作中，我们基于贝叶斯理论研究了这类问题，并利用变分方法推导出了一个利用预言观察的RL目标。我们的主要贡献是提出了一个被称为变分潜在预言引导（VLOG）的深度强化学习通用框架。VLOG具有优越的特性，如其稳健且前景广阔的性能，以及其能够与任何基于价值的深度强化学习算法结合的多样性。我们通过实证展示了VLOG在在线和离线RL领域中的有效性，任务范围从视频游戏到具有挑战性的基于瓦片的游戏麻将。此外，我们发布了麻将环境和离线RL数据集作为基准，以促进未来关于预言引导的研究（https://github.com/Agony5757/mahjong）。",
        "领域": "强化学习、决策系统、游戏AI",
        "问题": "如何利用离线训练时可用的预言观察信息来促进在线决策时的学习效果",
        "动机": "探索在强化学习中利用离线训练时可获得但在线决策时不可见的信息（预言观察）来提升学习效率和决策质量",
        "方法": "基于贝叶斯理论，利用变分方法推导出利用预言观察的强化学习目标，并提出变分潜在预言引导（VLOG）框架",
        "关键词": [
            "变分方法",
            "预言引导",
            "深度强化学习",
            "贝叶斯理论",
            "麻将AI"
        ],
        "涉及的技术概念": {
            "变分方法": "用于推导利用预言观察的强化学习目标，优化学习过程",
            "预言观察": "离线训练时可获得但在线决策时不可见的信息，用于提升学习效率和决策质量",
            "贝叶斯理论": "为利用预言观察提供理论基础，指导如何从可见信息中推断不可见信息"
        },
        "success": true
    },
    {
        "order": 1056,
        "title": "Variational Predictive Routing with Nested Subjective Timescales",
        "html": "https://iclr.cc//virtual/2022/poster/6641",
        "abstract": "Discovery and learning of an underlying spatiotemporal hierarchy in sequential data is an important topic for machine learning. Despite this, little work has been done to explore hierarchical generative models that can flexibly adapt their layerwise representations in response to datasets with different temporal dynamics. Here, we present Variational Predictive Routing (VPR) – a neural probabilistic inference system that organizes latent representations of video features in a temporal hierarchy, based on their rates of change, thus modeling continuous data as a hierarchical renewal process. By employing an event detection mechanism that relies solely on the system’s latent representations (without the need of a separate model), VPR is able to dynamically adjust its internal state following changes in the observed features, promoting an optimal organisation of representations across the levels of the model’s latent hierarchy.  Using several video datasets, we show that VPR is able to detect event boundaries, disentangle spatiotemporal features across its hierarchy, adapt to the dynamics of the data, and produce accurate time-agnostic rollouts of the future. Our approach integrates insights from neuroscience and introduces a framework with high potential for applications in model-based reinforcement learning, where flexible and informative state-space rollouts are of particular interest.",
        "conference": "ICLR",
        "中文标题": "具有嵌套主观时间尺度的变分预测路由",
        "摘要翻译": "发现和学习序列数据中潜在的时空层次结构是机器学习的一个重要课题。尽管如此，探索能够灵活适应具有不同时间动态的数据集的层次生成模型的工作还很少。在此，我们提出了变分预测路由（VPR）——一种神经概率推理系统，它根据变化率将视频特征的潜在表示组织在一个时间层次结构中，从而将连续数据建模为一个层次更新过程。通过采用仅依赖于系统潜在表示的事件检测机制（无需单独的模型），VPR能够在观察到特征变化时动态调整其内部状态，促进模型潜在层次各层表示的最优组织。使用多个视频数据集，我们展示了VPR能够检测事件边界，在其层次结构中解耦时空特征，适应数据的动态，并产生准确的时间无关的未来滚动。我们的方法整合了神经科学的见解，并引入了一个在基于模型的强化学习中具有高应用潜力的框架，其中灵活且信息丰富的状态空间滚动尤为重要。",
        "领域": "时空层次学习、视频特征分析、模型基强化学习",
        "问题": "如何灵活适应具有不同时间动态的数据集，并有效组织视频特征的潜在表示。",
        "动机": "探索能够发现和学习序列数据中潜在时空层次结构的层次生成模型，以解决现有模型在适应不同时间动态数据集方面的不足。",
        "方法": "提出变分预测路由（VPR），一种神经概率推理系统，通过事件检测机制动态调整内部状态，组织潜在表示的时间层次结构。",
        "关键词": [
            "变分预测路由",
            "时空层次结构",
            "神经概率推理",
            "事件检测",
            "模型基强化学习"
        ],
        "涉及的技术概念": {
            "变分预测路由（VPR）": "一种神经概率推理系统，用于组织视频特征的潜在表示在时间层次结构中。",
            "事件检测机制": "依赖于系统潜在表示的机制，用于动态调整模型的内部状态，无需单独的模型。",
            "层次更新过程": "将连续数据建模为一个层次结构，根据特征的变化率组织潜在表示。"
        },
        "success": true
    },
    {
        "order": 1057,
        "title": "VAT-Mart: Learning Visual Action Trajectory Proposals for Manipulating 3D ARTiculated Objects",
        "html": "https://iclr.cc//virtual/2022/poster/6298",
        "abstract": "Perceiving and manipulating 3D articulated objects (e.g., cabinets, doors) in human environments is an important yet challenging task for future home-assistant robots. The space of 3D articulated objects is exceptionally rich in their myriad semantic categories, diverse shape geometry, and complicated part functionality. Previous works mostly abstract kinematic structure with estimated joint parameters and part poses as the visual representations for manipulating 3D articulated objects. In this paper, we propose object-centric actionable visual priors as a novel perception-interaction handshaking point that the perception system outputs more actionable guidance than kinematic structure estimation, by predicting dense geometry-aware, interaction-aware, and task-aware visual action affordance and trajectory proposals. We design an interaction-for-perception framework VAT-Mart to learn such actionable visual representations by simultaneously training a curiosity-driven reinforcement learning policy exploring diverse interaction trajectories and a perception module summarizing and generalizing the explored knowledge for pointwise predictions among diverse shapes. Experiments prove the effectiveness of the proposed approach using the large-scale PartNet-Mobility dataset in SAPIEN environment and show promising generalization capabilities to novel test shapes, unseen object categories, and real-world data.",
        "conference": "ICLR",
        "中文标题": "VAT-Mart：学习视觉动作轨迹提议以操作3D铰接物体",
        "摘要翻译": "在人类环境中感知和操作3D铰接物体（如橱柜、门）对于未来的家庭助理机器人来说是一项重要但具有挑战性的任务。3D铰接物体的空间在其无数的语义类别、多样的形状几何和复杂的部件功能方面异常丰富。以前的工作大多通过估计关节参数和部件姿态来抽象运动学结构，作为操作3D铰接物体的视觉表示。在本文中，我们提出了以物体为中心的可操作视觉先验作为一种新颖的感知-交互握手点，感知系统通过预测密集的几何感知、交互感知和任务感知的视觉动作可供性和轨迹提议，输出比运动学结构估计更具操作性的指导。我们设计了一个交互促进感知的框架VAT-Mart，通过同时训练一个好奇心驱动的强化学习策略探索多样化的交互轨迹和一个感知模块总结和概括探索的知识以进行点预测，来学习这种可操作的视觉表示。实验证明了所提出方法在使用大规模PartNet-Mobility数据集在SAPIEN环境中的有效性，并展示了对新测试形状、未见物体类别和真实世界数据的有希望的泛化能力。",
        "领域": "机器人操作、3D视觉、强化学习",
        "问题": "如何在丰富多样的3D铰接物体空间中，有效地感知和操作这些物体。",
        "动机": "为了解决未来家庭助理机器人在感知和操作3D铰接物体时面临的挑战，特别是在物体语义类别、形状几何和部件功能多样性方面。",
        "方法": "提出了一种以物体为中心的可操作视觉先验，通过预测密集的视觉动作可供性和轨迹提议，设计了一个交互促进感知的框架VAT-Mart，结合好奇心驱动的强化学习策略和感知模块。",
        "关键词": [
            "3D铰接物体",
            "视觉动作可供性",
            "强化学习",
            "感知-交互框架",
            "轨迹提议"
        ],
        "涉及的技术概念": {
            "可操作视觉先验": "作为感知系统输出的视觉表示，提供比传统运动学结构估计更具操作性的指导。",
            "好奇心驱动的强化学习策略": "用于探索多样化的交互轨迹，以丰富感知模块的学习数据。",
            "感知模块": "负责总结和概括通过交互探索获得的知识，进行点预测，以支持对3D铰接物体的操作。"
        },
        "success": true
    },
    {
        "order": 1058,
        "title": "VC dimension of partially quantized neural networks in the overparametrized regime",
        "html": "https://iclr.cc//virtual/2022/poster/6203",
        "abstract": "Vapnik-Chervonenkis (VC) theory has so far been unable to explain the small generalization error of overparametrized neural networks. Indeed, existing applications of VC theory to large networks obtain upper bounds on VC dimension that are proportional to the number of weights, and for a large class of networks, these upper bound are known to be tight. In this work, we focus on a class of partially quantized networks that we refer to as hyperplane arrangement neural networks (HANNs). Using a sample compression analysis, we show that HANNs can have VC dimension significantly smaller than the number of weights, while being highly expressive. In particular, empirical risk minimization over HANNs in the overparametrized regime achieves the minimax rate for classification with Lipschitz posterior class probability. We further demonstrate the expressivity of HANNs empirically. On a panel of 121 UCI datasets, overparametrized HANNs are able to match the performance of state-of-the-art full-precision models.",
        "conference": "ICLR",
        "中文标题": "过参数化状态下部分量化神经网络的VC维",
        "摘要翻译": "迄今为止，Vapnik-Chervonenkis（VC）理论仍未能解释过参数化神经网络的小泛化误差。实际上，VC理论应用于大型网络时，得到的VC维上界与权重数量成正比，而对于一大类网络，这些上界已知是紧的。在这项工作中，我们关注一类部分量化网络，我们称之为超平面排列神经网络（HANNs）。通过样本压缩分析，我们表明HANNs可以拥有远小于权重数量的VC维，同时具有高度的表达能力。特别是，在过参数化状态下，HANNs上的经验风险最小化实现了带有Lipschitz后验类概率的分类的最小最大率。我们进一步通过实验证明了HANNs的表达能力。在121个UCI数据集的面板上，过参数化的HANNs能够匹配最先进的全精度模型的性能。",
        "领域": "神经网络理论、量化神经网络、统计学习理论",
        "问题": "解释过参数化神经网络的小泛化误差问题",
        "动机": "探索部分量化神经网络在过参数化状态下的VC维特性及其表达能力",
        "方法": "通过样本压缩分析研究一类称为超平面排列神经网络（HANNs）的部分量化网络",
        "关键词": [
            "VC维",
            "过参数化神经网络",
            "部分量化",
            "超平面排列神经网络",
            "经验风险最小化"
        ],
        "涉及的技术概念": {
            "VC维": "用于衡量模型复杂度和泛化能力的理论工具，本文中用于分析部分量化神经网络的泛化误差",
            "超平面排列神经网络（HANNs）": "一类部分量化神经网络，本文中用于研究在过参数化状态下的表达能力和VC维特性",
            "经验风险最小化": "一种学习策略，本文中用于实现在过参数化状态下带有Lipschitz后验类概率的分类的最小最大率"
        },
        "success": true
    },
    {
        "order": 1059,
        "title": "Vector-quantized Image Modeling with Improved VQGAN",
        "html": "https://iclr.cc//virtual/2022/poster/6405",
        "abstract": "Pretraining language models with next-token prediction on massive text corpora has delivered phenomenal zero-shot, few-shot, transfer learning and multi-tasking capabilities on both generative and discriminative language tasks. Motivated by this success, we explore a Vector-quantized Image Modeling (VIM) approach that involves pretraining a Transformer to predict rasterized image tokens autoregressively. The discrete image tokens are encoded from a learned Vision-Transformer-based VQGAN (ViT-VQGAN). We first propose multiple improvements over vanilla VQGAN from architecture to codebook learning, yielding better efficiency and reconstruction fidelity. The improved ViT-VQGAN further improves vector-quantized image modeling tasks, including unconditional, class-conditioned image generation and unsupervised representation learning. When trained on ImageNet at 256x256 resolution, we achieve Inception Score (IS) of 175.1 and Fr'echet Inception Distance (FID) of 4.17, a dramatic improvement over the vanilla VQGAN, which obtains 70.6 and 17.04 for IS and FID, respectively. Based on ViT-VQGAN and unsupervised pretraining, we further evaluate the pretrained Transformer by averaging intermediate features, similar to Image GPT (iGPT). This ImageNet-pretrained VIM-L significantly beats iGPT-L on linear-probe accuracy from 60.3% to 73.2% for a similar model size. ViM-L also outperforms iGPT-XL which is trained with extra web image data and larger model size.",
        "conference": "ICLR",
        "中文标题": "使用改进的VQGAN进行向量量化图像建模",
        "摘要翻译": "通过在大量文本语料库上进行下一令牌预测预训练语言模型，已经在生成性和判别性语言任务上展示了惊人的零样本、少样本、迁移学习和多任务处理能力。受此成功的启发，我们探索了一种向量量化图像建模（VIM）方法，该方法涉及预训练一个Transformer以自回归方式预测光栅化图像令牌。离散的图像令牌是从一个基于Vision Transformer的VQGAN（ViT-VQGAN）学习编码的。我们首先提出了从架构到码本学习的多项改进，超越了原始VQGAN，从而获得了更好的效率和重建保真度。改进后的ViT-VQGAN进一步提升了向量量化图像建模任务，包括无条件、类条件图像生成和无监督表示学习。当在256x256分辨率的ImageNet上训练时，我们实现了175.1的Inception Score（IS）和4.17的Fr'echet Inception Distance（FID），相比原始VQGAN的70.6 IS和17.04 FID，有了显著提升。基于ViT-VQGAN和无监督预训练，我们进一步通过平均中间特征来评估预训练的Transformer，类似于Image GPT（iGPT）。这个在ImageNet上预训练的VIM-L在类似模型大小下，线性探测准确率从60.3%显著提高到73.2%，显著优于iGPT-L。ViM-L也优于使用额外网络图像数据和更大模型大小训练的iGPT-XL。",
        "领域": "图像生成、无监督学习、表示学习",
        "问题": "如何通过改进VQGAN和向量量化图像建模方法，提升图像生成和表示学习的性能",
        "动机": "受语言模型预训练成功的启发，探索在图像领域应用类似的自回归预测方法，以提升图像生成和表示学习的性能",
        "方法": "提出多项VQGAN的改进措施，包括架构和码本学习，然后使用改进后的ViT-VQGAN进行向量量化图像建模，包括图像生成和表示学习任务",
        "关键词": [
            "向量量化",
            "VQGAN",
            "图像生成",
            "无监督学习",
            "表示学习"
        ],
        "涉及的技术概念": {
            "向量量化图像建模（VIM）": "一种通过预训练Transformer以自回归方式预测图像令牌的方法，用于图像生成和表示学习",
            "Vision-Transformer-based VQGAN（ViT-VQGAN）": "基于Vision Transformer的VQGAN，用于编码离散图像令牌，改进后提升了效率和重建保真度",
            "Inception Score（IS）和Fr'echet Inception Distance（FID）": "评估图像生成质量的指标，IS越高表示图像质量越好，FID越低表示生成图像与真实图像的差异越小"
        },
        "success": true
    },
    {
        "order": 1060,
        "title": "VICReg: Variance-Invariance-Covariance Regularization for Self-Supervised Learning",
        "html": "https://iclr.cc//virtual/2022/poster/6481",
        "abstract": "Recent self-supervised methods for image representation learning maximize the agreement between embedding vectors produced by encoders fed with different views of the same image.  The main challenge is to prevent a collapse in which the encoders produce constant or non-informative vectors. We introduce VICReg (Variance-Invariance-Covariance Regularization), a method that explicitly avoids the collapse problem with two regularizations terms applied to both embeddings separately: (1) a term that maintains the variance of each embedding dimension above a threshold,  (2) a term that decorrelates each pair of variables. Unlike most other approaches to the same problem, VICReg does not require techniques such as: weight sharing between the branches, batch normalization, feature-wise normalization, output quantization, stop gradient, memory banks, etc., and achieves results on par with the state of the art on several downstream tasks. In addition, we show that our variance regularization term stabilizes the training of other methods and leads to performance improvements.",
        "conference": "ICLR",
        "中文标题": "VICReg：自监督学习中的方差-不变性-协方差正则化",
        "摘要翻译": "最近的自监督图像表示学习方法通过最大化同一图像不同视图下编码器产生的嵌入向量之间的一致性来学习表示。主要挑战在于防止编码器产生恒定或无信息向量的崩溃问题。我们引入了VICReg（方差-不变性-协方差正则化），该方法通过分别应用于两个嵌入的两个正则化项明确避免了崩溃问题：（1）一个保持每个嵌入维度方差高于阈值的项，（2）一个使每对变量去相关的项。与大多数其他解决相同问题的方法不同，VICReg不需要诸如分支间权重共享、批量归一化、特征归一化、输出量化、停止梯度、记忆库等技术，并在多个下游任务上达到了与现有技术相当的结果。此外，我们还展示了我们的方差正则化项可以稳定其他方法的训练并带来性能提升。",
        "领域": "自监督学习、图像表示学习、深度学习正则化技术",
        "问题": "防止自监督学习中编码器产生恒定或无信息向量的崩溃问题",
        "动机": "解决自监督学习中编码器崩溃问题，提高图像表示学习的效率和效果",
        "方法": "引入VICReg方法，通过方差和协方差正则化项避免编码器崩溃，不依赖复杂技术",
        "关键词": [
            "自监督学习",
            "图像表示学习",
            "正则化技术",
            "编码器崩溃",
            "VICReg"
        ],
        "涉及的技术概念": {
            "方差正则化": "保持嵌入维度方差高于阈值，防止编码器产生恒定向量",
            "协方差正则化": "使嵌入变量对去相关，增加嵌入的多样性",
            "自监督学习": "无需人工标注，利用数据本身的结构学习表示的方法"
        },
        "success": true
    },
    {
        "order": 1061,
        "title": "ViDT: An Efficient and Effective Fully Transformer-based Object Detector",
        "html": "https://iclr.cc//virtual/2022/poster/6181",
        "abstract": "Transformers are transforming the landscape of computer vision, especially for recognition tasks. Detection transformers are the first fully end-to-end learning systems for object detection, while vision transformers are the first fully transformer-based architecture for image classification. In this paper, we integrate Vision and Detection Transformers (ViDT) to build an effective and efficient object detector. ViDT introduces a reconfigured attention module to extend the recent Swin Transformer to be a standalone object detector, followed by a computationally efficient transformer decoder that exploits multi-scale features and auxiliary techniques essential to boost the detection performance without much increase in computational load. Extensive evaluation results on the Microsoft COCO benchmark dataset demonstrate that ViDT obtains the best AP and latency trade-off among existing fully transformer-based object detectors, and achieves 49.2AP owing to its high scalability for large models. We release the code and trained models at https://github.com/naver-ai/vidt.",
        "conference": "ICLR",
        "中文标题": "ViDT：一种高效且完全基于Transformer的目标检测器",
        "摘要翻译": "Transformer正在改变计算机视觉的面貌，特别是在识别任务方面。检测Transformer是第一个完全端到端学习的目标检测系统，而视觉Transformer则是第一个完全基于Transformer架构的图像分类方法。在本文中，我们整合了视觉和检测Transformer（ViDT）来构建一个高效且有效的目标检测器。ViDT引入了一个重新配置的注意力模块，将最近的Swin Transformer扩展为一个独立的目标检测器，随后是一个计算效率高的Transformer解码器，该解码器利用多尺度特征和辅助技术，这些技术对于在不显著增加计算负载的情况下提升检测性能至关重要。在Microsoft COCO基准数据集上的广泛评估结果表明，ViDT在现有的完全基于Transformer的目标检测器中获得了最佳的AP和延迟权衡，并且由于其对于大型模型的高可扩展性，达到了49.2AP。我们在https://github.com/naver-ai/vidt上发布了代码和训练好的模型。",
        "领域": "目标检测",
        "问题": "如何构建一个高效且完全基于Transformer的目标检测器",
        "动机": "整合视觉和检测Transformer以构建一个高效且有效的目标检测器，解决现有Transformer在目标检测中的效率和性能问题",
        "方法": "引入重新配置的注意力模块扩展Swin Transformer为独立目标检测器，并采用计算效率高的Transformer解码器利用多尺度特征和辅助技术提升性能",
        "关键词": [
            "目标检测",
            "Transformer",
            "Swin Transformer",
            "多尺度特征",
            "计算效率"
        ],
        "涉及的技术概念": {
            "Swin Transformer": "一种高效的视觉Transformer架构，ViDT通过重新配置其注意力模块将其扩展为目标检测器",
            "多尺度特征": "ViDT利用多尺度特征来提升检测性能，使模型能够更好地处理不同大小的目标",
            "Transformer解码器": "ViDT采用的计算效率高的解码器，用于处理多尺度特征并辅助提升检测性能，而不显著增加计算负担"
        },
        "success": true
    },
    {
        "order": 1062,
        "title": "Vision-Based Manipulators Need to Also See from Their Hands",
        "html": "https://iclr.cc//virtual/2022/poster/6102",
        "abstract": "We study how the choice of visual perspective affects learning and generalization in the context of physical manipulation from raw sensor observations. Compared with the more commonly used global third-person perspective, a hand-centric (eye-in-hand) perspective affords reduced observability, but we find that it consistently improves training efficiency and out-of-distribution generalization. These benefits hold across a variety of learning algorithms, experimental settings, and distribution shifts, and for both simulated and real robot apparatuses. However, this is only the case when hand-centric observability is sufficient; otherwise, including a third-person perspective is necessary for learning, but also harms out-of-distribution generalization. To mitigate this, we propose to regularize the third-person information stream via a variational information bottleneck. On six representative manipulation tasks with varying hand-centric observability adapted from the Meta-World benchmark, this results in a state-of-the-art reinforcement learning agent operating from both perspectives improving its out-of-distribution generalization on every task. While some practitioners have long put cameras in the hands of robots, our work systematically analyzes the benefits of doing so and provides simple and broadly applicable insights for improving end-to-end learned vision-based robotic manipulation.",
        "conference": "ICLR",
        "中文标题": "基于视觉的机械手也需要从其手中看到",
        "摘要翻译": "我们研究了视觉视角的选择如何影响从原始传感器观察中学习物理操作和泛化的过程。与更常用的全局第三人称视角相比，以手为中心（眼在手）的视角提供了较低的观察能力，但我们发现它一致提高了训练效率和分布外泛化。这些好处在各种学习算法、实验设置、分布变化以及模拟和真实机器人装置中都得到了验证。然而，这只有在手为中心的观察能力足够时才成立；否则，包括第三人称视角对于学习是必要的，但也会损害分布外泛化。为了缓解这一点，我们提出通过变分信息瓶颈来规范化第三人称信息流。在来自Meta-World基准的六个具有不同手为中心观察能力的代表性操作任务上，这导致了一个从两种视角操作的最先进强化学习代理，在每个任务上都提高了其分布外泛化能力。虽然一些从业者长期以来一直在机器人手中放置摄像头，但我们的工作系统地分析了这样做的益处，并为改进端到端学习的基于视觉的机器人操作提供了简单且广泛适用的见解。",
        "领域": "机器人视觉操作、强化学习、视觉感知",
        "问题": "研究视觉视角选择对物理操作学习和泛化能力的影响",
        "动机": "探索手为中心视角在提高训练效率和泛化能力方面的潜力，以及如何优化第三人称视角的使用以避免损害泛化能力",
        "方法": "比较手为中心和第三人称视角的效果，提出使用变分信息瓶颈来规范化第三人称信息流，以提高分布外泛化能力",
        "关键词": [
            "视觉视角",
            "手为中心",
            "变分信息瓶颈",
            "强化学习",
            "机器人操作"
        ],
        "涉及的技术概念": {
            "手为中心视角": "提供较低的观察能力，但能提高训练效率和分布外泛化",
            "变分信息瓶颈": "用于规范化第三人称信息流，以减少对分布外泛化的负面影响",
            "强化学习": "用于训练机器人操作任务的学习算法，本研究中的代理通过强化学习从两种视角中学习"
        },
        "success": true
    },
    {
        "order": 1063,
        "title": "Visual Correspondence Hallucination",
        "html": "https://iclr.cc//virtual/2022/poster/6318",
        "abstract": "Given a pair of partially overlapping source and target images and a keypoint in the source image, the keypoint's correspondent in the target image can be either visible, occluded or outside the field of view. Local feature matching methods are only able to identify the correspondent's location when it is visible, while humans can also hallucinate its location when it is occluded or outside the field of view through geometric reasoning.  In this paper, we bridge this gap by training a network to output a peaked probability distribution over the correspondent's location, regardless of this correspondent being visible, occluded, or outside the field of view.  We experimentally demonstrate that this network is indeed able to hallucinate correspondences on pairs of images captured in scenes that were not seen at training-time.  We also apply this network to an absolute camera pose estimation problem and find it is significantly more robust than state-of-the-art local feature matching-based competitors.",
        "conference": "ICLR",
        "中文标题": "视觉对应幻觉",
        "摘要翻译": "给定一对部分重叠的源图像和目标图像以及源图像中的一个关键点，该关键点在目标图像中的对应点可能是可见的、被遮挡的或在视野之外的。局部特征匹配方法只能在对应点可见时识别其位置，而人类则可以通过几何推理在被遮挡或视野之外的情况下幻觉其位置。在本文中，我们通过训练一个网络来弥合这一差距，该网络能够输出对应点位置的高峰概率分布，无论该对应点是可见的、被遮挡的还是视野之外的。我们通过实验证明，该网络确实能够在训练时未见的场景中捕获的图像对上幻觉对应关系。我们还将该网络应用于绝对相机姿态估计问题，并发现它比基于最先进局部特征匹配的竞争对手要稳健得多。",
        "领域": "图像匹配、相机姿态估计、几何推理",
        "问题": "解决在图像中对应点被遮挡或视野之外时，如何准确预测其位置的问题。",
        "动机": "弥合人类视觉系统与现有局部特征匹配方法在预测被遮挡或视野之外对应点位置能力上的差距。",
        "方法": "训练一个神经网络，输出对应点位置的概率分布，无论对应点是否可见、被遮挡或在视野之外。",
        "关键词": [
            "视觉对应幻觉",
            "几何推理",
            "图像匹配",
            "相机姿态估计",
            "概率分布"
        ],
        "涉及的技术概念": {
            "局部特征匹配": "用于在图像中识别和匹配关键点的技术，但在对应点被遮挡或视野之外时效果有限。",
            "几何推理": "通过理解场景的几何结构来预测被遮挡或视野之外对应点的位置。",
            "概率分布": "网络输出的对应点位置的概率分布，用于表示对应点可能的位置，无论其是否可见。"
        },
        "success": true
    },
    {
        "order": 1064,
        "title": "Visual hyperacuity with moving sensor and recurrent neural computations",
        "html": "https://iclr.cc//virtual/2022/poster/6105",
        "abstract": "Dynamical phenomena, such as recurrent neuronal activity  and perpetual motion of the eye, are typically overlooked in models of bottom-up visual perception. Recent experiments suggest that tiny inter-saccadic eye motion ('fixational drift') enhances visual  acuity beyond the limit imposed by the density of retinal photoreceptors. Here we hypothesize that such an enhancement is enabled by recurrent neuronal computations in early visual areas. Specifically, we explore a setting involving a low-resolution dynamical sensor that moves with respect to a static scene, with drift-like tiny steps. This setting mimics a dynamical eye viewing objects in perceptually-challenging conditions. The dynamical sensory input is classified by a convolutional neural network with recurrent connectivity added to its lower layers, in analogy to recurrent connectivity in early visual areas.  Applying our system to CIFAR-10 and CIFAR-100 datasets down-sampled via 8x8 sensor, we found that (i) classification accuracy, which is drastically reduced by this down-sampling, is mostly restored to its 32x32 baseline level when using a moving sensor and recurrent connectivity, (ii) in this setting, neurons in the early layers exhibit a wide repertoire of selectivity patterns, spanning the spatiotemporal selectivity space, with neurons preferring different combinations of spatial and temporal patterning, and (iii) curved sensor's trajectories improve  visual acuity compared to straight trajectories, echoing recent experimental findings involving eye-tracking in challenging conditions. Our work sheds light on the possible role of recurrent connectivity in early vision as well as the roles of fixational drift and temporal-frequency selective cells in the visual system. It also proposes a solution for artificial image recognition in settings with limited resolution and multiple time samples, such as in edge AI applications.",
        "conference": "ICLR",
        "中文标题": "移动传感器与循环神经计算实现的视觉超锐度",
        "摘要翻译": "动态现象，如循环神经元活动和眼睛的持续运动，通常在自下而上的视觉感知模型中被忽视。最近的实验表明，微小的眼间跳动运动（'固定漂移'）能够将视觉锐度提升到超出视网膜光感受器密度所限制的水平。在此，我们假设这种提升是由早期视觉区域的循环神经元计算实现的。具体来说，我们探索了一个涉及低分辨率动态传感器的设置，该传感器相对于静态场景以类似漂移的微小步骤移动。这一设置模拟了在感知挑战条件下观察物体的动态眼睛。动态感官输入由一个卷积神经网络分类，该网络在其较低层添加了循环连接，类似于早期视觉区域的循环连接。将我们的系统应用于通过8x8传感器下采样的CIFAR-10和CIFAR-100数据集，我们发现（i）分类准确度，由于这种下采样而大幅降低，当使用移动传感器和循环连接时，大部分恢复到其32x32基线水平，（ii）在这种设置下，早期层的神经元表现出广泛的选择性模式，跨越时空选择性空间，神经元偏好不同的空间和时间模式组合，以及（iii）弯曲的传感器轨迹与直线轨迹相比，提高了视觉锐度，呼应了最近涉及在挑战条件下眼动追踪的实验发现。我们的工作揭示了循环连接在早期视觉中可能的作用，以及固定漂移和时间频率选择性细胞在视觉系统中的作用。它还提出了一种在分辨率有限和多个时间样本的设置下，如边缘AI应用中，进行人工图像识别的解决方案。",
        "领域": "视觉感知增强, 循环神经网络, 动态视觉处理",
        "问题": "如何在低分辨率动态传感器条件下恢复或增强视觉锐度",
        "动机": "探索循环神经元计算和微小眼动如何协同工作以提升视觉锐度，尤其是在感知挑战条件下",
        "方法": "采用带有循环连接的卷积神经网络处理由移动传感器捕获的动态视觉输入，模拟早期视觉区域的循环连接",
        "关键词": [
            "视觉超锐度",
            "循环神经网络",
            "动态传感器",
            "固定漂移",
            "边缘AI"
        ],
        "涉及的技术概念": {
            "循环神经元计算": "在早期视觉区域中模拟的循环连接，用于处理动态视觉输入，提升视觉锐度",
            "固定漂移": "微小的眼间跳动运动，模拟为传感器的微小移动步骤，以增强视觉感知",
            "时空选择性": "神经元对特定空间和时间模式的偏好，通过循环神经网络在早期层中实现，以处理动态视觉输入"
        },
        "success": true
    },
    {
        "order": 1065,
        "title": "Visual Representation Learning Does Not Generalize Strongly Within the Same Domain",
        "html": "https://iclr.cc//virtual/2022/poster/6276",
        "abstract": "An important component for generalization in machine learning is to uncover underlying latent factors of variation as well as the mechanism through which each factor acts in the world.In this paper, we test whether 17 unsupervised, weakly supervised, and fully supervised representation learning approaches correctly infer the generative factors of variation in simple datasets (dSprites, Shapes3D, MPI3D) from controlled environments, and on our contributed CelebGlow dataset. In contrast to prior robustness work that introduces novel factors of variation during test time, such as blur or other (un)structured noise, we here recompose, interpolate, or extrapolate only existing factors of variation from the training data set (e.g., small and medium-sized objects during training and large objects during testing). Models that learn the correct mechanism should be able to generalize to this benchmark.In total, we train and test 2000+ models and observe that all of them struggle to learn the underlying mechanism regardless of supervision signal and architectural bias. Moreover, the generalization capabilities of all tested models drop significantly as we move from artificial datasets towards more realistic real-world datasets.Despite their inability to identify the correct mechanism, the models are quite modular as their ability to infer other in-distribution factors remains fairly stable, providing only a single factor is out-of-distribution. These results point to an important yet understudied problem of learning mechanistic models of observations that can facilitate generalization.",
        "conference": "ICLR",
        "中文标题": "视觉表示学习在同一领域内未能实现强泛化",
        "摘要翻译": "机器学习中泛化的一个重要组成部分是揭示潜在的潜在变异因素以及每个因素在世界中作用的机制。在本文中，我们测试了17种无监督、弱监督和完全监督的表示学习方法是否能够从受控环境中的简单数据集（dSprites、Shapes3D、MPI3D）以及我们贡献的CelebGlow数据集中正确推断出生成的变异因素。与之前引入新变异因素（如模糊或其他（非）结构化噪声）的鲁棒性工作不同，我们在这里仅重新组合、插值或外推训练数据集中现有的变异因素（例如，训练中的小型和中型对象与测试中的大型对象）。学习正确机制的模型应该能够泛化到这个基准。总共，我们训练和测试了2000多个模型，观察到所有模型无论监督信号和架构偏见如何，都难以学习底层机制。此外，随着我们从人工数据集转向更现实的真实世界数据集，所有测试模型的泛化能力显著下降。尽管它们无法识别正确的机制，但这些模型相当模块化，因为它们推断其他分布内因素的能力保持相当稳定，前提是只有一个因素是分布外的。这些结果指向了一个重要但尚未充分研究的问题，即学习观察的机制模型可以促进泛化。",
        "领域": "表示学习、泛化能力研究、计算机视觉",
        "问题": "测试表示学习方法是否能够正确推断出数据中的生成变异因素，并评估其泛化能力。",
        "动机": "探索表示学习方法在推断数据生成机制和泛化能力方面的局限性，特别是在面对从人工数据集到真实世界数据集的转变时。",
        "方法": "使用17种不同的表示学习方法在多个数据集上进行训练和测试，评估它们在重新组合、插值或外推现有变异因素时的表现。",
        "关键词": [
            "表示学习",
            "泛化能力",
            "变异因素",
            "机制模型",
            "数据集"
        ],
        "涉及的技术概念": {
            "表示学习": "研究如何从数据中自动提取有用的表示，以便于后续的机器学习任务。",
            "泛化能力": "模型在未见过的数据上表现良好的能力，是评估模型性能的重要指标。",
            "变异因素": "影响数据生成和表现的可变因素，理解这些因素有助于提高模型的泛化能力。"
        },
        "success": true
    },
    {
        "order": 1066,
        "title": "Visual Representation Learning over Latent Domains",
        "html": "https://iclr.cc//virtual/2022/poster/5897",
        "abstract": "A fundamental shortcoming of deep neural networks is their specialization to a single task and domain. While multi-domain learning enables the learning of compact models that span multiple visual domains, these rely on the presence of domain labels, in turn requiring laborious curation of datasets. This paper proposes a less explored, but highly realistic new setting called latent domain learning: learning over data from different domains, without access to domain annotations. Experiments show that this setting is challenging for standard models and existing multi-domain approaches, calling for new customized solutions: a sparse adaptation strategy is formulated which enhances performance by accounting for latent domains in data. Our method can be paired seamlessly with existing models, and benefits conceptually related tasks, e.g. empirical fairness problems and long-tailed recognition.",
        "conference": "ICLR",
        "中文标题": "潜在域上的视觉表示学习",
        "摘要翻译": "深度神经网络的一个基本缺陷是它们专一于单一任务和领域。虽然多领域学习能够学习跨越多个视觉领域的紧凑模型，但这些模型依赖于领域标签的存在，进而需要繁琐的数据集整理工作。本文提出了一种较少探索但高度现实的新设置，称为潜在领域学习：在没有领域注释的情况下，对不同领域的数据进行学习。实验表明，这种设置对于标准模型和现有的多领域方法具有挑战性，需要新的定制解决方案：提出了一种稀疏适应策略，通过考虑数据中的潜在领域来提升性能。我们的方法可以与现有模型无缝配对，并且有益于概念上相关的任务，例如经验公平性问题和长尾识别。",
        "领域": "多领域学习、视觉表示学习、长尾识别",
        "问题": "在缺乏领域标注的情况下，如何有效地学习跨越多个视觉领域的数据表示。",
        "动机": "解决深度神经网络在缺乏领域标注时难以适应多领域学习的问题，提出一种无需领域注释的潜在领域学习方法。",
        "方法": "提出了一种稀疏适应策略，通过考虑数据中的潜在领域来提升模型性能，该方法可以与现有模型无缝集成。",
        "关键词": [
            "潜在领域学习",
            "稀疏适应策略",
            "多领域学习",
            "视觉表示学习",
            "长尾识别"
        ],
        "涉及的技术概念": {
            "潜在领域学习": "在没有领域注释的情况下，对不同领域的数据进行学习的技术。",
            "稀疏适应策略": "通过考虑数据中的潜在领域来提升模型性能的方法。",
            "多领域学习": "学习跨越多个视觉领域的紧凑模型的技术。"
        },
        "success": true
    },
    {
        "order": 1067,
        "title": "ViTGAN: Training GANs with Vision Transformers",
        "html": "https://iclr.cc//virtual/2022/poster/6287",
        "abstract": "Recently, Vision Transformers (ViTs) have shown competitive performance on image recognition while requiring less vision-specific inductive biases. In this paper, we investigate if such performance can be extended to image generation. To this end, we integrate the ViT architecture into generative adversarial networks (GANs). For ViT discriminators, we observe that existing regularization methods for GANs interact poorly with self-attention, causing serious instability during training. To resolve this issue, we introduce several novel regularization techniques for training GANs with ViTs. For ViT generators, we examine architectural choices for latent and pixel mapping layers to faciliate convergence. Empirically, our approach, named ViTGAN, achieves comparable performance to the leading CNN- based GAN models on three datasets: CIFAR-10, CelebA, and LSUN bedroom.",
        "conference": "ICLR",
        "中文标题": "ViTGAN：使用视觉变换器训练生成对抗网络",
        "摘要翻译": "最近，视觉变换器（ViTs）在图像识别任务上展现了与卷积神经网络相竞争的性能，同时需要更少的视觉特定归纳偏置。本文探讨了是否可以将这种性能扩展到图像生成领域。为此，我们将ViT架构集成到生成对抗网络（GANs）中。对于ViT判别器，我们观察到现有的GAN正则化方法与自注意力机制交互不佳，导致训练过程中的严重不稳定。为解决这一问题，我们引入了几种新颖的正则化技术来训练带有ViTs的GANs。对于ViT生成器，我们研究了潜在和像素映射层的架构选择以促进收敛。实验上，我们的方法名为ViTGAN，在CIFAR-10、CelebA和LSUN bedroom三个数据集上实现了与领先的基于CNN的GAN模型相当的性能。",
        "领域": "生成对抗网络、图像生成、视觉变换器",
        "问题": "如何将视觉变换器（ViTs）的性能扩展到图像生成领域，并解决训练过程中的不稳定性问题。",
        "动机": "探索视觉变换器在图像生成领域的应用潜力，解决现有GAN正则化方法与自注意力机制交互不佳导致的训练不稳定问题。",
        "方法": "集成ViT架构到GANs中，引入新的正则化技术以稳定训练，研究ViT生成器的架构选择以促进收敛。",
        "关键词": [
            "视觉变换器",
            "生成对抗网络",
            "图像生成",
            "正则化技术",
            "自注意力机制"
        ],
        "涉及的技术概念": {
            "视觉变换器（ViTs）": "一种基于自注意力机制的图像识别架构，本文中用于扩展GANs在图像生成领域的应用。",
            "生成对抗网络（GANs）": "一种通过对抗过程训练生成模型的框架，本文中与ViTs结合用于图像生成。",
            "自注意力机制": "ViTs中的核心技术，用于捕捉图像中的长距离依赖关系，但在GANs训练中与现有正则化方法交互不佳。"
        },
        "success": true
    },
    {
        "order": 1068,
        "title": "Vitruvion: A Generative Model of Parametric CAD Sketches",
        "html": "https://iclr.cc//virtual/2022/poster/6237",
        "abstract": "Parametric computer-aided design (CAD) tools are the predominant way that engineers specify physical structures, from bicycle pedals to airplanes to printed circuit boards. The key characteristic of parametric CAD is that design intent is encoded not only via geometric primitives, but also by parameterized constraints between the elements. This relational specification can be viewed as the construction of a constraint program, allowing edits to coherently propagate to other parts of the design. Machine learning offers the intriguing possibility of accelerating the design process via generative modeling of these structures, enabling new tools such as autocompletion, constraint inference, and conditional synthesis. In this work, we present such an approach to generative modeling of parametric CAD sketches, which constitute the basic computational building blocks of modern mechanical design. Our model, trained on real-world designs from the SketchGraphs dataset, autoregressively synthesizes sketches as sequences of primitives, with initial coordinates, and constraints that reference back to the sampled primitives. As samples from the model match the constraint graph representation used in standard CAD software, they may be directly imported, solved, and edited according to downstream design tasks. In addition, we condition the model on various contexts, including partial sketches (primers) and images of hand-drawn sketches. Evaluation of the proposed approach demonstrates its ability to synthesize realistic CAD sketches and its potential to aid the mechanical design workflow.",
        "conference": "ICLR",
        "中文标题": "Vitruvion：参数化CAD草图的生成模型",
        "摘要翻译": "参数化计算机辅助设计（CAD）工具是工程师指定物理结构的主要方式，从自行车踏板到飞机再到印刷电路板。参数化CAD的关键特征在于，设计意图不仅通过几何基元编码，还通过元素之间的参数化约束编码。这种关系规范可以被视为约束程序的构建，允许编辑连贯地传播到设计的其他部分。机器学习通过生成这些结构的模型，提供了加速设计过程的有趣可能性，实现了诸如自动完成、约束推断和条件合成等新工具。在这项工作中，我们提出了这样一种参数化CAD草图的生成建模方法，这些草图构成了现代机械设计的基本计算构建块。我们的模型在SketchGraphs数据集上的真实设计上进行训练，自回归地合成草图作为基元序列，具有初始坐标和引用回采样基元的约束。由于模型样本与标准CAD软件中使用的约束图表示匹配，它们可以直接导入、解决并根据下游设计任务进行编辑。此外，我们还在各种上下文条件下对模型进行条件化，包括部分草图（引物）和手绘草图的图像。对所提出方法的评估展示了其合成真实CAD草图的能力及其辅助机械设计流程的潜力。",
        "领域": "计算机辅助设计、生成模型、机械设计自动化",
        "问题": "如何通过机器学习加速参数化CAD设计过程，实现自动完成、约束推断和条件合成等新工具。",
        "动机": "探索利用生成模型加速和优化参数化CAD设计流程，提高设计效率和创新性。",
        "方法": "提出了一种基于SketchGraphs数据集训练的生成模型，该模型能够自回归地合成参数化CAD草图，支持直接导入标准CAD软件进行进一步编辑和应用。",
        "关键词": [
            "参数化CAD",
            "生成模型",
            "机械设计",
            "自动完成",
            "约束推断"
        ],
        "涉及的技术概念": {
            "参数化CAD": "一种设计方法，通过几何基元和参数化约束编码设计意图，支持设计的灵活修改和更新。",
            "生成模型": "利用机器学习技术生成新的设计草图，加速设计过程并实现创新设计。",
            "自回归合成": "一种序列生成技术，逐步构建草图作为基元和约束的序列，确保设计的连贯性和可编辑性。"
        },
        "success": true
    },
    {
        "order": 1069,
        "title": "VOS: Learning What You Don't Know by Virtual Outlier Synthesis",
        "html": "https://iclr.cc//virtual/2022/poster/6052",
        "abstract": "Out-of-distribution (OOD) detection has received much attention lately due to its importance in the safe deployment of neural networks. One of the key challenges is that models lack supervision signals from unknown data, and as a result, can produce overconfident predictions on OOD data. Previous approaches rely on real outlier datasets for model regularization, which can be costly and sometimes infeasible to obtain in practice. In this paper, we present VOS, a novel framework for OOD detection by adaptively synthesizing virtual outliers that can meaningfully regularize the model's decision boundary during training. Specifically, VOS samples virtual outliers from the low-likelihood region of the class-conditional distribution estimated in the feature space. Alongside,  we introduce a novel unknown-aware training objective,  which contrastively shapes the uncertainty space between the ID data and synthesized outlier data. VOS achieves competitive performance on both object detection and image classification models, reducing the  FPR95 by up to 7.87% compared to the previous best method on object detectors. Code is available at https://github.com/deeplearning-wisc/vos.",
        "conference": "ICLR",
        "中文标题": "VOS：通过虚拟异常合成学习未知内容",
        "摘要翻译": "由于在神经网络安全部署中的重要性，分布外（OOD）检测最近受到了广泛关注。其中一个关键挑战是模型缺乏来自未知数据的监督信号，因此可能对OOD数据产生过度自信的预测。先前的方法依赖于真实异常数据集进行模型正则化，这在实践中可能成本高昂且有时不可行。在本文中，我们提出了VOS，一种通过自适应合成虚拟异常来在训练过程中有意义地正则化模型决策边界的新框架。具体来说，VOS从特征空间中估计的类条件分布的低似然区域采样虚拟异常。同时，我们引入了一种新颖的未知感知训练目标，它对比性地塑造了ID数据和合成异常数据之间的不确定性空间。VOS在目标检测和图像分类模型上都实现了竞争性的性能，与目标检测器上先前的最佳方法相比，FPR95降低了高达7.87%。代码可在https://github.com/deeplearning-wisc/vos获取。",
        "领域": "异常检测、目标检测、图像分类",
        "问题": "解决神经网络在分布外数据上产生过度自信预测的问题",
        "动机": "由于缺乏未知数据的监督信号，模型在分布外数据上可能产生不可靠的预测，需要一种成本效益高的方法来提高模型的泛化能力",
        "方法": "通过自适应合成虚拟异常并引入未知感知训练目标，对比性地塑造ID数据和合成异常数据之间的不确定性空间",
        "关键词": [
            "分布外检测",
            "虚拟异常合成",
            "未知感知训练",
            "模型正则化",
            "决策边界优化"
        ],
        "涉及的技术概念": {
            "虚拟异常合成": "从类条件分布的低似然区域采样虚拟异常，用于模型训练",
            "未知感知训练目标": "一种新颖的训练目标，通过对比ID数据和合成异常数据来优化模型的不确定性空间",
            "模型正则化": "通过合成异常数据对模型进行正则化，防止在分布外数据上的过度自信预测"
        },
        "success": true
    },
    {
        "order": 1070,
        "title": "W-CTC: a Connectionist Temporal Classification Loss with Wild Cards",
        "html": "https://iclr.cc//virtual/2022/poster/6093",
        "abstract": "Connectionist Temporal Classification (CTC) loss is commonly used in sequence learning applications. For example, in Automatic Speech Recognition (ASR) task, the training data consists of pairs of audio (input sequence) and text (output label),without temporal alignment information. Standard CTC computes a loss by aggregating over all possible alignment paths, that map the entire sequence to the entire label (full alignment). However, in practice, there are often cases where the label is incomplete. Specifically, we solve the partial alignment problem where the label only matches a middle part of the sequence. This paper proposes the wild-card CTC (W-CTC) to address this issue, by padding wild-cards at both ends of the labels. Consequently, the proposed W-CTC improves the standard CTC via aggregating  over even more alignment paths. Evaluations on a number of tasks in speech and vision domains, show that the proposed W-CTC consistently outperforms the standard CTC by a large margin when label is incomplete. The effectiveness of the proposed method is further confirmed in an ablation study.",
        "conference": "ICLR",
        "中文标题": "W-CTC：一种带有通配符的连接时序分类损失",
        "摘要翻译": "连接时序分类（CTC）损失通常用于序列学习应用中。例如，在自动语音识别（ASR）任务中，训练数据由音频（输入序列）和文本（输出标签）对组成，没有时间对齐信息。标准CTC通过聚合所有可能的对齐路径来计算损失，这些路径将整个序列映射到整个标签（完全对齐）。然而，在实践中，经常存在标签不完整的情况。具体来说，我们解决了标签仅匹配序列中间部分的局部对齐问题。本文提出了通配符CTC（W-CTC）来解决这个问题，通过在标签的两端填充通配符。因此，提出的W-CTC通过聚合更多的对齐路径来改进标准CTC。在语音和视觉领域的多个任务上的评估表明，当标签不完整时，提出的W-CTC始终以较大幅度优于标准CTC。消融研究进一步证实了所提出方法的有效性。",
        "领域": "自动语音识别, 序列学习, 计算机视觉与语音结合",
        "问题": "解决在序列学习中标签不完整时的局部对齐问题",
        "动机": "改进标准CTC在处理不完整标签时的性能",
        "方法": "通过在标签两端填充通配符，扩展CTC的对齐路径，以处理不完整的标签",
        "关键词": [
            "连接时序分类",
            "通配符",
            "局部对齐",
            "自动语音识别",
            "序列学习"
        ],
        "涉及的技术概念": {
            "连接时序分类（CTC）": "一种用于序列学习中的损失函数，允许模型在没有精确时间对齐的情况下学习输入和输出序列之间的映射",
            "通配符": "在W-CTC中用于扩展标签的符号，允许模型处理不完整的标签",
            "局部对齐": "指标签仅匹配输入序列的一部分，W-CTC通过引入通配符来处理这种情况"
        },
        "success": true
    },
    {
        "order": 1071,
        "title": "WeakM3D: Towards Weakly Supervised Monocular 3D Object Detection",
        "html": "https://iclr.cc//virtual/2022/poster/5913",
        "abstract": "Monocular 3D object detection is one of the most challenging tasks in 3D scene understanding. Due to the ill-posed nature of monocular imagery, existing monocular 3D detection methods highly rely on training with the manually annotated 3D box labels on the LiDAR point clouds. This annotation process is very laborious and expensive. To dispense with the reliance on 3D box labels, in this paper we explore the weakly supervised monocular 3D detection. Specifically, we first detect 2D boxes on the image. Then, we adopt the generated 2D boxes to select corresponding RoI LiDAR points as the weak supervision. Eventually, we adopt a network to predict 3D boxes which can tightly align with associated RoI LiDAR points. This network is learned by minimizing our newly-proposed 3D alignment loss between the 3D box estimates and the corresponding RoI LiDAR points. We will illustrate the potential challenges of the above learning problem and resolve these challenges by introducing several effective designs into our method. Codes will be available at https://github.com/SPengLiang/WeakM3D.",
        "conference": "ICLR",
        "中文标题": "WeakM3D：迈向弱监督的单目3D目标检测",
        "摘要翻译": "单目3D目标检测是3D场景理解中最具挑战性的任务之一。由于单目图像的病态性质，现有的单目3D检测方法高度依赖于在LiDAR点云上手动标注的3D框标签进行训练。这一标注过程非常费力且昂贵。为了摆脱对3D框标签的依赖，本文探索了弱监督的单目3D检测。具体来说，我们首先在图像上检测2D框。然后，我们采用生成的2D框来选择相应的RoI LiDAR点作为弱监督。最终，我们采用一个网络来预测能够与相关RoI LiDAR点紧密对齐的3D框。该网络通过学习最小化我们新提出的3D对齐损失（在3D框估计和相应的RoI LiDAR点之间）来进行训练。我们将阐述上述学习问题的潜在挑战，并通过在我们的方法中引入几种有效设计来解决这些挑战。代码将在https://github.com/SPengLiang/WeakM3D 上提供。",
        "领域": "单目3D目标检测",
        "问题": "减少对昂贵3D标注数据的依赖，实现弱监督下的单目3D目标检测",
        "动机": "现有的单目3D检测方法需要大量手动标注的3D框标签，这一过程既费时又昂贵。为了降低这一成本，研究探索了弱监督方法。",
        "方法": "通过检测2D框并利用其选择RoI LiDAR点作为弱监督，采用网络预测与LiDAR点对齐的3D框，并通过最小化3D对齐损失进行训练。",
        "关键词": [
            "弱监督学习",
            "单目3D检测",
            "LiDAR点云",
            "3D对齐损失",
            "RoI选择"
        ],
        "涉及的技术概念": {
            "弱监督学习": "在缺乏完整标注数据的情况下，利用部分或间接的监督信息进行模型训练。",
            "3D对齐损失": "新提出的损失函数，用于衡量预测的3D框与RoI LiDAR点之间的对齐程度，优化模型预测的准确性。",
            "RoI选择": "基于2D检测框从LiDAR点云中选择相关区域（RoI），作为弱监督信号指导3D框的预测。"
        },
        "success": true
    },
    {
        "order": 1072,
        "title": "Weighted Training for Cross-Task Learning",
        "html": "https://iclr.cc//virtual/2022/poster/7203",
        "abstract": "In this paper, we introduce Target-Aware Weighted Training (TAWT), a weighted training algorithm for cross-task learning based on minimizing a representation-based task distance between the source and target tasks. We show that TAWT is easy to implement, is computationally efficient, requires little hyperparameter tuning, and enjoys non-asymptotic learning-theoretic guarantees. The effectiveness of TAWT is corroborated through extensive experiments with BERT on four sequence tagging tasks in natural language processing (NLP), including part-of-speech (PoS) tagging, chunking, predicate detection, and named entity recognition (NER). As a byproduct, the proposed representation-based task distance allows one to reason in a theoretically principled way about several critical aspects of cross-task learning, such as the choice of the source data and the impact of fine-tuning.",
        "conference": "ICLR",
        "中文标题": "跨任务学习的加权训练",
        "摘要翻译": "本文介绍了目标感知加权训练（TAWT），这是一种基于最小化源任务与目标任务之间基于表示的任务距离的加权训练算法，用于跨任务学习。我们展示了TAWT易于实现、计算效率高、需要很少的超参数调整，并且享有非渐进的学习理论保证。通过在自然语言处理（NLP）中的四个序列标记任务（包括词性（PoS）标记、分块、谓词检测和命名实体识别（NER））上使用BERT进行的广泛实验，验证了TAWT的有效性。作为副产品，所提出的基于表示的任务距离允许以一种理论上合理的方式推理跨任务学习的几个关键方面，例如源数据的选择和微调的影响。",
        "领域": "自然语言处理与视觉结合, 序列标记, 跨任务学习",
        "问题": "如何在跨任务学习中有效地利用源任务的知识来提升目标任务的性能",
        "动机": "探索一种能够减少超参数调整、计算高效且具有理论保证的跨任务学习方法",
        "方法": "提出目标感知加权训练（TAWT）算法，通过最小化源任务与目标任务之间的表示距离来实现知识迁移",
        "关键词": [
            "跨任务学习",
            "加权训练",
            "自然语言处理",
            "序列标记",
            "BERT"
        ],
        "涉及的技术概念": {
            "目标感知加权训练（TAWT）": "一种加权训练算法，通过最小化源任务与目标任务之间的表示距离来促进知识迁移",
            "表示基于的任务距离": "用于衡量源任务与目标任务之间差异的度量，指导加权训练过程",
            "非渐进学习理论保证": "为TAWT算法的有效性提供了理论支持，确保其在有限数据下的性能"
        },
        "success": true
    },
    {
        "order": 1073,
        "title": "What Do We Mean by Generalization in Federated Learning?",
        "html": "https://iclr.cc//virtual/2022/poster/6652",
        "abstract": "Federated learning data is drawn from a distribution of distributions: clients are drawn from a meta-distribution, and their data are drawn from local data distributions. Generalization studies in federated learning should separate performance gaps from unseen client data (out-of-sample gap) from performance gaps from unseen client distributions (participation gap). In this work, we propose a framework for disentangling these performance gaps. Using this framework, we observe and explain differences in behavior across natural and synthetic federated datasets, indicating that dataset synthesis strategy can be important for realistic simulations of generalization in federated learning. We propose a semantic synthesis strategy that enables realistic simulation without naturally partitioned data. Informed by our ﬁndings, we call out community suggestions for future federated learning works.",
        "conference": "ICLR",
        "中文标题": "联邦学习中的泛化意味着什么？",
        "摘要翻译": "联邦学习的数据来源于分布的分布：客户端来自于一个元分布，而它们的数据则来自于本地数据分布。联邦学习中的泛化研究应当将未见客户端数据的性能差距（样本外差距）与未见客户端分布的性能差距（参与差距）区分开来。在这项工作中，我们提出了一个框架来解开这些性能差距。利用这一框架，我们观察并解释了自然和合成联邦数据集之间行为的差异，表明数据集合成策略对于联邦学习中泛化的现实模拟可能非常重要。我们提出了一种语义合成策略，使得在没有自然分区数据的情况下也能进行现实的模拟。根据我们的发现，我们为未来的联邦学习工作提出了社区建议。",
        "领域": "联邦学习、机器学习泛化、数据分布",
        "问题": "如何区分和解决联邦学习中的样本外差距和参与差距问题。",
        "动机": "为了更准确地理解和评估联邦学习模型在未见数据和分布上的泛化能力。",
        "方法": "提出了一个框架来区分样本外差距和参与差距，并开发了一种语义合成策略以在没有自然分区数据的情况下进行现实模拟。",
        "关键词": [
            "联邦学习",
            "泛化",
            "数据分布",
            "语义合成",
            "性能差距"
        ],
        "涉及的技术概念": {
            "样本外差距": "指模型在未见过的客户端数据上的性能差距。",
            "参与差距": "指模型在未见过的客户端分布上的性能差距。",
            "语义合成策略": "一种在没有自然分区数据的情况下，模拟现实联邦学习场景的数据合成方法。"
        },
        "success": true
    },
    {
        "order": 1074,
        "title": "What Happens after SGD Reaches Zero Loss? --A Mathematical Framework",
        "html": "https://iclr.cc//virtual/2022/poster/7048",
        "abstract": "Understanding the implicit bias of Stochastic Gradient Descent (SGD) is one of the key challenges in deep learning, especially for overparametrized models, where the local minimizers of the loss function $L$ can form a manifold. Intuitively, with a sufficiently small learning rate $\\eta$, SGD tracks Gradient Descent (GD) until it gets close to such manifold, where the gradient noise prevents further convergence. In such regime, Blanc et al. (2020) proved that SGD with label noise locally decreases a regularizer-like term, the sharpness of loss, $\\text{tr}[\\nabla^2 L]$. The current paper gives a general framework for such analysis by adapting ideas from Katzenberger (1991). It allows in principle a complete characterization for the regularization effect of SGD around such manifold---i.e., the 'implicit bias'---using a stochastic differential equation (SDE) describing the limiting dynamics of the parameters, which is determined jointly by the loss function and the noise covariance. This yields some new results: (1) a *global* analysis of the implicit bias valid for $\\eta^{-2}$ steps, in contrast to the local analysis of Blanc et al. (2020) that is only valid for $\\eta^{-1.6}$ steps and (2) allowing *arbitrary* noise covariance. As an application, we show with arbitrary large initialization, label noise SGD can always escape the kernel regime and only requires $O(\\kappa\\ln d)$ samples for learning an $\\kappa$-sparse overparametrized linear model in $\\mathbb{R}^d$ (Woodworth et al., 2020), while GD initialized in the kernel regime requires $\\Omega(d)$ samples. This upper bound is minimax optimal and improves the previous $\\widetilde{O}(\\kappa^2)$ upper bound (HaoChen et al., 2020).",
        "conference": "ICLR",
        "success": true,
        "中文标题": "SGD达到零损失后会发生什么？--一个数学框架",
        "摘要翻译": "理解随机梯度下降（SGD）的隐式偏差是深度学习中的关键挑战之一，特别是对于过度参数化的模型，其中损失函数L的局部极小值可以形成一个流形。直观地说，如果学习率η足够小，SGD会跟踪梯度下降（GD），直到接近这样的流形，此时梯度噪声会阻止进一步收敛。在这种情况下，Blanc等人（2020）证明，带有标签噪声的SGD局部会减小一个类似正则化项，即损失的锐度，tr[∇²L]。本文通过借鉴Katzenberger（1991）的思想，给出了这种分析的通用框架。原则上，它允许对SGD在流形周围的正则化效应进行完整的表征——即“隐式偏差”——使用描述参数极限动态的随机微分方程（SDE），该方程由损失函数和噪声协方差共同决定。这产生了一些新的结果：（1）对η⁻²步有效的隐式偏差的*全局*分析，与Blanc等人（2020）的局部分析相比，后者仅对η⁻¹.⁶步有效；（2）允许*任意*噪声协方差。作为一个应用，我们证明了对于任意大的初始化，标签噪声SGD总是可以逃脱核机制，并且只需要O(κln d)个样本来学习在ℝᵈ中的κ-稀疏过度参数化线性模型（Woodworth等人，2020），而初始化在核机制中的GD需要Ω(d)个样本。这个上界是极小极大最优的，并且改进了之前的Õ(κ²)上界（HaoChen等人，2020）。",
        "领域": "优化算法、随机梯度下降、泛化能力",
        "问题": "过度参数化模型中，随机梯度下降（SGD）如何影响模型的泛化能力，以及其隐式偏差是什么？",
        "动机": "旨在理解和量化随机梯度下降（SGD）在深度学习，特别是过度参数化模型中的隐式正则化效应，以及在高噪声环境下SGD的收敛行为和泛化性能。",
        "方法": "通过构建一个通用的数学框架，利用随机微分方程（SDE）来描述SGD参数的极限动态，从而分析SGD的隐式偏差。",
        "关键词": [
            "随机梯度下降",
            "隐式偏差",
            "泛化",
            "随机微分方程",
            "过度参数化模型"
        ],
        "涉及的技术概念": {
            "随机梯度下降（SGD）": "一种优化算法，用于最小化损失函数，通过随机选择样本来更新模型参数。",
            "隐式偏差": "指优化算法在解决优化问题时，除了显式的正则化项外，算法本身所固有的偏好，影响解的性质。"
        }
    },
    {
        "order": 1075,
        "title": "What Makes Better Augmentation Strategies? Augment Difficult but Not too Different",
        "html": "https://iclr.cc//virtual/2022/poster/6037",
        "abstract": "The practice of data augmentation has been extensively used to boost the performance of deep neural networks for various NLP tasks. It is more effective when only a limited number of labeled samples is available, e.g., low-data or class-imbalanced regimes. Most current augmentation techniques rely on parameter tuning or inherent randomness; hence, their effectiveness largely varies on the tasks. To efficiently find the best augmentation strategy for each task, learning data augmentation policy is a promising solution, but the question of what makes a good augmentation in NLP tasks and how to design the reward function for learning a good policy remains under-explored. To answer this, we hypothesize that good data augmentation should construct more diverse and challenging samples for providing informative training signals, while avoiding the risk of losing the semantics of original samples. Therefore, we design a novel reward function for updating the augmentation policy to construct difficult but not too different samples (DND). Particularly, we jointly optimize a data augmentation policy while training the model, to construct the augmented samples with low confidence but a high semantic similarity with original ones. In addition, we introduce a sample re-weighting scheme to focus on difficult augmented samples after the original ones are learned confidently for more effective learning from the augmented ones. Our learning-based augmentation outperforms the recent state-of-the-art augmentation schemes on various text classification tasks and GLUE benchmark by successfully discovering the effective augmentations for each task. Remarkably, our method is more effective on the challenging low-data and class-imbalanced regimes, and the learned augmentation policy is well-transferable to the different tasks and models. ",
        "conference": "ICLR",
        "success": true,
        "中文标题": "什么造就了更好的数据增强策略？增强困难但不过于不同",
        "摘要翻译": "数据增强的实践已被广泛用于提升深度神经网络在各种NLP任务中的性能。当仅有有限数量的标记样本可用时，例如在数据量少或类别不平衡的情况下，它更为有效。当前大多数增强技术依赖于参数调整或固有的随机性；因此，它们的有效性在很大程度上因任务而异。为了有效地为每个任务找到最佳的增强策略，学习数据增强策略是一个有前景的解决方案，但在NLP任务中什么构成了好的增强以及如何设计奖励函数以学习好的策略仍然未被充分探索。为了回答这个问题，我们假设好的数据增强应该构建更多样化和具有挑战性的样本，以提供信息丰富的训练信号，同时避免失去原始样本语义的风险。因此，我们设计了一种新颖的奖励函数，用于更新增强策略以构建困难但不过于不同的样本（DND）。特别是，我们在训练模型的同时联合优化数据增强策略，以构建具有低置信度但与原始样本具有高语义相似性的增强样本。此外，我们引入了一个样本重加权方案，在原始样本被自信学习后，专注于困难的增强样本，以便更有效地从增强样本中学习。我们基于学习的增强方法在各种文本分类任务和GLUE基准测试中优于最近的最先进增强方案，成功地为每个任务发现了有效的增强。值得注意的是，我们的方法在具有挑战性的数据量少和类别不平衡的情况下更为有效，并且学习到的增强策略能够很好地转移到不同的任务和模型中。",
        "领域": "自然语言处理与视觉结合、文本分类、数据增强",
        "问题": "如何为NLP任务设计有效的数据增强策略，以及如何设计奖励函数以学习好的策略",
        "动机": "探索在NLP任务中什么构成了好的数据增强，以及如何设计奖励函数以学习好的策略，以提升模型在数据量少或类别不平衡情况下的性能",
        "方法": "设计了一种新颖的奖励函数，用于更新增强策略以构建困难但不过于不同的样本（DND），并在训练模型的同时联合优化数据增强策略，引入样本重加权方案以专注于困难的增强样本",
        "关键词": [
            "数据增强",
            "NLP任务",
            "文本分类",
            "奖励函数",
            "样本重加权"
        ],
        "涉及的技术概念": {
            "数据增强策略": "用于构建更多样化和具有挑战性的样本，以提供信息丰富的训练信号",
            "奖励函数": "设计用于更新增强策略，以构建困难但不过于不同的样本（DND）",
            "样本重加权": "在原始样本被自信学习后，专注于困难的增强样本，以便更有效地从增强样本中学习"
        }
    },
    {
        "order": 1076,
        "title": "What’s Wrong with Deep Learning in Tree Search for Combinatorial Optimization",
        "html": "https://iclr.cc//virtual/2022/poster/6426",
        "abstract": "Combinatorial optimization lies at the core of many real-world problems. Especially since the rise of graph neural networks (GNNs), the deep learning community has been developing solvers that derive solutions to NP-hard problems by learning the problem-specific solution structure. However, reproducing the results of these publications proves to be difficult. We make three contributions. First, we present an open-source benchmark suite for the NP-hard Maximum Independent Set problem, in both its weighted and unweighted variants. The suite offers a unified interface to various state-of-the-art traditional and machine learning-based solvers. Second, using our benchmark suite, we conduct an in-depth analysis of the popular guided tree search algorithm by Li et al. [NeurIPS 2018], testing various configurations on small and large synthetic and real-world graphs. By re-implementing their algorithm with a focus on code quality and extensibility, we show that the graph convolution network used in the tree search does not learn a meaningful representation of the solution structure, and can in fact be replaced by random values. Instead, the tree search relies on algorithmic techniques like graph kernelization to find good solutions. Thus, the results from the original publication are not reproducible. Third, we extend the analysis to compare the tree search implementations to other solvers, showing that the classical algorithmic solvers often are faster, while providing solutions of similar quality. Additionally, we analyze a recent solver based on reinforcement learning and observe that for this solver, the GNN is responsible for the competitive solution quality.",
        "conference": "ICLR",
        "中文标题": "深度学习在组合优化树搜索中的问题何在",
        "摘要翻译": "组合优化是许多现实世界问题的核心。特别是自从图神经网络（GNNs）兴起以来，深度学习社区一直在开发通过学习问题特定的解决方案结构来推导NP难问题解决方案的求解器。然而，重现这些出版物的结果被证明是困难的。我们做出了三个贡献。首先，我们为NP难的最大独立集问题（包括加权和非加权变体）提出了一个开源基准套件。该套件为各种最先进的传统和基于机器学习的求解器提供了统一的接口。其次，利用我们的基准套件，我们对Li等人[NeurIPS 2018]提出的流行的引导树搜索算法进行了深入分析，在小型和大型合成图以及现实世界图上测试了各种配置。通过以代码质量和可扩展性为重点重新实现他们的算法，我们展示了树搜索中使用的图卷积网络并没有学习到解决方案结构的有意义表示，实际上可以被随机值替代。相反，树搜索依赖于像图核化这样的算法技术来找到好的解决方案。因此，原始出版物中的结果无法重现。第三，我们将分析扩展到比较树搜索实现与其他求解器，显示经典算法求解器通常更快，同时提供类似质量的解决方案。此外，我们分析了基于强化学习的最新求解器，并观察到对于这个求解器，GNN负责竞争性的解决方案质量。",
        "领域": "组合优化、图神经网络、强化学习",
        "问题": "深度学习在组合优化树搜索中的有效性问题和结果的可重现性问题",
        "动机": "评估和验证深度学习在解决NP难组合优化问题中的实际效果，以及现有方法的可重现性",
        "方法": "开发开源基准套件，重新实现并分析引导树搜索算法，比较不同求解器的性能",
        "关键词": [
            "组合优化",
            "图神经网络",
            "树搜索",
            "最大独立集",
            "强化学习"
        ],
        "涉及的技术概念": {
            "图神经网络（GNNs）": "用于学习问题特定的解决方案结构，但在树搜索中未能有效表示解决方案结构",
            "引导树搜索算法": "一种流行的组合优化求解方法，本研究发现其依赖于算法技术而非学习到的表示",
            "图核化": "算法技术，用于在树搜索中有效减少问题规模，找到好的解决方案"
        },
        "success": true
    },
    {
        "order": 1077,
        "title": "When Can We Learn General-Sum Markov Games with a Large Number of Players Sample-Efficiently?",
        "html": "https://iclr.cc//virtual/2022/poster/7074",
        "abstract": "Multi-agent reinforcement learning has made substantial empirical progresses in solving games with a large number of players. However, theoretically, the best known sample complexity for finding a Nash equilibrium in general-sum games scales exponentially in the number of players due to the size of the joint action space, and there is a matching exponential lower bound. This paper investigates what learning goals admit better sample complexities in the setting of $m$-player general-sum Markov games with $H$ steps, $S$ states, and $A_i$ actions per player. First, we design algorithms for learning an $\\epsilon$-Coarse Correlated Equilibrium (CCE) in $\\widetilde{\\mathcal{O}}(H^5S\\max_{i\\le m} A_i / \\epsilon^2)$ episodes, and an $\\epsilon$-Correlated Equilibrium (CE) in $\\widetilde{\\mathcal{O}}(H^6S\\max_{i\\le m} A_i^2 / \\epsilon^2)$ episodes. This is the first line of results for learning CCE and CE with sample complexities polynomial in $\\max_{i\\le m} A_i$. Our algorithm for learning CE integrates an adversarial bandit subroutine which minimizes a weighted swap regret, along with several novel designs in the outer loop. Second, we consider the important special case of Markov Potential Games, and design an algorithm that learns an $\\epsilon$-approximate Nash equilibrium within $\\widetilde{\\mathcal{O}}(S\\sum_{i\\le m} A_i / \\epsilon^3)$ episodes (when only highlighting the dependence on $S$, $A_i$, and $\\epsilon$), which only depends linearly in $\\sum_{i\\le m} A_i$ and significantly improves over the existing efficient algorithm in the $\\epsilon$ dependence. Overall, our results shed light on what equilibria or structural assumptions on the game may enable sample-efficient learning with many players.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "何时我们能以样本高效的方式学习具有大量玩家的通用和马尔可夫博弈？",
        "摘要翻译": "多智能体强化学习在解决具有大量玩家的博弈方面取得了显著的经验进展。然而，从理论上讲，由于联合动作空间的规模，在通用和博弈中找到纳什均衡的最佳已知样本复杂度随着玩家数量呈指数级增长，并且存在匹配的指数下界。本文研究了在具有H步长、S个状态和每个玩家Ai个动作的m玩家通用和马尔可夫博弈的设置中，哪些学习目标可以获得更好的样本复杂度。首先，我们设计了算法，用于学习一个ε-粗略相关均衡 (CCE)，在$\\widetilde{\\mathcal{O}}(H^5S\\max_{i\\le m} A_i / \\epsilon^2)$个回合中，以及一个ε-相关均衡 (CE)，在$\\widetilde{\\mathcal{O}}(H^6S\\max_{i\\le m} A_i^2 / \\epsilon^2)$个回合中。这是学习CCE和CE的第一行结果，其样本复杂度是$\\max_{i\\le m} A_i$的多项式。我们用于学习CE的算法集成了对抗性bandit子程序，该子程序最小化加权交换后悔，以及外部循环中的几个新颖设计。其次，我们考虑了马尔可夫势博弈的重要特例，并设计了一种算法，该算法在$\\widetilde{\\mathcal{O}}(S\\sum_{i\\le m} A_i / \\epsilon^3)$个回合内学习一个ε-近似纳什均衡（当仅突出显示对S、Ai和ε的依赖性时），它仅线性依赖于$\\sum_{i\\le m} A_i$，并且显着改善了现有有效算法中对ε的依赖性。总的来说，我们的结果揭示了博弈中的哪些均衡或结构性假设可以实现具有许多玩家的样本高效学习。",
        "领域": "多智能体强化学习, 博弈论, 强化学习",
        "问题": "在多智能体马尔可夫博弈中，寻找纳什均衡的样本复杂度随着玩家数量呈指数级增长，这限制了算法在实际场景中的应用。论文旨在降低学习各种均衡所需的样本复杂度。",
        "动机": "现有的多智能体强化学习方法在解决大规模博弈问题时，样本复杂度高，效率低。研究旨在寻找更有效的算法，降低学习均衡所需的样本数量，从而推动多智能体强化学习在实际问题中的应用。",
        "方法": "论文设计了学习粗略相关均衡（CCE）和相关均衡（CE）的算法，并针对马尔可夫势博弈的特例，提出了学习近似纳什均衡的算法。算法结合了对抗性bandit子程序和新颖的外部循环设计。",
        "关键词": [
            "多智能体强化学习",
            "马尔可夫博弈",
            "纳什均衡",
            "样本复杂度",
            "相关均衡"
        ],
        "涉及的技术概念": {
            "粗略相关均衡（CCE）": "一种比纳什均衡更弱的均衡概念，要求所有玩家都不愿意单方面改变策略。论文设计了样本高效的算法来学习CCE。",
            "对抗性 Bandit": "一种在线学习算法，用于最小化累积损失。论文将其用作子程序，以优化学习相关均衡（CE）的过程。"
        }
    },
    {
        "order": 1078,
        "title": "When should agents explore?",
        "html": "https://iclr.cc//virtual/2022/poster/7009",
        "abstract": "Exploration remains a central challenge for reinforcement learning (RL). Virtually all existing methods share the feature of a *monolithic* behaviour policy that changes only gradually (at best). In contrast, the exploratory behaviours of animals and humans exhibit a rich diversity, namely including forms of *switching* between modes. This paper presents an initial study of mode-switching, non-monolithic exploration for RL. We investigate different modes to switch between, at what timescales it makes sense to switch, and what signals make for good switching triggers. We also propose practical algorithmic components that make the switching mechanism adaptive and robust, which enables flexibility without an accompanying hyper-parameter-tuning burden. Finally, we report a promising initial study on Atari, using two-mode exploration and switching at sub-episodic time-scales.",
        "conference": "ICLR",
        "中文标题": "智能体应在何时进行探索？",
        "摘要翻译": "探索仍然是强化学习（RL）面临的核心挑战。几乎所有现有方法都共享一个*单一*行为策略的特征，该策略最多只能逐渐变化。相比之下，动物和人类的探索行为展现出丰富的多样性，包括在模式之间*切换*的形式。本文对RL中的模式切换、非单一探索进行了初步研究。我们研究了不同的切换模式、在什么时间尺度上进行切换有意义，以及哪些信号可以作为良好的切换触发器。我们还提出了实用的算法组件，使切换机制具有适应性和鲁棒性，从而在不伴随超参数调整负担的情况下实现灵活性。最后，我们在Atari上报告了一项有前景的初步研究，使用双模式探索和在子情节时间尺度上的切换。",
        "领域": "强化学习",
        "问题": "如何改进强化学习中的探索策略，使其更加多样化和高效",
        "动机": "现有的强化学习方法大多采用单一且变化缓慢的探索策略，而自然界中的探索行为则表现出丰富的多样性，这激发了对于模式切换、非单一探索策略的研究",
        "方法": "研究不同的探索模式切换策略，包括切换的时间尺度和触发信号，并提出适应性强的算法组件以实现灵活的探索",
        "关键词": [
            "强化学习",
            "探索策略",
            "模式切换",
            "适应性算法",
            "Atari游戏"
        ],
        "涉及的技术概念": {
            "模式切换": "在强化学习中，探索行为在不同模式之间切换，以模拟自然界中多样化的探索策略",
            "子情节时间尺度": "在比完整情节更短的时间尺度上进行探索模式的切换，以提高探索的效率和灵活性",
            "适应性算法组件": "提出的算法组件能够自动调整探索策略，减少对超参数调整的依赖，提高模型的适应性和鲁棒性"
        },
        "success": true
    },
    {
        "order": 1079,
        "title": "When Vision Transformers Outperform ResNets without Pre-training or Strong Data Augmentations",
        "html": "https://iclr.cc//virtual/2022/poster/6357",
        "abstract": "Vision Transformers (ViTs) and MLPs signal further efforts on replacing hand-wired features or inductive biases with general-purpose neural architectures. Existing works empower the models by massive data, such as large-scale pre-training and/or repeated strong data augmentations, and still report optimization-related problems (e.g., sensitivity to initialization and learning rates). Hence, this paper investigates ViTs and MLP-Mixers from the lens of loss geometry, intending to improve the models' data efficiency at training and generalization at inference. Visualization and Hessian reveal extremely sharp local minima of converged models. By promoting smoothness with a recently proposed sharpness-aware optimizer, we substantially improve the accuracy and robustness of ViTs and MLP-Mixers on various tasks spanning supervised, adversarial, contrastive, and transfer learning (e.g., +5.3\\% and +11.0\\% top-1 accuracy on ImageNet for ViT-B/16 and Mixer-B/16, respectively, with the simple Inception-style preprocessing). We show that the improved smoothness attributes to sparser active neurons in the first few layers. The resultant ViTs outperform ResNets of similar size and throughput when trained from scratch on ImageNet without large-scale pre-training or strong data augmentations. Model checkpoints are available at \\url{https://github.com/google-research/vision_transformer}.",
        "conference": "ICLR",
        "中文标题": "当视觉变换器无需预训练或强数据增强即可超越ResNets时",
        "摘要翻译": "视觉变换器（ViTs）和MLPs标志着在用手工特征或归纳偏置替换通用神经架构方面的进一步努力。现有工作通过大量数据（如大规模预训练和/或重复的强数据增强）赋予模型能力，但仍报告了与优化相关的问题（例如，对初始化和学习率的敏感性）。因此，本文从损失几何的角度研究了ViTs和MLP-Mixers，旨在提高模型在训练时的数据效率和推理时的泛化能力。可视化和Hessian揭示了收敛模型的极尖锐局部最小值。通过使用最近提出的锐度感知优化器促进平滑性，我们显著提高了ViTs和MLP-Mixers在监督、对抗、对比和迁移学习等各种任务上的准确性和鲁棒性（例如，在ImageNet上，ViT-B/16和Mixer-B/16的top-1准确率分别提高了5.3%和11.0%，仅使用简单的Inception风格预处理）。我们展示了改进的平滑性归因于前几层中更稀疏的活跃神经元。由此产生的ViTs在从零开始在ImageNet上训练时，无需大规模预训练或强数据增强，即可超越相似大小和吞吐量的ResNets。模型检查点可在https://github.com/google-research/vision_transformer获取。",
        "领域": "视觉变换器、深度学习优化、图像分类",
        "问题": "提高视觉变换器和MLP-Mixers在训练时的数据效率和推理时的泛化能力，减少对大规模预训练和强数据增强的依赖。",
        "动机": "现有方法依赖于大量数据和复杂的数据增强技术，但仍存在优化相关的问题，如对初始化和学习率的敏感性。本研究旨在通过改进模型的平滑性，提高其性能和鲁棒性。",
        "方法": "从损失几何的角度分析ViTs和MLP-Mixers，使用锐度感知优化器促进模型平滑性，减少活跃神经元的稀疏性，从而提高模型的准确性和鲁棒性。",
        "关键词": [
            "视觉变换器",
            "MLP-Mixers",
            "锐度感知优化",
            "损失几何",
            "数据效率"
        ],
        "涉及的技术概念": {
            "视觉变换器（ViTs）": "一种基于自注意力机制的视觉处理架构，旨在替代传统的卷积神经网络，提供更通用的图像处理能力。",
            "锐度感知优化器": "一种优化技术，旨在通过促进损失函数的平滑性，提高模型的泛化能力和鲁棒性。",
            "损失几何": "研究损失函数在参数空间中的形状和特性，以理解模型的优化行为和泛化能力。"
        },
        "success": true
    },
    {
        "order": 1080,
        "title": "When, Why, and Which Pretrained GANs Are Useful?",
        "html": "https://iclr.cc//virtual/2022/poster/6642",
        "abstract": "The literature has proposed several methods to finetune pretrained GANs on new datasets, which typically results in higher performance compared to training from scratch, especially in the limited-data regime. However, despite the apparent empirical benefits of GAN pretraining, its inner mechanisms were not analyzed in-depth, and understanding of its role is not entirely clear. Moreover, the essential practical details, e.g., selecting a proper pretrained GAN checkpoint, currently do not have rigorous grounding and are typically determined by trial and error. This work aims to dissect the process of GAN finetuning. First, we show that initializing the GAN training process by a pretrained checkpoint primarily affects the model's coverage rather than the fidelity of individual samples. Second, we explicitly describe how pretrained generators and discriminators contribute to the finetuning process and explain the previous evidence on the importance of pretraining both of them. Finally, as an immediate practical benefit of our analysis, we describe a simple recipe to choose an appropriate GAN checkpoint that is the most suitable for finetuning to a particular target task. Importantly, for most of the target tasks, Imagenet-pretrained GAN, despite having poor visual quality, appears to be an excellent starting point for finetuning, resembling the typical pretraining scenario of discriminative computer vision models.",
        "conference": "ICLR",
        "中文标题": "何时、为何以及哪些预训练GAN是有用的？",
        "摘要翻译": "文献中提出了几种在新数据集上微调预训练GAN的方法，这通常比从头开始训练能获得更高的性能，特别是在数据有限的情况下。然而，尽管GAN预训练在经验上显然有益，但其内部机制尚未深入分析，对其作用的理解也不完全清楚。此外，关键的实践细节，例如选择合适的预训练GAN检查点，目前缺乏严格的基础，通常是通过试错来确定的。这项工作旨在剖析GAN微调的过程。首先，我们展示了通过预训练检查点初始化GAN训练过程主要影响模型的覆盖范围，而不是单个样本的保真度。其次，我们明确描述了预训练的生成器和判别器如何对微调过程做出贡献，并解释了先前关于预训练两者重要性的证据。最后，作为我们分析的直接实际好处，我们描述了一个简单的配方，用于选择最适合特定目标任务微调的GAN检查点。重要的是，对于大多数目标任务，尽管视觉质量较差，但Imagenet预训练的GAN似乎是微调的优秀起点，类似于判别性计算机视觉模型的典型预训练场景。",
        "领域": "生成对抗网络、图像生成、模型微调",
        "问题": "分析预训练GAN在微调过程中的作用机制，并提出选择合适预训练检查点的方法。",
        "动机": "深入理解预训练GAN在微调过程中的内部机制，解决选择合适预训练检查点缺乏理论基础的问题。",
        "方法": "通过实验分析预训练GAN检查点对模型覆盖范围和样本保真度的影响，明确预训练生成器和判别器在微调过程中的贡献，并提出选择预训练检查点的简单方法。",
        "关键词": [
            "生成对抗网络",
            "模型微调",
            "预训练",
            "图像生成",
            "检查点选择"
        ],
        "涉及的技术概念": {
            "生成对抗网络": "一种通过生成器和判别器相互对抗来生成数据的深度学习模型。",
            "模型微调": "在预训练模型的基础上，通过在新数据集上进一步训练来适应特定任务的技术。",
            "预训练检查点": "在特定任务上预训练的模型状态，用于初始化或微调模型以适应新任务。"
        },
        "success": true
    },
    {
        "order": 1081,
        "title": "Which Shortcut Cues Will DNNs Choose? A Study from the Parameter-Space Perspective",
        "html": "https://iclr.cc//virtual/2022/poster/5892",
        "abstract": "Deep neural networks (DNNs) often rely on easy–to–learn discriminatory features, or cues, that are not necessarily essential to the problem at hand. For example, ducks in an image may be recognized based on their typical background scenery, such as lakes or streams. This phenomenon, also known as shortcut learning, is emerging as a key limitation of the current generation of machine learning models. In this work, we introduce a set of experiments to deepen our understanding of shortcut learning and its implications. We design a training setup with several shortcut cues, named WCST-ML, where each cue is equally conducive to the visual recognition problem at hand. Even under equal opportunities, we observe that (1) certain cues are preferred to others, (2) solutions biased to the easy–to–learn cues tend to converge to relatively flat minima on the loss surface, and (3) the solutions focusing on those preferred cues are far more abundant in the parameter space. We explain the abundance of certain cues via their Kolmogorov (descriptional) complexity: solutions corresponding to Kolmogorov-simple cues are abundant in the parameter space and are thus preferred by DNNs. Our studies are based on the synthetic dataset DSprites and the face dataset UTKFace. In our WCST-ML, we observe that the inborn bias of models leans toward simple cues, such as color and ethnicity. Our findings emphasize the importance of active human intervention to remove the inborn model biases that may cause negative societal impacts.",
        "conference": "ICLR",
        "中文标题": "深度神经网络会选择哪些捷径线索？一项基于参数空间视角的研究",
        "摘要翻译": "深度神经网络（DNNs）常常依赖于易于学习的判别性特征或线索，这些特征或线索并不一定是解决当前问题的关键。例如，图像中的鸭子可能基于其典型的背景场景（如湖泊或溪流）被识别。这种现象，也被称为捷径学习，正成为当前一代机器学习模型的一个关键限制。在这项工作中，我们引入了一系列实验来加深对捷径学习及其影响的理解。我们设计了一个包含多个捷径线索的训练设置，名为WCST-ML，其中每个线索对当前的视觉识别问题都同样有利。即使在同等机会下，我们观察到（1）某些线索比其他线索更受青睐，（2）偏向于易于学习线索的解决方案倾向于在损失表面上收敛到相对平坦的最小值，（3）那些专注于受青睐线索的解决方案在参数空间中更为丰富。我们通过它们的Kolmogorov（描述性）复杂性来解释某些线索的丰富性：对应于Kolmogorov简单线索的解决方案在参数空间中丰富，因此被DNNs所偏好。我们的研究基于合成数据集DSprites和人脸数据集UTKFace。在我们的WCST-ML中，我们观察到模型的天生偏见倾向于简单线索，如颜色和种族。我们的发现强调了积极人为干预以消除可能导致负面社会影响的天生模型偏见的重要性。",
        "领域": "深度学习",
        "问题": "深度神经网络在视觉识别任务中倾向于选择易于学习的捷径线索，而非本质特征",
        "动机": "理解和解决深度神经网络中的捷径学习现象，以减少模型偏见及其潜在的负面社会影响",
        "方法": "设计包含多个等效捷径线索的训练设置WCST-ML，通过实验观察和分析模型对不同线索的偏好及其在参数空间中的分布",
        "关键词": [
            "捷径学习",
            "参数空间",
            "Kolmogorov复杂性",
            "模型偏见",
            "视觉识别"
        ],
        "涉及的技术概念": {
            "捷径学习": "深度神经网络倾向于依赖易于学习但不一定是本质的特征或线索进行决策的现象",
            "参数空间": "模型所有可能参数配置的集合，研究模型解决方案在其中的分布",
            "Kolmogorov复杂性": "描述对象或信息的最短描述长度，用于解释为何某些捷径线索在参数空间中更为丰富"
        },
        "success": true
    },
    {
        "order": 1082,
        "title": "Who Is the Strongest Enemy? Towards Optimal and Efficient Evasion Attacks in Deep RL",
        "html": "https://iclr.cc//virtual/2022/poster/7130",
        "abstract": "Evaluating the worst-case performance of a reinforcement learning (RL) agent under the strongest/optimal adversarial perturbations on state observations (within some constraints) is crucial for understanding the robustness of RL agents. However, finding the optimal adversary is challenging, in terms of both whether we can find the optimal attack and how efficiently we can find it. Existing works on adversarial RL either use heuristics-based methods that may not find the strongest adversary, or directly train an RL-based adversary by treating the agent as a part of the environment, which can find the optimal adversary but may become intractable in a large state space. This paper introduces a novel attacking method to find the optimal attacks through collaboration between a designed function named 'actor' and an RL-based learner named 'director''. The actor crafts state perturbations for a given policy perturbation direction, and the director learns to propose the best policy perturbation directions. Our proposed algorithm, PA-AD, is theoretically optimal and significantly more efficient than prior RL-based works in environments with large state spaces. Empirical results show that our proposed PA-AD universally outperforms state-of-the-art attacking methods in various Atari and MuJoCo environments. By applying PA-AD to adversarial training, we achieve state-of-the-art empirical robustness in multiple tasks under strong adversaries.",
        "conference": "ICLR",
        "中文标题": "谁是最强的敌人？——深度强化学习中最优高效规避攻击的探索",
        "摘要翻译": "评估强化学习（RL）智能体在状态观测上受到最强/最优对抗性扰动（在一定的约束条件下）的最坏情况表现，对于理解RL智能体的鲁棒性至关重要。然而，寻找最优对手具有挑战性，无论是在我们是否能找到最优攻击，还是在我们能多高效地找到它方面。现有的对抗性RL研究要么使用基于启发式的方法，这些方法可能找不到最强的对手，要么通过将智能体视为环境的一部分来直接训练基于RL的对手，这种方法可以找到最优对手，但在大状态空间中可能变得难以处理。本文介绍了一种新颖的攻击方法，通过一个名为‘演员’的设计函数和一个名为‘导演’的基于RL的学习者之间的协作来寻找最优攻击。演员为给定的策略扰动方向制作状态扰动，而导演学习提出最佳的策略扰动方向。我们提出的算法PA-AD在理论上是最优的，并且在具有大状态空间的环境中比之前基于RL的工作显著更高效。实证结果表明，我们提出的PA-AD在各种Atari和MuJoCo环境中普遍优于最先进的攻击方法。通过将PA-AD应用于对抗训练，我们在多个任务中在强对手下实现了最先进的实证鲁棒性。",
        "领域": "对抗性强化学习、深度强化学习、智能体鲁棒性",
        "问题": "如何在深度强化学习中高效地找到最优的对抗性扰动，以评估智能体的最坏情况表现。",
        "动机": "理解并提升强化学习智能体在对抗性扰动下的鲁棒性，特别是在大状态空间中高效寻找最优对抗性攻击的挑战。",
        "方法": "提出了一种新颖的攻击方法PA-AD，通过‘演员’和‘导演’的协作来寻找最优攻击，其中‘演员’负责制作状态扰动，‘导演’学习提出最佳的策略扰动方向。",
        "关键词": [
            "对抗性强化学习",
            "最优攻击",
            "智能体鲁棒性",
            "PA-AD算法",
            "大状态空间"
        ],
        "涉及的技术概念": {
            "演员-导演协作": "通过‘演员’和‘导演’的协作机制，分别负责状态扰动制作和策略扰动方向学习，以高效寻找最优对抗性攻击。",
            "PA-AD算法": "一种理论上最优且高效的对抗性攻击算法，特别适用于大状态空间的深度强化学习环境。",
            "对抗训练": "通过引入对抗性扰动来训练模型，以提高其在对抗性环境中的鲁棒性和性能。"
        },
        "success": true
    },
    {
        "order": 1083,
        "title": "Who Is Your Right Mixup Partner in Positive and Unlabeled Learning",
        "html": "https://iclr.cc//virtual/2022/poster/5904",
        "abstract": "Positive and Unlabeled (PU) learning targets inducing a binary classifier from weak training datasets of positive and unlabeled instances, which arise in many real-world applications. In this paper, we propose a novel PU learning method, namely Positive and unlabeled learning with Partially Positive Mixup (P3Mix), which simultaneously benefits from data augmentation and supervision correction with a heuristic mixup technique. To be specific, we take inspiration from the directional boundary deviation phenomenon observed in our preliminary experiments, where the learned PU boundary tends to deviate from the fully supervised boundary towards the positive side. For the unlabeled instances with ambiguous predictive results, we select their mixup partners from the positive instances around the learned PU boundary, so as to transform them into augmented instances near to the boundary yet with more precise supervision. Accordingly, those augmented instances may push the learned PU boundary towards the fully supervised boundary, thereby improving the classification performance. Comprehensive experimental results demonstrate the effectiveness of the heuristic mixup technique in PU learning and show that P3Mix can consistently outperform the state-of-the-art PU learning methods.",
        "conference": "ICLR",
        "中文标题": "在正例与未标记学习中谁是你的正确混合伙伴",
        "摘要翻译": "正例与未标记（PU）学习旨在从正例和未标记实例的弱训练数据集中诱导出二元分类器，这在许多现实世界的应用中都有出现。在本文中，我们提出了一种新颖的PU学习方法，即部分正例混合的正例与未标记学习（P3Mix），该方法通过启发式混合技术同时从数据增强和监督校正中受益。具体来说，我们从初步实验中观察到的方向性边界偏差现象中获得灵感，其中学习到的PU边界倾向于从完全监督的边界向正例侧偏离。对于预测结果模糊的未标记实例，我们从学习到的PU边界周围的正例中选择它们的混合伙伴，以便将它们转化为靠近边界但具有更精确监督的增强实例。因此，这些增强实例可能会将学习到的PU边界推向完全监督的边界，从而提高分类性能。全面的实验结果证明了启发式混合技术在PU学习中的有效性，并表明P3Mix可以持续优于最先进的PU学习方法。",
        "领域": "正例与未标记学习",
        "问题": "如何在正例与未标记学习中通过数据增强和监督校正提高分类性能",
        "动机": "观察到学习到的PU边界倾向于从完全监督的边界向正例侧偏离的现象，希望通过混合技术改善这一偏差",
        "方法": "提出P3Mix方法，通过启发式混合技术选择正例作为未标记实例的混合伙伴，生成靠近边界且具有更精确监督的增强实例",
        "关键词": [
            "正例与未标记学习",
            "数据增强",
            "监督校正",
            "混合技术",
            "分类性能"
        ],
        "涉及的技术概念": {
            "正例与未标记学习": "一种从正例和未标记实例的弱训练数据集中诱导出二元分类器的学习方法",
            "启发式混合技术": "通过选择特定的混合伙伴来生成增强实例，以改善模型的监督和学习边界",
            "方向性边界偏差": "学习到的PU边界倾向于从完全监督的边界向正例侧偏离的现象，P3Mix方法旨在纠正这一偏差"
        },
        "success": true
    },
    {
        "order": 1084,
        "title": "Why Propagate Alone? Parallel Use of Labels and Features on Graphs",
        "html": "https://iclr.cc//virtual/2022/poster/6772",
        "abstract": "One of the challenges of graph-based semi-supervised learning over ordinary supervised learning for classification tasks lies in label utilization.  The direct use of ground-truth labels in graphs for training purposes can result in a parametric model learning trivial degenerate solutions (e.g., an identity mapping from input to output).  In addressing this issue, a label trick has recently been proposed in the literature and applied to a wide range of graph neural network (GNN) architectures, achieving state-of-the-art results on various datasets.  The essential idea is to randomly split the observed labels on the graph and use a fraction of them as input to the model (along with original node features), and predict the remaining fraction.  Despite its success in enabling GNNs to propagate features and labels simultaneously, this approach has never been analyzed from a theoretical perspective, nor fully explored across certain natural use cases.  In this paper, we demonstrate that under suitable settings, this stochastic trick can be reduced to a more interpretable deterministic form, allowing us to better explain its behavior, including an emergent regularization effect, and motivate broader application scenarios.  Our experimental results corroborate these analyses while also demonstrating improved node classification performance applying the label trick in new domains.",
        "conference": "ICLR",
        "中文标题": "为何单独传播？图中标签与特征的并行使用",
        "摘要翻译": "基于图的半监督学习在分类任务中相对于普通监督学习的一个挑战在于标签的利用。直接在图中使用真实标签进行训练可能导致参数模型学习到平凡的退化解（例如，从输入到输出的恒等映射）。针对这一问题，文献中最近提出了一种标签技巧，并将其应用于广泛的图神经网络（GNN）架构，在各种数据集上取得了最先进的结果。其核心思想是随机分割图中的观察标签，并将其中一部分作为模型的输入（与原始节点特征一起），预测剩余部分。尽管这种方法在使GNN能够同时传播特征和标签方面取得了成功，但从理论角度从未对其进行分析，也未在某些自然用例中充分探索。在本文中，我们证明在适当的设置下，这种随机技巧可以简化为更可解释的确定性形式，使我们能够更好地解释其行为，包括一种新兴的正则化效应，并激发更广泛的应用场景。我们的实验结果证实了这些分析，同时也在新领域中应用标签技巧展示了改进的节点分类性能。",
        "领域": "图神经网络、半监督学习、节点分类",
        "问题": "解决图神经网络在半监督学习中标签利用不足和可能学习到退化解的问题",
        "动机": "探索并理论分析标签技巧在图神经网络中的应用，以提升标签的利用效率和模型的泛化能力",
        "方法": "提出将随机标签技巧转化为确定性形式的方法，以增强模型行为的可解释性，并探索其在更广泛场景下的应用",
        "关键词": [
            "图神经网络",
            "半监督学习",
            "标签技巧",
            "节点分类",
            "正则化效应"
        ],
        "涉及的技术概念": {
            "标签技巧": "一种在图神经网络中随机分割并使用部分标签作为输入的技术，旨在提升模型的泛化能力和标签利用效率",
            "图神经网络": "一种专门用于处理图结构数据的深度学习模型，能够捕捉节点间复杂的依赖关系",
            "正则化效应": "通过特定技术手段防止模型过拟合，提升模型在未见数据上的表现，本文中标签技巧展现出的一种效应"
        },
        "success": true
    },
    {
        "order": 1085,
        "title": "Wiring Up Vision: Minimizing Supervised Synaptic Updates Needed to Produce a Primate Ventral Stream",
        "html": "https://iclr.cc//virtual/2022/poster/6890",
        "abstract": "After training on large datasets, certain deep neural networks are surprisingly good models of the neural mechanisms of adult primate visual object recognition. Nevertheless, these models are considered poor models of the development of the visual system because they posit millions of sequential, precisely coordinated synaptic updates, each based on a labeled image.  While ongoing research is pursuing the use of unsupervised proxies for labels, we here explore a complementary strategy of reducing the required number of supervised synaptic updates to produce an adult-like ventral visual stream (as judged by the match to V1, V2, V4, IT, and behavior). Such models might require less precise machinery and energy expenditure to coordinate these updates and would thus move us closer to viable neuroscientific hypotheses about how the visual system wires itself up. Relative to standard model training on labeled images in ImageNet, we here demonstrate that the total number of supervised weight updates can be substantially reduced using three complementary strategies: First, we find that only 2% of supervised updates (epochs and images) are needed to achieve 80% of the match to adult ventral stream. Specifically, training benefits predictions of higher visual cortex the most whereas early visual cortex predictions only improve marginally over the course of training. Second, by improving the random distribution of synaptic connectivity, we find that 54% of the brain match can already be achieved “at birth' (i.e. no training at all). Third, we find that, by training only 5% of model synapses, we can still achieve nearly 80% of the match to the ventral stream. This approach further improves on ImageNet performance over previous attempts in computer vision of minimizing trained components without substantially increasing the relative number of trained parameters. These results reflect first steps in modeling not just primate adult visual processing during inference, but also how the ventral visual stream might be 'wired up' by evolution (a model's 'birth' state) and by developmental learning (a model's updates based on visual experience).",
        "conference": "ICLR",
        "中文标题": "视觉连线：最小化产生灵长类腹侧视觉流所需的监督突触更新",
        "摘要翻译": "在大型数据集上训练后，某些深度神经网络出人意料地成为了成年灵长类视觉对象识别的神经机制的良好模型。然而，这些模型被认为是视觉系统发展的不良模型，因为它们假设了数百万次基于标记图像的顺序、精确协调的突触更新。尽管正在进行的研究正在探索使用无监督代理替代标签，我们在此探索了一种互补策略，即减少产生类似成人的腹侧视觉流所需的监督突触更新数量（以与V1、V2、V4、IT和行为的匹配为判断标准）。这样的模型可能需要更少的精确机制和能量消耗来协调这些更新，从而使我们更接近关于视觉系统如何自我连接的可行的神经科学假设。相对于在ImageNet上对标记图像进行标准模型训练，我们在此展示了使用三种互补策略可以大幅减少监督权重更新的总数：首先，我们发现仅需2%的监督更新（周期和图像）即可实现与成年腹侧视觉流80%的匹配。具体来说，训练对高级视觉皮层预测的益处最大，而早期视觉皮层预测在训练过程中仅略有改善。其次，通过改善突触连接的随机分布，我们发现54%的大脑匹配已经可以在“出生时”实现（即完全不需要训练）。第三，我们发现，仅训练模型突触的5%，仍可实现与腹侧视觉流近80%的匹配。这种方法在ImageNet性能上进一步改进了计算机视觉中最小化训练组件而不显著增加训练参数相对数量的先前尝试。这些结果反映了不仅在模拟灵长类成年视觉处理推理过程中，而且在模拟腹侧视觉流如何通过进化（模型的“出生”状态）和发育学习（模型基于视觉经验的更新）“连线”方面的初步步骤。",
        "领域": "视觉神经科学建模、深度学习优化、计算机视觉与神经科学交叉研究",
        "问题": "如何减少深度神经网络模拟灵长类视觉系统发展过程中所需的监督学习量",
        "动机": "探索减少监督学习量的策略，以更接近视觉系统自我连接的实际神经科学机制",
        "方法": "采用三种策略减少监督突触更新：减少训练数据量、优化初始突触连接分布、选择性训练部分突触",
        "关键词": [
            "监督学习优化",
            "视觉神经科学建模",
            "突触更新最小化",
            "深度学习效率",
            "计算机视觉与神经科学交叉"
        ],
        "涉及的技术概念": {
            "监督突触更新": "指在深度学习中基于标记数据调整模型权重的过程，本文探讨如何减少这一过程的需求",
            "腹侧视觉流": "指灵长类大脑中负责物体识别的视觉处理路径，本文目标是模拟其发展过程",
            "突触连接随机分布优化": "指在模型初始化阶段改进权重分配策略，以减少后续训练需求的技术"
        },
        "success": true
    },
    {
        "order": 1086,
        "title": "Wisdom of Committees: An Overlooked Approach To Faster and More Accurate Models",
        "html": "https://iclr.cc//virtual/2022/poster/6397",
        "abstract": "Committee-based models (ensembles or cascades) construct models by combining existing pre-trained ones. While ensembles and cascades are well-known techniques that were proposed before deep learning, they are not considered a core building block of deep model architectures and are rarely compared to in recent literature on developing efficient models. In this work, we go back to basics and conduct a comprehensive analysis of the efficiency of committee-based models. We find that even the most simplistic method for building committees from existing, independently pre-trained models can match or exceed the accuracy of state-of-the-art models while being drastically more efficient. These simple committee-based models also outperform sophisticated neural architecture search methods (e.g., BigNAS). These findings hold true for several tasks, including image classification, video classification, and semantic segmentation, and various architecture families, such as ViT, EfficientNet, ResNet, MobileNetV2, and X3D. Our results show that an EfficientNet cascade can achieve a 5.4x speedup over B7 and a ViT cascade can achieve a 2.3x speedup over ViT-L-384 while being equally accurate.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "委员会的智慧：一种被忽视的更快更准确模型的方法",
        "摘要翻译": "基于委员会的模型（集成或级联）通过组合现有的预训练模型来构建模型。虽然集成和级联是在深度学习之前提出的众所周知的技术，但它们并未被视为深度模型架构的核心构建块，并且在最近关于开发高效模型的文献中很少被比较。在这项工作中，我们回归基础，对基于委员会的模型的效率进行了全面分析。我们发现，即使是从现有的、独立预训练的模型构建委员会的最简单方法，也能匹配或超过最先进模型的准确性，同时效率大大提高。这些简单的基于委员会的模型也优于复杂的神经架构搜索方法（例如BigNAS）。这些发现在多个任务中都成立，包括图像分类、视频分类和语义分割，以及各种架构家族，如ViT、EfficientNet、ResNet、MobileNetV2和X3D。我们的结果表明，EfficientNet级联可以比B7实现5.4倍的速度提升，ViT级联可以比ViT-L-384实现2.3倍的速度提升，同时保持相同的准确性。",
        "领域": "模型集成、神经架构搜索、图像分类",
        "问题": "如何在不牺牲准确性的前提下，提高模型的效率",
        "动机": "探索基于委员会的模型（集成或级联）在提高模型效率和准确性方面的潜力，尤其是在当前深度学习研究中被忽视的这一方法",
        "方法": "通过全面分析基于委员会的模型的效率，包括集成和级联方法，与现有最先进模型和神经架构搜索方法进行比较",
        "关键词": [
            "模型集成",
            "神经架构搜索",
            "效率优化",
            "图像分类",
            "语义分割"
        ],
        "涉及的技术概念": {
            "委员会模型": "通过组合现有的预训练模型来构建模型，以提高效率和准确性",
            "神经架构搜索": "一种自动化设计神经网络架构的方法，论文中通过比较显示委员会模型的优势",
            "效率优化": "论文中通过委员会模型实现的速度提升和准确性保持，展示了在模型效率方面的优化"
        }
    },
    {
        "order": 1087,
        "title": "Wish you were here: Hindsight Goal Selection for long-horizon dexterous manipulation",
        "html": "https://iclr.cc//virtual/2022/poster/6489",
        "abstract": "Complex sequential tasks in continuous-control settings often require agents to successfully traverse a set of ``narrow passages'' in their state space. Solving such tasks with a sparse reward in a sample-efficient manner poses a challenge to modern reinforcement learning (RL) due to the associated long-horizon nature of the problem and the lack of sufficient positive signal during learning. Various tools have been applied to address this challenge. When available, large sets of demonstrations can guide agent exploration. Hindsight relabelling on the other hand does not require additional sources of information. However, existing strategies explore based on task-agnostic goal distributions, which can render the solution of long-horizon tasks impractical. In this work, we extend hindsight relabelling mechanisms to guide exploration along task-specific distributions implied by a small set of successful demonstrations. We evaluate the approach on four complex, single and dual arm, robotics manipulation tasks against strong suitable baselines. The method requires far fewer demonstrations to solve all tasks and achieves a significantly higher overall performance as task complexity increases. Finally, we investigate the robustness of the proposed solution with respect to the quality of input representations and the number of demonstrations.",
        "conference": "ICLR",
        "中文标题": "愿你在此：针对长视距灵巧操作的后见之明目标选择",
        "摘要翻译": "在连续控制设置中的复杂顺序任务通常要求代理在其状态空间中成功穿越一系列‘狭窄通道’。由于问题的长视距性质和学习过程中缺乏足够的积极信号，以样本高效的方式解决这种稀疏奖励的任务对现代强化学习（RL）提出了挑战。已经应用了各种工具来应对这一挑战。当可用时，大量的演示集可以指导代理探索。另一方面，后见之明重新标记不需要额外的信息来源。然而，现有的策略基于任务无关的目标分布进行探索，这可能使得长视距任务的解决方案变得不切实际。在这项工作中，我们扩展了后见之明重新标记机制，以通过一小部分成功演示所暗示的任务特定分布来指导探索。我们在四个复杂的单臂和双臂机器人操作任务上评估了该方法，并与强大的合适基线进行了比较。该方法需要更少的演示来解决所有任务，并且随着任务复杂度的增加，实现了显著更高的整体性能。最后，我们研究了所提出解决方案对于输入表示质量和演示数量的鲁棒性。",
        "领域": "机器人操作、强化学习、灵巧控制",
        "问题": "解决在连续控制设置中，由于长视距任务和稀疏奖励导致的样本效率低下问题。",
        "动机": "通过利用一小部分成功演示的任务特定分布，提高强化学习在复杂顺序任务中的探索效率和性能。",
        "方法": "扩展后见之明重新标记机制，利用任务特定分布指导探索，减少对演示数量的依赖。",
        "关键词": [
            "后见之明重新标记",
            "任务特定分布",
            "机器人操作",
            "强化学习",
            "灵巧控制"
        ],
        "涉及的技术概念": {
            "后见之明重新标记": "一种不需要额外信息来源的技术，通过重新标记过去的经验来指导代理的探索。",
            "任务特定分布": "由成功演示暗示的分布，用于指导代理在特定任务中的探索。",
            "强化学习": "一种学习方法，代理通过与环境互动来学习策略，以最大化累积奖励。"
        },
        "success": true
    },
    {
        "order": 1088,
        "title": "X-model: Improving Data Efficiency in Deep Learning with A Minimax Model",
        "html": "https://iclr.cc//virtual/2022/poster/6998",
        "abstract": "To mitigate the burden of data labeling, we aim at improving data efficiency for both classification and regression setups in deep learning. However, the current focus is on classification problems while rare attention has been paid to deep regression, which usually requires more human effort to labeling. Further, due to the intrinsic difference between categorical and continuous label space, the common intuitions for classification, \\textit{e.g.} cluster assumptions or pseudo labeling strategies, cannot be naturally adapted into deep regression. To this end, we first delved into the existing data-efficient methods in deep learning and found that they either encourage invariance to \\textit{data stochasticity} (\\textit{e.g.}, consistency regularization under different augmentations) or \\textit{model stochasticity} (\\textit{e.g.}, difference penalty for predictions of models with different dropout). To take the power of both worlds, we propose a novel \\Chi-model by simultaneously encouraging the invariance to {data stochasticity} and {model stochasticity}. Further, the \\Chi-model plays a minimax game between the feature extractor and task-specific heads to further enhance the invariance to model stochasticity. Extensive experiments verify the superiority of the \\Chi-model among various tasks, from a single-value prediction task of age estimation to a dense-value prediction task of keypoint localization, a 2D synthetic and a 3D realistic dataset, as well as a multi-category object recognition task.",
        "conference": "ICLR",
        "中文标题": "X模型：通过极小极大模型提高深度学习中的数据效率",
        "摘要翻译": "为了减轻数据标注的负担，我们旨在提高深度学习中分类和回归设置的数据效率。然而，当前的研究主要集中在分类问题上，而对深度回归的关注较少，后者通常需要更多的人力进行标注。此外，由于分类和连续标签空间之间的内在差异，分类的常见直觉，例如聚类假设或伪标签策略，不能自然地适应深度回归。为此，我们首先深入研究了深度学习中现有的数据高效方法，发现它们要么鼓励对数据随机性的不变性（例如，在不同增强下的一致性正则化），要么鼓励对模型随机性的不变性（例如，对不同dropout模型预测的差异惩罚）。为了结合两者的优势，我们提出了一种新颖的X模型，通过同时鼓励对数据随机性和模型随机性的不变性。此外，X模型在特征提取器和任务特定头之间进行极小极大博弈，以进一步增强对模型随机性的不变性。大量实验验证了X模型在各种任务中的优越性，从年龄估计的单值预测任务到关键点定位的密集值预测任务，一个2D合成和一个3D现实数据集，以及一个多类别物体识别任务。",
        "领域": "深度学习数据效率、深度回归、多任务学习",
        "问题": "提高深度学习中分类和回归任务的数据效率，特别是在深度回归任务中减少对大量标注数据的依赖。",
        "动机": "当前深度学习中的数据高效方法主要集中于分类问题，深度回归任务因需要更多人力标注而较少受到关注，且分类任务中的直觉和方法不能直接应用于回归任务。",
        "方法": "提出X模型，通过同时鼓励对数据随机性和模型随机性的不变性，并在特征提取器和任务特定头之间进行极小极大博弈，以提高数据效率。",
        "关键词": [
            "数据效率",
            "深度回归",
            "极小极大模型",
            "不变性学习",
            "多任务学习"
        ],
        "涉及的技术概念": {
            "数据随机性不变性": "在不同数据增强下保持模型预测的一致性，以提高模型对数据变化的鲁棒性。",
            "模型随机性不变性": "通过惩罚不同dropout模型预测的差异，增强模型对内部随机变化的稳定性。",
            "极小极大博弈": "在特征提取器和任务特定头之间进行的优化策略，旨在通过对抗性训练进一步增强模型对模型随机性的不变性。"
        },
        "success": true
    },
    {
        "order": 1089,
        "title": "You are AllSet: A Multiset Function Framework for Hypergraph Neural Networks",
        "html": "https://iclr.cc//virtual/2022/poster/6302",
        "abstract": "Hypergraphs are used to model higher-order interactions amongst agents and there exist many practically relevant instances of hypergraph datasets. To enable the efficient processing of hypergraph data, several hypergraph neural network platforms have been proposed for learning hypergraph properties and structure, with a special focus on node classification tasks. However, almost all existing methods use heuristic propagation rules and offer suboptimal performance on benchmarking datasets. We propose AllSet, a new hypergraph neural network paradigm that represents a highly general framework for (hyper)graph neural networks and for the first time implements hypergraph neural network layers as compositions of two multiset functions that can be efficiently learned for each task and each dataset. The proposed AllSet framework also for the first time integrates Deep Sets and Set Transformers with hypergraph neural networks for the purpose of learning multiset functions and therefore allows for significant modeling flexibility and high expressive power. To evaluate the performance of AllSet, we conduct the most extensive experiments to date involving ten known benchmarking datasets and three newly curated datasets that represent significant challenges for hypergraph node classification. The results demonstrate that our method has the unique ability to either match or outperform all other hypergraph neural networks across the tested datasets: As an example, the performance improvements over existing methods and a new method based on heterogeneous graph neural networks are close to $4\\%$ on the Yelp and Zoo datasets, and $3\\%$ on the Walmart dataset.",
        "conference": "ICLR",
        "中文标题": "AllSet：超图神经网络的多集函数框架",
        "摘要翻译": "超图用于建模代理之间的高阶交互，并且存在许多实际相关的超图数据集实例。为了高效处理超图数据，已经提出了几种超图神经网络平台，用于学习超图属性和结构，特别关注节点分类任务。然而，几乎所有现有方法都使用启发式传播规则，并在基准数据集上提供次优性能。我们提出了AllSet，一种新的超图神经网络范式，代表了一个高度通用的（超）图神经网络框架，并首次将超图神经网络层实现为两个多集函数的组合，这些函数可以针对每个任务和每个数据集高效学习。提出的AllSet框架还首次将Deep Sets和Set Transformers与超图神经网络集成，用于学习多集函数，因此允许显著的建模灵活性和高表达能力。为了评估AllSet的性能，我们进行了迄今为止最广泛的实验，涉及十个已知的基准数据集和三个新策划的数据集，这些数据集代表了超图节点分类的重大挑战。结果表明，我们的方法具有独特的能力，可以在测试的数据集上匹配或超越所有其他超图神经网络：例如，在Yelp和Zoo数据集上，与现有方法和基于异构图神经网络的新方法相比，性能提升接近4%，在Walmart数据集上提升3%。",
        "领域": "超图学习、图神经网络、节点分类",
        "问题": "现有超图神经网络方法使用启发式传播规则，在基准数据集上表现不佳",
        "动机": "提出一个高度通用的超图神经网络框架，通过多集函数的学习提高模型性能和灵活性",
        "方法": "提出AllSet框架，将超图神经网络层实现为两个可学习的多集函数的组合，并集成Deep Sets和Set Transformers技术",
        "关键词": [
            "超图神经网络",
            "多集函数",
            "节点分类",
            "Deep Sets",
            "Set Transformers"
        ],
        "涉及的技术概念": {
            "多集函数": "用于组合超图神经网络层的两个函数，允许针对特定任务和数据集进行高效学习",
            "Deep Sets": "一种处理集合数据的神经网络架构，用于学习多集函数，提高模型的表达能力",
            "Set Transformers": "一种基于注意力机制的集合数据处理方法，用于增强模型对超图结构的理解和处理能力"
        },
        "success": true
    },
    {
        "order": 1090,
        "title": "You Mostly Walk Alone: Analyzing Feature Attribution in Trajectory Prediction",
        "html": "https://iclr.cc//virtual/2022/poster/6404",
        "abstract": "Predicting the future trajectory of a moving agent can be easy when the past trajectory continues smoothly but is challenging when complex interactions with other agents are involved. Recent deep learning approaches for trajectory prediction show promising performance and partially attribute this to successful reasoning about agent-agent interactions.  However, it remains unclear which features such black-box models actually learn to use for making predictions. This paper proposes a procedure that quantifies the contributions of different cues to model performance based on a variant of Shapley values. Applying this procedure to state-of-the-art trajectory prediction methods on standard benchmark datasets shows that they are, in fact, unable to reason about interactions. Instead, the past trajectory of the target is the only feature used for predicting its future. For a task with richer social interaction patterns, on the other hand, the tested models do pick up such interactions to a certain extent, as quantified by our feature attribution method. We discuss the limits of the proposed method and its links to causality.",
        "conference": "ICLR",
        "中文标题": "你大多独自行走：分析轨迹预测中的特征归因",
        "摘要翻译": "预测移动代理的未来轨迹在过去的轨迹平稳延续时可能很容易，但在涉及与其他代理的复杂交互时则具有挑战性。最近用于轨迹预测的深度学习方法显示出有希望的性能，并部分归因于成功地对代理间交互进行了推理。然而，这些黑盒模型实际上学习使用哪些特征进行预测仍不明确。本文提出了一种程序，基于Shapley值的一个变体，量化不同线索对模型性能的贡献。将这一程序应用于标准基准数据集上的最先进轨迹预测方法，结果表明它们实际上无法对交互进行推理。相反，目标的过去轨迹是用于预测其未来的唯一特征。另一方面，对于具有更丰富社交互动模式的任务，测试的模型确实在一定程度上捕捉到了这些互动，正如我们的特征归因方法所量化的那样。我们讨论了所提出方法的限制及其与因果性的联系。",
        "领域": "轨迹预测、社交互动分析、特征归因",
        "问题": "理解深度轨迹预测模型在实际预测中使用哪些特征，特别是是否能够有效利用代理间的交互信息。",
        "动机": "揭示当前深度轨迹预测模型是否真正能够理解和利用代理间的复杂交互信息进行预测，以及这些模型在实际应用中可能存在的局限性。",
        "方法": "提出了一种基于Shapley值变体的特征归因方法，用于量化不同特征对模型预测性能的贡献，并应用于现有轨迹预测模型进行分析。",
        "关键词": [
            "轨迹预测",
            "特征归因",
            "Shapley值",
            "社交互动",
            "深度学习"
        ],
        "涉及的技术概念": {
            "Shapley值": "用于量化不同特征对模型预测性能的贡献，帮助理解模型决策的依据。",
            "轨迹预测": "预测移动代理未来路径的技术，广泛应用于自动驾驶、机器人导航等领域。",
            "社交互动分析": "分析移动代理间的交互模式，以预测其未来行为，特别是在密集或动态环境中。"
        },
        "success": true
    },
    {
        "order": 1091,
        "title": "Zero-CL: Instance and Feature decorrelation for negative-free symmetric contrastive learning",
        "html": "https://iclr.cc//virtual/2022/poster/5905",
        "abstract": "For self-supervised contrastive learning, models can easily collapse and generate trivial constant solutions. The issue has been mitigated by recent improvement on objective design, which however often requires square complexity either for the size of instances ($\\mathcal{O}(N^{2})$) or feature dimensions ($\\mathcal{O}(d)^2$). To prevent such collapse, we develop two novel methods by decorrelating on different dimensions on the instance embedding stacking matrix, i.e., \\textbf{I}nstance-wise (ICL) and \\textbf{F}eature-wise (FCL) \\textbf{C}ontrastive \\textbf{L}earning. The proposed two methods (FCL, ICL) can be combined synthetically, called Zero-CL, where ``Zero'' means negative samples are \\textbf{zero} relevant, which allows Zero-CL to completely discard negative pairs i.e., with \\textbf{zero} negative samples. Compared with previous methods, Zero-CL mainly enjoys three advantages: 1) Negative free in symmetric architecture. 2) By whitening transformation, the correlation of the different features is equal to zero, alleviating information redundancy. 3) Zero-CL remains original information to a great extent after transformation, which improves the accuracy against other whitening transformation techniques. Extensive experimental results on CIFAR-10/100 and ImageNet show that Zero-CL outperforms or is on par with state-of-the-art symmetric contrastive learning methods.",
        "conference": "ICLR",
        "中文标题": "Zero-CL：用于无负样本对称对比学习的实例与特征解相关",
        "摘要翻译": "对于自监督对比学习，模型容易崩溃并生成平凡的常数解。这一问题已通过最近在目标设计上的改进得到缓解，然而这些改进通常需要实例数量（O(N^2)）或特征维度（O(d)^2）的平方复杂度。为了防止这种崩溃，我们通过在实例嵌入堆叠矩阵的不同维度上进行解相关，开发了两种新方法，即实例级（ICL）和特征级（FCL）对比学习。提出的这两种方法（FCL，ICL）可以综合结合，称为Zero-CL，其中“Zero”意味着负样本完全无关，这使得Zero-CL可以完全丢弃负样本对，即使用零负样本。与之前的方法相比，Zero-CL主要享有三个优势：1）在对称架构中无需负样本。2）通过白化变换，不同特征的相关性等于零，减轻了信息冗余。3）Zero-CL在变换后很大程度上保留了原始信息，这提高了相对于其他白化变换技术的准确性。在CIFAR-10/100和ImageNet上的大量实验结果表明，Zero-CL优于或与最先进的对称对比学习方法持平。",
        "领域": "自监督学习、对比学习、图像识别",
        "问题": "解决自监督对比学习中模型容易崩溃并生成平凡解的问题，同时减少计算复杂度。",
        "动机": "为了克服自监督对比学习中的模型崩溃问题，并减少计算复杂度，开发无需负样本的高效对比学习方法。",
        "方法": "通过在实例嵌入堆叠矩阵的不同维度上进行解相关，开发实例级和特征级对比学习方法，并将这两种方法综合结合为Zero-CL。",
        "关键词": [
            "自监督学习",
            "对比学习",
            "无负样本",
            "白化变换",
            "对称架构"
        ],
        "涉及的技术概念": {
            "实例级对比学习（ICL）": "通过在实例维度上进行解相关，防止模型崩溃。",
            "特征级对比学习（FCL）": "通过在特征维度上进行解相关，减轻信息冗余。",
            "白化变换": "用于使不同特征的相关性等于零，保留原始信息，提高模型准确性。"
        },
        "success": true
    },
    {
        "order": 1092,
        "title": "ZeroFL: Efficient On-Device Training for  Federated Learning with Local Sparsity",
        "html": "https://iclr.cc//virtual/2022/poster/6036",
        "abstract": "When the available hardware cannot meet the memory and compute requirements to efficiently train high performing machine learning models, a compromise in either the training quality or the model complexity is needed. In Federated Learning (FL), nodes are orders of magnitude more constrained than traditional server-grade hardware and are often battery powered, severely limiting the sophistication of models that can be trained under this paradigm. While most research has focused on designing better aggregation strategies to improve convergence rates and in alleviating the communication costs of FL, fewer efforts have been devoted to accelerating on-device training. Such stage, which repeats hundreds of times (i.e. every round) and can involve thousands of devices, accounts for the majority of the time required to train federated models and, the totality of the energy consumption at the client side. In this work, we present the first study on the unique aspects that arise when introducing sparsity at training time in FL workloads. We then propose ZeroFL, a framework that relies on highly sparse operations to accelerate on-device training. Models trained with ZeroFL and 95% sparsity achieve up to 2.3% higher accuracy compared to competitive baselines obtained from adapting a state-of-the-art sparse training framework to the FL setting.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "ZeroFL：联邦学习中基于本地稀疏性的高效设备端训练",
        "摘要翻译": "当可用硬件无法满足高效训练高性能机器学习模型的内存和计算需求时，需要在训练质量或模型复杂性之间做出妥协。在联邦学习（FL）中，节点的约束条件比传统服务器级硬件高出几个数量级，并且通常由电池供电，这严重限制了在该范式下可以训练的模型的复杂性。虽然大多数研究都集中在设计更好的聚合策略以提高收敛速度和减轻FL的通信成本上，但较少有努力致力于加速设备端训练。这一阶段重复数百次（即每一轮），可能涉及数千台设备，占据了训练联邦模型所需的大部分时间，以及客户端的总能量消耗。在这项工作中，我们首次研究了在FL工作负载中引入训练时稀疏性所带来的独特方面。然后，我们提出了ZeroFL，这是一个依赖于高度稀疏操作来加速设备端训练的框架。与将最先进的稀疏训练框架适应FL设置所获得的竞争基线相比，使用ZeroFL和95%稀疏性训练的模型实现了高达2.3%的更高准确率。",
        "领域": "联邦学习、设备端机器学习、模型优化",
        "问题": "解决在资源受限的设备上高效训练联邦学习模型的问题",
        "动机": "由于联邦学习中的设备通常资源有限，且由电池供电，这限制了可以训练的模型的复杂性，因此需要一种方法来加速设备端训练，同时减少能量消耗。",
        "方法": "提出了ZeroFL框架，该框架利用高度稀疏的操作来加速设备端训练，从而在保持或提高模型准确性的同时减少计算和内存需求。",
        "关键词": [
            "联邦学习",
            "设备端训练",
            "模型稀疏性",
            "高效计算",
            "能量消耗优化"
        ],
        "涉及的技术概念": {
            "联邦学习": "一种机器学习方法，允许多个设备或服务器在本地数据上训练模型，而无需共享数据本身。",
            "模型稀疏性": "通过减少模型中非零参数的数量来降低模型的计算和内存需求，同时尝试保持模型性能。",
            "设备端训练": "在终端设备上直接进行模型训练，而不是在中央服务器上，这有助于保护数据隐私并减少数据传输。"
        }
    },
    {
        "order": 1093,
        "title": "Zero Pixel Directional Boundary by Vector Transform",
        "html": "https://iclr.cc//virtual/2022/poster/6022",
        "abstract": "Boundaries or contours are among the primary visual cues used by human and computer vision systems. One of the key problems in boundary detection is the loss formulation, which typically leads to class imbalance and, as a consequence, to thick boundaries which require non-differential post-processing steps to be thinned.In this paper, we re-interpret boundaries as 1-D surfaces and formulate a one-to-one vector transform function that allows for training of boundary prediction completely avoiding the class imbalance issue. Specifically, we define the boundary representation at any point as the unit vector pointing to the closest boundary surface.Our problem formulation leads to the estimation of direction as well as richer contextual information of the boundary, and, if desired, the availability of zero-pixel thin boundaries also at training time. Our method uses no hyper-parameter in the training loss and a fixed stable hyper-parameter at inference. We provide theoretical justification/discussions of the vector transform representation. We evaluate the proposed loss method using a standard architecture and show the excellent performance over other losses and representations on several datasets.",
        "conference": "ICLR",
        "success": true,
        "中文标题": "通过向量变换实现的零像素方向边界",
        "摘要翻译": "边界或轮廓是人类和计算机视觉系统使用的主要视觉线索之一。边界检测中的一个关键问题是损失函数的制定，这通常会导致类别不平衡，进而产生需要非微分后处理步骤来细化的粗边界。在本文中，我们将边界重新解释为一维表面，并制定了一个一对一的向量变换函数，该函数允许完全避免类别不平衡问题的边界预测训练。具体来说，我们将任何点的边界表示定义为指向最近边界表面的单位向量。我们的问题制定导致了边界方向以及更丰富的上下文信息的估计，并且如果需要，还可以在训练时获得零像素细边界。我们的方法在训练损失中不使用超参数，在推理时使用一个固定的稳定超参数。我们提供了向量变换表示的理论论证/讨论。我们使用标准架构评估了所提出的损失方法，并在多个数据集上展示了优于其他损失和表示的性能。",
        "领域": "图像分割, 边缘检测, 计算机视觉中的深度学习应用",
        "问题": "解决边界检测中的类别不平衡问题和粗边界问题",
        "动机": "通过重新定义边界表示和损失函数，避免传统方法中的类别不平衡问题，实现更精确的边界检测",
        "方法": "提出一种一对一的向量变换函数，将边界表示为一维表面，并使用单位向量指向最近的边界表面，从而在训练时实现零像素细边界",
        "关键词": [
            "边界检测",
            "向量变换",
            "零像素边界",
            "类别不平衡",
            "深度学习"
        ],
        "涉及的技术概念": {
            "向量变换函数": "用于将边界表示为一维表面，避免类别不平衡问题",
            "单位向量": "用于定义任何点的边界表示，指向最近的边界表面",
            "零像素边界": "在训练时实现细边界，无需后处理步骤"
        }
    },
    {
        "order": 1094,
        "title": "Zero-Shot Self-Supervised Learning for MRI Reconstruction",
        "html": "https://iclr.cc//virtual/2022/poster/6862",
        "abstract": "Deep learning (DL) has emerged as a powerful tool for accelerated MRI reconstruction, but often necessitates a database of fully-sampled measurements for training. Recent self-supervised and unsupervised learning approaches enable training without fully-sampled data. However, a database of undersampled measurements may not be available in many scenarios, especially for scans involving contrast or translational acquisitions in development. Moreover, recent studies show that database-trained models may not generalize well when the unseen measurements differ in terms of sampling pattern, acceleration rate, SNR, image contrast, and anatomy. Such challenges necessitate a new methodology to enable subject-specific DL MRI reconstruction without external training datasets, since it is clinically imperative to provide high-quality reconstructions that can be used to identify lesions/disease for $\\textit{every individual}$. In this work, we propose a zero-shot self-supervised learning approach to perform subject-specific accelerated DL MRI reconstruction to tackle these issues. The proposed approach partitions the available measurements from a single scan into three disjoint sets. Two of these sets are used to enforce data consistency and define loss during training for self-supervision, while the last set serves to self-validate, establishing an early stopping criterion. In the presence of models pre-trained on a database with different image characteristics, we show that the proposed approach can be combined with transfer learning for faster convergence time and reduced computational complexity.",
        "conference": "ICLR",
        "中文标题": "零样本自监督学习用于MRI重建",
        "摘要翻译": "深度学习（DL）已成为加速MRI重建的强大工具，但通常需要完全采样的测量数据库进行训练。最近的自监督和无监督学习方法使得无需完全采样数据即可进行训练。然而，在许多情况下，尤其是在涉及对比度或开发中的平移采集扫描时，可能无法获得欠采样测量的数据库。此外，最近的研究表明，当未见过的测量在采样模式、加速率、信噪比（SNR）、图像对比度和解剖结构方面存在差异时，数据库训练的模型可能泛化能力不佳。这些挑战需要一种新的方法，以实现无需外部训练数据集的特定主题DL MRI重建，因为临床上必须提供可用于识别每个个体病变/疾病的高质量重建。在这项工作中，我们提出了一种零样本自监督学习方法，以执行特定主题的加速DL MRI重建来解决这些问题。所提出的方法将单个扫描的可用测量分为三个不相交的集合。其中两个集合用于在训练期间强制执行数据一致性和定义损失以实现自监督，而最后一个集合用于自我验证，建立早期停止标准。在存在具有不同图像特征的数据库预训练模型的情况下，我们展示了所提出的方法可以与迁移学习结合使用，以实现更快的收敛时间和降低的计算复杂度。",
        "领域": "医学图像重建",
        "问题": "在缺乏完全采样或欠采样测量数据库的情况下，实现特定主题的高质量MRI重建",
        "动机": "解决数据库训练的模型在采样模式、加速率、SNR、图像对比度和解剖结构差异下的泛化能力问题，以及在没有外部训练数据集的情况下实现特定主题的高质量MRI重建",
        "方法": "提出一种零样本自监督学习方法，将单个扫描的测量分为三个集合，两个用于自监督训练，一个用于自我验证，结合迁移学习以优化性能",
        "关键词": [
            "零样本学习",
            "自监督学习",
            "MRI重建",
            "迁移学习",
            "深度学习"
        ],
        "涉及的技术概念": {
            "零样本学习": "在无需外部训练数据集的情况下，直接对单个扫描进行模型训练和重建",
            "自监督学习": "利用数据本身的结构和关系进行训练，无需人工标注",
            "迁移学习": "利用预训练模型的知识，加速新任务的学习过程并提高性能"
        },
        "success": true
    }
]